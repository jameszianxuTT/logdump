Using PJRT plugin directory: /localdev/jameszianxu/tt-xla/python_package/pjrt_plugin_tt
Using TT-Metal from the source tree: /localdev/jameszianxu/tt-xla/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
WARNING: TT plugin is setting XLA_STABLEHLO_COMPILE to 1. This is required for TT PJRT plugin to work correctly.
============================= test session starts ==============================
platform linux -- Python 3.11.14, pytest-8.4.2, pluggy-1.6.0 -- /localdev/jameszianxu/tt-xla/venv/bin/python
cachedir: .pytest_cache
metadata: {'Python': '3.11.14', 'Platform': 'Linux-5.4.0-216-generic-x86_64-with-glibc2.35', 'Packages': {'pytest': '8.4.2', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.12.1', 'jaxtyping': '0.3.6', 'json-report': '1.5.0', 'metadata': '3.1.1', 'split': '0.10.0', 'forked': '1.6.0'}}
rootdir: /localdev/jameszianxu/tt-xla
configfile: pytest.ini
plugins: anyio-4.12.1, jaxtyping-0.3.6, json-report-1.5.0, metadata-3.1.1, split-0.10.0, forked-1.6.0
collecting ... collected 1 item

tests/torch/training/test_basic.py::test_qwen3_multichip_backward 2026-01-28 22:12:52.833 (   0.000s) [        66B35000]   plugin_attributes.cc:60       1| PluginAttributes::PJRT_Plugin_Initialize
2026-01-28 22:12:52.833 (   0.000s) [        66B35000]     client_instance.cc:546      1| ClientInstance::PJRT_Client_Create
2026-01-28 22:12:52.836 (   0.003s) [        66B35000]     client_instance.cc:177      1| ClientInstance::ClientInstance
2026-01-28 22:12:52.836 (   0.003s) [        66B35000]     client_instance.cc:198      1| ClientInstance::Initialize
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Device grid size = { 8, 8 }
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Device grid size = { 8, 8 }
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]              stubs.inc:103   WARN| STUB: PJRT_Client_TopologyDescription
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]     client_instance.cc:600      1| ClientInstance::PJRT_Client_PlatformVersion
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]     client_instance.cc:581      1| ClientInstance::PJRT_Client_PlatformName
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]     client_instance.cc:611      1| ClientInstance::PJRT_Client_Devices
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:82       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:82       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]     client_instance.cc:624      1| ClientInstance::PJRT_Client_AddressableDevices
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]     client_instance.cc:674      1| ClientInstance::PJRT_Client_AddressableMemories
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]   plugin_attributes.cc:66       1| PluginAttributes::PJRT_Plugin_Attributes
2026-01-28 22:12:54.282852: W torch_xla/csrc/runtime/profiler.cpp:88] Profiler API not found for PJRT plugin
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:120      1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:120      1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.282 (   1.449s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.517 (   1.684s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.517 (   1.684s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.518 (   1.685s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.518 (   1.685s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.518 (   1.685s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.520 (   1.686s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.520 (   1.686s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.520 (   1.686s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.520 (   1.686s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.520 (   1.686s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.520 (   1.687s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.520 (   1.687s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.520 (   1.687s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.520 (   1.687s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.522 (   1.689s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.522 (   1.689s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.522 (   1.689s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.522 (   1.689s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.523 (   1.689s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.523 (   1.689s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.523 (   1.689s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.523 (   1.689s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.523 (   1.689s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.523 (   1.689s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.523 (   1.690s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.523 (   1.690s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.524 (   1.691s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.524 (   1.691s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.524 (   1.691s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.524 (   1.691s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.524 (   1.691s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.524 (   1.691s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.524 (   1.691s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.524 (   1.691s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.524 (   1.691s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.524 (   1.691s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.525 (   1.691s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.525 (   1.691s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.526 (   1.693s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.526 (   1.693s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.526 (   1.693s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.526 (   1.693s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.526 (   1.693s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.526 (   1.693s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.526 (   1.693s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.526 (   1.693s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.527 (   1.693s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.527 (   1.693s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.527 (   1.693s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.527 (   1.693s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.527 (   1.694s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.527 (   1.694s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.527 (   1.694s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.528 (   1.694s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.528 (   1.694s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.528 (   1.694s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.528 (   1.694s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.528 (   1.694s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.528 (   1.694s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.528 (   1.694s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.528 (   1.695s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.528 (   1.695s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.528 (   1.695s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.529 (   1.695s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.529 (   1.695s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.529 (   1.695s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.529 (   1.695s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.529 (   1.695s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.529 (   1.695s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.529 (   1.696s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.529 (   1.696s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.529 (   1.696s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.529 (   1.696s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.529 (   1.696s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.530 (   1.696s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.530 (   1.696s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.530 (   1.696s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.530 (   1.697s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.530 (   1.697s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.530 (   1.697s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.530 (   1.697s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.530 (   1.697s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.530 (   1.697s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.530 (   1.697s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.530 (   1.697s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.531 (   1.697s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.531 (   1.698s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.531 (   1.698s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.531 (   1.698s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.531 (   1.698s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.531 (   1.698s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.531 (   1.698s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.531 (   1.698s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.531 (   1.698s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.532 (   1.698s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.532 (   1.698s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.532 (   1.698s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.532 (   1.699s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.533 (   1.699s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.533 (   1.699s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.533 (   1.699s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.533 (   1.700s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.533 (   1.700s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.533 (   1.700s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.533 (   1.700s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.533 (   1.700s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.533 (   1.700s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.533 (   1.700s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.534 (   1.700s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.534 (   1.700s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.535 (   1.702s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.535 (   1.702s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.535 (   1.702s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.535 (   1.702s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.535 (   1.702s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.535 (   1.702s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.535 (   1.702s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.535 (   1.702s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.535 (   1.702s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.535 (   1.702s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.535 (   1.702s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.535 (   1.702s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.536 (   1.703s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.536 (   1.703s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.536 (   1.703s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.536 (   1.703s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.536 (   1.703s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.536 (   1.703s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.536 (   1.703s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.536 (   1.703s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.536 (   1.703s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.536 (   1.703s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.536 (   1.703s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.536 (   1.703s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.537 (   1.703s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.537 (   1.703s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.537 (   1.703s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.537 (   1.704s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.537 (   1.704s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.537 (   1.704s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.537 (   1.704s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.537 (   1.704s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.537 (   1.704s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.537 (   1.704s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.537 (   1.704s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.537 (   1.704s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.538 (   1.704s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.538 (   1.704s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.538 (   1.704s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.538 (   1.705s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.538 (   1.705s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.538 (   1.705s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.538 (   1.705s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.538 (   1.705s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.538 (   1.705s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.538 (   1.705s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.538 (   1.705s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.538 (   1.705s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.539 (   1.706s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.539 (   1.706s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.539 (   1.706s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.539 (   1.706s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.539 (   1.706s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.539 (   1.706s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.539 (   1.706s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.539 (   1.706s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.539 (   1.706s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.539 (   1.706s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.540 (   1.706s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.540 (   1.706s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.540 (   1.707s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.540 (   1.707s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.540 (   1.707s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.541 (   1.707s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.541 (   1.707s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.541 (   1.707s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.541 (   1.707s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.541 (   1.707s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.541 (   1.707s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.541 (   1.707s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.541 (   1.707s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.541 (   1.708s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.541 (   1.708s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.541 (   1.708s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.541 (   1.708s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.541 (   1.708s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.541 (   1.708s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.541 (   1.708s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.541 (   1.708s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.541 (   1.708s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.542 (   1.708s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.542 (   1.708s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.542 (   1.708s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.542 (   1.708s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.542 (   1.709s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.542 (   1.709s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.542 (   1.709s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.542 (   1.709s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.542 (   1.709s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.542 (   1.709s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.542 (   1.709s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.542 (   1.709s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.543 (   1.709s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.543 (   1.709s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.543 (   1.709s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.543 (   1.709s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.543 (   1.710s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.543 (   1.710s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.543 (   1.710s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.543 (   1.710s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.543 (   1.710s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.544 (   1.710s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.544 (   1.710s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.544 (   1.710s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.544 (   1.710s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.544 (   1.710s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.544 (   1.711s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.544 (   1.711s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.544 (   1.711s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.544 (   1.711s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.544 (   1.711s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.544 (   1.711s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.544 (   1.711s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.544 (   1.711s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.544 (   1.711s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.544 (   1.711s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.545 (   1.711s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.545 (   1.711s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.545 (   1.711s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.545 (   1.711s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.545 (   1.712s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.545 (   1.712s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.545 (   1.712s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.545 (   1.712s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.545 (   1.712s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.545 (   1.712s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.545 (   1.712s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.545 (   1.712s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.545 (   1.712s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.545 (   1.712s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.545 (   1.712s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.545 (   1.712s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.546 (   1.713s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.546 (   1.713s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.546 (   1.713s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.546 (   1.713s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.546 (   1.713s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.546 (   1.713s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.546 (   1.713s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.546 (   1.713s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.546 (   1.713s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.546 (   1.713s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.546 (   1.713s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.546 (   1.713s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.547 (   1.714s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.547 (   1.714s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.547 (   1.714s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.547 (   1.714s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.548 (   1.714s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.548 (   1.714s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.548 (   1.714s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.548 (   1.714s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.548 (   1.714s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.548 (   1.714s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.548 (   1.714s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.548 (   1.715s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.548 (   1.715s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.548 (   1.715s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.548 (   1.715s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.548 (   1.715s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.549 (   1.715s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.549 (   1.715s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.549 (   1.715s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.549 (   1.715s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.549 (   1.715s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.549 (   1.715s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.549 (   1.715s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.549 (   1.715s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.549 (   1.716s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.549 (   1.716s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.550 (   1.716s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.550 (   1.716s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.550 (   1.716s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.550 (   1.716s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.550 (   1.716s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.550 (   1.716s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.550 (   1.717s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.550 (   1.717s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.550 (   1.717s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.550 (   1.717s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.551 (   1.717s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.551 (   1.717s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.551 (   1.717s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.551 (   1.717s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.551 (   1.717s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.551 (   1.717s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.551 (   1.717s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.551 (   1.717s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.551 (   1.718s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.551 (   1.718s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.551 (   1.718s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.551 (   1.718s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.551 (   1.718s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.551 (   1.718s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.551 (   1.718s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.551 (   1.718s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.551 (   1.718s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.551 (   1.718s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.552 (   1.718s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.552 (   1.718s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.552 (   1.718s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.552 (   1.718s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.552 (   1.718s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.552 (   1.718s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.552 (   1.719s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.552 (   1.719s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.552 (   1.719s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.552 (   1.719s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.552 (   1.719s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.552 (   1.719s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.552 (   1.719s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.552 (   1.719s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.552 (   1.719s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.552 (   1.719s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.553 (   1.719s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.553 (   1.719s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.553 (   1.720s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.553 (   1.720s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.553 (   1.720s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.553 (   1.720s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.553 (   1.720s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.553 (   1.720s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.553 (   1.720s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.553 (   1.720s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.553 (   1.720s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.553 (   1.720s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.553 (   1.720s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.554 (   1.720s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.554 (   1.721s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.554 (   1.721s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.554 (   1.721s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.554 (   1.721s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.555 (   1.721s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.555 (   1.721s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.555 (   1.721s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.555 (   1.721s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.555 (   1.722s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.555 (   1.722s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.555 (   1.722s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.555 (   1.722s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.556 (   1.722s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.556 (   1.722s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.556 (   1.722s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.556 (   1.723s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.556 (   1.723s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.556 (   1.723s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.556 (   1.723s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.556 (   1.723s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.556 (   1.723s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.556 (   1.723s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.556 (   1.723s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.556 (   1.723s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.557 (   1.724s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.557 (   1.724s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.557 (   1.724s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.557 (   1.724s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.557 (   1.724s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.557 (   1.724s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.557 (   1.724s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.557 (   1.724s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.557 (   1.724s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.557 (   1.724s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.558 (   1.724s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.558 (   1.724s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.558 (   1.725s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.558 (   1.725s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.558 (   1.725s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.558 (   1.725s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.558 (   1.725s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.558 (   1.725s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.558 (   1.725s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.558 (   1.725s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.558 (   1.725s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.558 (   1.725s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.559 (   1.725s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.559 (   1.725s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.559 (   1.725s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.559 (   1.725s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.559 (   1.725s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.559 (   1.726s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.559 (   1.726s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.559 (   1.726s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.559 (   1.726s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.559 (   1.726s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.559 (   1.726s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.559 (   1.726s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.559 (   1.726s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.559 (   1.726s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.560 (   1.726s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.560 (   1.726s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.560 (   1.726s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.560 (   1.726s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.560 (   1.726s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.560 (   1.726s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.560 (   1.726s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.560 (   1.726s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.560 (   1.727s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.560 (   1.727s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.560 (   1.727s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.560 (   1.727s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.561 (   1.727s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.561 (   1.727s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.561 (   1.727s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.561 (   1.727s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.561 (   1.727s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.561 (   1.727s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.561 (   1.727s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.561 (   1.727s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.561 (   1.728s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.561 (   1.728s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.561 (   1.728s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.561 (   1.728s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.562 (   1.728s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.562 (   1.728s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.562 (   1.728s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.562 (   1.728s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.562 (   1.728s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.562 (   1.728s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.562 (   1.728s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.562 (   1.728s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.562 (   1.729s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.562 (   1.729s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.562 (   1.729s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.562 (   1.729s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.563 (   1.729s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.563 (   1.729s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.563 (   1.729s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.563 (   1.729s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.563 (   1.729s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.563 (   1.729s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.563 (   1.729s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.563 (   1.729s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.563 (   1.730s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.563 (   1.730s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.563 (   1.730s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.563 (   1.730s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.564 (   1.730s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.564 (   1.730s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.564 (   1.730s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.564 (   1.731s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.564 (   1.731s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.564 (   1.731s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.564 (   1.731s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.564 (   1.731s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.564 (   1.731s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.564 (   1.731s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.564 (   1.731s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.564 (   1.731s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.565 (   1.731s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.565 (   1.731s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.565 (   1.731s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.565 (   1.731s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.565 (   1.732s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.565 (   1.732s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.565 (   1.732s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.565 (   1.732s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.565 (   1.732s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.565 (   1.732s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.565 (   1.732s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.565 (   1.732s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.565 (   1.732s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.565 (   1.732s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.565 (   1.732s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.566 (   1.732s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.566 (   1.732s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.566 (   1.732s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.566 (   1.732s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.566 (   1.732s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.566 (   1.732s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.566 (   1.732s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.566 (   1.733s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.566 (   1.733s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.566 (   1.733s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.566 (   1.733s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.566 (   1.733s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.566 (   1.733s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.566 (   1.733s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.566 (   1.733s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.566 (   1.733s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.566 (   1.733s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.566 (   1.733s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.567 (   1.733s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.567 (   1.733s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.567 (   1.734s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.567 (   1.734s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.567 (   1.734s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.567 (   1.734s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.568 (   1.734s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.568 (   1.734s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.568 (   1.734s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.568 (   1.734s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.568 (   1.734s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.568 (   1.735s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.568 (   1.735s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.568 (   1.735s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.568 (   1.735s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.569 (   1.735s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.569 (   1.735s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.569 (   1.735s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.569 (   1.736s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.569 (   1.736s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.569 (   1.736s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.569 (   1.736s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.569 (   1.736s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.569 (   1.736s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.569 (   1.736s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.569 (   1.736s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.569 (   1.736s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.570 (   1.737s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.570 (   1.737s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.570 (   1.737s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.570 (   1.737s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.570 (   1.737s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.570 (   1.737s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.570 (   1.737s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.570 (   1.737s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.570 (   1.737s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.570 (   1.737s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.571 (   1.737s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.571 (   1.737s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.571 (   1.738s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.571 (   1.738s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.571 (   1.738s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.571 (   1.738s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.571 (   1.738s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.571 (   1.738s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.571 (   1.738s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.571 (   1.738s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.572 (   1.738s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.572 (   1.738s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.572 (   1.739s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.572 (   1.739s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.572 (   1.739s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.572 (   1.739s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.572 (   1.739s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.572 (   1.739s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.573 (   1.739s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.573 (   1.739s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.573 (   1.739s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.573 (   1.739s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.573 (   1.739s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.573 (   1.739s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.573 (   1.740s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.573 (   1.740s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.573 (   1.740s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.573 (   1.740s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.573 (   1.740s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.573 (   1.740s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.573 (   1.740s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.573 (   1.740s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.573 (   1.740s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.573 (   1.740s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.574 (   1.740s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.574 (   1.740s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.574 (   1.740s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.574 (   1.741s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.574 (   1.741s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.574 (   1.741s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.574 (   1.741s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.574 (   1.741s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.574 (   1.741s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.574 (   1.741s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.574 (   1.741s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.574 (   1.741s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.575 (   1.741s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.575 (   1.741s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.575 (   1.741s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.575 (   1.741s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.575 (   1.742s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.575 (   1.742s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.575 (   1.742s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.575 (   1.742s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.575 (   1.742s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.576 (   1.742s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.576 (   1.742s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.576 (   1.742s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.576 (   1.742s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.576 (   1.742s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.576 (   1.743s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.576 (   1.743s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.577 (   1.743s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.577 (   1.743s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.577 (   1.743s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.577 (   1.743s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.577 (   1.743s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.577 (   1.743s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.577 (   1.743s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.577 (   1.743s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.577 (   1.744s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.577 (   1.744s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.577 (   1.744s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.577 (   1.744s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.578 (   1.744s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.578 (   1.744s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.578 (   1.744s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.578 (   1.745s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.578 (   1.745s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.578 (   1.745s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.578 (   1.745s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.578 (   1.745s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.578 (   1.745s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.578 (   1.745s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.578 (   1.745s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.578 (   1.745s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.579 (   1.746s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.579 (   1.746s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.579 (   1.746s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.579 (   1.746s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.579 (   1.746s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.579 (   1.746s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.579 (   1.746s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.579 (   1.746s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.579 (   1.746s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.579 (   1.746s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.580 (   1.746s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.580 (   1.746s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.580 (   1.747s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.580 (   1.747s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.580 (   1.747s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.580 (   1.747s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.580 (   1.747s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.580 (   1.747s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.580 (   1.747s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.580 (   1.747s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.580 (   1.747s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.580 (   1.747s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.580 (   1.747s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.580 (   1.747s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.581 (   1.747s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.581 (   1.747s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.581 (   1.747s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.581 (   1.748s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.581 (   1.748s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.581 (   1.748s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.581 (   1.748s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.581 (   1.748s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.581 (   1.748s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.581 (   1.748s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.581 (   1.748s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.581 (   1.748s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.582 (   1.748s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.582 (   1.748s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.582 (   1.748s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.582 (   1.748s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.582 (   1.748s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.582 (   1.748s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.582 (   1.748s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.582 (   1.748s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.582 (   1.749s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.582 (   1.749s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.582 (   1.749s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.582 (   1.749s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.583 (   1.749s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.583 (   1.749s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.583 (   1.749s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.583 (   1.749s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.583 (   1.749s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.583 (   1.749s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.583 (   1.749s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.583 (   1.749s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.583 (   1.750s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.583 (   1.750s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.583 (   1.750s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.583 (   1.750s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.584 (   1.750s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.584 (   1.750s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.584 (   1.750s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.584 (   1.750s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.584 (   1.750s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.584 (   1.750s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.584 (   1.750s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.584 (   1.750s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.584 (   1.751s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.584 (   1.751s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.584 (   1.751s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.584 (   1.751s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.585 (   1.751s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.585 (   1.751s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.585 (   1.751s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.585 (   1.751s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.585 (   1.751s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.585 (   1.751s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.585 (   1.751s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.585 (   1.751s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.585 (   1.752s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.585 (   1.752s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.585 (   1.752s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.585 (   1.752s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.586 (   1.752s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.586 (   1.752s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.586 (   1.752s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.586 (   1.752s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.586 (   1.752s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.586 (   1.752s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.586 (   1.752s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.586 (   1.753s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.586 (   1.753s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.586 (   1.753s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.586 (   1.753s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.586 (   1.753s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.586 (   1.753s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.586 (   1.753s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.586 (   1.753s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.587 (   1.753s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.587 (   1.753s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.587 (   1.753s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.587 (   1.753s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.587 (   1.753s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.587 (   1.753s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.587 (   1.753s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.587 (   1.754s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.587 (   1.754s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.587 (   1.754s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.587 (   1.754s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.587 (   1.754s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.587 (   1.754s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.587 (   1.754s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.587 (   1.754s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.587 (   1.754s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.587 (   1.754s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.587 (   1.754s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.588 (   1.754s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.588 (   1.754s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.588 (   1.754s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.588 (   1.755s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.588 (   1.755s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.588 (   1.755s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.588 (   1.755s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.588 (   1.755s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.588 (   1.755s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.588 (   1.755s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.588 (   1.755s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.588 (   1.755s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.588 (   1.755s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.588 (   1.755s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.588 (   1.755s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.589 (   1.756s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.589 (   1.756s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.589 (   1.756s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.589 (   1.756s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.589 (   1.756s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.589 (   1.756s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.589 (   1.756s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.589 (   1.756s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.589 (   1.756s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.589 (   1.756s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.589 (   1.756s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.589 (   1.756s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.590 (   1.757s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.590 (   1.757s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.590 (   1.757s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.590 (   1.757s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.590 (   1.757s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.590 (   1.757s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.590 (   1.757s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.590 (   1.757s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.591 (   1.757s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.591 (   1.757s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.591 (   1.757s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.591 (   1.757s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.591 (   1.758s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.591 (   1.758s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.591 (   1.758s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.591 (   1.758s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.591 (   1.758s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.591 (   1.758s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.591 (   1.758s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.591 (   1.758s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.591 (   1.758s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.591 (   1.758s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.592 (   1.758s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.592 (   1.758s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.592 (   1.759s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.592 (   1.759s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.592 (   1.759s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.592 (   1.759s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.592 (   1.759s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.592 (   1.759s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.593 (   1.759s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.593 (   1.759s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.593 (   1.759s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.593 (   1.759s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.593 (   1.759s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.593 (   1.759s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.593 (   1.760s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.593 (   1.760s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.593 (   1.760s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.593 (   1.760s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.593 (   1.760s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.593 (   1.760s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.593 (   1.760s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.593 (   1.760s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.594 (   1.760s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.594 (   1.760s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.594 (   1.760s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.594 (   1.760s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.594 (   1.761s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.594 (   1.761s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.594 (   1.761s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.594 (   1.761s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.594 (   1.761s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.594 (   1.761s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.594 (   1.761s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.594 (   1.761s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.594 (   1.761s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.594 (   1.761s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.595 (   1.761s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.595 (   1.761s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.595 (   1.762s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.595 (   1.762s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.595 (   1.762s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.595 (   1.762s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.595 (   1.762s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.595 (   1.762s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.595 (   1.762s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.595 (   1.762s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.595 (   1.762s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.595 (   1.762s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.595 (   1.762s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.595 (   1.762s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.596 (   1.762s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.596 (   1.762s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.596 (   1.762s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.596 (   1.763s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.596 (   1.763s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.596 (   1.763s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.596 (   1.763s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.596 (   1.763s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.596 (   1.763s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.596 (   1.763s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.596 (   1.763s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.596 (   1.763s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.597 (   1.764s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.597 (   1.764s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.597 (   1.764s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.597 (   1.764s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.597 (   1.764s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.597 (   1.764s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.597 (   1.764s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.597 (   1.764s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.597 (   1.764s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.597 (   1.764s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.597 (   1.764s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.597 (   1.764s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.598 (   1.765s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.598 (   1.765s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.598 (   1.765s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.598 (   1.765s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.598 (   1.765s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.598 (   1.765s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.598 (   1.765s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.598 (   1.765s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.598 (   1.765s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.598 (   1.765s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.598 (   1.765s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.598 (   1.765s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.599 (   1.766s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.599 (   1.766s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.599 (   1.766s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.599 (   1.766s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.599 (   1.766s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.599 (   1.766s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.599 (   1.766s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.599 (   1.766s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.599 (   1.766s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.599 (   1.766s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.600 (   1.766s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.600 (   1.766s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.600 (   1.767s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.600 (   1.767s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.600 (   1.767s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.600 (   1.767s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.600 (   1.767s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.600 (   1.767s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.600 (   1.767s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.600 (   1.767s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.600 (   1.767s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.600 (   1.767s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.600 (   1.767s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.601 (   1.767s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.601 (   1.767s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.601 (   1.767s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.601 (   1.767s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.601 (   1.768s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.601 (   1.768s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.601 (   1.768s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.601 (   1.768s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.601 (   1.768s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.601 (   1.768s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.601 (   1.768s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.601 (   1.768s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.601 (   1.768s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.602 (   1.768s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.602 (   1.768s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.602 (   1.768s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.602 (   1.768s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.602 (   1.768s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.602 (   1.768s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.602 (   1.768s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.602 (   1.768s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.602 (   1.769s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.602 (   1.769s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.602 (   1.769s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.602 (   1.769s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.602 (   1.769s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.603 (   1.769s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.603 (   1.769s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.603 (   1.769s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.603 (   1.769s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.603 (   1.769s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.603 (   1.769s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.603 (   1.769s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.603 (   1.770s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.603 (   1.770s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.603 (   1.770s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.603 (   1.770s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.604 (   1.770s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.604 (   1.770s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.604 (   1.770s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.604 (   1.771s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.604 (   1.771s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.604 (   1.771s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.604 (   1.771s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.604 (   1.771s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.604 (   1.771s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.604 (   1.771s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.604 (   1.771s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.604 (   1.771s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.605 (   1.771s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.605 (   1.771s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.605 (   1.771s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.605 (   1.771s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.605 (   1.771s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.605 (   1.771s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.605 (   1.771s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.605 (   1.771s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.605 (   1.772s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.605 (   1.772s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.605 (   1.772s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.605 (   1.772s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.606 (   1.772s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.606 (   1.772s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.606 (   1.772s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.606 (   1.772s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.606 (   1.772s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.606 (   1.772s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.606 (   1.772s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.606 (   1.772s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.606 (   1.773s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.606 (   1.773s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.606 (   1.773s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.606 (   1.773s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.606 (   1.773s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.606 (   1.773s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.606 (   1.773s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.607 (   1.773s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.607 (   1.773s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.607 (   1.773s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.607 (   1.773s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.607 (   1.773s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.607 (   1.773s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.607 (   1.773s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.607 (   1.774s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.607 (   1.774s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.607 (   1.774s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.607 (   1.774s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.607 (   1.774s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.607 (   1.774s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.607 (   1.774s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.607 (   1.774s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.607 (   1.774s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.607 (   1.774s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.608 (   1.774s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.608 (   1.774s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.608 (   1.774s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.608 (   1.774s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.608 (   1.775s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.608 (   1.775s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.608 (   1.775s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.608 (   1.775s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.608 (   1.775s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.608 (   1.775s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.608 (   1.775s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.608 (   1.775s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.608 (   1.775s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.608 (   1.775s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.608 (   1.775s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.608 (   1.775s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.609 (   1.776s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.609 (   1.776s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.609 (   1.776s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.609 (   1.776s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.609 (   1.776s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.609 (   1.776s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.609 (   1.776s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.609 (   1.776s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.609 (   1.776s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.609 (   1.776s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.609 (   1.776s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.609 (   1.776s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.610 (   1.777s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.610 (   1.777s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.610 (   1.777s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.610 (   1.777s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.610 (   1.777s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.610 (   1.777s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.610 (   1.777s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.610 (   1.777s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.610 (   1.777s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.610 (   1.777s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.611 (   1.777s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.611 (   1.777s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.611 (   1.778s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.611 (   1.778s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.611 (   1.778s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.611 (   1.778s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.611 (   1.778s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.611 (   1.778s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.611 (   1.778s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.611 (   1.778s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.611 (   1.778s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.611 (   1.778s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.611 (   1.778s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.611 (   1.778s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.612 (   1.779s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.612 (   1.779s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.612 (   1.779s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.612 (   1.779s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.612 (   1.779s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.612 (   1.779s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.612 (   1.779s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.612 (   1.779s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.613 (   1.779s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.613 (   1.779s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.613 (   1.779s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.613 (   1.779s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.613 (   1.780s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.613 (   1.780s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.613 (   1.780s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.613 (   1.780s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.613 (   1.780s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.613 (   1.780s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.613 (   1.780s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.613 (   1.780s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.613 (   1.780s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.613 (   1.780s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.614 (   1.780s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.614 (   1.780s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.614 (   1.781s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.614 (   1.781s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.614 (   1.781s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.614 (   1.781s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.614 (   1.781s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.614 (   1.781s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.614 (   1.781s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.614 (   1.781s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.614 (   1.781s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.614 (   1.781s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.614 (   1.781s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.614 (   1.781s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.615 (   1.781s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.615 (   1.781s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.615 (   1.781s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.615 (   1.781s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.615 (   1.781s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.615 (   1.781s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.615 (   1.781s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.615 (   1.781s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.615 (   1.782s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.615 (   1.782s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.615 (   1.782s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.615 (   1.782s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.616 (   1.782s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.616 (   1.782s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.616 (   1.782s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.616 (   1.782s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.616 (   1.782s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.616 (   1.782s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.616 (   1.782s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.616 (   1.782s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.616 (   1.783s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.616 (   1.783s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.616 (   1.783s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.616 (   1.783s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.617 (   1.783s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.617 (   1.783s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.617 (   1.783s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.617 (   1.783s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.617 (   1.784s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.617 (   1.784s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.617 (   1.784s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.617 (   1.784s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.617 (   1.784s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.617 (   1.784s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.617 (   1.784s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.617 (   1.784s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.618 (   1.784s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.618 (   1.784s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.618 (   1.784s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.618 (   1.784s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.618 (   1.784s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.618 (   1.784s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.618 (   1.784s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.618 (   1.784s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.618 (   1.785s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.618 (   1.785s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.618 (   1.785s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.618 (   1.785s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.619 (   1.785s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.619 (   1.785s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.619 (   1.785s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.619 (   1.785s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.619 (   1.785s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.619 (   1.785s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.619 (   1.785s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.619 (   1.785s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.619 (   1.786s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.619 (   1.786s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.619 (   1.786s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.619 (   1.786s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.619 (   1.786s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.619 (   1.786s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.619 (   1.786s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.620 (   1.786s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.620 (   1.786s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.620 (   1.786s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.620 (   1.786s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.620 (   1.786s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.620 (   1.786s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.620 (   1.786s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.620 (   1.787s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.620 (   1.787s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.620 (   1.787s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.620 (   1.787s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.620 (   1.787s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.620 (   1.787s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.620 (   1.787s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.620 (   1.787s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.620 (   1.787s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.620 (   1.787s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.621 (   1.787s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.621 (   1.787s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.621 (   1.787s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.621 (   1.787s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.621 (   1.788s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.621 (   1.788s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.621 (   1.788s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.621 (   1.788s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.621 (   1.788s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.621 (   1.788s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.621 (   1.788s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.621 (   1.788s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.621 (   1.788s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.621 (   1.788s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.621 (   1.788s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.621 (   1.788s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.622 (   1.789s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.622 (   1.789s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.622 (   1.789s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.622 (   1.789s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.622 (   1.789s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.622 (   1.789s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.622 (   1.789s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.622 (   1.789s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.622 (   1.789s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.622 (   1.789s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.622 (   1.789s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.622 (   1.789s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.623 (   1.790s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.623 (   1.790s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.623 (   1.790s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.623 (   1.790s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.623 (   1.790s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.623 (   1.790s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.623 (   1.790s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.623 (   1.790s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.623 (   1.790s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.623 (   1.790s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.624 (   1.790s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.624 (   1.790s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.624 (   1.791s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.624 (   1.791s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.624 (   1.791s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.624 (   1.791s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.624 (   1.791s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.624 (   1.791s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.624 (   1.791s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.624 (   1.791s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.624 (   1.791s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.624 (   1.791s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.624 (   1.791s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.624 (   1.791s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.625 (   1.792s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.625 (   1.792s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.625 (   1.792s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.625 (   1.792s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.625 (   1.792s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.625 (   1.792s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.625 (   1.792s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.625 (   1.792s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.626 (   1.792s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.626 (   1.792s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.626 (   1.792s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.626 (   1.792s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.626 (   1.793s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.626 (   1.793s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.626 (   1.793s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.626 (   1.793s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.626 (   1.793s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.626 (   1.793s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.626 (   1.793s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.626 (   1.793s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.627 (   1.793s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.627 (   1.793s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.627 (   1.793s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.627 (   1.793s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.627 (   1.794s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.627 (   1.794s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.627 (   1.794s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.627 (   1.794s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.627 (   1.794s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.627 (   1.794s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.627 (   1.794s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.627 (   1.794s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.627 (   1.794s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.627 (   1.794s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.627 (   1.794s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.627 (   1.794s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.628 (   1.794s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.628 (   1.794s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.628 (   1.794s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.628 (   1.795s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.628 (   1.795s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.628 (   1.795s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.628 (   1.795s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.628 (   1.795s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.628 (   1.795s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.628 (   1.795s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.628 (   1.795s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.628 (   1.795s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.629 (   1.795s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.629 (   1.795s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.629 (   1.795s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.629 (   1.796s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.629 (   1.796s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.629 (   1.796s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.629 (   1.796s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.629 (   1.796s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.629 (   1.796s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.629 (   1.796s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.629 (   1.796s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.629 (   1.796s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.630 (   1.797s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.630 (   1.797s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.630 (   1.797s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.630 (   1.797s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.630 (   1.797s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.630 (   1.797s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.630 (   1.797s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.630 (   1.797s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.630 (   1.797s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.630 (   1.797s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.630 (   1.797s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.630 (   1.797s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.631 (   1.798s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.631 (   1.798s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.631 (   1.798s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.631 (   1.798s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.631 (   1.798s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.631 (   1.798s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.631 (   1.798s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.631 (   1.798s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.631 (   1.798s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.631 (   1.798s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.631 (   1.798s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.631 (   1.798s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.632 (   1.799s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.632 (   1.799s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.632 (   1.799s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.632 (   1.799s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.632 (   1.799s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.632 (   1.799s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.632 (   1.799s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.632 (   1.799s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.633 (   1.799s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.633 (   1.799s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.633 (   1.799s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.633 (   1.799s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.633 (   1.800s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.633 (   1.800s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.633 (   1.800s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.633 (   1.800s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.633 (   1.800s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.633 (   1.800s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.633 (   1.800s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.633 (   1.800s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.633 (   1.800s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.633 (   1.800s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.634 (   1.800s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.634 (   1.800s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.634 (   1.800s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.634 (   1.800s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.634 (   1.801s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.634 (   1.801s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.634 (   1.801s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.634 (   1.801s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.634 (   1.801s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.634 (   1.801s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.634 (   1.801s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.634 (   1.801s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.634 (   1.801s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.634 (   1.801s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.635 (   1.801s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.635 (   1.801s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.635 (   1.801s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.635 (   1.801s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.635 (   1.801s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.635 (   1.801s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.635 (   1.801s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.635 (   1.801s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.635 (   1.802s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.635 (   1.802s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.635 (   1.802s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.635 (   1.802s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.636 (   1.802s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.636 (   1.802s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.636 (   1.802s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.636 (   1.802s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.636 (   1.802s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.636 (   1.802s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.636 (   1.802s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.636 (   1.802s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.636 (   1.803s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.636 (   1.803s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.636 (   1.803s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.636 (   1.803s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.637 (   1.803s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.637 (   1.803s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.637 (   1.803s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.637 (   1.804s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.637 (   1.804s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.637 (   1.804s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.637 (   1.804s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.637 (   1.804s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.637 (   1.804s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.637 (   1.804s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.637 (   1.804s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.637 (   1.804s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.638 (   1.804s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.638 (   1.804s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.638 (   1.804s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.638 (   1.805s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.638 (   1.805s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.638 (   1.805s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.638 (   1.805s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.638 (   1.805s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.638 (   1.805s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.638 (   1.805s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.638 (   1.805s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.638 (   1.805s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.639 (   1.806s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.639 (   1.806s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.639 (   1.806s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.639 (   1.806s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.639 (   1.806s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.639 (   1.806s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.639 (   1.806s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.639 (   1.806s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.639 (   1.806s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.639 (   1.806s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.640 (   1.806s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.640 (   1.806s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.640 (   1.807s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.640 (   1.807s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.640 (   1.807s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.640 (   1.807s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.640 (   1.807s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.640 (   1.807s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.640 (   1.807s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.640 (   1.807s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.641 (   1.807s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.641 (   1.807s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.641 (   1.807s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.641 (   1.807s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.641 (   1.808s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.641 (   1.808s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.641 (   1.808s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.641 (   1.808s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.641 (   1.808s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.641 (   1.808s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.641 (   1.808s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.641 (   1.808s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.641 (   1.808s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.641 (   1.808s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.641 (   1.808s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.641 (   1.808s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.642 (   1.808s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.642 (   1.808s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.642 (   1.808s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.642 (   1.809s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.642 (   1.809s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.642 (   1.809s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.642 (   1.809s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.642 (   1.809s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.642 (   1.809s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.642 (   1.809s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.642 (   1.809s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.642 (   1.809s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.643 (   1.809s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.643 (   1.809s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.643 (   1.809s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.643 (   1.809s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.643 (   1.809s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.643 (   1.809s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.643 (   1.809s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.643 (   1.809s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.643 (   1.810s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.643 (   1.810s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.643 (   1.810s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.643 (   1.810s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.644 (   1.810s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.644 (   1.810s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.644 (   1.810s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.644 (   1.811s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.644 (   1.811s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.644 (   1.811s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.644 (   1.811s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.644 (   1.811s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.644 (   1.811s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.644 (   1.811s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.644 (   1.811s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.644 (   1.811s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.645 (   1.811s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.645 (   1.811s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.645 (   1.811s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.645 (   1.811s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.645 (   1.812s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.645 (   1.812s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.645 (   1.812s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.645 (   1.812s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.645 (   1.812s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.645 (   1.812s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.645 (   1.812s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.645 (   1.812s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.646 (   1.812s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.646 (   1.813s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.646 (   1.813s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.646 (   1.813s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.646 (   1.813s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.646 (   1.813s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.646 (   1.813s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.646 (   1.813s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.646 (   1.813s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.646 (   1.813s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.646 (   1.813s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.646 (   1.813s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.647 (   1.813s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.647 (   1.813s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.647 (   1.813s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.647 (   1.814s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.647 (   1.814s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.647 (   1.814s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.647 (   1.814s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.647 (   1.814s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.647 (   1.814s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.647 (   1.814s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.647 (   1.814s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.647 (   1.814s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.648 (   1.814s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.648 (   1.814s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.648 (   1.814s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.648 (   1.814s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.648 (   1.814s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.648 (   1.814s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.648 (   1.814s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.648 (   1.814s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.648 (   1.815s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.648 (   1.815s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.648 (   1.815s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.648 (   1.815s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.648 (   1.815s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.648 (   1.815s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.648 (   1.815s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.648 (   1.815s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.648 (   1.815s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.648 (   1.815s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.648 (   1.815s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.648 (   1.815s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.649 (   1.815s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.649 (   1.815s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.649 (   1.815s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.649 (   1.815s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.649 (   1.816s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.649 (   1.816s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.649 (   1.816s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.649 (   1.816s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.649 (   1.816s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.649 (   1.816s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.649 (   1.816s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.649 (   1.816s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.650 (   1.816s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.650 (   1.816s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.650 (   1.816s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.650 (   1.816s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.650 (   1.817s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.650 (   1.817s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.650 (   1.817s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.650 (   1.817s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.650 (   1.817s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.650 (   1.817s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.650 (   1.817s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.650 (   1.817s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.651 (   1.817s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.651 (   1.817s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.651 (   1.817s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.651 (   1.817s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.651 (   1.818s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.651 (   1.818s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.651 (   1.818s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.651 (   1.818s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.651 (   1.818s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.651 (   1.818s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.651 (   1.818s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.651 (   1.818s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.652 (   1.818s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.652 (   1.818s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.652 (   1.818s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.652 (   1.818s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.652 (   1.819s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.652 (   1.819s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.652 (   1.819s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.653 (   1.819s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.653 (   1.819s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.653 (   1.819s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.653 (   1.819s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.653 (   1.819s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.653 (   1.819s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.653 (   1.819s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.653 (   1.820s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.653 (   1.820s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.654 (   1.820s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.654 (   1.820s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.654 (   1.820s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.654 (   1.820s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.654 (   1.820s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.654 (   1.820s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.654 (   1.820s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.654 (   1.820s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.654 (   1.821s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.654 (   1.821s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.654 (   1.821s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.654 (   1.821s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.654 (   1.821s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.654 (   1.821s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.654 (   1.821s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.654 (   1.821s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.654 (   1.821s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.654 (   1.821s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.654 (   1.821s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.654 (   1.821s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.655 (   1.821s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.655 (   1.821s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.655 (   1.821s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.655 (   1.821s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.655 (   1.822s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.655 (   1.822s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.655 (   1.822s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.655 (   1.822s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.655 (   1.822s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.655 (   1.822s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.655 (   1.822s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.655 (   1.822s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.655 (   1.822s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.655 (   1.822s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.655 (   1.822s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.655 (   1.822s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.656 (   1.823s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.656 (   1.823s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.656 (   1.823s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.656 (   1.823s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.656 (   1.823s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.656 (   1.823s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.656 (   1.823s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.656 (   1.823s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.656 (   1.823s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.656 (   1.823s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.656 (   1.823s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.656 (   1.823s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.657 (   1.824s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.657 (   1.824s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.657 (   1.824s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.657 (   1.824s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.657 (   1.824s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.657 (   1.824s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.657 (   1.824s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.657 (   1.824s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.657 (   1.824s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.657 (   1.824s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.657 (   1.824s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.658 (   1.824s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.658 (   1.825s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.658 (   1.825s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.658 (   1.825s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.658 (   1.825s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.658 (   1.825s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.658 (   1.825s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.658 (   1.825s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.658 (   1.825s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.658 (   1.825s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.658 (   1.825s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.658 (   1.825s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.658 (   1.825s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.659 (   1.826s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.659 (   1.826s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.659 (   1.826s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.659 (   1.826s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.659 (   1.826s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.659 (   1.826s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.659 (   1.826s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.659 (   1.826s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.659 (   1.826s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.659 (   1.826s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.660 (   1.826s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.660 (   1.826s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.660 (   1.827s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.660 (   1.827s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.660 (   1.827s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.660 (   1.827s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.660 (   1.827s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.660 (   1.827s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.660 (   1.827s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.660 (   1.827s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.660 (   1.827s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.660 (   1.827s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.661 (   1.827s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.661 (   1.827s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.661 (   1.828s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.661 (   1.828s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.661 (   1.828s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.661 (   1.828s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.661 (   1.828s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.661 (   1.828s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.661 (   1.828s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.661 (   1.828s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.661 (   1.828s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.661 (   1.828s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.661 (   1.828s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.661 (   1.828s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.662 (   1.828s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.662 (   1.828s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.662 (   1.828s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.662 (   1.828s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.662 (   1.828s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.662 (   1.828s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.662 (   1.828s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.662 (   1.828s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.662 (   1.829s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.662 (   1.829s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.662 (   1.829s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.662 (   1.829s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.663 (   1.829s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.663 (   1.829s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.663 (   1.829s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.663 (   1.829s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.663 (   1.829s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.663 (   1.829s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.663 (   1.829s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.663 (   1.829s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.663 (   1.830s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.663 (   1.830s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.663 (   1.830s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.663 (   1.830s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.664 (   1.830s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.664 (   1.830s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.664 (   1.830s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.664 (   1.831s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.664 (   1.831s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.664 (   1.831s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.664 (   1.831s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.664 (   1.831s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.664 (   1.831s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.664 (   1.831s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.664 (   1.831s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.664 (   1.831s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.665 (   1.831s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.665 (   1.831s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.665 (   1.831s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.665 (   1.832s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.665 (   1.832s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.665 (   1.832s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.665 (   1.832s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.665 (   1.832s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.665 (   1.832s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.665 (   1.832s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.665 (   1.832s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.665 (   1.832s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.666 (   1.833s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.666 (   1.833s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.666 (   1.833s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.666 (   1.833s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.666 (   1.833s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.666 (   1.833s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.666 (   1.833s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.666 (   1.833s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.666 (   1.833s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.666 (   1.833s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.666 (   1.833s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.666 (   1.833s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.667 (   1.834s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.667 (   1.834s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.667 (   1.834s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.667 (   1.834s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.667 (   1.834s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.667 (   1.834s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.667 (   1.834s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.667 (   1.834s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.667 (   1.834s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.667 (   1.834s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.667 (   1.834s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.667 (   1.834s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.668 (   1.834s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.668 (   1.834s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.668 (   1.834s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.668 (   1.834s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.668 (   1.834s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.668 (   1.834s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.668 (   1.834s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.668 (   1.834s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.668 (   1.835s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.668 (   1.835s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.668 (   1.835s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.668 (   1.835s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.668 (   1.835s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.668 (   1.835s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.668 (   1.835s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.668 (   1.835s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.668 (   1.835s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.668 (   1.835s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.668 (   1.835s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.668 (   1.835s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.669 (   1.835s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.669 (   1.835s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.669 (   1.835s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.669 (   1.835s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.669 (   1.836s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.669 (   1.836s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.669 (   1.836s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.669 (   1.836s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.669 (   1.836s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.669 (   1.836s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.669 (   1.836s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.669 (   1.836s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.669 (   1.836s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.670 (   1.836s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.670 (   1.836s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.670 (   1.836s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.670 (   1.837s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.670 (   1.837s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.670 (   1.837s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.670 (   1.837s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.670 (   1.837s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.670 (   1.837s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.670 (   1.837s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.670 (   1.837s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.671 (   1.837s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.671 (   1.837s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.671 (   1.837s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.671 (   1.837s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.671 (   1.838s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.671 (   1.838s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.671 (   1.838s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.671 (   1.838s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.671 (   1.838s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.671 (   1.838s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.671 (   1.838s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.671 (   1.838s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.672 (   1.838s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.672 (   1.838s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.672 (   1.838s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.672 (   1.838s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.672 (   1.839s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.672 (   1.839s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.672 (   1.839s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.673 (   1.839s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.673 (   1.839s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.673 (   1.839s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.673 (   1.839s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.673 (   1.839s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.673 (   1.839s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.673 (   1.839s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.673 (   1.840s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.673 (   1.840s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.673 (   1.840s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.673 (   1.840s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.673 (   1.840s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.673 (   1.840s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.673 (   1.840s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.674 (   1.840s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.674 (   1.840s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.674 (   1.840s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.674 (   1.840s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.674 (   1.840s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.674 (   1.840s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.674 (   1.840s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.674 (   1.841s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.674 (   1.841s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.674 (   1.841s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.674 (   1.841s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.674 (   1.841s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.674 (   1.841s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.674 (   1.841s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.674 (   1.841s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.674 (   1.841s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.674 (   1.841s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.675 (   1.841s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.675 (   1.841s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.675 (   1.841s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.675 (   1.841s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.675 (   1.841s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.675 (   1.842s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.675 (   1.842s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.675 (   1.842s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.675 (   1.842s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.675 (   1.842s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.675 (   1.842s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.675 (   1.842s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.675 (   1.842s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.675 (   1.842s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.676 (   1.842s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.676 (   1.842s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.676 (   1.842s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.676 (   1.843s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.676 (   1.843s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.676 (   1.843s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.676 (   1.843s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.676 (   1.843s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.676 (   1.843s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.676 (   1.843s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.676 (   1.843s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.676 (   1.843s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.677 (   1.844s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.677 (   1.844s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.677 (   1.844s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.677 (   1.844s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.677 (   1.844s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.677 (   1.844s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.677 (   1.844s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.677 (   1.844s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.677 (   1.844s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.677 (   1.844s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.677 (   1.844s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.677 (   1.844s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.678 (   1.845s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.678 (   1.845s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.678 (   1.845s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.678 (   1.845s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.678 (   1.845s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.678 (   1.845s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.678 (   1.845s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.678 (   1.845s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.678 (   1.845s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.678 (   1.845s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.678 (   1.845s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.678 (   1.845s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.680 (   1.846s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.680 (   1.846s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.680 (   1.846s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.680 (   1.846s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.680 (   1.846s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.680 (   1.846s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.680 (   1.846s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.680 (   1.846s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.680 (   1.847s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.680 (   1.847s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.680 (   1.847s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.680 (   1.847s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.680 (   1.847s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.680 (   1.847s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.680 (   1.847s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.681 (   1.847s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.681 (   1.847s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.681 (   1.847s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.681 (   1.847s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.681 (   1.847s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.681 (   1.847s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.681 (   1.847s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.681 (   1.848s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.681 (   1.848s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.681 (   1.848s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.681 (   1.848s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.681 (   1.848s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.681 (   1.848s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.681 (   1.848s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.681 (   1.848s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.681 (   1.848s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.681 (   1.848s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.681 (   1.848s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.681 (   1.848s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.682 (   1.848s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.682 (   1.848s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.682 (   1.849s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.682 (   1.849s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.682 (   1.849s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.682 (   1.849s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.682 (   1.849s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.682 (   1.849s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.682 (   1.849s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.682 (   1.849s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.682 (   1.849s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.682 (   1.849s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.682 (   1.849s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.682 (   1.849s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.683 (   1.850s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.683 (   1.850s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.683 (   1.850s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.683 (   1.850s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.683 (   1.850s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.683 (   1.850s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.683 (   1.850s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.683 (   1.850s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.683 (   1.850s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.683 (   1.850s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.683 (   1.850s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.683 (   1.850s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.684 (   1.851s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.684 (   1.851s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.684 (   1.851s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.684 (   1.851s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.684 (   1.851s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.684 (   1.851s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.684 (   1.851s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.684 (   1.851s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.684 (   1.851s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.684 (   1.851s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.685 (   1.851s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.685 (   1.851s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.685 (   1.852s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.685 (   1.852s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.685 (   1.852s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.685 (   1.852s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.685 (   1.852s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.685 (   1.852s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.685 (   1.852s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.685 (   1.852s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.685 (   1.852s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.685 (   1.852s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.685 (   1.852s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.685 (   1.852s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.687 (   1.853s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.687 (   1.853s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.687 (   1.853s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.687 (   1.854s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.687 (   1.854s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.687 (   1.854s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.687 (   1.854s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.687 (   1.854s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.687 (   1.854s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.687 (   1.854s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.687 (   1.854s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.687 (   1.854s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.688 (   1.854s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.688 (   1.854s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.688 (   1.854s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.688 (   1.855s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.688 (   1.855s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.688 (   1.855s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.688 (   1.855s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.688 (   1.855s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.688 (   1.855s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.688 (   1.855s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.688 (   1.855s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.688 (   1.855s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.688 (   1.855s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.688 (   1.855s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.689 (   1.855s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.689 (   1.855s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.689 (   1.855s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.689 (   1.855s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.689 (   1.855s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.689 (   1.855s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.689 (   1.855s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.689 (   1.855s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.689 (   1.856s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.689 (   1.856s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.689 (   1.856s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.689 (   1.856s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.689 (   1.856s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.689 (   1.856s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.689 (   1.856s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.689 (   1.856s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.689 (   1.856s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.689 (   1.856s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.690 (   1.856s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.690 (   1.856s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.690 (   1.856s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.690 (   1.856s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.690 (   1.857s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.690 (   1.857s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.690 (   1.857s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.690 (   1.857s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.690 (   1.857s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.690 (   1.857s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.690 (   1.857s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.690 (   1.857s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.690 (   1.857s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.690 (   1.857s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.691 (   1.857s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.691 (   1.857s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.691 (   1.858s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.691 (   1.858s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.691 (   1.858s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.691 (   1.858s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.691 (   1.858s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.691 (   1.858s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.691 (   1.858s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.691 (   1.858s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.692 (   1.858s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.692 (   1.858s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.692 (   1.858s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.692 (   1.858s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.693 (   1.859s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.693 (   1.859s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.693 (   1.859s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.693 (   1.859s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.693 (   1.859s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.693 (   1.859s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.693 (   1.860s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.693 (   1.860s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.693 (   1.860s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.693 (   1.860s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.693 (   1.860s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.693 (   1.860s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.695 (   1.862s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.695 (   1.862s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.695 (   1.862s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.695 (   1.862s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.695 (   1.862s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.695 (   1.862s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.695 (   1.862s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.695 (   1.862s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.695 (   1.862s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.695 (   1.862s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.695 (   1.862s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.695 (   1.862s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.696 (   1.863s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.696 (   1.863s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.696 (   1.863s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.696 (   1.863s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.696 (   1.863s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.696 (   1.863s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.696 (   1.863s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.696 (   1.863s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.696 (   1.863s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.696 (   1.863s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.696 (   1.863s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.696 (   1.863s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.697 (   1.863s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.697 (   1.863s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.697 (   1.863s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.697 (   1.864s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.697 (   1.864s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.697 (   1.864s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.697 (   1.864s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.697 (   1.864s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.697 (   1.864s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.697 (   1.864s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.697 (   1.864s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.697 (   1.864s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.697 (   1.864s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.697 (   1.864s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.697 (   1.864s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.698 (   1.864s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.698 (   1.864s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.698 (   1.864s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.698 (   1.864s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.698 (   1.864s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.698 (   1.864s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.698 (   1.864s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.698 (   1.865s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.698 (   1.865s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.698 (   1.865s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.698 (   1.865s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.698 (   1.865s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.699 (   1.865s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.699 (   1.865s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.699 (   1.865s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.699 (   1.865s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.699 (   1.865s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.699 (   1.865s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.699 (   1.865s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.699 (   1.865s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.699 (   1.866s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.699 (   1.866s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.699 (   1.866s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.699 (   1.866s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.700 (   1.866s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.700 (   1.866s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.700 (   1.866s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.700 (   1.866s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.700 (   1.866s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.700 (   1.866s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.700 (   1.866s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.700 (   1.867s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.700 (   1.867s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.700 (   1.867s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.700 (   1.867s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.700 (   1.867s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.701 (   1.867s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.701 (   1.867s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.701 (   1.867s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.701 (   1.867s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.701 (   1.867s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.701 (   1.867s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.701 (   1.867s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.701 (   1.868s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.701 (   1.868s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.702 (   1.869s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.702 (   1.869s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.702 (   1.869s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.702 (   1.869s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.702 (   1.869s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.702 (   1.869s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.702 (   1.869s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.702 (   1.869s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.702 (   1.869s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.702 (   1.869s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.703 (   1.869s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.703 (   1.869s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.703 (   1.870s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.703 (   1.870s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.703 (   1.870s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.703 (   1.870s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.703 (   1.870s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.703 (   1.870s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.703 (   1.870s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.703 (   1.870s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.703 (   1.870s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.703 (   1.870s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.703 (   1.870s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.704 (   1.870s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.704 (   1.870s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.704 (   1.870s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.704 (   1.870s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.704 (   1.871s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.704 (   1.871s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.704 (   1.871s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.704 (   1.871s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.704 (   1.871s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.704 (   1.871s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.704 (   1.871s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.704 (   1.871s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.704 (   1.871s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.704 (   1.871s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.704 (   1.871s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.704 (   1.871s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.705 (   1.871s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.705 (   1.871s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.705 (   1.871s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.705 (   1.871s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.705 (   1.871s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.705 (   1.871s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.705 (   1.871s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.705 (   1.872s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.705 (   1.872s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.705 (   1.872s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.705 (   1.872s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.705 (   1.872s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.706 (   1.872s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.706 (   1.872s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.706 (   1.872s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.706 (   1.872s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.706 (   1.872s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.706 (   1.872s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.706 (   1.872s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.706 (   1.873s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.706 (   1.873s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.706 (   1.873s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.706 (   1.873s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.706 (   1.873s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.707 (   1.873s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.707 (   1.873s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.707 (   1.873s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.707 (   1.873s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.707 (   1.873s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.707 (   1.873s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.707 (   1.873s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.707 (   1.874s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.707 (   1.874s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.707 (   1.874s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.707 (   1.874s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.707 (   1.874s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.708 (   1.874s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.708 (   1.874s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.708 (   1.874s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.708 (   1.874s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.708 (   1.874s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.708 (   1.874s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.708 (   1.874s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.708 (   1.875s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.708 (   1.875s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.709 (   1.876s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.709 (   1.876s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.709 (   1.876s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.710 (   1.876s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.710 (   1.876s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.710 (   1.876s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.710 (   1.876s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.710 (   1.876s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.710 (   1.877s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.710 (   1.877s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.710 (   1.877s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.710 (   1.877s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.710 (   1.877s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.710 (   1.877s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.710 (   1.877s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.711 (   1.877s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.711 (   1.877s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.711 (   1.877s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.711 (   1.877s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.711 (   1.877s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.711 (   1.877s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.711 (   1.877s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.711 (   1.878s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.711 (   1.878s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.711 (   1.878s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.711 (   1.878s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.711 (   1.878s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.711 (   1.878s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.711 (   1.878s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.711 (   1.878s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.711 (   1.878s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.711 (   1.878s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.712 (   1.878s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.712 (   1.878s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.712 (   1.878s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.712 (   1.878s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.712 (   1.879s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.712 (   1.879s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.712 (   1.879s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.712 (   1.879s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.712 (   1.879s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.712 (   1.879s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.712 (   1.879s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.712 (   1.879s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.712 (   1.879s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.712 (   1.879s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.712 (   1.879s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.712 (   1.879s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.713 (   1.880s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.713 (   1.880s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.713 (   1.880s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.713 (   1.880s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.713 (   1.880s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.713 (   1.880s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.713 (   1.880s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.713 (   1.880s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.713 (   1.880s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.713 (   1.880s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.713 (   1.880s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.713 (   1.880s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.714 (   1.881s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.714 (   1.881s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.714 (   1.881s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.714 (   1.881s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.714 (   1.881s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.714 (   1.881s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.714 (   1.881s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.714 (   1.881s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.714 (   1.881s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.714 (   1.881s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.714 (   1.881s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.714 (   1.881s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.715 (   1.882s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.715 (   1.882s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.715 (   1.882s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.715 (   1.882s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.715 (   1.882s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.715 (   1.882s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.715 (   1.882s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.715 (   1.882s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.715 (   1.882s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.715 (   1.882s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.715 (   1.882s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.715 (   1.882s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.718 (   1.885s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.718 (   1.885s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.718 (   1.885s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.718 (   1.885s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.718 (   1.885s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.718 (   1.885s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.718 (   1.885s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.718 (   1.885s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.718 (   1.885s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.718 (   1.885s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.718 (   1.885s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.718 (   1.885s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.719 (   1.886s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.719 (   1.886s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.719 (   1.886s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.719 (   1.886s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.719 (   1.886s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.719 (   1.886s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.719 (   1.886s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.719 (   1.886s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.719 (   1.886s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.719 (   1.886s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.719 (   1.886s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.719 (   1.886s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.720 (   1.886s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.720 (   1.886s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.720 (   1.886s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.720 (   1.886s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.720 (   1.886s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.720 (   1.886s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.720 (   1.887s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.720 (   1.887s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.720 (   1.887s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.720 (   1.887s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.720 (   1.887s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.720 (   1.887s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.720 (   1.887s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.720 (   1.887s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.720 (   1.887s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.721 (   1.887s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.721 (   1.887s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.721 (   1.887s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.721 (   1.887s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.721 (   1.887s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.721 (   1.887s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.721 (   1.887s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.721 (   1.887s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.721 (   1.888s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.721 (   1.888s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.721 (   1.888s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.721 (   1.888s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.722 (   1.888s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.722 (   1.888s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.722 (   1.888s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.722 (   1.888s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.722 (   1.888s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.722 (   1.888s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.722 (   1.888s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.722 (   1.888s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.722 (   1.889s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.778 (   1.944s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.778 (   1.944s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.778 (   1.944s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.778 (   1.945s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.778 (   1.945s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.778 (   1.945s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.778 (   1.945s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.778 (   1.945s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:54.778 (   1.945s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.778 (   1.945s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.841 (   2.007s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.841 (   2.007s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.841 (   2.007s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.841 (   2.007s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.841 (   2.007s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2026-01-28 22:12:54.841 (   2.008s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.841 (   2.008s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.842 (   2.008s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.842 (   2.008s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.842 (   2.008s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2026-01-28 22:12:54.842 (   2.008s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.842 (   2.008s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.842 (   2.009s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.842 (   2.009s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:54.842 (   2.009s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.842 (   2.009s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.842 (   2.009s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2026-01-28 22:12:54.842 (   2.009s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.842 (   2.009s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:54.842 (   2.009s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:54.842 (   2.009s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:54.842 (   2.009s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2026-01-28 22:12:54.842 (   2.009s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:54.842 (   2.009s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.082 (   5.249s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.082 (   5.249s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.082 (   5.249s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.082 (   5.249s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.082 (   5.249s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.082 (   5.249s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.082 (   5.249s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.082 (   5.249s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.083 (   5.249s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.083 (   5.249s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.083 (   5.249s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.083 (   5.249s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.083 (   5.250s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.084 (   5.250s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.084 (   5.250s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.084 (   5.250s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.084 (   5.250s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.084 (   5.250s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.084 (   5.250s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.084 (   5.250s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.084 (   5.251s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.085 (   5.251s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.085 (   5.251s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.085 (   5.251s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.085 (   5.251s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.085 (   5.251s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.085 (   5.251s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.085 (   5.251s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.085 (   5.252s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.085 (   5.252s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.141 (   5.308s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.141 (   5.308s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.141 (   5.308s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.142 (   5.309s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.142 (   5.309s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.142 (   5.309s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.142 (   5.309s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.142 (   5.309s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.142 (   5.309s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.142 (   5.309s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.181 (   5.347s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.181 (   5.347s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.181 (   5.347s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.181 (   5.347s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.181 (   5.347s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.181 (   5.348s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.181 (   5.348s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.181 (   5.348s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.181 (   5.348s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.181 (   5.348s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-28 22:12:58.181 (   5.348s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.181 (   5.348s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.183 (   5.349s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.183 (   5.349s) [        66B35000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:58.183 (   5.349s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.183 (   5.349s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.183 (   5.349s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | User provided a tensor of data type: Bool which is not supported by runtime/ttnn. Casting to: BFloat16, this may impact throughput and the integrity of the data.
2026-01-28 22:12:58.183 (   5.350s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.183 (   5.350s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.183 (   5.350s) [        66B35000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-28 22:12:58.183 (   5.350s) [        66B35000]     client_instance.cc:735      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-28 22:12:58.183 (   5.350s) [        66B35000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | User provided a tensor of data type: Bool which is not supported by runtime/ttnn. Casting to: BFloat16, this may impact throughput and the integrity of the data.
2026-01-28 22:12:58.183 (   5.350s) [        66B35000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-28 22:12:58.183 (   5.350s) [        66B35000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.192 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.193 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.193 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.193 (   5.359s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.193 (   5.360s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.193 (   5.360s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.193 (   5.360s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.193 (   5.360s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.193 (   5.360s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.193 (   5.360s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.193 (   5.360s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.194 (   5.360s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.194 (   5.360s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.194 (   5.360s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.194 (   5.360s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.194 (   5.361s) [        66B35000]     buffer_instance.cc:637      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-28 22:12:58.238 (   5.404s) [        66B35000]     client_instance.cc:687      1| ClientInstance::PJRT_Client_Compile
2026-01-28 22:12:58.238 (   5.405s) [        66B35000]      module_builder.cc:214      1| ModuleBuilder::buildModule
2026-01-28 22:12:58.246 (   5.413s) [        66B35000]      module_builder.cc:1111     1| MLIR Module vhlo:
#loc1 = loc("p0.1")
#loc2 = loc("p1.6")
#loc3 = loc("p2.14")
#loc4 = loc("p3.19")
#loc5 = loc("p4.70")
#loc6 = loc("p5.85")
#loc7 = loc("p6.93")
#loc8 = loc("p7.190")
#loc9 = loc("p8.195")
#loc10 = loc("p9.204")
#loc11 = loc("p10.209")
#loc12 = loc("p11.214")
#loc13 = loc("p12.223")
#loc14 = loc("p13.284")
#loc15 = loc("p14.296")
#loc16 = loc("p15.328")
#loc17 = loc("p16.336")
#loc18 = loc("p17.495")
#loc133 = loc("reduce.440")
#loc140 = loc("reduce.404")
#loc145 = loc("reduce.413")
#loc201 = loc("reduce.553")
#loc206 = loc("reduce.567")
#loc226 = loc("custom-call.512")
#loc227 = loc("custom-call.199")
#loc229 = loc("reduce.521")
#loc240 = loc("custom-call.461")
#loc241 = loc("custom-call.218")
#loc243 = loc("reduce.470")
#loc254 = loc("custom-call.345")
#loc255 = loc("custom-call.332")
#loc257 = loc("reduce.354")
#loc268 = loc("custom-call.102")
#loc269 = loc("custom-call.89")
#loc271 = loc("reduce.111")
#loc282 = loc("custom-call.26")
#loc283 = loc("custom-call.10")
#loc285 = loc("reduce.35")
module @SyncTensorsGraph.597 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1024x1024x!vhlo.f32_v1> loc("p0.1"), %arg1: !vhlo.tensor_v1<1024x!vhlo.f32_v1> loc("p1.6"), %arg2: !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc("p2.14"), %arg3: !vhlo.tensor_v1<151936x1024x!vhlo.f32_v1> loc("p3.19"), %arg4: !vhlo.tensor_v1<64x!vhlo.f32_v1> loc("p4.70"), %arg5: !vhlo.tensor_v1<128x!vhlo.f32_v1> loc("p5.85"), %arg6: !vhlo.tensor_v1<1024x1024x!vhlo.f32_v1> loc("p6.93"), %arg7: !vhlo.tensor_v1<151936x1024x!vhlo.f32_v1> loc("p7.190"), %arg8: !vhlo.tensor_v1<1024x!vhlo.f32_v1> loc("p8.195"), %arg9: !vhlo.tensor_v1<1024x3072x!vhlo.f32_v1> loc("p9.204"), %arg10: !vhlo.tensor_v1<3072x1024x!vhlo.f32_v1> loc("p10.209"), %arg11: !vhlo.tensor_v1<1024x!vhlo.f32_v1> loc("p11.214"), %arg12: !vhlo.tensor_v1<1024x2048x!vhlo.f32_v1> loc("p12.223"), %arg13: !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc("p13.284"), %arg14: !vhlo.tensor_v1<!vhlo.bool_v1> loc("p14.296"), %arg15: !vhlo.tensor_v1<128x!vhlo.f32_v1> loc("p15.328"), %arg16: !vhlo.tensor_v1<2048x1024x!vhlo.f32_v1> loc("p16.336"), %arg17: !vhlo.tensor_v1<3072x1024x!vhlo.f32_v1> loc("p17.495")) -> (!vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>, !vhlo.tensor_v1<72x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x151936x!vhlo.f32_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<true> : tensor<i1>>}> : () -> !vhlo.tensor_v1<!vhlo.bool_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]> : tensor<18xi64>>}> : () -> !vhlo.tensor_v1<18x!vhlo.i64_v1> loc(#loc)
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3]> : tensor<4xi64>>}> : () -> !vhlo.tensor_v1<4x!vhlo.i64_v1> loc(#loc)
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<false> : tensor<i1>>}> : () -> !vhlo.tensor_v1<!vhlo.bool_v1> loc(#loc)
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.40282347E+38> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[[[0.000000e+00, 1.000000e+00, 2.000000e+00, 3.000000e+00, 4.000000e+00, 5.000000e+00, 6.000000e+00, 7.000000e+00, 8.000000e+00, 9.000000e+00, 1.000000e+01, 1.100000e+01, 1.200000e+01, 1.300000e+01, 1.400000e+01, 1.500000e+01, 1.600000e+01, 1.700000e+01]]]> : tensor<1x1x18xf32>>}> : () -> !vhlo.tensor_v1<1x1x18x!vhlo.f32_v1> loc(#loc)
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-100> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.297301769> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %8 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<4> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %9 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<18> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %10 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %11 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFFF0000000000000> : tensor<f64>>}> : () -> !vhlo.tensor_v1<!vhlo.f64_v1> loc(#loc)
    %12 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %13 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %14 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x!vhlo.f32_v1> loc(#loc)
    %15 = "vhlo.broadcast_in_dim_v1"(%12) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<72x!vhlo.i64_v1> loc(#loc)
    %16 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1> loc(#loc)
    %17 = "vhlo.broadcast_in_dim_v1"(%11) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f64_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.f64_v1> loc(#loc)
    %18 = "vhlo.broadcast_in_dim_v1"(%10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x1x18x18x!vhlo.f32_v1> loc(#loc)
    %19 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x1x18x18x!vhlo.f32_v1> loc(#loc)
    %20 = "vhlo.broadcast_in_dim_v1"(%9) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc(#loc)
    %21 = "vhlo.broadcast_in_dim_v1"(%8) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc(#loc)
    %22 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x128x18x!vhlo.f32_v1> loc(#loc)
    %23 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1> loc(#loc)
    %24 = "vhlo.broadcast_in_dim_v1"(%6) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<72x!vhlo.i64_v1> loc(#loc)
    %25 = "vhlo.broadcast_in_dim_v1"(%12) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc(#loc)
    %26 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<151936x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x151936x1024x!vhlo.f32_v1> loc(#loc19)
    %27 = "vhlo.custom_call_v1"(%26) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x151936x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x151936x1024x!vhlo.f32_v1> loc(#loc20)
    %28 = "vhlo.reshape_v1"(%27) : (!vhlo.tensor_v1<1x151936x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<151936x1024x!vhlo.f32_v1> loc(#loc21)
    %29 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x18x!vhlo.i64_v1> loc(#loc22)
    %30 = "vhlo.custom_call_v1"(%29) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x18x!vhlo.i64_v1> loc(#loc23)
    %31 = "vhlo.reshape_v1"(%30) : (!vhlo.tensor_v1<1x4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc(#loc24)
    %32 = "vhlo.reshape_v1"(%30) : (!vhlo.tensor_v1<1x4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<72x!vhlo.i64_v1> loc(#loc25)
    %33 = "vhlo.convert_v1"(%32) : (!vhlo.tensor_v1<72x!vhlo.i64_v1>) -> !vhlo.tensor_v1<72x!vhlo.ui32_v1> loc(#loc26)
    %34 = "vhlo.gather_v2"(%28, %33) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 1024]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<151936x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<72x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<72x1024x!vhlo.f32_v1> loc(#loc27)
    %35 = "vhlo.reshape_v1"(%34) : (!vhlo.tensor_v1<72x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc28)
    %36 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1024x!vhlo.f32_v1> loc(#loc29)
    %37 = "vhlo.custom_call_v1"(%36) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1024x!vhlo.f32_v1> loc(#loc30)
    %38 = "vhlo.reshape_v1"(%37) : (!vhlo.tensor_v1<1x1x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1024x!vhlo.f32_v1> loc(#loc31)
    %39 = "vhlo.composite_v1"(%35, %38) <{composite_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"epsilon"> = #vhlo.float_v1<9.99999997E-7 : !vhlo.f32_v1>, #vhlo.string_v1<"normalized_shape"> = #vhlo.tensor_v1<dense<1024> : tensor<1xi64>>}>, decomposition = #vhlo.string_v1<"tenstorrent.rms_norm.impl_3">, name = #vhlo.string_v1<"tenstorrent.rms_norm">, version = #vhlo.integer_v1<0 : i32>}> : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc32)
    %40 = "vhlo.reshape_v1"(%39) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x1024x!vhlo.f32_v1> loc(#loc33)
    %41 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1024x1024x!vhlo.f32_v1> loc(#loc34)
    %42 = "vhlo.custom_call_v1"(%41) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1024x1024x!vhlo.f32_v1> loc(#loc35)
    %43 = "vhlo.reshape_v1"(%42) : (!vhlo.tensor_v1<1x1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1024x1024x!vhlo.f32_v1> loc(#loc36)
    %44 = "vhlo.transpose_v1"(%43) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"f32[1024,1024]{0,1}">} : (!vhlo.tensor_v1<1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1024x1024x!vhlo.f32_v1> loc(#loc37)
    %45 = "vhlo.dot_general_v2"(%40, %44) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<72x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x1024x!vhlo.f32_v1> loc(#loc38)
    %46 = "vhlo.reshape_v1"(%45) : (!vhlo.tensor_v1<72x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1> loc(#loc39)
    %47 = "vhlo.transpose_v1"(%46) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[4,8,18,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1> loc(#loc40)
    %48 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1024x1024x!vhlo.f32_v1> loc(#loc41)
    %49 = "vhlo.custom_call_v1"(%48) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1024x1024x!vhlo.f32_v1> loc(#loc42)
    %50 = "vhlo.reshape_v1"(%49) : (!vhlo.tensor_v1<1x1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1024x1024x!vhlo.f32_v1> loc(#loc43)
    %51 = "vhlo.transpose_v1"(%50) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"f32[1024,1024]{0,1}">} : (!vhlo.tensor_v1<1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1024x1024x!vhlo.f32_v1> loc(#loc44)
    %52 = "vhlo.dot_general_v2"(%40, %51) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<72x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x1024x!vhlo.f32_v1> loc(#loc45)
    %53 = "vhlo.reshape_v1"(%52) : (!vhlo.tensor_v1<72x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1> loc(#loc46)
    %54 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1> loc(#loc47)
    %55 = "vhlo.custom_call_v1"(%54) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_k_norm_weight">}>} : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1> loc(#loc48)
    %56 = "vhlo.reshape_v1"(%55) : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<128x!vhlo.f32_v1> loc(#loc49)
    %57 = "vhlo.composite_v1"(%53, %56) <{composite_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"epsilon"> = #vhlo.float_v1<9.99999997E-7 : !vhlo.f32_v1>, #vhlo.string_v1<"normalized_shape"> = #vhlo.tensor_v1<dense<128> : tensor<1xi64>>}>, decomposition = #vhlo.string_v1<"tenstorrent.rms_norm.impl_2">, name = #vhlo.string_v1<"tenstorrent.rms_norm">, version = #vhlo.integer_v1<0 : i32>}> : (!vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1>, !vhlo.tensor_v1<128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1> loc(#loc50)
    %58 = "vhlo.transpose_v1"(%57) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[4,8,18,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1> loc(#loc51)
    %59 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc52)
    %60 = "vhlo.custom_call_v1"(%59) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"constant">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc53)
    %61 = "vhlo.reshape_v1"(%60) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1> loc(#loc54)
    %62 = "vhlo.dot_general_v2"(%61, %5) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x18x!vhlo.f32_v1> loc(#loc55)
    %63 = "vhlo.transpose_v1"(%62) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,18,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x18x64x!vhlo.f32_v1> loc(#loc56)
    %64 = "vhlo.concatenate_v1"(%63, %63) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x18x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x18x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x18x128x!vhlo.f32_v1> loc(#loc57)
    %65 = "vhlo.cosine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x18x128x!vhlo.f32_v1> loc(#loc58)
    %66 = "vhlo.reshape_v1"(%65) : (!vhlo.tensor_v1<1x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<18x128x!vhlo.f32_v1> loc(#loc59)
    %67 = "vhlo.broadcast_in_dim_v1"(%66) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1> loc(#loc60)
    %68 = "vhlo.multiply_v1"(%58, %67) : (!vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1> loc(#loc61)
    %69 = "vhlo.slice_v1"(%58) <{limit_indices = #vhlo.tensor_v1<dense<[4, 8, 18, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x8x18x64x!vhlo.f32_v1> loc(#loc62)
    %70 = "vhlo.negate_v1"(%69) : (!vhlo.tensor_v1<4x8x18x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x8x18x64x!vhlo.f32_v1> loc(#loc63)
    %71 = "vhlo.slice_v1"(%58) <{limit_indices = #vhlo.tensor_v1<dense<[4, 8, 18, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x8x18x64x!vhlo.f32_v1> loc(#loc64)
    %72 = "vhlo.concatenate_v1"(%70, %71) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<4x8x18x64x!vhlo.f32_v1>, !vhlo.tensor_v1<4x8x18x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1> loc(#loc65)
    %73 = "vhlo.sine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x18x128x!vhlo.f32_v1> loc(#loc66)
    %74 = "vhlo.reshape_v1"(%73) : (!vhlo.tensor_v1<1x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<18x128x!vhlo.f32_v1> loc(#loc67)
    %75 = "vhlo.broadcast_in_dim_v1"(%74) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1> loc(#loc68)
    %76 = "vhlo.multiply_v1"(%72, %75) : (!vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1> loc(#loc69)
    %77 = "vhlo.add_v1"(%68, %76) : (!vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1> loc(#loc70)
    %78 = "vhlo.pad_v1"(%31, %6) <{edge_padding_high = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, edge_padding_low = #vhlo.tensor_v1<dense<0> : tensor<2xi64>>, interior_padding = #vhlo.tensor_v1<dense<0> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x18x!vhlo.i64_v1>, !vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x19x!vhlo.i64_v1> loc(#loc71)
    %79 = "vhlo.slice_v1"(%78) <{limit_indices = #vhlo.tensor_v1<dense<[4, 19]> : tensor<2xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x19x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc(#loc72)
    %80 = "vhlo.reshape_v1"(%79) : (!vhlo.tensor_v1<4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<72x!vhlo.i64_v1> loc(#loc73)
    %81 = "vhlo.compare_v1"(%80, %24) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 NE>}> : (!vhlo.tensor_v1<72x!vhlo.i64_v1>, !vhlo.tensor_v1<72x!vhlo.i64_v1>) -> !vhlo.tensor_v1<72x!vhlo.bool_v1> loc(#loc74)
    %82 = "vhlo.reshape_v1"(%arg16) : (!vhlo.tensor_v1<2048x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x2048x1024x!vhlo.f32_v1> loc(#loc75)
    %83 = "vhlo.custom_call_v1"(%82) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x2048x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x2048x1024x!vhlo.f32_v1> loc(#loc76)
    %84 = "vhlo.reshape_v1"(%83) : (!vhlo.tensor_v1<1x2048x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2048x1024x!vhlo.f32_v1> loc(#loc77)
    %85 = "vhlo.transpose_v1"(%84) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"f32[1024,2048]{0,1}">} : (!vhlo.tensor_v1<2048x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1024x2048x!vhlo.f32_v1> loc(#loc78)
    %86 = "vhlo.dot_general_v2"(%40, %85) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<72x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1024x2048x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x2048x!vhlo.f32_v1> loc(#loc79)
    %87 = "vhlo.reshape_v1"(%86) : (!vhlo.tensor_v1<72x2048x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1> loc(#loc80)
    %88 = "vhlo.reshape_v1"(%arg15) : (!vhlo.tensor_v1<128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1> loc(#loc81)
    %89 = "vhlo.custom_call_v1"(%88) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_q_norm_weight">}>} : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1> loc(#loc82)
    %90 = "vhlo.reshape_v1"(%89) : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<128x!vhlo.f32_v1> loc(#loc83)
    %91 = "vhlo.composite_v1"(%87, %90) <{composite_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"epsilon"> = #vhlo.float_v1<9.99999997E-7 : !vhlo.f32_v1>, #vhlo.string_v1<"normalized_shape"> = #vhlo.tensor_v1<dense<128> : tensor<1xi64>>}>, decomposition = #vhlo.string_v1<"tenstorrent.rms_norm.impl_1">, name = #vhlo.string_v1<"tenstorrent.rms_norm">, version = #vhlo.integer_v1<0 : i32>}> : (!vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1>, !vhlo.tensor_v1<128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1> loc(#loc84)
    %92 = "vhlo.transpose_v1"(%91) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[4,16,18,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1> loc(#loc85)
    %93 = "vhlo.broadcast_in_dim_v1"(%66) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1> loc(#loc86)
    %94 = "vhlo.multiply_v1"(%92, %93) : (!vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1> loc(#loc87)
    %95 = "vhlo.slice_v1"(%92) <{limit_indices = #vhlo.tensor_v1<dense<[4, 16, 18, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x64x!vhlo.f32_v1> loc(#loc88)
    %96 = "vhlo.negate_v1"(%95) : (!vhlo.tensor_v1<4x16x18x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x64x!vhlo.f32_v1> loc(#loc89)
    %97 = "vhlo.slice_v1"(%92) <{limit_indices = #vhlo.tensor_v1<dense<[4, 16, 18, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x64x!vhlo.f32_v1> loc(#loc90)
    %98 = "vhlo.concatenate_v1"(%96, %97) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<4x16x18x64x!vhlo.f32_v1>, !vhlo.tensor_v1<4x16x18x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1> loc(#loc91)
    %99 = "vhlo.broadcast_in_dim_v1"(%74) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[2, 3]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1> loc(#loc92)
    %100 = "vhlo.multiply_v1"(%98, %99) : (!vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1> loc(#loc93)
    %101 = "vhlo.add_v1"(%94, %100) : (!vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1> loc(#loc94)
    %102 = "vhlo.multiply_v1"(%101, %23) : (!vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1> loc(#loc95)
    %103 = "vhlo.broadcast_in_dim_v1"(%77) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x8x2x18x128x!vhlo.f32_v1> loc(#loc96)
    %104 = "vhlo.reshape_v1"(%103) : (!vhlo.tensor_v1<4x8x2x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1> loc(#loc97)
    %105 = "vhlo.transpose_v1"(%104) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[4,16,128,18]{2,3,1,0}">} : (!vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x128x18x!vhlo.f32_v1> loc(#loc98)
    %106 = "vhlo.multiply_v1"(%105, %22) : (!vhlo.tensor_v1<4x16x128x18x!vhlo.f32_v1>, !vhlo.tensor_v1<4x16x128x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x128x18x!vhlo.f32_v1> loc(#loc99)
    %107 = "vhlo.dot_general_v2"(%102, %106) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"grad_x"> = #vhlo.string_v1<"false">, #vhlo.string_v1<"grad_y"> = #vhlo.string_v1<"false">}>} : (!vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x16x128x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1> loc(#loc100)
    %108 = "vhlo.broadcast_in_dim_v1"(%arg14) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bool_v1>) -> !vhlo.tensor_v1<18x18x!vhlo.bool_v1> loc(#loc101)
    %109 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<18x18x!vhlo.i64_v1> loc(#loc102)
    %110 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<18x18x!vhlo.i64_v1> loc(#loc103)
    %111 = "vhlo.compare_v1"(%109, %110) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LE>}> : (!vhlo.tensor_v1<18x18x!vhlo.i64_v1>, !vhlo.tensor_v1<18x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<18x18x!vhlo.bool_v1> loc(#loc104)
    %112 = "vhlo.and_v1"(%108, %111) : (!vhlo.tensor_v1<18x18x!vhlo.bool_v1>, !vhlo.tensor_v1<18x18x!vhlo.bool_v1>) -> !vhlo.tensor_v1<18x18x!vhlo.bool_v1> loc(#loc105)
    %113 = "vhlo.broadcast_in_dim_v1"(%112) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[1, 2]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<18x18x!vhlo.bool_v1>) -> !vhlo.tensor_v1<4x18x18x!vhlo.bool_v1> loc(#loc106)
    %114 = "vhlo.reshape_v1"(%arg13) : (!vhlo.tensor_v1<4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x18x!vhlo.i64_v1> loc(#loc107)
    %115 = "vhlo.custom_call_v1"(%114) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x4x18x!vhlo.i64_v1> loc(#loc108)
    %116 = "vhlo.reshape_v1"(%115) : (!vhlo.tensor_v1<1x4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc(#loc109)
    %117 = "vhlo.compare_v1"(%116, %25) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 NE>}> : (!vhlo.tensor_v1<4x18x!vhlo.i64_v1>, !vhlo.tensor_v1<4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.bool_v1> loc(#loc110)
    %118 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<4x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc(#loc111)
    %119 = "vhlo.compare_v1"(%118, %25) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<4x18x!vhlo.i64_v1>, !vhlo.tensor_v1<4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.bool_v1> loc(#loc112)
    %120 = "vhlo.add_v1"(%118, %21) : (!vhlo.tensor_v1<4x18x!vhlo.i64_v1>, !vhlo.tensor_v1<4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc(#loc113)
    %121 = "vhlo.select_v1"(%119, %120, %118) : (!vhlo.tensor_v1<4x18x!vhlo.bool_v1>, !vhlo.tensor_v1<4x18x!vhlo.i64_v1>, !vhlo.tensor_v1<4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc(#loc114)
    %122 = "vhlo.reshape_v1"(%121) : (!vhlo.tensor_v1<4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.i64_v1> loc(#loc115)
    %123 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc(#loc116)
    %124 = "vhlo.compare_v1"(%123, %25) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<4x18x!vhlo.i64_v1>, !vhlo.tensor_v1<4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.bool_v1> loc(#loc117)
    %125 = "vhlo.add_v1"(%123, %20) : (!vhlo.tensor_v1<4x18x!vhlo.i64_v1>, !vhlo.tensor_v1<4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc(#loc118)
    %126 = "vhlo.select_v1"(%124, %125, %123) : (!vhlo.tensor_v1<4x18x!vhlo.bool_v1>, !vhlo.tensor_v1<4x18x!vhlo.i64_v1>, !vhlo.tensor_v1<4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.i64_v1> loc(#loc119)
    %127 = "vhlo.reshape_v1"(%126) : (!vhlo.tensor_v1<4x18x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.i64_v1> loc(#loc120)
    %128 = "vhlo.concatenate_v1"(%122, %127) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<4x18x1x!vhlo.i64_v1>, !vhlo.tensor_v1<4x18x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x2x!vhlo.i64_v1> loc(#loc121)
    %129 = "vhlo.gather_v2"(%117, %128) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, index_vector_dim = #vhlo.integer_v1<2 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<1> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<4x18x!vhlo.bool_v1>, !vhlo.tensor_v1<4x18x2x!vhlo.i64_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.bool_v1> loc(#loc122)
    %130 = "vhlo.broadcast_in_dim_v1"(%129) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x18x!vhlo.bool_v1>) -> !vhlo.tensor_v1<4x18x18x!vhlo.bool_v1> loc(#loc123)
    %131 = "vhlo.and_v1"(%113, %130) : (!vhlo.tensor_v1<4x18x18x!vhlo.bool_v1>, !vhlo.tensor_v1<4x18x18x!vhlo.bool_v1>) -> !vhlo.tensor_v1<4x18x18x!vhlo.bool_v1> loc(#loc124)
    %132 = "vhlo.reshape_v1"(%131) : (!vhlo.tensor_v1<4x18x18x!vhlo.bool_v1>) -> !vhlo.tensor_v1<4x1x18x18x!vhlo.bool_v1> loc(#loc125)
    %133 = "vhlo.select_v1"(%132, %19, %18) : (!vhlo.tensor_v1<4x1x18x18x!vhlo.bool_v1>, !vhlo.tensor_v1<4x1x18x18x!vhlo.f32_v1>, !vhlo.tensor_v1<4x1x18x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x1x18x18x!vhlo.f32_v1> loc(#loc126)
    %134 = "vhlo.reshape_v1"(%133) : (!vhlo.tensor_v1<4x1x18x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x18x!vhlo.f32_v1> loc(#loc127)
    %135 = "vhlo.broadcast_in_dim_v1"(%134) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x18x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1> loc(#loc128)
    %136 = "vhlo.add_v1"(%107, %135) : (!vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1>, !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1> loc(#loc129)
    %137 = "vhlo.convert_v1"(%136) : (!vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.f64_v1> loc(#loc130)
    %138 = "vhlo.compare_v1"(%137, %17) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 EQ>}> : (!vhlo.tensor_v1<4x16x18x18x!vhlo.f64_v1>, !vhlo.tensor_v1<4x16x18x18x!vhlo.f64_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.bool_v1> loc(#loc131)
    %139 = "vhlo.not_v1"(%138) : (!vhlo.tensor_v1<4x16x18x18x!vhlo.bool_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.bool_v1> loc(#loc132)
    %140 = "vhlo.reduce_v1"(%139, %3) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg18: !vhlo.tensor_v1<!vhlo.bool_v1> loc("reduce.440"), %arg19: !vhlo.tensor_v1<!vhlo.bool_v1> loc("reduce.440")):
      %228 = "vhlo.or_v1"(%arg18, %arg19) : (!vhlo.tensor_v1<!vhlo.bool_v1>, !vhlo.tensor_v1<!vhlo.bool_v1>) -> !vhlo.tensor_v1<!vhlo.bool_v1> loc(#loc134)
      %229 = "vhlo.select_v1"(%228, %0, %3) : (!vhlo.tensor_v1<!vhlo.bool_v1>, !vhlo.tensor_v1<!vhlo.bool_v1>, !vhlo.tensor_v1<!vhlo.bool_v1>) -> !vhlo.tensor_v1<!vhlo.bool_v1> loc(#loc135)
      "vhlo.return_v1"(%229) : (!vhlo.tensor_v1<!vhlo.bool_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<4x16x18x18x!vhlo.bool_v1>, !vhlo.tensor_v1<!vhlo.bool_v1>) -> !vhlo.tensor_v1<4x16x18x!vhlo.bool_v1> loc(#loc133)
    %141 = "vhlo.reshape_v1"(%140) : (!vhlo.tensor_v1<4x16x18x!vhlo.bool_v1>) -> !vhlo.tensor_v1<4x16x18x1x!vhlo.bool_v1> loc(#loc136)
    %142 = "vhlo.not_v1"(%141) : (!vhlo.tensor_v1<4x16x18x1x!vhlo.bool_v1>) -> !vhlo.tensor_v1<4x16x18x1x!vhlo.bool_v1> loc(#loc137)
    %143 = "vhlo.reshape_v1"(%142) : (!vhlo.tensor_v1<4x16x18x1x!vhlo.bool_v1>) -> !vhlo.tensor_v1<4x16x18x!vhlo.bool_v1> loc(#loc138)
    %144 = "vhlo.broadcast_in_dim_v1"(%143) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x16x18x!vhlo.bool_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.bool_v1> loc(#loc139)
    %145 = "vhlo.reduce_v1"(%136, %10) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg18: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.404"), %arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.404")):
      %228 = "vhlo.maximum_v1"(%arg18, %arg19) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc141)
      "vhlo.return_v1"(%228) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x!vhlo.f32_v1> loc(#loc140)
    %146 = "vhlo.broadcast_in_dim_v1"(%145) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x16x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1> loc(#loc142)
    %147 = "vhlo.subtract_v1"(%136, %146) : (!vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1>, !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1> loc(#loc143)
    %148 = "vhlo.exponential_v2"(%147) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1> loc(#loc144)
    %149 = "vhlo.reduce_v1"(%148, %13) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg18: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.413"), %arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.413")):
      %228 = "vhlo.add_v1"(%arg18, %arg19) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc146)
      "vhlo.return_v1"(%228) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x!vhlo.f32_v1> loc(#loc145)
    %150 = "vhlo.broadcast_in_dim_v1"(%149) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x16x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1> loc(#loc147)
    %151 = "vhlo.divide_v1"(%148, %150) : (!vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1>, !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1> loc(#loc148)
    %152 = "vhlo.select_v1"(%144, %16, %151) : (!vhlo.tensor_v1<4x16x18x18x!vhlo.bool_v1>, !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1>, !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1> loc(#loc149)
    %153 = "vhlo.broadcast_in_dim_v1"(%47) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x8x2x18x128x!vhlo.f32_v1> loc(#loc150)
    %154 = "vhlo.reshape_v1"(%153) : (!vhlo.tensor_v1<4x8x2x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1> loc(#loc151)
    %155 = "vhlo.dot_general_v2"(%152, %154) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"grad_x"> = #vhlo.string_v1<"false">, #vhlo.string_v1<"grad_y"> = #vhlo.string_v1<"false">}>} : (!vhlo.tensor_v1<4x16x18x18x!vhlo.f32_v1>, !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1> loc(#loc152)
    %156 = "vhlo.transpose_v1"(%155) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[4,18,16,128]{3,1,2,0}">} : (!vhlo.tensor_v1<4x16x18x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1> loc(#loc153)
    %157 = "vhlo.reshape_v1"(%156) : (!vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x2048x!vhlo.f32_v1> loc(#loc154)
    %158 = "vhlo.reshape_v1"(%arg12) : (!vhlo.tensor_v1<1024x2048x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1024x2048x!vhlo.f32_v1> loc(#loc155)
    %159 = "vhlo.custom_call_v1"(%158) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x2048x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1024x2048x!vhlo.f32_v1> loc(#loc156)
    %160 = "vhlo.reshape_v1"(%159) : (!vhlo.tensor_v1<1x1024x2048x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1024x2048x!vhlo.f32_v1> loc(#loc157)
    %161 = "vhlo.transpose_v1"(%160) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"f32[2048,1024]{0,1}">} : (!vhlo.tensor_v1<1024x2048x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2048x1024x!vhlo.f32_v1> loc(#loc158)
    %162 = "vhlo.dot_general_v2"(%157, %161) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<72x2048x!vhlo.f32_v1>, !vhlo.tensor_v1<2048x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x1024x!vhlo.f32_v1> loc(#loc159)
    %163 = "vhlo.reshape_v1"(%162) : (!vhlo.tensor_v1<72x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc160)
    %164 = "vhlo.add_v1"(%35, %163) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc161)
    %165 = "vhlo.reshape_v1"(%arg11) : (!vhlo.tensor_v1<1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1024x!vhlo.f32_v1> loc(#loc162)
    %166 = "vhlo.custom_call_v1"(%165) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1024x!vhlo.f32_v1> loc(#loc163)
    %167 = "vhlo.reshape_v1"(%166) : (!vhlo.tensor_v1<1x1x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1024x!vhlo.f32_v1> loc(#loc164)
    %168 = "vhlo.composite_v1"(%164, %167) <{composite_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"epsilon"> = #vhlo.float_v1<9.99999997E-7 : !vhlo.f32_v1>, #vhlo.string_v1<"normalized_shape"> = #vhlo.tensor_v1<dense<1024> : tensor<1xi64>>}>, decomposition = #vhlo.string_v1<"tenstorrent.rms_norm.impl_0">, name = #vhlo.string_v1<"tenstorrent.rms_norm">, version = #vhlo.integer_v1<0 : i32>}> : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc165)
    %169 = "vhlo.reshape_v1"(%168) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x1024x!vhlo.f32_v1> loc(#loc166)
    %170 = "vhlo.reshape_v1"(%arg17) : (!vhlo.tensor_v1<3072x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x3072x1024x!vhlo.f32_v1> loc(#loc167)
    %171 = "vhlo.custom_call_v1"(%170) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x3072x1024x!vhlo.f32_v1> loc(#loc168)
    %172 = "vhlo.reshape_v1"(%171) : (!vhlo.tensor_v1<1x3072x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.f32_v1> loc(#loc169)
    %173 = "vhlo.transpose_v1"(%172) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"f32[1024,3072]{0,1}">} : (!vhlo.tensor_v1<3072x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.f32_v1> loc(#loc170)
    %174 = "vhlo.dot_general_v2"(%169, %173) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<72x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1024x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x3072x!vhlo.f32_v1> loc(#loc171)
    %175 = "vhlo.reshape_v1"(%174) : (!vhlo.tensor_v1<72x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x3072x!vhlo.f32_v1> loc(#loc172)
    %176 = "vhlo.logistic_v2"(%175) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x18x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x3072x!vhlo.f32_v1> loc(#loc173)
    %177 = "vhlo.multiply_v1"(%175, %176) : (!vhlo.tensor_v1<4x18x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x3072x!vhlo.f32_v1> loc(#loc174)
    %178 = "vhlo.reshape_v1"(%arg10) : (!vhlo.tensor_v1<3072x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x3072x1024x!vhlo.f32_v1> loc(#loc175)
    %179 = "vhlo.custom_call_v1"(%178) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x3072x1024x!vhlo.f32_v1> loc(#loc176)
    %180 = "vhlo.reshape_v1"(%179) : (!vhlo.tensor_v1<1x3072x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.f32_v1> loc(#loc177)
    %181 = "vhlo.transpose_v1"(%180) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"f32[1024,3072]{0,1}">} : (!vhlo.tensor_v1<3072x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.f32_v1> loc(#loc178)
    %182 = "vhlo.dot_general_v2"(%169, %181) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<72x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1024x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x3072x!vhlo.f32_v1> loc(#loc179)
    %183 = "vhlo.reshape_v1"(%182) : (!vhlo.tensor_v1<72x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x3072x!vhlo.f32_v1> loc(#loc180)
    %184 = "vhlo.multiply_v1"(%177, %183) : (!vhlo.tensor_v1<4x18x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x3072x!vhlo.f32_v1> loc(#loc181)
    %185 = "vhlo.reshape_v1"(%184) : (!vhlo.tensor_v1<4x18x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x3072x!vhlo.f32_v1> loc(#loc182)
    %186 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<1024x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.f32_v1> loc(#loc183)
    %187 = "vhlo.custom_call_v1"(%186) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.f32_v1> loc(#loc184)
    %188 = "vhlo.reshape_v1"(%187) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.f32_v1> loc(#loc185)
    %189 = "vhlo.transpose_v1"(%188) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"f32[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.f32_v1> loc(#loc186)
    %190 = "vhlo.dot_general_v2"(%185, %189) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<72x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x1024x!vhlo.f32_v1> loc(#loc187)
    %191 = "vhlo.reshape_v1"(%190) : (!vhlo.tensor_v1<72x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc188)
    %192 = "vhlo.add_v1"(%164, %191) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc189)
    %193 = "vhlo.reshape_v1"(%arg8) : (!vhlo.tensor_v1<1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1024x!vhlo.f32_v1> loc(#loc190)
    %194 = "vhlo.custom_call_v1"(%193) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_norm_weight">}>} : (!vhlo.tensor_v1<1x1x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1024x!vhlo.f32_v1> loc(#loc191)
    %195 = "vhlo.reshape_v1"(%194) : (!vhlo.tensor_v1<1x1x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1024x!vhlo.f32_v1> loc(#loc192)
    %196 = "vhlo.composite_v1"(%192, %195) <{composite_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"epsilon"> = #vhlo.float_v1<9.99999997E-7 : !vhlo.f32_v1>, #vhlo.string_v1<"normalized_shape"> = #vhlo.tensor_v1<dense<1024> : tensor<1xi64>>}>, decomposition = #vhlo.string_v1<"tenstorrent.rms_norm.impl">, name = #vhlo.string_v1<"tenstorrent.rms_norm">, version = #vhlo.integer_v1<0 : i32>}> : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc193)
    %197 = "vhlo.reshape_v1"(%196) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x1024x!vhlo.f32_v1> loc(#loc194)
    %198 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<151936x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x151936x1024x!vhlo.f32_v1> loc(#loc195)
    %199 = "vhlo.custom_call_v1"(%198) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___lm_head_weight">}>} : (!vhlo.tensor_v1<1x151936x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x151936x1024x!vhlo.f32_v1> loc(#loc196)
    %200 = "vhlo.reshape_v1"(%199) : (!vhlo.tensor_v1<1x151936x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<151936x1024x!vhlo.f32_v1> loc(#loc197)
    %201 = "vhlo.transpose_v1"(%200) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"f32[1024,151936]{0,1}">} : (!vhlo.tensor_v1<151936x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1024x151936x!vhlo.f32_v1> loc(#loc198)
    %202 = "vhlo.dot_general_v2"(%197, %201) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<72x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1024x151936x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x151936x!vhlo.f32_v1> loc(#loc199)
    %203 = "vhlo.reshape_v1"(%202) : (!vhlo.tensor_v1<72x151936x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x151936x!vhlo.f32_v1> loc(#loc200)
    %204 = "vhlo.reduce_v1"(%202, %4) <{dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> ({
    ^bb0(%arg18: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.553"), %arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.553")):
      %228 = "vhlo.maximum_v1"(%arg18, %arg19) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc202)
      "vhlo.return_v1"(%228) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<72x151936x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x!vhlo.f32_v1> loc(#loc201)
    %205 = "vhlo.broadcast_in_dim_v1"(%204) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<72x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x151936x!vhlo.f32_v1> loc(#loc203)
    %206 = "vhlo.subtract_v1"(%202, %205) : (!vhlo.tensor_v1<72x151936x!vhlo.f32_v1>, !vhlo.tensor_v1<72x151936x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x151936x!vhlo.f32_v1> loc(#loc204)
    %207 = "vhlo.exponential_v2"(%206) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<72x151936x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x151936x!vhlo.f32_v1> loc(#loc205)
    %208 = "vhlo.reduce_v1"(%207, %13) <{dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> ({
    ^bb0(%arg18: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.567"), %arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.567")):
      %228 = "vhlo.add_v1"(%arg18, %arg19) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc207)
      "vhlo.return_v1"(%228) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<72x151936x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x!vhlo.f32_v1> loc(#loc206)
    %209 = "vhlo.reshape_v1"(%208) : (!vhlo.tensor_v1<72x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x1x!vhlo.f32_v1> loc(#loc208)
    %210 = "vhlo.log_v2"(%209) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<72x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x1x!vhlo.f32_v1> loc(#loc209)
    %211 = "vhlo.reshape_v1"(%210) : (!vhlo.tensor_v1<72x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x!vhlo.f32_v1> loc(#loc210)
    %212 = "vhlo.broadcast_in_dim_v1"(%211) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<72x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x151936x!vhlo.f32_v1> loc(#loc211)
    %213 = "vhlo.subtract_v1"(%206, %212) : (!vhlo.tensor_v1<72x151936x!vhlo.f32_v1>, !vhlo.tensor_v1<72x151936x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x151936x!vhlo.f32_v1> loc(#loc212)
    %214 = "vhlo.iota_v1"() <{iota_dimension = #vhlo.integer_v1<0 : i64>}> : () -> !vhlo.tensor_v1<72x!vhlo.ui32_v1> loc(#loc213)
    %215 = "vhlo.reshape_v1"(%214) : (!vhlo.tensor_v1<72x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<72x1x1x!vhlo.ui32_v1> loc(#loc213)
    %216 = "vhlo.select_v1"(%81, %80, %15) : (!vhlo.tensor_v1<72x!vhlo.bool_v1>, !vhlo.tensor_v1<72x!vhlo.i64_v1>, !vhlo.tensor_v1<72x!vhlo.i64_v1>) -> !vhlo.tensor_v1<72x!vhlo.i64_v1> loc(#loc214)
    %217 = "vhlo.reshape_v1"(%216) : (!vhlo.tensor_v1<72x!vhlo.i64_v1>) -> !vhlo.tensor_v1<72x1x!vhlo.i64_v1> loc(#loc215)
    %218 = "vhlo.convert_v1"(%217) : (!vhlo.tensor_v1<72x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<72x1x!vhlo.ui32_v1> loc(#loc216)
    %219 = "vhlo.reshape_v1"(%218) : (!vhlo.tensor_v1<72x1x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<72x1x1x!vhlo.ui32_v1> loc(#loc217)
    %220 = "vhlo.concatenate_v1"(%215, %219) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<72x1x1x!vhlo.ui32_v1>, !vhlo.tensor_v1<72x1x1x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<72x1x2x!vhlo.ui32_v1> loc(#loc218)
    %221 = "vhlo.gather_v2"(%213, %220) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, index_vector_dim = #vhlo.integer_v1<2 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<1> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<72x151936x!vhlo.f32_v1>, !vhlo.tensor_v1<72x1x2x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<72x1x!vhlo.f32_v1> loc(#loc219)
    %222 = "vhlo.reshape_v1"(%221) : (!vhlo.tensor_v1<72x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x!vhlo.f32_v1> loc(#loc220)
    %223 = "vhlo.negate_v1"(%222) : (!vhlo.tensor_v1<72x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x!vhlo.f32_v1> loc(#loc221)
    %224 = "vhlo.select_v1"(%81, %223, %14) : (!vhlo.tensor_v1<72x!vhlo.bool_v1>, !vhlo.tensor_v1<72x!vhlo.f32_v1>, !vhlo.tensor_v1<72x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x!vhlo.f32_v1> loc(#loc222)
    %225 = "vhlo.convert_v1"(%81) : (!vhlo.tensor_v1<72x!vhlo.bool_v1>) -> !vhlo.tensor_v1<72x!vhlo.i64_v1> loc(#loc223)
    %226 = "vhlo.convert_v1"(%225) : (!vhlo.tensor_v1<72x!vhlo.i64_v1>) -> !vhlo.tensor_v1<72x!vhlo.f32_v1> loc(#loc224)
    %227 = "vhlo.divide_v1"(%224, %226) : (!vhlo.tensor_v1<72x!vhlo.f32_v1>, !vhlo.tensor_v1<72x!vhlo.f32_v1>) -> !vhlo.tensor_v1<72x!vhlo.f32_v1> loc(#loc225)
    "vhlo.return_v1"(%47, %77, %227, %203) : (!vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x8x18x128x!vhlo.f32_v1>, !vhlo.tensor_v1<72x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x151936x!vhlo.f32_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
  vhlo.func_v1 @tenstorrent.rms_norm.impl(%arg0: !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc("custom-call.512"), %arg1: !vhlo.tensor_v1<1024x!vhlo.f32_v1> loc("custom-call.199")) -> (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.765625E-4> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.99999997E-7> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %4 = "vhlo.broadcast_in_dim_v1"(%3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1> loc(#loc)
    %5 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.f32_v1> loc(#loc)
    %6 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc)
    %7 = "vhlo.power_v1"(%arg0, %6) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc228)
    %8 = "vhlo.reduce_v1"(%7, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg2: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.521"), %arg3: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.521")):
      %18 = "vhlo.add_v1"(%arg2, %arg3) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc230)
      "vhlo.return_v1"(%18) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.f32_v1> loc(#loc229)
    %9 = "vhlo.multiply_v1"(%8, %5) : (!vhlo.tensor_v1<4x18x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.f32_v1> loc(#loc231)
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<4x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1> loc(#loc232)
    %11 = "vhlo.add_v1"(%10, %4) : (!vhlo.tensor_v1<4x18x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1> loc(#loc233)
    %12 = "vhlo.rsqrt_v2"(%11) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x18x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1> loc(#loc234)
    %13 = "vhlo.reshape_v1"(%12) : (!vhlo.tensor_v1<4x18x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.f32_v1> loc(#loc235)
    %14 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc236)
    %15 = "vhlo.multiply_v1"(%arg0, %14) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc237)
    %16 = "vhlo.broadcast_in_dim_v1"(%arg1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc238)
    %17 = "vhlo.multiply_v1"(%15, %16) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc239)
    "vhlo.return_v1"(%17) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"private">} loc(#loc)
  vhlo.func_v1 @tenstorrent.rms_norm.impl_0(%arg0: !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc("custom-call.461"), %arg1: !vhlo.tensor_v1<1024x!vhlo.f32_v1> loc("custom-call.218")) -> (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.765625E-4> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.99999997E-7> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %4 = "vhlo.broadcast_in_dim_v1"(%3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1> loc(#loc)
    %5 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.f32_v1> loc(#loc)
    %6 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc)
    %7 = "vhlo.power_v1"(%arg0, %6) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc242)
    %8 = "vhlo.reduce_v1"(%7, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg2: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.470"), %arg3: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.470")):
      %18 = "vhlo.add_v1"(%arg2, %arg3) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc244)
      "vhlo.return_v1"(%18) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.f32_v1> loc(#loc243)
    %9 = "vhlo.multiply_v1"(%8, %5) : (!vhlo.tensor_v1<4x18x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.f32_v1> loc(#loc245)
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<4x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1> loc(#loc246)
    %11 = "vhlo.add_v1"(%10, %4) : (!vhlo.tensor_v1<4x18x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1> loc(#loc247)
    %12 = "vhlo.rsqrt_v2"(%11) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x18x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1> loc(#loc248)
    %13 = "vhlo.reshape_v1"(%12) : (!vhlo.tensor_v1<4x18x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.f32_v1> loc(#loc249)
    %14 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc250)
    %15 = "vhlo.multiply_v1"(%arg0, %14) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc251)
    %16 = "vhlo.broadcast_in_dim_v1"(%arg1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc252)
    %17 = "vhlo.multiply_v1"(%15, %16) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc253)
    "vhlo.return_v1"(%17) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"private">} loc(#loc)
  vhlo.func_v1 @tenstorrent.rms_norm.impl_1(%arg0: !vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1> loc("custom-call.345"), %arg1: !vhlo.tensor_v1<128x!vhlo.f32_v1> loc("custom-call.332")) -> (!vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<7.812500e-03> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.99999997E-7> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %4 = "vhlo.broadcast_in_dim_v1"(%3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x1x!vhlo.f32_v1> loc(#loc)
    %5 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x!vhlo.f32_v1> loc(#loc)
    %6 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1> loc(#loc)
    %7 = "vhlo.power_v1"(%arg0, %6) : (!vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1> loc(#loc256)
    %8 = "vhlo.reduce_v1"(%7, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg2: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.354"), %arg3: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.354")):
      %18 = "vhlo.add_v1"(%arg2, %arg3) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc258)
      "vhlo.return_v1"(%18) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x!vhlo.f32_v1> loc(#loc257)
    %9 = "vhlo.multiply_v1"(%8, %5) : (!vhlo.tensor_v1<4x18x16x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x!vhlo.f32_v1> loc(#loc259)
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<4x18x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x1x!vhlo.f32_v1> loc(#loc260)
    %11 = "vhlo.add_v1"(%10, %4) : (!vhlo.tensor_v1<4x18x16x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x16x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x1x!vhlo.f32_v1> loc(#loc261)
    %12 = "vhlo.rsqrt_v2"(%11) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x18x16x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x1x!vhlo.f32_v1> loc(#loc262)
    %13 = "vhlo.reshape_v1"(%12) : (!vhlo.tensor_v1<4x18x16x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x!vhlo.f32_v1> loc(#loc263)
    %14 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x18x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1> loc(#loc264)
    %15 = "vhlo.multiply_v1"(%arg0, %14) : (!vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1> loc(#loc265)
    %16 = "vhlo.broadcast_in_dim_v1"(%arg1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> : (!vhlo.tensor_v1<128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1> loc(#loc266)
    %17 = "vhlo.multiply_v1"(%15, %16) : (!vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1> loc(#loc267)
    "vhlo.return_v1"(%17) : (!vhlo.tensor_v1<4x18x16x128x!vhlo.f32_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"private">} loc(#loc)
  vhlo.func_v1 @tenstorrent.rms_norm.impl_2(%arg0: !vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1> loc("custom-call.102"), %arg1: !vhlo.tensor_v1<128x!vhlo.f32_v1> loc("custom-call.89")) -> (!vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<7.812500e-03> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.99999997E-7> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %4 = "vhlo.broadcast_in_dim_v1"(%3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x1x!vhlo.f32_v1> loc(#loc)
    %5 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x!vhlo.f32_v1> loc(#loc)
    %6 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1> loc(#loc)
    %7 = "vhlo.power_v1"(%arg0, %6) : (!vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1> loc(#loc270)
    %8 = "vhlo.reduce_v1"(%7, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg2: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.111"), %arg3: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.111")):
      %18 = "vhlo.add_v1"(%arg2, %arg3) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc272)
      "vhlo.return_v1"(%18) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x!vhlo.f32_v1> loc(#loc271)
    %9 = "vhlo.multiply_v1"(%8, %5) : (!vhlo.tensor_v1<4x18x8x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x8x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x!vhlo.f32_v1> loc(#loc273)
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<4x18x8x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x1x!vhlo.f32_v1> loc(#loc274)
    %11 = "vhlo.add_v1"(%10, %4) : (!vhlo.tensor_v1<4x18x8x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x8x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x1x!vhlo.f32_v1> loc(#loc275)
    %12 = "vhlo.rsqrt_v2"(%11) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x18x8x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x1x!vhlo.f32_v1> loc(#loc276)
    %13 = "vhlo.reshape_v1"(%12) : (!vhlo.tensor_v1<4x18x8x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x!vhlo.f32_v1> loc(#loc277)
    %14 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<4x18x8x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1> loc(#loc278)
    %15 = "vhlo.multiply_v1"(%arg0, %14) : (!vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1> loc(#loc279)
    %16 = "vhlo.broadcast_in_dim_v1"(%arg1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> : (!vhlo.tensor_v1<128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1> loc(#loc280)
    %17 = "vhlo.multiply_v1"(%15, %16) : (!vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1> loc(#loc281)
    "vhlo.return_v1"(%17) : (!vhlo.tensor_v1<4x18x8x128x!vhlo.f32_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"private">} loc(#loc)
  vhlo.func_v1 @tenstorrent.rms_norm.impl_3(%arg0: !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc("custom-call.26"), %arg1: !vhlo.tensor_v1<1024x!vhlo.f32_v1> loc("custom-call.10")) -> (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.765625E-4> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.99999997E-7> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %4 = "vhlo.broadcast_in_dim_v1"(%3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1> loc(#loc)
    %5 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.f32_v1> loc(#loc)
    %6 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc)
    %7 = "vhlo.power_v1"(%arg0, %6) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc284)
    %8 = "vhlo.reduce_v1"(%7, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg2: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.35"), %arg3: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.35")):
      %18 = "vhlo.add_v1"(%arg2, %arg3) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc286)
      "vhlo.return_v1"(%18) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.f32_v1> loc(#loc285)
    %9 = "vhlo.multiply_v1"(%8, %5) : (!vhlo.tensor_v1<4x18x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.f32_v1> loc(#loc287)
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<4x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1> loc(#loc288)
    %11 = "vhlo.add_v1"(%10, %4) : (!vhlo.tensor_v1<4x18x1x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1> loc(#loc289)
    %12 = "vhlo.rsqrt_v2"(%11) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<4x18x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1x!vhlo.f32_v1> loc(#loc290)
    %13 = "vhlo.reshape_v1"(%12) : (!vhlo.tensor_v1<4x18x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x!vhlo.f32_v1> loc(#loc291)
    %14 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<4x18x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc292)
    %15 = "vhlo.multiply_v1"(%arg0, %14) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc293)
    %16 = "vhlo.broadcast_in_dim_v1"(%arg1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc294)
    %17 = "vhlo.multiply_v1"(%15, %16) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1> loc(#loc295)
    "vhlo.return_v1"(%17) : (!vhlo.tensor_v1<4x18x1024x!vhlo.f32_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"private">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc19 = loc("reshape.20")
#loc20 = loc("custom-call.21")
#loc21 = loc("reshape.22")
#loc22 = loc("reshape.15")
#loc23 = loc("custom-call.16")
#loc24 = loc("reshape.17")
#loc25 = loc("reshape.18")
#loc26 = loc("convert.23")
#loc27 = loc("gather.24")
#loc28 = loc("reshape.25")
#loc29 = loc("reshape.7")
#loc30 = loc("custom-call.8")
#loc31 = loc("reshape.9")
#loc32 = loc("custom-call.56")
#loc33 = loc("reshape.57")
#loc34 = loc("reshape.2")
#loc35 = loc("custom-call.3")
#loc36 = loc("reshape.4")
#loc37 = loc("transpose.5")
#loc38 = loc("dot.58")
#loc39 = loc("reshape.60")
#loc40 = loc("transpose.61")
#loc41 = loc("reshape.94")
#loc42 = loc("custom-call.95")
#loc43 = loc("reshape.96")
#loc44 = loc("transpose.97")
#loc45 = loc("dot.99")
#loc46 = loc("reshape.101")
#loc47 = loc("reshape.86")
#loc48 = loc("custom-call.87")
#loc49 = loc("reshape.88")
#loc50 = loc("custom-call.132")
#loc51 = loc("transpose.133")
#loc52 = loc("reshape.71")
#loc53 = loc("custom-call.72")
#loc54 = loc("reshape.75")
#loc55 = loc("dot.78")
#loc56 = loc("transpose.79")
#loc57 = loc("concatenate.80")
#loc58 = loc("cosine.142")
#loc59 = loc("reshape.146")
#loc60 = loc("broadcast.147")
#loc61 = loc("multiply.148")
#loc62 = loc("slice.135")
#loc63 = loc("negate.136")
#loc64 = loc("slice.134")
#loc65 = loc("concatenate.137")
#loc66 = loc("sine.81")
#loc67 = loc("reshape.138")
#loc68 = loc("broadcast.139")
#loc69 = loc("multiply.140")
#loc70 = loc("add.151")
#loc71 = loc("pad.155")
#loc72 = loc("slice.156")
#loc73 = loc("reshape.157")
#loc74 = loc("compare.585")
#loc75 = loc("reshape.337")
#loc76 = loc("custom-call.338")
#loc77 = loc("reshape.339")
#loc78 = loc("transpose.340")
#loc79 = loc("dot.342")
#loc80 = loc("reshape.344")
#loc81 = loc("reshape.329")
#loc82 = loc("custom-call.330")
#loc83 = loc("reshape.331")
#loc84 = loc("custom-call.375")
#loc85 = loc("transpose.376")
#loc86 = loc("broadcast.385")
#loc87 = loc("multiply.386")
#loc88 = loc("slice.378")
#loc89 = loc("negate.379")
#loc90 = loc("slice.377")
#loc91 = loc("concatenate.380")
#loc92 = loc("broadcast.382")
#loc93 = loc("multiply.383")
#loc94 = loc("add.389")
#loc95 = loc("multiply.391")
#loc96 = loc("broadcast.321")
#loc97 = loc("reshape.322")
#loc98 = loc("transpose.323")
#loc99 = loc("multiply.325")
#loc100 = loc("dot.392")
#loc101 = loc("broadcast.305")
#loc102 = loc("broadcast.292")
#loc103 = loc("broadcast.294")
#loc104 = loc("compare.295")
#loc105 = loc("and.306")
#loc106 = loc("broadcast.309")
#loc107 = loc("reshape.285")
#loc108 = loc("custom-call.286")
#loc109 = loc("reshape.287")
#loc110 = loc("convert.288")
#loc111 = loc("broadcast.270")
#loc112 = loc("compare.279")
#loc113 = loc("add.276")
#loc114 = loc("select.280")
#loc115 = loc("reshape.281")
#loc116 = loc("broadcast.255")
#loc117 = loc("compare.264")
#loc118 = loc("add.261")
#loc119 = loc("select.265")
#loc120 = loc("reshape.282")
#loc121 = loc("concatenate.283")
#loc122 = loc("gather.289")
#loc123 = loc("broadcast.311")
#loc124 = loc("and.312")
#loc125 = loc("reshape.313")
#loc126 = loc("select.316")
#loc127 = loc("reshape.396")
#loc128 = loc("broadcast.397")
#loc129 = loc("add.398")
#loc130 = loc("convert.424")
#loc131 = loc("compare.426")
#loc132 = loc("not.428")
#loc134 = loc("or.438")
#loc135 = loc("select.439")
#loc136 = loc("reshape.444")
#loc137 = loc("not.446")
#loc138 = loc("reshape.448")
#loc139 = loc("broadcast.449")
#loc141 = loc("maximum.403")
#loc142 = loc("broadcast.405")
#loc143 = loc("subtract.406")
#loc144 = loc("exponential.407")
#loc146 = loc("add.412")
#loc147 = loc("broadcast.414")
#loc148 = loc("divide.415")
#loc149 = loc("select.450")
#loc150 = loc("broadcast.231")
#loc151 = loc("reshape.232")
#loc152 = loc("dot.451")
#loc153 = loc("transpose.453")
#loc154 = loc("reshape.455")
#loc155 = loc("reshape.224")
#loc156 = loc("custom-call.225")
#loc157 = loc("reshape.226")
#loc158 = loc("transpose.227")
#loc159 = loc("dot.456")
#loc160 = loc("reshape.457")
#loc161 = loc("add.460")
#loc162 = loc("reshape.215")
#loc163 = loc("custom-call.216")
#loc164 = loc("reshape.217")
#loc165 = loc("custom-call.491")
#loc166 = loc("reshape.500")
#loc167 = loc("reshape.496")
#loc168 = loc("custom-call.497")
#loc169 = loc("reshape.498")
#loc170 = loc("transpose.499")
#loc171 = loc("dot.501")
#loc172 = loc("reshape.502")
#loc173 = loc("logistic.503")
#loc174 = loc("multiply.504")
#loc175 = loc("reshape.210")
#loc176 = loc("custom-call.211")
#loc177 = loc("reshape.212")
#loc178 = loc("transpose.213")
#loc179 = loc("dot.493")
#loc180 = loc("reshape.494")
#loc181 = loc("multiply.505")
#loc182 = loc("reshape.506")
#loc183 = loc("reshape.205")
#loc184 = loc("custom-call.206")
#loc185 = loc("reshape.207")
#loc186 = loc("transpose.208")
#loc187 = loc("dot.507")
#loc188 = loc("reshape.508")
#loc189 = loc("add.511")
#loc190 = loc("reshape.196")
#loc191 = loc("custom-call.197")
#loc192 = loc("reshape.198")
#loc193 = loc("custom-call.542")
#loc194 = loc("reshape.543")
#loc195 = loc("reshape.191")
#loc196 = loc("custom-call.192")
#loc197 = loc("reshape.193")
#loc198 = loc("transpose.194")
#loc199 = loc("dot.544")
#loc200 = loc("reshape.545")
#loc202 = loc("maximum.552")
#loc203 = loc("broadcast.558")
#loc204 = loc("subtract.559")
#loc205 = loc("exponential.560")
#loc207 = loc("add.566")
#loc208 = loc("reshape.568")
#loc209 = loc("log.569")
#loc210 = loc("reshape.572")
#loc211 = loc("broadcast.573")
#loc212 = loc("subtract.574")
#loc213 = loc("iota.576")
#loc214 = loc("select.186")
#loc215 = loc("reshape.187")
#loc216 = loc("convert.575")
#loc217 = loc("reshape.577")
#loc218 = loc("concatenate.578")
#loc219 = loc("gather.579")
#loc220 = loc("reshape.580")
#loc221 = loc("negate.581")
#loc222 = loc("select.587")
#loc223 = loc("convert.160")
#loc224 = loc("convert.168")
#loc225 = loc("divide.595")
#loc228 = loc("power.514")
#loc230 = loc("add.520")
#loc231 = loc("multiply.530")
#loc232 = loc("reshape.531")
#loc233 = loc("add.535")
#loc234 = loc("rsqrt.536")
#loc235 = loc("reshape.537")
#loc236 = loc("broadcast.538")
#loc237 = loc("multiply.539")
#loc238 = loc("broadcast.540")
#loc239 = loc("multiply.541")
#loc242 = loc("power.463")
#loc244 = loc("add.469")
#loc245 = loc("multiply.479")
#loc246 = loc("reshape.480")
#loc247 = loc("add.484")
#loc248 = loc("rsqrt.485")
#loc249 = loc("reshape.486")
#loc250 = loc("broadcast.487")
#loc251 = loc("multiply.488")
#loc252 = loc("broadcast.489")
#loc253 = loc("multiply.490")
#loc256 = loc("power.347")
#loc258 = loc("add.353")
#loc259 = loc("multiply.363")
#loc260 = loc("reshape.364")
#loc261 = loc("add.368")
#loc262 = loc("rsqrt.369")
#loc263 = loc("reshape.370")
#loc264 = loc("broadcast.371")
#loc265 = loc("multiply.372")
#loc266 = loc("broadcast.373")
#loc267 = loc("multiply.374")
#loc270 = loc("power.104")
#loc272 = loc("add.110")
#loc273 = loc("multiply.120")
#loc274 = loc("reshape.121")
#loc275 = loc("add.125")
#loc276 = loc("rsqrt.126")
#loc277 = loc("reshape.127")
#loc278 = loc("broadcast.128")
#loc279 = loc("multiply.129")
#loc280 = loc("broadcast.130")
#loc281 = loc("multiply.131")
#loc284 = loc("power.28")
#loc286 = loc("add.34")
#loc287 = loc("multiply.44")
#loc288 = loc("reshape.45")
#loc289 = loc("add.49")
#loc290 = loc("rsqrt.50")
#loc291 = loc("reshape.51")
#loc292 = loc("broadcast.52")
#loc293 = loc("multiply.53")
#loc294 = loc("broadcast.54")
#loc295 = loc("multiply.55")
------------------ END OF MLIR MODULE ------------------
2026-01-28 22:12:58.314 (   5.480s) [        66B35000]      module_builder.cc:1111     1| MLIR Module shlo:
#loc1 = loc("p0.1")
#loc2 = loc("p1.6")
#loc3 = loc("p2.14")
#loc4 = loc("p3.19")
#loc5 = loc("p4.70")
#loc6 = loc("p5.85")
#loc7 = loc("p6.93")
#loc8 = loc("p7.190")
#loc9 = loc("p8.195")
#loc10 = loc("p9.204")
#loc11 = loc("p10.209")
#loc12 = loc("p11.214")
#loc13 = loc("p12.223")
#loc14 = loc("p13.284")
#loc15 = loc("p14.296")
#loc16 = loc("p15.328")
#loc17 = loc("p16.336")
#loc18 = loc("p17.495")
#loc133 = loc("reduce.440")
#loc222 = loc("custom-call.512")
#loc223 = loc("custom-call.199")
#loc235 = loc("custom-call.461")
#loc236 = loc("custom-call.218")
#loc248 = loc("custom-call.345")
#loc249 = loc("custom-call.332")
#loc261 = loc("custom-call.102")
#loc262 = loc("custom-call.89")
#loc274 = loc("custom-call.26")
#loc275 = loc("custom-call.10")
module @SyncTensorsGraph.597 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1024x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p0.1"), %arg1: tensor<1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p1.6"), %arg2: tensor<4x18xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p2.14"), %arg3: tensor<151936x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p3.19"), %arg4: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p4.70"), %arg5: tensor<128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p5.85"), %arg6: tensor<1024x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p6.93"), %arg7: tensor<151936x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p7.190"), %arg8: tensor<1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p8.195"), %arg9: tensor<1024x3072xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p9.204"), %arg10: tensor<3072x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p10.209"), %arg11: tensor<1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p11.214"), %arg12: tensor<1024x2048xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p12.223"), %arg13: tensor<4x18xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p13.284"), %arg14: tensor<i1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"} loc("p14.296"), %arg15: tensor<128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p15.328"), %arg16: tensor<2048x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p16.336"), %arg17: tensor<3072x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p17.495")) -> (tensor<4x8x18x128xf32>, tensor<4x8x18x128xf32>, tensor<72xf32>, tensor<4x18x151936xf32>) {
    %c = stablehlo.constant dense<true> : tensor<i1> loc(#loc)
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]> : tensor<18xi64> loc(#loc)
    %c_1 = stablehlo.constant dense<[0, 1, 2, 3]> : tensor<4xi64> loc(#loc)
    %c_2 = stablehlo.constant dense<false> : tensor<i1> loc(#loc)
    %cst = stablehlo.constant dense<-3.40282347E+38> : tensor<f32> loc(#loc)
    %cst_3 = stablehlo.constant dense<[[[0.000000e+00, 1.000000e+00, 2.000000e+00, 3.000000e+00, 4.000000e+00, 5.000000e+00, 6.000000e+00, 7.000000e+00, 8.000000e+00, 9.000000e+00, 1.000000e+01, 1.100000e+01, 1.200000e+01, 1.300000e+01, 1.400000e+01, 1.500000e+01, 1.600000e+01, 1.700000e+01]]]> : tensor<1x1x18xf32> loc(#loc)
    %c_4 = stablehlo.constant dense<-100> : tensor<i64> loc(#loc)
    %cst_5 = stablehlo.constant dense<0.297301769> : tensor<f32> loc(#loc)
    %c_6 = stablehlo.constant dense<4> : tensor<i64> loc(#loc)
    %c_7 = stablehlo.constant dense<18> : tensor<i64> loc(#loc)
    %cst_8 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %cst_9 = stablehlo.constant dense<0xFFF0000000000000> : tensor<f64> loc(#loc)
    %c_10 = stablehlo.constant dense<0> : tensor<i64> loc(#loc)
    %cst_11 = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<72xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<i64>) -> tensor<72xi64> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<4x16x18x18xf32> loc(#loc)
    %3 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<f64>) -> tensor<4x16x18x18xf64> loc(#loc)
    %4 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<f32>) -> tensor<4x1x18x18xf32> loc(#loc)
    %5 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<4x1x18x18xf32> loc(#loc)
    %6 = stablehlo.broadcast_in_dim %c_7, dims = [] : (tensor<i64>) -> tensor<4x18xi64> loc(#loc)
    %7 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<4x18xi64> loc(#loc)
    %8 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<4x16x128x18xf32> loc(#loc)
    %9 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<4x16x18x128xf32> loc(#loc)
    %10 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<i64>) -> tensor<72xi64> loc(#loc)
    %11 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<i64>) -> tensor<4x18xi64> loc(#loc)
    %12 = stablehlo.reshape %arg3 : (tensor<151936x1024xf32>) -> tensor<1x151936x1024xf32> loc(#loc19)
    %13 = stablehlo.custom_call @tt.mark_argument(%12) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_embed_tokens_weight"}} : (tensor<1x151936x1024xf32>) -> tensor<1x151936x1024xf32> loc(#loc20)
    %14 = stablehlo.reshape %13 : (tensor<1x151936x1024xf32>) -> tensor<151936x1024xf32> loc(#loc21)
    %15 = stablehlo.reshape %arg2 : (tensor<4x18xi64>) -> tensor<1x4x18xi64> loc(#loc22)
    %16 = stablehlo.custom_call @tt.mark_argument(%15) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x4x18xi64>) -> tensor<1x4x18xi64> loc(#loc23)
    %17 = stablehlo.reshape %16 : (tensor<1x4x18xi64>) -> tensor<4x18xi64> loc(#loc24)
    %18 = stablehlo.reshape %16 : (tensor<1x4x18xi64>) -> tensor<72xi64> loc(#loc25)
    %19 = stablehlo.convert %18 : (tensor<72xi64>) -> tensor<72xui32> loc(#loc26)
    %20 = "stablehlo.gather"(%14, %19) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1024>}> : (tensor<151936x1024xf32>, tensor<72xui32>) -> tensor<72x1024xf32> loc(#loc27)
    %21 = stablehlo.reshape %20 : (tensor<72x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc28)
    %22 = stablehlo.reshape %arg1 : (tensor<1024xf32>) -> tensor<1x1x1024xf32> loc(#loc29)
    %23 = stablehlo.custom_call @tt.mark_argument(%22) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}} : (tensor<1x1x1024xf32>) -> tensor<1x1x1024xf32> loc(#loc30)
    %24 = stablehlo.reshape %23 : (tensor<1x1x1024xf32>) -> tensor<1024xf32> loc(#loc31)
    %25 = stablehlo.composite "tenstorrent.rms_norm" %21, %24 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, decomposition = @tenstorrent.rms_norm.impl_3} : (tensor<4x18x1024xf32>, tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc32)
    %26 = stablehlo.reshape %25 : (tensor<4x18x1024xf32>) -> tensor<72x1024xf32> loc(#loc33)
    %27 = stablehlo.reshape %arg0 : (tensor<1024x1024xf32>) -> tensor<1x1024x1024xf32> loc(#loc34)
    %28 = stablehlo.custom_call @tt.mark_argument(%27) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}} : (tensor<1x1024x1024xf32>) -> tensor<1x1024x1024xf32> loc(#loc35)
    %29 = stablehlo.reshape %28 : (tensor<1x1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc36)
    %30 = stablehlo.transpose %29, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,1024]{0,1}"} : (tensor<1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc37)
    %31 = stablehlo.dot_general %26, %30, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x1024xf32>) -> tensor<72x1024xf32> loc(#loc38)
    %32 = stablehlo.reshape %31 : (tensor<72x1024xf32>) -> tensor<4x18x8x128xf32> loc(#loc39)
    %33 = stablehlo.transpose %32, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[4,8,18,128]{3,1,2,0}"} : (tensor<4x18x8x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc40)
    %34 = stablehlo.reshape %arg6 : (tensor<1024x1024xf32>) -> tensor<1x1024x1024xf32> loc(#loc41)
    %35 = stablehlo.custom_call @tt.mark_argument(%34) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}} : (tensor<1x1024x1024xf32>) -> tensor<1x1024x1024xf32> loc(#loc42)
    %36 = stablehlo.reshape %35 : (tensor<1x1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc43)
    %37 = stablehlo.transpose %36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,1024]{0,1}"} : (tensor<1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc44)
    %38 = stablehlo.dot_general %26, %37, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x1024xf32>) -> tensor<72x1024xf32> loc(#loc45)
    %39 = stablehlo.reshape %38 : (tensor<72x1024xf32>) -> tensor<4x18x8x128xf32> loc(#loc46)
    %40 = stablehlo.reshape %arg5 : (tensor<128xf32>) -> tensor<1x1x128xf32> loc(#loc47)
    %41 = stablehlo.custom_call @tt.mark_argument(%40) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_k_norm_weight"}} : (tensor<1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc48)
    %42 = stablehlo.reshape %41 : (tensor<1x1x128xf32>) -> tensor<128xf32> loc(#loc49)
    %43 = stablehlo.composite "tenstorrent.rms_norm" %39, %42 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<128> : tensor<1xi64>}, decomposition = @tenstorrent.rms_norm.impl_2} : (tensor<4x18x8x128xf32>, tensor<128xf32>) -> tensor<4x18x8x128xf32> loc(#loc50)
    %44 = stablehlo.transpose %43, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[4,8,18,128]{3,1,2,0}"} : (tensor<4x18x8x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc51)
    %45 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc52)
    %46 = stablehlo.custom_call @tt.mark_argument(%45) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "constant", ttir.name = "l__self___model_rotary_emb_inv_freq"}} : (tensor<1x1x64xf32>) -> tensor<1x1x64xf32> loc(#loc53)
    %47 = stablehlo.reshape %46 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc54)
    %48 = stablehlo.dot_general %47, %cst_3, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x18xf32>) -> tensor<1x64x18xf32> loc(#loc55)
    %49 = stablehlo.transpose %48, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,18,64]{1,2,0}"} : (tensor<1x64x18xf32>) -> tensor<1x18x64xf32> loc(#loc56)
    %50 = stablehlo.concatenate %49, %49, dim = 2 : (tensor<1x18x64xf32>, tensor<1x18x64xf32>) -> tensor<1x18x128xf32> loc(#loc57)
    %51 = stablehlo.cosine %50 : tensor<1x18x128xf32> loc(#loc58)
    %52 = stablehlo.reshape %51 : (tensor<1x18x128xf32>) -> tensor<18x128xf32> loc(#loc59)
    %53 = stablehlo.broadcast_in_dim %52, dims = [2, 3] : (tensor<18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc60)
    %54 = stablehlo.multiply %44, %53 : tensor<4x8x18x128xf32> loc(#loc61)
    %55 = stablehlo.slice %44 [0:4, 0:8, 0:18, 64:128] : (tensor<4x8x18x128xf32>) -> tensor<4x8x18x64xf32> loc(#loc62)
    %56 = stablehlo.negate %55 : tensor<4x8x18x64xf32> loc(#loc63)
    %57 = stablehlo.slice %44 [0:4, 0:8, 0:18, 0:64] : (tensor<4x8x18x128xf32>) -> tensor<4x8x18x64xf32> loc(#loc64)
    %58 = stablehlo.concatenate %56, %57, dim = 3 : (tensor<4x8x18x64xf32>, tensor<4x8x18x64xf32>) -> tensor<4x8x18x128xf32> loc(#loc65)
    %59 = stablehlo.sine %50 : tensor<1x18x128xf32> loc(#loc66)
    %60 = stablehlo.reshape %59 : (tensor<1x18x128xf32>) -> tensor<18x128xf32> loc(#loc67)
    %61 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc68)
    %62 = stablehlo.multiply %58, %61 : tensor<4x8x18x128xf32> loc(#loc69)
    %63 = stablehlo.add %54, %62 : tensor<4x8x18x128xf32> loc(#loc70)
    %64 = stablehlo.pad %17, %c_4, low = [0, 0], high = [0, 1], interior = [0, 0] : (tensor<4x18xi64>, tensor<i64>) -> tensor<4x19xi64> loc(#loc71)
    %65 = stablehlo.slice %64 [0:4, 1:19] : (tensor<4x19xi64>) -> tensor<4x18xi64> loc(#loc72)
    %66 = stablehlo.reshape %65 : (tensor<4x18xi64>) -> tensor<72xi64> loc(#loc73)
    %67 = stablehlo.compare  NE, %66, %10 : (tensor<72xi64>, tensor<72xi64>) -> tensor<72xi1> loc(#loc74)
    %68 = stablehlo.reshape %arg16 : (tensor<2048x1024xf32>) -> tensor<1x2048x1024xf32> loc(#loc75)
    %69 = stablehlo.custom_call @tt.mark_argument(%68) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}} : (tensor<1x2048x1024xf32>) -> tensor<1x2048x1024xf32> loc(#loc76)
    %70 = stablehlo.reshape %69 : (tensor<1x2048x1024xf32>) -> tensor<2048x1024xf32> loc(#loc77)
    %71 = stablehlo.transpose %70, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,2048]{0,1}"} : (tensor<2048x1024xf32>) -> tensor<1024x2048xf32> loc(#loc78)
    %72 = stablehlo.dot_general %26, %71, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x2048xf32>) -> tensor<72x2048xf32> loc(#loc79)
    %73 = stablehlo.reshape %72 : (tensor<72x2048xf32>) -> tensor<4x18x16x128xf32> loc(#loc80)
    %74 = stablehlo.reshape %arg15 : (tensor<128xf32>) -> tensor<1x1x128xf32> loc(#loc81)
    %75 = stablehlo.custom_call @tt.mark_argument(%74) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_q_norm_weight"}} : (tensor<1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc82)
    %76 = stablehlo.reshape %75 : (tensor<1x1x128xf32>) -> tensor<128xf32> loc(#loc83)
    %77 = stablehlo.composite "tenstorrent.rms_norm" %73, %76 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<128> : tensor<1xi64>}, decomposition = @tenstorrent.rms_norm.impl_1} : (tensor<4x18x16x128xf32>, tensor<128xf32>) -> tensor<4x18x16x128xf32> loc(#loc84)
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[4,16,18,128]{3,1,2,0}"} : (tensor<4x18x16x128xf32>) -> tensor<4x16x18x128xf32> loc(#loc85)
    %79 = stablehlo.broadcast_in_dim %52, dims = [2, 3] : (tensor<18x128xf32>) -> tensor<4x16x18x128xf32> loc(#loc86)
    %80 = stablehlo.multiply %78, %79 : tensor<4x16x18x128xf32> loc(#loc87)
    %81 = stablehlo.slice %78 [0:4, 0:16, 0:18, 64:128] : (tensor<4x16x18x128xf32>) -> tensor<4x16x18x64xf32> loc(#loc88)
    %82 = stablehlo.negate %81 : tensor<4x16x18x64xf32> loc(#loc89)
    %83 = stablehlo.slice %78 [0:4, 0:16, 0:18, 0:64] : (tensor<4x16x18x128xf32>) -> tensor<4x16x18x64xf32> loc(#loc90)
    %84 = stablehlo.concatenate %82, %83, dim = 3 : (tensor<4x16x18x64xf32>, tensor<4x16x18x64xf32>) -> tensor<4x16x18x128xf32> loc(#loc91)
    %85 = stablehlo.broadcast_in_dim %60, dims = [2, 3] : (tensor<18x128xf32>) -> tensor<4x16x18x128xf32> loc(#loc92)
    %86 = stablehlo.multiply %84, %85 : tensor<4x16x18x128xf32> loc(#loc93)
    %87 = stablehlo.add %80, %86 : tensor<4x16x18x128xf32> loc(#loc94)
    %88 = stablehlo.multiply %87, %9 : tensor<4x16x18x128xf32> loc(#loc95)
    %89 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<4x8x18x128xf32>) -> tensor<4x8x2x18x128xf32> loc(#loc96)
    %90 = stablehlo.reshape %89 : (tensor<4x8x2x18x128xf32>) -> tensor<4x16x18x128xf32> loc(#loc97)
    %91 = stablehlo.transpose %90, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "f32[4,16,128,18]{2,3,1,0}"} : (tensor<4x16x18x128xf32>) -> tensor<4x16x128x18xf32> loc(#loc98)
    %92 = stablehlo.multiply %91, %8 : tensor<4x16x128x18xf32> loc(#loc99)
    %93 = stablehlo.dot_general %88, %92, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<4x16x18x128xf32>, tensor<4x16x128x18xf32>) -> tensor<4x16x18x18xf32> loc(#loc100)
    %94 = stablehlo.broadcast_in_dim %arg14, dims = [] : (tensor<i1>) -> tensor<18x18xi1> loc(#loc101)
    %95 = stablehlo.broadcast_in_dim %c_0, dims = [1] : (tensor<18xi64>) -> tensor<18x18xi64> loc(#loc102)
    %96 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<18xi64>) -> tensor<18x18xi64> loc(#loc103)
    %97 = stablehlo.compare  LE, %95, %96 : (tensor<18x18xi64>, tensor<18x18xi64>) -> tensor<18x18xi1> loc(#loc104)
    %98 = stablehlo.and %94, %97 : tensor<18x18xi1> loc(#loc105)
    %99 = stablehlo.broadcast_in_dim %98, dims = [1, 2] : (tensor<18x18xi1>) -> tensor<4x18x18xi1> loc(#loc106)
    %100 = stablehlo.reshape %arg13 : (tensor<4x18xi64>) -> tensor<1x4x18xi64> loc(#loc107)
    %101 = stablehlo.custom_call @tt.mark_argument(%100) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<1x4x18xi64>) -> tensor<1x4x18xi64> loc(#loc108)
    %102 = stablehlo.reshape %101 : (tensor<1x4x18xi64>) -> tensor<4x18xi64> loc(#loc109)
    %103 = stablehlo.compare  NE, %102, %11 : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi1> loc(#loc110)
    %104 = stablehlo.broadcast_in_dim %c_1, dims = [0] : (tensor<4xi64>) -> tensor<4x18xi64> loc(#loc111)
    %105 = stablehlo.compare  LT, %104, %11 : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi1> loc(#loc112)
    %106 = stablehlo.add %104, %7 : tensor<4x18xi64> loc(#loc113)
    %107 = stablehlo.select %105, %106, %104 : tensor<4x18xi1>, tensor<4x18xi64> loc(#loc114)
    %108 = stablehlo.reshape %107 : (tensor<4x18xi64>) -> tensor<4x18x1xi64> loc(#loc115)
    %109 = stablehlo.broadcast_in_dim %c_0, dims = [1] : (tensor<18xi64>) -> tensor<4x18xi64> loc(#loc116)
    %110 = stablehlo.compare  LT, %109, %11 : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi1> loc(#loc117)
    %111 = stablehlo.add %109, %6 : tensor<4x18xi64> loc(#loc118)
    %112 = stablehlo.select %110, %111, %109 : tensor<4x18xi1>, tensor<4x18xi64> loc(#loc119)
    %113 = stablehlo.reshape %112 : (tensor<4x18xi64>) -> tensor<4x18x1xi64> loc(#loc120)
    %114 = stablehlo.concatenate %108, %113, dim = 2 : (tensor<4x18x1xi64>, tensor<4x18x1xi64>) -> tensor<4x18x2xi64> loc(#loc121)
    %115 = "stablehlo.gather"(%103, %114) <{dimension_numbers = #stablehlo.gather<collapsed_slice_dims = [0, 1], start_index_map = [0, 1], index_vector_dim = 2>, slice_sizes = array<i64: 1, 1>}> : (tensor<4x18xi1>, tensor<4x18x2xi64>) -> tensor<4x18xi1> loc(#loc122)
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2] : (tensor<4x18xi1>) -> tensor<4x18x18xi1> loc(#loc123)
    %117 = stablehlo.and %99, %116 : tensor<4x18x18xi1> loc(#loc124)
    %118 = stablehlo.reshape %117 : (tensor<4x18x18xi1>) -> tensor<4x1x18x18xi1> loc(#loc125)
    %119 = stablehlo.select %118, %5, %4 : tensor<4x1x18x18xi1>, tensor<4x1x18x18xf32> loc(#loc126)
    %120 = stablehlo.reshape %119 : (tensor<4x1x18x18xf32>) -> tensor<4x18x18xf32> loc(#loc127)
    %121 = stablehlo.broadcast_in_dim %120, dims = [0, 2, 3] : (tensor<4x18x18xf32>) -> tensor<4x16x18x18xf32> loc(#loc128)
    %122 = stablehlo.add %93, %121 : tensor<4x16x18x18xf32> loc(#loc129)
    %123 = stablehlo.convert %122 : (tensor<4x16x18x18xf32>) -> tensor<4x16x18x18xf64> loc(#loc130)
    %124 = stablehlo.compare  EQ, %123, %3 : (tensor<4x16x18x18xf64>, tensor<4x16x18x18xf64>) -> tensor<4x16x18x18xi1> loc(#loc131)
    %125 = stablehlo.not %124 : tensor<4x16x18x18xi1> loc(#loc132)
    %126 = stablehlo.reduce(%125 init: %c_2) across dimensions = [3] : (tensor<4x16x18x18xi1>, tensor<i1>) -> tensor<4x16x18xi1>
     reducer(%arg18: tensor<i1> loc("reduce.440"), %arg19: tensor<i1> loc("reduce.440"))  {
      %214 = stablehlo.or %arg18, %arg19 : tensor<i1> loc(#loc134)
      %215 = stablehlo.select %214, %c, %c_2 : tensor<i1>, tensor<i1> loc(#loc135)
      stablehlo.return %215 : tensor<i1> loc(#loc)
    } loc(#loc133)
    %127 = stablehlo.reshape %126 : (tensor<4x16x18xi1>) -> tensor<4x16x18x1xi1> loc(#loc136)
    %128 = stablehlo.not %127 : tensor<4x16x18x1xi1> loc(#loc137)
    %129 = stablehlo.reshape %128 : (tensor<4x16x18x1xi1>) -> tensor<4x16x18xi1> loc(#loc138)
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 1, 2] : (tensor<4x16x18xi1>) -> tensor<4x16x18x18xi1> loc(#loc139)
    %131 = stablehlo.reduce(%122 init: %cst_8) applies stablehlo.maximum across dimensions = [3] : (tensor<4x16x18x18xf32>, tensor<f32>) -> tensor<4x16x18xf32> loc(#loc140)
    %132 = stablehlo.broadcast_in_dim %131, dims = [0, 1, 2] : (tensor<4x16x18xf32>) -> tensor<4x16x18x18xf32> loc(#loc141)
    %133 = stablehlo.subtract %122, %132 : tensor<4x16x18x18xf32> loc(#loc142)
    %134 = stablehlo.exponential %133 : tensor<4x16x18x18xf32> loc(#loc143)
    %135 = stablehlo.reduce(%134 init: %cst_11) applies stablehlo.add across dimensions = [3] : (tensor<4x16x18x18xf32>, tensor<f32>) -> tensor<4x16x18xf32> loc(#loc144)
    %136 = stablehlo.broadcast_in_dim %135, dims = [0, 1, 2] : (tensor<4x16x18xf32>) -> tensor<4x16x18x18xf32> loc(#loc145)
    %137 = stablehlo.divide %134, %136 : tensor<4x16x18x18xf32> loc(#loc146)
    %138 = stablehlo.select %130, %2, %137 : tensor<4x16x18x18xi1>, tensor<4x16x18x18xf32> loc(#loc147)
    %139 = stablehlo.broadcast_in_dim %33, dims = [0, 1, 3, 4] : (tensor<4x8x18x128xf32>) -> tensor<4x8x2x18x128xf32> loc(#loc148)
    %140 = stablehlo.reshape %139 : (tensor<4x8x2x18x128xf32>) -> tensor<4x16x18x128xf32> loc(#loc149)
    %141 = stablehlo.dot_general %138, %140, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<4x16x18x18xf32>, tensor<4x16x18x128xf32>) -> tensor<4x16x18x128xf32> loc(#loc150)
    %142 = stablehlo.transpose %141, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[4,18,16,128]{3,1,2,0}"} : (tensor<4x16x18x128xf32>) -> tensor<4x18x16x128xf32> loc(#loc151)
    %143 = stablehlo.reshape %142 : (tensor<4x18x16x128xf32>) -> tensor<72x2048xf32> loc(#loc152)
    %144 = stablehlo.reshape %arg12 : (tensor<1024x2048xf32>) -> tensor<1x1024x2048xf32> loc(#loc153)
    %145 = stablehlo.custom_call @tt.mark_argument(%144) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}} : (tensor<1x1024x2048xf32>) -> tensor<1x1024x2048xf32> loc(#loc154)
    %146 = stablehlo.reshape %145 : (tensor<1x1024x2048xf32>) -> tensor<1024x2048xf32> loc(#loc155)
    %147 = stablehlo.transpose %146, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[2048,1024]{0,1}"} : (tensor<1024x2048xf32>) -> tensor<2048x1024xf32> loc(#loc156)
    %148 = stablehlo.dot_general %143, %147, contracting_dims = [1] x [0] : (tensor<72x2048xf32>, tensor<2048x1024xf32>) -> tensor<72x1024xf32> loc(#loc157)
    %149 = stablehlo.reshape %148 : (tensor<72x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc158)
    %150 = stablehlo.add %21, %149 : tensor<4x18x1024xf32> loc(#loc159)
    %151 = stablehlo.reshape %arg11 : (tensor<1024xf32>) -> tensor<1x1x1024xf32> loc(#loc160)
    %152 = stablehlo.custom_call @tt.mark_argument(%151) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}} : (tensor<1x1x1024xf32>) -> tensor<1x1x1024xf32> loc(#loc161)
    %153 = stablehlo.reshape %152 : (tensor<1x1x1024xf32>) -> tensor<1024xf32> loc(#loc162)
    %154 = stablehlo.composite "tenstorrent.rms_norm" %150, %153 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, decomposition = @tenstorrent.rms_norm.impl_0} : (tensor<4x18x1024xf32>, tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc163)
    %155 = stablehlo.reshape %154 : (tensor<4x18x1024xf32>) -> tensor<72x1024xf32> loc(#loc164)
    %156 = stablehlo.reshape %arg17 : (tensor<3072x1024xf32>) -> tensor<1x3072x1024xf32> loc(#loc165)
    %157 = stablehlo.custom_call @tt.mark_argument(%156) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}} : (tensor<1x3072x1024xf32>) -> tensor<1x3072x1024xf32> loc(#loc166)
    %158 = stablehlo.reshape %157 : (tensor<1x3072x1024xf32>) -> tensor<3072x1024xf32> loc(#loc167)
    %159 = stablehlo.transpose %158, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,3072]{0,1}"} : (tensor<3072x1024xf32>) -> tensor<1024x3072xf32> loc(#loc168)
    %160 = stablehlo.dot_general %155, %159, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x3072xf32>) -> tensor<72x3072xf32> loc(#loc169)
    %161 = stablehlo.reshape %160 : (tensor<72x3072xf32>) -> tensor<4x18x3072xf32> loc(#loc170)
    %162 = stablehlo.logistic %161 : tensor<4x18x3072xf32> loc(#loc171)
    %163 = stablehlo.multiply %161, %162 : tensor<4x18x3072xf32> loc(#loc172)
    %164 = stablehlo.reshape %arg10 : (tensor<3072x1024xf32>) -> tensor<1x3072x1024xf32> loc(#loc173)
    %165 = stablehlo.custom_call @tt.mark_argument(%164) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}} : (tensor<1x3072x1024xf32>) -> tensor<1x3072x1024xf32> loc(#loc174)
    %166 = stablehlo.reshape %165 : (tensor<1x3072x1024xf32>) -> tensor<3072x1024xf32> loc(#loc175)
    %167 = stablehlo.transpose %166, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,3072]{0,1}"} : (tensor<3072x1024xf32>) -> tensor<1024x3072xf32> loc(#loc176)
    %168 = stablehlo.dot_general %155, %167, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x3072xf32>) -> tensor<72x3072xf32> loc(#loc177)
    %169 = stablehlo.reshape %168 : (tensor<72x3072xf32>) -> tensor<4x18x3072xf32> loc(#loc178)
    %170 = stablehlo.multiply %163, %169 : tensor<4x18x3072xf32> loc(#loc179)
    %171 = stablehlo.reshape %170 : (tensor<4x18x3072xf32>) -> tensor<72x3072xf32> loc(#loc180)
    %172 = stablehlo.reshape %arg9 : (tensor<1024x3072xf32>) -> tensor<1x1024x3072xf32> loc(#loc181)
    %173 = stablehlo.custom_call @tt.mark_argument(%172) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}} : (tensor<1x1024x3072xf32>) -> tensor<1x1024x3072xf32> loc(#loc182)
    %174 = stablehlo.reshape %173 : (tensor<1x1024x3072xf32>) -> tensor<1024x3072xf32> loc(#loc183)
    %175 = stablehlo.transpose %174, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[3072,1024]{0,1}"} : (tensor<1024x3072xf32>) -> tensor<3072x1024xf32> loc(#loc184)
    %176 = stablehlo.dot_general %171, %175, contracting_dims = [1] x [0] : (tensor<72x3072xf32>, tensor<3072x1024xf32>) -> tensor<72x1024xf32> loc(#loc185)
    %177 = stablehlo.reshape %176 : (tensor<72x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc186)
    %178 = stablehlo.add %150, %177 : tensor<4x18x1024xf32> loc(#loc187)
    %179 = stablehlo.reshape %arg8 : (tensor<1024xf32>) -> tensor<1x1x1024xf32> loc(#loc188)
    %180 = stablehlo.custom_call @tt.mark_argument(%179) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_norm_weight"}} : (tensor<1x1x1024xf32>) -> tensor<1x1x1024xf32> loc(#loc189)
    %181 = stablehlo.reshape %180 : (tensor<1x1x1024xf32>) -> tensor<1024xf32> loc(#loc190)
    %182 = stablehlo.composite "tenstorrent.rms_norm" %178, %181 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, decomposition = @tenstorrent.rms_norm.impl} : (tensor<4x18x1024xf32>, tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc191)
    %183 = stablehlo.reshape %182 : (tensor<4x18x1024xf32>) -> tensor<72x1024xf32> loc(#loc192)
    %184 = stablehlo.reshape %arg7 : (tensor<151936x1024xf32>) -> tensor<1x151936x1024xf32> loc(#loc193)
    %185 = stablehlo.custom_call @tt.mark_argument(%184) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___lm_head_weight"}} : (tensor<1x151936x1024xf32>) -> tensor<1x151936x1024xf32> loc(#loc194)
    %186 = stablehlo.reshape %185 : (tensor<1x151936x1024xf32>) -> tensor<151936x1024xf32> loc(#loc195)
    %187 = stablehlo.transpose %186, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,151936]{0,1}"} : (tensor<151936x1024xf32>) -> tensor<1024x151936xf32> loc(#loc196)
    %188 = stablehlo.dot_general %183, %187, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x151936xf32>) -> tensor<72x151936xf32> loc(#loc197)
    %189 = stablehlo.reshape %188 : (tensor<72x151936xf32>) -> tensor<4x18x151936xf32> loc(#loc198)
    %190 = stablehlo.reduce(%188 init: %cst) applies stablehlo.maximum across dimensions = [1] : (tensor<72x151936xf32>, tensor<f32>) -> tensor<72xf32> loc(#loc199)
    %191 = stablehlo.broadcast_in_dim %190, dims = [0] : (tensor<72xf32>) -> tensor<72x151936xf32> loc(#loc200)
    %192 = stablehlo.subtract %188, %191 : tensor<72x151936xf32> loc(#loc201)
    %193 = stablehlo.exponential %192 : tensor<72x151936xf32> loc(#loc202)
    %194 = stablehlo.reduce(%193 init: %cst_11) applies stablehlo.add across dimensions = [1] : (tensor<72x151936xf32>, tensor<f32>) -> tensor<72xf32> loc(#loc203)
    %195 = stablehlo.reshape %194 : (tensor<72xf32>) -> tensor<72x1xf32> loc(#loc204)
    %196 = stablehlo.log %195 : tensor<72x1xf32> loc(#loc205)
    %197 = stablehlo.reshape %196 : (tensor<72x1xf32>) -> tensor<72xf32> loc(#loc206)
    %198 = stablehlo.broadcast_in_dim %197, dims = [0] : (tensor<72xf32>) -> tensor<72x151936xf32> loc(#loc207)
    %199 = stablehlo.subtract %192, %198 : tensor<72x151936xf32> loc(#loc208)
    %200 = stablehlo.iota dim = 0 : tensor<72xui32> loc(#loc209)
    %201 = stablehlo.reshape %200 : (tensor<72xui32>) -> tensor<72x1x1xui32> loc(#loc209)
    %202 = stablehlo.select %67, %66, %1 : tensor<72xi1>, tensor<72xi64> loc(#loc210)
    %203 = stablehlo.reshape %202 : (tensor<72xi64>) -> tensor<72x1xi64> loc(#loc211)
    %204 = stablehlo.convert %203 : (tensor<72x1xi64>) -> tensor<72x1xui32> loc(#loc212)
    %205 = stablehlo.reshape %204 : (tensor<72x1xui32>) -> tensor<72x1x1xui32> loc(#loc213)
    %206 = stablehlo.concatenate %201, %205, dim = 2 : (tensor<72x1x1xui32>, tensor<72x1x1xui32>) -> tensor<72x1x2xui32> loc(#loc214)
    %207 = "stablehlo.gather"(%199, %206) <{dimension_numbers = #stablehlo.gather<collapsed_slice_dims = [0, 1], start_index_map = [0, 1], index_vector_dim = 2>, slice_sizes = array<i64: 1, 1>}> : (tensor<72x151936xf32>, tensor<72x1x2xui32>) -> tensor<72x1xf32> loc(#loc215)
    %208 = stablehlo.reshape %207 : (tensor<72x1xf32>) -> tensor<72xf32> loc(#loc216)
    %209 = stablehlo.negate %208 : tensor<72xf32> loc(#loc217)
    %210 = stablehlo.select %67, %209, %0 : tensor<72xi1>, tensor<72xf32> loc(#loc218)
    %211 = stablehlo.convert %67 : (tensor<72xi1>) -> tensor<72xi64> loc(#loc219)
    %212 = stablehlo.convert %211 : (tensor<72xi64>) -> tensor<72xf32> loc(#loc220)
    %213 = stablehlo.divide %210, %212 : tensor<72xf32> loc(#loc221)
    return %33, %63, %213, %189 : tensor<4x8x18x128xf32>, tensor<4x8x18x128xf32>, tensor<72xf32>, tensor<4x18x151936xf32> loc(#loc)
  } loc(#loc)
  func.func private @tenstorrent.rms_norm.impl(%arg0: tensor<4x18x1024xf32> loc("custom-call.512"), %arg1: tensor<1024xf32> loc("custom-call.199")) -> tensor<4x18x1024xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<9.765625E-4> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x1024xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x1024xf32> loc(#loc224)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x18x1024xf32>, tensor<f32>) -> tensor<4x18xf32> loc(#loc225)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18xf32> loc(#loc226)
    %6 = stablehlo.reshape %5 : (tensor<4x18xf32>) -> tensor<4x18x1xf32> loc(#loc227)
    %7 = stablehlo.add %6, %0 : tensor<4x18x1xf32> loc(#loc228)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x1xf32> loc(#loc229)
    %9 = stablehlo.reshape %8 : (tensor<4x18x1xf32>) -> tensor<4x18xf32> loc(#loc230)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1] : (tensor<4x18xf32>) -> tensor<4x18x1024xf32> loc(#loc231)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x1024xf32> loc(#loc232)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc233)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x1024xf32> loc(#loc234)
    return %13 : tensor<4x18x1024xf32> loc(#loc)
  } loc(#loc)
  func.func private @tenstorrent.rms_norm.impl_0(%arg0: tensor<4x18x1024xf32> loc("custom-call.461"), %arg1: tensor<1024xf32> loc("custom-call.218")) -> tensor<4x18x1024xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<9.765625E-4> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x1024xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x1024xf32> loc(#loc237)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x18x1024xf32>, tensor<f32>) -> tensor<4x18xf32> loc(#loc238)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18xf32> loc(#loc239)
    %6 = stablehlo.reshape %5 : (tensor<4x18xf32>) -> tensor<4x18x1xf32> loc(#loc240)
    %7 = stablehlo.add %6, %0 : tensor<4x18x1xf32> loc(#loc241)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x1xf32> loc(#loc242)
    %9 = stablehlo.reshape %8 : (tensor<4x18x1xf32>) -> tensor<4x18xf32> loc(#loc243)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1] : (tensor<4x18xf32>) -> tensor<4x18x1024xf32> loc(#loc244)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x1024xf32> loc(#loc245)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc246)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x1024xf32> loc(#loc247)
    return %13 : tensor<4x18x1024xf32> loc(#loc)
  } loc(#loc)
  func.func private @tenstorrent.rms_norm.impl_1(%arg0: tensor<4x18x16x128xf32> loc("custom-call.345"), %arg1: tensor<128xf32> loc("custom-call.332")) -> tensor<4x18x16x128xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<7.812500e-03> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x16x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18x16xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x16x128xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x16x128xf32> loc(#loc250)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x18x16x128xf32>, tensor<f32>) -> tensor<4x18x16xf32> loc(#loc251)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18x16xf32> loc(#loc252)
    %6 = stablehlo.reshape %5 : (tensor<4x18x16xf32>) -> tensor<4x18x16x1xf32> loc(#loc253)
    %7 = stablehlo.add %6, %0 : tensor<4x18x16x1xf32> loc(#loc254)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x16x1xf32> loc(#loc255)
    %9 = stablehlo.reshape %8 : (tensor<4x18x16x1xf32>) -> tensor<4x18x16xf32> loc(#loc256)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1, 2] : (tensor<4x18x16xf32>) -> tensor<4x18x16x128xf32> loc(#loc257)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x16x128xf32> loc(#loc258)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [3] : (tensor<128xf32>) -> tensor<4x18x16x128xf32> loc(#loc259)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x16x128xf32> loc(#loc260)
    return %13 : tensor<4x18x16x128xf32> loc(#loc)
  } loc(#loc)
  func.func private @tenstorrent.rms_norm.impl_2(%arg0: tensor<4x18x8x128xf32> loc("custom-call.102"), %arg1: tensor<128xf32> loc("custom-call.89")) -> tensor<4x18x8x128xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<7.812500e-03> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x8x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18x8xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x8x128xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x8x128xf32> loc(#loc263)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x18x8x128xf32>, tensor<f32>) -> tensor<4x18x8xf32> loc(#loc264)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18x8xf32> loc(#loc265)
    %6 = stablehlo.reshape %5 : (tensor<4x18x8xf32>) -> tensor<4x18x8x1xf32> loc(#loc266)
    %7 = stablehlo.add %6, %0 : tensor<4x18x8x1xf32> loc(#loc267)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x8x1xf32> loc(#loc268)
    %9 = stablehlo.reshape %8 : (tensor<4x18x8x1xf32>) -> tensor<4x18x8xf32> loc(#loc269)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1, 2] : (tensor<4x18x8xf32>) -> tensor<4x18x8x128xf32> loc(#loc270)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x8x128xf32> loc(#loc271)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [3] : (tensor<128xf32>) -> tensor<4x18x8x128xf32> loc(#loc272)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x8x128xf32> loc(#loc273)
    return %13 : tensor<4x18x8x128xf32> loc(#loc)
  } loc(#loc)
  func.func private @tenstorrent.rms_norm.impl_3(%arg0: tensor<4x18x1024xf32> loc("custom-call.26"), %arg1: tensor<1024xf32> loc("custom-call.10")) -> tensor<4x18x1024xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<9.765625E-4> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x1024xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x1024xf32> loc(#loc276)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x18x1024xf32>, tensor<f32>) -> tensor<4x18xf32> loc(#loc277)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18xf32> loc(#loc278)
    %6 = stablehlo.reshape %5 : (tensor<4x18xf32>) -> tensor<4x18x1xf32> loc(#loc279)
    %7 = stablehlo.add %6, %0 : tensor<4x18x1xf32> loc(#loc280)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x1xf32> loc(#loc281)
    %9 = stablehlo.reshape %8 : (tensor<4x18x1xf32>) -> tensor<4x18xf32> loc(#loc282)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1] : (tensor<4x18xf32>) -> tensor<4x18x1024xf32> loc(#loc283)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x1024xf32> loc(#loc284)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc285)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x1024xf32> loc(#loc286)
    return %13 : tensor<4x18x1024xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc19 = loc("reshape.20")
#loc20 = loc("custom-call.21")
#loc21 = loc("reshape.22")
#loc22 = loc("reshape.15")
#loc23 = loc("custom-call.16")
#loc24 = loc("reshape.17")
#loc25 = loc("reshape.18")
#loc26 = loc("convert.23")
#loc27 = loc("gather.24")
#loc28 = loc("reshape.25")
#loc29 = loc("reshape.7")
#loc30 = loc("custom-call.8")
#loc31 = loc("reshape.9")
#loc32 = loc("custom-call.56")
#loc33 = loc("reshape.57")
#loc34 = loc("reshape.2")
#loc35 = loc("custom-call.3")
#loc36 = loc("reshape.4")
#loc37 = loc("transpose.5")
#loc38 = loc("dot.58")
#loc39 = loc("reshape.60")
#loc40 = loc("transpose.61")
#loc41 = loc("reshape.94")
#loc42 = loc("custom-call.95")
#loc43 = loc("reshape.96")
#loc44 = loc("transpose.97")
#loc45 = loc("dot.99")
#loc46 = loc("reshape.101")
#loc47 = loc("reshape.86")
#loc48 = loc("custom-call.87")
#loc49 = loc("reshape.88")
#loc50 = loc("custom-call.132")
#loc51 = loc("transpose.133")
#loc52 = loc("reshape.71")
#loc53 = loc("custom-call.72")
#loc54 = loc("reshape.75")
#loc55 = loc("dot.78")
#loc56 = loc("transpose.79")
#loc57 = loc("concatenate.80")
#loc58 = loc("cosine.142")
#loc59 = loc("reshape.146")
#loc60 = loc("broadcast.147")
#loc61 = loc("multiply.148")
#loc62 = loc("slice.135")
#loc63 = loc("negate.136")
#loc64 = loc("slice.134")
#loc65 = loc("concatenate.137")
#loc66 = loc("sine.81")
#loc67 = loc("reshape.138")
#loc68 = loc("broadcast.139")
#loc69 = loc("multiply.140")
#loc70 = loc("add.151")
#loc71 = loc("pad.155")
#loc72 = loc("slice.156")
#loc73 = loc("reshape.157")
#loc74 = loc("compare.585")
#loc75 = loc("reshape.337")
#loc76 = loc("custom-call.338")
#loc77 = loc("reshape.339")
#loc78 = loc("transpose.340")
#loc79 = loc("dot.342")
#loc80 = loc("reshape.344")
#loc81 = loc("reshape.329")
#loc82 = loc("custom-call.330")
#loc83 = loc("reshape.331")
#loc84 = loc("custom-call.375")
#loc85 = loc("transpose.376")
#loc86 = loc("broadcast.385")
#loc87 = loc("multiply.386")
#loc88 = loc("slice.378")
#loc89 = loc("negate.379")
#loc90 = loc("slice.377")
#loc91 = loc("concatenate.380")
#loc92 = loc("broadcast.382")
#loc93 = loc("multiply.383")
#loc94 = loc("add.389")
#loc95 = loc("multiply.391")
#loc96 = loc("broadcast.321")
#loc97 = loc("reshape.322")
#loc98 = loc("transpose.323")
#loc99 = loc("multiply.325")
#loc100 = loc("dot.392")
#loc101 = loc("broadcast.305")
#loc102 = loc("broadcast.292")
#loc103 = loc("broadcast.294")
#loc104 = loc("compare.295")
#loc105 = loc("and.306")
#loc106 = loc("broadcast.309")
#loc107 = loc("reshape.285")
#loc108 = loc("custom-call.286")
#loc109 = loc("reshape.287")
#loc110 = loc("convert.288")
#loc111 = loc("broadcast.270")
#loc112 = loc("compare.279")
#loc113 = loc("add.276")
#loc114 = loc("select.280")
#loc115 = loc("reshape.281")
#loc116 = loc("broadcast.255")
#loc117 = loc("compare.264")
#loc118 = loc("add.261")
#loc119 = loc("select.265")
#loc120 = loc("reshape.282")
#loc121 = loc("concatenate.283")
#loc122 = loc("gather.289")
#loc123 = loc("broadcast.311")
#loc124 = loc("and.312")
#loc125 = loc("reshape.313")
#loc126 = loc("select.316")
#loc127 = loc("reshape.396")
#loc128 = loc("broadcast.397")
#loc129 = loc("add.398")
#loc130 = loc("convert.424")
#loc131 = loc("compare.426")
#loc132 = loc("not.428")
#loc134 = loc("or.438")
#loc135 = loc("select.439")
#loc136 = loc("reshape.444")
#loc137 = loc("not.446")
#loc138 = loc("reshape.448")
#loc139 = loc("broadcast.449")
#loc140 = loc("reduce.404")
#loc141 = loc("broadcast.405")
#loc142 = loc("subtract.406")
#loc143 = loc("exponential.407")
#loc144 = loc("reduce.413")
#loc145 = loc("broadcast.414")
#loc146 = loc("divide.415")
#loc147 = loc("select.450")
#loc148 = loc("broadcast.231")
#loc149 = loc("reshape.232")
#loc150 = loc("dot.451")
#loc151 = loc("transpose.453")
#loc152 = loc("reshape.455")
#loc153 = loc("reshape.224")
#loc154 = loc("custom-call.225")
#loc155 = loc("reshape.226")
#loc156 = loc("transpose.227")
#loc157 = loc("dot.456")
#loc158 = loc("reshape.457")
#loc159 = loc("add.460")
#loc160 = loc("reshape.215")
#loc161 = loc("custom-call.216")
#loc162 = loc("reshape.217")
#loc163 = loc("custom-call.491")
#loc164 = loc("reshape.500")
#loc165 = loc("reshape.496")
#loc166 = loc("custom-call.497")
#loc167 = loc("reshape.498")
#loc168 = loc("transpose.499")
#loc169 = loc("dot.501")
#loc170 = loc("reshape.502")
#loc171 = loc("logistic.503")
#loc172 = loc("multiply.504")
#loc173 = loc("reshape.210")
#loc174 = loc("custom-call.211")
#loc175 = loc("reshape.212")
#loc176 = loc("transpose.213")
#loc177 = loc("dot.493")
#loc178 = loc("reshape.494")
#loc179 = loc("multiply.505")
#loc180 = loc("reshape.506")
#loc181 = loc("reshape.205")
#loc182 = loc("custom-call.206")
#loc183 = loc("reshape.207")
#loc184 = loc("transpose.208")
#loc185 = loc("dot.507")
#loc186 = loc("reshape.508")
#loc187 = loc("add.511")
#loc188 = loc("reshape.196")
#loc189 = loc("custom-call.197")
#loc190 = loc("reshape.198")
#loc191 = loc("custom-call.542")
#loc192 = loc("reshape.543")
#loc193 = loc("reshape.191")
#loc194 = loc("custom-call.192")
#loc195 = loc("reshape.193")
#loc196 = loc("transpose.194")
#loc197 = loc("dot.544")
#loc198 = loc("reshape.545")
#loc199 = loc("reduce.553")
#loc200 = loc("broadcast.558")
#loc201 = loc("subtract.559")
#loc202 = loc("exponential.560")
#loc203 = loc("reduce.567")
#loc204 = loc("reshape.568")
#loc205 = loc("log.569")
#loc206 = loc("reshape.572")
#loc207 = loc("broadcast.573")
#loc208 = loc("subtract.574")
#loc209 = loc("iota.576")
#loc210 = loc("select.186")
#loc211 = loc("reshape.187")
#loc212 = loc("convert.575")
#loc213 = loc("reshape.577")
#loc214 = loc("concatenate.578")
#loc215 = loc("gather.579")
#loc216 = loc("reshape.580")
#loc217 = loc("negate.581")
#loc218 = loc("select.587")
#loc219 = loc("convert.160")
#loc220 = loc("convert.168")
#loc221 = loc("divide.595")
#loc224 = loc("power.514")
#loc225 = loc("reduce.521")
#loc226 = loc("multiply.530")
#loc227 = loc("reshape.531")
#loc228 = loc("add.535")
#loc229 = loc("rsqrt.536")
#loc230 = loc("reshape.537")
#loc231 = loc("broadcast.538")
#loc232 = loc("multiply.539")
#loc233 = loc("broadcast.540")
#loc234 = loc("multiply.541")
#loc237 = loc("power.463")
#loc238 = loc("reduce.470")
#loc239 = loc("multiply.479")
#loc240 = loc("reshape.480")
#loc241 = loc("add.484")
#loc242 = loc("rsqrt.485")
#loc243 = loc("reshape.486")
#loc244 = loc("broadcast.487")
#loc245 = loc("multiply.488")
#loc246 = loc("broadcast.489")
#loc247 = loc("multiply.490")
#loc250 = loc("power.347")
#loc251 = loc("reduce.354")
#loc252 = loc("multiply.363")
#loc253 = loc("reshape.364")
#loc254 = loc("add.368")
#loc255 = loc("rsqrt.369")
#loc256 = loc("reshape.370")
#loc257 = loc("broadcast.371")
#loc258 = loc("multiply.372")
#loc259 = loc("broadcast.373")
#loc260 = loc("multiply.374")
#loc263 = loc("power.104")
#loc264 = loc("reduce.111")
#loc265 = loc("multiply.120")
#loc266 = loc("reshape.121")
#loc267 = loc("add.125")
#loc268 = loc("rsqrt.126")
#loc269 = loc("reshape.127")
#loc270 = loc("broadcast.128")
#loc271 = loc("multiply.129")
#loc272 = loc("broadcast.130")
#loc273 = loc("multiply.131")
#loc276 = loc("power.28")
#loc277 = loc("reduce.35")
#loc278 = loc("multiply.44")
#loc279 = loc("reshape.45")
#loc280 = loc("add.49")
#loc281 = loc("rsqrt.50")
#loc282 = loc("reshape.51")
#loc283 = loc("broadcast.52")
#loc284 = loc("multiply.53")
#loc285 = loc("broadcast.54")
#loc286 = loc("multiply.55")
------------------ END OF MLIR MODULE ------------------
2026-01-28 22:12:58.337 (   5.504s) [        66B35000]      module_builder.cc:1111     1| MLIR Module shlo_frontend:
#loc1 = loc("p0.1")
#loc2 = loc("p1.6")
#loc3 = loc("p2.14")
#loc4 = loc("p3.19")
#loc5 = loc("p4.70")
#loc6 = loc("p5.85")
#loc7 = loc("p6.93")
#loc8 = loc("p7.190")
#loc9 = loc("p8.195")
#loc10 = loc("p9.204")
#loc11 = loc("p10.209")
#loc12 = loc("p11.214")
#loc13 = loc("p12.223")
#loc14 = loc("p13.284")
#loc15 = loc("p14.296")
#loc16 = loc("p15.328")
#loc17 = loc("p16.336")
#loc18 = loc("p17.495")
#loc123 = loc("reduce.440")
#loc205 = loc("custom-call.512")
#loc206 = loc("custom-call.199")
#loc218 = loc("custom-call.461")
#loc219 = loc("custom-call.218")
#loc231 = loc("custom-call.345")
#loc232 = loc("custom-call.332")
#loc244 = loc("custom-call.102")
#loc245 = loc("custom-call.89")
#loc257 = loc("custom-call.26")
#loc258 = loc("custom-call.10")
module @SyncTensorsGraph.597 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1024x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p0.1"), %arg1: tensor<1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p1.6"), %arg2: tensor<4x18xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("p2.14"), %arg3: tensor<151936x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p3.19"), %arg4: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p4.70"), %arg5: tensor<128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_norm_weight"} loc("p5.85"), %arg6: tensor<1024x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p6.93"), %arg7: tensor<151936x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"} loc("p7.190"), %arg8: tensor<1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"} loc("p8.195"), %arg9: tensor<1024x3072xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p9.204"), %arg10: tensor<3072x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p10.209"), %arg11: tensor<1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p11.214"), %arg12: tensor<1024x2048xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p12.223"), %arg13: tensor<4x18xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"} loc("p13.284"), %arg14: tensor<i1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>} loc("p14.296"), %arg15: tensor<128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_norm_weight"} loc("p15.328"), %arg16: tensor<2048x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p16.336"), %arg17: tensor<3072x1024xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p17.495")) -> (tensor<4x8x18x128xf32>, tensor<4x8x18x128xf32>, tensor<72xf32>, tensor<4x18x151936xf32>) {
    %c = stablehlo.constant dense<true> : tensor<i1> loc(#loc)
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]> : tensor<18xi64> loc(#loc)
    %c_1 = stablehlo.constant dense<[0, 1, 2, 3]> : tensor<4xi64> loc(#loc)
    %c_2 = stablehlo.constant dense<false> : tensor<i1> loc(#loc)
    %cst = stablehlo.constant dense<-3.40282347E+38> : tensor<f32> loc(#loc)
    %cst_3 = stablehlo.constant dense<[[[0.000000e+00, 1.000000e+00, 2.000000e+00, 3.000000e+00, 4.000000e+00, 5.000000e+00, 6.000000e+00, 7.000000e+00, 8.000000e+00, 9.000000e+00, 1.000000e+01, 1.100000e+01, 1.200000e+01, 1.300000e+01, 1.400000e+01, 1.500000e+01, 1.600000e+01, 1.700000e+01]]]> : tensor<1x1x18xf32> loc(#loc)
    %c_4 = stablehlo.constant dense<-100> : tensor<i64> loc(#loc)
    %cst_5 = stablehlo.constant dense<0.297301769> : tensor<f32> loc(#loc)
    %c_6 = stablehlo.constant dense<4> : tensor<i64> loc(#loc)
    %c_7 = stablehlo.constant dense<18> : tensor<i64> loc(#loc)
    %cst_8 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %cst_9 = stablehlo.constant dense<0xFFF0000000000000> : tensor<f64> loc(#loc)
    %c_10 = stablehlo.constant dense<0> : tensor<i64> loc(#loc)
    %cst_11 = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<72xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<i64>) -> tensor<72xi64> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<4x16x18x18xf32> loc(#loc)
    %3 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<f64>) -> tensor<4x16x18x18xf64> loc(#loc)
    %4 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<f32>) -> tensor<4x1x18x18xf32> loc(#loc)
    %5 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<4x1x18x18xf32> loc(#loc)
    %6 = stablehlo.broadcast_in_dim %c_7, dims = [] : (tensor<i64>) -> tensor<4x18xi64> loc(#loc)
    %7 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<4x18xi64> loc(#loc)
    %8 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<4x16x128x18xf32> loc(#loc)
    %9 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<4x16x18x128xf32> loc(#loc)
    %10 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<i64>) -> tensor<72xi64> loc(#loc)
    %11 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<i64>) -> tensor<4x18xi64> loc(#loc)
    %12 = stablehlo.reshape %arg3 : (tensor<151936x1024xf32>) -> tensor<1x151936x1024xf32> loc(#loc19)
    %13 = stablehlo.reshape %12 : (tensor<1x151936x1024xf32>) -> tensor<151936x1024xf32> loc(#loc20)
    %14 = stablehlo.reshape %arg2 : (tensor<4x18xi64>) -> tensor<1x4x18xi64> loc(#loc21)
    %15 = stablehlo.reshape %14 : (tensor<1x4x18xi64>) -> tensor<4x18xi64> loc(#loc22)
    %16 = stablehlo.reshape %14 : (tensor<1x4x18xi64>) -> tensor<72xi64> loc(#loc23)
    %17 = stablehlo.convert %16 : (tensor<72xi64>) -> tensor<72xui32> loc(#loc24)
    %18 = "stablehlo.gather"(%13, %17) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1024>}> : (tensor<151936x1024xf32>, tensor<72xui32>) -> tensor<72x1024xf32> loc(#loc25)
    %19 = stablehlo.reshape %18 : (tensor<72x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc26)
    %20 = stablehlo.reshape %arg1 : (tensor<1024xf32>) -> tensor<1x1x1024xf32> loc(#loc27)
    %21 = stablehlo.reshape %20 : (tensor<1x1x1024xf32>) -> tensor<1024xf32> loc(#loc28)
    %22 = stablehlo.composite "tenstorrent.rms_norm" %19, %21 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, decomposition = @tenstorrent.rms_norm.impl_3} : (tensor<4x18x1024xf32>, tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc29)
    %23 = stablehlo.reshape %22 : (tensor<4x18x1024xf32>) -> tensor<72x1024xf32> loc(#loc30)
    %24 = stablehlo.reshape %arg0 : (tensor<1024x1024xf32>) -> tensor<1x1024x1024xf32> loc(#loc31)
    %25 = stablehlo.reshape %24 : (tensor<1x1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc32)
    %26 = stablehlo.transpose %25, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,1024]{0,1}"} : (tensor<1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc33)
    %27 = stablehlo.dot_general %23, %26, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x1024xf32>) -> tensor<72x1024xf32> loc(#loc34)
    %28 = stablehlo.reshape %27 : (tensor<72x1024xf32>) -> tensor<4x18x8x128xf32> loc(#loc35)
    %29 = stablehlo.transpose %28, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[4,8,18,128]{3,1,2,0}"} : (tensor<4x18x8x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc36)
    %30 = stablehlo.reshape %arg6 : (tensor<1024x1024xf32>) -> tensor<1x1024x1024xf32> loc(#loc37)
    %31 = stablehlo.reshape %30 : (tensor<1x1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc38)
    %32 = stablehlo.transpose %31, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,1024]{0,1}"} : (tensor<1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc39)
    %33 = stablehlo.dot_general %23, %32, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x1024xf32>) -> tensor<72x1024xf32> loc(#loc40)
    %34 = stablehlo.reshape %33 : (tensor<72x1024xf32>) -> tensor<4x18x8x128xf32> loc(#loc41)
    %35 = stablehlo.reshape %arg5 : (tensor<128xf32>) -> tensor<1x1x128xf32> loc(#loc42)
    %36 = stablehlo.reshape %35 : (tensor<1x1x128xf32>) -> tensor<128xf32> loc(#loc43)
    %37 = stablehlo.composite "tenstorrent.rms_norm" %34, %36 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<128> : tensor<1xi64>}, decomposition = @tenstorrent.rms_norm.impl_2} : (tensor<4x18x8x128xf32>, tensor<128xf32>) -> tensor<4x18x8x128xf32> loc(#loc44)
    %38 = stablehlo.transpose %37, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[4,8,18,128]{3,1,2,0}"} : (tensor<4x18x8x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc45)
    %39 = stablehlo.reshape %arg4 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc46)
    %40 = stablehlo.reshape %39 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc47)
    %41 = stablehlo.dot_general %40, %cst_3, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x18xf32>) -> tensor<1x64x18xf32> loc(#loc48)
    %42 = stablehlo.transpose %41, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,18,64]{1,2,0}"} : (tensor<1x64x18xf32>) -> tensor<1x18x64xf32> loc(#loc49)
    %43 = stablehlo.concatenate %42, %42, dim = 2 : (tensor<1x18x64xf32>, tensor<1x18x64xf32>) -> tensor<1x18x128xf32> loc(#loc50)
    %44 = stablehlo.cosine %43 : tensor<1x18x128xf32> loc(#loc51)
    %45 = stablehlo.reshape %44 : (tensor<1x18x128xf32>) -> tensor<18x128xf32> loc(#loc52)
    %46 = stablehlo.broadcast_in_dim %45, dims = [2, 3] : (tensor<18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc53)
    %47 = stablehlo.multiply %38, %46 : tensor<4x8x18x128xf32> loc(#loc54)
    %48 = stablehlo.slice %38 [0:4, 0:8, 0:18, 64:128] : (tensor<4x8x18x128xf32>) -> tensor<4x8x18x64xf32> loc(#loc55)
    %49 = stablehlo.negate %48 : tensor<4x8x18x64xf32> loc(#loc56)
    %50 = stablehlo.slice %38 [0:4, 0:8, 0:18, 0:64] : (tensor<4x8x18x128xf32>) -> tensor<4x8x18x64xf32> loc(#loc57)
    %51 = stablehlo.concatenate %49, %50, dim = 3 : (tensor<4x8x18x64xf32>, tensor<4x8x18x64xf32>) -> tensor<4x8x18x128xf32> loc(#loc58)
    %52 = stablehlo.sine %43 : tensor<1x18x128xf32> loc(#loc59)
    %53 = stablehlo.reshape %52 : (tensor<1x18x128xf32>) -> tensor<18x128xf32> loc(#loc60)
    %54 = stablehlo.broadcast_in_dim %53, dims = [2, 3] : (tensor<18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc61)
    %55 = stablehlo.multiply %51, %54 : tensor<4x8x18x128xf32> loc(#loc62)
    %56 = stablehlo.add %47, %55 : tensor<4x8x18x128xf32> loc(#loc63)
    %57 = stablehlo.pad %15, %c_4, low = [0, 0], high = [0, 1], interior = [0, 0] : (tensor<4x18xi64>, tensor<i64>) -> tensor<4x19xi64> loc(#loc64)
    %58 = stablehlo.slice %57 [0:4, 1:19] : (tensor<4x19xi64>) -> tensor<4x18xi64> loc(#loc65)
    %59 = stablehlo.reshape %58 : (tensor<4x18xi64>) -> tensor<72xi64> loc(#loc66)
    %60 = stablehlo.compare  NE, %59, %10 : (tensor<72xi64>, tensor<72xi64>) -> tensor<72xi1> loc(#loc67)
    %61 = stablehlo.reshape %arg16 : (tensor<2048x1024xf32>) -> tensor<1x2048x1024xf32> loc(#loc68)
    %62 = stablehlo.reshape %61 : (tensor<1x2048x1024xf32>) -> tensor<2048x1024xf32> loc(#loc69)
    %63 = stablehlo.transpose %62, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,2048]{0,1}"} : (tensor<2048x1024xf32>) -> tensor<1024x2048xf32> loc(#loc70)
    %64 = stablehlo.dot_general %23, %63, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x2048xf32>) -> tensor<72x2048xf32> loc(#loc71)
    %65 = stablehlo.reshape %64 : (tensor<72x2048xf32>) -> tensor<4x18x16x128xf32> loc(#loc72)
    %66 = stablehlo.reshape %arg15 : (tensor<128xf32>) -> tensor<1x1x128xf32> loc(#loc73)
    %67 = stablehlo.reshape %66 : (tensor<1x1x128xf32>) -> tensor<128xf32> loc(#loc74)
    %68 = stablehlo.composite "tenstorrent.rms_norm" %65, %67 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<128> : tensor<1xi64>}, decomposition = @tenstorrent.rms_norm.impl_1} : (tensor<4x18x16x128xf32>, tensor<128xf32>) -> tensor<4x18x16x128xf32> loc(#loc75)
    %69 = stablehlo.transpose %68, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[4,16,18,128]{3,1,2,0}"} : (tensor<4x18x16x128xf32>) -> tensor<4x16x18x128xf32> loc(#loc76)
    %70 = stablehlo.broadcast_in_dim %45, dims = [2, 3] : (tensor<18x128xf32>) -> tensor<4x16x18x128xf32> loc(#loc77)
    %71 = stablehlo.multiply %69, %70 : tensor<4x16x18x128xf32> loc(#loc78)
    %72 = stablehlo.slice %69 [0:4, 0:16, 0:18, 64:128] : (tensor<4x16x18x128xf32>) -> tensor<4x16x18x64xf32> loc(#loc79)
    %73 = stablehlo.negate %72 : tensor<4x16x18x64xf32> loc(#loc80)
    %74 = stablehlo.slice %69 [0:4, 0:16, 0:18, 0:64] : (tensor<4x16x18x128xf32>) -> tensor<4x16x18x64xf32> loc(#loc81)
    %75 = stablehlo.concatenate %73, %74, dim = 3 : (tensor<4x16x18x64xf32>, tensor<4x16x18x64xf32>) -> tensor<4x16x18x128xf32> loc(#loc82)
    %76 = stablehlo.broadcast_in_dim %53, dims = [2, 3] : (tensor<18x128xf32>) -> tensor<4x16x18x128xf32> loc(#loc83)
    %77 = stablehlo.multiply %75, %76 : tensor<4x16x18x128xf32> loc(#loc84)
    %78 = stablehlo.add %71, %77 : tensor<4x16x18x128xf32> loc(#loc85)
    %79 = stablehlo.multiply %78, %9 : tensor<4x16x18x128xf32> loc(#loc86)
    %80 = stablehlo.broadcast_in_dim %56, dims = [0, 1, 3, 4] : (tensor<4x8x18x128xf32>) -> tensor<4x8x2x18x128xf32> loc(#loc87)
    %81 = stablehlo.reshape %80 : (tensor<4x8x2x18x128xf32>) -> tensor<4x16x18x128xf32> loc(#loc88)
    %82 = stablehlo.transpose %81, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "f32[4,16,128,18]{2,3,1,0}"} : (tensor<4x16x18x128xf32>) -> tensor<4x16x128x18xf32> loc(#loc89)
    %83 = stablehlo.multiply %82, %8 : tensor<4x16x128x18xf32> loc(#loc90)
    %84 = stablehlo.dot_general %79, %83, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<4x16x18x128xf32>, tensor<4x16x128x18xf32>) -> tensor<4x16x18x18xf32> loc(#loc91)
    %85 = stablehlo.broadcast_in_dim %arg14, dims = [] : (tensor<i1>) -> tensor<18x18xi1> loc(#loc92)
    %86 = stablehlo.broadcast_in_dim %c_0, dims = [1] : (tensor<18xi64>) -> tensor<18x18xi64> loc(#loc93)
    %87 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<18xi64>) -> tensor<18x18xi64> loc(#loc94)
    %88 = stablehlo.compare  LE, %86, %87 : (tensor<18x18xi64>, tensor<18x18xi64>) -> tensor<18x18xi1> loc(#loc95)
    %89 = stablehlo.and %85, %88 : tensor<18x18xi1> loc(#loc96)
    %90 = stablehlo.broadcast_in_dim %89, dims = [1, 2] : (tensor<18x18xi1>) -> tensor<4x18x18xi1> loc(#loc97)
    %91 = stablehlo.reshape %arg13 : (tensor<4x18xi64>) -> tensor<1x4x18xi64> loc(#loc98)
    %92 = stablehlo.reshape %91 : (tensor<1x4x18xi64>) -> tensor<4x18xi64> loc(#loc99)
    %93 = stablehlo.compare  NE, %92, %11 : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi1> loc(#loc100)
    %94 = stablehlo.broadcast_in_dim %c_1, dims = [0] : (tensor<4xi64>) -> tensor<4x18xi64> loc(#loc101)
    %95 = stablehlo.compare  LT, %94, %11 : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi1> loc(#loc102)
    %96 = stablehlo.add %94, %7 : tensor<4x18xi64> loc(#loc103)
    %97 = stablehlo.select %95, %96, %94 : tensor<4x18xi1>, tensor<4x18xi64> loc(#loc104)
    %98 = stablehlo.reshape %97 : (tensor<4x18xi64>) -> tensor<4x18x1xi64> loc(#loc105)
    %99 = stablehlo.broadcast_in_dim %c_0, dims = [1] : (tensor<18xi64>) -> tensor<4x18xi64> loc(#loc106)
    %100 = stablehlo.compare  LT, %99, %11 : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi1> loc(#loc107)
    %101 = stablehlo.add %99, %6 : tensor<4x18xi64> loc(#loc108)
    %102 = stablehlo.select %100, %101, %99 : tensor<4x18xi1>, tensor<4x18xi64> loc(#loc109)
    %103 = stablehlo.reshape %102 : (tensor<4x18xi64>) -> tensor<4x18x1xi64> loc(#loc110)
    %104 = stablehlo.concatenate %98, %103, dim = 2 : (tensor<4x18x1xi64>, tensor<4x18x1xi64>) -> tensor<4x18x2xi64> loc(#loc111)
    %105 = "stablehlo.gather"(%93, %104) <{dimension_numbers = #stablehlo.gather<collapsed_slice_dims = [0, 1], start_index_map = [0, 1], index_vector_dim = 2>, slice_sizes = array<i64: 1, 1>}> : (tensor<4x18xi1>, tensor<4x18x2xi64>) -> tensor<4x18xi1> loc(#loc112)
    %106 = stablehlo.broadcast_in_dim %105, dims = [0, 2] : (tensor<4x18xi1>) -> tensor<4x18x18xi1> loc(#loc113)
    %107 = stablehlo.and %90, %106 : tensor<4x18x18xi1> loc(#loc114)
    %108 = stablehlo.reshape %107 : (tensor<4x18x18xi1>) -> tensor<4x1x18x18xi1> loc(#loc115)
    %109 = stablehlo.select %108, %5, %4 : tensor<4x1x18x18xi1>, tensor<4x1x18x18xf32> loc(#loc116)
    %110 = stablehlo.reshape %109 : (tensor<4x1x18x18xf32>) -> tensor<4x18x18xf32> loc(#loc117)
    %111 = stablehlo.broadcast_in_dim %110, dims = [0, 2, 3] : (tensor<4x18x18xf32>) -> tensor<4x16x18x18xf32> loc(#loc118)
    %112 = stablehlo.add %84, %111 : tensor<4x16x18x18xf32> loc(#loc119)
    %113 = stablehlo.convert %112 : (tensor<4x16x18x18xf32>) -> tensor<4x16x18x18xf64> loc(#loc120)
    %114 = stablehlo.compare  EQ, %113, %3 : (tensor<4x16x18x18xf64>, tensor<4x16x18x18xf64>) -> tensor<4x16x18x18xi1> loc(#loc121)
    %115 = stablehlo.not %114 : tensor<4x16x18x18xi1> loc(#loc122)
    %116 = stablehlo.reduce(%115 init: %c_2) across dimensions = [3] : (tensor<4x16x18x18xi1>, tensor<i1>) -> tensor<4x16x18xi1>
     reducer(%arg18: tensor<i1> loc("reduce.440"), %arg19: tensor<i1> loc("reduce.440"))  {
      %197 = stablehlo.or %arg18, %arg19 : tensor<i1> loc(#loc124)
      %198 = stablehlo.select %197, %c, %c_2 : tensor<i1>, tensor<i1> loc(#loc125)
      stablehlo.return %198 : tensor<i1> loc(#loc)
    } loc(#loc123)
    %117 = stablehlo.reshape %116 : (tensor<4x16x18xi1>) -> tensor<4x16x18x1xi1> loc(#loc126)
    %118 = stablehlo.not %117 : tensor<4x16x18x1xi1> loc(#loc127)
    %119 = stablehlo.reshape %118 : (tensor<4x16x18x1xi1>) -> tensor<4x16x18xi1> loc(#loc128)
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] : (tensor<4x16x18xi1>) -> tensor<4x16x18x18xi1> loc(#loc129)
    %121 = stablehlo.reduce(%112 init: %cst_8) applies stablehlo.maximum across dimensions = [3] : (tensor<4x16x18x18xf32>, tensor<f32>) -> tensor<4x16x18xf32> loc(#loc130)
    %122 = stablehlo.broadcast_in_dim %121, dims = [0, 1, 2] : (tensor<4x16x18xf32>) -> tensor<4x16x18x18xf32> loc(#loc131)
    %123 = stablehlo.subtract %112, %122 : tensor<4x16x18x18xf32> loc(#loc132)
    %124 = stablehlo.exponential %123 : tensor<4x16x18x18xf32> loc(#loc133)
    %125 = stablehlo.reduce(%124 init: %cst_11) applies stablehlo.add across dimensions = [3] : (tensor<4x16x18x18xf32>, tensor<f32>) -> tensor<4x16x18xf32> loc(#loc134)
    %126 = stablehlo.broadcast_in_dim %125, dims = [0, 1, 2] : (tensor<4x16x18xf32>) -> tensor<4x16x18x18xf32> loc(#loc135)
    %127 = stablehlo.divide %124, %126 : tensor<4x16x18x18xf32> loc(#loc136)
    %128 = stablehlo.select %120, %2, %127 : tensor<4x16x18x18xi1>, tensor<4x16x18x18xf32> loc(#loc137)
    %129 = stablehlo.broadcast_in_dim %29, dims = [0, 1, 3, 4] : (tensor<4x8x18x128xf32>) -> tensor<4x8x2x18x128xf32> loc(#loc138)
    %130 = stablehlo.reshape %129 : (tensor<4x8x2x18x128xf32>) -> tensor<4x16x18x128xf32> loc(#loc139)
    %131 = stablehlo.dot_general %128, %130, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<4x16x18x18xf32>, tensor<4x16x18x128xf32>) -> tensor<4x16x18x128xf32> loc(#loc140)
    %132 = stablehlo.transpose %131, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[4,18,16,128]{3,1,2,0}"} : (tensor<4x16x18x128xf32>) -> tensor<4x18x16x128xf32> loc(#loc141)
    %133 = stablehlo.reshape %132 : (tensor<4x18x16x128xf32>) -> tensor<72x2048xf32> loc(#loc142)
    %134 = stablehlo.reshape %arg12 : (tensor<1024x2048xf32>) -> tensor<1x1024x2048xf32> loc(#loc143)
    %135 = stablehlo.reshape %134 : (tensor<1x1024x2048xf32>) -> tensor<1024x2048xf32> loc(#loc144)
    %136 = stablehlo.transpose %135, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[2048,1024]{0,1}"} : (tensor<1024x2048xf32>) -> tensor<2048x1024xf32> loc(#loc145)
    %137 = stablehlo.dot_general %133, %136, contracting_dims = [1] x [0] : (tensor<72x2048xf32>, tensor<2048x1024xf32>) -> tensor<72x1024xf32> loc(#loc146)
    %138 = stablehlo.reshape %137 : (tensor<72x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc147)
    %139 = stablehlo.add %19, %138 : tensor<4x18x1024xf32> loc(#loc148)
    %140 = stablehlo.reshape %arg11 : (tensor<1024xf32>) -> tensor<1x1x1024xf32> loc(#loc149)
    %141 = stablehlo.reshape %140 : (tensor<1x1x1024xf32>) -> tensor<1024xf32> loc(#loc150)
    %142 = stablehlo.composite "tenstorrent.rms_norm" %139, %141 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, decomposition = @tenstorrent.rms_norm.impl_0} : (tensor<4x18x1024xf32>, tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc151)
    %143 = stablehlo.reshape %142 : (tensor<4x18x1024xf32>) -> tensor<72x1024xf32> loc(#loc152)
    %144 = stablehlo.reshape %arg17 : (tensor<3072x1024xf32>) -> tensor<1x3072x1024xf32> loc(#loc153)
    %145 = stablehlo.reshape %144 : (tensor<1x3072x1024xf32>) -> tensor<3072x1024xf32> loc(#loc154)
    %146 = stablehlo.transpose %145, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,3072]{0,1}"} : (tensor<3072x1024xf32>) -> tensor<1024x3072xf32> loc(#loc155)
    %147 = stablehlo.dot_general %143, %146, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x3072xf32>) -> tensor<72x3072xf32> loc(#loc156)
    %148 = stablehlo.reshape %147 : (tensor<72x3072xf32>) -> tensor<4x18x3072xf32> loc(#loc157)
    %149 = stablehlo.logistic %148 : tensor<4x18x3072xf32> loc(#loc158)
    %150 = stablehlo.multiply %148, %149 : tensor<4x18x3072xf32> loc(#loc159)
    %151 = stablehlo.reshape %arg10 : (tensor<3072x1024xf32>) -> tensor<1x3072x1024xf32> loc(#loc160)
    %152 = stablehlo.reshape %151 : (tensor<1x3072x1024xf32>) -> tensor<3072x1024xf32> loc(#loc161)
    %153 = stablehlo.transpose %152, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,3072]{0,1}"} : (tensor<3072x1024xf32>) -> tensor<1024x3072xf32> loc(#loc162)
    %154 = stablehlo.dot_general %143, %153, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x3072xf32>) -> tensor<72x3072xf32> loc(#loc163)
    %155 = stablehlo.reshape %154 : (tensor<72x3072xf32>) -> tensor<4x18x3072xf32> loc(#loc164)
    %156 = stablehlo.multiply %150, %155 : tensor<4x18x3072xf32> loc(#loc165)
    %157 = stablehlo.reshape %156 : (tensor<4x18x3072xf32>) -> tensor<72x3072xf32> loc(#loc166)
    %158 = stablehlo.reshape %arg9 : (tensor<1024x3072xf32>) -> tensor<1x1024x3072xf32> loc(#loc167)
    %159 = stablehlo.reshape %158 : (tensor<1x1024x3072xf32>) -> tensor<1024x3072xf32> loc(#loc168)
    %160 = stablehlo.transpose %159, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[3072,1024]{0,1}"} : (tensor<1024x3072xf32>) -> tensor<3072x1024xf32> loc(#loc169)
    %161 = stablehlo.dot_general %157, %160, contracting_dims = [1] x [0] : (tensor<72x3072xf32>, tensor<3072x1024xf32>) -> tensor<72x1024xf32> loc(#loc170)
    %162 = stablehlo.reshape %161 : (tensor<72x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc171)
    %163 = stablehlo.add %139, %162 : tensor<4x18x1024xf32> loc(#loc172)
    %164 = stablehlo.reshape %arg8 : (tensor<1024xf32>) -> tensor<1x1x1024xf32> loc(#loc173)
    %165 = stablehlo.reshape %164 : (tensor<1x1x1024xf32>) -> tensor<1024xf32> loc(#loc174)
    %166 = stablehlo.composite "tenstorrent.rms_norm" %163, %165 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, decomposition = @tenstorrent.rms_norm.impl} : (tensor<4x18x1024xf32>, tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc175)
    %167 = stablehlo.reshape %166 : (tensor<4x18x1024xf32>) -> tensor<72x1024xf32> loc(#loc176)
    %168 = stablehlo.reshape %arg7 : (tensor<151936x1024xf32>) -> tensor<1x151936x1024xf32> loc(#loc177)
    %169 = stablehlo.reshape %168 : (tensor<1x151936x1024xf32>) -> tensor<151936x1024xf32> loc(#loc178)
    %170 = stablehlo.transpose %169, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,151936]{0,1}"} : (tensor<151936x1024xf32>) -> tensor<1024x151936xf32> loc(#loc179)
    %171 = stablehlo.dot_general %167, %170, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x151936xf32>) -> tensor<72x151936xf32> loc(#loc180)
    %172 = stablehlo.reshape %171 : (tensor<72x151936xf32>) -> tensor<4x18x151936xf32> loc(#loc181)
    %173 = stablehlo.reduce(%171 init: %cst) applies stablehlo.maximum across dimensions = [1] : (tensor<72x151936xf32>, tensor<f32>) -> tensor<72xf32> loc(#loc182)
    %174 = stablehlo.broadcast_in_dim %173, dims = [0] : (tensor<72xf32>) -> tensor<72x151936xf32> loc(#loc183)
    %175 = stablehlo.subtract %171, %174 : tensor<72x151936xf32> loc(#loc184)
    %176 = stablehlo.exponential %175 : tensor<72x151936xf32> loc(#loc185)
    %177 = stablehlo.reduce(%176 init: %cst_11) applies stablehlo.add across dimensions = [1] : (tensor<72x151936xf32>, tensor<f32>) -> tensor<72xf32> loc(#loc186)
    %178 = stablehlo.reshape %177 : (tensor<72xf32>) -> tensor<72x1xf32> loc(#loc187)
    %179 = stablehlo.log %178 : tensor<72x1xf32> loc(#loc188)
    %180 = stablehlo.reshape %179 : (tensor<72x1xf32>) -> tensor<72xf32> loc(#loc189)
    %181 = stablehlo.broadcast_in_dim %180, dims = [0] : (tensor<72xf32>) -> tensor<72x151936xf32> loc(#loc190)
    %182 = stablehlo.subtract %175, %181 : tensor<72x151936xf32> loc(#loc191)
    %183 = stablehlo.iota dim = 0 : tensor<72xui32> loc(#loc192)
    %184 = stablehlo.reshape %183 : (tensor<72xui32>) -> tensor<72x1x1xui32> loc(#loc192)
    %185 = stablehlo.select %60, %59, %1 : tensor<72xi1>, tensor<72xi64> loc(#loc193)
    %186 = stablehlo.reshape %185 : (tensor<72xi64>) -> tensor<72x1xi64> loc(#loc194)
    %187 = stablehlo.convert %186 : (tensor<72x1xi64>) -> tensor<72x1xui32> loc(#loc195)
    %188 = stablehlo.reshape %187 : (tensor<72x1xui32>) -> tensor<72x1x1xui32> loc(#loc196)
    %189 = stablehlo.concatenate %184, %188, dim = 2 : (tensor<72x1x1xui32>, tensor<72x1x1xui32>) -> tensor<72x1x2xui32> loc(#loc197)
    %190 = "stablehlo.gather"(%182, %189) <{dimension_numbers = #stablehlo.gather<collapsed_slice_dims = [0, 1], start_index_map = [0, 1], index_vector_dim = 2>, slice_sizes = array<i64: 1, 1>}> : (tensor<72x151936xf32>, tensor<72x1x2xui32>) -> tensor<72x1xf32> loc(#loc198)
    %191 = stablehlo.reshape %190 : (tensor<72x1xf32>) -> tensor<72xf32> loc(#loc199)
    %192 = stablehlo.negate %191 : tensor<72xf32> loc(#loc200)
    %193 = stablehlo.select %60, %192, %0 : tensor<72xi1>, tensor<72xf32> loc(#loc201)
    %194 = stablehlo.convert %60 : (tensor<72xi1>) -> tensor<72xi64> loc(#loc202)
    %195 = stablehlo.convert %194 : (tensor<72xi64>) -> tensor<72xf32> loc(#loc203)
    %196 = stablehlo.divide %193, %195 : tensor<72xf32> loc(#loc204)
    return %29, %56, %196, %172 : tensor<4x8x18x128xf32>, tensor<4x8x18x128xf32>, tensor<72xf32>, tensor<4x18x151936xf32> loc(#loc)
  } loc(#loc)
  func.func private @tenstorrent.rms_norm.impl(%arg0: tensor<4x18x1024xf32> {ttcore.argument_type = #ttcore.argument_type<input>} loc("custom-call.512"), %arg1: tensor<1024xf32> {ttcore.argument_type = #ttcore.argument_type<input>} loc("custom-call.199")) -> tensor<4x18x1024xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<9.765625E-4> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x1024xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x1024xf32> loc(#loc207)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x18x1024xf32>, tensor<f32>) -> tensor<4x18xf32> loc(#loc208)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18xf32> loc(#loc209)
    %6 = stablehlo.reshape %5 : (tensor<4x18xf32>) -> tensor<4x18x1xf32> loc(#loc210)
    %7 = stablehlo.add %6, %0 : tensor<4x18x1xf32> loc(#loc211)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x1xf32> loc(#loc212)
    %9 = stablehlo.reshape %8 : (tensor<4x18x1xf32>) -> tensor<4x18xf32> loc(#loc213)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1] : (tensor<4x18xf32>) -> tensor<4x18x1024xf32> loc(#loc214)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x1024xf32> loc(#loc215)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc216)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x1024xf32> loc(#loc217)
    return %13 : tensor<4x18x1024xf32> loc(#loc)
  } loc(#loc)
  func.func private @tenstorrent.rms_norm.impl_0(%arg0: tensor<4x18x1024xf32> {ttcore.argument_type = #ttcore.argument_type<input>} loc("custom-call.461"), %arg1: tensor<1024xf32> {ttcore.argument_type = #ttcore.argument_type<input>} loc("custom-call.218")) -> tensor<4x18x1024xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<9.765625E-4> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x1024xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x1024xf32> loc(#loc220)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x18x1024xf32>, tensor<f32>) -> tensor<4x18xf32> loc(#loc221)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18xf32> loc(#loc222)
    %6 = stablehlo.reshape %5 : (tensor<4x18xf32>) -> tensor<4x18x1xf32> loc(#loc223)
    %7 = stablehlo.add %6, %0 : tensor<4x18x1xf32> loc(#loc224)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x1xf32> loc(#loc225)
    %9 = stablehlo.reshape %8 : (tensor<4x18x1xf32>) -> tensor<4x18xf32> loc(#loc226)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1] : (tensor<4x18xf32>) -> tensor<4x18x1024xf32> loc(#loc227)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x1024xf32> loc(#loc228)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc229)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x1024xf32> loc(#loc230)
    return %13 : tensor<4x18x1024xf32> loc(#loc)
  } loc(#loc)
  func.func private @tenstorrent.rms_norm.impl_1(%arg0: tensor<4x18x16x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>} loc("custom-call.345"), %arg1: tensor<128xf32> {ttcore.argument_type = #ttcore.argument_type<input>} loc("custom-call.332")) -> tensor<4x18x16x128xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<7.812500e-03> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x16x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18x16xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x16x128xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x16x128xf32> loc(#loc233)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x18x16x128xf32>, tensor<f32>) -> tensor<4x18x16xf32> loc(#loc234)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18x16xf32> loc(#loc235)
    %6 = stablehlo.reshape %5 : (tensor<4x18x16xf32>) -> tensor<4x18x16x1xf32> loc(#loc236)
    %7 = stablehlo.add %6, %0 : tensor<4x18x16x1xf32> loc(#loc237)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x16x1xf32> loc(#loc238)
    %9 = stablehlo.reshape %8 : (tensor<4x18x16x1xf32>) -> tensor<4x18x16xf32> loc(#loc239)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1, 2] : (tensor<4x18x16xf32>) -> tensor<4x18x16x128xf32> loc(#loc240)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x16x128xf32> loc(#loc241)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [3] : (tensor<128xf32>) -> tensor<4x18x16x128xf32> loc(#loc242)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x16x128xf32> loc(#loc243)
    return %13 : tensor<4x18x16x128xf32> loc(#loc)
  } loc(#loc)
  func.func private @tenstorrent.rms_norm.impl_2(%arg0: tensor<4x18x8x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>} loc("custom-call.102"), %arg1: tensor<128xf32> {ttcore.argument_type = #ttcore.argument_type<input>} loc("custom-call.89")) -> tensor<4x18x8x128xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<7.812500e-03> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x8x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18x8xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x8x128xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x8x128xf32> loc(#loc246)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x18x8x128xf32>, tensor<f32>) -> tensor<4x18x8xf32> loc(#loc247)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18x8xf32> loc(#loc248)
    %6 = stablehlo.reshape %5 : (tensor<4x18x8xf32>) -> tensor<4x18x8x1xf32> loc(#loc249)
    %7 = stablehlo.add %6, %0 : tensor<4x18x8x1xf32> loc(#loc250)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x8x1xf32> loc(#loc251)
    %9 = stablehlo.reshape %8 : (tensor<4x18x8x1xf32>) -> tensor<4x18x8xf32> loc(#loc252)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1, 2] : (tensor<4x18x8xf32>) -> tensor<4x18x8x128xf32> loc(#loc253)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x8x128xf32> loc(#loc254)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [3] : (tensor<128xf32>) -> tensor<4x18x8x128xf32> loc(#loc255)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x8x128xf32> loc(#loc256)
    return %13 : tensor<4x18x8x128xf32> loc(#loc)
  } loc(#loc)
  func.func private @tenstorrent.rms_norm.impl_3(%arg0: tensor<4x18x1024xf32> {ttcore.argument_type = #ttcore.argument_type<input>} loc("custom-call.26"), %arg1: tensor<1024xf32> {ttcore.argument_type = #ttcore.argument_type<input>} loc("custom-call.10")) -> tensor<4x18x1024xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<9.765625E-4> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x1024xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x1024xf32> loc(#loc259)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x18x1024xf32>, tensor<f32>) -> tensor<4x18xf32> loc(#loc260)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18xf32> loc(#loc261)
    %6 = stablehlo.reshape %5 : (tensor<4x18xf32>) -> tensor<4x18x1xf32> loc(#loc262)
    %7 = stablehlo.add %6, %0 : tensor<4x18x1xf32> loc(#loc263)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x1xf32> loc(#loc264)
    %9 = stablehlo.reshape %8 : (tensor<4x18x1xf32>) -> tensor<4x18xf32> loc(#loc265)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1] : (tensor<4x18xf32>) -> tensor<4x18x1024xf32> loc(#loc266)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x1024xf32> loc(#loc267)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc268)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x1024xf32> loc(#loc269)
    return %13 : tensor<4x18x1024xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc19 = loc("reshape.20")
#loc20 = loc("reshape.22")
#loc21 = loc("reshape.15")
#loc22 = loc("reshape.17")
#loc23 = loc("reshape.18")
#loc24 = loc("convert.23")
#loc25 = loc("gather.24")
#loc26 = loc("reshape.25")
#loc27 = loc("reshape.7")
#loc28 = loc("reshape.9")
#loc29 = loc("custom-call.56")
#loc30 = loc("reshape.57")
#loc31 = loc("reshape.2")
#loc32 = loc("reshape.4")
#loc33 = loc("transpose.5")
#loc34 = loc("dot.58")
#loc35 = loc("reshape.60")
#loc36 = loc("transpose.61")
#loc37 = loc("reshape.94")
#loc38 = loc("reshape.96")
#loc39 = loc("transpose.97")
#loc40 = loc("dot.99")
#loc41 = loc("reshape.101")
#loc42 = loc("reshape.86")
#loc43 = loc("reshape.88")
#loc44 = loc("custom-call.132")
#loc45 = loc("transpose.133")
#loc46 = loc("reshape.71")
#loc47 = loc("reshape.75")
#loc48 = loc("dot.78")
#loc49 = loc("transpose.79")
#loc50 = loc("concatenate.80")
#loc51 = loc("cosine.142")
#loc52 = loc("reshape.146")
#loc53 = loc("broadcast.147")
#loc54 = loc("multiply.148")
#loc55 = loc("slice.135")
#loc56 = loc("negate.136")
#loc57 = loc("slice.134")
#loc58 = loc("concatenate.137")
#loc59 = loc("sine.81")
#loc60 = loc("reshape.138")
#loc61 = loc("broadcast.139")
#loc62 = loc("multiply.140")
#loc63 = loc("add.151")
#loc64 = loc("pad.155")
#loc65 = loc("slice.156")
#loc66 = loc("reshape.157")
#loc67 = loc("compare.585")
#loc68 = loc("reshape.337")
#loc69 = loc("reshape.339")
#loc70 = loc("transpose.340")
#loc71 = loc("dot.342")
#loc72 = loc("reshape.344")
#loc73 = loc("reshape.329")
#loc74 = loc("reshape.331")
#loc75 = loc("custom-call.375")
#loc76 = loc("transpose.376")
#loc77 = loc("broadcast.385")
#loc78 = loc("multiply.386")
#loc79 = loc("slice.378")
#loc80 = loc("negate.379")
#loc81 = loc("slice.377")
#loc82 = loc("concatenate.380")
#loc83 = loc("broadcast.382")
#loc84 = loc("multiply.383")
#loc85 = loc("add.389")
#loc86 = loc("multiply.391")
#loc87 = loc("broadcast.321")
#loc88 = loc("reshape.322")
#loc89 = loc("transpose.323")
#loc90 = loc("multiply.325")
#loc91 = loc("dot.392")
#loc92 = loc("broadcast.305")
#loc93 = loc("broadcast.292")
#loc94 = loc("broadcast.294")
#loc95 = loc("compare.295")
#loc96 = loc("and.306")
#loc97 = loc("broadcast.309")
#loc98 = loc("reshape.285")
#loc99 = loc("reshape.287")
#loc100 = loc("convert.288")
#loc101 = loc("broadcast.270")
#loc102 = loc("compare.279")
#loc103 = loc("add.276")
#loc104 = loc("select.280")
#loc105 = loc("reshape.281")
#loc106 = loc("broadcast.255")
#loc107 = loc("compare.264")
#loc108 = loc("add.261")
#loc109 = loc("select.265")
#loc110 = loc("reshape.282")
#loc111 = loc("concatenate.283")
#loc112 = loc("gather.289")
#loc113 = loc("broadcast.311")
#loc114 = loc("and.312")
#loc115 = loc("reshape.313")
#loc116 = loc("select.316")
#loc117 = loc("reshape.396")
#loc118 = loc("broadcast.397")
#loc119 = loc("add.398")
#loc120 = loc("convert.424")
#loc121 = loc("compare.426")
#loc122 = loc("not.428")
#loc124 = loc("or.438")
#loc125 = loc("select.439")
#loc126 = loc("reshape.444")
#loc127 = loc("not.446")
#loc128 = loc("reshape.448")
#loc129 = loc("broadcast.449")
#loc130 = loc("reduce.404")
#loc131 = loc("broadcast.405")
#loc132 = loc("subtract.406")
#loc133 = loc("exponential.407")
#loc134 = loc("reduce.413")
#loc135 = loc("broadcast.414")
#loc136 = loc("divide.415")
#loc137 = loc("select.450")
#loc138 = loc("broadcast.231")
#loc139 = loc("reshape.232")
#loc140 = loc("dot.451")
#loc141 = loc("transpose.453")
#loc142 = loc("reshape.455")
#loc143 = loc("reshape.224")
#loc144 = loc("reshape.226")
#loc145 = loc("transpose.227")
#loc146 = loc("dot.456")
#loc147 = loc("reshape.457")
#loc148 = loc("add.460")
#loc149 = loc("reshape.215")
#loc150 = loc("reshape.217")
#loc151 = loc("custom-call.491")
#loc152 = loc("reshape.500")
#loc153 = loc("reshape.496")
#loc154 = loc("reshape.498")
#loc155 = loc("transpose.499")
#loc156 = loc("dot.501")
#loc157 = loc("reshape.502")
#loc158 = loc("logistic.503")
#loc159 = loc("multiply.504")
#loc160 = loc("reshape.210")
#loc161 = loc("reshape.212")
#loc162 = loc("transpose.213")
#loc163 = loc("dot.493")
#loc164 = loc("reshape.494")
#loc165 = loc("multiply.505")
#loc166 = loc("reshape.506")
#loc167 = loc("reshape.205")
#loc168 = loc("reshape.207")
#loc169 = loc("transpose.208")
#loc170 = loc("dot.507")
#loc171 = loc("reshape.508")
#loc172 = loc("add.511")
#loc173 = loc("reshape.196")
#loc174 = loc("reshape.198")
#loc175 = loc("custom-call.542")
#loc176 = loc("reshape.543")
#loc177 = loc("reshape.191")
#loc178 = loc("reshape.193")
#loc179 = loc("transpose.194")
#loc180 = loc("dot.544")
#loc181 = loc("reshape.545")
#loc182 = loc("reduce.553")
#loc183 = loc("broadcast.558")
#loc184 = loc("subtract.559")
#loc185 = loc("exponential.560")
#loc186 = loc("reduce.567")
#loc187 = loc("reshape.568")
#loc188 = loc("log.569")
#loc189 = loc("reshape.572")
#loc190 = loc("broadcast.573")
#loc191 = loc("subtract.574")
#loc192 = loc("iota.576")
#loc193 = loc("select.186")
#loc194 = loc("reshape.187")
#loc195 = loc("convert.575")
#loc196 = loc("reshape.577")
#loc197 = loc("concatenate.578")
#loc198 = loc("gather.579")
#loc199 = loc("reshape.580")
#loc200 = loc("negate.581")
#loc201 = loc("select.587")
#loc202 = loc("convert.160")
#loc203 = loc("convert.168")
#loc204 = loc("divide.595")
#loc207 = loc("power.514")
#loc208 = loc("reduce.521")
#loc209 = loc("multiply.530")
#loc210 = loc("reshape.531")
#loc211 = loc("add.535")
#loc212 = loc("rsqrt.536")
#loc213 = loc("reshape.537")
#loc214 = loc("broadcast.538")
#loc215 = loc("multiply.539")
#loc216 = loc("broadcast.540")
#loc217 = loc("multiply.541")
#loc220 = loc("power.463")
#loc221 = loc("reduce.470")
#loc222 = loc("multiply.479")
#loc223 = loc("reshape.480")
#loc224 = loc("add.484")
#loc225 = loc("rsqrt.485")
#loc226 = loc("reshape.486")
#loc227 = loc("broadcast.487")
#loc228 = loc("multiply.488")
#loc229 = loc("broadcast.489")
#loc230 = loc("multiply.490")
#loc233 = loc("power.347")
#loc234 = loc("reduce.354")
#loc235 = loc("multiply.363")
#loc236 = loc("reshape.364")
#loc237 = loc("add.368")
#loc238 = loc("rsqrt.369")
#loc239 = loc("reshape.370")
#loc240 = loc("broadcast.371")
#loc241 = loc("multiply.372")
#loc242 = loc("broadcast.373")
#loc243 = loc("multiply.374")
#loc246 = loc("power.104")
#loc247 = loc("reduce.111")
#loc248 = loc("multiply.120")
#loc249 = loc("reshape.121")
#loc250 = loc("add.125")
#loc251 = loc("rsqrt.126")
#loc252 = loc("reshape.127")
#loc253 = loc("broadcast.128")
#loc254 = loc("multiply.129")
#loc255 = loc("broadcast.130")
#loc256 = loc("multiply.131")
#loc259 = loc("power.28")
#loc260 = loc("reduce.35")
#loc261 = loc("multiply.44")
#loc262 = loc("reshape.45")
#loc263 = loc("add.49")
#loc264 = loc("rsqrt.50")
#loc265 = loc("reshape.51")
#loc266 = loc("broadcast.52")
#loc267 = loc("multiply.53")
#loc268 = loc("broadcast.54")
#loc269 = loc("multiply.55")
------------------ END OF MLIR MODULE ------------------
2026-01-28 22:12:58.640 (   5.806s) [        66B35000]      module_builder.cc:1111     1| MLIR Module shlo_compiler:
#loc = loc(unknown)
#loc1 = loc("p0.1")
#loc2 = loc("p1.6")
#loc3 = loc("p2.14")
#loc4 = loc("p3.19")
#loc5 = loc("p4.70")
#loc6 = loc("p5.85")
#loc7 = loc("p6.93")
#loc8 = loc("p7.190")
#loc9 = loc("p8.195")
#loc10 = loc("p9.204")
#loc11 = loc("p10.209")
#loc12 = loc("p11.214")
#loc13 = loc("p12.223")
#loc14 = loc("p13.284")
#loc15 = loc("p14.296")
#loc16 = loc("p15.328")
#loc17 = loc("p16.336")
#loc18 = loc("p17.495")
#loc120 = loc("reduce.440")
#loc143 = loc("dot.456")
#loc166 = loc("dot.507")
#loc177 = loc("reduce.553")
#loc181 = loc("reduce.567")
#loc193 = loc("gather.579")
module @SyncTensorsGraph.597 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]> loc(#loc)
  func.func @main(%arg0: tensor<1024x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<512x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p0.1"), %arg1: tensor<1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024xf32>>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p1.6"), %arg2: tensor<4x18xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<4x18xi64>>, ttir.name = "args_0"} loc("p2.14"), %arg3: tensor<151936x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<151936x1024xf32>>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p3.19"), %arg4: tensor<64xf32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<64xf32>>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p4.70"), %arg5: tensor<128xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<128xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_norm_weight"} loc("p5.85"), %arg6: tensor<1024x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<512x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p6.93"), %arg7: tensor<151936x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<75968x1024xf32>>, ttir.name = "l__self___lm_head_weight"} loc("p7.190"), %arg8: tensor<1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024xf32>>, ttir.name = "l__self___model_norm_weight"} loc("p8.195"), %arg9: tensor<1024x3072xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024x1536xf32>>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p9.204"), %arg10: tensor<3072x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1536x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p10.209"), %arg11: tensor<1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024xf32>>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p11.214"), %arg12: tensor<1024x2048xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p12.223"), %arg13: tensor<4x18xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<4x18xi64>>, ttir.name = "args_1"} loc("p13.284"), %arg14: tensor<i1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<i1>>} loc("p14.296"), %arg15: tensor<128xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<128xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_norm_weight"} loc("p15.328"), %arg16: tensor<2048x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p16.336"), %arg17: tensor<3072x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1536x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p17.495")) -> (tensor<4x8x18x128xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<4x8x18x128xf32>>}, tensor<4x8x18x128xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<4x8x18x128xf32>>}, tensor<72xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<72xf32>>}, tensor<4x18x151936xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<4x18x151936xf32>>}) {
    %0:4 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17) in_shardings=[<@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{}, {}]>, <@mesh, []>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{"_axis_0"}, {}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {}, {"_axis_0"}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg18: tensor<512x1024xf32> loc("p0.1"), %arg19: tensor<1024xf32> loc("p1.6"), %arg20: tensor<4x18xi64> loc("p2.14"), %arg21: tensor<151936x1024xf32> loc("p3.19"), %arg22: tensor<64xf32> loc("p4.70"), %arg23: tensor<128xf32> loc("p5.85"), %arg24: tensor<512x1024xf32> loc("p6.93"), %arg25: tensor<75968x1024xf32> loc("p7.190"), %arg26: tensor<1024xf32> loc("p8.195"), %arg27: tensor<1024x1536xf32> loc("p9.204"), %arg28: tensor<1536x1024xf32> loc("p10.209"), %arg29: tensor<1024xf32> loc("p11.214"), %arg30: tensor<1024x1024xf32> loc("p12.223"), %arg31: tensor<4x18xi64> loc("p13.284"), %arg32: tensor<i1> loc("p14.296"), %arg33: tensor<128xf32> loc("p15.328"), %arg34: tensor<1024x1024xf32> loc("p16.336"), %arg35: tensor<1536x1024xf32> loc("p17.495")) {
      %c = stablehlo.constant dense<true> : tensor<i1> loc(#loc)
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]> : tensor<18xi64> loc(#loc)
      %c_1 = stablehlo.constant dense<[0, 1, 2, 3]> : tensor<4xi64> loc(#loc)
      %c_2 = stablehlo.constant dense<false> : tensor<i1> loc(#loc)
      %cst = stablehlo.constant dense<-3.40282347E+38> : tensor<f32> loc(#loc)
      %cst_3 = stablehlo.constant dense<[[[0.000000e+00, 1.000000e+00, 2.000000e+00, 3.000000e+00, 4.000000e+00, 5.000000e+00, 6.000000e+00, 7.000000e+00, 8.000000e+00, 9.000000e+00, 1.000000e+01, 1.100000e+01, 1.200000e+01, 1.300000e+01, 1.400000e+01, 1.500000e+01, 1.600000e+01, 1.700000e+01]]]> : tensor<1x1x18xf32> loc(#loc)
      %c_4 = stablehlo.constant dense<-100> : tensor<i64> loc(#loc)
      %cst_5 = stablehlo.constant dense<0.297301769> : tensor<f32> loc(#loc)
      %c_6 = stablehlo.constant dense<4> : tensor<i64> loc(#loc)
      %c_7 = stablehlo.constant dense<18> : tensor<i64> loc(#loc)
      %cst_8 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
      %cst_9 = stablehlo.constant dense<0xFFF0000000000000> : tensor<f64> loc(#loc)
      %c_10 = stablehlo.constant dense<0> : tensor<i64> loc(#loc)
      %cst_11 = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
      %1 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<72xf32> loc(#loc)
      %2 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<i64>) -> tensor<72xi64> loc(#loc)
      %3 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<4x8x18x18xf32> loc(#loc)
      %4 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<f64>) -> tensor<4x8x18x18xf64> loc(#loc)
      %5 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<f32>) -> tensor<4x1x18x18xf32> loc(#loc)
      %6 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<4x1x18x18xf32> loc(#loc)
      %7 = stablehlo.broadcast_in_dim %c_7, dims = [] : (tensor<i64>) -> tensor<4x18xi64> loc(#loc)
      %8 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<i64>) -> tensor<4x18xi64> loc(#loc)
      %9 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<4x8x128x18xf32> loc(#loc)
      %10 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<4x8x18x128xf32> loc(#loc)
      %11 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<i64>) -> tensor<72xi64> loc(#loc)
      %12 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<i64>) -> tensor<4x18xi64> loc(#loc)
      %13 = stablehlo.reshape %arg21 : (tensor<151936x1024xf32>) -> tensor<1x151936x1024xf32> loc(#loc19)
      %14 = stablehlo.reshape %13 : (tensor<1x151936x1024xf32>) -> tensor<151936x1024xf32> loc(#loc20)
      %15 = stablehlo.reshape %arg20 : (tensor<4x18xi64>) -> tensor<1x4x18xi64> loc(#loc21)
      %16 = stablehlo.reshape %15 : (tensor<1x4x18xi64>) -> tensor<4x18xi64> loc(#loc22)
      %17 = stablehlo.reshape %15 : (tensor<1x4x18xi64>) -> tensor<72xi64> loc(#loc23)
      %18 = stablehlo.convert %17 : (tensor<72xi64>) -> tensor<72xui32> loc(#loc24)
      %19 = "stablehlo.gather"(%14, %18) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1024>}> : (tensor<151936x1024xf32>, tensor<72xui32>) -> tensor<72x1024xf32> loc(#loc25)
      %20 = stablehlo.reshape %19 : (tensor<72x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc26)
      %21 = stablehlo.reshape %arg19 : (tensor<1024xf32>) -> tensor<1x1x1024xf32> loc(#loc27)
      %22 = stablehlo.reshape %21 : (tensor<1x1x1024xf32>) -> tensor<1024xf32> loc(#loc28)
      %23 = stablehlo.composite "tenstorrent.rms_norm" %20, %22 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, decomposition = @outlined_composite_tenstorrent.rms_norm.impl_3} : (tensor<4x18x1024xf32>, tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc)
      %24 = stablehlo.reshape %23 : (tensor<4x18x1024xf32>) -> tensor<72x1024xf32> loc(#loc29)
      %25 = stablehlo.reshape %arg18 : (tensor<512x1024xf32>) -> tensor<1x512x1024xf32> loc(#loc30)
      %26 = stablehlo.reshape %25 : (tensor<1x512x1024xf32>) -> tensor<512x1024xf32> loc(#loc31)
      %27 = stablehlo.transpose %26, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,1024]{0,1}"} : (tensor<512x1024xf32>) -> tensor<1024x512xf32> loc(#loc32)
      %28 = stablehlo.dot_general %24, %27, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x512xf32>) -> tensor<72x512xf32> loc(#loc33)
      %29 = stablehlo.reshape %28 : (tensor<72x512xf32>) -> tensor<4x18x4x128xf32> loc(#loc34)
      %30 = stablehlo.transpose %29, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[4,8,18,128]{3,1,2,0}"} : (tensor<4x18x4x128xf32>) -> tensor<4x4x18x128xf32> loc(#loc35)
      %31 = stablehlo.reshape %arg24 : (tensor<512x1024xf32>) -> tensor<1x512x1024xf32> loc(#loc36)
      %32 = stablehlo.reshape %31 : (tensor<1x512x1024xf32>) -> tensor<512x1024xf32> loc(#loc37)
      %33 = stablehlo.transpose %32, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,1024]{0,1}"} : (tensor<512x1024xf32>) -> tensor<1024x512xf32> loc(#loc38)
      %34 = stablehlo.dot_general %24, %33, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x512xf32>) -> tensor<72x512xf32> loc(#loc39)
      %35 = stablehlo.reshape %34 : (tensor<72x512xf32>) -> tensor<4x18x4x128xf32> loc(#loc40)
      %36 = stablehlo.reshape %arg23 : (tensor<128xf32>) -> tensor<1x1x128xf32> loc(#loc41)
      %37 = stablehlo.reshape %36 : (tensor<1x1x128xf32>) -> tensor<128xf32> loc(#loc42)
      %38 = stablehlo.composite "tenstorrent.rms_norm" %35, %37 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<128> : tensor<1xi64>}, decomposition = @outlined_composite_tenstorrent.rms_norm.impl_2} : (tensor<4x18x4x128xf32>, tensor<128xf32>) -> tensor<4x18x4x128xf32> loc(#loc)
      %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[4,8,18,128]{3,1,2,0}"} : (tensor<4x18x4x128xf32>) -> tensor<4x4x18x128xf32> loc(#loc43)
      %40 = stablehlo.reshape %arg22 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc44)
      %41 = stablehlo.reshape %40 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc45)
      %42 = stablehlo.dot_general %41, %cst_3, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x18xf32>) -> tensor<1x64x18xf32> loc(#loc46)
      %43 = stablehlo.transpose %42, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,18,64]{1,2,0}"} : (tensor<1x64x18xf32>) -> tensor<1x18x64xf32> loc(#loc47)
      %44 = stablehlo.concatenate %43, %43, dim = 2 : (tensor<1x18x64xf32>, tensor<1x18x64xf32>) -> tensor<1x18x128xf32> loc(#loc48)
      %45 = stablehlo.cosine %44 : tensor<1x18x128xf32> loc(#loc49)
      %46 = stablehlo.reshape %45 : (tensor<1x18x128xf32>) -> tensor<18x128xf32> loc(#loc50)
      %47 = stablehlo.broadcast_in_dim %46, dims = [2, 3] : (tensor<18x128xf32>) -> tensor<4x4x18x128xf32> loc(#loc51)
      %48 = stablehlo.multiply %39, %47 : tensor<4x4x18x128xf32> loc(#loc52)
      %49 = stablehlo.slice %39 [0:4, 0:4, 0:18, 64:128] : (tensor<4x4x18x128xf32>) -> tensor<4x4x18x64xf32> loc(#loc53)
      %50 = stablehlo.negate %49 : tensor<4x4x18x64xf32> loc(#loc54)
      %51 = stablehlo.slice %39 [0:4, 0:4, 0:18, 0:64] : (tensor<4x4x18x128xf32>) -> tensor<4x4x18x64xf32> loc(#loc55)
      %52 = stablehlo.concatenate %50, %51, dim = 3 : (tensor<4x4x18x64xf32>, tensor<4x4x18x64xf32>) -> tensor<4x4x18x128xf32> loc(#loc56)
      %53 = stablehlo.sine %44 : tensor<1x18x128xf32> loc(#loc57)
      %54 = stablehlo.reshape %53 : (tensor<1x18x128xf32>) -> tensor<18x128xf32> loc(#loc58)
      %55 = stablehlo.broadcast_in_dim %54, dims = [2, 3] : (tensor<18x128xf32>) -> tensor<4x4x18x128xf32> loc(#loc59)
      %56 = stablehlo.multiply %52, %55 : tensor<4x4x18x128xf32> loc(#loc60)
      %57 = stablehlo.add %48, %56 : tensor<4x4x18x128xf32> loc(#loc61)
      %58 = stablehlo.pad %16, %c_4, low = [0, 0], high = [0, 1], interior = [0, 0] : (tensor<4x18xi64>, tensor<i64>) -> tensor<4x19xi64> loc(#loc62)
      %59 = stablehlo.slice %58 [0:4, 1:19] : (tensor<4x19xi64>) -> tensor<4x18xi64> loc(#loc63)
      %60 = stablehlo.reshape %59 : (tensor<4x18xi64>) -> tensor<72xi64> loc(#loc64)
      %61 = stablehlo.compare  NE, %60, %11 : (tensor<72xi64>, tensor<72xi64>) -> tensor<72xi1> loc(#loc65)
      %62 = stablehlo.reshape %arg34 : (tensor<1024x1024xf32>) -> tensor<1x1024x1024xf32> loc(#loc66)
      %63 = stablehlo.reshape %62 : (tensor<1x1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc67)
      %64 = stablehlo.transpose %63, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,2048]{0,1}"} : (tensor<1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc68)
      %65 = stablehlo.dot_general %24, %64, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x1024xf32>) -> tensor<72x1024xf32> loc(#loc69)
      %66 = stablehlo.reshape %65 : (tensor<72x1024xf32>) -> tensor<4x18x8x128xf32> loc(#loc70)
      %67 = stablehlo.reshape %arg33 : (tensor<128xf32>) -> tensor<1x1x128xf32> loc(#loc71)
      %68 = stablehlo.reshape %67 : (tensor<1x1x128xf32>) -> tensor<128xf32> loc(#loc72)
      %69 = stablehlo.composite "tenstorrent.rms_norm" %66, %68 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<128> : tensor<1xi64>}, decomposition = @outlined_composite_tenstorrent.rms_norm.impl_1} : (tensor<4x18x8x128xf32>, tensor<128xf32>) -> tensor<4x18x8x128xf32> loc(#loc)
      %70 = stablehlo.transpose %69, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[4,16,18,128]{3,1,2,0}"} : (tensor<4x18x8x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc73)
      %71 = stablehlo.broadcast_in_dim %46, dims = [2, 3] : (tensor<18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc74)
      %72 = stablehlo.multiply %70, %71 : tensor<4x8x18x128xf32> loc(#loc75)
      %73 = stablehlo.slice %70 [0:4, 0:8, 0:18, 64:128] : (tensor<4x8x18x128xf32>) -> tensor<4x8x18x64xf32> loc(#loc76)
      %74 = stablehlo.negate %73 : tensor<4x8x18x64xf32> loc(#loc77)
      %75 = stablehlo.slice %70 [0:4, 0:8, 0:18, 0:64] : (tensor<4x8x18x128xf32>) -> tensor<4x8x18x64xf32> loc(#loc78)
      %76 = stablehlo.concatenate %74, %75, dim = 3 : (tensor<4x8x18x64xf32>, tensor<4x8x18x64xf32>) -> tensor<4x8x18x128xf32> loc(#loc79)
      %77 = stablehlo.broadcast_in_dim %54, dims = [2, 3] : (tensor<18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc80)
      %78 = stablehlo.multiply %76, %77 : tensor<4x8x18x128xf32> loc(#loc81)
      %79 = stablehlo.add %72, %78 : tensor<4x8x18x128xf32> loc(#loc82)
      %80 = stablehlo.multiply %79, %10 : tensor<4x8x18x128xf32> loc(#loc83)
      %81 = stablehlo.broadcast_in_dim %57, dims = [0, 1, 3, 4] : (tensor<4x4x18x128xf32>) -> tensor<4x4x2x18x128xf32> loc(#loc84)
      %82 = stablehlo.reshape %81 : (tensor<4x4x2x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc85)
      %83 = stablehlo.transpose %82, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "f32[4,16,128,18]{2,3,1,0}"} : (tensor<4x8x18x128xf32>) -> tensor<4x8x128x18xf32> loc(#loc86)
      %84 = stablehlo.multiply %83, %9 : tensor<4x8x128x18xf32> loc(#loc87)
      %85 = stablehlo.dot_general %80, %84, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<4x8x18x128xf32>, tensor<4x8x128x18xf32>) -> tensor<4x8x18x18xf32> loc(#loc88)
      %86 = stablehlo.broadcast_in_dim %arg32, dims = [] : (tensor<i1>) -> tensor<18x18xi1> loc(#loc89)
      %87 = stablehlo.broadcast_in_dim %c_0, dims = [1] : (tensor<18xi64>) -> tensor<18x18xi64> loc(#loc90)
      %88 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<18xi64>) -> tensor<18x18xi64> loc(#loc91)
      %89 = stablehlo.compare  LE, %87, %88 : (tensor<18x18xi64>, tensor<18x18xi64>) -> tensor<18x18xi1> loc(#loc92)
      %90 = stablehlo.and %86, %89 : tensor<18x18xi1> loc(#loc93)
      %91 = stablehlo.broadcast_in_dim %90, dims = [1, 2] : (tensor<18x18xi1>) -> tensor<4x18x18xi1> loc(#loc94)
      %92 = stablehlo.reshape %arg31 : (tensor<4x18xi64>) -> tensor<1x4x18xi64> loc(#loc95)
      %93 = stablehlo.reshape %92 : (tensor<1x4x18xi64>) -> tensor<4x18xi64> loc(#loc96)
      %94 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<i64>) -> tensor<4x18xi64> loc(#loc)
      %95 = stablehlo.compare  NE, %93, %94 : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi1> loc(#loc97)
      %96 = stablehlo.broadcast_in_dim %c_1, dims = [0] : (tensor<4xi64>) -> tensor<4x18xi64> loc(#loc98)
      %97 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<i64>) -> tensor<4x18xi64> loc(#loc)
      %98 = stablehlo.broadcast_in_dim %c_1, dims = [0] : (tensor<4xi64>) -> tensor<4x18xi64> loc(#loc98)
      %99 = stablehlo.compare  LT, %98, %97 : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi1> loc(#loc99)
      %100 = stablehlo.broadcast_in_dim %c_1, dims = [0] : (tensor<4xi64>) -> tensor<4x18xi64> loc(#loc98)
      %101 = stablehlo.add %100, %8 : tensor<4x18xi64> loc(#loc100)
      %102 = stablehlo.select %99, %101, %96 : tensor<4x18xi1>, tensor<4x18xi64> loc(#loc101)
      %103 = stablehlo.reshape %102 : (tensor<4x18xi64>) -> tensor<4x18x1xi64> loc(#loc102)
      %104 = stablehlo.broadcast_in_dim %c_0, dims = [1] : (tensor<18xi64>) -> tensor<4x18xi64> loc(#loc103)
      %105 = stablehlo.broadcast_in_dim %c_0, dims = [1] : (tensor<18xi64>) -> tensor<4x18xi64> loc(#loc103)
      %106 = stablehlo.compare  LT, %105, %12 : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi1> loc(#loc104)
      %107 = stablehlo.broadcast_in_dim %c_0, dims = [1] : (tensor<18xi64>) -> tensor<4x18xi64> loc(#loc103)
      %108 = stablehlo.add %107, %7 : tensor<4x18xi64> loc(#loc105)
      %109 = stablehlo.select %106, %108, %104 : tensor<4x18xi1>, tensor<4x18xi64> loc(#loc106)
      %110 = stablehlo.reshape %109 : (tensor<4x18xi64>) -> tensor<4x18x1xi64> loc(#loc107)
      %111 = stablehlo.concatenate %103, %110, dim = 2 : (tensor<4x18x1xi64>, tensor<4x18x1xi64>) -> tensor<4x18x2xi64> loc(#loc108)
      %112 = "stablehlo.gather"(%95, %111) <{dimension_numbers = #stablehlo.gather<collapsed_slice_dims = [0, 1], start_index_map = [0, 1], index_vector_dim = 2>, slice_sizes = array<i64: 1, 1>}> : (tensor<4x18xi1>, tensor<4x18x2xi64>) -> tensor<4x18xi1> loc(#loc109)
      %113 = stablehlo.broadcast_in_dim %112, dims = [0, 2] : (tensor<4x18xi1>) -> tensor<4x18x18xi1> loc(#loc110)
      %114 = stablehlo.and %91, %113 : tensor<4x18x18xi1> loc(#loc111)
      %115 = stablehlo.reshape %114 : (tensor<4x18x18xi1>) -> tensor<4x1x18x18xi1> loc(#loc112)
      %116 = stablehlo.select %115, %6, %5 : tensor<4x1x18x18xi1>, tensor<4x1x18x18xf32> loc(#loc113)
      %117 = stablehlo.reshape %116 : (tensor<4x1x18x18xf32>) -> tensor<4x18x18xf32> loc(#loc114)
      %118 = stablehlo.broadcast_in_dim %117, dims = [0, 2, 3] : (tensor<4x18x18xf32>) -> tensor<4x8x18x18xf32> loc(#loc115)
      %119 = stablehlo.add %85, %118 : tensor<4x8x18x18xf32> loc(#loc116)
      %120 = stablehlo.convert %119 : (tensor<4x8x18x18xf32>) -> tensor<4x8x18x18xf64> loc(#loc117)
      %121 = stablehlo.compare  EQ, %120, %4 : (tensor<4x8x18x18xf64>, tensor<4x8x18x18xf64>) -> tensor<4x8x18x18xi1> loc(#loc118)
      %122 = stablehlo.not %121 : tensor<4x8x18x18xi1> loc(#loc119)
      %123 = stablehlo.reduce(%122 init: %c_2) across dimensions = [3] : (tensor<4x8x18x18xi1>, tensor<i1>) -> tensor<4x8x18xi1>
       reducer(%arg36: tensor<i1> loc("reduce.440"), %arg37: tensor<i1> loc("reduce.440"))  {
        %209 = stablehlo.or %arg36, %arg37 : tensor<i1> loc(#loc121)
        %210 = stablehlo.select %209, %c, %c_2 : tensor<i1>, tensor<i1> loc(#loc122)
        stablehlo.return %210 : tensor<i1> loc(#loc)
      } loc(#loc120)
      %124 = stablehlo.reshape %123 : (tensor<4x8x18xi1>) -> tensor<4x8x18x1xi1> loc(#loc123)
      %125 = stablehlo.not %124 : tensor<4x8x18x1xi1> loc(#loc124)
      %126 = stablehlo.reshape %125 : (tensor<4x8x18x1xi1>) -> tensor<4x8x18xi1> loc(#loc125)
      %127 = stablehlo.broadcast_in_dim %126, dims = [0, 1, 2] : (tensor<4x8x18xi1>) -> tensor<4x8x18x18xi1> loc(#loc126)
      %128 = stablehlo.reduce(%119 init: %cst_8) applies stablehlo.maximum across dimensions = [3] : (tensor<4x8x18x18xf32>, tensor<f32>) -> tensor<4x8x18xf32> loc(#loc127)
      %129 = stablehlo.broadcast_in_dim %128, dims = [0, 1, 2] : (tensor<4x8x18xf32>) -> tensor<4x8x18x18xf32> loc(#loc128)
      %130 = stablehlo.subtract %119, %129 : tensor<4x8x18x18xf32> loc(#loc129)
      %131 = stablehlo.exponential %130 : tensor<4x8x18x18xf32> loc(#loc130)
      %132 = stablehlo.reduce(%131 init: %cst_11) applies stablehlo.add across dimensions = [3] : (tensor<4x8x18x18xf32>, tensor<f32>) -> tensor<4x8x18xf32> loc(#loc131)
      %133 = stablehlo.broadcast_in_dim %132, dims = [0, 1, 2] : (tensor<4x8x18xf32>) -> tensor<4x8x18x18xf32> loc(#loc132)
      %134 = stablehlo.divide %131, %133 : tensor<4x8x18x18xf32> loc(#loc133)
      %135 = stablehlo.select %127, %3, %134 : tensor<4x8x18x18xi1>, tensor<4x8x18x18xf32> loc(#loc134)
      %136 = stablehlo.broadcast_in_dim %30, dims = [0, 1, 3, 4] : (tensor<4x4x18x128xf32>) -> tensor<4x4x2x18x128xf32> loc(#loc135)
      %137 = stablehlo.reshape %136 : (tensor<4x4x2x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc136)
      %138 = stablehlo.dot_general %135, %137, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<4x8x18x18xf32>, tensor<4x8x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc137)
      %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[4,18,16,128]{3,1,2,0}"} : (tensor<4x8x18x128xf32>) -> tensor<4x18x8x128xf32> loc(#loc138)
      %140 = stablehlo.reshape %139 : (tensor<4x18x8x128xf32>) -> tensor<72x1024xf32> loc(#loc139)
      %141 = stablehlo.reshape %arg30 : (tensor<1024x1024xf32>) -> tensor<1x1024x1024xf32> loc(#loc140)
      %142 = stablehlo.reshape %141 : (tensor<1x1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc141)
      %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[2048,1024]{0,1}"} : (tensor<1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc142)
      %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x1024xf32>) -> tensor<72x1024xf32> loc(#loc143)
      %145 = "stablehlo.all_reduce"(%144) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg36: tensor<f32> loc("dot.456"), %arg37: tensor<f32> loc("dot.456")):
        %209 = stablehlo.add %arg36, %arg37 : tensor<f32> loc(#loc143)
        stablehlo.return %209 : tensor<f32> loc(#loc143)
      }) : (tensor<72x1024xf32>) -> tensor<72x1024xf32> loc(#loc143)
      %146 = stablehlo.reshape %145 : (tensor<72x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc144)
      %147 = stablehlo.add %20, %146 : tensor<4x18x1024xf32> loc(#loc145)
      %148 = stablehlo.reshape %arg29 : (tensor<1024xf32>) -> tensor<1x1x1024xf32> loc(#loc146)
      %149 = stablehlo.reshape %148 : (tensor<1x1x1024xf32>) -> tensor<1024xf32> loc(#loc147)
      %150 = stablehlo.composite "tenstorrent.rms_norm" %147, %149 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, decomposition = @outlined_composite_tenstorrent.rms_norm.impl_0} : (tensor<4x18x1024xf32>, tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc)
      %151 = stablehlo.reshape %150 : (tensor<4x18x1024xf32>) -> tensor<72x1024xf32> loc(#loc148)
      %152 = stablehlo.reshape %arg35 : (tensor<1536x1024xf32>) -> tensor<1x1536x1024xf32> loc(#loc149)
      %153 = stablehlo.reshape %152 : (tensor<1x1536x1024xf32>) -> tensor<1536x1024xf32> loc(#loc150)
      %154 = stablehlo.transpose %153, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,3072]{0,1}"} : (tensor<1536x1024xf32>) -> tensor<1024x1536xf32> loc(#loc151)
      %155 = stablehlo.dot_general %151, %154, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x1536xf32>) -> tensor<72x1536xf32> loc(#loc152)
      %156 = stablehlo.reshape %155 : (tensor<72x1536xf32>) -> tensor<4x18x1536xf32> loc(#loc153)
      %157 = stablehlo.logistic %156 : tensor<4x18x1536xf32> loc(#loc154)
      %158 = stablehlo.multiply %156, %157 : tensor<4x18x1536xf32> loc(#loc155)
      %159 = stablehlo.reshape %arg28 : (tensor<1536x1024xf32>) -> tensor<1x1536x1024xf32> loc(#loc156)
      %160 = stablehlo.reshape %159 : (tensor<1x1536x1024xf32>) -> tensor<1536x1024xf32> loc(#loc157)
      %161 = stablehlo.transpose %160, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,3072]{0,1}"} : (tensor<1536x1024xf32>) -> tensor<1024x1536xf32> loc(#loc158)
      %162 = stablehlo.dot_general %151, %161, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x1536xf32>) -> tensor<72x1536xf32> loc(#loc159)
      %163 = stablehlo.reshape %162 : (tensor<72x1536xf32>) -> tensor<4x18x1536xf32> loc(#loc160)
      %164 = stablehlo.multiply %158, %163 : tensor<4x18x1536xf32> loc(#loc161)
      %165 = stablehlo.reshape %164 : (tensor<4x18x1536xf32>) -> tensor<72x1536xf32> loc(#loc162)
      %166 = stablehlo.reshape %arg27 : (tensor<1024x1536xf32>) -> tensor<1x1024x1536xf32> loc(#loc163)
      %167 = stablehlo.reshape %166 : (tensor<1x1024x1536xf32>) -> tensor<1024x1536xf32> loc(#loc164)
      %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[3072,1024]{0,1}"} : (tensor<1024x1536xf32>) -> tensor<1536x1024xf32> loc(#loc165)
      %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] : (tensor<72x1536xf32>, tensor<1536x1024xf32>) -> tensor<72x1024xf32> loc(#loc166)
      %170 = "stablehlo.all_reduce"(%169) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg36: tensor<f32> loc("dot.507"), %arg37: tensor<f32> loc("dot.507")):
        %209 = stablehlo.add %arg36, %arg37 : tensor<f32> loc(#loc166)
        stablehlo.return %209 : tensor<f32> loc(#loc166)
      }) : (tensor<72x1024xf32>) -> tensor<72x1024xf32> loc(#loc166)
      %171 = stablehlo.reshape %170 : (tensor<72x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc167)
      %172 = stablehlo.add %147, %171 : tensor<4x18x1024xf32> loc(#loc168)
      %173 = stablehlo.reshape %arg26 : (tensor<1024xf32>) -> tensor<1x1x1024xf32> loc(#loc169)
      %174 = stablehlo.reshape %173 : (tensor<1x1x1024xf32>) -> tensor<1024xf32> loc(#loc170)
      %175 = stablehlo.composite "tenstorrent.rms_norm" %172, %174 {composite_attributes = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, decomposition = @outlined_composite_tenstorrent.rms_norm.impl} : (tensor<4x18x1024xf32>, tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc)
      %176 = stablehlo.reshape %175 : (tensor<4x18x1024xf32>) -> tensor<72x1024xf32> loc(#loc171)
      %177 = stablehlo.reshape %arg25 : (tensor<75968x1024xf32>) -> tensor<1x75968x1024xf32> loc(#loc172)
      %178 = stablehlo.reshape %177 : (tensor<1x75968x1024xf32>) -> tensor<75968x1024xf32> loc(#loc173)
      %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[1024,151936]{0,1}"} : (tensor<75968x1024xf32>) -> tensor<1024x75968xf32> loc(#loc174)
      %180 = stablehlo.dot_general %176, %179, contracting_dims = [1] x [0] : (tensor<72x1024xf32>, tensor<1024x75968xf32>) -> tensor<72x75968xf32> loc(#loc175)
      %181 = stablehlo.reshape %180 : (tensor<72x75968xf32>) -> tensor<4x18x75968xf32> loc(#loc176)
      %182 = stablehlo.reduce(%180 init: %cst) applies stablehlo.maximum across dimensions = [1] : (tensor<72x75968xf32>, tensor<f32>) -> tensor<72xf32> loc(#loc177)
      %183 = "stablehlo.all_reduce"(%182) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg36: tensor<f32> loc("reduce.553"), %arg37: tensor<f32> loc("reduce.553")):
        %209 = stablehlo.add %arg36, %arg37 : tensor<f32> loc(#loc177)
        stablehlo.return %209 : tensor<f32> loc(#loc177)
      }) : (tensor<72xf32>) -> tensor<72xf32> loc(#loc177)
      %184 = stablehlo.broadcast_in_dim %183, dims = [0] : (tensor<72xf32>) -> tensor<72x75968xf32> loc(#loc178)
      %185 = stablehlo.subtract %180, %184 : tensor<72x75968xf32> loc(#loc179)
      %186 = stablehlo.exponential %185 : tensor<72x75968xf32> loc(#loc180)
      %187 = stablehlo.reduce(%186 init: %cst_11) applies stablehlo.add across dimensions = [1] : (tensor<72x75968xf32>, tensor<f32>) -> tensor<72xf32> loc(#loc181)
      %188 = "stablehlo.all_reduce"(%187) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg36: tensor<f32> loc("reduce.567"), %arg37: tensor<f32> loc("reduce.567")):
        %209 = stablehlo.add %arg36, %arg37 : tensor<f32> loc(#loc181)
        stablehlo.return %209 : tensor<f32> loc(#loc181)
      }) : (tensor<72xf32>) -> tensor<72xf32> loc(#loc181)
      %189 = stablehlo.reshape %188 : (tensor<72xf32>) -> tensor<72x1xf32> loc(#loc182)
      %190 = stablehlo.log %189 : tensor<72x1xf32> loc(#loc183)
      %191 = stablehlo.reshape %190 : (tensor<72x1xf32>) -> tensor<72xf32> loc(#loc184)
      %192 = stablehlo.broadcast_in_dim %191, dims = [0] : (tensor<72xf32>) -> tensor<72x75968xf32> loc(#loc185)
      %193 = stablehlo.subtract %185, %192 : tensor<72x75968xf32> loc(#loc186)
      %194 = stablehlo.iota dim = 0 : tensor<72xui32> loc(#loc187)
      %195 = stablehlo.reshape %194 : (tensor<72xui32>) -> tensor<72x1x1xui32> loc(#loc187)
      %196 = stablehlo.select %61, %60, %2 : tensor<72xi1>, tensor<72xi64> loc(#loc188)
      %197 = stablehlo.reshape %196 : (tensor<72xi64>) -> tensor<72x1xi64> loc(#loc189)
      %198 = stablehlo.convert %197 : (tensor<72x1xi64>) -> tensor<72x1xui32> loc(#loc190)
      %199 = stablehlo.reshape %198 : (tensor<72x1xui32>) -> tensor<72x1x1xui32> loc(#loc191)
      %200 = stablehlo.concatenate %195, %199, dim = 2 : (tensor<72x1x1xui32>, tensor<72x1x1xui32>) -> tensor<72x1x2xui32> loc(#loc192)
      %201 = "stablehlo.gather"(%193, %200) <{dimension_numbers = #stablehlo.gather<collapsed_slice_dims = [0, 1], start_index_map = [0, 1], index_vector_dim = 2>, slice_sizes = array<i64: 1, 1>}> : (tensor<72x75968xf32>, tensor<72x1x2xui32>) -> tensor<72x1xf32> loc(#loc193)
      %202 = "stablehlo.all_reduce"(%201) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg36: tensor<f32> loc("gather.579"), %arg37: tensor<f32> loc("gather.579")):
        %209 = stablehlo.add %arg36, %arg37 : tensor<f32> loc(#loc193)
        stablehlo.return %209 : tensor<f32> loc(#loc193)
      }) : (tensor<72x1xf32>) -> tensor<72x1xf32> loc(#loc193)
      %203 = stablehlo.reshape %202 : (tensor<72x1xf32>) -> tensor<72xf32> loc(#loc194)
      %204 = stablehlo.negate %203 : tensor<72xf32> loc(#loc195)
      %205 = stablehlo.select %61, %204, %1 : tensor<72xi1>, tensor<72xf32> loc(#loc196)
      %206 = stablehlo.convert %61 : (tensor<72xi1>) -> tensor<72xi64> loc(#loc197)
      %207 = stablehlo.convert %206 : (tensor<72xi64>) -> tensor<72xf32> loc(#loc198)
      %208 = stablehlo.divide %205, %207 : tensor<72xf32> loc(#loc199)
      sdy.return %30, %57, %208, %181 : tensor<4x4x18x128xf32>, tensor<4x4x18x128xf32>, tensor<72xf32>, tensor<4x18x75968xf32> loc(#loc)
    } : (tensor<1024x1024xf32>, tensor<1024xf32>, tensor<4x18xi64>, tensor<151936x1024xf32>, tensor<64xf32>, tensor<128xf32>, tensor<1024x1024xf32>, tensor<151936x1024xf32>, tensor<1024xf32>, tensor<1024x3072xf32>, tensor<3072x1024xf32>, tensor<1024xf32>, tensor<1024x2048xf32>, tensor<4x18xi64>, tensor<i1>, tensor<128xf32>, tensor<2048x1024xf32>, tensor<3072x1024xf32>) -> (tensor<4x8x18x128xf32>, tensor<4x8x18x128xf32>, tensor<72xf32>, tensor<4x18x151936xf32>) loc(#loc)
    return %0#0, %0#1, %0#2, %0#3 : tensor<4x8x18x128xf32>, tensor<4x8x18x128xf32>, tensor<72xf32>, tensor<4x18x151936xf32> loc(#loc)
  } loc(#loc)
  func.func private @outlined_composite_tenstorrent.rms_norm.impl_1(%arg0: tensor<4x18x8x128xf32> loc(unknown), %arg1: tensor<128xf32> loc(unknown)) -> tensor<4x18x8x128xf32> {
    %cst = stablehlo.constant {reoutline.comp_attrs = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<128> : tensor<1xi64>}, reoutline.orig_name = "tenstorrent.rms_norm"} dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<7.812500e-03> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x8x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18x8xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x8x128xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x8x128xf32> loc(#loc200)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x18x8x128xf32>, tensor<f32>) -> tensor<4x18x8xf32> loc(#loc201)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18x8xf32> loc(#loc202)
    %6 = stablehlo.reshape %5 : (tensor<4x18x8xf32>) -> tensor<4x18x8x1xf32> loc(#loc203)
    %7 = stablehlo.add %6, %0 : tensor<4x18x8x1xf32> loc(#loc204)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x8x1xf32> loc(#loc205)
    %9 = stablehlo.reshape %8 : (tensor<4x18x8x1xf32>) -> tensor<4x18x8xf32> loc(#loc206)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1, 2] : (tensor<4x18x8xf32>) -> tensor<4x18x8x128xf32> loc(#loc207)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x8x128xf32> loc(#loc208)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [3] : (tensor<128xf32>) -> tensor<4x18x8x128xf32> loc(#loc209)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x8x128xf32> loc(#loc210)
    return %13 : tensor<4x18x8x128xf32> loc(#loc)
  } loc(#loc)
  func.func private @outlined_composite_tenstorrent.rms_norm.impl_2(%arg0: tensor<4x18x4x128xf32> loc(unknown), %arg1: tensor<128xf32> loc(unknown)) -> tensor<4x18x4x128xf32> {
    %cst = stablehlo.constant {reoutline.comp_attrs = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<128> : tensor<1xi64>}, reoutline.orig_name = "tenstorrent.rms_norm"} dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<7.812500e-03> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x4x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18x4xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x4x128xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x4x128xf32> loc(#loc211)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x18x4x128xf32>, tensor<f32>) -> tensor<4x18x4xf32> loc(#loc212)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18x4xf32> loc(#loc213)
    %6 = stablehlo.reshape %5 : (tensor<4x18x4xf32>) -> tensor<4x18x4x1xf32> loc(#loc214)
    %7 = stablehlo.add %6, %0 : tensor<4x18x4x1xf32> loc(#loc215)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x4x1xf32> loc(#loc216)
    %9 = stablehlo.reshape %8 : (tensor<4x18x4x1xf32>) -> tensor<4x18x4xf32> loc(#loc217)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1, 2] : (tensor<4x18x4xf32>) -> tensor<4x18x4x128xf32> loc(#loc218)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x4x128xf32> loc(#loc219)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [3] : (tensor<128xf32>) -> tensor<4x18x4x128xf32> loc(#loc220)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x4x128xf32> loc(#loc221)
    return %13 : tensor<4x18x4x128xf32> loc(#loc)
  } loc(#loc)
  func.func private @outlined_composite_tenstorrent.rms_norm.impl(%arg0: tensor<4x18x1024xf32> loc(unknown), %arg1: tensor<1024xf32> loc(unknown)) -> tensor<4x18x1024xf32> {
    %cst = stablehlo.constant {reoutline.comp_attrs = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, reoutline.orig_name = "tenstorrent.rms_norm"} dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<9.765625E-4> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x1024xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x1024xf32> loc(#loc222)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x18x1024xf32>, tensor<f32>) -> tensor<4x18xf32> loc(#loc223)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18xf32> loc(#loc224)
    %6 = stablehlo.reshape %5 : (tensor<4x18xf32>) -> tensor<4x18x1xf32> loc(#loc225)
    %7 = stablehlo.add %6, %0 : tensor<4x18x1xf32> loc(#loc226)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x1xf32> loc(#loc227)
    %9 = stablehlo.reshape %8 : (tensor<4x18x1xf32>) -> tensor<4x18xf32> loc(#loc228)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1] : (tensor<4x18xf32>) -> tensor<4x18x1024xf32> loc(#loc229)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x1024xf32> loc(#loc230)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc231)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x1024xf32> loc(#loc232)
    return %13 : tensor<4x18x1024xf32> loc(#loc)
  } loc(#loc)
  func.func private @outlined_composite_tenstorrent.rms_norm.impl_0(%arg0: tensor<4x18x1024xf32> loc(unknown), %arg1: tensor<1024xf32> loc(unknown)) -> tensor<4x18x1024xf32> {
    %cst = stablehlo.constant {reoutline.comp_attrs = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, reoutline.orig_name = "tenstorrent.rms_norm"} dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<9.765625E-4> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x1024xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x1024xf32> loc(#loc233)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x18x1024xf32>, tensor<f32>) -> tensor<4x18xf32> loc(#loc234)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18xf32> loc(#loc235)
    %6 = stablehlo.reshape %5 : (tensor<4x18xf32>) -> tensor<4x18x1xf32> loc(#loc236)
    %7 = stablehlo.add %6, %0 : tensor<4x18x1xf32> loc(#loc237)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x1xf32> loc(#loc238)
    %9 = stablehlo.reshape %8 : (tensor<4x18x1xf32>) -> tensor<4x18xf32> loc(#loc239)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1] : (tensor<4x18xf32>) -> tensor<4x18x1024xf32> loc(#loc240)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x1024xf32> loc(#loc241)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc242)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x1024xf32> loc(#loc243)
    return %13 : tensor<4x18x1024xf32> loc(#loc)
  } loc(#loc)
  func.func private @outlined_composite_tenstorrent.rms_norm.impl_3(%arg0: tensor<4x18x1024xf32> loc(unknown), %arg1: tensor<1024xf32> loc(unknown)) -> tensor<4x18x1024xf32> {
    %cst = stablehlo.constant {reoutline.comp_attrs = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, reoutline.orig_name = "tenstorrent.rms_norm"} dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<9.765625E-4> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x1024xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x1024xf32> loc(#loc244)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x18x1024xf32>, tensor<f32>) -> tensor<4x18xf32> loc(#loc245)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18xf32> loc(#loc246)
    %6 = stablehlo.reshape %5 : (tensor<4x18xf32>) -> tensor<4x18x1xf32> loc(#loc247)
    %7 = stablehlo.add %6, %0 : tensor<4x18x1xf32> loc(#loc248)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x1xf32> loc(#loc249)
    %9 = stablehlo.reshape %8 : (tensor<4x18x1xf32>) -> tensor<4x18xf32> loc(#loc250)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1] : (tensor<4x18xf32>) -> tensor<4x18x1024xf32> loc(#loc251)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x1024xf32> loc(#loc252)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc253)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x1024xf32> loc(#loc254)
    return %13 : tensor<4x18x1024xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc19 = loc("reshape.20")
#loc20 = loc("reshape.22")
#loc21 = loc("reshape.15")
#loc22 = loc("reshape.17")
#loc23 = loc("reshape.18")
#loc24 = loc("convert.23")
#loc25 = loc("gather.24")
#loc26 = loc("reshape.25")
#loc27 = loc("reshape.7")
#loc28 = loc("reshape.9")
#loc29 = loc("reshape.57")
#loc30 = loc("reshape.2")
#loc31 = loc("reshape.4")
#loc32 = loc("transpose.5")
#loc33 = loc("dot.58")
#loc34 = loc("reshape.60")
#loc35 = loc("transpose.61")
#loc36 = loc("reshape.94")
#loc37 = loc("reshape.96")
#loc38 = loc("transpose.97")
#loc39 = loc("dot.99")
#loc40 = loc("reshape.101")
#loc41 = loc("reshape.86")
#loc42 = loc("reshape.88")
#loc43 = loc("transpose.133")
#loc44 = loc("reshape.71")
#loc45 = loc("reshape.75")
#loc46 = loc("dot.78")
#loc47 = loc("transpose.79")
#loc48 = loc("concatenate.80")
#loc49 = loc("cosine.142")
#loc50 = loc("reshape.146")
#loc51 = loc("broadcast.147")
#loc52 = loc("multiply.148")
#loc53 = loc("slice.135")
#loc54 = loc("negate.136")
#loc55 = loc("slice.134")
#loc56 = loc("concatenate.137")
#loc57 = loc("sine.81")
#loc58 = loc("reshape.138")
#loc59 = loc("broadcast.139")
#loc60 = loc("multiply.140")
#loc61 = loc("add.151")
#loc62 = loc("pad.155")
#loc63 = loc("slice.156")
#loc64 = loc("reshape.157")
#loc65 = loc("compare.585")
#loc66 = loc("reshape.337")
#loc67 = loc("reshape.339")
#loc68 = loc("transpose.340")
#loc69 = loc("dot.342")
#loc70 = loc("reshape.344")
#loc71 = loc("reshape.329")
#loc72 = loc("reshape.331")
#loc73 = loc("transpose.376")
#loc74 = loc("broadcast.385")
#loc75 = loc("multiply.386")
#loc76 = loc("slice.378")
#loc77 = loc("negate.379")
#loc78 = loc("slice.377")
#loc79 = loc("concatenate.380")
#loc80 = loc("broadcast.382")
#loc81 = loc("multiply.383")
#loc82 = loc("add.389")
#loc83 = loc("multiply.391")
#loc84 = loc("broadcast.321")
#loc85 = loc("reshape.322")
#loc86 = loc("transpose.323")
#loc87 = loc("multiply.325")
#loc88 = loc("dot.392")
#loc89 = loc("broadcast.305")
#loc90 = loc("broadcast.292")
#loc91 = loc("broadcast.294")
#loc92 = loc("compare.295")
#loc93 = loc("and.306")
#loc94 = loc("broadcast.309")
#loc95 = loc("reshape.285")
#loc96 = loc("reshape.287")
#loc97 = loc("convert.288")
#loc98 = loc("broadcast.270")
#loc99 = loc("compare.279")
#loc100 = loc("add.276")
#loc101 = loc("select.280")
#loc102 = loc("reshape.281")
#loc103 = loc("broadcast.255")
#loc104 = loc("compare.264")
#loc105 = loc("add.261")
#loc106 = loc("select.265")
#loc107 = loc("reshape.282")
#loc108 = loc("concatenate.283")
#loc109 = loc("gather.289")
#loc110 = loc("broadcast.311")
#loc111 = loc("and.312")
#loc112 = loc("reshape.313")
#loc113 = loc("select.316")
#loc114 = loc("reshape.396")
#loc115 = loc("broadcast.397")
#loc116 = loc("add.398")
#loc117 = loc("convert.424")
#loc118 = loc("compare.426")
#loc119 = loc("not.428")
#loc121 = loc("or.438")
#loc122 = loc("select.439")
#loc123 = loc("reshape.444")
#loc124 = loc("not.446")
#loc125 = loc("reshape.448")
#loc126 = loc("broadcast.449")
#loc127 = loc("reduce.404")
#loc128 = loc("broadcast.405")
#loc129 = loc("subtract.406")
#loc130 = loc("exponential.407")
#loc131 = loc("reduce.413")
#loc132 = loc("broadcast.414")
#loc133 = loc("divide.415")
#loc134 = loc("select.450")
#loc135 = loc("broadcast.231")
#loc136 = loc("reshape.232")
#loc137 = loc("dot.451")
#loc138 = loc("transpose.453")
#loc139 = loc("reshape.455")
#loc140 = loc("reshape.224")
#loc141 = loc("reshape.226")
#loc142 = loc("transpose.227")
#loc144 = loc("reshape.457")
#loc145 = loc("add.460")
#loc146 = loc("reshape.215")
#loc147 = loc("reshape.217")
#loc148 = loc("reshape.500")
#loc149 = loc("reshape.496")
#loc150 = loc("reshape.498")
#loc151 = loc("transpose.499")
#loc152 = loc("dot.501")
#loc153 = loc("reshape.502")
#loc154 = loc("logistic.503")
#loc155 = loc("multiply.504")
#loc156 = loc("reshape.210")
#loc157 = loc("reshape.212")
#loc158 = loc("transpose.213")
#loc159 = loc("dot.493")
#loc160 = loc("reshape.494")
#loc161 = loc("multiply.505")
#loc162 = loc("reshape.506")
#loc163 = loc("reshape.205")
#loc164 = loc("reshape.207")
#loc165 = loc("transpose.208")
#loc167 = loc("reshape.508")
#loc168 = loc("add.511")
#loc169 = loc("reshape.196")
#loc170 = loc("reshape.198")
#loc171 = loc("reshape.543")
#loc172 = loc("reshape.191")
#loc173 = loc("reshape.193")
#loc174 = loc("transpose.194")
#loc175 = loc("dot.544")
#loc176 = loc("reshape.545")
#loc178 = loc("broadcast.558")
#loc179 = loc("subtract.559")
#loc180 = loc("exponential.560")
#loc182 = loc("reshape.568")
#loc183 = loc("log.569")
#loc184 = loc("reshape.572")
#loc185 = loc("broadcast.573")
#loc186 = loc("subtract.574")
#loc187 = loc("iota.576")
#loc188 = loc("select.186")
#loc189 = loc("reshape.187")
#loc190 = loc("convert.575")
#loc191 = loc("reshape.577")
#loc192 = loc("concatenate.578")
#loc194 = loc("reshape.580")
#loc195 = loc("negate.581")
#loc196 = loc("select.587")
#loc197 = loc("convert.160")
#loc198 = loc("convert.168")
#loc199 = loc("divide.595")
#loc200 = loc("power.347")
#loc201 = loc("reduce.354")
#loc202 = loc("multiply.363")
#loc203 = loc("reshape.364")
#loc204 = loc("add.368")
#loc205 = loc("rsqrt.369")
#loc206 = loc("reshape.370")
#loc207 = loc("broadcast.371")
#loc208 = loc("multiply.372")
#loc209 = loc("broadcast.373")
#loc210 = loc("multiply.374")
#loc211 = loc("power.104")
#loc212 = loc("reduce.111")
#loc213 = loc("multiply.120")
#loc214 = loc("reshape.121")
#loc215 = loc("add.125")
#loc216 = loc("rsqrt.126")
#loc217 = loc("reshape.127")
#loc218 = loc("broadcast.128")
#loc219 = loc("multiply.129")
#loc220 = loc("broadcast.130")
#loc221 = loc("multiply.131")
#loc222 = loc("power.514")
#loc223 = loc("reduce.521")
#loc224 = loc("multiply.530")
#loc225 = loc("reshape.531")
#loc226 = loc("add.535")
#loc227 = loc("rsqrt.536")
#loc228 = loc("reshape.537")
#loc229 = loc("broadcast.538")
#loc230 = loc("multiply.539")
#loc231 = loc("broadcast.540")
#loc232 = loc("multiply.541")
#loc233 = loc("power.463")
#loc234 = loc("reduce.470")
#loc235 = loc("multiply.479")
#loc236 = loc("reshape.480")
#loc237 = loc("add.484")
#loc238 = loc("rsqrt.485")
#loc239 = loc("reshape.486")
#loc240 = loc("broadcast.487")
#loc241 = loc("multiply.488")
#loc242 = loc("broadcast.489")
#loc243 = loc("multiply.490")
#loc244 = loc("power.28")
#loc245 = loc("reduce.35")
#loc246 = loc("multiply.44")
#loc247 = loc("reshape.45")
#loc248 = loc("add.49")
#loc249 = loc("rsqrt.50")
#loc250 = loc("reshape.51")
#loc251 = loc("broadcast.52")
#loc252 = loc("multiply.53")
#loc253 = loc("broadcast.54")
#loc254 = loc("multiply.55")
------------------ END OF MLIR MODULE ------------------
2026-01-28 22:12:58.659 (   5.826s) [        66B35000]      module_builder.cc:294      1| SHLO compiler pipeline run completed - is using shardy output shardings: 1
2026-01-28 22:12:58.668 (   5.835s) [        66B35000]      module_builder.cc:1111     1| MLIR Module shlo_compiler_cleaned:
#loc = loc(unknown)
module @SyncTensorsGraph.597 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{devices=[1,2,1,1]<=[2]},{devices=[1,2,1,1]<=[2]},{replicated},{devices=[1,1,2]<=[2]}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1024x1024xf32> loc(unknown), %arg1: tensor<1024xf32> loc(unknown), %arg2: tensor<4x18xi64> loc(unknown), %arg3: tensor<151936x1024xf32> loc(unknown), %arg4: tensor<64xf32> loc(unknown), %arg5: tensor<128xf32> loc(unknown), %arg6: tensor<1024x1024xf32> loc(unknown), %arg7: tensor<151936x1024xf32> loc(unknown), %arg8: tensor<1024xf32> loc(unknown), %arg9: tensor<1024x3072xf32> loc(unknown), %arg10: tensor<3072x1024xf32> loc(unknown), %arg11: tensor<1024xf32> loc(unknown), %arg12: tensor<1024x2048xf32> loc(unknown), %arg13: tensor<4x18xi64> loc(unknown), %arg14: tensor<i1> loc(unknown), %arg15: tensor<128xf32> loc(unknown), %arg16: tensor<2048x1024xf32> loc(unknown), %arg17: tensor<3072x1024xf32> loc(unknown)) -> (tensor<4x8x18x128xf32>, tensor<4x8x18x128xf32>, tensor<72xf32>, tensor<4x18x151936xf32>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<4x8x18x128xf32> loc(#loc)
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<4x8x18x128xf32> loc(#loc)
    %cst_1 = stablehlo.constant dense<0.000000e+00> : tensor<72xf32> loc(#loc)
    %cst_2 = stablehlo.constant dense<0.000000e+00> : tensor<4x18x151936xf32> loc(#loc)
    return %cst, %cst_0, %cst_1, %cst_2 : tensor<4x8x18x128xf32>, tensor<4x8x18x128xf32>, tensor<72xf32>, tensor<4x18x151936xf32> loc(#loc)
  } loc(#loc)
  func.func private @outlined_composite_tenstorrent.rms_norm.impl_1(%arg0: tensor<4x18x8x128xf32> loc(unknown), %arg1: tensor<128xf32> loc(unknown)) -> tensor<4x18x8x128xf32> {
    %cst = stablehlo.constant {reoutline.comp_attrs = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<128> : tensor<1xi64>}, reoutline.orig_name = "tenstorrent.rms_norm"} dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<7.812500e-03> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x8x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18x8xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x8x128xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x8x128xf32> loc(#loc)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x18x8x128xf32>, tensor<f32>) -> tensor<4x18x8xf32> loc(#loc)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18x8xf32> loc(#loc)
    %6 = stablehlo.reshape %5 : (tensor<4x18x8xf32>) -> tensor<4x18x8x1xf32> loc(#loc)
    %7 = stablehlo.add %6, %0 : tensor<4x18x8x1xf32> loc(#loc)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x8x1xf32> loc(#loc)
    %9 = stablehlo.reshape %8 : (tensor<4x18x8x1xf32>) -> tensor<4x18x8xf32> loc(#loc)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1, 2] : (tensor<4x18x8xf32>) -> tensor<4x18x8x128xf32> loc(#loc)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x8x128xf32> loc(#loc)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [3] : (tensor<128xf32>) -> tensor<4x18x8x128xf32> loc(#loc)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x8x128xf32> loc(#loc)
    return %13 : tensor<4x18x8x128xf32> loc(#loc)
  } loc(#loc)
  func.func private @outlined_composite_tenstorrent.rms_norm.impl_2(%arg0: tensor<4x18x4x128xf32> loc(unknown), %arg1: tensor<128xf32> loc(unknown)) -> tensor<4x18x4x128xf32> {
    %cst = stablehlo.constant {reoutline.comp_attrs = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<128> : tensor<1xi64>}, reoutline.orig_name = "tenstorrent.rms_norm"} dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<7.812500e-03> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x4x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18x4xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x4x128xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x4x128xf32> loc(#loc)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<4x18x4x128xf32>, tensor<f32>) -> tensor<4x18x4xf32> loc(#loc)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18x4xf32> loc(#loc)
    %6 = stablehlo.reshape %5 : (tensor<4x18x4xf32>) -> tensor<4x18x4x1xf32> loc(#loc)
    %7 = stablehlo.add %6, %0 : tensor<4x18x4x1xf32> loc(#loc)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x4x1xf32> loc(#loc)
    %9 = stablehlo.reshape %8 : (tensor<4x18x4x1xf32>) -> tensor<4x18x4xf32> loc(#loc)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1, 2] : (tensor<4x18x4xf32>) -> tensor<4x18x4x128xf32> loc(#loc)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x4x128xf32> loc(#loc)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [3] : (tensor<128xf32>) -> tensor<4x18x4x128xf32> loc(#loc)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x4x128xf32> loc(#loc)
    return %13 : tensor<4x18x4x128xf32> loc(#loc)
  } loc(#loc)
  func.func private @outlined_composite_tenstorrent.rms_norm.impl(%arg0: tensor<4x18x1024xf32> loc(unknown), %arg1: tensor<1024xf32> loc(unknown)) -> tensor<4x18x1024xf32> {
    %cst = stablehlo.constant {reoutline.comp_attrs = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, reoutline.orig_name = "tenstorrent.rms_norm"} dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<9.765625E-4> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x1024xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x1024xf32> loc(#loc)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x18x1024xf32>, tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18xf32> loc(#loc)
    %6 = stablehlo.reshape %5 : (tensor<4x18xf32>) -> tensor<4x18x1xf32> loc(#loc)
    %7 = stablehlo.add %6, %0 : tensor<4x18x1xf32> loc(#loc)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x1xf32> loc(#loc)
    %9 = stablehlo.reshape %8 : (tensor<4x18x1xf32>) -> tensor<4x18xf32> loc(#loc)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1] : (tensor<4x18xf32>) -> tensor<4x18x1024xf32> loc(#loc)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x1024xf32> loc(#loc)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x1024xf32> loc(#loc)
    return %13 : tensor<4x18x1024xf32> loc(#loc)
  } loc(#loc)
  func.func private @outlined_composite_tenstorrent.rms_norm.impl_0(%arg0: tensor<4x18x1024xf32> loc(unknown), %arg1: tensor<1024xf32> loc(unknown)) -> tensor<4x18x1024xf32> {
    %cst = stablehlo.constant {reoutline.comp_attrs = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, reoutline.orig_name = "tenstorrent.rms_norm"} dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<9.765625E-4> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x1024xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x1024xf32> loc(#loc)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x18x1024xf32>, tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18xf32> loc(#loc)
    %6 = stablehlo.reshape %5 : (tensor<4x18xf32>) -> tensor<4x18x1xf32> loc(#loc)
    %7 = stablehlo.add %6, %0 : tensor<4x18x1xf32> loc(#loc)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x1xf32> loc(#loc)
    %9 = stablehlo.reshape %8 : (tensor<4x18x1xf32>) -> tensor<4x18xf32> loc(#loc)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1] : (tensor<4x18xf32>) -> tensor<4x18x1024xf32> loc(#loc)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x1024xf32> loc(#loc)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x1024xf32> loc(#loc)
    return %13 : tensor<4x18x1024xf32> loc(#loc)
  } loc(#loc)
  func.func private @outlined_composite_tenstorrent.rms_norm.impl_3(%arg0: tensor<4x18x1024xf32> loc(unknown), %arg1: tensor<1024xf32> loc(unknown)) -> tensor<4x18x1024xf32> {
    %cst = stablehlo.constant {reoutline.comp_attrs = {epsilon = 9.99999997E-7 : f32, normalized_shape = dense<1024> : tensor<1xi64>}, reoutline.orig_name = "tenstorrent.rms_norm"} dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<9.765625E-4> : tensor<f32> loc(#loc)
    %cst_2 = stablehlo.constant dense<9.99999997E-7> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<4x18x1xf32> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<4x18x1024xf32> loc(#loc)
    %3 = stablehlo.power %arg0, %2 : tensor<4x18x1024xf32> loc(#loc)
    %4 = stablehlo.reduce(%3 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<4x18x1024xf32>, tensor<f32>) -> tensor<4x18xf32> loc(#loc)
    %5 = stablehlo.multiply %4, %1 : tensor<4x18xf32> loc(#loc)
    %6 = stablehlo.reshape %5 : (tensor<4x18xf32>) -> tensor<4x18x1xf32> loc(#loc)
    %7 = stablehlo.add %6, %0 : tensor<4x18x1xf32> loc(#loc)
    %8 = stablehlo.rsqrt %7 : tensor<4x18x1xf32> loc(#loc)
    %9 = stablehlo.reshape %8 : (tensor<4x18x1xf32>) -> tensor<4x18xf32> loc(#loc)
    %10 = stablehlo.broadcast_in_dim %9, dims = [0, 1] : (tensor<4x18xf32>) -> tensor<4x18x1024xf32> loc(#loc)
    %11 = stablehlo.multiply %arg0, %10 : tensor<4x18x1024xf32> loc(#loc)
    %12 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc)
    %13 = stablehlo.multiply %11, %12 : tensor<4x18x1024xf32> loc(#loc)
    return %13 : tensor<4x18x1024xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
------------------ END OF MLIR MODULE ------------------
2026-01-28 22:12:58.721 (   5.888s) [        66B35000]      module_builder.cc:1111     1| MLIR Module ttir:
#loc1 = loc("p0.1")
#loc2 = loc("p1.6")
#loc3 = loc("p2.14")
#loc4 = loc("p3.19")
#loc5 = loc("p4.70")
#loc6 = loc("p5.85")
#loc7 = loc("p6.93")
#loc8 = loc("p7.190")
#loc9 = loc("p8.195")
#loc10 = loc("p9.204")
#loc11 = loc("p10.209")
#loc12 = loc("p11.214")
#loc13 = loc("p12.223")
#loc14 = loc("p13.284")
#loc15 = loc("p14.296")
#loc16 = loc("p15.328")
#loc17 = loc("p16.336")
#loc18 = loc("p17.495")
module @SyncTensorsGraph.597 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.597 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
      func.func @main(%arg0: tensor<1024x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<512x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p0.1"), %arg1: tensor<1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024xf32>>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p1.6"), %arg2: tensor<4x18xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<4x18xi64>>, ttir.name = "args_0"} loc("p2.14"), %arg3: tensor<151936x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<151936x1024xf32>>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p3.19"), %arg4: tensor<64xf32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<64xf32>>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p4.70"), %arg5: tensor<128xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<128xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_norm_weight"} loc("p5.85"), %arg6: tensor<1024x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<512x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p6.93"), %arg7: tensor<151936x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<75968x1024xf32>>, ttir.name = "l__self___lm_head_weight"} loc("p7.190"), %arg8: tensor<1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024xf32>>, ttir.name = "l__self___model_norm_weight"} loc("p8.195"), %arg9: tensor<1024x3072xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024x1536xf32>>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p9.204"), %arg10: tensor<3072x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1536x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p10.209"), %arg11: tensor<1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024xf32>>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p11.214"), %arg12: tensor<1024x2048xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p12.223"), %arg13: tensor<4x18xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<4x18xi64>>, ttir.name = "args_1"} loc("p13.284"), %arg14: tensor<i1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<i1>>} loc("p14.296"), %arg15: tensor<128xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<128xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_norm_weight"} loc("p15.328"), %arg16: tensor<2048x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p16.336"), %arg17: tensor<3072x1024xf32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1536x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p17.495")) -> (tensor<4x8x18x128xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<4x8x18x128xf32>>}, tensor<4x8x18x128xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<4x8x18x128xf32>>}, tensor<72xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<72xf32>>}, tensor<4x18x151936xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<4x18x151936xf32>>}) {
        %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x1024xf32>) -> tensor<512x1024xf32> loc(#loc)
        %1 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024xf32>) -> tensor<1024xf32> loc(#loc)
        %2 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<4x18xi64>) -> tensor<4x18xi64> loc(#loc)
        %3 = "ttir.mesh_shard"(%arg3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<151936x1024xf32>) -> tensor<151936x1024xf32> loc(#loc)
        %4 = "ttir.mesh_shard"(%arg4) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32>) -> tensor<64xf32> loc(#loc)
        %5 = "ttir.mesh_shard"(%arg5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128xf32>) -> tensor<128xf32> loc(#loc)
        %6 = "ttir.mesh_shard"(%arg6) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x1024xf32>) -> tensor<512x1024xf32> loc(#loc)
        %7 = "ttir.mesh_shard"(%arg7) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<151936x1024xf32>) -> tensor<75968x1024xf32> loc(#loc)
        %8 = "ttir.mesh_shard"(%arg8) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024xf32>) -> tensor<1024xf32> loc(#loc)
        %9 = "ttir.mesh_shard"(%arg9) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xf32>) -> tensor<1024x1536xf32> loc(#loc)
        %10 = "ttir.mesh_shard"(%arg10) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x1024xf32>) -> tensor<1536x1024xf32> loc(#loc)
        %11 = "ttir.mesh_shard"(%arg11) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024xf32>) -> tensor<1024xf32> loc(#loc)
        %12 = "ttir.mesh_shard"(%arg12) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x2048xf32>) -> tensor<1024x1024xf32> loc(#loc)
        %13 = "ttir.mesh_shard"(%arg13) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<4x18xi64>) -> tensor<4x18xi64> loc(#loc)
        %14 = "ttir.mesh_shard"(%arg14) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<i1>) -> tensor<i1> loc(#loc)
        %15 = "ttir.mesh_shard"(%arg15) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128xf32>) -> tensor<128xf32> loc(#loc)
        %16 = "ttir.mesh_shard"(%arg16) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2048x1024xf32>) -> tensor<1024x1024xf32> loc(#loc)
        %17 = "ttir.mesh_shard"(%arg17) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x1024xf32>) -> tensor<1536x1024xf32> loc(#loc)
        %18 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]> : tensor<18xi64>}> : () -> tensor<18xi64> loc(#loc)
        %19 = "ttir.constant"() <{value = dense<[0, 1, 2, 3]> : tensor<4xi64>}> : () -> tensor<4xi64> loc(#loc)
        %20 = "ttir.constant"() <{value = dense<[[[0.000000e+00, 1.000000e+00, 2.000000e+00, 3.000000e+00, 4.000000e+00, 5.000000e+00, 6.000000e+00, 7.000000e+00, 8.000000e+00, 9.000000e+00, 1.000000e+01, 1.100000e+01, 1.200000e+01, 1.300000e+01, 1.400000e+01, 1.500000e+01, 1.600000e+01, 1.700000e+01]]]> : tensor<1x1x18xf32>}> : () -> tensor<1x1x18xf32> loc(#loc)
        %21 = "ttir.constant"() <{value = dense<-100> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
        %22 = "ttir.constant"() <{value = dense<0.297301769> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
        %23 = "ttir.constant"() <{value = dense<4> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
        %24 = "ttir.constant"() <{value = dense<18> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
        %25 = "ttir.constant"() <{value = dense<0xFF800000> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
        %26 = "ttir.constant"() <{value = dense<0xFFF0000000000000> : tensor<f64>}> : () -> tensor<f64> loc(#loc)
        %27 = "ttir.constant"() <{value = dense<0> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
        %28 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
        %29 = "ttir.reshape"(%28) <{shape = [1 : i32]}> : (tensor<f32>) -> tensor<1xf32> loc(#loc)
        %30 = "ttir.broadcast"(%29) <{broadcast_dimensions = array<i64: 72>}> : (tensor<1xf32>) -> tensor<72xf32> loc(#loc)
        %31 = "ttir.reshape"(%27) <{shape = [1 : i32]}> : (tensor<i64>) -> tensor<1xi64> loc(#loc)
        %32 = "ttir.broadcast"(%31) <{broadcast_dimensions = array<i64: 72>}> : (tensor<1xi64>) -> tensor<72xi64> loc(#loc)
        %33 = "ttir.reshape"(%28) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>) -> tensor<1x1x1x1xf32> loc(#loc)
        %34 = "ttir.broadcast"(%33) <{broadcast_dimensions = array<i64: 4, 8, 18, 18>}> : (tensor<1x1x1x1xf32>) -> tensor<4x8x18x18xf32> loc(#loc)
        %35 = "ttir.reshape"(%26) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f64>) -> tensor<1x1x1x1xf64> loc(#loc)
        %36 = "ttir.broadcast"(%35) <{broadcast_dimensions = array<i64: 4, 8, 18, 18>}> : (tensor<1x1x1x1xf64>) -> tensor<4x8x18x18xf64> loc(#loc)
        %37 = "ttir.reshape"(%25) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>) -> tensor<1x1x1x1xf32> loc(#loc)
        %38 = "ttir.broadcast"(%37) <{broadcast_dimensions = array<i64: 4, 1, 18, 18>}> : (tensor<1x1x1x1xf32>) -> tensor<4x1x18x18xf32> loc(#loc)
        %39 = "ttir.broadcast"(%33) <{broadcast_dimensions = array<i64: 4, 1, 18, 18>}> : (tensor<1x1x1x1xf32>) -> tensor<4x1x18x18xf32> loc(#loc)
        %40 = "ttir.reshape"(%24) <{shape = [1 : i32, 1 : i32]}> : (tensor<i64>) -> tensor<1x1xi64> loc(#loc)
        %41 = "ttir.broadcast"(%40) <{broadcast_dimensions = array<i64: 4, 18>}> : (tensor<1x1xi64>) -> tensor<4x18xi64> loc(#loc)
        %42 = "ttir.reshape"(%23) <{shape = [1 : i32, 1 : i32]}> : (tensor<i64>) -> tensor<1x1xi64> loc(#loc)
        %43 = "ttir.broadcast"(%42) <{broadcast_dimensions = array<i64: 4, 18>}> : (tensor<1x1xi64>) -> tensor<4x18xi64> loc(#loc)
        %44 = "ttir.reshape"(%22) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>) -> tensor<1x1x1x1xf32> loc(#loc)
        %45 = "ttir.broadcast"(%44) <{broadcast_dimensions = array<i64: 4, 8, 128, 18>}> : (tensor<1x1x1x1xf32>) -> tensor<4x8x128x18xf32> loc(#loc)
        %46 = "ttir.broadcast"(%44) <{broadcast_dimensions = array<i64: 4, 8, 18, 128>}> : (tensor<1x1x1x1xf32>) -> tensor<4x8x18x128xf32> loc(#loc)
        %47 = "ttir.reshape"(%21) <{shape = [1 : i32]}> : (tensor<i64>) -> tensor<1xi64> loc(#loc)
        %48 = "ttir.broadcast"(%47) <{broadcast_dimensions = array<i64: 72>}> : (tensor<1xi64>) -> tensor<72xi64> loc(#loc)
        %49 = "ttir.reshape"(%27) <{shape = [1 : i32, 1 : i32]}> : (tensor<i64>) -> tensor<1x1xi64> loc(#loc)
        %50 = "ttir.broadcast"(%49) <{broadcast_dimensions = array<i64: 4, 18>}> : (tensor<1x1xi64>) -> tensor<4x18xi64> loc(#loc)
        %51 = "ttir.reshape"(%3) <{shape = [1 : i32, 151936 : i32, 1024 : i32]}> : (tensor<151936x1024xf32>) -> tensor<1x151936x1024xf32> loc(#loc19)
        %52 = "ttir.reshape"(%51) <{shape = [151936 : i32, 1024 : i32]}> : (tensor<1x151936x1024xf32>) -> tensor<151936x1024xf32> loc(#loc20)
        %53 = "ttir.reshape"(%2) <{shape = [1 : i32, 4 : i32, 18 : i32]}> : (tensor<4x18xi64>) -> tensor<1x4x18xi64> loc(#loc21)
        %54 = "ttir.reshape"(%53) <{shape = [4 : i32, 18 : i32]}> : (tensor<1x4x18xi64>) -> tensor<4x18xi64> loc(#loc22)
        %55 = "ttir.reshape"(%53) <{shape = [72 : i32]}> : (tensor<1x4x18xi64>) -> tensor<72xi64> loc(#loc23)
        %56 = "ttir.typecast"(%55) <{conservative_folding = false}> : (tensor<72xi64>) -> tensor<72xui32> loc(#loc24)
        %57 = "ttir.gather"(%52, %56) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 1024>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<151936x1024xf32>, tensor<72xui32>) -> tensor<72x1024xf32> loc(#loc25)
        %58 = "ttir.reshape"(%57) <{shape = [4 : i32, 18 : i32, 1024 : i32]}> : (tensor<72x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc26)
        %59 = "ttir.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xf32>) -> tensor<1x1x1024xf32> loc(#loc27)
        %60 = "ttir.reshape"(%59) <{shape = [1024 : i32]}> : (tensor<1x1x1024xf32>) -> tensor<1024xf32> loc(#loc28)
        %61 = "ttir.rms_norm"(%58, %60) <{epsilon = 9.99999997E-7 : f32, normalized_shape = array<i64: 1024>, operandSegmentSizes = array<i32: 1, 1, 0>}> : (tensor<4x18x1024xf32>, tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc)
        %62 = "ttir.reshape"(%61) <{shape = [72 : i32, 1024 : i32]}> : (tensor<4x18x1024xf32>) -> tensor<72x1024xf32> loc(#loc29)
        %63 = "ttir.reshape"(%0) <{shape = [1 : i32, 512 : i32, 1024 : i32]}> : (tensor<512x1024xf32>) -> tensor<1x512x1024xf32> loc(#loc30)
        %64 = "ttir.reshape"(%63) <{shape = [512 : i32, 1024 : i32]}> : (tensor<1x512x1024xf32>) -> tensor<512x1024xf32> loc(#loc31)
        %65 = "ttir.permute"(%64) <{permutation = array<i64: 1, 0>}> : (tensor<512x1024xf32>) -> tensor<1024x512xf32> loc(#loc32)
        %66 = "ttir.dot_general"(%62, %65) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<72x1024xf32>, tensor<1024x512xf32>) -> tensor<72x512xf32> loc(#loc33)
        %67 = "ttir.reshape"(%66) <{shape = [4 : i32, 18 : i32, 4 : i32, 128 : i32]}> : (tensor<72x512xf32>) -> tensor<4x18x4x128xf32> loc(#loc34)
        %68 = "ttir.permute"(%67) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<4x18x4x128xf32>) -> tensor<4x4x18x128xf32> loc(#loc35)
        %69 = "ttir.reshape"(%6) <{shape = [1 : i32, 512 : i32, 1024 : i32]}> : (tensor<512x1024xf32>) -> tensor<1x512x1024xf32> loc(#loc36)
        %70 = "ttir.reshape"(%69) <{shape = [512 : i32, 1024 : i32]}> : (tensor<1x512x1024xf32>) -> tensor<512x1024xf32> loc(#loc37)
        %71 = "ttir.permute"(%70) <{permutation = array<i64: 1, 0>}> : (tensor<512x1024xf32>) -> tensor<1024x512xf32> loc(#loc38)
        %72 = "ttir.dot_general"(%62, %71) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<72x1024xf32>, tensor<1024x512xf32>) -> tensor<72x512xf32> loc(#loc39)
        %73 = "ttir.reshape"(%72) <{shape = [4 : i32, 18 : i32, 4 : i32, 128 : i32]}> : (tensor<72x512xf32>) -> tensor<4x18x4x128xf32> loc(#loc40)
        %74 = "ttir.reshape"(%5) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xf32>) -> tensor<1x1x128xf32> loc(#loc41)
        %75 = "ttir.reshape"(%74) <{shape = [128 : i32]}> : (tensor<1x1x128xf32>) -> tensor<128xf32> loc(#loc42)
        %76 = "ttir.rms_norm"(%73, %75) <{epsilon = 9.99999997E-7 : f32, normalized_shape = array<i64: 128>, operandSegmentSizes = array<i32: 1, 1, 0>}> : (tensor<4x18x4x128xf32>, tensor<128xf32>) -> tensor<4x18x4x128xf32> loc(#loc)
        %77 = "ttir.permute"(%76) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<4x18x4x128xf32>) -> tensor<4x4x18x128xf32> loc(#loc43)
        %78 = "ttir.reshape"(%4) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc44)
        %79 = "ttir.reshape"(%78) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc45)
        %80 = "ttir.dot_general"(%79, %20) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<1x64x1xf32>, tensor<1x1x18xf32>) -> tensor<1x64x18xf32> loc(#loc46)
        %81 = "ttir.permute"(%80) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x18xf32>) -> tensor<1x18x64xf32> loc(#loc47)
        %82 = "ttir.concat"(%81, %81) <{dim = 2 : si32}> : (tensor<1x18x64xf32>, tensor<1x18x64xf32>) -> tensor<1x18x128xf32> loc(#loc48)
        %83 = "ttir.cos"(%82) : (tensor<1x18x128xf32>) -> tensor<1x18x128xf32> loc(#loc49)
        %84 = "ttir.reshape"(%83) <{shape = [18 : i32, 128 : i32]}> : (tensor<1x18x128xf32>) -> tensor<18x128xf32> loc(#loc50)
        %85 = "ttir.reshape"(%84) <{shape = [1 : i32, 1 : i32, 18 : i32, 128 : i32]}> : (tensor<18x128xf32>) -> tensor<1x1x18x128xf32> loc(#loc51)
        %86 = "ttir.broadcast"(%85) <{broadcast_dimensions = array<i64: 4, 4, 1, 1>}> : (tensor<1x1x18x128xf32>) -> tensor<4x4x18x128xf32> loc(#loc51)
        %87 = "ttir.multiply"(%77, %86) : (tensor<4x4x18x128xf32>, tensor<4x4x18x128xf32>) -> tensor<4x4x18x128xf32> loc(#loc52)
        %88 = "ttir.slice_static"(%77) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [4 : i32, 4 : i32, 18 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<4x4x18x128xf32>) -> tensor<4x4x18x64xf32> loc(#loc53)
        %89 = "ttir.neg"(%88) : (tensor<4x4x18x64xf32>) -> tensor<4x4x18x64xf32> loc(#loc54)
        %90 = "ttir.slice_static"(%77) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [4 : i32, 4 : i32, 18 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<4x4x18x128xf32>) -> tensor<4x4x18x64xf32> loc(#loc55)
        %91 = "ttir.concat"(%89, %90) <{dim = 3 : si32}> : (tensor<4x4x18x64xf32>, tensor<4x4x18x64xf32>) -> tensor<4x4x18x128xf32> loc(#loc56)
        %92 = "ttir.sin"(%82) : (tensor<1x18x128xf32>) -> tensor<1x18x128xf32> loc(#loc57)
        %93 = "ttir.reshape"(%92) <{shape = [18 : i32, 128 : i32]}> : (tensor<1x18x128xf32>) -> tensor<18x128xf32> loc(#loc58)
        %94 = "ttir.reshape"(%93) <{shape = [1 : i32, 1 : i32, 18 : i32, 128 : i32]}> : (tensor<18x128xf32>) -> tensor<1x1x18x128xf32> loc(#loc59)
        %95 = "ttir.broadcast"(%94) <{broadcast_dimensions = array<i64: 4, 4, 1, 1>}> : (tensor<1x1x18x128xf32>) -> tensor<4x4x18x128xf32> loc(#loc59)
        %96 = "ttir.multiply"(%91, %95) : (tensor<4x4x18x128xf32>, tensor<4x4x18x128xf32>) -> tensor<4x4x18x128xf32> loc(#loc60)
        %97 = "ttir.add"(%87, %96) : (tensor<4x4x18x128xf32>, tensor<4x4x18x128xf32>) -> tensor<4x4x18x128xf32> loc(#loc61)
        %98 = "ttir.pad"(%54) <{padding = array<i32: 0, 0, 0, 1>, value = -1.000000e+02 : f32}> : (tensor<4x18xi64>) -> tensor<4x19xi64> loc(#loc62)
        %99 = "ttir.slice_static"(%98) <{begins = [0 : i32, 1 : i32], ends = [4 : i32, 19 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x19xi64>) -> tensor<4x18xi64> loc(#loc63)
        %100 = "ttir.reshape"(%99) <{shape = [72 : i32]}> : (tensor<4x18xi64>) -> tensor<72xi64> loc(#loc64)
        %101 = "ttir.ne"(%100, %48) : (tensor<72xi64>, tensor<72xi64>) -> tensor<72xi1> loc(#loc65)
        %102 = "ttir.reshape"(%16) <{shape = [1 : i32, 1024 : i32, 1024 : i32]}> : (tensor<1024x1024xf32>) -> tensor<1x1024x1024xf32> loc(#loc66)
        %103 = "ttir.reshape"(%102) <{shape = [1024 : i32, 1024 : i32]}> : (tensor<1x1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc67)
        %104 = "ttir.permute"(%103) <{permutation = array<i64: 1, 0>}> : (tensor<1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc68)
        %105 = "ttir.dot_general"(%62, %104) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<72x1024xf32>, tensor<1024x1024xf32>) -> tensor<72x1024xf32> loc(#loc69)
        %106 = "ttir.reshape"(%105) <{shape = [4 : i32, 18 : i32, 8 : i32, 128 : i32]}> : (tensor<72x1024xf32>) -> tensor<4x18x8x128xf32> loc(#loc70)
        %107 = "ttir.reshape"(%15) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xf32>) -> tensor<1x1x128xf32> loc(#loc71)
        %108 = "ttir.reshape"(%107) <{shape = [128 : i32]}> : (tensor<1x1x128xf32>) -> tensor<128xf32> loc(#loc72)
        %109 = "ttir.rms_norm"(%106, %108) <{epsilon = 9.99999997E-7 : f32, normalized_shape = array<i64: 128>, operandSegmentSizes = array<i32: 1, 1, 0>}> : (tensor<4x18x8x128xf32>, tensor<128xf32>) -> tensor<4x18x8x128xf32> loc(#loc)
        %110 = "ttir.permute"(%109) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<4x18x8x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc73)
        %111 = "ttir.broadcast"(%85) <{broadcast_dimensions = array<i64: 4, 8, 1, 1>}> : (tensor<1x1x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc74)
        %112 = "ttir.multiply"(%110, %111) : (tensor<4x8x18x128xf32>, tensor<4x8x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc75)
        %113 = "ttir.slice_static"(%110) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [4 : i32, 8 : i32, 18 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<4x8x18x128xf32>) -> tensor<4x8x18x64xf32> loc(#loc76)
        %114 = "ttir.neg"(%113) : (tensor<4x8x18x64xf32>) -> tensor<4x8x18x64xf32> loc(#loc77)
        %115 = "ttir.slice_static"(%110) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [4 : i32, 8 : i32, 18 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<4x8x18x128xf32>) -> tensor<4x8x18x64xf32> loc(#loc78)
        %116 = "ttir.concat"(%114, %115) <{dim = 3 : si32}> : (tensor<4x8x18x64xf32>, tensor<4x8x18x64xf32>) -> tensor<4x8x18x128xf32> loc(#loc79)
        %117 = "ttir.broadcast"(%94) <{broadcast_dimensions = array<i64: 4, 8, 1, 1>}> : (tensor<1x1x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc80)
        %118 = "ttir.multiply"(%116, %117) : (tensor<4x8x18x128xf32>, tensor<4x8x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc81)
        %119 = "ttir.add"(%112, %118) : (tensor<4x8x18x128xf32>, tensor<4x8x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc82)
        %120 = "ttir.multiply"(%119, %46) : (tensor<4x8x18x128xf32>, tensor<4x8x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc83)
        %121 = "ttir.reshape"(%97) <{shape = [4 : i32, 4 : i32, 1 : i32, 18 : i32, 128 : i32]}> : (tensor<4x4x18x128xf32>) -> tensor<4x4x1x18x128xf32> loc(#loc84)
        %122 = "ttir.broadcast"(%121) <{broadcast_dimensions = array<i64: 1, 1, 2, 1, 1>}> : (tensor<4x4x1x18x128xf32>) -> tensor<4x4x2x18x128xf32> loc(#loc84)
        %123 = "ttir.reshape"(%122) <{shape = [4 : i32, 8 : i32, 18 : i32, 128 : i32]}> : (tensor<4x4x2x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc85)
        %124 = "ttir.permute"(%123) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<4x8x18x128xf32>) -> tensor<4x8x128x18xf32> loc(#loc86)
        %125 = "ttir.multiply"(%124, %45) : (tensor<4x8x128x18xf32>, tensor<4x8x128x18xf32>) -> tensor<4x8x128x18xf32> loc(#loc87)
        %126 = "ttir.dot_general"(%120, %125) <{batch_dims_lhs = array<i64: 0, 1>, batch_dims_rhs = array<i64: 0, 1>, contract_dims_lhs = array<i64: 3>, contract_dims_rhs = array<i64: 2>}> : (tensor<4x8x18x128xf32>, tensor<4x8x128x18xf32>) -> tensor<4x8x18x18xf32> loc(#loc88)
        %127 = "ttir.reshape"(%14) <{shape = [1 : i32, 1 : i32]}> : (tensor<i1>) -> tensor<1x1xi1> loc(#loc89)
        %128 = "ttir.broadcast"(%127) <{broadcast_dimensions = array<i64: 18, 18>}> : (tensor<1x1xi1>) -> tensor<18x18xi1> loc(#loc89)
        %129 = "ttir.reshape"(%18) <{shape = [1 : i32, 18 : i32]}> : (tensor<18xi64>) -> tensor<1x18xi64> loc(#loc90)
        %130 = "ttir.broadcast"(%129) <{broadcast_dimensions = array<i64: 18, 1>}> : (tensor<1x18xi64>) -> tensor<18x18xi64> loc(#loc90)
        %131 = "ttir.reshape"(%18) <{shape = [18 : i32, 1 : i32]}> : (tensor<18xi64>) -> tensor<18x1xi64> loc(#loc91)
        %132 = "ttir.broadcast"(%131) <{broadcast_dimensions = array<i64: 1, 18>}> : (tensor<18x1xi64>) -> tensor<18x18xi64> loc(#loc91)
        %133 = "ttir.le"(%130, %132) : (tensor<18x18xi64>, tensor<18x18xi64>) -> tensor<18x18xi1> loc(#loc92)
        %134 = "ttir.logical_and"(%128, %133) : (tensor<18x18xi1>, tensor<18x18xi1>) -> tensor<18x18xi1> loc(#loc93)
        %135 = "ttir.reshape"(%134) <{shape = [1 : i32, 18 : i32, 18 : i32]}> : (tensor<18x18xi1>) -> tensor<1x18x18xi1> loc(#loc94)
        %136 = "ttir.broadcast"(%135) <{broadcast_dimensions = array<i64: 4, 1, 1>}> : (tensor<1x18x18xi1>) -> tensor<4x18x18xi1> loc(#loc94)
        %137 = "ttir.reshape"(%13) <{shape = [1 : i32, 4 : i32, 18 : i32]}> : (tensor<4x18xi64>) -> tensor<1x4x18xi64> loc(#loc95)
        %138 = "ttir.reshape"(%137) <{shape = [4 : i32, 18 : i32]}> : (tensor<1x4x18xi64>) -> tensor<4x18xi64> loc(#loc96)
        %139 = "ttir.ne"(%138, %50) : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi1> loc(#loc97)
        %140 = "ttir.reshape"(%19) <{shape = [4 : i32, 1 : i32]}> : (tensor<4xi64>) -> tensor<4x1xi64> loc(#loc98)
        %141 = "ttir.broadcast"(%140) <{broadcast_dimensions = array<i64: 1, 18>}> : (tensor<4x1xi64>) -> tensor<4x18xi64> loc(#loc98)
        %142 = "ttir.lt"(%141, %50) : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi1> loc(#loc99)
        %143 = "ttir.add"(%141, %43) : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi64> loc(#loc100)
        %144 = "ttir.where"(%142, %143, %141) : (tensor<4x18xi1>, tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi64> loc(#loc101)
        %145 = "ttir.reshape"(%144) <{shape = [4 : i32, 18 : i32, 1 : i32]}> : (tensor<4x18xi64>) -> tensor<4x18x1xi64> loc(#loc102)
        %146 = "ttir.broadcast"(%129) <{broadcast_dimensions = array<i64: 4, 1>}> : (tensor<1x18xi64>) -> tensor<4x18xi64> loc(#loc103)
        %147 = "ttir.lt"(%146, %50) : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi1> loc(#loc104)
        %148 = "ttir.add"(%146, %41) : (tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi64> loc(#loc105)
        %149 = "ttir.where"(%147, %148, %146) : (tensor<4x18xi1>, tensor<4x18xi64>, tensor<4x18xi64>) -> tensor<4x18xi64> loc(#loc106)
        %150 = "ttir.reshape"(%149) <{shape = [4 : i32, 18 : i32, 1 : i32]}> : (tensor<4x18xi64>) -> tensor<4x18x1xi64> loc(#loc107)
        %151 = "ttir.concat"(%145, %150) <{dim = 2 : si32}> : (tensor<4x18x1xi64>, tensor<4x18x1xi64>) -> tensor<4x18x2xi64> loc(#loc108)
        %152 = "ttir.gather"(%139, %151) <{collapsed_slice_dims = array<i64: 0, 1>, index_vector_dim = 2 : si64, indices_are_sorted = false, offset_dims = array<i64>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 1>, start_index_map = array<i64: 0, 1>, start_indices_batching_dims = array<i64>}> : (tensor<4x18xi1>, tensor<4x18x2xi64>) -> tensor<4x18xi1> loc(#loc109)
        %153 = "ttir.reshape"(%152) <{shape = [4 : i32, 1 : i32, 18 : i32]}> : (tensor<4x18xi1>) -> tensor<4x1x18xi1> loc(#loc110)
        %154 = "ttir.broadcast"(%153) <{broadcast_dimensions = array<i64: 1, 18, 1>}> : (tensor<4x1x18xi1>) -> tensor<4x18x18xi1> loc(#loc110)
        %155 = "ttir.logical_and"(%136, %154) : (tensor<4x18x18xi1>, tensor<4x18x18xi1>) -> tensor<4x18x18xi1> loc(#loc111)
        %156 = "ttir.reshape"(%155) <{shape = [4 : i32, 1 : i32, 18 : i32, 18 : i32]}> : (tensor<4x18x18xi1>) -> tensor<4x1x18x18xi1> loc(#loc112)
        %157 = "ttir.where"(%156, %39, %38) : (tensor<4x1x18x18xi1>, tensor<4x1x18x18xf32>, tensor<4x1x18x18xf32>) -> tensor<4x1x18x18xf32> loc(#loc113)
        %158 = "ttir.reshape"(%157) <{shape = [4 : i32, 18 : i32, 18 : i32]}> : (tensor<4x1x18x18xf32>) -> tensor<4x18x18xf32> loc(#loc114)
        %159 = "ttir.reshape"(%158) <{shape = [4 : i32, 1 : i32, 18 : i32, 18 : i32]}> : (tensor<4x18x18xf32>) -> tensor<4x1x18x18xf32> loc(#loc115)
        %160 = "ttir.broadcast"(%159) <{broadcast_dimensions = array<i64: 1, 8, 1, 1>}> : (tensor<4x1x18x18xf32>) -> tensor<4x8x18x18xf32> loc(#loc115)
        %161 = "ttir.add"(%126, %160) : (tensor<4x8x18x18xf32>, tensor<4x8x18x18xf32>) -> tensor<4x8x18x18xf32> loc(#loc116)
        %162 = "ttir.typecast"(%161) <{conservative_folding = false}> : (tensor<4x8x18x18xf32>) -> tensor<4x8x18x18xf64> loc(#loc117)
        %163 = "ttir.eq"(%162, %36) : (tensor<4x8x18x18xf64>, tensor<4x8x18x18xf64>) -> tensor<4x8x18x18xi1> loc(#loc118)
        %164 = "ttir.logical_not"(%163) : (tensor<4x8x18x18xi1>) -> tensor<4x8x18x18xi1> loc(#loc119)
        %165 = "ttir.reduce_or"(%164) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<4x8x18x18xi1>) -> tensor<4x8x18xi1> loc(#loc120)
        %166 = "ttir.reshape"(%165) <{shape = [4 : i32, 8 : i32, 18 : i32, 1 : i32]}> : (tensor<4x8x18xi1>) -> tensor<4x8x18x1xi1> loc(#loc121)
        %167 = "ttir.logical_not"(%166) : (tensor<4x8x18x1xi1>) -> tensor<4x8x18x1xi1> loc(#loc122)
        %168 = "ttir.reshape"(%167) <{shape = [4 : i32, 8 : i32, 18 : i32]}> : (tensor<4x8x18x1xi1>) -> tensor<4x8x18xi1> loc(#loc123)
        %169 = "ttir.reshape"(%168) <{shape = [4 : i32, 8 : i32, 18 : i32, 1 : i32]}> : (tensor<4x8x18xi1>) -> tensor<4x8x18x1xi1> loc(#loc124)
        %170 = "ttir.broadcast"(%169) <{broadcast_dimensions = array<i64: 1, 1, 1, 18>}> : (tensor<4x8x18x1xi1>) -> tensor<4x8x18x18xi1> loc(#loc124)
        %171 = "ttir.max"(%161) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<4x8x18x18xf32>) -> tensor<4x8x18xf32> loc(#loc125)
        %172 = "ttir.reshape"(%171) <{shape = [4 : i32, 8 : i32, 18 : i32, 1 : i32]}> : (tensor<4x8x18xf32>) -> tensor<4x8x18x1xf32> loc(#loc126)
        %173 = "ttir.broadcast"(%172) <{broadcast_dimensions = array<i64: 1, 1, 1, 18>}> : (tensor<4x8x18x1xf32>) -> tensor<4x8x18x18xf32> loc(#loc126)
        %174 = "ttir.subtract"(%161, %173) : (tensor<4x8x18x18xf32>, tensor<4x8x18x18xf32>) -> tensor<4x8x18x18xf32> loc(#loc127)
        %175 = "ttir.exp"(%174) : (tensor<4x8x18x18xf32>) -> tensor<4x8x18x18xf32> loc(#loc128)
        %176 = "ttir.sum"(%175) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<4x8x18x18xf32>) -> tensor<4x8x18xf32> loc(#loc129)
        %177 = "ttir.reshape"(%176) <{shape = [4 : i32, 8 : i32, 18 : i32, 1 : i32]}> : (tensor<4x8x18xf32>) -> tensor<4x8x18x1xf32> loc(#loc130)
        %178 = "ttir.broadcast"(%177) <{broadcast_dimensions = array<i64: 1, 1, 1, 18>}> : (tensor<4x8x18x1xf32>) -> tensor<4x8x18x18xf32> loc(#loc130)
        %179 = "ttir.div"(%175, %178) : (tensor<4x8x18x18xf32>, tensor<4x8x18x18xf32>) -> tensor<4x8x18x18xf32> loc(#loc131)
        %180 = "ttir.where"(%170, %34, %179) : (tensor<4x8x18x18xi1>, tensor<4x8x18x18xf32>, tensor<4x8x18x18xf32>) -> tensor<4x8x18x18xf32> loc(#loc132)
        %181 = "ttir.reshape"(%68) <{shape = [4 : i32, 4 : i32, 1 : i32, 18 : i32, 128 : i32]}> : (tensor<4x4x18x128xf32>) -> tensor<4x4x1x18x128xf32> loc(#loc133)
        %182 = "ttir.broadcast"(%181) <{broadcast_dimensions = array<i64: 1, 1, 2, 1, 1>}> : (tensor<4x4x1x18x128xf32>) -> tensor<4x4x2x18x128xf32> loc(#loc133)
        %183 = "ttir.reshape"(%182) <{shape = [4 : i32, 8 : i32, 18 : i32, 128 : i32]}> : (tensor<4x4x2x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc134)
        %184 = "ttir.dot_general"(%180, %183) <{batch_dims_lhs = array<i64: 0, 1>, batch_dims_rhs = array<i64: 0, 1>, contract_dims_lhs = array<i64: 3>, contract_dims_rhs = array<i64: 2>}> : (tensor<4x8x18x18xf32>, tensor<4x8x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc135)
        %185 = "ttir.permute"(%184) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<4x8x18x128xf32>) -> tensor<4x18x8x128xf32> loc(#loc136)
        %186 = "ttir.reshape"(%185) <{shape = [72 : i32, 1024 : i32]}> : (tensor<4x18x8x128xf32>) -> tensor<72x1024xf32> loc(#loc137)
        %187 = "ttir.reshape"(%12) <{shape = [1 : i32, 1024 : i32, 1024 : i32]}> : (tensor<1024x1024xf32>) -> tensor<1x1024x1024xf32> loc(#loc138)
        %188 = "ttir.reshape"(%187) <{shape = [1024 : i32, 1024 : i32]}> : (tensor<1x1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc139)
        %189 = "ttir.permute"(%188) <{permutation = array<i64: 1, 0>}> : (tensor<1024x1024xf32>) -> tensor<1024x1024xf32> loc(#loc140)
        %190 = "ttir.dot_general"(%186, %189) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<72x1024xf32>, tensor<1024x1024xf32>) -> tensor<72x1024xf32> loc(#loc141)
        %191 = "ttir.all_reduce"(%190) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<72x1024xf32>) -> tensor<72x1024xf32> loc(#loc141)
        %192 = "ttir.reshape"(%191) <{shape = [4 : i32, 18 : i32, 1024 : i32]}> : (tensor<72x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc142)
        %193 = "ttir.add"(%58, %192) : (tensor<4x18x1024xf32>, tensor<4x18x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc143)
        %194 = "ttir.reshape"(%11) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xf32>) -> tensor<1x1x1024xf32> loc(#loc144)
        %195 = "ttir.reshape"(%194) <{shape = [1024 : i32]}> : (tensor<1x1x1024xf32>) -> tensor<1024xf32> loc(#loc145)
        %196 = "ttir.rms_norm"(%193, %195) <{epsilon = 9.99999997E-7 : f32, normalized_shape = array<i64: 1024>, operandSegmentSizes = array<i32: 1, 1, 0>}> : (tensor<4x18x1024xf32>, tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc)
        %197 = "ttir.reshape"(%196) <{shape = [72 : i32, 1024 : i32]}> : (tensor<4x18x1024xf32>) -> tensor<72x1024xf32> loc(#loc146)
        %198 = "ttir.reshape"(%17) <{shape = [1 : i32, 1536 : i32, 1024 : i32]}> : (tensor<1536x1024xf32>) -> tensor<1x1536x1024xf32> loc(#loc147)
        %199 = "ttir.reshape"(%198) <{shape = [1536 : i32, 1024 : i32]}> : (tensor<1x1536x1024xf32>) -> tensor<1536x1024xf32> loc(#loc148)
        %200 = "ttir.permute"(%199) <{permutation = array<i64: 1, 0>}> : (tensor<1536x1024xf32>) -> tensor<1024x1536xf32> loc(#loc149)
        %201 = "ttir.dot_general"(%197, %200) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<72x1024xf32>, tensor<1024x1536xf32>) -> tensor<72x1536xf32> loc(#loc150)
        %202 = "ttir.reshape"(%201) <{shape = [4 : i32, 18 : i32, 1536 : i32]}> : (tensor<72x1536xf32>) -> tensor<4x18x1536xf32> loc(#loc151)
        %203 = "ttir.sigmoid"(%202) : (tensor<4x18x1536xf32>) -> tensor<4x18x1536xf32> loc(#loc152)
        %204 = "ttir.multiply"(%202, %203) : (tensor<4x18x1536xf32>, tensor<4x18x1536xf32>) -> tensor<4x18x1536xf32> loc(#loc153)
        %205 = "ttir.reshape"(%10) <{shape = [1 : i32, 1536 : i32, 1024 : i32]}> : (tensor<1536x1024xf32>) -> tensor<1x1536x1024xf32> loc(#loc154)
        %206 = "ttir.reshape"(%205) <{shape = [1536 : i32, 1024 : i32]}> : (tensor<1x1536x1024xf32>) -> tensor<1536x1024xf32> loc(#loc155)
        %207 = "ttir.permute"(%206) <{permutation = array<i64: 1, 0>}> : (tensor<1536x1024xf32>) -> tensor<1024x1536xf32> loc(#loc156)
        %208 = "ttir.dot_general"(%197, %207) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<72x1024xf32>, tensor<1024x1536xf32>) -> tensor<72x1536xf32> loc(#loc157)
        %209 = "ttir.reshape"(%208) <{shape = [4 : i32, 18 : i32, 1536 : i32]}> : (tensor<72x1536xf32>) -> tensor<4x18x1536xf32> loc(#loc158)
        %210 = "ttir.multiply"(%204, %209) : (tensor<4x18x1536xf32>, tensor<4x18x1536xf32>) -> tensor<4x18x1536xf32> loc(#loc159)
        %211 = "ttir.reshape"(%210) <{shape = [72 : i32, 1536 : i32]}> : (tensor<4x18x1536xf32>) -> tensor<72x1536xf32> loc(#loc160)
        %212 = "ttir.reshape"(%9) <{shape = [1 : i32, 1024 : i32, 1536 : i32]}> : (tensor<1024x1536xf32>) -> tensor<1x1024x1536xf32> loc(#loc161)
        %213 = "ttir.reshape"(%212) <{shape = [1024 : i32, 1536 : i32]}> : (tensor<1x1024x1536xf32>) -> tensor<1024x1536xf32> loc(#loc162)
        %214 = "ttir.permute"(%213) <{permutation = array<i64: 1, 0>}> : (tensor<1024x1536xf32>) -> tensor<1536x1024xf32> loc(#loc163)
        %215 = "ttir.dot_general"(%211, %214) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<72x1536xf32>, tensor<1536x1024xf32>) -> tensor<72x1024xf32> loc(#loc164)
        %216 = "ttir.all_reduce"(%215) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<72x1024xf32>) -> tensor<72x1024xf32> loc(#loc164)
        %217 = "ttir.reshape"(%216) <{shape = [4 : i32, 18 : i32, 1024 : i32]}> : (tensor<72x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc165)
        %218 = "ttir.add"(%193, %217) : (tensor<4x18x1024xf32>, tensor<4x18x1024xf32>) -> tensor<4x18x1024xf32> loc(#loc166)
        %219 = "ttir.reshape"(%8) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xf32>) -> tensor<1x1x1024xf32> loc(#loc167)
        %220 = "ttir.reshape"(%219) <{shape = [1024 : i32]}> : (tensor<1x1x1024xf32>) -> tensor<1024xf32> loc(#loc168)
        %221 = "ttir.rms_norm"(%218, %220) <{epsilon = 9.99999997E-7 : f32, normalized_shape = array<i64: 1024>, operandSegmentSizes = array<i32: 1, 1, 0>}> : (tensor<4x18x1024xf32>, tensor<1024xf32>) -> tensor<4x18x1024xf32> loc(#loc)
        %222 = "ttir.reshape"(%221) <{shape = [72 : i32, 1024 : i32]}> : (tensor<4x18x1024xf32>) -> tensor<72x1024xf32> loc(#loc169)
        %223 = "ttir.reshape"(%7) <{shape = [1 : i32, 75968 : i32, 1024 : i32]}> : (tensor<75968x1024xf32>) -> tensor<1x75968x1024xf32> loc(#loc170)
        %224 = "ttir.reshape"(%223) <{shape = [75968 : i32, 1024 : i32]}> : (tensor<1x75968x1024xf32>) -> tensor<75968x1024xf32> loc(#loc171)
        %225 = "ttir.permute"(%224) <{permutation = array<i64: 1, 0>}> : (tensor<75968x1024xf32>) -> tensor<1024x75968xf32> loc(#loc172)
        %226 = "ttir.dot_general"(%222, %225) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<72x1024xf32>, tensor<1024x75968xf32>) -> tensor<72x75968xf32> loc(#loc173)
        %227 = "ttir.reshape"(%226) <{shape = [4 : i32, 18 : i32, 75968 : i32]}> : (tensor<72x75968xf32>) -> tensor<4x18x75968xf32> loc(#loc174)
        %228 = "ttir.max"(%226) <{dim_arg = [1 : i32], keep_dim = false}> : (tensor<72x75968xf32>) -> tensor<72xf32> loc(#loc175)
        %229 = "ttir.all_reduce"(%228) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<72xf32>) -> tensor<72xf32> loc(#loc175)
        %230 = "ttir.reshape"(%229) <{shape = [72 : i32, 1 : i32]}> : (tensor<72xf32>) -> tensor<72x1xf32> loc(#loc176)
        %231 = "ttir.broadcast"(%230) <{broadcast_dimensions = array<i64: 1, 75968>}> : (tensor<72x1xf32>) -> tensor<72x75968xf32> loc(#loc176)
        %232 = "ttir.subtract"(%226, %231) : (tensor<72x75968xf32>, tensor<72x75968xf32>) -> tensor<72x75968xf32> loc(#loc177)
        %233 = "ttir.exp"(%232) : (tensor<72x75968xf32>) -> tensor<72x75968xf32> loc(#loc178)
        %234 = "ttir.sum"(%233) <{dim_arg = [1 : i32], keep_dim = false}> : (tensor<72x75968xf32>) -> tensor<72xf32> loc(#loc179)
        %235 = "ttir.all_reduce"(%234) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<72xf32>) -> tensor<72xf32> loc(#loc179)
        %236 = "ttir.reshape"(%235) <{shape = [72 : i32, 1 : i32]}> : (tensor<72xf32>) -> tensor<72x1xf32> loc(#loc180)
        %237 = "ttir.log"(%236) : (tensor<72x1xf32>) -> tensor<72x1xf32> loc(#loc181)
        %238 = "ttir.reshape"(%237) <{shape = [72 : i32]}> : (tensor<72x1xf32>) -> tensor<72xf32> loc(#loc182)
        %239 = "ttir.reshape"(%238) <{shape = [72 : i32, 1 : i32]}> : (tensor<72xf32>) -> tensor<72x1xf32> loc(#loc183)
        %240 = "ttir.broadcast"(%239) <{broadcast_dimensions = array<i64: 1, 75968>}> : (tensor<72x1xf32>) -> tensor<72x75968xf32> loc(#loc183)
        %241 = "ttir.subtract"(%232, %240) : (tensor<72x75968xf32>, tensor<72x75968xf32>) -> tensor<72x75968xf32> loc(#loc184)
        %242 = "ttir.arange"() <{arange_dimension = 0 : i64, end = 72 : si64, start = 0 : si64, step = 1 : si64}> : () -> tensor<72xui32> loc(#loc185)
        %243 = "ttir.reshape"(%242) <{shape = [72 : i32, 1 : i32, 1 : i32]}> : (tensor<72xui32>) -> tensor<72x1x1xui32> loc(#loc185)
        %244 = "ttir.where"(%101, %100, %32) : (tensor<72xi1>, tensor<72xi64>, tensor<72xi64>) -> tensor<72xi64> loc(#loc186)
        %245 = "ttir.reshape"(%244) <{shape = [72 : i32, 1 : i32]}> : (tensor<72xi64>) -> tensor<72x1xi64> loc(#loc187)
        %246 = "ttir.typecast"(%245) <{conservative_folding = false}> : (tensor<72x1xi64>) -> tensor<72x1xui32> loc(#loc188)
        %247 = "ttir.reshape"(%246) <{shape = [72 : i32, 1 : i32, 1 : i32]}> : (tensor<72x1xui32>) -> tensor<72x1x1xui32> loc(#loc189)
        %248 = "ttir.concat"(%243, %247) <{dim = 2 : si32}> : (tensor<72x1x1xui32>, tensor<72x1x1xui32>) -> tensor<72x1x2xui32> loc(#loc190)
        %249 = "ttir.gather"(%241, %248) <{collapsed_slice_dims = array<i64: 0, 1>, index_vector_dim = 2 : si64, indices_are_sorted = false, offset_dims = array<i64>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 1>, start_index_map = array<i64: 0, 1>, start_indices_batching_dims = array<i64>}> : (tensor<72x75968xf32>, tensor<72x1x2xui32>) -> tensor<72x1xf32> loc(#loc191)
        %250 = "ttir.all_reduce"(%249) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<72x1xf32>) -> tensor<72x1xf32> loc(#loc191)
        %251 = "ttir.reshape"(%250) <{shape = [72 : i32]}> : (tensor<72x1xf32>) -> tensor<72xf32> loc(#loc192)
        %252 = "ttir.neg"(%251) : (tensor<72xf32>) -> tensor<72xf32> loc(#loc193)
        %253 = "ttir.where"(%101, %252, %30) : (tensor<72xi1>, tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32> loc(#loc194)
        %254 = "ttir.typecast"(%101) <{conservative_folding = false}> : (tensor<72xi1>) -> tensor<72xi64> loc(#loc195)
        %255 = "ttir.typecast"(%254) <{conservative_folding = false}> : (tensor<72xi64>) -> tensor<72xf32> loc(#loc196)
        %256 = "ttir.div"(%253, %255) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32> loc(#loc197)
        %257 = "ttir.mesh_shard"(%68) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<4x4x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc)
        %258 = "ttir.mesh_shard"(%97) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<4x4x18x128xf32>) -> tensor<4x8x18x128xf32> loc(#loc)
        %259 = "ttir.mesh_shard"(%256) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<72xf32>) -> tensor<72xf32> loc(#loc)
        %260 = "ttir.mesh_shard"(%227) <{shard_dims = array<i64: -1, 2>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<4x18x75968xf32>) -> tensor<4x18x151936xf32> loc(#loc)
        return %257, %258, %259, %260 : tensor<4x8x18x128xf32>, tensor<4x8x18x128xf32>, tensor<72xf32>, tensor<4x18x151936xf32> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc19 = loc("reshape.20")
#loc20 = loc("reshape.22")
#loc21 = loc("reshape.15")
#loc22 = loc("reshape.17")
#loc23 = loc("reshape.18")
#loc24 = loc("convert.23")
#loc25 = loc("gather.24")
#loc26 = loc("reshape.25")
#loc27 = loc("reshape.7")
#loc28 = loc("reshape.9")
#loc29 = loc("reshape.57")
#loc30 = loc("reshape.2")
#loc31 = loc("reshape.4")
#loc32 = loc("transpose.5")
#loc33 = loc("dot.58")
#loc34 = loc("reshape.60")
#loc35 = loc("transpose.61")
#loc36 = loc("reshape.94")
#loc37 = loc("reshape.96")
#loc38 = loc("transpose.97")
#loc39 = loc("dot.99")
#loc40 = loc("reshape.101")
#loc41 = loc("reshape.86")
#loc42 = loc("reshape.88")
#loc43 = loc("transpose.133")
#loc44 = loc("reshape.71")
#loc45 = loc("reshape.75")
#loc46 = loc("dot.78")
#loc47 = loc("transpose.79")
#loc48 = loc("concatenate.80")
#loc49 = loc("cosine.142")
#loc50 = loc("reshape.146")
#loc51 = loc("broadcast.147")
#loc52 = loc("multiply.148")
#loc53 = loc("slice.135")
#loc54 = loc("negate.136")
#loc55 = loc("slice.134")
#loc56 = loc("concatenate.137")
#loc57 = loc("sine.81")
#loc58 = loc("reshape.138")
#loc59 = loc("broadcast.139")
#loc60 = loc("multiply.140")
#loc61 = loc("add.151")
#loc62 = loc("pad.155")
#loc63 = loc("slice.156")
#loc64 = loc("reshape.157")
#loc65 = loc("compare.585")
#loc66 = loc("reshape.337")
#loc67 = loc("reshape.339")
#loc68 = loc("transpose.340")
#loc69 = loc("dot.342")
#loc70 = loc("reshape.344")
#loc71 = loc("reshape.329")
#loc72 = loc("reshape.331")
#loc73 = loc("transpose.376")
#loc74 = loc("broadcast.385")
#loc75 = loc("multiply.386")
#loc76 = loc("slice.378")
#loc77 = loc("negate.379")
#loc78 = loc("slice.377")
#loc79 = loc("concatenate.380")
#loc80 = loc("broadcast.382")
#loc81 = loc("multiply.383")
#loc82 = loc("add.389")
#loc83 = loc("multiply.391")
#loc84 = loc("broadcast.321")
#loc85 = loc("reshape.322")
#loc86 = loc("transpose.323")
#loc87 = loc("multiply.325")
#loc88 = loc("dot.392")
#loc89 = loc("broadcast.305")
#loc90 = loc("broadcast.292")
#loc91 = loc("broadcast.294")
#loc92 = loc("compare.295")
#loc93 = loc("and.306")
#loc94 = loc("broadcast.309")
#loc95 = loc("reshape.285")
#loc96 = loc("reshape.287")
#loc97 = loc("convert.288")
#loc98 = loc("broadcast.270")
#loc99 = loc("compare.279")
#loc100 = loc("add.276")
#loc101 = loc("select.280")
#loc102 = loc("reshape.281")
#loc103 = loc("broadcast.255")
#loc104 = loc("compare.264")
#loc105 = loc("add.261")
#loc106 = loc("select.265")
#loc107 = loc("reshape.282")
#loc108 = loc("concatenate.283")
#loc109 = loc("gather.289")
#loc110 = loc("broadcast.311")
#loc111 = loc("and.312")
#loc112 = loc("reshape.313")
#loc113 = loc("select.316")
#loc114 = loc("reshape.396")
#loc115 = loc("broadcast.397")
#loc116 = loc("add.398")
#loc117 = loc("convert.424")
#loc118 = loc("compare.426")
#loc119 = loc("not.428")
#loc120 = loc("reduce.440")
#loc121 = loc("reshape.444")
#loc122 = loc("not.446")
#loc123 = loc("reshape.448")
#loc124 = loc("broadcast.449")
#loc125 = loc("reduce.404")
#loc126 = loc("broadcast.405")
#loc127 = loc("subtract.406")
#loc128 = loc("exponential.407")
#loc129 = loc("reduce.413")
#loc130 = loc("broadcast.414")
#loc131 = loc("divide.415")
#loc132 = loc("select.450")
#loc133 = loc("broadcast.231")
#loc134 = loc("reshape.232")
#loc135 = loc("dot.451")
#loc136 = loc("transpose.453")
#loc137 = loc("reshape.455")
#loc138 = loc("reshape.224")
#loc139 = loc("reshape.226")
#loc140 = loc("transpose.227")
#loc141 = loc("dot.456")
#loc142 = loc("reshape.457")
#loc143 = loc("add.460")
#loc144 = loc("reshape.215")
#loc145 = loc("reshape.217")
#loc146 = loc("reshape.500")
#loc147 = loc("reshape.496")
#loc148 = loc("reshape.498")
#loc149 = loc("transpose.499")
#loc150 = loc("dot.501")
#loc151 = loc("reshape.502")
#loc152 = loc("logistic.503")
#loc153 = loc("multiply.504")
#loc154 = loc("reshape.210")
#loc155 = loc("reshape.212")
#loc156 = loc("transpose.213")
#loc157 = loc("dot.493")
#loc158 = loc("reshape.494")
#loc159 = loc("multiply.505")
#loc160 = loc("reshape.506")
#loc161 = loc("reshape.205")
#loc162 = loc("reshape.207")
#loc163 = loc("transpose.208")
#loc164 = loc("dot.507")
#loc165 = loc("reshape.508")
#loc166 = loc("add.511")
#loc167 = loc("reshape.196")
#loc168 = loc("reshape.198")
#loc169 = loc("reshape.543")
#loc170 = loc("reshape.191")
#loc171 = loc("reshape.193")
#loc172 = loc("transpose.194")
#loc173 = loc("dot.544")
#loc174 = loc("reshape.545")
#loc175 = loc("reduce.553")
#loc176 = loc("broadcast.558")
#loc177 = loc("subtract.559")
#loc178 = loc("exponential.560")
#loc179 = loc("reduce.567")
#loc180 = loc("reshape.568")
#loc181 = loc("log.569")
#loc182 = loc("reshape.572")
#loc183 = loc("broadcast.573")
#loc184 = loc("subtract.574")
#loc185 = loc("iota.576")
#loc186 = loc("select.186")
#loc187 = loc("reshape.187")
#loc188 = loc("convert.575")
#loc189 = loc("reshape.577")
#loc190 = loc("concatenate.578")
#loc191 = loc("gather.579")
#loc192 = loc("reshape.580")
#loc193 = loc("negate.581")
#loc194 = loc("select.587")
#loc195 = loc("convert.160")
#loc196 = loc("convert.168")
#loc197 = loc("divide.595")
------------------ END OF MLIR MODULE ------------------
2026-01-28 22:12:58.736 (   5.903s) [        66B35000]      module_builder.cc:853   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2026-01-28 22:12:58.736 (   5.903s) [        66B35000]      module_builder.cc:867   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2026-01-28 22:12:58.736 (   5.903s) [        66B35000]      module_builder.cc:877   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2026-01-28 22:12:58.974 (   6.140s) [        66B35000]      module_builder.cc:1111     1| MLIR Module ttnn:
#dram = #ttnn.buffer_type<dram>
#loc = loc(unknown)
#loc30 = loc("p0.1")
#loc31 = loc("p1.6")
#loc32 = loc("p2.14")
#loc33 = loc("p3.19")
#loc34 = loc("p4.70")
#loc35 = loc("p5.85")
#loc36 = loc("p6.93")
#loc37 = loc("p7.190")
#loc38 = loc("p8.195")
#loc39 = loc("p9.204")
#loc40 = loc("p10.209")
#loc41 = loc("p11.214")
#loc42 = loc("p12.223")
#loc43 = loc("p13.284")
#loc44 = loc("p14.296")
#loc45 = loc("p15.328")
#loc46 = loc("p16.336")
#loc47 = loc("p17.495")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 103552, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073163648, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 103552, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073172288, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<4x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xf32, #system_memory>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2374x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xf32, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4748x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #system_memory>>
#ttnn_layout11 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout12 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #dram>, <interleaved>>
#ttnn_layout13 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout14 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #system_memory>>
#ttnn_layout15 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout16 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #dram>, <interleaved>>
#ttnn_layout17 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout18 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2048x1024xf32, #system_memory>>
#ttnn_layout19 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2048x1024xf32, #dram>, <interleaved>>
#ttnn_layout20 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<64x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout21 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xbf16, #dram>, <interleaved>>
#ttnn_layout22 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xbf16, #system_memory>>
#ttnn_layout23 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x3072xf32, #system_memory>>
#ttnn_layout24 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x48x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout25 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x3072xf32, #dram>, <interleaved>>
#ttnn_layout26 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout27 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<72x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout28 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout29 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<72x1x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout30 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x64xf32, #system_memory>>
#ttnn_layout31 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout32 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x64xf32, #dram>, <interleaved>>
#ttnn_layout33 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout34 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout35 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout36 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout37 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout38 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<32x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout39 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout40 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout41 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout42 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout43 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x72xui32, #dram>, <interleaved>>
#ttnn_layout44 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout45 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout46 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout47 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout48 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout49 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x3x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout50 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x3x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout51 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout52 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x2048xf32, #system_memory>>
#ttnn_layout53 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x2048xf32, #dram>, <interleaved>>
#ttnn_layout54 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x64x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout55 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout56 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4x18xsi32, #dram>, <interleaved>>
#ttnn_layout57 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout58 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1xbf16, #system_memory>>
#ttnn_layout59 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout60 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x4748x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout61 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout62 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 96 + d1, d2), <1x1>, memref<3x32x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout63 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 96 + d1, d2), <1x1>, memref<3x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout64 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout65 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3x16x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout66 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 576 + d1 * 32 + d2, d3), <1x1>, memref<72x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout67 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout68 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<16x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout69 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout70 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<32x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout71 = #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 128 + d1 * 32 + d2 * 32 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout72 = #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 256 + d1 * 64 + d2 * 32 + d3, d4), <1x1>, memref<32x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout73 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<128x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout74 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1xbf16, #dram>, <interleaved>>
#ttnn_layout75 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout76 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout77 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<72x1xbf16, #dram>, <interleaved>>
#ttnn_layout78 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 96 + d1, d2), <1x1>, memref<3x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout79 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<4x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout80 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<32x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout81 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout82 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 96 + d1 * 96 + d2, d3), <1x1>, memref<3x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout83 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout84 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3x48x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout85 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3x2374x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout86 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x2374x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout87 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x3x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout88 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout89 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<170928x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout90 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<72x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout91 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<170928x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout92 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<5469696x1xbf16, #dram>, <interleaved>>
#ttnn_layout93 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 96 + d1, d2), <1x1>, memref<3x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout94 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 96 + d1 * 96 + d2, d3), <1x1>, memref<3x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout95 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 64 + d2, d3), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.597 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.597 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]> loc(#loc)
      func.func private @main_const_eval_0() -> tensor<2x1xf32, #ttnn_layout> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[[7.596800e+04], [1.000000e+00]]> : tensor<2x1xf32>}> : (!ttnn.device) -> tensor<2x1xf32, #ttnn_layout> loc(#loc116)
        return %1 : tensor<2x1xf32, #ttnn_layout> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_1() -> tensor<4x1x18x18xf32, #ttnn_layout1> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 0xFF800000 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn_layout2> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout2>) -> tensor<1x1x1x1xf32, #ttnn_layout3> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn_layout2>) -> () loc(#loc)
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<4x1x18x18>}> : (tensor<1x1x1x1xf32, #ttnn_layout3>) -> tensor<4x1x18x18xf32, #ttnn_layout1> loc(#loc2)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn_layout3>) -> () loc(#loc2)
        return %3 : tensor<4x1x18x18xf32, #ttnn_layout1> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_2() -> tensor<1xsi32, #ttnn_layout4> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = -100 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn_layout5> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32]}> : (tensor<si32, #ttnn_layout5>) -> tensor<1xsi32, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<si32, #ttnn_layout5>) -> () loc(#loc)
        return %2 : tensor<1xsi32, #ttnn_layout4> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_3(%arg0: tensor<151936x1024xf32, #ttnn_layout6> loc(unknown)) -> tensor<75968x1024xf32, #ttnn_layout7> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<151936x1024xf32, #ttnn_layout6>, !ttnn.device) -> tensor<151936x1024xf32, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<151936x1024xf32, #ttnn_layout8>) -> tensor<151936x1024xf32, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<151936x1024xf32, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<151936x1024xf32, #ttnn_layout9>, !ttnn.device) -> tensor<75968x1024xf32, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<151936x1024xf32, #ttnn_layout9>) -> () loc(#loc)
        return %3 : tensor<75968x1024xf32, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_4(%arg0: tensor<1024x1024xf32, #ttnn_layout10> loc(unknown)) -> tensor<512x1024xf32, #ttnn_layout11> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1024x1024xf32, #ttnn_layout10>, !ttnn.device) -> tensor<1024x1024xf32, #ttnn_layout12> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1024x1024xf32, #ttnn_layout12>) -> tensor<1024x1024xf32, #ttnn_layout13> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1024x1024xf32, #ttnn_layout12>) -> () loc(#loc)
        %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x1024xf32, #ttnn_layout13>, !ttnn.device) -> tensor<512x1024xf32, #ttnn_layout11> loc(#loc)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1024x1024xf32, #ttnn_layout13>) -> () loc(#loc)
        return %3 : tensor<512x1024xf32, #ttnn_layout11> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_5(%arg0: tensor<3072x1024xf32, #ttnn_layout14> loc(unknown)) -> tensor<1536x1024xf32, #ttnn_layout15> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<3072x1024xf32, #ttnn_layout14>, !ttnn.device) -> tensor<3072x1024xf32, #ttnn_layout16> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<3072x1024xf32, #ttnn_layout16>) -> tensor<3072x1024xf32, #ttnn_layout17> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072x1024xf32, #ttnn_layout16>) -> () loc(#loc)
        %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x1024xf32, #ttnn_layout17>, !ttnn.device) -> tensor<1536x1024xf32, #ttnn_layout15> loc(#loc)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<3072x1024xf32, #ttnn_layout17>) -> () loc(#loc)
        return %3 : tensor<1536x1024xf32, #ttnn_layout15> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_6(%arg0: tensor<2048x1024xf32, #ttnn_layout18> loc(unknown)) -> tensor<1024x1024xf32, #ttnn_layout13> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<2048x1024xf32, #ttnn_layout18>, !ttnn.device) -> tensor<2048x1024xf32, #ttnn_layout19> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<2048x1024xf32, #ttnn_layout19>) -> tensor<2048x1024xf32, #ttnn_layout20> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<2048x1024xf32, #ttnn_layout19>) -> () loc(#loc)
        %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2048x1024xf32, #ttnn_layout20>, !ttnn.device) -> tensor<1024x1024xf32, #ttnn_layout13> loc(#loc)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<2048x1024xf32, #ttnn_layout20>) -> () loc(#loc)
        return %3 : tensor<1024x1024xf32, #ttnn_layout13> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_7(%arg0: tensor<151936x1024xf32, #ttnn_layout6> loc(unknown)) -> tensor<151936x1024xbf16, #ttnn_layout21> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc117)
        %1 = "ttnn.to_dtype"(%arg0) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<151936x1024xf32, #ttnn_layout6>) -> tensor<151936x1024xbf16, #ttnn_layout22> loc(#loc117)
        %2 = "ttnn.to_device"(%1, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<151936x1024xbf16, #ttnn_layout22>, !ttnn.device) -> tensor<151936x1024xbf16, #ttnn_layout21> loc(#loc117)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<151936x1024xbf16, #ttnn_layout22>) -> () loc(#loc117)
        return %2 : tensor<151936x1024xbf16, #ttnn_layout21> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_8(%arg0: tensor<1024x3072xf32, #ttnn_layout23> loc(unknown)) -> tensor<1024x1536xf32, #ttnn_layout24> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1024x3072xf32, #ttnn_layout23>, !ttnn.device) -> tensor<1024x3072xf32, #ttnn_layout25> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1024x3072xf32, #ttnn_layout25>) -> tensor<1024x3072xf32, #ttnn_layout26> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1024x3072xf32, #ttnn_layout25>) -> () loc(#loc)
        %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xf32, #ttnn_layout26>, !ttnn.device) -> tensor<1024x1536xf32, #ttnn_layout24> loc(#loc)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1024x3072xf32, #ttnn_layout26>) -> () loc(#loc)
        return %3 : tensor<1024x1536xf32, #ttnn_layout24> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_9() -> tensor<72x1x1xbf16, #ttnn_layout27> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.arange"(%0) <{dtype = #ttcore.supportedDataTypes<u32>, end = 72 : i64, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, start = 0 : i64, step = 1 : i64}> : (!ttnn.device) -> tensor<72xui32, #ttnn_layout28> loc(#loc4)
        %2 = "ttnn.reshape"(%1) <{shape = [72 : i32, 1 : i32, 1 : i32]}> : (tensor<72xui32, #ttnn_layout28>) -> tensor<72x1x1xui32, #ttnn_layout29> loc(#loc4)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<72xui32, #ttnn_layout28>) -> () loc(#loc4)
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<72x1x1xui32, #ttnn_layout29>) -> tensor<72x1x1xbf16, #ttnn_layout27> loc(#loc118)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<72x1x1xui32, #ttnn_layout29>) -> () loc(#loc118)
        return %3 : tensor<72x1x1xbf16, #ttnn_layout27> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_10(%arg0: tensor<64xf32, #ttnn_layout30> loc(unknown)) -> (tensor<1x1x18x128xf32, #ttnn_layout31>, tensor<1x1x18x128xf32, #ttnn_layout31>) attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<64xf32, #ttnn_layout30>, !ttnn.device) -> tensor<64xf32, #ttnn_layout32> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<64xf32, #ttnn_layout32>) -> tensor<64xf32, #ttnn_layout33> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<64xf32, #ttnn_layout32>) -> () loc(#loc)
        %3 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[[[0.000000e+00, 1.000000e+00, 2.000000e+00, 3.000000e+00, 4.000000e+00, 5.000000e+00, 6.000000e+00, 7.000000e+00, 8.000000e+00, 9.000000e+00, 1.000000e+01, 1.100000e+01, 1.200000e+01, 1.300000e+01, 1.400000e+01, 1.500000e+01, 1.600000e+01, 1.700000e+01]]]> : tensor<1x1x18xf32>}> : (!ttnn.device) -> tensor<1x1x18xf32, #ttnn_layout34> loc(#loc)
        %4 = "ttnn.reshape"(%2) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32, #ttnn_layout33>) -> tensor<1x64x1xf32, #ttnn_layout35> loc(#loc6)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<64xf32, #ttnn_layout33>) -> () loc(#loc6)
        %5 = "ttnn.matmul"(%4, %3) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = false}> : (tensor<1x64x1xf32, #ttnn_layout35>, tensor<1x1x18xf32, #ttnn_layout34>) -> tensor<1x64x18xf32, #ttnn_layout35> loc(#loc7)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1x64x1xf32, #ttnn_layout35>) -> () loc(#loc7)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x18xf32, #ttnn_layout34>) -> () loc(#loc7)
        %6 = "ttnn.permute"(%5) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x18xf32, #ttnn_layout35>) -> tensor<1x18x64xf32, #ttnn_layout36> loc(#loc8)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1x64x18xf32, #ttnn_layout35>) -> () loc(#loc8)
        %7 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 18 : i32, 64 : i32]}> : (tensor<1x18x64xf32, #ttnn_layout36>) -> tensor<1x1x18x64xf32, #ttnn_layout37> loc(#loc9)
        %8 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 18 : i32, 64 : i32]}> : (tensor<1x18x64xf32, #ttnn_layout36>) -> tensor<1x1x18x64xf32, #ttnn_layout37> loc(#loc9)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1x18x64xf32, #ttnn_layout36>) -> () loc(#loc9)
        %9 = "ttnn.concat"(%7, %8) <{dim = 3 : si32}> : (tensor<1x1x18x64xf32, #ttnn_layout37>, tensor<1x1x18x64xf32, #ttnn_layout37>) -> tensor<1x1x18x128xf32, #ttnn_layout31> loc(#loc9)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x1x18x64xf32, #ttnn_layout37>) -> () loc(#loc9)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x18x64xf32, #ttnn_layout37>) -> () loc(#loc9)
        %10 = "ttnn.cos"(%9) : (tensor<1x1x18x128xf32, #ttnn_layout31>) -> tensor<1x1x18x128xf32, #ttnn_layout31> loc(#loc10)
        %11 = "ttnn.sin"(%9) : (tensor<1x1x18x128xf32, #ttnn_layout31>) -> tensor<1x1x18x128xf32, #ttnn_layout31> loc(#loc11)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x18x128xf32, #ttnn_layout31>) -> () loc(#loc11)
        return %10, %11 : tensor<1x1x18x128xf32, #ttnn_layout31>, tensor<1x1x18x128xf32, #ttnn_layout31> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_11() -> (tensor<4x1x18x18xf32, #ttnn_layout1>, tensor<4x8x18x18xf32, #ttnn_layout38>, tensor<72xf32, #ttnn_layout39>) attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn_layout2> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32]}> : (tensor<f32, #ttnn_layout2>) -> tensor<1xf32, #ttnn_layout40> loc(#loc)
        %3 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout2>) -> tensor<1x1x1x1xf32, #ttnn_layout3> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn_layout2>) -> () loc(#loc)
        %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<4x1x18x18>}> : (tensor<1x1x1x1xf32, #ttnn_layout3>) -> tensor<4x1x18x18xf32, #ttnn_layout1> loc(#loc2)
        %5 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<4x8x18x18>}> : (tensor<1x1x1x1xf32, #ttnn_layout3>) -> tensor<4x8x18x18xf32, #ttnn_layout38> loc(#loc12)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn_layout3>) -> () loc(#loc12)
        %6 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<72>}> : (tensor<1xf32, #ttnn_layout40>) -> tensor<72xf32, #ttnn_layout39> loc(#loc13)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1xf32, #ttnn_layout40>) -> () loc(#loc13)
        return %4, %5, %6 : tensor<4x1x18x18xf32, #ttnn_layout1>, tensor<4x8x18x18xf32, #ttnn_layout38>, tensor<72xf32, #ttnn_layout39> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_12() -> (tensor<1x1xsi32, #ttnn_layout41>, tensor<1x1x18x18xbf16, #ttnn_layout42>, tensor<1x72xui32, #ttnn_layout43>, tensor<72xf32, #ttnn_layout39>) attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[[1.800000e+01], [1.000000e+00]]> : tensor<2x1xf32>}> : (!ttnn.device) -> tensor<2x1xf32, #ttnn_layout> loc(#loc119)
        %2 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3]> : tensor<4xsi32>}> : (!ttnn.device) -> tensor<4xsi32, #ttnn_layout4> loc(#loc)
        %3 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]> : tensor<18xsi32>}> : (!ttnn.device) -> tensor<18xsi32, #ttnn_layout4> loc(#loc)
        %4 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = 0 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn_layout5> loc(#loc)
        %5 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = 18 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn_layout5> loc(#loc)
        %6 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = 4 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn_layout5> loc(#loc)
        %7 = "ttnn.reshape"(%4) <{shape = [1 : i32]}> : (tensor<si32, #ttnn_layout5>) -> tensor<1xsi32, #ttnn_layout4> loc(#loc)
        %8 = "ttnn.reshape"(%5) <{shape = [1 : i32, 1 : i32]}> : (tensor<si32, #ttnn_layout5>) -> tensor<1x1xsi32, #ttnn_layout41> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<si32, #ttnn_layout5>) -> () loc(#loc)
        %9 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<si32, #ttnn_layout5>) -> tensor<1x1xsi32, #ttnn_layout41> loc(#loc)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<si32, #ttnn_layout5>) -> () loc(#loc)
        %10 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32]}> : (tensor<si32, #ttnn_layout5>) -> tensor<1x1xsi32, #ttnn_layout41> loc(#loc)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<si32, #ttnn_layout5>) -> () loc(#loc)
        %11 = "ttnn.reshape"(%3) <{shape = [1 : i32, 18 : i32]}> : (tensor<18xsi32, #ttnn_layout4>) -> tensor<1x18xsi32, #ttnn_layout41> loc(#loc15)
        %12 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32, 1 : i32, 18 : i32]}> : (tensor<18xsi32, #ttnn_layout4>) -> tensor<1x1x1x18xsi32, #ttnn_layout44> loc(#loc164)
        %13 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32, 18 : i32, 1 : i32]}> : (tensor<18xsi32, #ttnn_layout4>) -> tensor<1x1x18x1xsi32, #ttnn_layout44> loc(#loc165)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<18xsi32, #ttnn_layout4>) -> () loc(#loc165)
        %14 = "ttnn.le"(%12, %13) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x18xsi32, #ttnn_layout44>, tensor<1x1x18x1xsi32, #ttnn_layout44>) -> tensor<1x1x18x18xbf16, #ttnn_layout42> loc(#loc17)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<1x1x18x1xsi32, #ttnn_layout44>) -> () loc(#loc17)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x1x1x18xsi32, #ttnn_layout44>) -> () loc(#loc17)
        %15 = "ttnn.reshape"(%2) <{shape = [4 : i32, 1 : i32]}> : (tensor<4xsi32, #ttnn_layout4>) -> tensor<4x1xsi32, #ttnn_layout41> loc(#loc18)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<4xsi32, #ttnn_layout4>) -> () loc(#loc18)
        %16 = "ttnn.lt"(%15, %10) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<4x1xsi32, #ttnn_layout41>, tensor<1x1xsi32, #ttnn_layout41>) -> tensor<4x1xbf16, #ttnn_layout45> loc(#loc19)
        %17 = "ttnn.add"(%15, %9) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<4x1xsi32, #ttnn_layout41>, tensor<1x1xsi32, #ttnn_layout41>) -> tensor<4x1xsi32, #ttnn_layout41> loc(#loc20)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1xsi32, #ttnn_layout41>) -> () loc(#loc20)
        %18 = "ttnn.typecast"(%16) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x1xbf16, #ttnn_layout45>) -> tensor<4x1xf32, #ttnn_layout> loc(#loc121)
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<4x1xbf16, #ttnn_layout45>) -> () loc(#loc121)
        %19 = "ttnn.typecast"(%17) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x1xsi32, #ttnn_layout41>) -> tensor<4x1xf32, #ttnn_layout> loc(#loc121)
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<4x1xsi32, #ttnn_layout41>) -> () loc(#loc121)
        %20 = "ttnn.typecast"(%15) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x1xsi32, #ttnn_layout41>) -> tensor<4x1xf32, #ttnn_layout> loc(#loc121)
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<4x1xsi32, #ttnn_layout41>) -> () loc(#loc121)
        %21 = "ttnn.where"(%18, %19, %20) : (tensor<4x1xf32, #ttnn_layout>, tensor<4x1xf32, #ttnn_layout>, tensor<4x1xf32, #ttnn_layout>) -> tensor<4x1xf32, #ttnn_layout> loc(#loc21)
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<4x1xf32, #ttnn_layout>) -> () loc(#loc21)
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<4x1xf32, #ttnn_layout>) -> () loc(#loc21)
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<4x1xf32, #ttnn_layout>) -> () loc(#loc21)
        %22 = "ttnn.typecast"(%21) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<4x1xf32, #ttnn_layout>) -> tensor<4x1xsi32, #ttnn_layout41> loc(#loc121)
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<4x1xf32, #ttnn_layout>) -> () loc(#loc121)
        %23 = "ttnn.repeat"(%22) <{repeat_dims = #ttnn.shape<1x18>}> : (tensor<4x1xsi32, #ttnn_layout41>) -> tensor<4x18xsi32, #ttnn_layout41> loc(#loc21)
        "ttnn.deallocate"(%22) <{force = false}> : (tensor<4x1xsi32, #ttnn_layout41>) -> () loc(#loc21)
        %24 = "ttnn.reshape"(%23) <{shape = [4 : i32, 18 : i32, 1 : i32]}> : (tensor<4x18xsi32, #ttnn_layout41>) -> tensor<4x18x1xsi32, #ttnn_layout46> loc(#loc22)
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<4x18xsi32, #ttnn_layout41>) -> () loc(#loc22)
        %25 = "ttnn.lt"(%11, %10) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x18xsi32, #ttnn_layout41>, tensor<1x1xsi32, #ttnn_layout41>) -> tensor<1x18xbf16, #ttnn_layout45> loc(#loc23)
        %26 = "ttnn.add"(%11, %8) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<1x18xsi32, #ttnn_layout41>, tensor<1x1xsi32, #ttnn_layout41>) -> tensor<1x18xsi32, #ttnn_layout41> loc(#loc24)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x1xsi32, #ttnn_layout41>) -> () loc(#loc24)
        %27 = "ttnn.typecast"(%25) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x18xbf16, #ttnn_layout45>) -> tensor<1x18xf32, #ttnn_layout> loc(#loc122)
        "ttnn.deallocate"(%25) <{force = false}> : (tensor<1x18xbf16, #ttnn_layout45>) -> () loc(#loc122)
        %28 = "ttnn.typecast"(%26) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x18xsi32, #ttnn_layout41>) -> tensor<1x18xf32, #ttnn_layout> loc(#loc122)
        "ttnn.deallocate"(%26) <{force = false}> : (tensor<1x18xsi32, #ttnn_layout41>) -> () loc(#loc122)
        %29 = "ttnn.typecast"(%11) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x18xsi32, #ttnn_layout41>) -> tensor<1x18xf32, #ttnn_layout> loc(#loc122)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x18xsi32, #ttnn_layout41>) -> () loc(#loc122)
        %30 = "ttnn.where"(%27, %28, %29) : (tensor<1x18xf32, #ttnn_layout>, tensor<1x18xf32, #ttnn_layout>, tensor<1x18xf32, #ttnn_layout>) -> tensor<1x18xf32, #ttnn_layout> loc(#loc25)
        "ttnn.deallocate"(%29) <{force = false}> : (tensor<1x18xf32, #ttnn_layout>) -> () loc(#loc25)
        "ttnn.deallocate"(%28) <{force = false}> : (tensor<1x18xf32, #ttnn_layout>) -> () loc(#loc25)
        "ttnn.deallocate"(%27) <{force = false}> : (tensor<1x18xf32, #ttnn_layout>) -> () loc(#loc25)
        %31 = "ttnn.typecast"(%30) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<1x18xf32, #ttnn_layout>) -> tensor<1x18xsi32, #ttnn_layout41> loc(#loc122)
        "ttnn.deallocate"(%30) <{force = false}> : (tensor<1x18xf32, #ttnn_layout>) -> () loc(#loc122)
        %32 = "ttnn.repeat"(%31) <{repeat_dims = #ttnn.shape<4x1>}> : (tensor<1x18xsi32, #ttnn_layout41>) -> tensor<4x18xsi32, #ttnn_layout41> loc(#loc25)
        "ttnn.deallocate"(%31) <{force = false}> : (tensor<1x18xsi32, #ttnn_layout41>) -> () loc(#loc25)
        %33 = "ttnn.reshape"(%32) <{shape = [4 : i32, 18 : i32, 1 : i32]}> : (tensor<4x18xsi32, #ttnn_layout41>) -> tensor<4x18x1xsi32, #ttnn_layout46> loc(#loc26)
        "ttnn.deallocate"(%32) <{force = false}> : (tensor<4x18xsi32, #ttnn_layout41>) -> () loc(#loc26)
        %34 = "ttnn.typecast"(%24) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<4x18x1xsi32, #ttnn_layout46>) -> tensor<4x18x1xbf16, #ttnn_layout47> loc(#loc123)
        "ttnn.deallocate"(%24) <{force = false}> : (tensor<4x18x1xsi32, #ttnn_layout46>) -> () loc(#loc123)
        %35 = "ttnn.typecast"(%33) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<4x18x1xsi32, #ttnn_layout46>) -> tensor<4x18x1xbf16, #ttnn_layout47> loc(#loc123)
        "ttnn.deallocate"(%33) <{force = false}> : (tensor<4x18x1xsi32, #ttnn_layout46>) -> () loc(#loc123)
        %36 = "ttnn.concat"(%34, %35) <{dim = 2 : si32}> : (tensor<4x18x1xbf16, #ttnn_layout47>, tensor<4x18x1xbf16, #ttnn_layout47>) -> tensor<4x18x2xbf16, #ttnn_layout47> loc(#loc27)
        "ttnn.deallocate"(%35) <{force = false}> : (tensor<4x18x1xbf16, #ttnn_layout47>) -> () loc(#loc27)
        "ttnn.deallocate"(%34) <{force = false}> : (tensor<4x18x1xbf16, #ttnn_layout47>) -> () loc(#loc27)
        %37 = "ttnn.typecast"(%36) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<4x18x2xbf16, #ttnn_layout47>) -> tensor<4x18x2xsi32, #ttnn_layout46> loc(#loc123)
        "ttnn.deallocate"(%36) <{force = false}> : (tensor<4x18x2xbf16, #ttnn_layout47>) -> () loc(#loc123)
        %38 = "ttnn.typecast"(%37) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x18x2xsi32, #ttnn_layout46>) -> tensor<4x18x2xf32, #ttnn_layout48> loc(#loc124)
        "ttnn.deallocate"(%37) <{force = false}> : (tensor<4x18x2xsi32, #ttnn_layout46>) -> () loc(#loc124)
        %39 = "ttnn.matmul"(%38, %1) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = false}> : (tensor<4x18x2xf32, #ttnn_layout48>, tensor<2x1xf32, #ttnn_layout>) -> tensor<4x18x1xf32, #ttnn_layout48> loc(#loc14)
        "ttnn.deallocate"(%38) <{force = false}> : (tensor<4x18x2xf32, #ttnn_layout48>) -> () loc(#loc14)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<2x1xf32, #ttnn_layout>) -> () loc(#loc14)
        %40 = "ttnn.reshape"(%39) <{shape = [1 : i32, 72 : i32]}> : (tensor<4x18x1xf32, #ttnn_layout48>) -> tensor<1x72xf32, #ttnn_layout49> loc(#loc125)
        "ttnn.deallocate"(%39) <{force = false}> : (tensor<4x18x1xf32, #ttnn_layout48>) -> () loc(#loc125)
        %41 = "ttnn.typecast"(%40) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x72xf32, #ttnn_layout49>) -> tensor<1x72xui32, #ttnn_layout50> loc(#loc126)
        "ttnn.deallocate"(%40) <{force = false}> : (tensor<1x72xf32, #ttnn_layout49>) -> () loc(#loc126)
        %42 = "ttnn.to_layout"(%41) <{layout = #ttnn.layout<row_major>}> : (tensor<1x72xui32, #ttnn_layout50>) -> tensor<1x72xui32, #ttnn_layout43> loc(#loc126)
        "ttnn.deallocate"(%41) <{force = false}> : (tensor<1x72xui32, #ttnn_layout50>) -> () loc(#loc126)
        %43 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<72>}> : (tensor<1xsi32, #ttnn_layout4>) -> tensor<72xsi32, #ttnn_layout51> loc(#loc28)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1xsi32, #ttnn_layout4>) -> () loc(#loc28)
        %44 = "ttnn.typecast"(%43) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<72xsi32, #ttnn_layout51>) -> tensor<72xf32, #ttnn_layout39> loc(#loc127)
        "ttnn.deallocate"(%43) <{force = false}> : (tensor<72xsi32, #ttnn_layout51>) -> () loc(#loc127)
        return %10, %14, %42, %44 : tensor<1x1xsi32, #ttnn_layout41>, tensor<1x1x18x18xbf16, #ttnn_layout42>, tensor<1x72xui32, #ttnn_layout43>, tensor<72xf32, #ttnn_layout39> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_13(%arg0: tensor<1024x2048xf32, #ttnn_layout52> loc(unknown)) -> tensor<1024x1024xf32, #ttnn_layout13> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1024x2048xf32, #ttnn_layout52>, !ttnn.device) -> tensor<1024x2048xf32, #ttnn_layout53> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1024x2048xf32, #ttnn_layout53>) -> tensor<1024x2048xf32, #ttnn_layout54> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1024x2048xf32, #ttnn_layout53>) -> () loc(#loc)
        %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x2048xf32, #ttnn_layout54>, !ttnn.device) -> tensor<1024x1024xf32, #ttnn_layout13> loc(#loc)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1024x2048xf32, #ttnn_layout54>) -> () loc(#loc)
        return %3 : tensor<1024x1024xf32, #ttnn_layout13> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_14(%arg0: tensor<3072x1024xf32, #ttnn_layout14> loc(unknown)) -> tensor<1536x1024xf32, #ttnn_layout15> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<3072x1024xf32, #ttnn_layout14>, !ttnn.device) -> tensor<3072x1024xf32, #ttnn_layout16> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<3072x1024xf32, #ttnn_layout16>) -> tensor<3072x1024xf32, #ttnn_layout17> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072x1024xf32, #ttnn_layout16>) -> () loc(#loc)
        %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x1024xf32, #ttnn_layout17>, !ttnn.device) -> tensor<1536x1024xf32, #ttnn_layout15> loc(#loc)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<3072x1024xf32, #ttnn_layout17>) -> () loc(#loc)
        return %3 : tensor<1536x1024xf32, #ttnn_layout15> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_15() -> tensor<1x1x1x1xf32, #ttnn_layout3> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 0.297301769 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn_layout2> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout2>) -> tensor<1x1x1x1xf32, #ttnn_layout3> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn_layout2>) -> () loc(#loc)
        return %2 : tensor<1x1x1x1xf32, #ttnn_layout3> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_16(%arg0: tensor<1024x1024xf32, #ttnn_layout10> loc(unknown)) -> tensor<512x1024xf32, #ttnn_layout11> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1024x1024xf32, #ttnn_layout10>, !ttnn.device) -> tensor<1024x1024xf32, #ttnn_layout12> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1024x1024xf32, #ttnn_layout12>) -> tensor<1024x1024xf32, #ttnn_layout13> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1024x1024xf32, #ttnn_layout12>) -> () loc(#loc)
        %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x1024xf32, #ttnn_layout13>, !ttnn.device) -> tensor<512x1024xf32, #ttnn_layout11> loc(#loc)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1024x1024xf32, #ttnn_layout13>) -> () loc(#loc)
        return %3 : tensor<512x1024xf32, #ttnn_layout11> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_17() -> tensor<1x1x1x1xf32, #ttnn_layout3> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 0xFF800000 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn_layout2> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout2>) -> tensor<1x1x1x1xf32, #ttnn_layout3> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn_layout2>) -> () loc(#loc)
        return %2 : tensor<1x1x1x1xf32, #ttnn_layout3> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_18() -> tensor<4x8x18xbf16, #ttnn_layout47> attributes {tt.function_type = "const_eval"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<4x8x18>}> : (!ttnn.device) -> tensor<4x8x18xbf16, #ttnn_layout47> loc(#loc128)
        return %1 : tensor<4x8x18xbf16, #ttnn_layout47> loc(#loc)
      } loc(#loc)
      func.func @main(%arg0: tensor<1024x1024xf32, #ttnn_layout10> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<512x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p0.1"), %arg1: tensor<1024xf32, #ttnn_layout55> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024xf32>>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p1.6"), %arg2: tensor<4x18xsi32, #ttnn_layout56> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<4x18xi64>>, ttir.name = "args_0"} loc("p2.14"), %arg3: tensor<151936x1024xf32, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<151936x1024xf32>>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p3.19"), %arg4: tensor<64xf32, #ttnn_layout30> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<64xf32>>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p4.70"), %arg5: tensor<128xf32, #ttnn_layout57> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<128xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_norm_weight"} loc("p5.85"), %arg6: tensor<1024x1024xf32, #ttnn_layout10> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<512x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p6.93"), %arg7: tensor<151936x1024xf32, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<75968x1024xf32>>, ttir.name = "l__self___lm_head_weight"} loc("p7.190"), %arg8: tensor<1024xf32, #ttnn_layout55> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024xf32>>, ttir.name = "l__self___model_norm_weight"} loc("p8.195"), %arg9: tensor<1024x3072xf32, #ttnn_layout23> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024x1536xf32>>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p9.204"), %arg10: tensor<3072x1024xf32, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1536x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p10.209"), %arg11: tensor<1024xf32, #ttnn_layout55> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024xf32>>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p11.214"), %arg12: tensor<1024x2048xf32, #ttnn_layout52> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p12.223"), %arg13: tensor<4x18xsi32, #ttnn_layout56> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<4x18xi64>>, ttir.name = "args_1"} loc("p13.284"), %arg14: tensor<bf16, #ttnn_layout58> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<i1>>} loc("p14.296"), %arg15: tensor<128xf32, #ttnn_layout57> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<128xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_norm_weight"} loc("p15.328"), %arg16: tensor<2048x1024xf32, #ttnn_layout18> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1024x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p16.336"), %arg17: tensor<3072x1024xf32, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<1536x1024xf32>>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p17.495")) -> (tensor<4x8x18x128xf32, #ttnn_layout59> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<4x8x18x128xf32>>}, tensor<4x8x18x128xf32, #ttnn_layout59> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<4x8x18x128xf32>>}, tensor<72xf32, #ttnn_layout39> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<72xf32>>}, tensor<4x18x151936xf32, #ttnn_layout60> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<4x18x151936xf32>>}) attributes {tt.function_type = "forward_device"} {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<2x1xf32, #ttnn_layout> loc(#loc)
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<4x1x18x18xf32, #ttnn_layout1> loc(#loc)
        %2 = ttcore.load_cached(@main_const_eval_2, []) : () -> tensor<1xsi32, #ttnn_layout4> loc(#loc)
        %3 = ttcore.load_cached(@main_const_eval_3, [%arg7]) : (tensor<151936x1024xf32, #ttnn_layout6>) -> tensor<75968x1024xf32, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<151936x1024xf32, #ttnn_layout6>) -> () loc(#loc)
        %4 = ttcore.load_cached(@main_const_eval_4, [%arg0]) : (tensor<1024x1024xf32, #ttnn_layout10>) -> tensor<512x1024xf32, #ttnn_layout11> loc(#loc)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<1024x1024xf32, #ttnn_layout10>) -> () loc(#loc)
        %5 = ttcore.load_cached(@main_const_eval_5, [%arg10]) : (tensor<3072x1024xf32, #ttnn_layout14>) -> tensor<1536x1024xf32, #ttnn_layout15> loc(#loc)
        "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<3072x1024xf32, #ttnn_layout14>) -> () loc(#loc)
        %6 = ttcore.load_cached(@main_const_eval_6, [%arg16]) : (tensor<2048x1024xf32, #ttnn_layout18>) -> tensor<1024x1024xf32, #ttnn_layout13> loc(#loc)
        "ttnn.deallocate"(%arg16) <{force = false}> : (tensor<2048x1024xf32, #ttnn_layout18>) -> () loc(#loc)
        %7 = ttcore.load_cached(@main_const_eval_7, [%arg3]) : (tensor<151936x1024xf32, #ttnn_layout6>) -> tensor<151936x1024xbf16, #ttnn_layout21> loc(#loc)
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<151936x1024xf32, #ttnn_layout6>) -> () loc(#loc)
        %8 = ttcore.load_cached(@main_const_eval_8, [%arg9]) : (tensor<1024x3072xf32, #ttnn_layout23>) -> tensor<1024x1536xf32, #ttnn_layout24> loc(#loc)
        "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<1024x3072xf32, #ttnn_layout23>) -> () loc(#loc)
        %9 = ttcore.load_cached(@main_const_eval_9, []) : () -> tensor<72x1x1xbf16, #ttnn_layout27> loc(#loc)
        %10:2 = ttcore.load_cached(@main_const_eval_10, [%arg4]) : (tensor<64xf32, #ttnn_layout30>) -> (tensor<1x1x18x128xf32, #ttnn_layout31>, tensor<1x1x18x128xf32, #ttnn_layout31>) loc(#loc)
        "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<64xf32, #ttnn_layout30>) -> () loc(#loc)
        %11:3 = ttcore.load_cached(@main_const_eval_11, []) : () -> (tensor<4x1x18x18xf32, #ttnn_layout1>, tensor<4x8x18x18xf32, #ttnn_layout38>, tensor<72xf32, #ttnn_layout39>) loc(#loc)
        %12:4 = ttcore.load_cached(@main_const_eval_12, []) : () -> (tensor<1x1xsi32, #ttnn_layout41>, tensor<1x1x18x18xbf16, #ttnn_layout42>, tensor<1x72xui32, #ttnn_layout43>, tensor<72xf32, #ttnn_layout39>) loc(#loc)
        %13 = ttcore.load_cached(@main_const_eval_13, [%arg12]) : (tensor<1024x2048xf32, #ttnn_layout52>) -> tensor<1024x1024xf32, #ttnn_layout13> loc(#loc)
        "ttnn.deallocate"(%arg12) <{force = false}> : (tensor<1024x2048xf32, #ttnn_layout52>) -> () loc(#loc)
        %14 = ttcore.load_cached(@main_const_eval_14, [%arg17]) : (tensor<3072x1024xf32, #ttnn_layout14>) -> tensor<1536x1024xf32, #ttnn_layout15> loc(#loc)
        "ttnn.deallocate"(%arg17) <{force = false}> : (tensor<3072x1024xf32, #ttnn_layout14>) -> () loc(#loc)
        %15 = ttcore.load_cached(@main_const_eval_15, []) : () -> tensor<1x1x1x1xf32, #ttnn_layout3> loc(#loc)
        %16 = ttcore.load_cached(@main_const_eval_16, [%arg6]) : (tensor<1024x1024xf32, #ttnn_layout10>) -> tensor<512x1024xf32, #ttnn_layout11> loc(#loc)
        "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<1024x1024xf32, #ttnn_layout10>) -> () loc(#loc)
        %17 = ttcore.load_cached(@main_const_eval_17, []) : () -> tensor<1x1x1x1xf32, #ttnn_layout3> loc(#loc)
        %18 = ttcore.load_cached(@main_const_eval_18, []) : () -> tensor<4x8x18xbf16, #ttnn_layout47> loc(#loc)
        %19 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %20 = "ttnn.distribute_tensor"(%arg14, %19) <{mapper_config = #ttnn.mesh_mapper_config<placements = [<replicate, -1 : i32>, <replicate, -1 : i32>], mesh_shape_override = [1 : ui32, 2 : ui32]>}> : (tensor<bf16, #ttnn_layout58>, !ttnn.device) -> tensor<bf16, #ttnn_layout58> loc(#loc)
        "ttnn.deallocate"(%arg14) <{force = false}> : (tensor<bf16, #ttnn_layout58>) -> () loc(#loc)
        %21 = "ttnn.to_layout"(%arg2) <{layout = #ttnn.layout<tile>}> : (tensor<4x18xsi32, #ttnn_layout56>) -> tensor<4x18xsi32, #ttnn_layout41> loc(#loc48)
        %22 = "ttnn.typecast"(%21) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<4x18xsi32, #ttnn_layout41>) -> tensor<4x18xui32, #ttnn_layout61> loc(#loc49)
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<4x18xsi32, #ttnn_layout41>) -> () loc(#loc49)
        %23 = "ttnn.reshape"(%22) <{shape = [1 : i32, 72 : i32]}> : (tensor<4x18xui32, #ttnn_layout61>) -> tensor<1x72xui32, #ttnn_layout50> loc(#loc49)
        "ttnn.deallocate"(%22) <{force = false}> : (tensor<4x18xui32, #ttnn_layout61>) -> () loc(#loc49)
        %24 = "ttnn.to_layout"(%23) <{layout = #ttnn.layout<row_major>}> : (tensor<1x72xui32, #ttnn_layout50>) -> tensor<1x72xui32, #ttnn_layout43> loc(#loc117)
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<1x72xui32, #ttnn_layout50>) -> () loc(#loc117)
        %25 = "ttnn.embedding"(%24, %7) : (tensor<1x72xui32, #ttnn_layout43>, tensor<151936x1024xbf16, #ttnn_layout21>) -> tensor<1x72x1024xbf16, #ttnn_layout62> loc(#loc3)
        "ttnn.deallocate"(%24) <{force = false}> : (tensor<1x72xui32, #ttnn_layout43>) -> () loc(#loc3)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<151936x1024xbf16, #ttnn_layout21>) -> () loc(#loc3)
        %26 = "ttnn.typecast"(%25) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x72x1024xbf16, #ttnn_layout62>) -> tensor<1x72x1024xf32, #ttnn_layout63> loc(#loc117)
        "ttnn.deallocate"(%25) <{force = false}> : (tensor<1x72x1024xbf16, #ttnn_layout62>) -> () loc(#loc117)
        %27 = "ttnn.reshape"(%26) <{shape = [72 : i32, 1024 : i32]}> : (tensor<1x72x1024xf32, #ttnn_layout63>) -> tensor<72x1024xf32, #ttnn_layout64> loc(#loc)
        %28 = "ttnn.rms_norm"(%27, %arg1) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, math_approx_mode = false, fp32_dest_acc_en = true, packer_l1_acc = true>, epsilon = 9.99999997E-7 : f32, operandSegmentSizes = array<i32: 1, 1, 0>}> : (tensor<72x1024xf32, #ttnn_layout64>, tensor<1024xf32, #ttnn_layout55>) -> tensor<72x1024xf32, #ttnn_layout64> loc(#loc)
        "ttnn.deallocate"(%27) <{force = false}> : (tensor<72x1024xf32, #ttnn_layout64>) -> () loc(#loc)
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<1024xf32, #ttnn_layout55>) -> () loc(#loc)
        %29 = "ttnn.matmul"(%28, %4) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<72x1024xf32, #ttnn_layout64>, tensor<512x1024xf32, #ttnn_layout11>) -> tensor<72x512xf32, #ttnn_layout65> loc(#loc50)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<512x1024xf32, #ttnn_layout11>) -> () loc(#loc50)
        %30 = "ttnn.reshape"(%29) <{shape = [4 : i32, 18 : i32, 4 : i32, 128 : i32]}> : (tensor<72x512xf32, #ttnn_layout65>) -> tensor<4x18x4x128xf32, #ttnn_layout66> loc(#loc51)
        "ttnn.deallocate"(%29) <{force = false}> : (tensor<72x512xf32, #ttnn_layout65>) -> () loc(#loc51)
        %31 = "ttnn.permute"(%30) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<4x18x4x128xf32, #ttnn_layout66>) -> tensor<4x4x18x128xf32, #ttnn_layout67> loc(#loc52)
        "ttnn.deallocate"(%30) <{force = false}> : (tensor<4x18x4x128xf32, #ttnn_layout66>) -> () loc(#loc52)
        %32 = "ttnn.matmul"(%28, %16) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<72x1024xf32, #ttnn_layout64>, tensor<512x1024xf32, #ttnn_layout11>) -> tensor<72x512xf32, #ttnn_layout65> loc(#loc53)
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<512x1024xf32, #ttnn_layout11>) -> () loc(#loc53)
        %33 = "ttnn.reshape"(%32) <{shape = [4 : i32, 18 : i32, 4 : i32, 128 : i32]}> : (tensor<72x512xf32, #ttnn_layout65>) -> tensor<4x18x4x128xf32, #ttnn_layout66> loc(#loc54)
        "ttnn.deallocate"(%32) <{force = false}> : (tensor<72x512xf32, #ttnn_layout65>) -> () loc(#loc54)
        %34 = "ttnn.rms_norm"(%33, %arg5) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, math_approx_mode = false, fp32_dest_acc_en = true, packer_l1_acc = true>, epsilon = 9.99999997E-7 : f32, operandSegmentSizes = array<i32: 1, 1, 0>}> : (tensor<4x18x4x128xf32, #ttnn_layout66>, tensor<128xf32, #ttnn_layout57>) -> tensor<4x18x4x128xf32, #ttnn_layout66> loc(#loc)
        "ttnn.deallocate"(%33) <{force = false}> : (tensor<4x18x4x128xf32, #ttnn_layout66>) -> () loc(#loc)
        "ttnn.deallocate"(%arg5) <{force = false}> : (tensor<128xf32, #ttnn_layout57>) -> () loc(#loc)
        %35 = "ttnn.permute"(%34) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<4x18x4x128xf32, #ttnn_layout66>) -> tensor<4x4x18x128xf32, #ttnn_layout67> loc(#loc55)
        "ttnn.deallocate"(%34) <{force = false}> : (tensor<4x18x4x128xf32, #ttnn_layout66>) -> () loc(#loc55)
        %36 = "ttnn.multiply"(%35, %10#0) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x4x18x128xf32, #ttnn_layout67>, tensor<1x1x18x128xf32, #ttnn_layout31>) -> tensor<4x4x18x128xf32, #ttnn_layout67> loc(#loc56)
        %37 = "ttnn.slice_static"(%35) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [4 : i32, 4 : i32, 18 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<4x4x18x128xf32, #ttnn_layout67>) -> tensor<4x4x18x64xf32, #ttnn_layout68> loc(#loc57)
        %38 = "ttnn.neg"(%37) : (tensor<4x4x18x64xf32, #ttnn_layout68>) -> tensor<4x4x18x64xf32, #ttnn_layout68> loc(#loc58)
        "ttnn.deallocate"(%37) <{force = false}> : (tensor<4x4x18x64xf32, #ttnn_layout68>) -> () loc(#loc58)
        %39 = "ttnn.slice_static"(%35) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [4 : i32, 4 : i32, 18 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<4x4x18x128xf32, #ttnn_layout67>) -> tensor<4x4x18x64xf32, #ttnn_layout68> loc(#loc59)
        "ttnn.deallocate"(%35) <{force = false}> : (tensor<4x4x18x128xf32, #ttnn_layout67>) -> () loc(#loc59)
        %40 = "ttnn.concat"(%38, %39) <{dim = 3 : si32}> : (tensor<4x4x18x64xf32, #ttnn_layout68>, tensor<4x4x18x64xf32, #ttnn_layout68>) -> tensor<4x4x18x128xf32, #ttnn_layout67> loc(#loc60)
        "ttnn.deallocate"(%39) <{force = false}> : (tensor<4x4x18x64xf32, #ttnn_layout68>) -> () loc(#loc60)
        "ttnn.deallocate"(%38) <{force = false}> : (tensor<4x4x18x64xf32, #ttnn_layout68>) -> () loc(#loc60)
        %41 = "ttnn.multiply"(%40, %10#1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x4x18x128xf32, #ttnn_layout67>, tensor<1x1x18x128xf32, #ttnn_layout31>) -> tensor<4x4x18x128xf32, #ttnn_layout67> loc(#loc61)
        "ttnn.deallocate"(%40) <{force = false}> : (tensor<4x4x18x128xf32, #ttnn_layout67>) -> () loc(#loc61)
        %42 = "ttnn.add"(%36, %41) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x4x18x128xf32, #ttnn_layout67>, tensor<4x4x18x128xf32, #ttnn_layout67>) -> tensor<4x4x18x128xf32, #ttnn_layout67> loc(#loc62)
        "ttnn.deallocate"(%41) <{force = false}> : (tensor<4x4x18x128xf32, #ttnn_layout67>) -> () loc(#loc62)
        "ttnn.deallocate"(%36) <{force = false}> : (tensor<4x4x18x128xf32, #ttnn_layout67>) -> () loc(#loc62)
        %43 = "ttnn.to_layout"(%arg2) <{layout = #ttnn.layout<tile>}> : (tensor<4x18xsi32, #ttnn_layout56>) -> tensor<4x18xsi32, #ttnn_layout41> loc(#loc129)
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<4x18xsi32, #ttnn_layout56>) -> () loc(#loc129)
        %44 = "ttnn.typecast"(%43) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<4x18xsi32, #ttnn_layout41>) -> tensor<4x18xbf16, #ttnn_layout45> loc(#loc129)
        "ttnn.deallocate"(%43) <{force = false}> : (tensor<4x18xsi32, #ttnn_layout41>) -> () loc(#loc129)
        %45 = "ttnn.pad"(%44) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>, padding = array<i32: 0, 0, 0, 1>, use_multicore = true, value = -1.000000e+02 : f32}> : (tensor<4x18xbf16, #ttnn_layout45>) -> tensor<4x19xbf16, #ttnn_layout45> loc(#loc63)
        "ttnn.deallocate"(%44) <{force = false}> : (tensor<4x18xbf16, #ttnn_layout45>) -> () loc(#loc63)
        %46 = "ttnn.typecast"(%45) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<4x19xbf16, #ttnn_layout45>) -> tensor<4x19xsi32, #ttnn_layout41> loc(#loc129)
        "ttnn.deallocate"(%45) <{force = false}> : (tensor<4x19xbf16, #ttnn_layout45>) -> () loc(#loc129)
        %47 = "ttnn.slice_static"(%46) <{begins = [0 : i32, 1 : i32], ends = [4 : i32, 19 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x19xsi32, #ttnn_layout41>) -> tensor<4x18xsi32, #ttnn_layout41> loc(#loc64)
        "ttnn.deallocate"(%46) <{force = false}> : (tensor<4x19xsi32, #ttnn_layout41>) -> () loc(#loc64)
        %48 = "ttnn.reshape"(%47) <{shape = [72 : i32]}> : (tensor<4x18xsi32, #ttnn_layout41>) -> tensor<72xsi32, #ttnn_layout51> loc(#loc65)
        "ttnn.deallocate"(%47) <{force = false}> : (tensor<4x18xsi32, #ttnn_layout41>) -> () loc(#loc65)
        %49 = "ttnn.ne"(%48, %2) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<72xsi32, #ttnn_layout51>, tensor<1xsi32, #ttnn_layout4>) -> tensor<72xbf16, #ttnn_layout69> loc(#loc66)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1xsi32, #ttnn_layout4>) -> () loc(#loc66)
        %50 = "ttnn.matmul"(%28, %6) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<72x1024xf32, #ttnn_layout64>, tensor<1024x1024xf32, #ttnn_layout13>) -> tensor<72x1024xf32, #ttnn_layout64> loc(#loc67)
        "ttnn.deallocate"(%28) <{force = false}> : (tensor<72x1024xf32, #ttnn_layout64>) -> () loc(#loc67)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1024x1024xf32, #ttnn_layout13>) -> () loc(#loc67)
        %51 = "ttnn.reshape"(%50) <{shape = [4 : i32, 18 : i32, 8 : i32, 128 : i32]}> : (tensor<72x1024xf32, #ttnn_layout64>) -> tensor<4x18x8x128xf32, #ttnn_layout66> loc(#loc68)
        "ttnn.deallocate"(%50) <{force = false}> : (tensor<72x1024xf32, #ttnn_layout64>) -> () loc(#loc68)
        %52 = "ttnn.rms_norm"(%51, %arg15) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, math_approx_mode = false, fp32_dest_acc_en = true, packer_l1_acc = true>, epsilon = 9.99999997E-7 : f32, operandSegmentSizes = array<i32: 1, 1, 0>}> : (tensor<4x18x8x128xf32, #ttnn_layout66>, tensor<128xf32, #ttnn_layout57>) -> tensor<4x18x8x128xf32, #ttnn_layout66> loc(#loc)
        "ttnn.deallocate"(%51) <{force = false}> : (tensor<4x18x8x128xf32, #ttnn_layout66>) -> () loc(#loc)
        "ttnn.deallocate"(%arg15) <{force = false}> : (tensor<128xf32, #ttnn_layout57>) -> () loc(#loc)
        %53 = "ttnn.permute"(%52) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<4x18x8x128xf32, #ttnn_layout66>) -> tensor<4x8x18x128xf32, #ttnn_layout59> loc(#loc69)
        "ttnn.deallocate"(%52) <{force = false}> : (tensor<4x18x8x128xf32, #ttnn_layout66>) -> () loc(#loc69)
        %54 = "ttnn.multiply"(%53, %10#0) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x8x18x128xf32, #ttnn_layout59>, tensor<1x1x18x128xf32, #ttnn_layout31>) -> tensor<4x8x18x128xf32, #ttnn_layout59> loc(#loc70)
        "ttnn.deallocate"(%10#0) <{force = false}> : (tensor<1x1x18x128xf32, #ttnn_layout31>) -> () loc(#loc70)
        %55 = "ttnn.slice_static"(%53) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [4 : i32, 8 : i32, 18 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<4x8x18x128xf32, #ttnn_layout59>) -> tensor<4x8x18x64xf32, #ttnn_layout70> loc(#loc71)
        %56 = "ttnn.neg"(%55) : (tensor<4x8x18x64xf32, #ttnn_layout70>) -> tensor<4x8x18x64xf32, #ttnn_layout70> loc(#loc72)
        "ttnn.deallocate"(%55) <{force = false}> : (tensor<4x8x18x64xf32, #ttnn_layout70>) -> () loc(#loc72)
        %57 = "ttnn.slice_static"(%53) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [4 : i32, 8 : i32, 18 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<4x8x18x128xf32, #ttnn_layout59>) -> tensor<4x8x18x64xf32, #ttnn_layout70> loc(#loc73)
        "ttnn.deallocate"(%53) <{force = false}> : (tensor<4x8x18x128xf32, #ttnn_layout59>) -> () loc(#loc73)
        %58 = "ttnn.concat"(%56, %57) <{dim = 3 : si32}> : (tensor<4x8x18x64xf32, #ttnn_layout70>, tensor<4x8x18x64xf32, #ttnn_layout70>) -> tensor<4x8x18x128xf32, #ttnn_layout59> loc(#loc74)
        "ttnn.deallocate"(%57) <{force = false}> : (tensor<4x8x18x64xf32, #ttnn_layout70>) -> () loc(#loc74)
        "ttnn.deallocate"(%56) <{force = false}> : (tensor<4x8x18x64xf32, #ttnn_layout70>) -> () loc(#loc74)
        %59 = "ttnn.multiply"(%58, %10#1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x8x18x128xf32, #ttnn_layout59>, tensor<1x1x18x128xf32, #ttnn_layout31>) -> tensor<4x8x18x128xf32, #ttnn_layout59> loc(#loc75)
        "ttnn.deallocate"(%58) <{force = false}> : (tensor<4x8x18x128xf32, #ttnn_layout59>) -> () loc(#loc75)
        "ttnn.deallocate"(%10#1) <{force = false}> : (tensor<1x1x18x128xf32, #ttnn_layout31>) -> () loc(#loc75)
        %60 = "ttnn.add"(%54, %59) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x8x18x128xf32, #ttnn_layout59>, tensor<4x8x18x128xf32, #ttnn_layout59>) -> tensor<4x8x18x128xf32, #ttnn_layout59> loc(#loc76)
        "ttnn.deallocate"(%59) <{force = false}> : (tensor<4x8x18x128xf32, #ttnn_layout59>) -> () loc(#loc76)
        "ttnn.deallocate"(%54) <{force = false}> : (tensor<4x8x18x128xf32, #ttnn_layout59>) -> () loc(#loc76)
        %61 = "ttnn.multiply"(%60, %15) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x8x18x128xf32, #ttnn_layout59>, tensor<1x1x1x1xf32, #ttnn_layout3>) -> tensor<4x8x18x128xf32, #ttnn_layout59> loc(#loc77)
        "ttnn.deallocate"(%60) <{force = false}> : (tensor<4x8x18x128xf32, #ttnn_layout59>) -> () loc(#loc77)
        %62 = "ttnn.reshape"(%42) <{shape = [4 : i32, 4 : i32, 1 : i32, 18 : i32, 128 : i32]}> : (tensor<4x4x18x128xf32, #ttnn_layout67>) -> tensor<4x4x1x18x128xf32, #ttnn_layout71> loc(#loc78)
        %63 = "ttnn.repeat"(%62) <{repeat_dims = #ttnn.shape<1x1x2x1x1>}> : (tensor<4x4x1x18x128xf32, #ttnn_layout71>) -> tensor<4x4x2x18x128xf32, #ttnn_layout72> loc(#loc78)
        "ttnn.deallocate"(%62) <{force = false}> : (tensor<4x4x1x18x128xf32, #ttnn_layout71>) -> () loc(#loc78)
        %64 = "ttnn.reshape"(%63) <{shape = [4 : i32, 8 : i32, 18 : i32, 128 : i32]}> : (tensor<4x4x2x18x128xf32, #ttnn_layout72>) -> tensor<4x8x18x128xf32, #ttnn_layout59> loc(#loc79)
        "ttnn.deallocate"(%63) <{force = false}> : (tensor<4x4x2x18x128xf32, #ttnn_layout72>) -> () loc(#loc79)
        %65 = "ttnn.permute"(%64) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<4x8x18x128xf32, #ttnn_layout59>) -> tensor<4x8x128x18xf32, #ttnn_layout73> loc(#loc80)
        "ttnn.deallocate"(%64) <{force = false}> : (tensor<4x8x18x128xf32, #ttnn_layout59>) -> () loc(#loc80)
        %66 = "ttnn.multiply"(%65, %15) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x8x128x18xf32, #ttnn_layout73>, tensor<1x1x1x1xf32, #ttnn_layout3>) -> tensor<4x8x128x18xf32, #ttnn_layout73> loc(#loc81)
        "ttnn.deallocate"(%65) <{force = false}> : (tensor<4x8x128x18xf32, #ttnn_layout73>) -> () loc(#loc81)
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn_layout3>) -> () loc(#loc81)
        %67 = "ttnn.to_device"(%20, %19) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<bf16, #ttnn_layout58>, !ttnn.device) -> tensor<bf16, #ttnn_layout74> loc(#loc152)
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<bf16, #ttnn_layout58>) -> () loc(#loc152)
        %68 = "ttnn.to_layout"(%67) <{layout = #ttnn.layout<tile>}> : (tensor<bf16, #ttnn_layout74>) -> tensor<bf16, #ttnn_layout75> loc(#loc152)
        "ttnn.deallocate"(%67) <{force = false}> : (tensor<bf16, #ttnn_layout74>) -> () loc(#loc152)
        %69 = "ttnn.reshape"(%68) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout75>) -> tensor<1x1x1x1xbf16, #ttnn_layout42> loc(#loc153)
        "ttnn.deallocate"(%68) <{force = false}> : (tensor<bf16, #ttnn_layout75>) -> () loc(#loc153)
        %70 = "ttnn.logical_and"(%69, %12#1) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x1xbf16, #ttnn_layout42>, tensor<1x1x18x18xbf16, #ttnn_layout42>) -> tensor<1x1x18x18xbf16, #ttnn_layout42> loc(#loc82)
        "ttnn.deallocate"(%69) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout42>) -> () loc(#loc82)
        "ttnn.deallocate"(%12#1) <{force = false}> : (tensor<1x1x18x18xbf16, #ttnn_layout42>) -> () loc(#loc82)
        %71 = "ttnn.to_layout"(%arg13) <{layout = #ttnn.layout<tile>}> : (tensor<4x18xsi32, #ttnn_layout56>) -> tensor<4x18xsi32, #ttnn_layout41> loc(#loc83)
        "ttnn.deallocate"(%arg13) <{force = false}> : (tensor<4x18xsi32, #ttnn_layout56>) -> () loc(#loc83)
        %72 = "ttnn.ne"(%71, %12#0) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<4x18xsi32, #ttnn_layout41>, tensor<1x1xsi32, #ttnn_layout41>) -> tensor<4x18xbf16, #ttnn_layout45> loc(#loc84)
        "ttnn.deallocate"(%71) <{force = false}> : (tensor<4x18xsi32, #ttnn_layout41>) -> () loc(#loc84)
        "ttnn.deallocate"(%12#0) <{force = false}> : (tensor<1x1xsi32, #ttnn_layout41>) -> () loc(#loc84)
        %73 = "ttnn.reshape"(%72) <{shape = [72 : i32, 1 : i32]}> : (tensor<4x18xbf16, #ttnn_layout45>) -> tensor<72x1xbf16, #ttnn_layout76> loc(#loc84)
        "ttnn.deallocate"(%72) <{force = false}> : (tensor<4x18xbf16, #ttnn_layout45>) -> () loc(#loc84)
        %74 = "ttnn.to_layout"(%73) <{layout = #ttnn.layout<row_major>}> : (tensor<72x1xbf16, #ttnn_layout76>) -> tensor<72x1xbf16, #ttnn_layout77> loc(#loc126)
        "ttnn.deallocate"(%73) <{force = false}> : (tensor<72x1xbf16, #ttnn_layout76>) -> () loc(#loc126)
        %75 = "ttnn.embedding"(%12#2, %74) : (tensor<1x72xui32, #ttnn_layout43>, tensor<72x1xbf16, #ttnn_layout77>) -> tensor<1x72x1xbf16, #ttnn_layout78> loc(#loc14)
        "ttnn.deallocate"(%74) <{force = false}> : (tensor<72x1xbf16, #ttnn_layout77>) -> () loc(#loc14)
        "ttnn.deallocate"(%12#2) <{force = false}> : (tensor<1x72xui32, #ttnn_layout43>) -> () loc(#loc14)
        %76 = "ttnn.reshape"(%75) <{shape = [4 : i32, 1 : i32, 1 : i32, 18 : i32]}> : (tensor<1x72x1xbf16, #ttnn_layout78>) -> tensor<4x1x1x18xbf16, #ttnn_layout79> loc(#loc130)
        "ttnn.deallocate"(%75) <{force = false}> : (tensor<1x72x1xbf16, #ttnn_layout78>) -> () loc(#loc130)
        %77 = "ttnn.logical_and"(%70, %76) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x18x18xbf16, #ttnn_layout42>, tensor<4x1x1x18xbf16, #ttnn_layout79>) -> tensor<4x1x18x18xbf16, #ttnn_layout79> loc(#loc85)
        "ttnn.deallocate"(%76) <{force = false}> : (tensor<4x1x1x18xbf16, #ttnn_layout79>) -> () loc(#loc85)
        "ttnn.deallocate"(%70) <{force = false}> : (tensor<1x1x18x18xbf16, #ttnn_layout42>) -> () loc(#loc85)
        %78 = "ttnn.typecast"(%77) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x1x18x18xbf16, #ttnn_layout79>) -> tensor<4x1x18x18xf32, #ttnn_layout1> loc(#loc131)
        "ttnn.deallocate"(%77) <{force = false}> : (tensor<4x1x18x18xbf16, #ttnn_layout79>) -> () loc(#loc131)
        %79 = "ttnn.where"(%78, %11#0, %1) : (tensor<4x1x18x18xf32, #ttnn_layout1>, tensor<4x1x18x18xf32, #ttnn_layout1>, tensor<4x1x18x18xf32, #ttnn_layout1>) -> tensor<4x1x18x18xf32, #ttnn_layout1> loc(#loc2)
        "ttnn.deallocate"(%78) <{force = false}> : (tensor<4x1x18x18xf32, #ttnn_layout1>) -> () loc(#loc2)
        "ttnn.deallocate"(%11#0) <{force = false}> : (tensor<4x1x18x18xf32, #ttnn_layout1>) -> () loc(#loc2)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<4x1x18x18xf32, #ttnn_layout1>) -> () loc(#loc2)
        %80 = "ttnn.repeat"(%79) <{repeat_dims = #ttnn.shape<1x8x1x1>}> : (tensor<4x1x18x18xf32, #ttnn_layout1>) -> tensor<4x8x18x18xf32, #ttnn_layout38> loc(#loc86)
        "ttnn.deallocate"(%79) <{force = false}> : (tensor<4x1x18x18xf32, #ttnn_layout1>) -> () loc(#loc86)
        %81 = "ttnn.matmul"(%61, %66) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = false}> : (tensor<4x8x18x128xf32, #ttnn_layout59>, tensor<4x8x128x18xf32, #ttnn_layout73>) -> tensor<4x8x18x18xf32, #ttnn_layout38> loc(#loc132)
        "ttnn.deallocate"(%66) <{force = false}> : (tensor<4x8x128x18xf32, #ttnn_layout73>) -> () loc(#loc132)
        "ttnn.deallocate"(%61) <{force = false}> : (tensor<4x8x18x128xf32, #ttnn_layout59>) -> () loc(#loc132)
        %82 = "ttnn.add"(%81, %80) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x8x18x18xf32, #ttnn_layout38>, tensor<4x8x18x18xf32, #ttnn_layout38>) -> tensor<4x8x18x18xf32, #ttnn_layout38> loc(#loc133)
        "ttnn.deallocate"(%81) <{force = false}> : (tensor<4x8x18x18xf32, #ttnn_layout38>) -> () loc(#loc133)
        "ttnn.deallocate"(%80) <{force = false}> : (tensor<4x8x18x18xf32, #ttnn_layout38>) -> () loc(#loc133)
        %83 = "ttnn.eq"(%82, %17) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<4x8x18x18xf32, #ttnn_layout38>, tensor<1x1x1x1xf32, #ttnn_layout3>) -> tensor<4x8x18x18xbf16, #ttnn_layout80> loc(#loc88)
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn_layout3>) -> () loc(#loc88)
        %84 = "ttnn.logical_not"(%83) : (tensor<4x8x18x18xbf16, #ttnn_layout80>) -> tensor<4x8x18x18xbf16, #ttnn_layout80> loc(#loc89)
        "ttnn.deallocate"(%83) <{force = false}> : (tensor<4x8x18x18xbf16, #ttnn_layout80>) -> () loc(#loc89)
        %85 = "ttnn.sum"(%84) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, dim_arg = [3 : i32], keep_dim = false}> : (tensor<4x8x18x18xbf16, #ttnn_layout80>) -> tensor<4x8x18xbf16, #ttnn_layout47> loc(#loc29)
        "ttnn.deallocate"(%84) <{force = false}> : (tensor<4x8x18x18xbf16, #ttnn_layout80>) -> () loc(#loc29)
        %86 = "ttnn.ne"(%85, %18) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<4x8x18xbf16, #ttnn_layout47>, tensor<4x8x18xbf16, #ttnn_layout47>) -> tensor<4x8x18xbf16, #ttnn_layout47> loc(#loc29)
        "ttnn.deallocate"(%85) <{force = false}> : (tensor<4x8x18xbf16, #ttnn_layout47>) -> () loc(#loc29)
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<4x8x18xbf16, #ttnn_layout47>) -> () loc(#loc29)
        %87 = "ttnn.logical_not"(%86) : (tensor<4x8x18xbf16, #ttnn_layout47>) -> tensor<4x8x18xbf16, #ttnn_layout47> loc(#loc90)
        "ttnn.deallocate"(%86) <{force = false}> : (tensor<4x8x18xbf16, #ttnn_layout47>) -> () loc(#loc90)
        %88 = "ttnn.reshape"(%87) <{shape = [4 : i32, 8 : i32, 18 : i32, 1 : i32]}> : (tensor<4x8x18xbf16, #ttnn_layout47>) -> tensor<4x8x18x1xbf16, #ttnn_layout80> loc(#loc90)
        "ttnn.deallocate"(%87) <{force = false}> : (tensor<4x8x18xbf16, #ttnn_layout47>) -> () loc(#loc90)
        %89 = "ttnn.softmax"(%82) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, dimension = 3 : si32, numericStable = true}> : (tensor<4x8x18x18xf32, #ttnn_layout38>) -> tensor<4x8x18x18xf32, #ttnn_layout38> loc(#loc91)
        "ttnn.deallocate"(%82) <{force = false}> : (tensor<4x8x18x18xf32, #ttnn_layout38>) -> () loc(#loc91)
        %90 = "ttnn.repeat"(%88) <{repeat_dims = #ttnn.shape<1x1x1x18>}> : (tensor<4x8x18x1xbf16, #ttnn_layout80>) -> tensor<4x8x18x18xbf16, #ttnn_layout80> loc(#loc12)
        "ttnn.deallocate"(%88) <{force = false}> : (tensor<4x8x18x1xbf16, #ttnn_layout80>) -> () loc(#loc12)
        %91 = "ttnn.typecast"(%90) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x8x18x18xbf16, #ttnn_layout80>) -> tensor<4x8x18x18xf32, #ttnn_layout38> loc(#loc134)
        "ttnn.deallocate"(%90) <{force = false}> : (tensor<4x8x18x18xbf16, #ttnn_layout80>) -> () loc(#loc134)
        %92 = "ttnn.where"(%91, %11#1, %89) : (tensor<4x8x18x18xf32, #ttnn_layout38>, tensor<4x8x18x18xf32, #ttnn_layout38>, tensor<4x8x18x18xf32, #ttnn_layout38>) -> tensor<4x8x18x18xf32, #ttnn_layout38> loc(#loc12)
        "ttnn.deallocate"(%91) <{force = false}> : (tensor<4x8x18x18xf32, #ttnn_layout38>) -> () loc(#loc12)
        "ttnn.deallocate"(%89) <{force = false}> : (tensor<4x8x18x18xf32, #ttnn_layout38>) -> () loc(#loc12)
        "ttnn.deallocate"(%11#1) <{force = false}> : (tensor<4x8x18x18xf32, #ttnn_layout38>) -> () loc(#loc12)
        %93 = "ttnn.reshape"(%31) <{shape = [4 : i32, 4 : i32, 1 : i32, 18 : i32, 128 : i32]}> : (tensor<4x4x18x128xf32, #ttnn_layout67>) -> tensor<4x4x1x18x128xf32, #ttnn_layout71> loc(#loc92)
        %94 = "ttnn.repeat"(%93) <{repeat_dims = #ttnn.shape<1x1x2x1x1>}> : (tensor<4x4x1x18x128xf32, #ttnn_layout71>) -> tensor<4x4x2x18x128xf32, #ttnn_layout72> loc(#loc92)
        "ttnn.deallocate"(%93) <{force = false}> : (tensor<4x4x1x18x128xf32, #ttnn_layout71>) -> () loc(#loc92)
        %95 = "ttnn.reshape"(%94) <{shape = [4 : i32, 8 : i32, 18 : i32, 128 : i32]}> : (tensor<4x4x2x18x128xf32, #ttnn_layout72>) -> tensor<4x8x18x128xf32, #ttnn_layout59> loc(#loc93)
        "ttnn.deallocate"(%94) <{force = false}> : (tensor<4x4x2x18x128xf32, #ttnn_layout72>) -> () loc(#loc93)
        %96 = "ttnn.matmul"(%92, %95) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = false}> : (tensor<4x8x18x18xf32, #ttnn_layout38>, tensor<4x8x18x128xf32, #ttnn_layout59>) -> tensor<4x8x18x128xf32, #ttnn_layout59> loc(#loc94)
        "ttnn.deallocate"(%95) <{force = false}> : (tensor<4x8x18x128xf32, #ttnn_layout59>) -> () loc(#loc94)
        "ttnn.deallocate"(%92) <{force = false}> : (tensor<4x8x18x18xf32, #ttnn_layout38>) -> () loc(#loc94)
        %97 = "ttnn.concatenate_heads"(%96) : (tensor<4x8x18x128xf32, #ttnn_layout59>) -> tensor<4x18x1024xf32, #ttnn_layout81> loc(#loc95)
        "ttnn.deallocate"(%96) <{force = false}> : (tensor<4x8x18x128xf32, #ttnn_layout59>) -> () loc(#loc95)
        %98 = "ttnn.reshape"(%97) <{shape = [72 : i32, 1024 : i32]}> : (tensor<4x18x1024xf32, #ttnn_layout81>) -> tensor<72x1024xf32, #ttnn_layout64> loc(#loc95)
        "ttnn.deallocate"(%97) <{force = false}> : (tensor<4x18x1024xf32, #ttnn_layout81>) -> () loc(#loc95)
        %99 = "ttnn.matmul"(%98, %13) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<72x1024xf32, #ttnn_layout64>, tensor<1024x1024xf32, #ttnn_layout13>) -> tensor<72x1024xf32, #ttnn_layout64> loc(#loc96)
        "ttnn.deallocate"(%98) <{force = false}> : (tensor<72x1024xf32, #ttnn_layout64>) -> () loc(#loc96)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<1024x1024xf32, #ttnn_layout13>) -> () loc(#loc96)
        %100 = "ttnn.reshape"(%99) <{shape = [1 : i32, 1 : i32, 72 : i32, 1024 : i32]}> : (tensor<72x1024xf32, #ttnn_layout64>) -> tensor<1x1x72x1024xf32, #ttnn_layout82> loc(#loc154)
        "ttnn.deallocate"(%99) <{force = false}> : (tensor<72x1024xf32, #ttnn_layout64>) -> () loc(#loc154)
        %101 = "ttnn.reduce_scatter"(%100) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 2 : si32}> : (tensor<1x1x72x1024xf32, #ttnn_layout82>) -> tensor<1x1x36x1024xf32, #ttnn_layout83> loc(#loc155)
        "ttnn.deallocate"(%100) <{force = false}> : (tensor<1x1x72x1024xf32, #ttnn_layout82>) -> () loc(#loc155)
        %102 = "ttnn.all_gather"(%101) <{all_gather_dim = 2 : si32, cluster_axis = 1 : ui32}> : (tensor<1x1x36x1024xf32, #ttnn_layout83>) -> tensor<1x1x72x1024xf32, #ttnn_layout82> loc(#loc136)
        "ttnn.deallocate"(%101) <{force = false}> : (tensor<1x1x36x1024xf32, #ttnn_layout83>) -> () loc(#loc136)
        %103 = "ttnn.reshape"(%102) <{shape = [72 : i32, 1024 : i32]}> : (tensor<1x1x72x1024xf32, #ttnn_layout82>) -> tensor<72x1024xf32, #ttnn_layout64> loc(#loc96)
        "ttnn.deallocate"(%102) <{force = false}> : (tensor<1x1x72x1024xf32, #ttnn_layout82>) -> () loc(#loc96)
        %104 = "ttnn.reshape"(%26) <{shape = [72 : i32, 1024 : i32]}> : (tensor<1x72x1024xf32, #ttnn_layout63>) -> tensor<72x1024xf32, #ttnn_layout64> loc(#loc)
        "ttnn.deallocate"(%26) <{force = false}> : (tensor<1x72x1024xf32, #ttnn_layout63>) -> () loc(#loc)
        %105 = "ttnn.add"(%104, %103) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<72x1024xf32, #ttnn_layout64>, tensor<72x1024xf32, #ttnn_layout64>) -> tensor<72x1024xf32, #ttnn_layout64> loc(#loc97)
        "ttnn.deallocate"(%104) <{force = false}> : (tensor<72x1024xf32, #ttnn_layout64>) -> () loc(#loc97)
        "ttnn.deallocate"(%103) <{force = false}> : (tensor<72x1024xf32, #ttnn_layout64>) -> () loc(#loc97)
        %106 = "ttnn.rms_norm"(%105, %arg11) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, math_approx_mode = false, fp32_dest_acc_en = true, packer_l1_acc = true>, epsilon = 9.99999997E-7 : f32, operandSegmentSizes = array<i32: 1, 1, 0>}> : (tensor<72x1024xf32, #ttnn_layout64>, tensor<1024xf32, #ttnn_layout55>) -> tensor<72x1024xf32, #ttnn_layout64> loc(#loc)
        "ttnn.deallocate"(%arg11) <{force = false}> : (tensor<1024xf32, #ttnn_layout55>) -> () loc(#loc)
        %107 = "ttnn.matmul"(%106, %14) <{activation = "silu", compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<72x1024xf32, #ttnn_layout64>, tensor<1536x1024xf32, #ttnn_layout15>) -> tensor<72x1536xf32, #ttnn_layout84> loc(#loc98)
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<1536x1024xf32, #ttnn_layout15>) -> () loc(#loc98)
        %108 = "ttnn.matmul"(%106, %5) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<72x1024xf32, #ttnn_layout64>, tensor<1536x1024xf32, #ttnn_layout15>) -> tensor<72x1536xf32, #ttnn_layout84> loc(#loc99)
        "ttnn.deallocate"(%106) <{force = false}> : (tensor<72x1024xf32, #ttnn_layout64>) -> () loc(#loc99)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1536x1024xf32, #ttnn_layout15>) -> () loc(#loc99)
        %109 = "ttnn.multiply"(%107, %108) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<72x1536xf32, #ttnn_layout84>, tensor<72x1536xf32, #ttnn_layout84>) -> tensor<72x1536xf32, #ttnn_layout84> loc(#loc100)
        "ttnn.deallocate"(%108) <{force = false}> : (tensor<72x1536xf32, #ttnn_layout84>) -> () loc(#loc100)
        "ttnn.deallocate"(%107) <{force = false}> : (tensor<72x1536xf32, #ttnn_layout84>) -> () loc(#loc100)
        %110 = "ttnn.matmul"(%109, %8) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<72x1536xf32, #ttnn_layout84>, tensor<1024x1536xf32, #ttnn_layout24>) -> tensor<72x1024xf32, #ttnn_layout64> loc(#loc101)
        "ttnn.deallocate"(%109) <{force = false}> : (tensor<72x1536xf32, #ttnn_layout84>) -> () loc(#loc101)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1024x1536xf32, #ttnn_layout24>) -> () loc(#loc101)
        %111 = "ttnn.reshape"(%110) <{shape = [1 : i32, 1 : i32, 72 : i32, 1024 : i32]}> : (tensor<72x1024xf32, #ttnn_layout64>) -> tensor<1x1x72x1024xf32, #ttnn_layout82> loc(#loc156)
        "ttnn.deallocate"(%110) <{force = false}> : (tensor<72x1024xf32, #ttnn_layout64>) -> () loc(#loc156)
        %112 = "ttnn.reduce_scatter"(%111) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 2 : si32}> : (tensor<1x1x72x1024xf32, #ttnn_layout82>) -> tensor<1x1x36x1024xf32, #ttnn_layout83> loc(#loc157)
        "ttnn.deallocate"(%111) <{force = false}> : (tensor<1x1x72x1024xf32, #ttnn_layout82>) -> () loc(#loc157)
        %113 = "ttnn.all_gather"(%112) <{all_gather_dim = 2 : si32, cluster_axis = 1 : ui32}> : (tensor<1x1x36x1024xf32, #ttnn_layout83>) -> tensor<1x1x72x1024xf32, #ttnn_layout82> loc(#loc138)
        "ttnn.deallocate"(%112) <{force = false}> : (tensor<1x1x36x1024xf32, #ttnn_layout83>) -> () loc(#loc138)
        %114 = "ttnn.reshape"(%113) <{shape = [72 : i32, 1024 : i32]}> : (tensor<1x1x72x1024xf32, #ttnn_layout82>) -> tensor<72x1024xf32, #ttnn_layout64> loc(#loc101)
        "ttnn.deallocate"(%113) <{force = false}> : (tensor<1x1x72x1024xf32, #ttnn_layout82>) -> () loc(#loc101)
        %115 = "ttnn.add"(%105, %114) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<72x1024xf32, #ttnn_layout64>, tensor<72x1024xf32, #ttnn_layout64>) -> tensor<72x1024xf32, #ttnn_layout64> loc(#loc102)
        "ttnn.deallocate"(%114) <{force = false}> : (tensor<72x1024xf32, #ttnn_layout64>) -> () loc(#loc102)
        "ttnn.deallocate"(%105) <{force = false}> : (tensor<72x1024xf32, #ttnn_layout64>) -> () loc(#loc102)
        %116 = "ttnn.rms_norm"(%115, %arg8) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, math_approx_mode = false, fp32_dest_acc_en = true, packer_l1_acc = true>, epsilon = 9.99999997E-7 : f32, operandSegmentSizes = array<i32: 1, 1, 0>}> : (tensor<72x1024xf32, #ttnn_layout64>, tensor<1024xf32, #ttnn_layout55>) -> tensor<72x1024xf32, #ttnn_layout64> loc(#loc)
        "ttnn.deallocate"(%115) <{force = false}> : (tensor<72x1024xf32, #ttnn_layout64>) -> () loc(#loc)
        "ttnn.deallocate"(%arg8) <{force = false}> : (tensor<1024xf32, #ttnn_layout55>) -> () loc(#loc)
        %117 = "ttnn.matmul"(%116, %3) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = true}> : (tensor<72x1024xf32, #ttnn_layout64>, tensor<75968x1024xf32, #ttnn_layout7>) -> tensor<72x75968xf32, #ttnn_layout85> loc(#loc103)
        "ttnn.deallocate"(%116) <{force = false}> : (tensor<72x1024xf32, #ttnn_layout64>) -> () loc(#loc103)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<75968x1024xf32, #ttnn_layout7>) -> () loc(#loc103)
        %118 = "ttnn.reshape"(%117) <{shape = [4 : i32, 18 : i32, 75968 : i32]}> : (tensor<72x75968xf32, #ttnn_layout85>) -> tensor<4x18x75968xf32, #ttnn_layout86> loc(#loc104)
        %119 = "ttnn.max"(%117) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, dim_arg = [1 : i32], keep_dim = false}> : (tensor<72x75968xf32, #ttnn_layout85>) -> tensor<72xf32, #ttnn_layout39> loc(#loc105)
        %120 = "ttnn.reshape"(%119) <{shape = [1 : i32, 1 : i32, 1 : i32, 72 : i32]}> : (tensor<72xf32, #ttnn_layout39>) -> tensor<1x1x1x72xf32, #ttnn_layout87> loc(#loc158)
        "ttnn.deallocate"(%119) <{force = false}> : (tensor<72xf32, #ttnn_layout39>) -> () loc(#loc158)
        %121 = "ttnn.reduce_scatter"(%120) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x72xf32, #ttnn_layout87>) -> tensor<1x1x1x36xf32, #ttnn_layout37> loc(#loc159)
        "ttnn.deallocate"(%120) <{force = false}> : (tensor<1x1x1x72xf32, #ttnn_layout87>) -> () loc(#loc159)
        %122 = "ttnn.all_gather"(%121) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32}> : (tensor<1x1x1x36xf32, #ttnn_layout37>) -> tensor<1x1x1x72xf32, #ttnn_layout87> loc(#loc140)
        "ttnn.deallocate"(%121) <{force = false}> : (tensor<1x1x1x36xf32, #ttnn_layout37>) -> () loc(#loc140)
        %123 = "ttnn.reshape"(%122) <{shape = [72 : i32, 1 : i32]}> : (tensor<1x1x1x72xf32, #ttnn_layout87>) -> tensor<72x1xf32, #ttnn_layout88> loc(#loc106)
        "ttnn.deallocate"(%122) <{force = false}> : (tensor<1x1x1x72xf32, #ttnn_layout87>) -> () loc(#loc106)
        %124 = "ttnn.neg"(%123) : (tensor<72x1xf32, #ttnn_layout88>) -> tensor<72x1xf32, #ttnn_layout88> loc(#loc141)
        "ttnn.deallocate"(%123) <{force = false}> : (tensor<72x1xf32, #ttnn_layout88>) -> () loc(#loc141)
        %125 = "ttnn.add"(%117, %124) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<72x75968xf32, #ttnn_layout85>, tensor<72x1xf32, #ttnn_layout88>) -> tensor<72x75968xf32, #ttnn_layout85> loc(#loc107)
        "ttnn.deallocate"(%124) <{force = false}> : (tensor<72x1xf32, #ttnn_layout88>) -> () loc(#loc107)
        "ttnn.deallocate"(%117) <{force = false}> : (tensor<72x75968xf32, #ttnn_layout85>) -> () loc(#loc107)
        %126 = "ttnn.exp"(%125) : (tensor<72x75968xf32, #ttnn_layout85>) -> tensor<72x75968xf32, #ttnn_layout85> loc(#loc108)
        %127 = "ttnn.sum"(%126) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, dim_arg = [1 : i32], keep_dim = false}> : (tensor<72x75968xf32, #ttnn_layout85>) -> tensor<72xf32, #ttnn_layout39> loc(#loc109)
        "ttnn.deallocate"(%126) <{force = false}> : (tensor<72x75968xf32, #ttnn_layout85>) -> () loc(#loc109)
        %128 = "ttnn.reshape"(%127) <{shape = [1 : i32, 1 : i32, 1 : i32, 72 : i32]}> : (tensor<72xf32, #ttnn_layout39>) -> tensor<1x1x1x72xf32, #ttnn_layout87> loc(#loc160)
        "ttnn.deallocate"(%127) <{force = false}> : (tensor<72xf32, #ttnn_layout39>) -> () loc(#loc160)
        %129 = "ttnn.reduce_scatter"(%128) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x72xf32, #ttnn_layout87>) -> tensor<1x1x1x36xf32, #ttnn_layout37> loc(#loc161)
        "ttnn.deallocate"(%128) <{force = false}> : (tensor<1x1x1x72xf32, #ttnn_layout87>) -> () loc(#loc161)
        %130 = "ttnn.all_gather"(%129) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32}> : (tensor<1x1x1x36xf32, #ttnn_layout37>) -> tensor<1x1x1x72xf32, #ttnn_layout87> loc(#loc143)
        "ttnn.deallocate"(%129) <{force = false}> : (tensor<1x1x1x36xf32, #ttnn_layout37>) -> () loc(#loc143)
        %131 = "ttnn.reshape"(%130) <{shape = [72 : i32]}> : (tensor<1x1x1x72xf32, #ttnn_layout87>) -> tensor<72xf32, #ttnn_layout39> loc(#loc109)
        "ttnn.deallocate"(%130) <{force = false}> : (tensor<1x1x1x72xf32, #ttnn_layout87>) -> () loc(#loc109)
        %132 = "ttnn.log"(%131) : (tensor<72xf32, #ttnn_layout39>) -> tensor<72xf32, #ttnn_layout39> loc(#loc110)
        "ttnn.deallocate"(%131) <{force = false}> : (tensor<72xf32, #ttnn_layout39>) -> () loc(#loc110)
        %133 = "ttnn.reshape"(%132) <{shape = [72 : i32, 1 : i32]}> : (tensor<72xf32, #ttnn_layout39>) -> tensor<72x1xf32, #ttnn_layout88> loc(#loc110)
        "ttnn.deallocate"(%132) <{force = false}> : (tensor<72xf32, #ttnn_layout39>) -> () loc(#loc110)
        %134 = "ttnn.neg"(%133) : (tensor<72x1xf32, #ttnn_layout88>) -> tensor<72x1xf32, #ttnn_layout88> loc(#loc144)
        "ttnn.deallocate"(%133) <{force = false}> : (tensor<72x1xf32, #ttnn_layout88>) -> () loc(#loc144)
        %135 = "ttnn.add"(%125, %134) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<72x75968xf32, #ttnn_layout85>, tensor<72x1xf32, #ttnn_layout88>) -> tensor<72x75968xf32, #ttnn_layout85> loc(#loc111)
        "ttnn.deallocate"(%134) <{force = false}> : (tensor<72x1xf32, #ttnn_layout88>) -> () loc(#loc111)
        "ttnn.deallocate"(%125) <{force = false}> : (tensor<72x75968xf32, #ttnn_layout85>) -> () loc(#loc111)
        %136 = "ttnn.reshape"(%135) <{shape = [5469696 : i32, 1 : i32]}> : (tensor<72x75968xf32, #ttnn_layout85>) -> tensor<5469696x1xf32, #ttnn_layout89> loc(#loc111)
        "ttnn.deallocate"(%135) <{force = false}> : (tensor<72x75968xf32, #ttnn_layout85>) -> () loc(#loc111)
        %137 = "ttnn.typecast"(%49) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<72xbf16, #ttnn_layout69>) -> tensor<72xf32, #ttnn_layout39> loc(#loc127)
        %138 = "ttnn.typecast"(%48) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<72xsi32, #ttnn_layout51>) -> tensor<72xf32, #ttnn_layout39> loc(#loc127)
        "ttnn.deallocate"(%48) <{force = false}> : (tensor<72xsi32, #ttnn_layout51>) -> () loc(#loc127)
        %139 = "ttnn.where"(%137, %138, %12#3) : (tensor<72xf32, #ttnn_layout39>, tensor<72xf32, #ttnn_layout39>, tensor<72xf32, #ttnn_layout39>) -> tensor<72xf32, #ttnn_layout39> loc(#loc28)
        "ttnn.deallocate"(%138) <{force = false}> : (tensor<72xf32, #ttnn_layout39>) -> () loc(#loc28)
        "ttnn.deallocate"(%137) <{force = false}> : (tensor<72xf32, #ttnn_layout39>) -> () loc(#loc28)
        "ttnn.deallocate"(%12#3) <{force = false}> : (tensor<72xf32, #ttnn_layout39>) -> () loc(#loc28)
        %140 = "ttnn.typecast"(%139) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<72xf32, #ttnn_layout39>) -> tensor<72xsi32, #ttnn_layout51> loc(#loc127)
        "ttnn.deallocate"(%139) <{force = false}> : (tensor<72xf32, #ttnn_layout39>) -> () loc(#loc127)
        %141 = "ttnn.typecast"(%140) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<72xsi32, #ttnn_layout51>) -> tensor<72xui32, #ttnn_layout28> loc(#loc112)
        "ttnn.deallocate"(%140) <{force = false}> : (tensor<72xsi32, #ttnn_layout51>) -> () loc(#loc112)
        %142 = "ttnn.reshape"(%141) <{shape = [72 : i32, 1 : i32, 1 : i32]}> : (tensor<72xui32, #ttnn_layout28>) -> tensor<72x1x1xui32, #ttnn_layout29> loc(#loc112)
        "ttnn.deallocate"(%141) <{force = false}> : (tensor<72xui32, #ttnn_layout28>) -> () loc(#loc112)
        %143 = "ttnn.typecast"(%142) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<72x1x1xui32, #ttnn_layout29>) -> tensor<72x1x1xbf16, #ttnn_layout27> loc(#loc118)
        "ttnn.deallocate"(%142) <{force = false}> : (tensor<72x1x1xui32, #ttnn_layout29>) -> () loc(#loc118)
        %144 = "ttnn.concat"(%9, %143) <{dim = 2 : si32}> : (tensor<72x1x1xbf16, #ttnn_layout27>, tensor<72x1x1xbf16, #ttnn_layout27>) -> tensor<72x1x2xbf16, #ttnn_layout27> loc(#loc5)
        "ttnn.deallocate"(%143) <{force = false}> : (tensor<72x1x1xbf16, #ttnn_layout27>) -> () loc(#loc5)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<72x1x1xbf16, #ttnn_layout27>) -> () loc(#loc5)
        %145 = "ttnn.typecast"(%144) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<72x1x2xbf16, #ttnn_layout27>) -> tensor<72x1x2xui32, #ttnn_layout29> loc(#loc118)
        "ttnn.deallocate"(%144) <{force = false}> : (tensor<72x1x2xbf16, #ttnn_layout27>) -> () loc(#loc118)
        %146 = "ttnn.typecast"(%145) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<72x1x2xui32, #ttnn_layout29>) -> tensor<72x1x2xf32, #ttnn_layout90> loc(#loc145)
        "ttnn.deallocate"(%145) <{force = false}> : (tensor<72x1x2xui32, #ttnn_layout29>) -> () loc(#loc145)
        %147 = "ttnn.matmul"(%146, %0) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = false}> : (tensor<72x1x2xf32, #ttnn_layout90>, tensor<2x1xf32, #ttnn_layout>) -> tensor<72x1x1xf32, #ttnn_layout90> loc(#loc1)
        "ttnn.deallocate"(%146) <{force = false}> : (tensor<72x1x2xf32, #ttnn_layout90>) -> () loc(#loc1)
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<2x1xf32, #ttnn_layout>) -> () loc(#loc1)
        %148 = "ttnn.reshape"(%147) <{shape = [1 : i32, 72 : i32]}> : (tensor<72x1x1xf32, #ttnn_layout90>) -> tensor<1x72xf32, #ttnn_layout49> loc(#loc146)
        "ttnn.deallocate"(%147) <{force = false}> : (tensor<72x1x1xf32, #ttnn_layout90>) -> () loc(#loc146)
        %149 = "ttnn.typecast"(%148) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x72xf32, #ttnn_layout49>) -> tensor<1x72xui32, #ttnn_layout50> loc(#loc147)
        "ttnn.deallocate"(%148) <{force = false}> : (tensor<1x72xf32, #ttnn_layout49>) -> () loc(#loc147)
        %150 = "ttnn.to_layout"(%149) <{layout = #ttnn.layout<row_major>}> : (tensor<1x72xui32, #ttnn_layout50>) -> tensor<1x72xui32, #ttnn_layout43> loc(#loc147)
        "ttnn.deallocate"(%149) <{force = false}> : (tensor<1x72xui32, #ttnn_layout50>) -> () loc(#loc147)
        %151 = "ttnn.typecast"(%136) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<5469696x1xf32, #ttnn_layout89>) -> tensor<5469696x1xbf16, #ttnn_layout91> loc(#loc147)
        "ttnn.deallocate"(%136) <{force = false}> : (tensor<5469696x1xf32, #ttnn_layout89>) -> () loc(#loc147)
        %152 = "ttnn.to_layout"(%151) <{layout = #ttnn.layout<row_major>}> : (tensor<5469696x1xbf16, #ttnn_layout91>) -> tensor<5469696x1xbf16, #ttnn_layout92> loc(#loc147)
        "ttnn.deallocate"(%151) <{force = false}> : (tensor<5469696x1xbf16, #ttnn_layout91>) -> () loc(#loc147)
        %153 = "ttnn.embedding"(%150, %152) : (tensor<1x72xui32, #ttnn_layout43>, tensor<5469696x1xbf16, #ttnn_layout92>) -> tensor<1x72x1xbf16, #ttnn_layout78> loc(#loc1)
        "ttnn.deallocate"(%152) <{force = false}> : (tensor<5469696x1xbf16, #ttnn_layout92>) -> () loc(#loc1)
        "ttnn.deallocate"(%150) <{force = false}> : (tensor<1x72xui32, #ttnn_layout43>) -> () loc(#loc1)
        %154 = "ttnn.typecast"(%153) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x72x1xbf16, #ttnn_layout78>) -> tensor<1x72x1xf32, #ttnn_layout93> loc(#loc147)
        "ttnn.deallocate"(%153) <{force = false}> : (tensor<1x72x1xbf16, #ttnn_layout78>) -> () loc(#loc147)
        %155 = "ttnn.reshape"(%154) <{shape = [1 : i32, 1 : i32, 72 : i32, 1 : i32]}> : (tensor<1x72x1xf32, #ttnn_layout93>) -> tensor<1x1x72x1xf32, #ttnn_layout94> loc(#loc162)
        "ttnn.deallocate"(%154) <{force = false}> : (tensor<1x72x1xf32, #ttnn_layout93>) -> () loc(#loc162)
        %156 = "ttnn.reduce_scatter"(%155) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 2 : si32}> : (tensor<1x1x72x1xf32, #ttnn_layout94>) -> tensor<1x1x36x1xf32, #ttnn_layout95> loc(#loc163)
        "ttnn.deallocate"(%155) <{force = false}> : (tensor<1x1x72x1xf32, #ttnn_layout94>) -> () loc(#loc163)
        %157 = "ttnn.all_gather"(%156) <{all_gather_dim = 2 : si32, cluster_axis = 1 : ui32}> : (tensor<1x1x36x1xf32, #ttnn_layout95>) -> tensor<1x1x72x1xf32, #ttnn_layout94> loc(#loc149)
        "ttnn.deallocate"(%156) <{force = false}> : (tensor<1x1x36x1xf32, #ttnn_layout95>) -> () loc(#loc149)
        %158 = "ttnn.reshape"(%157) <{shape = [72 : i32, 1 : i32]}> : (tensor<1x1x72x1xf32, #ttnn_layout94>) -> tensor<72x1xf32, #ttnn_layout88> loc(#loc1)
        "ttnn.deallocate"(%157) <{force = false}> : (tensor<1x1x72x1xf32, #ttnn_layout94>) -> () loc(#loc1)
        %159 = "ttnn.neg"(%158) : (tensor<72x1xf32, #ttnn_layout88>) -> tensor<72x1xf32, #ttnn_layout88> loc(#loc113)
        "ttnn.deallocate"(%158) <{force = false}> : (tensor<72x1xf32, #ttnn_layout88>) -> () loc(#loc113)
        %160 = "ttnn.reshape"(%159) <{shape = [72 : i32]}> : (tensor<72x1xf32, #ttnn_layout88>) -> tensor<72xf32, #ttnn_layout39> loc(#loc113)
        "ttnn.deallocate"(%159) <{force = false}> : (tensor<72x1xf32, #ttnn_layout88>) -> () loc(#loc113)
        %161 = "ttnn.typecast"(%49) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<72xbf16, #ttnn_layout69>) -> tensor<72xf32, #ttnn_layout39> loc(#loc150)
        %162 = "ttnn.where"(%161, %160, %11#2) : (tensor<72xf32, #ttnn_layout39>, tensor<72xf32, #ttnn_layout39>, tensor<72xf32, #ttnn_layout39>) -> tensor<72xf32, #ttnn_layout39> loc(#loc13)
        "ttnn.deallocate"(%161) <{force = false}> : (tensor<72xf32, #ttnn_layout39>) -> () loc(#loc13)
        "ttnn.deallocate"(%160) <{force = false}> : (tensor<72xf32, #ttnn_layout39>) -> () loc(#loc13)
        "ttnn.deallocate"(%11#2) <{force = false}> : (tensor<72xf32, #ttnn_layout39>) -> () loc(#loc13)
        %163 = "ttnn.typecast"(%49) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<72xbf16, #ttnn_layout69>) -> tensor<72xf32, #ttnn_layout39> loc(#loc114)
        "ttnn.deallocate"(%49) <{force = false}> : (tensor<72xbf16, #ttnn_layout69>) -> () loc(#loc114)
        %164 = "ttnn.divide"(%162, %163) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<72xf32, #ttnn_layout39>, tensor<72xf32, #ttnn_layout39>) -> tensor<72xf32, #ttnn_layout39> loc(#loc115)
        "ttnn.deallocate"(%163) <{force = false}> : (tensor<72xf32, #ttnn_layout39>) -> () loc(#loc115)
        "ttnn.deallocate"(%162) <{force = false}> : (tensor<72xf32, #ttnn_layout39>) -> () loc(#loc115)
        %165 = "ttnn.mesh_shard"(%31, %19) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<4x4x18x128xf32, #ttnn_layout67>, !ttnn.device) -> tensor<4x8x18x128xf32, #ttnn_layout59> loc(#loc)
        "ttnn.deallocate"(%31) <{force = false}> : (tensor<4x4x18x128xf32, #ttnn_layout67>) -> () loc(#loc)
        %166 = "ttnn.mesh_shard"(%42, %19) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<4x4x18x128xf32, #ttnn_layout67>, !ttnn.device) -> tensor<4x8x18x128xf32, #ttnn_layout59> loc(#loc)
        "ttnn.deallocate"(%42) <{force = false}> : (tensor<4x4x18x128xf32, #ttnn_layout67>) -> () loc(#loc)
        %167 = "ttnn.mesh_shard"(%118, %19) <{shard_dims = array<i64: -1, 2>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<4x18x75968xf32, #ttnn_layout86>, !ttnn.device) -> tensor<4x18x151936xf32, #ttnn_layout60> loc(#loc)
        "ttnn.deallocate"(%118) <{force = false}> : (tensor<4x18x75968xf32, #ttnn_layout86>) -> () loc(#loc)
        return %165, %166, %164, %167 : tensor<4x8x18x128xf32, #ttnn_layout59>, tensor<4x8x18x128xf32, #ttnn_layout59>, tensor<72xf32, #ttnn_layout39>, tensor<4x18x151936xf32, #ttnn_layout60> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("gather.579")
#loc2 = loc("select.316")
#loc3 = loc("gather.24")
#loc4 = loc("iota.576")
#loc5 = loc("concatenate.578")
#loc6 = loc("reshape.75")
#loc7 = loc("dot.78")
#loc8 = loc("transpose.79")
#loc9 = loc("concatenate.80")
#loc10 = loc("cosine.142")
#loc11 = loc("sine.81")
#loc12 = loc("select.450")
#loc13 = loc("select.587")
#loc14 = loc("gather.289")
#loc15 = loc("broadcast.292")
#loc16 = loc("reshape.313")
#loc17 = loc("compare.295")
#loc18 = loc("broadcast.270")
#loc19 = loc("compare.279")
#loc20 = loc("add.276")
#loc21 = loc("select.280")
#loc22 = loc("reshape.281")
#loc23 = loc("compare.264")
#loc24 = loc("add.261")
#loc25 = loc("select.265")
#loc26 = loc("reshape.282")
#loc27 = loc("concatenate.283")
#loc28 = loc("select.186")
#loc29 = loc("reduce.440")
#loc48 = loc("convert.23_in_0_layout")
#loc49 = loc("convert.23")
#loc50 = loc("dot.58")
#loc51 = loc("reshape.60")
#loc52 = loc("transpose.61")
#loc53 = loc("dot.99")
#loc54 = loc("reshape.101")
#loc55 = loc("transpose.133")
#loc56 = loc("multiply.148")
#loc57 = loc("slice.135")
#loc58 = loc("negate.136")
#loc59 = loc("slice.134")
#loc60 = loc("concatenate.137")
#loc61 = loc("multiply.140")
#loc62 = loc("add.151")
#loc63 = loc("pad.155")
#loc64 = loc("slice.156")
#loc65 = loc("reshape.157")
#loc66 = loc("compare.585")
#loc67 = loc("dot.342")
#loc68 = loc("reshape.344")
#loc69 = loc("transpose.376")
#loc70 = loc("multiply.386")
#loc71 = loc("slice.378")
#loc72 = loc("negate.379")
#loc73 = loc("slice.377")
#loc74 = loc("concatenate.380")
#loc75 = loc("multiply.383")
#loc76 = loc("add.389")
#loc77 = loc("multiply.391")
#loc78 = loc("broadcast.321")
#loc79 = loc("reshape.322")
#loc80 = loc("transpose.323")
#loc81 = loc("multiply.325")
#loc82 = loc("and.306")
#loc83 = loc("convert.288_in_0_layout")
#loc84 = loc("convert.288")
#loc85 = loc("and.312")
#loc86 = loc("broadcast.397")
#loc87 = loc("add.398")
#loc88 = loc("compare.426")
#loc89 = loc("not.428")
#loc90 = loc("not.446")
#loc91 = loc("divide.415")
#loc92 = loc("broadcast.231")
#loc93 = loc("reshape.232")
#loc94 = loc("dot.451")
#loc95 = loc("reshape.455")
#loc96 = loc("dot.456")
#loc97 = loc("add.460")
#loc98 = loc("dot.501")
#loc99 = loc("dot.493")
#loc100 = loc("multiply.505")
#loc101 = loc("dot.507")
#loc102 = loc("add.511")
#loc103 = loc("dot.544")
#loc104 = loc("reshape.545")
#loc105 = loc("reduce.553")
#loc106 = loc("broadcast.558")
#loc107 = loc("subtract.559")
#loc108 = loc("exponential.560")
#loc109 = loc("reduce.567")
#loc110 = loc("log.569")
#loc111 = loc("subtract.574")
#loc112 = loc("convert.575")
#loc113 = loc("negate.581")
#loc114 = loc("convert.168")
#loc115 = loc("divide.595")
#loc116 = loc("gather.579_constant"(#loc1))
#loc117 = loc("gather.24_workaround"(#loc3))
#loc118 = loc("concatenate.578_workaround"(#loc5))
#loc119 = loc("gather.289_constant"(#loc14))
#loc120 = loc("reshape.313_tm0"(#loc16))
#loc121 = loc("select.280_workaround"(#loc21))
#loc122 = loc("select.265_workaround"(#loc25))
#loc123 = loc("concatenate.283_workaround"(#loc27))
#loc124 = loc("gather.289_typecast"(#loc14))
#loc125 = loc("gather.289_reshapeStartIndices"(#loc14))
#loc126 = loc("gather.289_workaround"(#loc14))
#loc127 = loc("select.186_workaround"(#loc28))
#loc128 = loc("reduce.440_zeroConstant"(#loc29))
#loc129 = loc("pad.155_workaround"(#loc63))
#loc130 = loc("reshape.313_tm1"(#loc16))
#loc131 = loc("select.316_workaround"(#loc2))
#loc132 = loc("add.398_decomp_matmul"(#loc87))
#loc133 = loc("add.398_decomp_add"(#loc87))
#loc134 = loc("select.450_workaround"(#loc12))
#loc135 = loc("dot.456_reduceScatter"(#loc96))
#loc136 = loc("dot.456_all_gather_4d"(#loc96))
#loc137 = loc("dot.507_reduceScatter"(#loc101))
#loc138 = loc("dot.507_all_gather_4d"(#loc101))
#loc139 = loc("reduce.553_reduceScatter"(#loc105))
#loc140 = loc("reduce.553_all_gather_4d"(#loc105))
#loc141 = loc("subtract.559_neg"(#loc107))
#loc142 = loc("reduce.567_reduceScatter"(#loc109))
#loc143 = loc("reduce.567_all_gather_4d"(#loc109))
#loc144 = loc("subtract.574_neg"(#loc111))
#loc145 = loc("gather.579_typecast"(#loc1))
#loc146 = loc("gather.579_reshapeStartIndices"(#loc1))
#loc147 = loc("gather.579_workaround"(#loc1))
#loc148 = loc("gather.579_reduceScatter"(#loc1))
#loc149 = loc("gather.579_all_gather_4d"(#loc1))
#loc150 = loc("select.587_workaround"(#loc13))
#loc151 = loc("reshape.313_tm0_tm1"(#loc120))
#loc152 = loc("reshape.313_tm0_tm0_in_0_layout"(#loc120))
#loc153 = loc("reshape.313_tm0_tm0"(#loc120))
#loc154 = loc("dot.456_reduceScatter_reshape_to_4d"(#loc135))
#loc155 = loc("dot.456_reduceScatter_reduce_scatter_4d"(#loc135))
#loc156 = loc("dot.507_reduceScatter_reshape_to_4d"(#loc137))
#loc157 = loc("dot.507_reduceScatter_reduce_scatter_4d"(#loc137))
#loc158 = loc("reduce.553_reduceScatter_reshape_to_4d"(#loc139))
#loc159 = loc("reduce.553_reduceScatter_reduce_scatter_4d"(#loc139))
#loc160 = loc("reduce.567_reduceScatter_reshape_to_4d"(#loc142))
#loc161 = loc("reduce.567_reduceScatter_reduce_scatter_4d"(#loc142))
#loc162 = loc("gather.579_reduceScatter_reshape_to_4d"(#loc148))
#loc163 = loc("gather.579_reduceScatter_reduce_scatter_4d"(#loc148))
#loc164 = loc("reshape.313_tm0_tm1_tm0"(#loc151))
#loc165 = loc("reshape.313_tm0_tm1_tm1"(#loc151))
------------------ END OF MLIR MODULE ------------------
2026-01-28 22:12:59.088 (   6.255s) [        66B35000]loaded_executable_insta:290      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2026-01-28 22:12:59.088 (   6.255s) [        66B35000]loaded_executable_insta:309      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2026-01-28 22:12:59.090 (   6.256s) [        66B35000]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2026-01-28 22:12:59.090 (   6.256s) [        66B35000]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-01-28 22:12:59.090 (   6.256s) [        66B35000]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-01-28 22:12:59.090 (   6.256s) [        66B35000]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-01-28 22:12:59.090 (   6.256s) [        66B35000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-28 22:12:59.090 (   6.257s) [        66B35000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-28 22:12:59.099 (   6.265s) [        66B35000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-28 22:12:59.099 (   6.265s) [        66B35000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-28 22:12:59.106 (   6.272s) [        66B35000] executable_instance.cc:239      1| ExecutableInstance::PJRT_Executable_Serialize
2026-01-28 22:12:59.111 (   6.277s) [        DEFFD640]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:59.111 (   6.277s) [        DEFFD640]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-28 22:12:59.111 (   6.277s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     buffer_instance.cc:689      1| BufferInstance::PJRT_Buffer_Device
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640] executable_instance.cc:145      1| ExecutableInstance::PJRT_Executable_NumOutputs
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]loaded_executable_insta:345      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]flatbuffer_loaded_execu:260      1| FlatbufferLoadedExecutableInstance::Execute
2026-01-28 22:12:59.111 (   6.278s) [        DEFFD640]     client_instance.cc:416      1| ClientInstance::getOrCreateMeshDevice - reusing already opened mesh device [1, 2]
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<2x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_0 with hash: b9d7d88889b029590ff493d0aaace0651a0dda667bdbf95c2ee88c1bf0a1e266
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_0
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_0
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<<dram>, <interleaved>>, value = dense<[[7.596800e+04], [1.000000e+00]]> : tensor<2x1xf32>}> : (!ttnn.device) -> tensor<2x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.579_constant"("gather.579"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_0
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_0
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<4x1x18x18xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<4x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_1 with hash: 7dc3334a740f09a01975bf9e65677656c0d6832b60ff56aeca14484b6e91e1c4
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_1
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_1
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 0xFF800000 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<4x1x18x18>}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x1x18x18xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<4x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.316")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.316")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_1
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_1
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = ttcore.load_cached(@main_const_eval_2, []) : () -> tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_2 with hash: 97bbc7a4c5a4f278b590215609efab8232076172d9589ff7c2181730b51ef561
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_2
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_2
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = -100 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.reshape"(%1) <{shape = [1 : i32]}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_2
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_2
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = ttcore.load_cached(@main_const_eval_3, [%arg7]) : (tensor<151936x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> tensor<75968x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2374x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_3 with hash: ba648537f0464ee84834b98bb742b7280932a4b41ad8027d3a07fbabc88c383c
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_3
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_3
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<151936x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xf32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<151936x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<151936x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<151936x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4748x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<151936x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<151936x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4748x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<75968x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2374x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<151936x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4748x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_3
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_3
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<151936x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %4 = ttcore.load_cached(@main_const_eval_4, [%arg0]) : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> tensor<512x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_4 with hash: 4740a9824337f67dff8d0d9211ec45fc61d6a66e308b958b6d207dab01e7e9cd
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_4
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_4
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_4
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_4
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %5 = ttcore.load_cached(@main_const_eval_5, [%arg10]) : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> tensor<1536x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_5 with hash: 3f6a54dc427fe71d56d6a0b55d9a05f3d6a9ecac003844873cfb2176235426e0
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_5
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_5
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_5
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_5
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %6 = ttcore.load_cached(@main_const_eval_6, [%arg16]) : (tensor<2048x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2048x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_6 with hash: fce8ebc2cb7f2461091d7f1eeb7706001ca31c063b892f0181be6dbf2360084d
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_6
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_6
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<2048x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2048x1024xf32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<2048x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2048x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<2048x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2048x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<2048x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<64x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<2048x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2048x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2048x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<64x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<2048x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<64x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_6
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_6
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg16) <{force = false}> : (tensor<2048x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2048x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %7 = ttcore.load_cached(@main_const_eval_7, [%arg3]) : (tensor<151936x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> tensor<151936x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xbf16, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_7 with hash: 1e3ec92499ec32fb271dbc563f497b7f11bcd8c3b8d261ad2d7b7bdb095e8d95
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_7
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_7
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc("gather.24_workaround"("gather.24"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.to_dtype"(%arg0) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<151936x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> tensor<151936x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xbf16, #ttnn.buffer_type<system_memory>>>> loc("gather.24_workaround"("gather.24"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.to_device"(%1, %0) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<151936x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<151936x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xbf16, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.24_workaround"("gather.24"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<151936x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xbf16, #ttnn.buffer_type<system_memory>>>>) -> () loc("gather.24_workaround"("gather.24"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_7
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_7
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<151936x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<151936x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %8 = ttcore.load_cached(@main_const_eval_8, [%arg9]) : (tensor<1024x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x3072xf32, #ttnn.buffer_type<system_memory>>>>) -> tensor<1024x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_8 with hash: 9915905f103c39a5cb940be3378c72a79e876f0dfb7714fa2a92ab1b648be6cf
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_8
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_8
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<1024x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x3072xf32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1024x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x3072xf32, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1024x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x3072xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1024x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<1024x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x3072xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1024x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<1024x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_8
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_8
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<1024x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x3072xf32, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %9 = ttcore.load_cached(@main_const_eval_9, []) : () -> tensor<72x1x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<72x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_9 with hash: 1129cedb4e6be0ee61b00dcbeb83f74ead6d2bd3be0888e80c0f000013f60294
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_9
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_9
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.arange"(%0) <{dtype = #ttcore.supportedDataTypes<u32>, end = 72 : i64, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<<dram>, <interleaved>>, start = 0 : i64, step = 1 : i64}> : (!ttnn.device) -> tensor<72xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("iota.576")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.reshape"(%1) <{shape = [72 : i32, 1 : i32, 1 : i32]}> : (tensor<72xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<72x1x1xui32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<72x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("iota.576")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<72xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("iota.576")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<72x1x1xui32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<72x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<72x1x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<72x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("concatenate.578_workaround"("concatenate.578"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<72x1x1xui32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<72x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.578_workaround"("concatenate.578"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_9
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_9
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %10:2 = ttcore.load_cached(@main_const_eval_10, [%arg4]) : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x64xf32, #ttnn.buffer_type<system_memory>>>>) -> (tensor<1x1x18x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x18x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_10 with hash: ce2d498dcbded7d0666c154c4bb07f876d1e1e1d30de97dbdd4b2fd5f55b3378
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_10
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_10
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x64xf32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x64xf32, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x64xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x64xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<<dram>, <interleaved>>, value = dense_resource<__elided__> : tensor<1x1x18xf32>}> : (!ttnn.device) -> tensor<1x1x18xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %4 = "ttnn.reshape"(%2) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.75")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.75")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %5 = "ttnn.matmul"(%4, %3) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x18xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x18xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.78")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%4) <{force = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.78")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x18xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.78")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %6 = "ttnn.permute"(%5) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x18xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x18x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("transpose.79")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%5) <{force = false}> : (tensor<1x64x18xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("transpose.79")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %7 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 18 : i32, 64 : i32]}> : (tensor<1x18x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x18x64xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("concatenate.80")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %8 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32, 18 : i32, 64 : i32]}> : (tensor<1x18x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x18x64xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("concatenate.80")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%6) <{force = false}> : (tensor<1x18x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.80")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %9 = "ttnn.concat"(%7, %8) <{dim = 3 : si32}> : (tensor<1x1x18x64xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x18x64xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x18x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("concatenate.80")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x1x18x64xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.80")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x18x64xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.80")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %10 = "ttnn.cos"(%9) : (tensor<1x1x18x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x18x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("cosine.142")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %11 = "ttnn.sin"(%9) : (tensor<1x1x18x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x18x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("sine.81")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1x18x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("sine.81")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_10
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_10
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x64xf32, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %11:3 = ttcore.load_cached(@main_const_eval_11, []) : () -> (tensor<4x1x18x18xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<4x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4x8x18x18xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<32x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<72xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_11 with hash: fd7232fe47f9905b8b0dabafa2f2cc4f073c301bf8b63be02999a322922886e8
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_11
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_11
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.reshape"(%1) <{shape = [1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %4 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<4x1x18x18>}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x1x18x18xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<4x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.316")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %5 = "ttnn.repeat"(%3) <{repeat_dims = #ttnn.shape<4x8x18x18>}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x8x18x18xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<32x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.450")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.450")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %6 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<72>}> : (tensor<1xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<72xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.587")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<1xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.587")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_11
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_11
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %12:4 = ttcore.load_cached(@main_const_eval_12, []) : () -> (tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x18x18xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x72xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x72xui32, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<72xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_12 with hash: ac10f1a55689844d5da038cf57af71a0a603c12bec6e29c956cda4022c8739d7
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_12
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_12
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<<dram>, <interleaved>>, value = dense<[[1.800000e+01], [1.000000e+00]]> : tensor<2x1xf32>}> : (!ttnn.device) -> tensor<2x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.289_constant"("gather.289"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<<dram>, <interleaved>>, value = dense<[0, 1, 2, 3]> : tensor<4xsi32>}> : (!ttnn.device) -> tensor<4xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<<dram>, <interleaved>>, value = dense_resource<__elided__> : tensor<18xsi32>}> : (!ttnn.device) -> tensor<18xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %4 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = 0 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %5 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = 18 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %6 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = 4 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %7 = "ttnn.reshape"(%4) <{shape = [1 : i32]}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %8 = "ttnn.reshape"(%5) <{shape = [1 : i32, 1 : i32]}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%5) <{force = false}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %9 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%6) <{force = false}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %10 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32]}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%4) <{force = false}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %11 = "ttnn.reshape"(%3) <{shape = [1 : i32, 18 : i32]}> : (tensor<18xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("broadcast.292")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %12 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32, 1 : i32, 18 : i32]}> : (tensor<18xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x18xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.313_tm0_tm1_tm0"("reshape.313_tm0_tm1"("reshape.313_tm0"("reshape.313"))))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %13 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32, 18 : i32, 1 : i32]}> : (tensor<18xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x18x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.313_tm0_tm1_tm1"("reshape.313_tm0_tm1"("reshape.313_tm0"("reshape.313"))))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%3) <{force = false}> : (tensor<18xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.313_tm0_tm1_tm1"("reshape.313_tm0_tm1"("reshape.313_tm0"("reshape.313"))))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %14 = "ttnn.le"(%12, %13) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x18xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x18x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x18x18xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("compare.295")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%13) <{force = false}> : (tensor<1x1x18x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("compare.295")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x1x1x18xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("compare.295")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %15 = "ttnn.reshape"(%2) <{shape = [4 : i32, 1 : i32]}> : (tensor<4xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("broadcast.270")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<4xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("broadcast.270")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %16 = "ttnn.lt"(%15, %10) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<4x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x1xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("compare.279")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %17 = "ttnn.add"(%15, %9) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<4x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("add.276")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.276")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %18 = "ttnn.typecast"(%16) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x1xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.280_workaround"("select.280"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%16) <{force = false}> : (tensor<4x1xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.280_workaround"("select.280"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %19 = "ttnn.typecast"(%17) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.280_workaround"("select.280"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%17) <{force = false}> : (tensor<4x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.280_workaround"("select.280"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %20 = "ttnn.typecast"(%15) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.280_workaround"("select.280"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%15) <{force = false}> : (tensor<4x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.280_workaround"("select.280"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %21 = "ttnn.where"(%18, %19, %20) : (tensor<4x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.280")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%20) <{force = false}> : (tensor<4x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.280")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%19) <{force = false}> : (tensor<4x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.280")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%18) <{force = false}> : (tensor<4x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.280")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %22 = "ttnn.typecast"(%21) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<4x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.280_workaround"("select.280"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%21) <{force = false}> : (tensor<4x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.280_workaround"("select.280"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %23 = "ttnn.repeat"(%22) <{repeat_dims = #ttnn.shape<1x18>}> : (tensor<4x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.280")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%22) <{force = false}> : (tensor<4x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.280")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %24 = "ttnn.reshape"(%23) <{shape = [4 : i32, 18 : i32, 1 : i32]}> : (tensor<4x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x18x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.281")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%23) <{force = false}> : (tensor<4x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.281")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %25 = "ttnn.lt"(%11, %10) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x18xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("compare.264")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %26 = "ttnn.add"(%11, %8) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<1x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("add.261")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.261")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %27 = "ttnn.typecast"(%25) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x18xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x18xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.265_workaround"("select.265"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%25) <{force = false}> : (tensor<1x18xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.265_workaround"("select.265"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %28 = "ttnn.typecast"(%26) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x18xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.265_workaround"("select.265"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%26) <{force = false}> : (tensor<1x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.265_workaround"("select.265"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %29 = "ttnn.typecast"(%11) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x18xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.265_workaround"("select.265"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.265_workaround"("select.265"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %30 = "ttnn.where"(%27, %28, %29) : (tensor<1x18xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x18xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x18xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x18xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.265")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%29) <{force = false}> : (tensor<1x18xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.265")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%28) <{force = false}> : (tensor<1x18xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.265")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%27) <{force = false}> : (tensor<1x18xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.265")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %31 = "ttnn.typecast"(%30) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<1x18xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.265_workaround"("select.265"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%30) <{force = false}> : (tensor<1x18xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.265_workaround"("select.265"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %32 = "ttnn.repeat"(%31) <{repeat_dims = #ttnn.shape<4x1>}> : (tensor<1x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.265")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%31) <{force = false}> : (tensor<1x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.265")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %33 = "ttnn.reshape"(%32) <{shape = [4 : i32, 18 : i32, 1 : i32]}> : (tensor<4x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x18x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.282")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%32) <{force = false}> : (tensor<4x18xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.282")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %34 = "ttnn.typecast"(%24) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<4x18x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x18x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("concatenate.283_workaround"("concatenate.283"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%24) <{force = false}> : (tensor<4x18x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.283_workaround"("concatenate.283"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %35 = "ttnn.typecast"(%33) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<4x18x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x18x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("concatenate.283_workaround"("concatenate.283"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%33) <{force = false}> : (tensor<4x18x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.283_workaround"("concatenate.283"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %36 = "ttnn.concat"(%34, %35) <{dim = 2 : si32}> : (tensor<4x18x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4x18x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x18x2xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("concatenate.283")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%35) <{force = false}> : (tensor<4x18x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.283")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%34) <{force = false}> : (tensor<4x18x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.283")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %37 = "ttnn.typecast"(%36) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<4x18x2xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x18x2xsi32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("concatenate.283_workaround"("concatenate.283"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%36) <{force = false}> : (tensor<4x18x2xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.283_workaround"("concatenate.283"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %38 = "ttnn.typecast"(%37) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<4x18x2xsi32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x18x2xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.289_typecast"("gather.289"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%37) <{force = false}> : (tensor<4x18x2xsi32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("gather.289_typecast"("gather.289"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %39 = "ttnn.matmul"(%38, %1) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, transpose_a = false, transpose_b = false}> : (tensor<4x18x2xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<2x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<4x18x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.289")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%38) <{force = false}> : (tensor<4x18x2xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("gather.289")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<2x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("gather.289")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %40 = "ttnn.reshape"(%39) <{shape = [1 : i32, 72 : i32]}> : (tensor<4x18x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x72xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x3x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.289_reshapeStartIndices"("gather.289"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%39) <{force = false}> : (tensor<4x18x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("gather.289_reshapeStartIndices"("gather.289"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %41 = "ttnn.typecast"(%40) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x72xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x3x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x72xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x3x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.289_workaround"("gather.289"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%40) <{force = false}> : (tensor<1x72xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x3x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("gather.289_workaround"("gather.289"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %42 = "ttnn.to_layout"(%41) <{layout = #ttnn.layout<row_major>}> : (tensor<1x72xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x3x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x72xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x72xui32, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.289_workaround"("gather.289"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%41) <{force = false}> : (tensor<1x72xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x3x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("gather.289_workaround"("gather.289"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %43 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<72>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<72xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.186")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%7) <{force = false}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.186")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %44 = "ttnn.typecast"(%43) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<72xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<72xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("select.186_workaround"("select.186"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%43) <{force = false}> : (tensor<72xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("select.186_workaround"("select.186"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_12
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_12
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %13 = ttcore.load_cached(@main_const_eval_13, [%arg12]) : (tensor<1024x2048xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x2048xf32, #ttnn.buffer_type<system_memory>>>>) -> tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_13 with hash: f3db4c2aca05a772b251678852abfb5d22942bc64c1cef7dc25ae5c6ce8d3330
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_13
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_13
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<1024x2048xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x2048xf32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1024x2048xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x2048xf32, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1024x2048xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x2048xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1024x2048xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x64x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<1024x2048xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x2048xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x2048xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x64x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<1024x2048xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x64x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_13
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_13
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg12) <{force = false}> : (tensor<1024x2048xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x2048xf32, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %14 = ttcore.load_cached(@main_const_eval_14, [%arg17]) : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> tensor<1536x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_14 with hash: 3f6a54dc427fe71d56d6a0b55d9a05f3d6a9ecac003844873cfb2176235426e0
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_14
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_14
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_14
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_14
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg17) <{force = false}> : (tensor<3072x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<3072x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %15 = ttcore.load_cached(@main_const_eval_15, []) : () -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_15 with hash: 45c6c505c7a5bf6fc2dee232b291e5738568124a523194a9b1c5327d227d3bfc
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_15
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_15
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 0.297301769 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_15
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_15
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %16 = ttcore.load_cached(@main_const_eval_16, [%arg6]) : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> tensor<512x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_16 with hash: 4740a9824337f67dff8d0d9211ec45fc61d6a66e308b958b6d207dab01e7e9cd
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_16
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_16
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.mesh_shard"(%2, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x32x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_16
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_16
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<1024x1024xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1024x1024xf32, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %17 = ttcore.load_cached(@main_const_eval_17, []) : () -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_17 with hash: b2d76728f0d937409fc05a80b1f50885f30e09e737b8f0f9be1d768f6f4b242d
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_17
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_17
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 0xFF800000 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_17
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_17
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %18 = ttcore.load_cached(@main_const_eval_18, []) : () -> tensor<4x8x18xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Running LoadCachedOp for function main_const_eval_18 with hash: a0f45a862bdbcd2d18cf44b29b7a4a3ce3aeef69a4281b8ea1fd31c33fc9ec7f
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_18
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_18
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<4x8x18>}> : (!ttnn.device) -> tensor<4x8x18xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<4x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reduce.440_zeroConstant"("reduce.440"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_18
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_18
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %19 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %20 = "ttnn.distribute_tensor"(%arg14, %19) <{mapper_config = #ttnn.mesh_mapper_config<placements = [<replicate, -1 : i32>, <replicate, -1 : i32>], mesh_shape_override = [1 : ui32, 2 : ui32]>}> : (tensor<bf16, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<bf16, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1xbf16, #ttnn.buffer_type<system_memory>>>> loc(unknown)
2026-01-28 22:13:08.326 | critical |          Always | TT_FATAL: Can't get a single buffer from host storage distributed over mesh shape MeshShape([1, 2]) (assert.hpp:104)
2026-01-28 22:13:08.363 (  15.529s) [        DEFFD640]                utils.h:62     ERR| Exception:
{TT_FATAL @ /localdev/jameszianxu/tt-xla/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal/ttnn/core/tensor/host_buffer/functions.cpp:25: buffers.size() == 1
info:
Can't get a single buffer from host storage distributed over mesh shape MeshShape([1, 2])
backtrace:
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/libtt_metal.so(+0x13d723f) [0x7f72c364123f]
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/_ttnncpp.so(+0x20bf126) [0x7f72ba24e126]
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/_ttnncpp.so(+0x20bf008) [0x7f72ba24e008]
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/_ttnncpp.so(+0x20befa8) [0x7f72ba24dfa8]
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/_ttnncpp.so(+0x20bef20) [0x7f72ba24df20]
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/_ttnncpp.so(+0x20bee97) [0x7f72ba24de97]
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/_ttnncpp.so(+0x20b8eee) [0x7f72ba247eee]
 --- tt::tt_metal::host_buffer::get_host_buffer(tt::tt_metal::Tensor const&)
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/_ttnncpp.so(+0x288c915) [0x7f72baa1b915]
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/_ttnncpp.so(+0x28896a2) [0x7f72baa186a2]
 --- ttnn::distributed::TensorToMesh::operator()(tt::tt_metal::Tensor const&) const
 --- ttnn::distributed::distribute_tensor(tt::tt_metal::Tensor const&, ttnn::distributed::TensorToMesh const&, std::optional<std::reference_wrapper<tt::tt_metal::distributed::MeshDevice> >, std::optional<ttsl::StrongType<unsigned char, tt::tt_metal::QueueIdTag> >)
 --- tt::runtime::ttnn::operations::ccl::run(tt::target::ttnn::DistributeTensorOp const*, tt::runtime::ttnn::ProgramContext&)
 --- tt::runtime::ttnn::ProgramExecutor::runOperation(tt::target::ttnn::Operation const*)
 --- tt::runtime::ttnn::ProgramExecutor::execute()
 --- tt::runtime::ttnn::submit(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&)
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/libTTMLIRRuntime.so(+0x30159c) [0x7f7399cdc59c]
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/libTTMLIRRuntime.so(+0x2fb634) [0x7f7399cd6634]
 --- tt::runtime::submit(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&)
 --- std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > std::__invoke_impl<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&>(std::__invoke_other, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&)
 --- std::__invoke_result<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&>::type std::__invoke<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&>(std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&)
 --- std::invoke_result<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&>::type std::invoke<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&>(std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&)
 --- std::optional<std::conditional<std::is_same_v<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >, void>, std::monostate, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > >::type> tt::pjrt::utils::invoke_noexcept<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > >(std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&)
 --- tt::pjrt::FlatbufferLoadedExecutableInstance::execute(PJRT_LoadedExecutable_Execute_Args*)
 --- tt::pjrt::internal::onLoadedExecutableExecute(PJRT_LoadedExecutable_Execute_Args*)
 --- xla::PjRtCApiLoadedExecutable::Execute(absl::lts_20230802::Span<std::vector<xla::PjRtBuffer*, std::allocator<xla::PjRtBuffer*> > const>, xla::ExecuteOptions const&, std::optional<std::vector<xla::PjRtFuture<void>, std::allocator<xla::PjRtFuture<void> > > >&)
 --- torch_xla::runtime::PjRtComputationClient::ExecuteReplicated(torch_xla::runtime::ComputationClient::Computation const&, absl::lts_20230802::Span<std::shared_ptr<torch_xla::runtime::ComputationClient::Data> const>, absl::lts_20230802::Span<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, torch_xla::runtime::ComputationClient::ExecuteReplicatedOptions const&)
 --- /usr/local/lib/python3.11/dist-packages/_XLAC.cpython-311-x86_64-linux-gnu.so(+0x6ded712) [0x7f749a17f712]
 --- torch::lazy::MultiWait::Complete(std::function<void ()> const&)
 --- Eigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)
 --- void absl::lts_20230802::internal_any_invocable::RemoteInvoker<false, void, tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}&>(absl::lts_20230802::internal_any_invocable::TypeErasedState*)
 --- /usr/local/lib/python3.11/dist-packages/_XLAC.cpython-311-x86_64-linux-gnu.so(+0x1168a1c2) [0x7f74a4a1c1c2]
 --- /lib/x86_64-linux-gnu/libc.so.6(+0x94ac3) [0x7f7566bcaac3]
 --- /lib/x86_64-linux-gnu/libc.so.6(+0x1268c0) [0x7f7566c5c8c0]
}

2026-01-28 22:13:08.363 (  15.529s) [        DEFFD640]     client_instance.cc:499      1| Closing parent mesh.
2026-01-28 22:13:08.450 (  15.616s) [        DEFFD640]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-01-28 22:13:08.450 (  15.616s) [        DEFFD640]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-01-28 22:13:08.450 (  15.616s) [        DEFFD640]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
Fatal Python error: Segmentation fault

Thread 0x00007f6cdd7fa640 (most recent call first):
  <no Python frame>

Thread 0x00007f6cddffb640 (most recent call first):
  <no Python frame>

Thread 0x00007f6f2ae7e640 (most recent call first):
  File "/usr/lib/python3.11/threading.py", line 331 in wait
  File "/usr/lib/python3.11/threading.py", line 629 in wait
  File "/usr/local/lib/python3.11/dist-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/lib/python3.11/threading.py", line 1002 in _bootstrap

Current thread 0x00007f7566b35000 (most recent call first):
  File "/usr/local/lib/python3.11/dist-packages/torch/_tensor_str.py", line 458 in _str_intern
  File "/usr/local/lib/python3.11/dist-packages/torch/_tensor_str.py", line 722 in _str
  File "/usr/local/lib/python3.11/dist-packages/torch/_tensor.py", line 568 in __repr__
  File "/localdev/jameszianxu/tt-xla/python_package/tt_torch/torch_overrides.py", line 22 in __torch_function__
  File "/usr/local/lib/python3.11/dist-packages/torch/overrides.py", line 1728 in handle_torch_function
  File "/usr/local/lib/python3.11/dist-packages/torch/_tensor.py", line 564 in __repr__
  File "/usr/local/lib/python3.11/dist-packages/_pytest/_io/saferepr.py", line 73 in repr_instance
  File "/usr/lib/python3.11/reprlib.py", line 63 in repr1
  File "/usr/lib/python3.11/reprlib.py", line 72 in <listcomp>
  File "/usr/lib/python3.11/reprlib.py", line 72 in _repr_iterable
  File "/usr/lib/python3.11/reprlib.py", line 81 in repr_tuple
  File "/usr/lib/python3.11/reprlib.py", line 61 in repr1
  File "/usr/lib/python3.11/reprlib.py", line 53 in repr
  File "/usr/local/lib/python3.11/dist-packages/_pytest/_io/saferepr.py", line 62 in repr
  File "/usr/local/lib/python3.11/dist-packages/_pytest/_io/saferepr.py", line 111 in saferepr
  File "/usr/local/lib/python3.11/dist-packages/_pytest/_code/code.py", line 913 in repr_args
  File "/usr/local/lib/python3.11/dist-packages/_pytest/_code/code.py", line 1076 in repr_traceback_entry
  File "/usr/local/lib/python3.11/dist-packages/_pytest/_code/code.py", line 1135 in <listcomp>
  File "/usr/local/lib/python3.11/dist-packages/_pytest/_code/code.py", line 1134 in repr_traceback
  File "/usr/local/lib/python3.11/dist-packages/_pytest/_code/code.py", line 1202 in repr_excinfo
  File "/usr/local/lib/python3.11/dist-packages/_pytest/_code/code.py", line 766 in getrepr
  File "/usr/local/lib/python3.11/dist-packages/_pytest/nodes.py", line 456 in _repr_failure_py
  File "/usr/local/lib/python3.11/dist-packages/_pytest/python.py", line 1713 in repr_failure
  File "/usr/local/lib/python3.11/dist-packages/_pytest/reports.py", line 377 in from_item_and_call
  File "/usr/local/lib/python3.11/dist-packages/_pytest/runner.py", line 368 in pytest_runtest_makereport
  File "/usr/local/lib/python3.11/dist-packages/pluggy/_callers.py", line 121 in _multicall
  File "/usr/local/lib/python3.11/dist-packages/pluggy/_manager.py", line 120 in _hookexec
  File "/usr/local/lib/python3.11/dist-packages/pluggy/_hooks.py", line 512 in __call__
  File "/usr/local/lib/python3.11/dist-packages/_pytest/runner.py", line 248 in call_and_report
  File "/usr/local/lib/python3.11/dist-packages/_pytest/runner.py", line 136 in runtestprotocol
  File "/usr/local/lib/python3.11/dist-packages/_pytest/runner.py", line 117 in pytest_runtest_protocol
  File "/usr/local/lib/python3.11/dist-packages/pluggy/_callers.py", line 121 in _multicall
  File "/usr/local/lib/python3.11/dist-packages/pluggy/_manager.py", line 120 in _hookexec
  File "/usr/local/lib/python3.11/dist-packages/pluggy/_hooks.py", line 512 in __call__
  File "/usr/local/lib/python3.11/dist-packages/_pytest/main.py", line 367 in pytest_runtestloop
  File "/usr/local/lib/python3.11/dist-packages/pluggy/_callers.py", line 121 in _multicall
  File "/usr/local/lib/python3.11/dist-packages/pluggy/_manager.py", line 120 in _hookexec
  File "/usr/local/lib/python3.11/dist-packages/pluggy/_hooks.py", line 512 in __call__
  File "/usr/local/lib/python3.11/dist-packages/_pytest/main.py", line 343 in _main
  File "/usr/local/lib/python3.11/dist-packages/_pytest/main.py", line 289 in wrap_session
  File "/usr/local/lib/python3.11/dist-packages/_pytest/main.py", line 336 in pytest_cmdline_main
  File "/usr/local/lib/python3.11/dist-packages/pluggy/_callers.py", line 121 in _multicall
  File "/usr/local/lib/python3.11/dist-packages/pluggy/_manager.py", line 120 in _hookexec
  File "/usr/local/lib/python3.11/dist-packages/pluggy/_hooks.py", line 512 in __call__
  File "/usr/local/lib/python3.11/dist-packages/_pytest/config/__init__.py", line 175 in main
  File "/usr/local/lib/python3.11/dist-packages/_pytest/config/__init__.py", line 201 in console_main
  File "/usr/local/lib/python3.11/dist-packages/pytest/__main__.py", line 9 in <module>
  File "<frozen runpy>", line 88 in _run_code
  File "<frozen runpy>", line 198 in _run_module_as_main

Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, psutil._psutil_linux, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, charset_normalizer.md, simplejson._speedups, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._pcg64, numpy.random._mt19937, numpy.random._generator, numpy.random._philox, numpy.random._sfc64, numpy.random.mtrand, markupsafe._speedups, jaxlib.cpu_feature_guard, msgpack._cmsgpack, regex._regex, PIL._imaging, sklearn.__check_build._check_build, _cyutility, scipy._cyutility, scipy._lib._ccallback_c, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, lz4._version, lz4.frame._frame, scipy.special._ufuncs_cxx, scipy.special._ellip_harm_2, scipy.special._special_ufuncs, scipy.special._gufuncs, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._batched_linalg, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_schur_sqrtm, scipy.linalg._matfuncs_expm, scipy.linalg._linalg_pythran, scipy.linalg.cython_blas, scipy.linalg._decomp_update, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpacklib, scipy.sparse.linalg._propack, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._hausdorff, scipy.spatial._distance_wrap, scipy.spatial.transform._rotation_cy, scipy.spatial.transform._rigid_transform_cy, scipy.optimize._group_columns, scipy.optimize._trlib._trlib, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._slsqplib, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy._lib._uarray._uarray, scipy.linalg._decomp_interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.optimize._direct, scipy.integrate._odepack, scipy.integrate._quadpack, scipy.integrate._vode, scipy.integrate._dop, scipy.interpolate._fitpack, scipy.interpolate._dfitpack, scipy.interpolate._dierckx, scipy.interpolate._ppoly, scipy.interpolate._interpnd, scipy.interpolate._rbfinterp_pythran, scipy.interpolate._rgi_cython, scipy.special.cython_special, scipy.stats._stats, scipy.stats._biasedurn, scipy.stats._stats_pythran, scipy.stats._levy_stable.levyst, scipy.stats._ansari_swilk_statistics, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.stats._sobol, scipy.stats._qmc_cy, scipy.stats._rcont.rcont, scipy.stats._qmvnt_cy, scipy.ndimage._nd_image, scipy.ndimage._rank_filter_1d, _ni_label, scipy.ndimage._ni_label, pyarrow.lib, pandas._libs._cyutility, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.properties, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, sklearn._cyutility, sklearn.utils._isfinite, sklearn.utils.sparsefuncs_fast, sklearn.utils.murmurhash, sklearn.utils._openmp_helpers, sklearn.metrics.cluster._expected_mutual_info_fast, sklearn.metrics._dist_metrics, sklearn.metrics._pairwise_distances_reduction._datasets_pair, sklearn.utils._cython_blas, sklearn.metrics._pairwise_distances_reduction._base, sklearn.metrics._pairwise_distances_reduction._middle_term_computer, sklearn.utils._heap, sklearn.utils._sorting, sklearn.metrics._pairwise_distances_reduction._argkmin, sklearn.metrics._pairwise_distances_reduction._argkmin_classmode, sklearn.utils._vector_sentinel, sklearn.metrics._pairwise_distances_reduction._radius_neighbors, sklearn.metrics._pairwise_distances_reduction._radius_neighbors_classmode, sklearn.metrics._pairwise_fast, sklearn.preprocessing._csr_polynomial_expansion, sklearn.preprocessing._target_encoder_fast, PIL._imagingft, av._core, av.logging, av.bytesource, av.buffer, av.audio.format, av.error, av.dictionary, av.container.pyio, av.option, av.descriptor, av.format, av.utils, av.stream, av.container.streams, av.sidedata.encparams, av.sidedata.motionvectors, av.sidedata.sidedata, av.opaque, av.packet, av.container.input, av.container.output, av.container.core, av.codec.context, av.video.format, av.video.reformatter, av.plane, av.video.plane, av.video.frame, av.video.stream, av.codec.hwaccel, av.codec.codec, av.frame, av.audio.layout, av.audio.plane, av.audio.frame, av.audio.stream, av.filter.link, av.filter.context, av.filter.graph, av.filter.filter, av.filter.loudnorm, av.audio.resampler, av.audio.codeccontext, av.audio.fifo, av.bitstream, av.video.codeccontext, _cffi_backend (total: 230)
