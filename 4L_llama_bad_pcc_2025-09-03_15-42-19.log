WARNING:root:Defaulting to PJRT_DEVICE=CPU
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.4.1, pluggy-1.6.0 -- /localdev/jameszianxu/test2/tt-torch/env/venv/bin/python3.10
cachedir: .pytest_cache
rootdir: /localdev/jameszianxu/test2/tt-torch
configfile: pytest.ini
plugins: cov-6.2.1, forked-1.6.0, xdist-3.8.0, split-0.10.0
collecting ... collected 1 item

tests/models/llama/test_llama3_generative.py::test_llama3_generate Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 47.86it/s]
2025-09-03 15:39:58.054254: W torch_xla/csrc/runtime/profiler.cpp:88] Profiler API not found for PJRT plugin
Initial prompt: '<|begin_of_text|>I like taking walks in the'
Setting up XLA environment...
XLA environment configured.
Created device mesh: (1, 2) with 2 devices
<|begin_of_text|>I like taking walks in theNote: Using experimental XLA backend.
[XLA Debug] Processing 51 input specs:
[XLA Debug] Input 0: kind=InputKind.PARAMETER, arg=TensorArgument(name='p__fx_const_folded_attrs_0'), target=_FX_CONST_FOLDED_ATTRS.0

[XLA Debug] Input 1: kind=InputKind.PARAMETER, arg=TensorArgument(name='p__fx_const_folded_attrs_1'), target=_FX_CONST_FOLDED_ATTRS.1

[XLA Debug] Input 2: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___key_cache_0'), target=kwargs____past_key_values___key_cache_0

[XLA Debug] Input 3: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___value_cache_0'), target=kwargs____past_key_values___value_cache_0

[XLA Debug] Input 4: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___key_cache_1'), target=kwargs____past_key_values___key_cache_1

[XLA Debug] Input 5: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___value_cache_1'), target=kwargs____past_key_values___value_cache_1

[XLA Debug] Input 6: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___key_cache_2'), target=kwargs____past_key_values___key_cache_2

[XLA Debug] Input 7: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___value_cache_2'), target=kwargs____past_key_values___value_cache_2

[XLA Debug] Input 8: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___key_cache_3'), target=kwargs____past_key_values___key_cache_3

[XLA Debug] Input 9: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___value_cache_3'), target=kwargs____past_key_values___value_cache_3

[XLA Debug] Input 10: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_0'), target=None
[XLA Debug] Input 11: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_1'), target=None
[XLA Debug] Input 12: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_2'), target=None
[XLA Debug] Input 13: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_3'), target=None
[XLA Debug] Input 14: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_4'), target=None
[XLA Debug] Input 15: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_5'), target=None
[XLA Debug] Input 16: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_6'), target=None
[XLA Debug] Input 17: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_7'), target=None
[XLA Debug] Input 18: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_8'), target=None
[XLA Debug] Input 19: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_9'), target=None
[XLA Debug] Input 20: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_10'), target=None
[XLA Debug] Input 21: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_11'), target=None
[XLA Debug] Input 22: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_12'), target=None
[XLA Debug] Input 23: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_13'), target=None
[XLA Debug] Input 24: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_14'), target=None
[XLA Debug] Input 25: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_15'), target=None
[XLA Debug] Input 26: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_16'), target=None
[XLA Debug] Input 27: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_17'), target=None
[XLA Debug] Input 28: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_18'), target=None
[XLA Debug] Input 29: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_19'), target=None
[XLA Debug] Input 30: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_20'), target=None
[XLA Debug] Input 31: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_21'), target=None
[XLA Debug] Input 32: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_22'), target=None
[XLA Debug] Input 33: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_23'), target=None
[XLA Debug] Input 34: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_24'), target=None
[XLA Debug] Input 35: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_25'), target=None
[XLA Debug] Input 36: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_26'), target=None
[XLA Debug] Input 37: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_27'), target=None
[XLA Debug] Input 38: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_28'), target=None
[XLA Debug] Input 39: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_29'), target=None
[XLA Debug] Input 40: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_30'), target=None
[XLA Debug] Input 41: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_31'), target=None
[XLA Debug] Input 42: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_32'), target=None
[XLA Debug] Input 43: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_33'), target=None
[XLA Debug] Input 44: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_34'), target=None
[XLA Debug] Input 45: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_35'), target=None
[XLA Debug] Input 46: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_36'), target=None
[XLA Debug] Input 47: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_37'), target=None
[XLA Debug] Input 48: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_38'), target=None
[XLA Debug] Input 49: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_39'), target=None
[XLA Debug] Input 50: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_40'), target=None
[XLA Debug] Initialization complete - total inputs: 51, user input indices: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
module @SyncTensorsGraph.1220 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<7x!vhlo.i64_v1>, %arg1: !vhlo.tensor_v1<64x!vhlo.f32_v1>, %arg2: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg3: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg4: !vhlo.tensor_v1<1x7x!vhlo.i64_v1>, %arg5: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, %arg6: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg7: !vhlo.tensor_v1<!vhlo.i64_v1>, %arg8: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg9: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg10: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg11: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg12: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg13: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg14: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg15: !vhlo.tensor_v1<128x!vhlo.i64_v1>, %arg16: !vhlo.tensor_v1<7x128x!vhlo.bf16_v1>, %arg17: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg18: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg19: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg20: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg21: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg23: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg24: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg25: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg26: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg27: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg28: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg29: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg30: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg31: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg32: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg33: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg34: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg35: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg36: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg37: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg38: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg39: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg40: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg41: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg42: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg43: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg44: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg45: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg46: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg47: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg48: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg49: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg50: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg51: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg52: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg53: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<7xi64>>}> : () -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<3.25520843E-4> : tensor<1x7xf32>>}> : () -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %5 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %6 = "vhlo.compare_v1"(%arg0, %0) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.bool_v1>
    %7 = "vhlo.broadcast_in_dim_v1"(%arg7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %8 = "vhlo.add_v1"(%arg0, %7) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %9 = "vhlo.select_v1"(%6, %8, %arg0) : (!vhlo.tensor_v1<7x!vhlo.bool_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1x!vhlo.i64_v1>
    %11 = "vhlo.convert_v1"(%arg6) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %12 = "vhlo.broadcast_in_dim_v1"(%11) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %13 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %14 = "vhlo.convert_v1"(%13) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.ui32_v1>
    %15 = "vhlo.gather_v2"(%arg5, %14) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3072]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %16 = "vhlo.reshape_v1"(%15) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %17 = "vhlo.convert_v1"(%16) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %18 = "vhlo.power_v1"(%17, %5) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %19 = "vhlo.reduce_v1"(%18, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %20 = "vhlo.multiply_v1"(%19, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %21 = "vhlo.reshape_v1"(%20) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %22 = "vhlo.broadcast_in_dim_v1"(%arg3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %23 = "vhlo.add_v1"(%21, %22) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %24 = "vhlo.rsqrt_v2"(%23) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %25 = "vhlo.reshape_v1"(%24) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %26 = "vhlo.broadcast_in_dim_v1"(%25) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %27 = "vhlo.multiply_v1"(%17, %26) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %28 = "vhlo.convert_v1"(%27) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %29 = "vhlo.convert_v1"(%28) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %30 = "vhlo.multiply_v1"(%12, %29) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %31 = "vhlo.convert_v1"(%30) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %32 = "vhlo.reshape_v1"(%31) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %33 = "vhlo.transpose_v1"(%arg2) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %34 = "vhlo.dot_general_v2"(%32, %33) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %35 = "vhlo.reshape_v1"(%34) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %36 = "vhlo.transpose_v1"(%35) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %37 = "vhlo.convert_v1"(%36) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %38 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %39 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %40 = "vhlo.convert_v1"(%39) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1>
    %41 = "vhlo.dot_general_v2"(%38, %40) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x7x!vhlo.f32_v1>
    %42 = "vhlo.transpose_v1"(%41) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,7,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>
    %43 = "vhlo.concatenate_v1"(%42, %42) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %44 = "vhlo.cosine_v2"(%43) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %45 = "vhlo.convert_v1"(%44) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %46 = "vhlo.reshape_v1"(%45) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>
    %47 = "vhlo.convert_v1"(%46) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>
    %48 = "vhlo.reshape_v1"(%47) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %49 = "vhlo.broadcast_in_dim_v1"(%48) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %50 = "vhlo.multiply_v1"(%37, %49) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %51 = "vhlo.convert_v1"(%50) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %52 = "vhlo.slice_v1"(%36) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %53 = "vhlo.negate_v1"(%52) : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %54 = "vhlo.slice_v1"(%36) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %55 = "vhlo.concatenate_v1"(%53, %54) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %56 = "vhlo.convert_v1"(%55) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %57 = "vhlo.sine_v2"(%43) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %58 = "vhlo.convert_v1"(%57) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %59 = "vhlo.reshape_v1"(%58) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>
    %60 = "vhlo.convert_v1"(%59) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>
    %61 = "vhlo.reshape_v1"(%60) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %62 = "vhlo.broadcast_in_dim_v1"(%61) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %63 = "vhlo.multiply_v1"(%56, %62) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %64 = "vhlo.convert_v1"(%63) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %65 = "vhlo.add_v1"(%51, %64) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %66 = "vhlo.scatter_v2"(%arg8, %10, %65) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %67 = "vhlo.custom_call_v1"(%66) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %68 = "vhlo.transpose_v1"(%arg9) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %69 = "vhlo.dot_general_v2"(%32, %68) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %70 = "vhlo.reshape_v1"(%69) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %71 = "vhlo.transpose_v1"(%70) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %72 = "vhlo.scatter_v2"(%arg10, %10, %71) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %73 = "vhlo.custom_call_v1"(%72) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %74 = "vhlo.convert_v1"(%arg21) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %75 = "vhlo.broadcast_in_dim_v1"(%74) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %76 = "vhlo.transpose_v1"(%arg18) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %77 = "vhlo.dot_general_v2"(%32, %76) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %78 = "vhlo.reshape_v1"(%77) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %79 = "vhlo.transpose_v1"(%78) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %80 = "vhlo.convert_v1"(%79) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %81 = "vhlo.broadcast_in_dim_v1"(%48) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %82 = "vhlo.multiply_v1"(%80, %81) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %83 = "vhlo.convert_v1"(%82) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %84 = "vhlo.slice_v1"(%79) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %85 = "vhlo.negate_v1"(%84) : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %86 = "vhlo.slice_v1"(%79) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %87 = "vhlo.concatenate_v1"(%85, %86) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %88 = "vhlo.convert_v1"(%87) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %89 = "vhlo.broadcast_in_dim_v1"(%61) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %90 = "vhlo.multiply_v1"(%88, %89) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %91 = "vhlo.convert_v1"(%90) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %92 = "vhlo.add_v1"(%83, %91) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %93 = "vhlo.reshape_v1"(%92) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %94 = "vhlo.broadcast_in_dim_v1"(%66) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %95 = "vhlo.reshape_v1"(%94) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %96 = "vhlo.transpose_v1"(%95) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %97 = "vhlo.reshape_v1"(%96) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %98 = "vhlo.dot_general_v2"(%93, %97) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %99 = "vhlo.reshape_v1"(%98) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %100 = "vhlo.convert_v1"(%99) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %101 = "vhlo.broadcast_in_dim_v1"(%arg17) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %102 = "vhlo.multiply_v1"(%100, %101) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %103 = "vhlo.convert_v1"(%102) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %104 = "vhlo.convert_v1"(%arg16) : (!vhlo.tensor_v1<7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.f32_v1>
    %105 = "vhlo.broadcast_in_dim_v1"(%arg15) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.i64_v1>
    %106 = "vhlo.broadcast_in_dim_v1"(%arg0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.i64_v1>
    %107 = "vhlo.compare_v1"(%105, %106) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<7x128x!vhlo.i64_v1>, !vhlo.tensor_v1<7x128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.bool_v1>
    %108 = "vhlo.convert_v1"(%107) : (!vhlo.tensor_v1<7x128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.f32_v1>
    %109 = "vhlo.multiply_v1"(%104, %108) : (!vhlo.tensor_v1<7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.f32_v1>
    %110 = "vhlo.convert_v1"(%109) : (!vhlo.tensor_v1<7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.bf16_v1>
    %111 = "vhlo.reshape_v1"(%110) : (!vhlo.tensor_v1<7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %112 = "vhlo.broadcast_in_dim_v1"(%111) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %113 = "vhlo.add_v1"(%103, %112) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %114 = "vhlo.convert_v1"(%113) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %115 = "vhlo.reduce_v1"(%114, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.maximum_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %116 = "vhlo.broadcast_in_dim_v1"(%115) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %117 = "vhlo.subtract_v1"(%114, %116) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %118 = "vhlo.exponential_v2"(%117) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %119 = "vhlo.reduce_v1"(%118, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %120 = "vhlo.broadcast_in_dim_v1"(%119) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %121 = "vhlo.divide_v1"(%118, %120) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %122 = "vhlo.convert_v1"(%121) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %123 = "vhlo.reshape_v1"(%122) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %124 = "vhlo.broadcast_in_dim_v1"(%72) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %125 = "vhlo.reshape_v1"(%124) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %126 = "vhlo.dot_general_v2"(%123, %125) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %127 = "vhlo.reshape_v1"(%126) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %128 = "vhlo.transpose_v1"(%127) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,7,24,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %129 = "vhlo.reshape_v1"(%128) : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %130 = "vhlo.transpose_v1"(%arg14) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %131 = "vhlo.dot_general_v2"(%129, %130) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %132 = "vhlo.reshape_v1"(%131) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %133 = "vhlo.add_v1"(%16, %132) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %134 = "vhlo.convert_v1"(%arg19) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %135 = "vhlo.broadcast_in_dim_v1"(%134) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %136 = "vhlo.convert_v1"(%133) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %137 = "vhlo.power_v1"(%136, %5) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %138 = "vhlo.reduce_v1"(%137, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %139 = "vhlo.multiply_v1"(%138, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %140 = "vhlo.reshape_v1"(%139) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %141 = "vhlo.add_v1"(%140, %22) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %142 = "vhlo.rsqrt_v2"(%141) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %143 = "vhlo.reshape_v1"(%142) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %144 = "vhlo.broadcast_in_dim_v1"(%143) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %145 = "vhlo.multiply_v1"(%136, %144) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %146 = "vhlo.convert_v1"(%145) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %147 = "vhlo.convert_v1"(%146) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %148 = "vhlo.multiply_v1"(%135, %147) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %149 = "vhlo.convert_v1"(%148) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %150 = "vhlo.reshape_v1"(%149) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %151 = "vhlo.transpose_v1"(%arg20) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %152 = "vhlo.dot_general_v2"(%150, %151) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %153 = "vhlo.reshape_v1"(%152) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %154 = "vhlo.convert_v1"(%153) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %155 = "vhlo.logistic_v2"(%153) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %156 = "vhlo.convert_v1"(%155) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %157 = "vhlo.multiply_v1"(%154, %156) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %158 = "vhlo.convert_v1"(%157) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %159 = "vhlo.convert_v1"(%158) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %160 = "vhlo.transpose_v1"(%arg13) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %161 = "vhlo.dot_general_v2"(%150, %160) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %162 = "vhlo.reshape_v1"(%161) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %163 = "vhlo.convert_v1"(%162) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %164 = "vhlo.multiply_v1"(%159, %163) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %165 = "vhlo.convert_v1"(%164) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %166 = "vhlo.reshape_v1"(%165) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %167 = "vhlo.transpose_v1"(%arg12) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %168 = "vhlo.dot_general_v2"(%166, %167) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %169 = "vhlo.reshape_v1"(%168) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %170 = "vhlo.add_v1"(%133, %169) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %171 = "vhlo.convert_v1"(%170) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %172 = "vhlo.power_v1"(%171, %5) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %173 = "vhlo.reduce_v1"(%172, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %174 = "vhlo.multiply_v1"(%173, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %175 = "vhlo.reshape_v1"(%174) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %176 = "vhlo.add_v1"(%175, %22) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %177 = "vhlo.rsqrt_v2"(%176) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %178 = "vhlo.reshape_v1"(%177) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %179 = "vhlo.broadcast_in_dim_v1"(%178) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %180 = "vhlo.multiply_v1"(%171, %179) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %181 = "vhlo.convert_v1"(%180) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %182 = "vhlo.convert_v1"(%181) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %183 = "vhlo.multiply_v1"(%75, %182) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %184 = "vhlo.convert_v1"(%183) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %185 = "vhlo.reshape_v1"(%184) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %186 = "vhlo.transpose_v1"(%arg11) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %187 = "vhlo.dot_general_v2"(%185, %186) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %188 = "vhlo.reshape_v1"(%187) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %189 = "vhlo.transpose_v1"(%188) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %190 = "vhlo.convert_v1"(%189) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %191 = "vhlo.multiply_v1"(%190, %49) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %192 = "vhlo.convert_v1"(%191) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %193 = "vhlo.slice_v1"(%189) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %194 = "vhlo.negate_v1"(%193) : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %195 = "vhlo.slice_v1"(%189) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %196 = "vhlo.concatenate_v1"(%194, %195) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %197 = "vhlo.convert_v1"(%196) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %198 = "vhlo.multiply_v1"(%197, %62) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %199 = "vhlo.convert_v1"(%198) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %200 = "vhlo.add_v1"(%192, %199) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %201 = "vhlo.scatter_v2"(%arg22, %10, %200) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %202 = "vhlo.custom_call_v1"(%201) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %203 = "vhlo.transpose_v1"(%arg23) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %204 = "vhlo.dot_general_v2"(%185, %203) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %205 = "vhlo.reshape_v1"(%204) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %206 = "vhlo.transpose_v1"(%205) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %207 = "vhlo.scatter_v2"(%arg24, %10, %206) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %208 = "vhlo.custom_call_v1"(%207) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %209 = "vhlo.convert_v1"(%arg32) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %210 = "vhlo.broadcast_in_dim_v1"(%209) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %211 = "vhlo.transpose_v1"(%arg29) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %212 = "vhlo.dot_general_v2"(%185, %211) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %213 = "vhlo.reshape_v1"(%212) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %214 = "vhlo.transpose_v1"(%213) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %215 = "vhlo.convert_v1"(%214) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %216 = "vhlo.multiply_v1"(%215, %81) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %217 = "vhlo.convert_v1"(%216) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %218 = "vhlo.slice_v1"(%214) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %219 = "vhlo.negate_v1"(%218) : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %220 = "vhlo.slice_v1"(%214) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %221 = "vhlo.concatenate_v1"(%219, %220) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %222 = "vhlo.convert_v1"(%221) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %223 = "vhlo.multiply_v1"(%222, %89) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %224 = "vhlo.convert_v1"(%223) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %225 = "vhlo.add_v1"(%217, %224) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %226 = "vhlo.reshape_v1"(%225) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %227 = "vhlo.broadcast_in_dim_v1"(%201) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %228 = "vhlo.reshape_v1"(%227) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %229 = "vhlo.transpose_v1"(%228) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %230 = "vhlo.reshape_v1"(%229) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %231 = "vhlo.dot_general_v2"(%226, %230) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %232 = "vhlo.reshape_v1"(%231) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %233 = "vhlo.convert_v1"(%232) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %234 = "vhlo.multiply_v1"(%233, %101) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %235 = "vhlo.convert_v1"(%234) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %236 = "vhlo.add_v1"(%235, %112) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %237 = "vhlo.convert_v1"(%236) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %238 = "vhlo.reduce_v1"(%237, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.maximum_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %239 = "vhlo.broadcast_in_dim_v1"(%238) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %240 = "vhlo.subtract_v1"(%237, %239) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %241 = "vhlo.exponential_v2"(%240) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %242 = "vhlo.reduce_v1"(%241, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %243 = "vhlo.broadcast_in_dim_v1"(%242) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %244 = "vhlo.divide_v1"(%241, %243) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %245 = "vhlo.convert_v1"(%244) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %246 = "vhlo.reshape_v1"(%245) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %247 = "vhlo.broadcast_in_dim_v1"(%207) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %248 = "vhlo.reshape_v1"(%247) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %249 = "vhlo.dot_general_v2"(%246, %248) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %250 = "vhlo.reshape_v1"(%249) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %251 = "vhlo.transpose_v1"(%250) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,7,24,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %252 = "vhlo.reshape_v1"(%251) : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %253 = "vhlo.transpose_v1"(%arg28) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %254 = "vhlo.dot_general_v2"(%252, %253) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %255 = "vhlo.reshape_v1"(%254) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %256 = "vhlo.add_v1"(%170, %255) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %257 = "vhlo.convert_v1"(%arg30) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %258 = "vhlo.broadcast_in_dim_v1"(%257) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %259 = "vhlo.convert_v1"(%256) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %260 = "vhlo.power_v1"(%259, %5) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %261 = "vhlo.reduce_v1"(%260, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %262 = "vhlo.multiply_v1"(%261, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %263 = "vhlo.reshape_v1"(%262) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %264 = "vhlo.add_v1"(%263, %22) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %265 = "vhlo.rsqrt_v2"(%264) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %266 = "vhlo.reshape_v1"(%265) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %267 = "vhlo.broadcast_in_dim_v1"(%266) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %268 = "vhlo.multiply_v1"(%259, %267) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %269 = "vhlo.convert_v1"(%268) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %270 = "vhlo.convert_v1"(%269) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %271 = "vhlo.multiply_v1"(%258, %270) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %272 = "vhlo.convert_v1"(%271) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %273 = "vhlo.reshape_v1"(%272) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %274 = "vhlo.transpose_v1"(%arg31) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %275 = "vhlo.dot_general_v2"(%273, %274) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %276 = "vhlo.reshape_v1"(%275) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %277 = "vhlo.convert_v1"(%276) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %278 = "vhlo.logistic_v2"(%276) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %279 = "vhlo.convert_v1"(%278) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %280 = "vhlo.multiply_v1"(%277, %279) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %281 = "vhlo.convert_v1"(%280) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %282 = "vhlo.convert_v1"(%281) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %283 = "vhlo.transpose_v1"(%arg27) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %284 = "vhlo.dot_general_v2"(%273, %283) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %285 = "vhlo.reshape_v1"(%284) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %286 = "vhlo.convert_v1"(%285) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %287 = "vhlo.multiply_v1"(%282, %286) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %288 = "vhlo.convert_v1"(%287) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %289 = "vhlo.reshape_v1"(%288) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %290 = "vhlo.transpose_v1"(%arg26) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %291 = "vhlo.dot_general_v2"(%289, %290) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %292 = "vhlo.reshape_v1"(%291) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %293 = "vhlo.add_v1"(%256, %292) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %294 = "vhlo.convert_v1"(%293) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %295 = "vhlo.power_v1"(%294, %5) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %296 = "vhlo.reduce_v1"(%295, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %297 = "vhlo.multiply_v1"(%296, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %298 = "vhlo.reshape_v1"(%297) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %299 = "vhlo.add_v1"(%298, %22) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %300 = "vhlo.rsqrt_v2"(%299) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %301 = "vhlo.reshape_v1"(%300) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %302 = "vhlo.broadcast_in_dim_v1"(%301) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %303 = "vhlo.multiply_v1"(%294, %302) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %304 = "vhlo.convert_v1"(%303) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %305 = "vhlo.convert_v1"(%304) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %306 = "vhlo.multiply_v1"(%210, %305) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %307 = "vhlo.convert_v1"(%306) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %308 = "vhlo.reshape_v1"(%307) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %309 = "vhlo.transpose_v1"(%arg25) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %310 = "vhlo.dot_general_v2"(%308, %309) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %311 = "vhlo.reshape_v1"(%310) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %312 = "vhlo.transpose_v1"(%311) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %313 = "vhlo.convert_v1"(%312) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %314 = "vhlo.multiply_v1"(%313, %49) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %315 = "vhlo.convert_v1"(%314) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %316 = "vhlo.slice_v1"(%312) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %317 = "vhlo.negate_v1"(%316) : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %318 = "vhlo.slice_v1"(%312) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %319 = "vhlo.concatenate_v1"(%317, %318) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %320 = "vhlo.convert_v1"(%319) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %321 = "vhlo.multiply_v1"(%320, %62) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %322 = "vhlo.convert_v1"(%321) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %323 = "vhlo.add_v1"(%315, %322) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %324 = "vhlo.scatter_v2"(%arg33, %10, %323) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %325 = "vhlo.custom_call_v1"(%324) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %326 = "vhlo.transpose_v1"(%arg34) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %327 = "vhlo.dot_general_v2"(%308, %326) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %328 = "vhlo.reshape_v1"(%327) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %329 = "vhlo.transpose_v1"(%328) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %330 = "vhlo.scatter_v2"(%arg35, %10, %329) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %331 = "vhlo.custom_call_v1"(%330) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %332 = "vhlo.convert_v1"(%arg43) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %333 = "vhlo.broadcast_in_dim_v1"(%332) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %334 = "vhlo.transpose_v1"(%arg40) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %335 = "vhlo.dot_general_v2"(%308, %334) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %336 = "vhlo.reshape_v1"(%335) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %337 = "vhlo.transpose_v1"(%336) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %338 = "vhlo.convert_v1"(%337) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %339 = "vhlo.multiply_v1"(%338, %81) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %340 = "vhlo.convert_v1"(%339) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %341 = "vhlo.slice_v1"(%337) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %342 = "vhlo.negate_v1"(%341) : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %343 = "vhlo.slice_v1"(%337) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %344 = "vhlo.concatenate_v1"(%342, %343) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %345 = "vhlo.convert_v1"(%344) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %346 = "vhlo.multiply_v1"(%345, %89) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %347 = "vhlo.convert_v1"(%346) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %348 = "vhlo.add_v1"(%340, %347) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %349 = "vhlo.reshape_v1"(%348) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %350 = "vhlo.broadcast_in_dim_v1"(%324) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %351 = "vhlo.reshape_v1"(%350) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %352 = "vhlo.transpose_v1"(%351) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %353 = "vhlo.reshape_v1"(%352) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %354 = "vhlo.dot_general_v2"(%349, %353) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %355 = "vhlo.reshape_v1"(%354) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %356 = "vhlo.convert_v1"(%355) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %357 = "vhlo.multiply_v1"(%356, %101) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %358 = "vhlo.convert_v1"(%357) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %359 = "vhlo.add_v1"(%358, %112) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %360 = "vhlo.convert_v1"(%359) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %361 = "vhlo.reduce_v1"(%360, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.maximum_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %362 = "vhlo.broadcast_in_dim_v1"(%361) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %363 = "vhlo.subtract_v1"(%360, %362) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %364 = "vhlo.exponential_v2"(%363) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %365 = "vhlo.reduce_v1"(%364, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %366 = "vhlo.broadcast_in_dim_v1"(%365) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %367 = "vhlo.divide_v1"(%364, %366) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %368 = "vhlo.convert_v1"(%367) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %369 = "vhlo.reshape_v1"(%368) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %370 = "vhlo.broadcast_in_dim_v1"(%330) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %371 = "vhlo.reshape_v1"(%370) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %372 = "vhlo.dot_general_v2"(%369, %371) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %373 = "vhlo.reshape_v1"(%372) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %374 = "vhlo.transpose_v1"(%373) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,7,24,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %375 = "vhlo.reshape_v1"(%374) : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %376 = "vhlo.transpose_v1"(%arg39) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %377 = "vhlo.dot_general_v2"(%375, %376) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %378 = "vhlo.reshape_v1"(%377) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %379 = "vhlo.add_v1"(%293, %378) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %380 = "vhlo.convert_v1"(%arg41) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %381 = "vhlo.broadcast_in_dim_v1"(%380) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %382 = "vhlo.convert_v1"(%379) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %383 = "vhlo.power_v1"(%382, %5) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %384 = "vhlo.reduce_v1"(%383, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %385 = "vhlo.multiply_v1"(%384, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %386 = "vhlo.reshape_v1"(%385) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %387 = "vhlo.add_v1"(%386, %22) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %388 = "vhlo.rsqrt_v2"(%387) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %389 = "vhlo.reshape_v1"(%388) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %390 = "vhlo.broadcast_in_dim_v1"(%389) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %391 = "vhlo.multiply_v1"(%382, %390) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %392 = "vhlo.convert_v1"(%391) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %393 = "vhlo.convert_v1"(%392) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %394 = "vhlo.multiply_v1"(%381, %393) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %395 = "vhlo.convert_v1"(%394) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %396 = "vhlo.reshape_v1"(%395) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %397 = "vhlo.transpose_v1"(%arg42) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %398 = "vhlo.dot_general_v2"(%396, %397) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %399 = "vhlo.reshape_v1"(%398) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %400 = "vhlo.convert_v1"(%399) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %401 = "vhlo.logistic_v2"(%399) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %402 = "vhlo.convert_v1"(%401) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %403 = "vhlo.multiply_v1"(%400, %402) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %404 = "vhlo.convert_v1"(%403) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %405 = "vhlo.convert_v1"(%404) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %406 = "vhlo.transpose_v1"(%arg38) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %407 = "vhlo.dot_general_v2"(%396, %406) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %408 = "vhlo.reshape_v1"(%407) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %409 = "vhlo.convert_v1"(%408) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %410 = "vhlo.multiply_v1"(%405, %409) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %411 = "vhlo.convert_v1"(%410) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %412 = "vhlo.reshape_v1"(%411) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %413 = "vhlo.transpose_v1"(%arg37) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %414 = "vhlo.dot_general_v2"(%412, %413) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %415 = "vhlo.reshape_v1"(%414) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %416 = "vhlo.add_v1"(%379, %415) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %417 = "vhlo.convert_v1"(%416) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %418 = "vhlo.power_v1"(%417, %5) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %419 = "vhlo.reduce_v1"(%418, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %420 = "vhlo.multiply_v1"(%419, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %421 = "vhlo.reshape_v1"(%420) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %422 = "vhlo.add_v1"(%421, %22) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %423 = "vhlo.rsqrt_v2"(%422) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %424 = "vhlo.reshape_v1"(%423) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %425 = "vhlo.broadcast_in_dim_v1"(%424) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %426 = "vhlo.multiply_v1"(%417, %425) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %427 = "vhlo.convert_v1"(%426) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %428 = "vhlo.convert_v1"(%427) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %429 = "vhlo.multiply_v1"(%333, %428) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %430 = "vhlo.convert_v1"(%429) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %431 = "vhlo.reshape_v1"(%430) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %432 = "vhlo.transpose_v1"(%arg36) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %433 = "vhlo.dot_general_v2"(%431, %432) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %434 = "vhlo.reshape_v1"(%433) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %435 = "vhlo.transpose_v1"(%434) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %436 = "vhlo.convert_v1"(%435) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %437 = "vhlo.multiply_v1"(%436, %49) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %438 = "vhlo.convert_v1"(%437) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %439 = "vhlo.slice_v1"(%435) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %440 = "vhlo.negate_v1"(%439) : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %441 = "vhlo.slice_v1"(%435) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %442 = "vhlo.concatenate_v1"(%440, %441) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %443 = "vhlo.convert_v1"(%442) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %444 = "vhlo.multiply_v1"(%443, %62) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %445 = "vhlo.convert_v1"(%444) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %446 = "vhlo.add_v1"(%438, %445) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %447 = "vhlo.scatter_v2"(%arg44, %10, %446) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %448 = "vhlo.custom_call_v1"(%447) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %449 = "vhlo.transpose_v1"(%arg45) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %450 = "vhlo.dot_general_v2"(%431, %449) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %451 = "vhlo.reshape_v1"(%450) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %452 = "vhlo.transpose_v1"(%451) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %453 = "vhlo.scatter_v2"(%arg46, %10, %452) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %454 = "vhlo.custom_call_v1"(%453) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %455 = "vhlo.convert_v1"(%arg53) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %456 = "vhlo.broadcast_in_dim_v1"(%455) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %457 = "vhlo.transpose_v1"(%arg50) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %458 = "vhlo.dot_general_v2"(%431, %457) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %459 = "vhlo.reshape_v1"(%458) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %460 = "vhlo.transpose_v1"(%459) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %461 = "vhlo.convert_v1"(%460) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %462 = "vhlo.multiply_v1"(%461, %81) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %463 = "vhlo.convert_v1"(%462) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %464 = "vhlo.slice_v1"(%460) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %465 = "vhlo.negate_v1"(%464) : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %466 = "vhlo.slice_v1"(%460) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %467 = "vhlo.concatenate_v1"(%465, %466) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %468 = "vhlo.convert_v1"(%467) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %469 = "vhlo.multiply_v1"(%468, %89) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %470 = "vhlo.convert_v1"(%469) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %471 = "vhlo.add_v1"(%463, %470) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %472 = "vhlo.reshape_v1"(%471) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %473 = "vhlo.broadcast_in_dim_v1"(%447) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %474 = "vhlo.reshape_v1"(%473) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %475 = "vhlo.transpose_v1"(%474) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %476 = "vhlo.reshape_v1"(%475) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %477 = "vhlo.dot_general_v2"(%472, %476) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %478 = "vhlo.reshape_v1"(%477) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %479 = "vhlo.convert_v1"(%478) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %480 = "vhlo.multiply_v1"(%479, %101) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %481 = "vhlo.convert_v1"(%480) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %482 = "vhlo.add_v1"(%481, %112) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %483 = "vhlo.convert_v1"(%482) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %484 = "vhlo.reduce_v1"(%483, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.maximum_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %485 = "vhlo.broadcast_in_dim_v1"(%484) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %486 = "vhlo.subtract_v1"(%483, %485) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %487 = "vhlo.exponential_v2"(%486) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %488 = "vhlo.reduce_v1"(%487, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %489 = "vhlo.broadcast_in_dim_v1"(%488) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %490 = "vhlo.divide_v1"(%487, %489) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %491 = "vhlo.convert_v1"(%490) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %492 = "vhlo.reshape_v1"(%491) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %493 = "vhlo.broadcast_in_dim_v1"(%453) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %494 = "vhlo.reshape_v1"(%493) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %495 = "vhlo.dot_general_v2"(%492, %494) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %496 = "vhlo.reshape_v1"(%495) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %497 = "vhlo.transpose_v1"(%496) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,7,24,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %498 = "vhlo.reshape_v1"(%497) : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %499 = "vhlo.transpose_v1"(%arg49) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %500 = "vhlo.dot_general_v2"(%498, %499) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %501 = "vhlo.reshape_v1"(%500) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %502 = "vhlo.add_v1"(%416, %501) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %503 = "vhlo.convert_v1"(%arg51) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %504 = "vhlo.broadcast_in_dim_v1"(%503) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %505 = "vhlo.convert_v1"(%502) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %506 = "vhlo.power_v1"(%505, %5) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %507 = "vhlo.reduce_v1"(%506, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %508 = "vhlo.multiply_v1"(%507, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %509 = "vhlo.reshape_v1"(%508) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %510 = "vhlo.add_v1"(%509, %22) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %511 = "vhlo.rsqrt_v2"(%510) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %512 = "vhlo.reshape_v1"(%511) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %513 = "vhlo.broadcast_in_dim_v1"(%512) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %514 = "vhlo.multiply_v1"(%505, %513) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %515 = "vhlo.convert_v1"(%514) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %516 = "vhlo.convert_v1"(%515) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %517 = "vhlo.multiply_v1"(%504, %516) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %518 = "vhlo.convert_v1"(%517) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %519 = "vhlo.reshape_v1"(%518) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %520 = "vhlo.transpose_v1"(%arg52) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %521 = "vhlo.dot_general_v2"(%519, %520) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %522 = "vhlo.reshape_v1"(%521) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %523 = "vhlo.convert_v1"(%522) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %524 = "vhlo.logistic_v2"(%522) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %525 = "vhlo.convert_v1"(%524) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %526 = "vhlo.multiply_v1"(%523, %525) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %527 = "vhlo.convert_v1"(%526) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %528 = "vhlo.convert_v1"(%527) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %529 = "vhlo.transpose_v1"(%arg48) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %530 = "vhlo.dot_general_v2"(%519, %529) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %531 = "vhlo.reshape_v1"(%530) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %532 = "vhlo.convert_v1"(%531) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %533 = "vhlo.multiply_v1"(%528, %532) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %534 = "vhlo.convert_v1"(%533) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %535 = "vhlo.reshape_v1"(%534) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %536 = "vhlo.transpose_v1"(%arg47) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %537 = "vhlo.dot_general_v2"(%535, %536) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %538 = "vhlo.reshape_v1"(%537) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %539 = "vhlo.add_v1"(%502, %538) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %540 = "vhlo.convert_v1"(%539) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %541 = "vhlo.power_v1"(%540, %5) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %542 = "vhlo.reduce_v1"(%541, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %558 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%558) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %543 = "vhlo.multiply_v1"(%542, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %544 = "vhlo.reshape_v1"(%543) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %545 = "vhlo.add_v1"(%544, %22) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %546 = "vhlo.rsqrt_v2"(%545) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %547 = "vhlo.reshape_v1"(%546) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %548 = "vhlo.broadcast_in_dim_v1"(%547) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %549 = "vhlo.multiply_v1"(%540, %548) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %550 = "vhlo.convert_v1"(%549) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %551 = "vhlo.convert_v1"(%550) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %552 = "vhlo.multiply_v1"(%456, %551) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %553 = "vhlo.convert_v1"(%552) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %554 = "vhlo.reshape_v1"(%553) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %555 = "vhlo.transpose_v1"(%arg5) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,128256]{0,1}">} : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>
    %556 = "vhlo.dot_general_v2"(%554, %555) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>
    %557 = "vhlo.reshape_v1"(%556) : (!vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>
    "vhlo.return_v1"(%67, %73, %202, %208, %325, %331, %448, %454, %556, %557) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}
module @SyncTensorsGraph.1220 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg2: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg3: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg4: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg5: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg6: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg7: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg8: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg9: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg10: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg11: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg12: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg13: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg14: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg15: tensor<128xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg16: tensor<7x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg17: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg18: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg19: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg20: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg21: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg22: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg23: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg24: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg25: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg26: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg27: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg28: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg29: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg30: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg31: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg32: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg33: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg34: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg35: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg36: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg37: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg38: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg39: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg40: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg41: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg42: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg43: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg44: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg45: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg46: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg47: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg48: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg49: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg50: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg51: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg52: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg53: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>) {
    %c = stablehlo.constant dense<0> : tensor<7xi64>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %1 = stablehlo.compare  LT, %arg0, %c : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %2 = stablehlo.broadcast_in_dim %arg7, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %3 = stablehlo.add %arg0, %2 : tensor<7xi64>
    %4 = stablehlo.select %1, %3, %arg0 : tensor<7xi1>, tensor<7xi64>
    %5 = stablehlo.reshape %4 : (tensor<7xi64>) -> tensor<7x1xi64>
    %6 = stablehlo.convert %arg6 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %7 = stablehlo.broadcast_in_dim %6, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %8 = stablehlo.convert %arg4 : (tensor<1x7xi64>) -> tensor<1x7xui32>
    %9 = stablehlo.reshape %8 : (tensor<1x7xui32>) -> tensor<7xui32>
    %10 = "stablehlo.gather"(%arg5, %9) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %11 = stablehlo.reshape %10 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %12 = stablehlo.convert %11 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %13 = stablehlo.power %12, %0 : tensor<1x7x3072xf32>
    %14 = stablehlo.reduce(%13 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %15 = stablehlo.multiply %14, %cst_1 : tensor<1x7xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %17 = stablehlo.broadcast_in_dim %arg3, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %18 = stablehlo.add %16, %17 : tensor<1x7x1xf32>
    %19 = stablehlo.rsqrt %18 : tensor<1x7x1xf32>
    %20 = stablehlo.reshape %19 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %21 = stablehlo.broadcast_in_dim %20, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %22 = stablehlo.multiply %12, %21 : tensor<1x7x3072xf32>
    %23 = stablehlo.convert %22 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %24 = stablehlo.convert %23 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %25 = stablehlo.multiply %7, %24 : tensor<1x7x3072xf32>
    %26 = stablehlo.convert %25 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %27 = stablehlo.reshape %26 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %28 = stablehlo.transpose %arg2, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %29 = stablehlo.dot_general %27, %28, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %30 = stablehlo.reshape %29 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %31 = stablehlo.transpose %30, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %32 = stablehlo.convert %31 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %33 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x64x1xf32>
    %34 = stablehlo.convert %arg0 : (tensor<7xi64>) -> tensor<7xf32>
    %35 = stablehlo.reshape %34 : (tensor<7xf32>) -> tensor<1x1x7xf32>
    %36 = stablehlo.dot_general %33, %35, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %38 = stablehlo.concatenate %37, %37, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %39 = stablehlo.cosine %38 : tensor<1x7x128xf32>
    %40 = stablehlo.convert %39 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %41 = stablehlo.convert %40 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %42 = stablehlo.broadcast_in_dim %41, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %43 = stablehlo.multiply %32, %42 : tensor<1x8x7x128xf32>
    %44 = stablehlo.convert %43 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %45 = stablehlo.slice %31 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %46 = stablehlo.negate %45 : tensor<1x8x7x64xbf16>
    %47 = stablehlo.slice %31 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %48 = stablehlo.concatenate %46, %47, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %49 = stablehlo.convert %48 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %50 = stablehlo.sine %38 : tensor<1x7x128xf32>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %52 = stablehlo.convert %51 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %53 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %54 = stablehlo.multiply %49, %53 : tensor<1x8x7x128xf32>
    %55 = stablehlo.convert %54 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %56 = stablehlo.add %44, %55 : tensor<1x8x7x128xbf16>
    %57 = "stablehlo.scatter"(%arg8, %5, %56) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %58 = sdy.sharding_constraint %57 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %59 = stablehlo.transpose %arg9, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %60 = stablehlo.dot_general %27, %59, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %61 = stablehlo.reshape %60 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %62 = stablehlo.transpose %61, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %63 = "stablehlo.scatter"(%arg10, %5, %62) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %64 = sdy.sharding_constraint %63 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %65 = stablehlo.convert %arg21 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %67 = stablehlo.transpose %arg18, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %68 = stablehlo.dot_general %27, %67, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %69 = stablehlo.reshape %68 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %70 = stablehlo.transpose %69, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %71 = stablehlo.convert %70 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %72 = stablehlo.broadcast_in_dim %41, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %73 = stablehlo.multiply %71, %72 : tensor<1x24x7x128xf32>
    %74 = stablehlo.convert %73 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %75 = stablehlo.slice %70 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %76 = stablehlo.negate %75 : tensor<1x24x7x64xbf16>
    %77 = stablehlo.slice %70 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %79 = stablehlo.convert %78 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %81 = stablehlo.multiply %79, %80 : tensor<1x24x7x128xf32>
    %82 = stablehlo.convert %81 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %83 = stablehlo.add %74, %82 : tensor<1x24x7x128xbf16>
    %84 = stablehlo.reshape %83 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %85 = stablehlo.broadcast_in_dim %57, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %86 = stablehlo.reshape %85 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %87 = stablehlo.transpose %86, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %88 = stablehlo.reshape %87 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %89 = stablehlo.dot_general %84, %88, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %90 = stablehlo.convert %89 : (tensor<24x7x128xbf16>) -> tensor<24x7x128xf32>
    %91 = stablehlo.reshape %90 : (tensor<24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %92 = stablehlo.broadcast_in_dim %arg17, dims = [] : (tensor<f32>) -> tensor<1x24x7x128xf32>
    %93 = stablehlo.multiply %91, %92 : tensor<1x24x7x128xf32>
    %94 = stablehlo.convert %93 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %95 = stablehlo.convert %arg16 : (tensor<7x128xbf16>) -> tensor<7x128xf32>
    %96 = stablehlo.broadcast_in_dim %arg15, dims = [1] : (tensor<128xi64>) -> tensor<7x128xi64>
    %97 = stablehlo.broadcast_in_dim %arg0, dims = [0] : (tensor<7xi64>) -> tensor<7x128xi64>
    %98 = stablehlo.compare  GT, %96, %97 : (tensor<7x128xi64>, tensor<7x128xi64>) -> tensor<7x128xi1>
    %99 = stablehlo.convert %98 : (tensor<7x128xi1>) -> tensor<7x128xf32>
    %100 = stablehlo.multiply %95, %99 : tensor<7x128xf32>
    %101 = stablehlo.convert %100 : (tensor<7x128xf32>) -> tensor<7x128xbf16>
    %102 = stablehlo.reshape %101 : (tensor<7x128xbf16>) -> tensor<1x7x128xbf16>
    %103 = stablehlo.broadcast_in_dim %102, dims = [0, 2, 3] : (tensor<1x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %104 = stablehlo.add %94, %103 : tensor<1x24x7x128xbf16>
    %105 = stablehlo.convert %104 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %106 = stablehlo.reduce(%105 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %107 = stablehlo.broadcast_in_dim %106, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %108 = stablehlo.subtract %105, %107 : tensor<1x24x7x128xf32>
    %109 = stablehlo.exponential %108 : tensor<1x24x7x128xf32>
    %110 = stablehlo.reduce(%109 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %111 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %112 = stablehlo.divide %109, %111 : tensor<1x24x7x128xf32>
    %113 = stablehlo.convert %112 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %114 = stablehlo.reshape %113 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %115 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %116 = stablehlo.reshape %115 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %117 = stablehlo.dot_general %114, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %118 = stablehlo.reshape %117 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %119 = stablehlo.transpose %118, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %120 = stablehlo.reshape %119 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %121 = stablehlo.transpose %arg14, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %122 = stablehlo.dot_general %120, %121, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %123 = stablehlo.reshape %122 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %124 = stablehlo.add %11, %123 : tensor<1x7x3072xbf16>
    %125 = stablehlo.convert %arg19 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %126 = stablehlo.broadcast_in_dim %125, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %127 = stablehlo.convert %124 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %128 = stablehlo.power %127, %0 : tensor<1x7x3072xf32>
    %129 = stablehlo.reduce(%128 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %130 = stablehlo.multiply %129, %cst_1 : tensor<1x7xf32>
    %131 = stablehlo.reshape %130 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %132 = stablehlo.add %131, %17 : tensor<1x7x1xf32>
    %133 = stablehlo.rsqrt %132 : tensor<1x7x1xf32>
    %134 = stablehlo.reshape %133 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %136 = stablehlo.multiply %127, %135 : tensor<1x7x3072xf32>
    %137 = stablehlo.convert %136 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %138 = stablehlo.convert %137 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %139 = stablehlo.multiply %126, %138 : tensor<1x7x3072xf32>
    %140 = stablehlo.convert %139 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %141 = stablehlo.reshape %140 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %142 = stablehlo.transpose %arg20, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %143 = stablehlo.dot_general %141, %142, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %144 = stablehlo.reshape %143 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %145 = stablehlo.convert %144 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %146 = stablehlo.logistic %144 : tensor<1x7x8192xbf16>
    %147 = stablehlo.convert %146 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %148 = stablehlo.multiply %145, %147 : tensor<1x7x8192xf32>
    %149 = stablehlo.convert %148 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %150 = stablehlo.convert %149 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %151 = stablehlo.transpose %arg13, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %152 = stablehlo.dot_general %141, %151, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %153 = stablehlo.convert %152 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %154 = stablehlo.reshape %153 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %155 = stablehlo.multiply %150, %154 : tensor<1x7x8192xf32>
    %156 = stablehlo.convert %155 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %157 = stablehlo.reshape %156 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %158 = stablehlo.transpose %arg12, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %159 = stablehlo.dot_general %157, %158, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %160 = stablehlo.reshape %159 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %161 = stablehlo.add %124, %160 : tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.power %162, %0 : tensor<1x7x3072xf32>
    %164 = stablehlo.reduce(%163 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %165 = stablehlo.multiply %164, %cst_1 : tensor<1x7xf32>
    %166 = stablehlo.reshape %165 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %167 = stablehlo.add %166, %17 : tensor<1x7x1xf32>
    %168 = stablehlo.rsqrt %167 : tensor<1x7x1xf32>
    %169 = stablehlo.reshape %168 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %170 = stablehlo.broadcast_in_dim %169, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %171 = stablehlo.multiply %162, %170 : tensor<1x7x3072xf32>
    %172 = stablehlo.convert %171 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %173 = stablehlo.convert %172 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %174 = stablehlo.multiply %66, %173 : tensor<1x7x3072xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %176 = stablehlo.reshape %175 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %177 = stablehlo.transpose %arg11, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %178 = stablehlo.dot_general %176, %177, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %179 = stablehlo.reshape %178 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %180 = stablehlo.transpose %179, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %181 = stablehlo.convert %180 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %182 = stablehlo.multiply %181, %42 : tensor<1x8x7x128xf32>
    %183 = stablehlo.convert %182 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %184 = stablehlo.slice %180 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %185 = stablehlo.negate %184 : tensor<1x8x7x64xbf16>
    %186 = stablehlo.slice %180 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %187 = stablehlo.concatenate %185, %186, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %188 = stablehlo.convert %187 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %189 = stablehlo.multiply %188, %53 : tensor<1x8x7x128xf32>
    %190 = stablehlo.convert %189 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %191 = stablehlo.add %183, %190 : tensor<1x8x7x128xbf16>
    %192 = "stablehlo.scatter"(%arg22, %5, %191) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %193 = sdy.sharding_constraint %192 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %194 = stablehlo.transpose %arg23, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %195 = stablehlo.dot_general %176, %194, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %196 = stablehlo.reshape %195 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %197 = stablehlo.transpose %196, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %198 = "stablehlo.scatter"(%arg24, %5, %197) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %199 = sdy.sharding_constraint %198 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %200 = stablehlo.convert %arg32 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %201 = stablehlo.broadcast_in_dim %200, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %202 = stablehlo.transpose %arg29, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %203 = stablehlo.dot_general %176, %202, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %204 = stablehlo.reshape %203 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %205 = stablehlo.transpose %204, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %206 = stablehlo.convert %205 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %207 = stablehlo.multiply %206, %72 : tensor<1x24x7x128xf32>
    %208 = stablehlo.convert %207 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %209 = stablehlo.slice %205 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %210 = stablehlo.negate %209 : tensor<1x24x7x64xbf16>
    %211 = stablehlo.slice %205 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %212 = stablehlo.concatenate %210, %211, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %213 = stablehlo.convert %212 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %214 = stablehlo.multiply %213, %80 : tensor<1x24x7x128xf32>
    %215 = stablehlo.convert %214 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %216 = stablehlo.add %208, %215 : tensor<1x24x7x128xbf16>
    %217 = stablehlo.reshape %216 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %218 = stablehlo.broadcast_in_dim %192, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %219 = stablehlo.reshape %218 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %220 = stablehlo.transpose %219, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %221 = stablehlo.reshape %220 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %222 = stablehlo.dot_general %217, %221, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %223 = stablehlo.convert %222 : (tensor<24x7x128xbf16>) -> tensor<24x7x128xf32>
    %224 = stablehlo.reshape %223 : (tensor<24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %225 = stablehlo.multiply %224, %92 : tensor<1x24x7x128xf32>
    %226 = stablehlo.convert %225 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %227 = stablehlo.add %226, %103 : tensor<1x24x7x128xbf16>
    %228 = stablehlo.convert %227 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %229 = stablehlo.reduce(%228 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %230 = stablehlo.broadcast_in_dim %229, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %231 = stablehlo.subtract %228, %230 : tensor<1x24x7x128xf32>
    %232 = stablehlo.exponential %231 : tensor<1x24x7x128xf32>
    %233 = stablehlo.reduce(%232 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %234 = stablehlo.broadcast_in_dim %233, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %235 = stablehlo.divide %232, %234 : tensor<1x24x7x128xf32>
    %236 = stablehlo.convert %235 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %237 = stablehlo.reshape %236 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %238 = stablehlo.broadcast_in_dim %198, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %239 = stablehlo.reshape %238 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %240 = stablehlo.dot_general %237, %239, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %241 = stablehlo.reshape %240 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %242 = stablehlo.transpose %241, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %243 = stablehlo.reshape %242 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %244 = stablehlo.transpose %arg28, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %245 = stablehlo.dot_general %243, %244, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %246 = stablehlo.reshape %245 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %247 = stablehlo.add %161, %246 : tensor<1x7x3072xbf16>
    %248 = stablehlo.convert %arg30 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %249 = stablehlo.broadcast_in_dim %248, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %250 = stablehlo.convert %247 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %251 = stablehlo.power %250, %0 : tensor<1x7x3072xf32>
    %252 = stablehlo.reduce(%251 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %253 = stablehlo.multiply %252, %cst_1 : tensor<1x7xf32>
    %254 = stablehlo.reshape %253 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %255 = stablehlo.add %254, %17 : tensor<1x7x1xf32>
    %256 = stablehlo.rsqrt %255 : tensor<1x7x1xf32>
    %257 = stablehlo.reshape %256 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %258 = stablehlo.broadcast_in_dim %257, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %259 = stablehlo.multiply %250, %258 : tensor<1x7x3072xf32>
    %260 = stablehlo.convert %259 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %261 = stablehlo.convert %260 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %262 = stablehlo.multiply %249, %261 : tensor<1x7x3072xf32>
    %263 = stablehlo.convert %262 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %264 = stablehlo.reshape %263 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %265 = stablehlo.transpose %arg31, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %266 = stablehlo.dot_general %264, %265, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %267 = stablehlo.reshape %266 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %268 = stablehlo.convert %267 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %269 = stablehlo.logistic %267 : tensor<1x7x8192xbf16>
    %270 = stablehlo.convert %269 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %271 = stablehlo.multiply %268, %270 : tensor<1x7x8192xf32>
    %272 = stablehlo.convert %271 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %273 = stablehlo.convert %272 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %274 = stablehlo.transpose %arg27, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %275 = stablehlo.dot_general %264, %274, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %276 = stablehlo.convert %275 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %277 = stablehlo.reshape %276 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %278 = stablehlo.multiply %273, %277 : tensor<1x7x8192xf32>
    %279 = stablehlo.convert %278 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %280 = stablehlo.reshape %279 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %281 = stablehlo.transpose %arg26, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %282 = stablehlo.dot_general %280, %281, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %283 = stablehlo.reshape %282 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %284 = stablehlo.add %247, %283 : tensor<1x7x3072xbf16>
    %285 = stablehlo.convert %284 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %286 = stablehlo.power %285, %0 : tensor<1x7x3072xf32>
    %287 = stablehlo.reduce(%286 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %288 = stablehlo.multiply %287, %cst_1 : tensor<1x7xf32>
    %289 = stablehlo.reshape %288 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %290 = stablehlo.add %289, %17 : tensor<1x7x1xf32>
    %291 = stablehlo.rsqrt %290 : tensor<1x7x1xf32>
    %292 = stablehlo.reshape %291 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %293 = stablehlo.broadcast_in_dim %292, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %294 = stablehlo.multiply %285, %293 : tensor<1x7x3072xf32>
    %295 = stablehlo.convert %294 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %296 = stablehlo.convert %295 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %297 = stablehlo.multiply %201, %296 : tensor<1x7x3072xf32>
    %298 = stablehlo.convert %297 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %299 = stablehlo.reshape %298 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %300 = stablehlo.transpose %arg25, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %301 = stablehlo.dot_general %299, %300, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %302 = stablehlo.reshape %301 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %303 = stablehlo.transpose %302, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %304 = stablehlo.convert %303 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %305 = stablehlo.multiply %304, %42 : tensor<1x8x7x128xf32>
    %306 = stablehlo.convert %305 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %307 = stablehlo.slice %303 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %308 = stablehlo.negate %307 : tensor<1x8x7x64xbf16>
    %309 = stablehlo.slice %303 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %310 = stablehlo.concatenate %308, %309, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %311 = stablehlo.convert %310 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %312 = stablehlo.multiply %311, %53 : tensor<1x8x7x128xf32>
    %313 = stablehlo.convert %312 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %314 = stablehlo.add %306, %313 : tensor<1x8x7x128xbf16>
    %315 = "stablehlo.scatter"(%arg33, %5, %314) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %316 = sdy.sharding_constraint %315 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %317 = stablehlo.transpose %arg34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %318 = stablehlo.dot_general %299, %317, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %319 = stablehlo.reshape %318 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %320 = stablehlo.transpose %319, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %321 = "stablehlo.scatter"(%arg35, %5, %320) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %322 = sdy.sharding_constraint %321 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %323 = stablehlo.convert %arg43 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %324 = stablehlo.broadcast_in_dim %323, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %325 = stablehlo.transpose %arg40, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %326 = stablehlo.dot_general %299, %325, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %327 = stablehlo.reshape %326 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %328 = stablehlo.transpose %327, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %329 = stablehlo.convert %328 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %330 = stablehlo.multiply %329, %72 : tensor<1x24x7x128xf32>
    %331 = stablehlo.convert %330 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %332 = stablehlo.slice %328 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %333 = stablehlo.negate %332 : tensor<1x24x7x64xbf16>
    %334 = stablehlo.slice %328 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %335 = stablehlo.concatenate %333, %334, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %336 = stablehlo.convert %335 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %337 = stablehlo.multiply %336, %80 : tensor<1x24x7x128xf32>
    %338 = stablehlo.convert %337 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %339 = stablehlo.add %331, %338 : tensor<1x24x7x128xbf16>
    %340 = stablehlo.reshape %339 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %341 = stablehlo.broadcast_in_dim %315, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %342 = stablehlo.reshape %341 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %343 = stablehlo.transpose %342, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %344 = stablehlo.reshape %343 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %345 = stablehlo.dot_general %340, %344, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %346 = stablehlo.convert %345 : (tensor<24x7x128xbf16>) -> tensor<24x7x128xf32>
    %347 = stablehlo.reshape %346 : (tensor<24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %348 = stablehlo.multiply %347, %92 : tensor<1x24x7x128xf32>
    %349 = stablehlo.convert %348 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %350 = stablehlo.add %349, %103 : tensor<1x24x7x128xbf16>
    %351 = stablehlo.convert %350 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %352 = stablehlo.reduce(%351 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %353 = stablehlo.broadcast_in_dim %352, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %354 = stablehlo.subtract %351, %353 : tensor<1x24x7x128xf32>
    %355 = stablehlo.exponential %354 : tensor<1x24x7x128xf32>
    %356 = stablehlo.reduce(%355 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %357 = stablehlo.broadcast_in_dim %356, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %358 = stablehlo.divide %355, %357 : tensor<1x24x7x128xf32>
    %359 = stablehlo.convert %358 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %360 = stablehlo.reshape %359 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %361 = stablehlo.broadcast_in_dim %321, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %362 = stablehlo.reshape %361 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %363 = stablehlo.dot_general %360, %362, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %364 = stablehlo.reshape %363 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %365 = stablehlo.transpose %364, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %366 = stablehlo.reshape %365 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %367 = stablehlo.transpose %arg39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %368 = stablehlo.dot_general %366, %367, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %369 = stablehlo.reshape %368 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %370 = stablehlo.add %284, %369 : tensor<1x7x3072xbf16>
    %371 = stablehlo.convert %arg41 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %372 = stablehlo.broadcast_in_dim %371, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %373 = stablehlo.convert %370 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %374 = stablehlo.power %373, %0 : tensor<1x7x3072xf32>
    %375 = stablehlo.reduce(%374 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %376 = stablehlo.multiply %375, %cst_1 : tensor<1x7xf32>
    %377 = stablehlo.reshape %376 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %378 = stablehlo.add %377, %17 : tensor<1x7x1xf32>
    %379 = stablehlo.rsqrt %378 : tensor<1x7x1xf32>
    %380 = stablehlo.reshape %379 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %381 = stablehlo.broadcast_in_dim %380, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %382 = stablehlo.multiply %373, %381 : tensor<1x7x3072xf32>
    %383 = stablehlo.convert %382 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %384 = stablehlo.convert %383 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %385 = stablehlo.multiply %372, %384 : tensor<1x7x3072xf32>
    %386 = stablehlo.convert %385 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %387 = stablehlo.reshape %386 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %388 = stablehlo.transpose %arg42, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %389 = stablehlo.dot_general %387, %388, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %390 = stablehlo.reshape %389 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %391 = stablehlo.convert %390 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %392 = stablehlo.logistic %390 : tensor<1x7x8192xbf16>
    %393 = stablehlo.convert %392 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %394 = stablehlo.multiply %391, %393 : tensor<1x7x8192xf32>
    %395 = stablehlo.convert %394 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %396 = stablehlo.convert %395 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %397 = stablehlo.transpose %arg38, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %398 = stablehlo.dot_general %387, %397, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %399 = stablehlo.convert %398 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %400 = stablehlo.reshape %399 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %401 = stablehlo.multiply %396, %400 : tensor<1x7x8192xf32>
    %402 = stablehlo.convert %401 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %403 = stablehlo.reshape %402 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %404 = stablehlo.transpose %arg37, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %405 = stablehlo.dot_general %403, %404, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %406 = stablehlo.reshape %405 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %407 = stablehlo.add %370, %406 : tensor<1x7x3072xbf16>
    %408 = stablehlo.convert %407 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %409 = stablehlo.power %408, %0 : tensor<1x7x3072xf32>
    %410 = stablehlo.reduce(%409 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %411 = stablehlo.multiply %410, %cst_1 : tensor<1x7xf32>
    %412 = stablehlo.reshape %411 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %413 = stablehlo.add %412, %17 : tensor<1x7x1xf32>
    %414 = stablehlo.rsqrt %413 : tensor<1x7x1xf32>
    %415 = stablehlo.reshape %414 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %416 = stablehlo.broadcast_in_dim %415, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %417 = stablehlo.multiply %408, %416 : tensor<1x7x3072xf32>
    %418 = stablehlo.convert %417 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %419 = stablehlo.convert %418 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %420 = stablehlo.multiply %324, %419 : tensor<1x7x3072xf32>
    %421 = stablehlo.convert %420 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %422 = stablehlo.reshape %421 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %423 = stablehlo.transpose %arg36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %424 = stablehlo.dot_general %422, %423, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %425 = stablehlo.reshape %424 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %426 = stablehlo.transpose %425, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %427 = stablehlo.convert %426 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %428 = stablehlo.multiply %427, %42 : tensor<1x8x7x128xf32>
    %429 = stablehlo.convert %428 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %430 = stablehlo.slice %426 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %431 = stablehlo.negate %430 : tensor<1x8x7x64xbf16>
    %432 = stablehlo.slice %426 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %433 = stablehlo.concatenate %431, %432, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %434 = stablehlo.convert %433 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %435 = stablehlo.multiply %434, %53 : tensor<1x8x7x128xf32>
    %436 = stablehlo.convert %435 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %437 = stablehlo.add %429, %436 : tensor<1x8x7x128xbf16>
    %438 = "stablehlo.scatter"(%arg44, %5, %437) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %439 = sdy.sharding_constraint %438 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %440 = stablehlo.transpose %arg45, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %441 = stablehlo.dot_general %422, %440, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %442 = stablehlo.reshape %441 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %443 = stablehlo.transpose %442, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %444 = "stablehlo.scatter"(%arg46, %5, %443) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %445 = sdy.sharding_constraint %444 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %446 = stablehlo.convert %arg53 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %447 = stablehlo.broadcast_in_dim %446, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %448 = stablehlo.transpose %arg50, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %449 = stablehlo.dot_general %422, %448, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %450 = stablehlo.reshape %449 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %451 = stablehlo.transpose %450, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %452 = stablehlo.convert %451 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %453 = stablehlo.multiply %452, %72 : tensor<1x24x7x128xf32>
    %454 = stablehlo.convert %453 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %455 = stablehlo.slice %451 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %456 = stablehlo.negate %455 : tensor<1x24x7x64xbf16>
    %457 = stablehlo.slice %451 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %458 = stablehlo.concatenate %456, %457, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %459 = stablehlo.convert %458 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %460 = stablehlo.multiply %459, %80 : tensor<1x24x7x128xf32>
    %461 = stablehlo.convert %460 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %462 = stablehlo.add %454, %461 : tensor<1x24x7x128xbf16>
    %463 = stablehlo.reshape %462 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %464 = stablehlo.broadcast_in_dim %438, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %465 = stablehlo.reshape %464 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %466 = stablehlo.transpose %465, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %467 = stablehlo.reshape %466 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %468 = stablehlo.dot_general %463, %467, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %469 = stablehlo.convert %468 : (tensor<24x7x128xbf16>) -> tensor<24x7x128xf32>
    %470 = stablehlo.reshape %469 : (tensor<24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %471 = stablehlo.multiply %470, %92 : tensor<1x24x7x128xf32>
    %472 = stablehlo.convert %471 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %473 = stablehlo.add %472, %103 : tensor<1x24x7x128xbf16>
    %474 = stablehlo.convert %473 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %475 = stablehlo.reduce(%474 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %476 = stablehlo.broadcast_in_dim %475, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %477 = stablehlo.subtract %474, %476 : tensor<1x24x7x128xf32>
    %478 = stablehlo.exponential %477 : tensor<1x24x7x128xf32>
    %479 = stablehlo.reduce(%478 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %480 = stablehlo.broadcast_in_dim %479, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %481 = stablehlo.divide %478, %480 : tensor<1x24x7x128xf32>
    %482 = stablehlo.convert %481 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %483 = stablehlo.reshape %482 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %484 = stablehlo.broadcast_in_dim %444, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %485 = stablehlo.reshape %484 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %486 = stablehlo.dot_general %483, %485, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %487 = stablehlo.reshape %486 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %488 = stablehlo.transpose %487, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %489 = stablehlo.reshape %488 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %490 = stablehlo.transpose %arg49, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %491 = stablehlo.dot_general %489, %490, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %492 = stablehlo.reshape %491 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %493 = stablehlo.add %407, %492 : tensor<1x7x3072xbf16>
    %494 = stablehlo.convert %arg51 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %495 = stablehlo.broadcast_in_dim %494, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %496 = stablehlo.convert %493 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %497 = stablehlo.power %496, %0 : tensor<1x7x3072xf32>
    %498 = stablehlo.reduce(%497 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %499 = stablehlo.multiply %498, %cst_1 : tensor<1x7xf32>
    %500 = stablehlo.reshape %499 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %501 = stablehlo.add %500, %17 : tensor<1x7x1xf32>
    %502 = stablehlo.rsqrt %501 : tensor<1x7x1xf32>
    %503 = stablehlo.reshape %502 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %504 = stablehlo.broadcast_in_dim %503, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %505 = stablehlo.multiply %496, %504 : tensor<1x7x3072xf32>
    %506 = stablehlo.convert %505 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %507 = stablehlo.convert %506 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %508 = stablehlo.multiply %495, %507 : tensor<1x7x3072xf32>
    %509 = stablehlo.convert %508 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %510 = stablehlo.reshape %509 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %511 = stablehlo.transpose %arg52, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %512 = stablehlo.dot_general %510, %511, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %513 = stablehlo.reshape %512 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %514 = stablehlo.convert %513 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %515 = stablehlo.logistic %513 : tensor<1x7x8192xbf16>
    %516 = stablehlo.convert %515 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %517 = stablehlo.multiply %514, %516 : tensor<1x7x8192xf32>
    %518 = stablehlo.convert %517 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %519 = stablehlo.convert %518 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %520 = stablehlo.transpose %arg48, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %521 = stablehlo.dot_general %510, %520, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %522 = stablehlo.convert %521 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %523 = stablehlo.reshape %522 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %524 = stablehlo.multiply %519, %523 : tensor<1x7x8192xf32>
    %525 = stablehlo.convert %524 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %526 = stablehlo.reshape %525 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %527 = stablehlo.transpose %arg47, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %528 = stablehlo.dot_general %526, %527, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %529 = stablehlo.reshape %528 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %530 = stablehlo.add %493, %529 : tensor<1x7x3072xbf16>
    %531 = stablehlo.convert %530 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %532 = stablehlo.power %531, %0 : tensor<1x7x3072xf32>
    %533 = stablehlo.reduce(%532 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %534 = stablehlo.multiply %533, %cst_1 : tensor<1x7xf32>
    %535 = stablehlo.reshape %534 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %536 = stablehlo.add %535, %17 : tensor<1x7x1xf32>
    %537 = stablehlo.rsqrt %536 : tensor<1x7x1xf32>
    %538 = stablehlo.reshape %537 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %539 = stablehlo.broadcast_in_dim %538, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %540 = stablehlo.multiply %531, %539 : tensor<1x7x3072xf32>
    %541 = stablehlo.convert %540 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %542 = stablehlo.convert %541 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %543 = stablehlo.multiply %447, %542 : tensor<1x7x3072xf32>
    %544 = stablehlo.convert %543 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %545 = stablehlo.reshape %544 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %546 = stablehlo.transpose %arg5, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %547 = stablehlo.dot_general %545, %546, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %548 = stablehlo.reshape %547 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %58, %64, %193, %199, %316, %322, %439, %445, %547, %548 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>
  }
}
module @SyncTensorsGraph.1220 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg2: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg3: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg4: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg5: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg6: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg7: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg8: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg9: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg10: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg11: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg12: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg13: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg14: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg15: tensor<128xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg16: tensor<7x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg17: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg18: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg19: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg20: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg21: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg22: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg23: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg24: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg25: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg26: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg27: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg28: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg29: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg30: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg31: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg32: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg33: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg34: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg35: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg36: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg37: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg38: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg39: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg40: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg41: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg42: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg43: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg44: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg45: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg46: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg47: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg48: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg49: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg50: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg51: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg52: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg53: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>) {
    %c = stablehlo.constant dense<0> : tensor<7xi64>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %1 = stablehlo.compare  LT, %arg0, %c : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %2 = stablehlo.broadcast_in_dim %arg7, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %3 = stablehlo.add %arg0, %2 : tensor<7xi64>
    %4 = stablehlo.select %1, %3, %arg0 : tensor<7xi1>, tensor<7xi64>
    %5 = stablehlo.reshape %4 : (tensor<7xi64>) -> tensor<7x1xi64>
    %6 = stablehlo.convert %arg6 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %7 = stablehlo.broadcast_in_dim %6, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %8 = stablehlo.convert %arg4 : (tensor<1x7xi64>) -> tensor<1x7xui32>
    %9 = stablehlo.reshape %8 : (tensor<1x7xui32>) -> tensor<7xui32>
    %10 = "stablehlo.gather"(%arg5, %9) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %11 = stablehlo.reshape %10 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %12 = stablehlo.convert %11 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %13 = stablehlo.power %12, %0 : tensor<1x7x3072xf32>
    %14 = stablehlo.reduce(%13 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %15 = stablehlo.multiply %14, %cst_1 : tensor<1x7xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %17 = stablehlo.broadcast_in_dim %arg3, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %18 = stablehlo.add %16, %17 : tensor<1x7x1xf32>
    %19 = stablehlo.rsqrt %18 : tensor<1x7x1xf32>
    %20 = stablehlo.reshape %19 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %21 = stablehlo.broadcast_in_dim %20, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %22 = stablehlo.multiply %12, %21 : tensor<1x7x3072xf32>
    %23 = stablehlo.convert %22 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %24 = stablehlo.convert %23 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %25 = stablehlo.multiply %7, %24 : tensor<1x7x3072xf32>
    %26 = stablehlo.convert %25 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %27 = stablehlo.reshape %26 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %28 = stablehlo.transpose %arg2, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %29 = stablehlo.dot_general %27, %28, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %30 = stablehlo.reshape %29 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %31 = stablehlo.transpose %30, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %32 = stablehlo.convert %31 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %33 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x64x1xf32>
    %34 = stablehlo.convert %arg0 : (tensor<7xi64>) -> tensor<7xf32>
    %35 = stablehlo.reshape %34 : (tensor<7xf32>) -> tensor<1x1x7xf32>
    %36 = stablehlo.dot_general %33, %35, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %38 = stablehlo.concatenate %37, %37, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %39 = stablehlo.cosine %38 : tensor<1x7x128xf32>
    %40 = stablehlo.convert %39 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %41 = stablehlo.convert %40 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %42 = stablehlo.broadcast_in_dim %41, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %43 = stablehlo.multiply %32, %42 : tensor<1x8x7x128xf32>
    %44 = stablehlo.convert %43 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %45 = stablehlo.slice %31 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %46 = stablehlo.negate %45 : tensor<1x8x7x64xbf16>
    %47 = stablehlo.slice %31 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %48 = stablehlo.concatenate %46, %47, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %49 = stablehlo.convert %48 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %50 = stablehlo.sine %38 : tensor<1x7x128xf32>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %52 = stablehlo.convert %51 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %53 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %54 = stablehlo.multiply %49, %53 : tensor<1x8x7x128xf32>
    %55 = stablehlo.convert %54 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %56 = stablehlo.add %44, %55 : tensor<1x8x7x128xbf16>
    %57 = "stablehlo.scatter"(%arg8, %5, %56) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %58 = sdy.sharding_constraint %57 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %59 = stablehlo.transpose %arg9, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %60 = stablehlo.dot_general %27, %59, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %61 = stablehlo.reshape %60 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %62 = stablehlo.transpose %61, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %63 = "stablehlo.scatter"(%arg10, %5, %62) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %64 = sdy.sharding_constraint %63 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %65 = stablehlo.convert %arg21 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %67 = stablehlo.transpose %arg18, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %68 = stablehlo.dot_general %27, %67, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %69 = stablehlo.reshape %68 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %70 = stablehlo.transpose %69, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %71 = stablehlo.convert %70 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %72 = stablehlo.broadcast_in_dim %41, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %73 = stablehlo.multiply %71, %72 : tensor<1x24x7x128xf32>
    %74 = stablehlo.convert %73 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %75 = stablehlo.slice %70 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %76 = stablehlo.negate %75 : tensor<1x24x7x64xbf16>
    %77 = stablehlo.slice %70 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %79 = stablehlo.convert %78 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %81 = stablehlo.multiply %79, %80 : tensor<1x24x7x128xf32>
    %82 = stablehlo.convert %81 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %83 = stablehlo.add %74, %82 : tensor<1x24x7x128xbf16>
    %84 = stablehlo.reshape %83 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %85 = stablehlo.broadcast_in_dim %57, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %86 = stablehlo.reshape %85 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %87 = stablehlo.transpose %86, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %88 = stablehlo.reshape %87 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %89 = stablehlo.dot_general %84, %88, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %90 = stablehlo.convert %89 : (tensor<24x7x128xbf16>) -> tensor<24x7x128xf32>
    %91 = stablehlo.reshape %90 : (tensor<24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %92 = stablehlo.broadcast_in_dim %arg17, dims = [] : (tensor<f32>) -> tensor<1x24x7x128xf32>
    %93 = stablehlo.multiply %91, %92 : tensor<1x24x7x128xf32>
    %94 = stablehlo.convert %93 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %95 = stablehlo.convert %arg16 : (tensor<7x128xbf16>) -> tensor<7x128xf32>
    %96 = stablehlo.broadcast_in_dim %arg15, dims = [1] : (tensor<128xi64>) -> tensor<7x128xi64>
    %97 = stablehlo.broadcast_in_dim %arg0, dims = [0] : (tensor<7xi64>) -> tensor<7x128xi64>
    %98 = stablehlo.compare  GT, %96, %97 : (tensor<7x128xi64>, tensor<7x128xi64>) -> tensor<7x128xi1>
    %99 = stablehlo.convert %98 : (tensor<7x128xi1>) -> tensor<7x128xf32>
    %100 = stablehlo.multiply %95, %99 : tensor<7x128xf32>
    %101 = stablehlo.convert %100 : (tensor<7x128xf32>) -> tensor<7x128xbf16>
    %102 = stablehlo.reshape %101 : (tensor<7x128xbf16>) -> tensor<1x7x128xbf16>
    %103 = stablehlo.broadcast_in_dim %102, dims = [0, 2, 3] : (tensor<1x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %104 = stablehlo.add %94, %103 : tensor<1x24x7x128xbf16>
    %105 = stablehlo.convert %104 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %106 = stablehlo.reduce(%105 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %107 = stablehlo.broadcast_in_dim %106, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %108 = stablehlo.subtract %105, %107 : tensor<1x24x7x128xf32>
    %109 = stablehlo.exponential %108 : tensor<1x24x7x128xf32>
    %110 = stablehlo.reduce(%109 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %111 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %112 = stablehlo.divide %109, %111 : tensor<1x24x7x128xf32>
    %113 = stablehlo.convert %112 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %114 = stablehlo.reshape %113 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %115 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %116 = stablehlo.reshape %115 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %117 = stablehlo.dot_general %114, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %118 = stablehlo.reshape %117 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %119 = stablehlo.transpose %118, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %120 = stablehlo.reshape %119 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %121 = stablehlo.transpose %arg14, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %122 = stablehlo.dot_general %120, %121, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %123 = stablehlo.reshape %122 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %124 = stablehlo.add %11, %123 : tensor<1x7x3072xbf16>
    %125 = stablehlo.convert %arg19 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %126 = stablehlo.broadcast_in_dim %125, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %127 = stablehlo.convert %124 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %128 = stablehlo.power %127, %0 : tensor<1x7x3072xf32>
    %129 = stablehlo.reduce(%128 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %130 = stablehlo.multiply %129, %cst_1 : tensor<1x7xf32>
    %131 = stablehlo.reshape %130 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %132 = stablehlo.add %131, %17 : tensor<1x7x1xf32>
    %133 = stablehlo.rsqrt %132 : tensor<1x7x1xf32>
    %134 = stablehlo.reshape %133 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %136 = stablehlo.multiply %127, %135 : tensor<1x7x3072xf32>
    %137 = stablehlo.convert %136 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %138 = stablehlo.convert %137 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %139 = stablehlo.multiply %126, %138 : tensor<1x7x3072xf32>
    %140 = stablehlo.convert %139 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %141 = stablehlo.reshape %140 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %142 = stablehlo.transpose %arg20, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %143 = stablehlo.dot_general %141, %142, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %144 = stablehlo.reshape %143 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %145 = stablehlo.convert %144 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %146 = stablehlo.logistic %144 : tensor<1x7x8192xbf16>
    %147 = stablehlo.convert %146 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %148 = stablehlo.multiply %145, %147 : tensor<1x7x8192xf32>
    %149 = stablehlo.convert %148 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %150 = stablehlo.convert %149 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %151 = stablehlo.transpose %arg13, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %152 = stablehlo.dot_general %141, %151, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %153 = stablehlo.convert %152 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %154 = stablehlo.reshape %153 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %155 = stablehlo.multiply %150, %154 : tensor<1x7x8192xf32>
    %156 = stablehlo.convert %155 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %157 = stablehlo.reshape %156 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %158 = stablehlo.transpose %arg12, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %159 = stablehlo.dot_general %157, %158, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %160 = stablehlo.reshape %159 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %161 = stablehlo.add %124, %160 : tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.power %162, %0 : tensor<1x7x3072xf32>
    %164 = stablehlo.reduce(%163 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %165 = stablehlo.multiply %164, %cst_1 : tensor<1x7xf32>
    %166 = stablehlo.reshape %165 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %167 = stablehlo.add %166, %17 : tensor<1x7x1xf32>
    %168 = stablehlo.rsqrt %167 : tensor<1x7x1xf32>
    %169 = stablehlo.reshape %168 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %170 = stablehlo.broadcast_in_dim %169, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %171 = stablehlo.multiply %162, %170 : tensor<1x7x3072xf32>
    %172 = stablehlo.convert %171 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %173 = stablehlo.convert %172 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %174 = stablehlo.multiply %66, %173 : tensor<1x7x3072xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %176 = stablehlo.reshape %175 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %177 = stablehlo.transpose %arg11, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %178 = stablehlo.dot_general %176, %177, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %179 = stablehlo.reshape %178 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %180 = stablehlo.transpose %179, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %181 = stablehlo.convert %180 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %182 = stablehlo.multiply %181, %42 : tensor<1x8x7x128xf32>
    %183 = stablehlo.convert %182 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %184 = stablehlo.slice %180 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %185 = stablehlo.negate %184 : tensor<1x8x7x64xbf16>
    %186 = stablehlo.slice %180 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %187 = stablehlo.concatenate %185, %186, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %188 = stablehlo.convert %187 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %189 = stablehlo.multiply %188, %53 : tensor<1x8x7x128xf32>
    %190 = stablehlo.convert %189 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %191 = stablehlo.add %183, %190 : tensor<1x8x7x128xbf16>
    %192 = "stablehlo.scatter"(%arg22, %5, %191) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %193 = sdy.sharding_constraint %192 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %194 = stablehlo.transpose %arg23, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %195 = stablehlo.dot_general %176, %194, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %196 = stablehlo.reshape %195 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %197 = stablehlo.transpose %196, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %198 = "stablehlo.scatter"(%arg24, %5, %197) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %199 = sdy.sharding_constraint %198 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %200 = stablehlo.convert %arg32 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %201 = stablehlo.broadcast_in_dim %200, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %202 = stablehlo.transpose %arg29, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %203 = stablehlo.dot_general %176, %202, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %204 = stablehlo.reshape %203 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %205 = stablehlo.transpose %204, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %206 = stablehlo.convert %205 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %207 = stablehlo.multiply %206, %72 : tensor<1x24x7x128xf32>
    %208 = stablehlo.convert %207 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %209 = stablehlo.slice %205 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %210 = stablehlo.negate %209 : tensor<1x24x7x64xbf16>
    %211 = stablehlo.slice %205 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %212 = stablehlo.concatenate %210, %211, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %213 = stablehlo.convert %212 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %214 = stablehlo.multiply %213, %80 : tensor<1x24x7x128xf32>
    %215 = stablehlo.convert %214 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %216 = stablehlo.add %208, %215 : tensor<1x24x7x128xbf16>
    %217 = stablehlo.reshape %216 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %218 = stablehlo.broadcast_in_dim %192, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %219 = stablehlo.reshape %218 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %220 = stablehlo.transpose %219, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %221 = stablehlo.reshape %220 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %222 = stablehlo.dot_general %217, %221, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %223 = stablehlo.convert %222 : (tensor<24x7x128xbf16>) -> tensor<24x7x128xf32>
    %224 = stablehlo.reshape %223 : (tensor<24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %225 = stablehlo.multiply %224, %92 : tensor<1x24x7x128xf32>
    %226 = stablehlo.convert %225 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %227 = stablehlo.add %226, %103 : tensor<1x24x7x128xbf16>
    %228 = stablehlo.convert %227 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %229 = stablehlo.reduce(%228 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %230 = stablehlo.broadcast_in_dim %229, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %231 = stablehlo.subtract %228, %230 : tensor<1x24x7x128xf32>
    %232 = stablehlo.exponential %231 : tensor<1x24x7x128xf32>
    %233 = stablehlo.reduce(%232 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %234 = stablehlo.broadcast_in_dim %233, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %235 = stablehlo.divide %232, %234 : tensor<1x24x7x128xf32>
    %236 = stablehlo.convert %235 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %237 = stablehlo.reshape %236 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %238 = stablehlo.broadcast_in_dim %198, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %239 = stablehlo.reshape %238 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %240 = stablehlo.dot_general %237, %239, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %241 = stablehlo.reshape %240 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %242 = stablehlo.transpose %241, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %243 = stablehlo.reshape %242 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %244 = stablehlo.transpose %arg28, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %245 = stablehlo.dot_general %243, %244, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %246 = stablehlo.reshape %245 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %247 = stablehlo.add %161, %246 : tensor<1x7x3072xbf16>
    %248 = stablehlo.convert %arg30 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %249 = stablehlo.broadcast_in_dim %248, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %250 = stablehlo.convert %247 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %251 = stablehlo.power %250, %0 : tensor<1x7x3072xf32>
    %252 = stablehlo.reduce(%251 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %253 = stablehlo.multiply %252, %cst_1 : tensor<1x7xf32>
    %254 = stablehlo.reshape %253 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %255 = stablehlo.add %254, %17 : tensor<1x7x1xf32>
    %256 = stablehlo.rsqrt %255 : tensor<1x7x1xf32>
    %257 = stablehlo.reshape %256 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %258 = stablehlo.broadcast_in_dim %257, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %259 = stablehlo.multiply %250, %258 : tensor<1x7x3072xf32>
    %260 = stablehlo.convert %259 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %261 = stablehlo.convert %260 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %262 = stablehlo.multiply %249, %261 : tensor<1x7x3072xf32>
    %263 = stablehlo.convert %262 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %264 = stablehlo.reshape %263 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %265 = stablehlo.transpose %arg31, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %266 = stablehlo.dot_general %264, %265, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %267 = stablehlo.reshape %266 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %268 = stablehlo.convert %267 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %269 = stablehlo.logistic %267 : tensor<1x7x8192xbf16>
    %270 = stablehlo.convert %269 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %271 = stablehlo.multiply %268, %270 : tensor<1x7x8192xf32>
    %272 = stablehlo.convert %271 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %273 = stablehlo.convert %272 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %274 = stablehlo.transpose %arg27, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %275 = stablehlo.dot_general %264, %274, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %276 = stablehlo.convert %275 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %277 = stablehlo.reshape %276 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %278 = stablehlo.multiply %273, %277 : tensor<1x7x8192xf32>
    %279 = stablehlo.convert %278 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %280 = stablehlo.reshape %279 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %281 = stablehlo.transpose %arg26, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %282 = stablehlo.dot_general %280, %281, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %283 = stablehlo.reshape %282 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %284 = stablehlo.add %247, %283 : tensor<1x7x3072xbf16>
    %285 = stablehlo.convert %284 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %286 = stablehlo.power %285, %0 : tensor<1x7x3072xf32>
    %287 = stablehlo.reduce(%286 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %288 = stablehlo.multiply %287, %cst_1 : tensor<1x7xf32>
    %289 = stablehlo.reshape %288 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %290 = stablehlo.add %289, %17 : tensor<1x7x1xf32>
    %291 = stablehlo.rsqrt %290 : tensor<1x7x1xf32>
    %292 = stablehlo.reshape %291 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %293 = stablehlo.broadcast_in_dim %292, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %294 = stablehlo.multiply %285, %293 : tensor<1x7x3072xf32>
    %295 = stablehlo.convert %294 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %296 = stablehlo.convert %295 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %297 = stablehlo.multiply %201, %296 : tensor<1x7x3072xf32>
    %298 = stablehlo.convert %297 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %299 = stablehlo.reshape %298 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %300 = stablehlo.transpose %arg25, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %301 = stablehlo.dot_general %299, %300, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %302 = stablehlo.reshape %301 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %303 = stablehlo.transpose %302, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %304 = stablehlo.convert %303 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %305 = stablehlo.multiply %304, %42 : tensor<1x8x7x128xf32>
    %306 = stablehlo.convert %305 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %307 = stablehlo.slice %303 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %308 = stablehlo.negate %307 : tensor<1x8x7x64xbf16>
    %309 = stablehlo.slice %303 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %310 = stablehlo.concatenate %308, %309, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %311 = stablehlo.convert %310 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %312 = stablehlo.multiply %311, %53 : tensor<1x8x7x128xf32>
    %313 = stablehlo.convert %312 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %314 = stablehlo.add %306, %313 : tensor<1x8x7x128xbf16>
    %315 = "stablehlo.scatter"(%arg33, %5, %314) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %316 = sdy.sharding_constraint %315 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %317 = stablehlo.transpose %arg34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %318 = stablehlo.dot_general %299, %317, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %319 = stablehlo.reshape %318 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %320 = stablehlo.transpose %319, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %321 = "stablehlo.scatter"(%arg35, %5, %320) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %322 = sdy.sharding_constraint %321 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %323 = stablehlo.convert %arg43 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %324 = stablehlo.broadcast_in_dim %323, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %325 = stablehlo.transpose %arg40, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %326 = stablehlo.dot_general %299, %325, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %327 = stablehlo.reshape %326 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %328 = stablehlo.transpose %327, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %329 = stablehlo.convert %328 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %330 = stablehlo.multiply %329, %72 : tensor<1x24x7x128xf32>
    %331 = stablehlo.convert %330 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %332 = stablehlo.slice %328 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %333 = stablehlo.negate %332 : tensor<1x24x7x64xbf16>
    %334 = stablehlo.slice %328 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %335 = stablehlo.concatenate %333, %334, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %336 = stablehlo.convert %335 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %337 = stablehlo.multiply %336, %80 : tensor<1x24x7x128xf32>
    %338 = stablehlo.convert %337 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %339 = stablehlo.add %331, %338 : tensor<1x24x7x128xbf16>
    %340 = stablehlo.reshape %339 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %341 = stablehlo.broadcast_in_dim %315, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %342 = stablehlo.reshape %341 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %343 = stablehlo.transpose %342, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %344 = stablehlo.reshape %343 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %345 = stablehlo.dot_general %340, %344, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %346 = stablehlo.convert %345 : (tensor<24x7x128xbf16>) -> tensor<24x7x128xf32>
    %347 = stablehlo.reshape %346 : (tensor<24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %348 = stablehlo.multiply %347, %92 : tensor<1x24x7x128xf32>
    %349 = stablehlo.convert %348 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %350 = stablehlo.add %349, %103 : tensor<1x24x7x128xbf16>
    %351 = stablehlo.convert %350 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %352 = stablehlo.reduce(%351 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %353 = stablehlo.broadcast_in_dim %352, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %354 = stablehlo.subtract %351, %353 : tensor<1x24x7x128xf32>
    %355 = stablehlo.exponential %354 : tensor<1x24x7x128xf32>
    %356 = stablehlo.reduce(%355 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %357 = stablehlo.broadcast_in_dim %356, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %358 = stablehlo.divide %355, %357 : tensor<1x24x7x128xf32>
    %359 = stablehlo.convert %358 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %360 = stablehlo.reshape %359 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %361 = stablehlo.broadcast_in_dim %321, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %362 = stablehlo.reshape %361 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %363 = stablehlo.dot_general %360, %362, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %364 = stablehlo.reshape %363 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %365 = stablehlo.transpose %364, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %366 = stablehlo.reshape %365 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %367 = stablehlo.transpose %arg39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %368 = stablehlo.dot_general %366, %367, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %369 = stablehlo.reshape %368 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %370 = stablehlo.add %284, %369 : tensor<1x7x3072xbf16>
    %371 = stablehlo.convert %arg41 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %372 = stablehlo.broadcast_in_dim %371, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %373 = stablehlo.convert %370 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %374 = stablehlo.power %373, %0 : tensor<1x7x3072xf32>
    %375 = stablehlo.reduce(%374 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %376 = stablehlo.multiply %375, %cst_1 : tensor<1x7xf32>
    %377 = stablehlo.reshape %376 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %378 = stablehlo.add %377, %17 : tensor<1x7x1xf32>
    %379 = stablehlo.rsqrt %378 : tensor<1x7x1xf32>
    %380 = stablehlo.reshape %379 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %381 = stablehlo.broadcast_in_dim %380, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %382 = stablehlo.multiply %373, %381 : tensor<1x7x3072xf32>
    %383 = stablehlo.convert %382 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %384 = stablehlo.convert %383 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %385 = stablehlo.multiply %372, %384 : tensor<1x7x3072xf32>
    %386 = stablehlo.convert %385 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %387 = stablehlo.reshape %386 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %388 = stablehlo.transpose %arg42, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %389 = stablehlo.dot_general %387, %388, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %390 = stablehlo.reshape %389 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %391 = stablehlo.convert %390 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %392 = stablehlo.logistic %390 : tensor<1x7x8192xbf16>
    %393 = stablehlo.convert %392 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %394 = stablehlo.multiply %391, %393 : tensor<1x7x8192xf32>
    %395 = stablehlo.convert %394 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %396 = stablehlo.convert %395 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %397 = stablehlo.transpose %arg38, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %398 = stablehlo.dot_general %387, %397, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %399 = stablehlo.convert %398 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %400 = stablehlo.reshape %399 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %401 = stablehlo.multiply %396, %400 : tensor<1x7x8192xf32>
    %402 = stablehlo.convert %401 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %403 = stablehlo.reshape %402 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %404 = stablehlo.transpose %arg37, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %405 = stablehlo.dot_general %403, %404, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %406 = stablehlo.reshape %405 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %407 = stablehlo.add %370, %406 : tensor<1x7x3072xbf16>
    %408 = stablehlo.convert %407 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %409 = stablehlo.power %408, %0 : tensor<1x7x3072xf32>
    %410 = stablehlo.reduce(%409 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %411 = stablehlo.multiply %410, %cst_1 : tensor<1x7xf32>
    %412 = stablehlo.reshape %411 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %413 = stablehlo.add %412, %17 : tensor<1x7x1xf32>
    %414 = stablehlo.rsqrt %413 : tensor<1x7x1xf32>
    %415 = stablehlo.reshape %414 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %416 = stablehlo.broadcast_in_dim %415, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %417 = stablehlo.multiply %408, %416 : tensor<1x7x3072xf32>
    %418 = stablehlo.convert %417 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %419 = stablehlo.convert %418 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %420 = stablehlo.multiply %324, %419 : tensor<1x7x3072xf32>
    %421 = stablehlo.convert %420 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %422 = stablehlo.reshape %421 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %423 = stablehlo.transpose %arg36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %424 = stablehlo.dot_general %422, %423, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %425 = stablehlo.reshape %424 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %426 = stablehlo.transpose %425, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %427 = stablehlo.convert %426 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %428 = stablehlo.multiply %427, %42 : tensor<1x8x7x128xf32>
    %429 = stablehlo.convert %428 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %430 = stablehlo.slice %426 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %431 = stablehlo.negate %430 : tensor<1x8x7x64xbf16>
    %432 = stablehlo.slice %426 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %433 = stablehlo.concatenate %431, %432, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %434 = stablehlo.convert %433 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %435 = stablehlo.multiply %434, %53 : tensor<1x8x7x128xf32>
    %436 = stablehlo.convert %435 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %437 = stablehlo.add %429, %436 : tensor<1x8x7x128xbf16>
    %438 = "stablehlo.scatter"(%arg44, %5, %437) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %439 = sdy.sharding_constraint %438 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %440 = stablehlo.transpose %arg45, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %441 = stablehlo.dot_general %422, %440, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %442 = stablehlo.reshape %441 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %443 = stablehlo.transpose %442, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %444 = "stablehlo.scatter"(%arg46, %5, %443) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %445 = sdy.sharding_constraint %444 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %446 = stablehlo.convert %arg53 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %447 = stablehlo.broadcast_in_dim %446, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %448 = stablehlo.transpose %arg50, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %449 = stablehlo.dot_general %422, %448, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %450 = stablehlo.reshape %449 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %451 = stablehlo.transpose %450, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %452 = stablehlo.convert %451 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %453 = stablehlo.multiply %452, %72 : tensor<1x24x7x128xf32>
    %454 = stablehlo.convert %453 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %455 = stablehlo.slice %451 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %456 = stablehlo.negate %455 : tensor<1x24x7x64xbf16>
    %457 = stablehlo.slice %451 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %458 = stablehlo.concatenate %456, %457, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %459 = stablehlo.convert %458 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %460 = stablehlo.multiply %459, %80 : tensor<1x24x7x128xf32>
    %461 = stablehlo.convert %460 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %462 = stablehlo.add %454, %461 : tensor<1x24x7x128xbf16>
    %463 = stablehlo.reshape %462 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %464 = stablehlo.broadcast_in_dim %438, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %465 = stablehlo.reshape %464 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %466 = stablehlo.transpose %465, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %467 = stablehlo.reshape %466 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %468 = stablehlo.dot_general %463, %467, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %469 = stablehlo.convert %468 : (tensor<24x7x128xbf16>) -> tensor<24x7x128xf32>
    %470 = stablehlo.reshape %469 : (tensor<24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %471 = stablehlo.multiply %470, %92 : tensor<1x24x7x128xf32>
    %472 = stablehlo.convert %471 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %473 = stablehlo.add %472, %103 : tensor<1x24x7x128xbf16>
    %474 = stablehlo.convert %473 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %475 = stablehlo.reduce(%474 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %476 = stablehlo.broadcast_in_dim %475, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %477 = stablehlo.subtract %474, %476 : tensor<1x24x7x128xf32>
    %478 = stablehlo.exponential %477 : tensor<1x24x7x128xf32>
    %479 = stablehlo.reduce(%478 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %480 = stablehlo.broadcast_in_dim %479, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %481 = stablehlo.divide %478, %480 : tensor<1x24x7x128xf32>
    %482 = stablehlo.convert %481 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %483 = stablehlo.reshape %482 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %484 = stablehlo.broadcast_in_dim %444, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %485 = stablehlo.reshape %484 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %486 = stablehlo.dot_general %483, %485, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %487 = stablehlo.reshape %486 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %488 = stablehlo.transpose %487, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %489 = stablehlo.reshape %488 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %490 = stablehlo.transpose %arg49, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %491 = stablehlo.dot_general %489, %490, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %492 = stablehlo.reshape %491 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %493 = stablehlo.add %407, %492 : tensor<1x7x3072xbf16>
    %494 = stablehlo.convert %arg51 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %495 = stablehlo.broadcast_in_dim %494, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %496 = stablehlo.convert %493 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %497 = stablehlo.power %496, %0 : tensor<1x7x3072xf32>
    %498 = stablehlo.reduce(%497 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %499 = stablehlo.multiply %498, %cst_1 : tensor<1x7xf32>
    %500 = stablehlo.reshape %499 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %501 = stablehlo.add %500, %17 : tensor<1x7x1xf32>
    %502 = stablehlo.rsqrt %501 : tensor<1x7x1xf32>
    %503 = stablehlo.reshape %502 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %504 = stablehlo.broadcast_in_dim %503, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %505 = stablehlo.multiply %496, %504 : tensor<1x7x3072xf32>
    %506 = stablehlo.convert %505 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %507 = stablehlo.convert %506 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %508 = stablehlo.multiply %495, %507 : tensor<1x7x3072xf32>
    %509 = stablehlo.convert %508 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %510 = stablehlo.reshape %509 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %511 = stablehlo.transpose %arg52, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %512 = stablehlo.dot_general %510, %511, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %513 = stablehlo.reshape %512 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %514 = stablehlo.convert %513 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %515 = stablehlo.logistic %513 : tensor<1x7x8192xbf16>
    %516 = stablehlo.convert %515 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %517 = stablehlo.multiply %514, %516 : tensor<1x7x8192xf32>
    %518 = stablehlo.convert %517 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %519 = stablehlo.convert %518 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %520 = stablehlo.transpose %arg48, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %521 = stablehlo.dot_general %510, %520, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %522 = stablehlo.convert %521 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %523 = stablehlo.reshape %522 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %524 = stablehlo.multiply %519, %523 : tensor<1x7x8192xf32>
    %525 = stablehlo.convert %524 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %526 = stablehlo.reshape %525 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %527 = stablehlo.transpose %arg47, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %528 = stablehlo.dot_general %526, %527, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %529 = stablehlo.reshape %528 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %530 = stablehlo.add %493, %529 : tensor<1x7x3072xbf16>
    %531 = stablehlo.convert %530 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %532 = stablehlo.power %531, %0 : tensor<1x7x3072xf32>
    %533 = stablehlo.reduce(%532 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %534 = stablehlo.multiply %533, %cst_1 : tensor<1x7xf32>
    %535 = stablehlo.reshape %534 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %536 = stablehlo.add %535, %17 : tensor<1x7x1xf32>
    %537 = stablehlo.rsqrt %536 : tensor<1x7x1xf32>
    %538 = stablehlo.reshape %537 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %539 = stablehlo.broadcast_in_dim %538, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %540 = stablehlo.multiply %531, %539 : tensor<1x7x3072xf32>
    %541 = stablehlo.convert %540 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %542 = stablehlo.convert %541 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %543 = stablehlo.multiply %447, %542 : tensor<1x7x3072xf32>
    %544 = stablehlo.convert %543 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %545 = stablehlo.reshape %544 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %546 = stablehlo.transpose %arg5, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %547 = stablehlo.dot_general %545, %546, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %548 = stablehlo.reshape %547 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %58, %64, %193, %199, %316, %322, %439, %445, %547, %548 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>
  }
}
module @SyncTensorsGraph.1220 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<7xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<64xf32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg3: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg4: tensor<1x7xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg5: tensor<128256x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg6: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg7: tensor<i64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg8: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg9: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg10: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg11: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg12: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg13: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg14: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg15: tensor<128xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg16: tensor<7x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg17: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg18: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg19: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg20: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg21: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg22: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg23: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg24: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg25: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg26: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg27: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg28: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg29: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg30: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg31: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg32: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg33: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg34: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg35: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg36: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg37: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg38: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg39: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg40: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg41: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg42: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg43: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg44: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg45: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg46: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg47: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg48: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg49: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg50: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg51: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg52: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg53: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:10 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18, %arg19, %arg20, %arg21, %arg22, %arg23, %arg24, %arg25, %arg26, %arg27, %arg28, %arg29, %arg30, %arg31, %arg32, %arg33, %arg34, %arg35, %arg36, %arg37, %arg38, %arg39, %arg40, %arg41, %arg42, %arg43, %arg44, %arg45, %arg46, %arg47, %arg48, %arg49, %arg50, %arg51, %arg52, %arg53) in_shardings=[<@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>, <@mesh, []>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{}, {}, {"_axis_0"}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg54: tensor<7xi64>, %arg55: tensor<64xf32>, %arg56: tensor<512x3072xbf16>, %arg57: tensor<f32>, %arg58: tensor<1x7xi64>, %arg59: tensor<64128x3072xbf16>, %arg60: tensor<3072xbf16>, %arg61: tensor<i64>, %arg62: tensor<1x4x128x128xbf16>, %arg63: tensor<512x3072xbf16>, %arg64: tensor<1x4x128x128xbf16>, %arg65: tensor<512x3072xbf16>, %arg66: tensor<3072x4096xbf16>, %arg67: tensor<4096x3072xbf16>, %arg68: tensor<3072x1536xbf16>, %arg69: tensor<128xi64>, %arg70: tensor<7x128xbf16>, %arg71: tensor<f32>, %arg72: tensor<1536x3072xbf16>, %arg73: tensor<3072xbf16>, %arg74: tensor<4096x3072xbf16>, %arg75: tensor<3072xbf16>, %arg76: tensor<1x4x128x128xbf16>, %arg77: tensor<512x3072xbf16>, %arg78: tensor<1x4x128x128xbf16>, %arg79: tensor<512x3072xbf16>, %arg80: tensor<3072x4096xbf16>, %arg81: tensor<4096x3072xbf16>, %arg82: tensor<3072x1536xbf16>, %arg83: tensor<1536x3072xbf16>, %arg84: tensor<3072xbf16>, %arg85: tensor<4096x3072xbf16>, %arg86: tensor<3072xbf16>, %arg87: tensor<1x4x128x128xbf16>, %arg88: tensor<512x3072xbf16>, %arg89: tensor<1x4x128x128xbf16>, %arg90: tensor<512x3072xbf16>, %arg91: tensor<3072x4096xbf16>, %arg92: tensor<4096x3072xbf16>, %arg93: tensor<3072x1536xbf16>, %arg94: tensor<1536x3072xbf16>, %arg95: tensor<3072xbf16>, %arg96: tensor<4096x3072xbf16>, %arg97: tensor<3072xbf16>, %arg98: tensor<1x4x128x128xbf16>, %arg99: tensor<512x3072xbf16>, %arg100: tensor<1x4x128x128xbf16>, %arg101: tensor<3072x4096xbf16>, %arg102: tensor<4096x3072xbf16>, %arg103: tensor<3072x1536xbf16>, %arg104: tensor<1536x3072xbf16>, %arg105: tensor<3072xbf16>, %arg106: tensor<4096x3072xbf16>, %arg107: tensor<3072xbf16>) {
      %c = stablehlo.constant dense<0> : tensor<7xi64>
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
      %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %1 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
      %2 = stablehlo.compare  LT, %arg54, %c : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
      %3 = stablehlo.broadcast_in_dim %arg61, dims = [] : (tensor<i64>) -> tensor<7xi64>
      %4 = stablehlo.add %arg54, %3 : tensor<7xi64>
      %5 = stablehlo.select %2, %4, %arg54 : tensor<7xi1>, tensor<7xi64>
      %6 = stablehlo.reshape %5 : (tensor<7xi64>) -> tensor<7x1xi64>
      %7 = stablehlo.convert %arg60 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %8 = stablehlo.broadcast_in_dim %7, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %9 = stablehlo.convert %arg58 : (tensor<1x7xi64>) -> tensor<1x7xui32>
      %10 = stablehlo.reshape %9 : (tensor<1x7xui32>) -> tensor<7xui32>
      %11 = "stablehlo.gather"(%arg59, %10) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<64128x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
      %12 = "stablehlo.all_reduce"(%11) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %551 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %551 : tensor<bf16>
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %14 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %15 = stablehlo.power %14, %1 : tensor<1x7x3072xf32>
      %16 = stablehlo.reduce(%15 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %17 = stablehlo.multiply %16, %cst_1 : tensor<1x7xf32>
      %18 = stablehlo.reshape %17 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %19 = stablehlo.broadcast_in_dim %arg57, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
      %20 = stablehlo.add %18, %19 : tensor<1x7x1xf32>
      %21 = stablehlo.rsqrt %20 : tensor<1x7x1xf32>
      %22 = stablehlo.reshape %21 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %23 = stablehlo.broadcast_in_dim %22, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %24 = stablehlo.multiply %14, %23 : tensor<1x7x3072xf32>
      %25 = stablehlo.convert %24 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %26 = stablehlo.convert %25 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %27 = stablehlo.multiply %8, %26 : tensor<1x7x3072xf32>
      %28 = stablehlo.convert %27 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %29 = stablehlo.reshape %28 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %30 = stablehlo.transpose %arg56, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %31 = stablehlo.dot_general %29, %30, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
      %32 = stablehlo.reshape %31 : (tensor<7x512xbf16>) -> tensor<1x7x4x128xbf16>
      %33 = stablehlo.transpose %32, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x4x128xbf16>) -> tensor<1x4x7x128xbf16>
      %34 = stablehlo.convert %33 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32>
      %35 = stablehlo.reshape %arg55 : (tensor<64xf32>) -> tensor<1x64x1xf32>
      %36 = stablehlo.convert %arg54 : (tensor<7xi64>) -> tensor<7xf32>
      %37 = stablehlo.reshape %36 : (tensor<7xf32>) -> tensor<1x1x7xf32>
      %38 = stablehlo.dot_general %35, %37, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
      %39 = stablehlo.transpose %38, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
      %40 = stablehlo.concatenate %39, %39, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
      %41 = stablehlo.cosine %40 : tensor<1x7x128xf32>
      %42 = stablehlo.convert %41 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
      %43 = stablehlo.convert %42 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
      %44 = stablehlo.broadcast_in_dim %43, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x4x7x128xf32>
      %45 = stablehlo.multiply %34, %44 : tensor<1x4x7x128xf32>
      %46 = stablehlo.convert %45 : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16>
      %47 = stablehlo.slice %33 [0:1, 0:4, 0:7, 64:128] : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16>
      %48 = stablehlo.negate %47 : tensor<1x4x7x64xbf16>
      %49 = stablehlo.slice %33 [0:1, 0:4, 0:7, 0:64] : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16>
      %50 = stablehlo.concatenate %48, %49, dim = 3 : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x128xbf16>
      %51 = stablehlo.convert %50 : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32>
      %52 = stablehlo.sine %40 : tensor<1x7x128xf32>
      %53 = stablehlo.convert %52 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
      %54 = stablehlo.convert %53 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
      %55 = stablehlo.broadcast_in_dim %54, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x4x7x128xf32>
      %56 = stablehlo.multiply %51, %55 : tensor<1x4x7x128xf32>
      %57 = stablehlo.convert %56 : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16>
      %58 = stablehlo.add %46, %57 : tensor<1x4x7x128xbf16>
      %59 = "stablehlo.scatter"(%arg62, %6, %58) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>) -> tensor<1x4x128x128xbf16>
      %60 = stablehlo.transpose %arg63, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %61 = stablehlo.dot_general %29, %60, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
      %62 = stablehlo.reshape %61 : (tensor<7x512xbf16>) -> tensor<1x7x4x128xbf16>
      %63 = stablehlo.transpose %62, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x4x128xbf16>) -> tensor<1x4x7x128xbf16>
      %64 = "stablehlo.scatter"(%arg64, %6, %63) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>) -> tensor<1x4x128x128xbf16>
      %65 = stablehlo.convert %arg75 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %67 = stablehlo.transpose %arg72, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %68 = stablehlo.dot_general %29, %67, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<7x1536xbf16>
      %69 = stablehlo.reshape %68 : (tensor<7x1536xbf16>) -> tensor<1x7x12x128xbf16>
      %70 = stablehlo.transpose %69, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x12x128xbf16>) -> tensor<1x12x7x128xbf16>
      %71 = stablehlo.convert %70 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %72 = stablehlo.broadcast_in_dim %43, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x12x7x128xf32>
      %73 = stablehlo.multiply %71, %72 : tensor<1x12x7x128xf32>
      %74 = stablehlo.convert %73 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %75 = stablehlo.slice %70 [0:1, 0:12, 0:7, 64:128] : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16>
      %76 = stablehlo.negate %75 : tensor<1x12x7x64xbf16>
      %77 = stablehlo.slice %70 [0:1, 0:12, 0:7, 0:64] : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16>
      %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x128xbf16>
      %79 = stablehlo.convert %78 : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %80 = stablehlo.broadcast_in_dim %54, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x12x7x128xf32>
      %81 = stablehlo.multiply %79, %80 : tensor<1x12x7x128xf32>
      %82 = stablehlo.convert %81 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %83 = stablehlo.add %74, %82 : tensor<1x12x7x128xbf16>
      %84 = stablehlo.reshape %83 : (tensor<1x12x7x128xbf16>) -> tensor<12x7x128xbf16>
      %85 = stablehlo.broadcast_in_dim %59, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %86 = stablehlo.reshape %85 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %87 = stablehlo.transpose %86, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %88 = stablehlo.reshape %87 : (tensor<1x12x128x128xbf16>) -> tensor<12x128x128xbf16>
      %89 = stablehlo.dot_general %84, %88, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
      %90 = stablehlo.convert %89 : (tensor<12x7x128xbf16>) -> tensor<12x7x128xf32>
      %91 = stablehlo.reshape %90 : (tensor<12x7x128xf32>) -> tensor<1x12x7x128xf32>
      %92 = stablehlo.broadcast_in_dim %arg71, dims = [] : (tensor<f32>) -> tensor<1x12x7x128xf32>
      %93 = stablehlo.multiply %91, %92 : tensor<1x12x7x128xf32>
      %94 = stablehlo.convert %93 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %95 = stablehlo.convert %arg70 : (tensor<7x128xbf16>) -> tensor<7x128xf32>
      %96 = stablehlo.broadcast_in_dim %arg69, dims = [1] : (tensor<128xi64>) -> tensor<7x128xi64>
      %97 = stablehlo.broadcast_in_dim %arg54, dims = [0] : (tensor<7xi64>) -> tensor<7x128xi64>
      %98 = stablehlo.compare  GT, %96, %97 : (tensor<7x128xi64>, tensor<7x128xi64>) -> tensor<7x128xi1>
      %99 = stablehlo.convert %98 : (tensor<7x128xi1>) -> tensor<7x128xf32>
      %100 = stablehlo.multiply %95, %99 : tensor<7x128xf32>
      %101 = stablehlo.convert %100 : (tensor<7x128xf32>) -> tensor<7x128xbf16>
      %102 = stablehlo.reshape %101 : (tensor<7x128xbf16>) -> tensor<1x7x128xbf16>
      %103 = stablehlo.broadcast_in_dim %102, dims = [0, 2, 3] : (tensor<1x7x128xbf16>) -> tensor<1x12x7x128xbf16>
      %104 = stablehlo.add %94, %103 : tensor<1x12x7x128xbf16>
      %105 = stablehlo.convert %104 : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %106 = stablehlo.reduce(%105 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x7x128xf32>, tensor<f32>) -> tensor<1x12x7xf32>
      %107 = stablehlo.broadcast_in_dim %106, dims = [0, 1, 2] : (tensor<1x12x7xf32>) -> tensor<1x12x7x128xf32>
      %108 = stablehlo.subtract %105, %107 : tensor<1x12x7x128xf32>
      %109 = stablehlo.exponential %108 : tensor<1x12x7x128xf32>
      %110 = stablehlo.reduce(%109 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x7x128xf32>, tensor<f32>) -> tensor<1x12x7xf32>
      %111 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 2] : (tensor<1x12x7xf32>) -> tensor<1x12x7x128xf32>
      %112 = stablehlo.divide %109, %111 : tensor<1x12x7x128xf32>
      %113 = stablehlo.convert %112 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %114 = stablehlo.reshape %113 : (tensor<1x12x7x128xbf16>) -> tensor<12x7x128xbf16>
      %115 = stablehlo.broadcast_in_dim %64, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %116 = stablehlo.reshape %115 : (tensor<1x4x3x128x128xbf16>) -> tensor<12x128x128xbf16>
      %117 = stablehlo.dot_general %114, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
      %118 = stablehlo.reshape %117 : (tensor<12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
      %119 = stablehlo.transpose %118, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x12x7x128xbf16>) -> tensor<1x7x12x128xbf16>
      %120 = stablehlo.reshape %119 : (tensor<1x7x12x128xbf16>) -> tensor<7x1536xbf16>
      %121 = stablehlo.transpose %arg68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
      %122 = stablehlo.dot_general %120, %121, contracting_dims = [1] x [0] : (tensor<7x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<7x3072xbf16>
      %123 = "stablehlo.all_reduce"(%122) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %551 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %551 : tensor<bf16>
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %124 = stablehlo.reshape %123 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %125 = stablehlo.add %13, %124 : tensor<1x7x3072xbf16>
      %126 = stablehlo.convert %arg73 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %127 = stablehlo.broadcast_in_dim %126, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %128 = stablehlo.convert %125 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %129 = stablehlo.power %128, %1 : tensor<1x7x3072xf32>
      %130 = stablehlo.reduce(%129 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %131 = stablehlo.multiply %130, %cst_1 : tensor<1x7xf32>
      %132 = stablehlo.reshape %131 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %133 = stablehlo.add %132, %19 : tensor<1x7x1xf32>
      %134 = stablehlo.rsqrt %133 : tensor<1x7x1xf32>
      %135 = stablehlo.reshape %134 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %136 = stablehlo.broadcast_in_dim %135, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %137 = stablehlo.multiply %128, %136 : tensor<1x7x3072xf32>
      %138 = stablehlo.convert %137 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %139 = stablehlo.convert %138 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %140 = stablehlo.multiply %127, %139 : tensor<1x7x3072xf32>
      %141 = stablehlo.convert %140 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %142 = stablehlo.reshape %141 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %143 = stablehlo.transpose %arg74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %144 = stablehlo.dot_general %142, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
      %145 = stablehlo.reshape %144 : (tensor<7x4096xbf16>) -> tensor<1x7x4096xbf16>
      %146 = stablehlo.convert %145 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %147 = stablehlo.logistic %145 : tensor<1x7x4096xbf16>
      %148 = stablehlo.convert %147 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %149 = stablehlo.multiply %146, %148 : tensor<1x7x4096xf32>
      %150 = stablehlo.convert %149 : (tensor<1x7x4096xf32>) -> tensor<1x7x4096xbf16>
      %151 = stablehlo.convert %150 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %152 = stablehlo.transpose %arg67, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %153 = stablehlo.dot_general %142, %152, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
      %154 = stablehlo.convert %153 : (tensor<7x4096xbf16>) -> tensor<7x4096xf32>
      %155 = stablehlo.reshape %154 : (tensor<7x4096xf32>) -> tensor<1x7x4096xf32>
      %156 = stablehlo.multiply %151, %155 : tensor<1x7x4096xf32>
      %157 = stablehlo.convert %156 : (tensor<1x7x4096xf32>) -> tensor<1x7x4096xbf16>
      %158 = stablehlo.reshape %157 : (tensor<1x7x4096xbf16>) -> tensor<7x4096xbf16>
      %159 = stablehlo.transpose %arg66, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
      %160 = stablehlo.dot_general %158, %159, contracting_dims = [1] x [0] : (tensor<7x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<7x3072xbf16>
      %161 = "stablehlo.all_reduce"(%160) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %551 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %551 : tensor<bf16>
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %162 = stablehlo.reshape %161 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %163 = stablehlo.add %125, %162 : tensor<1x7x3072xbf16>
      %164 = stablehlo.convert %163 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %165 = stablehlo.power %164, %1 : tensor<1x7x3072xf32>
      %166 = stablehlo.reduce(%165 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %167 = stablehlo.multiply %166, %cst_1 : tensor<1x7xf32>
      %168 = stablehlo.reshape %167 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %169 = stablehlo.add %168, %19 : tensor<1x7x1xf32>
      %170 = stablehlo.rsqrt %169 : tensor<1x7x1xf32>
      %171 = stablehlo.reshape %170 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %172 = stablehlo.broadcast_in_dim %171, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %173 = stablehlo.multiply %164, %172 : tensor<1x7x3072xf32>
      %174 = stablehlo.convert %173 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %175 = stablehlo.convert %174 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %176 = stablehlo.multiply %66, %175 : tensor<1x7x3072xf32>
      %177 = stablehlo.convert %176 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %178 = stablehlo.reshape %177 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %179 = stablehlo.transpose %arg65, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %180 = stablehlo.dot_general %178, %179, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
      %181 = stablehlo.reshape %180 : (tensor<7x512xbf16>) -> tensor<1x7x4x128xbf16>
      %182 = stablehlo.transpose %181, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x4x128xbf16>) -> tensor<1x4x7x128xbf16>
      %183 = stablehlo.convert %182 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32>
      %184 = stablehlo.multiply %183, %44 : tensor<1x4x7x128xf32>
      %185 = stablehlo.convert %184 : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16>
      %186 = stablehlo.slice %182 [0:1, 0:4, 0:7, 64:128] : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16>
      %187 = stablehlo.negate %186 : tensor<1x4x7x64xbf16>
      %188 = stablehlo.slice %182 [0:1, 0:4, 0:7, 0:64] : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16>
      %189 = stablehlo.concatenate %187, %188, dim = 3 : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x128xbf16>
      %190 = stablehlo.convert %189 : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32>
      %191 = stablehlo.multiply %190, %55 : tensor<1x4x7x128xf32>
      %192 = stablehlo.convert %191 : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16>
      %193 = stablehlo.add %185, %192 : tensor<1x4x7x128xbf16>
      %194 = "stablehlo.scatter"(%arg76, %6, %193) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>) -> tensor<1x4x128x128xbf16>
      %195 = stablehlo.transpose %arg77, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %196 = stablehlo.dot_general %178, %195, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
      %197 = stablehlo.reshape %196 : (tensor<7x512xbf16>) -> tensor<1x7x4x128xbf16>
      %198 = stablehlo.transpose %197, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x4x128xbf16>) -> tensor<1x4x7x128xbf16>
      %199 = "stablehlo.scatter"(%arg78, %6, %198) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>) -> tensor<1x4x128x128xbf16>
      %200 = stablehlo.convert %arg86 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %201 = stablehlo.broadcast_in_dim %200, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %202 = stablehlo.transpose %arg83, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %203 = stablehlo.dot_general %178, %202, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<7x1536xbf16>
      %204 = stablehlo.reshape %203 : (tensor<7x1536xbf16>) -> tensor<1x7x12x128xbf16>
      %205 = stablehlo.transpose %204, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x12x128xbf16>) -> tensor<1x12x7x128xbf16>
      %206 = stablehlo.convert %205 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %207 = stablehlo.multiply %206, %72 : tensor<1x12x7x128xf32>
      %208 = stablehlo.convert %207 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %209 = stablehlo.slice %205 [0:1, 0:12, 0:7, 64:128] : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16>
      %210 = stablehlo.negate %209 : tensor<1x12x7x64xbf16>
      %211 = stablehlo.slice %205 [0:1, 0:12, 0:7, 0:64] : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16>
      %212 = stablehlo.concatenate %210, %211, dim = 3 : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x128xbf16>
      %213 = stablehlo.convert %212 : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %214 = stablehlo.multiply %213, %80 : tensor<1x12x7x128xf32>
      %215 = stablehlo.convert %214 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %216 = stablehlo.add %208, %215 : tensor<1x12x7x128xbf16>
      %217 = stablehlo.reshape %216 : (tensor<1x12x7x128xbf16>) -> tensor<12x7x128xbf16>
      %218 = stablehlo.broadcast_in_dim %194, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %219 = stablehlo.reshape %218 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %220 = stablehlo.transpose %219, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %221 = stablehlo.reshape %220 : (tensor<1x12x128x128xbf16>) -> tensor<12x128x128xbf16>
      %222 = stablehlo.dot_general %217, %221, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
      %223 = stablehlo.convert %222 : (tensor<12x7x128xbf16>) -> tensor<12x7x128xf32>
      %224 = stablehlo.reshape %223 : (tensor<12x7x128xf32>) -> tensor<1x12x7x128xf32>
      %225 = stablehlo.multiply %224, %92 : tensor<1x12x7x128xf32>
      %226 = stablehlo.convert %225 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %227 = stablehlo.add %226, %103 : tensor<1x12x7x128xbf16>
      %228 = stablehlo.convert %227 : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %229 = stablehlo.reduce(%228 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x7x128xf32>, tensor<f32>) -> tensor<1x12x7xf32>
      %230 = stablehlo.broadcast_in_dim %229, dims = [0, 1, 2] : (tensor<1x12x7xf32>) -> tensor<1x12x7x128xf32>
      %231 = stablehlo.subtract %228, %230 : tensor<1x12x7x128xf32>
      %232 = stablehlo.exponential %231 : tensor<1x12x7x128xf32>
      %233 = stablehlo.reduce(%232 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x7x128xf32>, tensor<f32>) -> tensor<1x12x7xf32>
      %234 = stablehlo.broadcast_in_dim %233, dims = [0, 1, 2] : (tensor<1x12x7xf32>) -> tensor<1x12x7x128xf32>
      %235 = stablehlo.divide %232, %234 : tensor<1x12x7x128xf32>
      %236 = stablehlo.convert %235 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %237 = stablehlo.reshape %236 : (tensor<1x12x7x128xbf16>) -> tensor<12x7x128xbf16>
      %238 = stablehlo.broadcast_in_dim %199, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %239 = stablehlo.reshape %238 : (tensor<1x4x3x128x128xbf16>) -> tensor<12x128x128xbf16>
      %240 = stablehlo.dot_general %237, %239, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
      %241 = stablehlo.reshape %240 : (tensor<12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
      %242 = stablehlo.transpose %241, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x12x7x128xbf16>) -> tensor<1x7x12x128xbf16>
      %243 = stablehlo.reshape %242 : (tensor<1x7x12x128xbf16>) -> tensor<7x1536xbf16>
      %244 = stablehlo.transpose %arg82, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
      %245 = stablehlo.dot_general %243, %244, contracting_dims = [1] x [0] : (tensor<7x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<7x3072xbf16>
      %246 = "stablehlo.all_reduce"(%245) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %551 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %551 : tensor<bf16>
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %247 = stablehlo.reshape %246 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %248 = stablehlo.add %163, %247 : tensor<1x7x3072xbf16>
      %249 = stablehlo.convert %arg84 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %250 = stablehlo.broadcast_in_dim %249, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %251 = stablehlo.convert %248 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %252 = stablehlo.power %251, %1 : tensor<1x7x3072xf32>
      %253 = stablehlo.reduce(%252 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %254 = stablehlo.multiply %253, %cst_1 : tensor<1x7xf32>
      %255 = stablehlo.reshape %254 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %256 = stablehlo.add %255, %19 : tensor<1x7x1xf32>
      %257 = stablehlo.rsqrt %256 : tensor<1x7x1xf32>
      %258 = stablehlo.reshape %257 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %259 = stablehlo.broadcast_in_dim %258, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %260 = stablehlo.multiply %251, %259 : tensor<1x7x3072xf32>
      %261 = stablehlo.convert %260 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %262 = stablehlo.convert %261 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %263 = stablehlo.multiply %250, %262 : tensor<1x7x3072xf32>
      %264 = stablehlo.convert %263 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %265 = stablehlo.reshape %264 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %266 = stablehlo.transpose %arg85, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %267 = stablehlo.dot_general %265, %266, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
      %268 = stablehlo.reshape %267 : (tensor<7x4096xbf16>) -> tensor<1x7x4096xbf16>
      %269 = stablehlo.convert %268 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %270 = stablehlo.logistic %268 : tensor<1x7x4096xbf16>
      %271 = stablehlo.convert %270 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %272 = stablehlo.multiply %269, %271 : tensor<1x7x4096xf32>
      %273 = stablehlo.convert %272 : (tensor<1x7x4096xf32>) -> tensor<1x7x4096xbf16>
      %274 = stablehlo.convert %273 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %275 = stablehlo.transpose %arg81, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %276 = stablehlo.dot_general %265, %275, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
      %277 = stablehlo.convert %276 : (tensor<7x4096xbf16>) -> tensor<7x4096xf32>
      %278 = stablehlo.reshape %277 : (tensor<7x4096xf32>) -> tensor<1x7x4096xf32>
      %279 = stablehlo.multiply %274, %278 : tensor<1x7x4096xf32>
      %280 = stablehlo.convert %279 : (tensor<1x7x4096xf32>) -> tensor<1x7x4096xbf16>
      %281 = stablehlo.reshape %280 : (tensor<1x7x4096xbf16>) -> tensor<7x4096xbf16>
      %282 = stablehlo.transpose %arg80, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
      %283 = stablehlo.dot_general %281, %282, contracting_dims = [1] x [0] : (tensor<7x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<7x3072xbf16>
      %284 = "stablehlo.all_reduce"(%283) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %551 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %551 : tensor<bf16>
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %285 = stablehlo.reshape %284 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %286 = stablehlo.add %248, %285 : tensor<1x7x3072xbf16>
      %287 = stablehlo.convert %286 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %288 = stablehlo.power %287, %1 : tensor<1x7x3072xf32>
      %289 = stablehlo.reduce(%288 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %290 = stablehlo.multiply %289, %cst_1 : tensor<1x7xf32>
      %291 = stablehlo.reshape %290 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %292 = stablehlo.add %291, %19 : tensor<1x7x1xf32>
      %293 = stablehlo.rsqrt %292 : tensor<1x7x1xf32>
      %294 = stablehlo.reshape %293 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %295 = stablehlo.broadcast_in_dim %294, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %296 = stablehlo.multiply %287, %295 : tensor<1x7x3072xf32>
      %297 = stablehlo.convert %296 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %298 = stablehlo.convert %297 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %299 = stablehlo.multiply %201, %298 : tensor<1x7x3072xf32>
      %300 = stablehlo.convert %299 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %301 = stablehlo.reshape %300 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %302 = stablehlo.transpose %arg79, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %303 = stablehlo.dot_general %301, %302, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
      %304 = stablehlo.reshape %303 : (tensor<7x512xbf16>) -> tensor<1x7x4x128xbf16>
      %305 = stablehlo.transpose %304, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x4x128xbf16>) -> tensor<1x4x7x128xbf16>
      %306 = stablehlo.convert %305 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32>
      %307 = stablehlo.multiply %306, %44 : tensor<1x4x7x128xf32>
      %308 = stablehlo.convert %307 : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16>
      %309 = stablehlo.slice %305 [0:1, 0:4, 0:7, 64:128] : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16>
      %310 = stablehlo.negate %309 : tensor<1x4x7x64xbf16>
      %311 = stablehlo.slice %305 [0:1, 0:4, 0:7, 0:64] : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16>
      %312 = stablehlo.concatenate %310, %311, dim = 3 : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x128xbf16>
      %313 = stablehlo.convert %312 : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32>
      %314 = stablehlo.multiply %313, %55 : tensor<1x4x7x128xf32>
      %315 = stablehlo.convert %314 : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16>
      %316 = stablehlo.add %308, %315 : tensor<1x4x7x128xbf16>
      %317 = "stablehlo.scatter"(%arg87, %6, %316) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>) -> tensor<1x4x128x128xbf16>
      %318 = stablehlo.transpose %arg88, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %319 = stablehlo.dot_general %301, %318, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
      %320 = stablehlo.reshape %319 : (tensor<7x512xbf16>) -> tensor<1x7x4x128xbf16>
      %321 = stablehlo.transpose %320, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x4x128xbf16>) -> tensor<1x4x7x128xbf16>
      %322 = "stablehlo.scatter"(%arg89, %6, %321) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>) -> tensor<1x4x128x128xbf16>
      %323 = stablehlo.convert %arg97 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %324 = stablehlo.broadcast_in_dim %323, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %325 = stablehlo.transpose %arg94, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %326 = stablehlo.dot_general %301, %325, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<7x1536xbf16>
      %327 = stablehlo.reshape %326 : (tensor<7x1536xbf16>) -> tensor<1x7x12x128xbf16>
      %328 = stablehlo.transpose %327, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x12x128xbf16>) -> tensor<1x12x7x128xbf16>
      %329 = stablehlo.convert %328 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %330 = stablehlo.multiply %329, %72 : tensor<1x12x7x128xf32>
      %331 = stablehlo.convert %330 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %332 = stablehlo.slice %328 [0:1, 0:12, 0:7, 64:128] : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16>
      %333 = stablehlo.negate %332 : tensor<1x12x7x64xbf16>
      %334 = stablehlo.slice %328 [0:1, 0:12, 0:7, 0:64] : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16>
      %335 = stablehlo.concatenate %333, %334, dim = 3 : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x128xbf16>
      %336 = stablehlo.convert %335 : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %337 = stablehlo.multiply %336, %80 : tensor<1x12x7x128xf32>
      %338 = stablehlo.convert %337 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %339 = stablehlo.add %331, %338 : tensor<1x12x7x128xbf16>
      %340 = stablehlo.reshape %339 : (tensor<1x12x7x128xbf16>) -> tensor<12x7x128xbf16>
      %341 = stablehlo.broadcast_in_dim %317, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %342 = stablehlo.reshape %341 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %343 = stablehlo.transpose %342, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %344 = stablehlo.reshape %343 : (tensor<1x12x128x128xbf16>) -> tensor<12x128x128xbf16>
      %345 = stablehlo.dot_general %340, %344, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
      %346 = stablehlo.convert %345 : (tensor<12x7x128xbf16>) -> tensor<12x7x128xf32>
      %347 = stablehlo.reshape %346 : (tensor<12x7x128xf32>) -> tensor<1x12x7x128xf32>
      %348 = stablehlo.multiply %347, %92 : tensor<1x12x7x128xf32>
      %349 = stablehlo.convert %348 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %350 = stablehlo.add %349, %103 : tensor<1x12x7x128xbf16>
      %351 = stablehlo.convert %350 : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %352 = stablehlo.reduce(%351 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x7x128xf32>, tensor<f32>) -> tensor<1x12x7xf32>
      %353 = stablehlo.broadcast_in_dim %352, dims = [0, 1, 2] : (tensor<1x12x7xf32>) -> tensor<1x12x7x128xf32>
      %354 = stablehlo.subtract %351, %353 : tensor<1x12x7x128xf32>
      %355 = stablehlo.exponential %354 : tensor<1x12x7x128xf32>
      %356 = stablehlo.reduce(%355 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x7x128xf32>, tensor<f32>) -> tensor<1x12x7xf32>
      %357 = stablehlo.broadcast_in_dim %356, dims = [0, 1, 2] : (tensor<1x12x7xf32>) -> tensor<1x12x7x128xf32>
      %358 = stablehlo.divide %355, %357 : tensor<1x12x7x128xf32>
      %359 = stablehlo.convert %358 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %360 = stablehlo.reshape %359 : (tensor<1x12x7x128xbf16>) -> tensor<12x7x128xbf16>
      %361 = stablehlo.broadcast_in_dim %322, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %362 = stablehlo.reshape %361 : (tensor<1x4x3x128x128xbf16>) -> tensor<12x128x128xbf16>
      %363 = stablehlo.dot_general %360, %362, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
      %364 = stablehlo.reshape %363 : (tensor<12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
      %365 = stablehlo.transpose %364, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x12x7x128xbf16>) -> tensor<1x7x12x128xbf16>
      %366 = stablehlo.reshape %365 : (tensor<1x7x12x128xbf16>) -> tensor<7x1536xbf16>
      %367 = stablehlo.transpose %arg93, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
      %368 = stablehlo.dot_general %366, %367, contracting_dims = [1] x [0] : (tensor<7x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<7x3072xbf16>
      %369 = "stablehlo.all_reduce"(%368) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %551 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %551 : tensor<bf16>
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %370 = stablehlo.reshape %369 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %371 = stablehlo.add %286, %370 : tensor<1x7x3072xbf16>
      %372 = stablehlo.convert %arg95 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %373 = stablehlo.broadcast_in_dim %372, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %374 = stablehlo.convert %371 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %375 = stablehlo.power %374, %1 : tensor<1x7x3072xf32>
      %376 = stablehlo.reduce(%375 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %377 = stablehlo.multiply %376, %cst_1 : tensor<1x7xf32>
      %378 = stablehlo.reshape %377 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %379 = stablehlo.add %378, %19 : tensor<1x7x1xf32>
      %380 = stablehlo.rsqrt %379 : tensor<1x7x1xf32>
      %381 = stablehlo.reshape %380 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %382 = stablehlo.broadcast_in_dim %381, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %383 = stablehlo.multiply %374, %382 : tensor<1x7x3072xf32>
      %384 = stablehlo.convert %383 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %385 = stablehlo.convert %384 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %386 = stablehlo.multiply %373, %385 : tensor<1x7x3072xf32>
      %387 = stablehlo.convert %386 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %388 = stablehlo.reshape %387 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %389 = stablehlo.transpose %arg96, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %390 = stablehlo.dot_general %388, %389, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
      %391 = stablehlo.reshape %390 : (tensor<7x4096xbf16>) -> tensor<1x7x4096xbf16>
      %392 = stablehlo.convert %391 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %393 = stablehlo.logistic %391 : tensor<1x7x4096xbf16>
      %394 = stablehlo.convert %393 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %395 = stablehlo.multiply %392, %394 : tensor<1x7x4096xf32>
      %396 = stablehlo.convert %395 : (tensor<1x7x4096xf32>) -> tensor<1x7x4096xbf16>
      %397 = stablehlo.convert %396 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %398 = stablehlo.transpose %arg92, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %399 = stablehlo.dot_general %388, %398, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
      %400 = stablehlo.convert %399 : (tensor<7x4096xbf16>) -> tensor<7x4096xf32>
      %401 = stablehlo.reshape %400 : (tensor<7x4096xf32>) -> tensor<1x7x4096xf32>
      %402 = stablehlo.multiply %397, %401 : tensor<1x7x4096xf32>
      %403 = stablehlo.convert %402 : (tensor<1x7x4096xf32>) -> tensor<1x7x4096xbf16>
      %404 = stablehlo.reshape %403 : (tensor<1x7x4096xbf16>) -> tensor<7x4096xbf16>
      %405 = stablehlo.transpose %arg91, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
      %406 = stablehlo.dot_general %404, %405, contracting_dims = [1] x [0] : (tensor<7x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<7x3072xbf16>
      %407 = "stablehlo.all_reduce"(%406) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %551 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %551 : tensor<bf16>
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %408 = stablehlo.reshape %407 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %409 = stablehlo.add %371, %408 : tensor<1x7x3072xbf16>
      %410 = stablehlo.convert %409 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %411 = stablehlo.power %410, %1 : tensor<1x7x3072xf32>
      %412 = stablehlo.reduce(%411 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %413 = stablehlo.multiply %412, %cst_1 : tensor<1x7xf32>
      %414 = stablehlo.reshape %413 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %415 = stablehlo.add %414, %19 : tensor<1x7x1xf32>
      %416 = stablehlo.rsqrt %415 : tensor<1x7x1xf32>
      %417 = stablehlo.reshape %416 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %418 = stablehlo.broadcast_in_dim %417, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %419 = stablehlo.multiply %410, %418 : tensor<1x7x3072xf32>
      %420 = stablehlo.convert %419 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %421 = stablehlo.convert %420 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %422 = stablehlo.multiply %324, %421 : tensor<1x7x3072xf32>
      %423 = stablehlo.convert %422 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %424 = stablehlo.reshape %423 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %425 = stablehlo.transpose %arg90, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %426 = stablehlo.dot_general %424, %425, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
      %427 = stablehlo.reshape %426 : (tensor<7x512xbf16>) -> tensor<1x7x4x128xbf16>
      %428 = stablehlo.transpose %427, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x4x128xbf16>) -> tensor<1x4x7x128xbf16>
      %429 = stablehlo.convert %428 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32>
      %430 = stablehlo.multiply %429, %44 : tensor<1x4x7x128xf32>
      %431 = stablehlo.convert %430 : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16>
      %432 = stablehlo.slice %428 [0:1, 0:4, 0:7, 64:128] : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16>
      %433 = stablehlo.negate %432 : tensor<1x4x7x64xbf16>
      %434 = stablehlo.slice %428 [0:1, 0:4, 0:7, 0:64] : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16>
      %435 = stablehlo.concatenate %433, %434, dim = 3 : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x128xbf16>
      %436 = stablehlo.convert %435 : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32>
      %437 = stablehlo.multiply %436, %55 : tensor<1x4x7x128xf32>
      %438 = stablehlo.convert %437 : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16>
      %439 = stablehlo.add %431, %438 : tensor<1x4x7x128xbf16>
      %440 = "stablehlo.scatter"(%arg98, %6, %439) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>) -> tensor<1x4x128x128xbf16>
      %441 = stablehlo.transpose %arg99, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %442 = stablehlo.dot_general %424, %441, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
      %443 = stablehlo.reshape %442 : (tensor<7x512xbf16>) -> tensor<1x7x4x128xbf16>
      %444 = stablehlo.transpose %443, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x4x128xbf16>) -> tensor<1x4x7x128xbf16>
      %445 = "stablehlo.scatter"(%arg100, %6, %444) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>) -> tensor<1x4x128x128xbf16>
      %446 = stablehlo.convert %arg107 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %447 = stablehlo.broadcast_in_dim %446, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %448 = stablehlo.transpose %arg104, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %449 = stablehlo.dot_general %424, %448, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<7x1536xbf16>
      %450 = stablehlo.reshape %449 : (tensor<7x1536xbf16>) -> tensor<1x7x12x128xbf16>
      %451 = stablehlo.transpose %450, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x12x128xbf16>) -> tensor<1x12x7x128xbf16>
      %452 = stablehlo.convert %451 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %453 = stablehlo.multiply %452, %72 : tensor<1x12x7x128xf32>
      %454 = stablehlo.convert %453 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %455 = stablehlo.slice %451 [0:1, 0:12, 0:7, 64:128] : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16>
      %456 = stablehlo.negate %455 : tensor<1x12x7x64xbf16>
      %457 = stablehlo.slice %451 [0:1, 0:12, 0:7, 0:64] : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16>
      %458 = stablehlo.concatenate %456, %457, dim = 3 : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x128xbf16>
      %459 = stablehlo.convert %458 : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %460 = stablehlo.multiply %459, %80 : tensor<1x12x7x128xf32>
      %461 = stablehlo.convert %460 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %462 = stablehlo.add %454, %461 : tensor<1x12x7x128xbf16>
      %463 = stablehlo.reshape %462 : (tensor<1x12x7x128xbf16>) -> tensor<12x7x128xbf16>
      %464 = stablehlo.broadcast_in_dim %440, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %465 = stablehlo.reshape %464 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %466 = stablehlo.transpose %465, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %467 = stablehlo.reshape %466 : (tensor<1x12x128x128xbf16>) -> tensor<12x128x128xbf16>
      %468 = stablehlo.dot_general %463, %467, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
      %469 = stablehlo.convert %468 : (tensor<12x7x128xbf16>) -> tensor<12x7x128xf32>
      %470 = stablehlo.reshape %469 : (tensor<12x7x128xf32>) -> tensor<1x12x7x128xf32>
      %471 = stablehlo.multiply %470, %92 : tensor<1x12x7x128xf32>
      %472 = stablehlo.convert %471 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %473 = stablehlo.add %472, %103 : tensor<1x12x7x128xbf16>
      %474 = stablehlo.convert %473 : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %475 = stablehlo.reduce(%474 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x7x128xf32>, tensor<f32>) -> tensor<1x12x7xf32>
      %476 = stablehlo.broadcast_in_dim %475, dims = [0, 1, 2] : (tensor<1x12x7xf32>) -> tensor<1x12x7x128xf32>
      %477 = stablehlo.subtract %474, %476 : tensor<1x12x7x128xf32>
      %478 = stablehlo.exponential %477 : tensor<1x12x7x128xf32>
      %479 = stablehlo.reduce(%478 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x7x128xf32>, tensor<f32>) -> tensor<1x12x7xf32>
      %480 = stablehlo.broadcast_in_dim %479, dims = [0, 1, 2] : (tensor<1x12x7xf32>) -> tensor<1x12x7x128xf32>
      %481 = stablehlo.divide %478, %480 : tensor<1x12x7x128xf32>
      %482 = stablehlo.convert %481 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %483 = stablehlo.reshape %482 : (tensor<1x12x7x128xbf16>) -> tensor<12x7x128xbf16>
      %484 = stablehlo.broadcast_in_dim %445, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %485 = stablehlo.reshape %484 : (tensor<1x4x3x128x128xbf16>) -> tensor<12x128x128xbf16>
      %486 = stablehlo.dot_general %483, %485, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
      %487 = stablehlo.reshape %486 : (tensor<12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
      %488 = stablehlo.transpose %487, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x12x7x128xbf16>) -> tensor<1x7x12x128xbf16>
      %489 = stablehlo.reshape %488 : (tensor<1x7x12x128xbf16>) -> tensor<7x1536xbf16>
      %490 = stablehlo.transpose %arg103, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
      %491 = stablehlo.dot_general %489, %490, contracting_dims = [1] x [0] : (tensor<7x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<7x3072xbf16>
      %492 = "stablehlo.all_reduce"(%491) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %551 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %551 : tensor<bf16>
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %493 = stablehlo.reshape %492 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %494 = stablehlo.add %409, %493 : tensor<1x7x3072xbf16>
      %495 = stablehlo.convert %arg105 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %496 = stablehlo.broadcast_in_dim %495, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %497 = stablehlo.convert %494 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %498 = stablehlo.power %497, %1 : tensor<1x7x3072xf32>
      %499 = stablehlo.reduce(%498 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %500 = stablehlo.multiply %499, %cst_1 : tensor<1x7xf32>
      %501 = stablehlo.reshape %500 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %502 = stablehlo.add %501, %19 : tensor<1x7x1xf32>
      %503 = stablehlo.rsqrt %502 : tensor<1x7x1xf32>
      %504 = stablehlo.reshape %503 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %505 = stablehlo.broadcast_in_dim %504, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %506 = stablehlo.multiply %497, %505 : tensor<1x7x3072xf32>
      %507 = stablehlo.convert %506 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %508 = stablehlo.convert %507 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %509 = stablehlo.multiply %496, %508 : tensor<1x7x3072xf32>
      %510 = stablehlo.convert %509 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %511 = stablehlo.reshape %510 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %512 = stablehlo.transpose %arg106, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %513 = stablehlo.dot_general %511, %512, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
      %514 = stablehlo.reshape %513 : (tensor<7x4096xbf16>) -> tensor<1x7x4096xbf16>
      %515 = stablehlo.convert %514 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %516 = stablehlo.logistic %514 : tensor<1x7x4096xbf16>
      %517 = stablehlo.convert %516 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %518 = stablehlo.multiply %515, %517 : tensor<1x7x4096xf32>
      %519 = stablehlo.convert %518 : (tensor<1x7x4096xf32>) -> tensor<1x7x4096xbf16>
      %520 = stablehlo.convert %519 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %521 = stablehlo.transpose %arg102, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %522 = stablehlo.dot_general %511, %521, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
      %523 = stablehlo.convert %522 : (tensor<7x4096xbf16>) -> tensor<7x4096xf32>
      %524 = stablehlo.reshape %523 : (tensor<7x4096xf32>) -> tensor<1x7x4096xf32>
      %525 = stablehlo.multiply %520, %524 : tensor<1x7x4096xf32>
      %526 = stablehlo.convert %525 : (tensor<1x7x4096xf32>) -> tensor<1x7x4096xbf16>
      %527 = stablehlo.reshape %526 : (tensor<1x7x4096xbf16>) -> tensor<7x4096xbf16>
      %528 = stablehlo.transpose %arg101, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
      %529 = stablehlo.dot_general %527, %528, contracting_dims = [1] x [0] : (tensor<7x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<7x3072xbf16>
      %530 = "stablehlo.all_reduce"(%529) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %551 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %551 : tensor<bf16>
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %531 = stablehlo.reshape %530 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %532 = stablehlo.add %494, %531 : tensor<1x7x3072xbf16>
      %533 = stablehlo.convert %532 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %534 = stablehlo.power %533, %1 : tensor<1x7x3072xf32>
      %535 = stablehlo.reduce(%534 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %536 = stablehlo.multiply %535, %cst_1 : tensor<1x7xf32>
      %537 = stablehlo.reshape %536 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %538 = stablehlo.add %537, %19 : tensor<1x7x1xf32>
      %539 = stablehlo.rsqrt %538 : tensor<1x7x1xf32>
      %540 = stablehlo.reshape %539 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %541 = stablehlo.broadcast_in_dim %540, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %542 = stablehlo.multiply %533, %541 : tensor<1x7x3072xf32>
      %543 = stablehlo.convert %542 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %544 = stablehlo.convert %543 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %545 = stablehlo.multiply %447, %544 : tensor<1x7x3072xf32>
      %546 = stablehlo.convert %545 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %547 = stablehlo.reshape %546 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %548 = stablehlo.transpose %arg59, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<64128x3072xbf16>) -> tensor<3072x64128xbf16>
      %549 = stablehlo.dot_general %547, %548, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x64128xbf16>) -> tensor<7x64128xbf16>
      %550 = stablehlo.reshape %549 : (tensor<7x64128xbf16>) -> tensor<1x7x64128xbf16>
      sdy.return %59, %64, %194, %199, %317, %322, %440, %445, %549, %550 : tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<7x64128xbf16>, tensor<1x7x64128xbf16>
    } : (tensor<7xi64>, tensor<64xf32>, tensor<1024x3072xbf16>, tensor<f32>, tensor<1x7xi64>, tensor<128256x3072xbf16>, tensor<3072xbf16>, tensor<i64>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<128xi64>, tensor<7x128xbf16>, tensor<f32>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>)
    return %0#0, %0#1, %0#2, %0#3, %0#4, %0#5, %0#6, %0#7, %0#8, %0#9 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>
  }
}
module @SyncTensorsGraph.1220 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<7xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<64xf32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg3: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg4: tensor<1x7xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg5: tensor<128256x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg6: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg7: tensor<i64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg8: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg9: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg10: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg11: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg12: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg13: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg14: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg15: tensor<128xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg16: tensor<7x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg17: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg18: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg19: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg20: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg21: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg22: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg23: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg24: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg25: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg26: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg27: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg28: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg29: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg30: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg31: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg32: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg33: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg34: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg35: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg36: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg37: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg38: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg39: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg40: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg41: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg42: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg43: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg44: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg45: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg46: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg47: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg48: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg49: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg50: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg51: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg52: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg53: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = ttir.empty() : tensor<7xi64>
    %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi64>
    %2 = ttir.empty() : tensor<64xf32>
    %3 = "ttir.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xf32>
    %4 = ttir.empty() : tensor<512x3072xbf16>
    %5 = "ttir.mesh_shard"(%arg2, %4) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %6 = ttir.empty() : tensor<f32>
    %7 = "ttir.mesh_shard"(%arg3, %6) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32>, tensor<f32>) -> tensor<f32>
    %8 = ttir.empty() : tensor<1x7xi64>
    %9 = "ttir.mesh_shard"(%arg4, %8) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x7xi64>, tensor<1x7xi64>) -> tensor<1x7xi64>
    %10 = ttir.empty() : tensor<64128x3072xbf16>
    %11 = "ttir.mesh_shard"(%arg5, %10) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16>, tensor<64128x3072xbf16>) -> tensor<64128x3072xbf16>
    %12 = ttir.empty() : tensor<3072xbf16>
    %13 = "ttir.mesh_shard"(%arg6, %12) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %14 = ttir.empty() : tensor<i64>
    %15 = "ttir.mesh_shard"(%arg7, %14) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<i64>, tensor<i64>) -> tensor<i64>
    %16 = ttir.empty() : tensor<1x4x128x128xbf16>
    %17 = "ttir.mesh_shard"(%arg8, %16) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %18 = ttir.empty() : tensor<512x3072xbf16>
    %19 = "ttir.mesh_shard"(%arg9, %18) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %20 = ttir.empty() : tensor<1x4x128x128xbf16>
    %21 = "ttir.mesh_shard"(%arg10, %20) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %22 = ttir.empty() : tensor<512x3072xbf16>
    %23 = "ttir.mesh_shard"(%arg11, %22) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %24 = ttir.empty() : tensor<3072x4096xbf16>
    %25 = "ttir.mesh_shard"(%arg12, %24) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %26 = ttir.empty() : tensor<4096x3072xbf16>
    %27 = "ttir.mesh_shard"(%arg13, %26) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %28 = ttir.empty() : tensor<3072x1536xbf16>
    %29 = "ttir.mesh_shard"(%arg14, %28) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %30 = ttir.empty() : tensor<128xi64>
    %31 = "ttir.mesh_shard"(%arg15, %30) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi64>
    %32 = ttir.empty() : tensor<7x128xbf16>
    %33 = "ttir.mesh_shard"(%arg16, %32) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<7x128xbf16>, tensor<7x128xbf16>) -> tensor<7x128xbf16>
    %34 = ttir.empty() : tensor<f32>
    %35 = "ttir.mesh_shard"(%arg17, %34) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32>, tensor<f32>) -> tensor<f32>
    %36 = ttir.empty() : tensor<1536x3072xbf16>
    %37 = "ttir.mesh_shard"(%arg18, %36) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %38 = ttir.empty() : tensor<3072xbf16>
    %39 = "ttir.mesh_shard"(%arg19, %38) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %40 = ttir.empty() : tensor<4096x3072xbf16>
    %41 = "ttir.mesh_shard"(%arg20, %40) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %42 = ttir.empty() : tensor<3072xbf16>
    %43 = "ttir.mesh_shard"(%arg21, %42) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %44 = ttir.empty() : tensor<1x4x128x128xbf16>
    %45 = "ttir.mesh_shard"(%arg22, %44) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %46 = ttir.empty() : tensor<512x3072xbf16>
    %47 = "ttir.mesh_shard"(%arg23, %46) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %48 = ttir.empty() : tensor<1x4x128x128xbf16>
    %49 = "ttir.mesh_shard"(%arg24, %48) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %50 = ttir.empty() : tensor<512x3072xbf16>
    %51 = "ttir.mesh_shard"(%arg25, %50) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %52 = ttir.empty() : tensor<3072x4096xbf16>
    %53 = "ttir.mesh_shard"(%arg26, %52) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %54 = ttir.empty() : tensor<4096x3072xbf16>
    %55 = "ttir.mesh_shard"(%arg27, %54) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %56 = ttir.empty() : tensor<3072x1536xbf16>
    %57 = "ttir.mesh_shard"(%arg28, %56) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %58 = ttir.empty() : tensor<1536x3072xbf16>
    %59 = "ttir.mesh_shard"(%arg29, %58) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %60 = ttir.empty() : tensor<3072xbf16>
    %61 = "ttir.mesh_shard"(%arg30, %60) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %62 = ttir.empty() : tensor<4096x3072xbf16>
    %63 = "ttir.mesh_shard"(%arg31, %62) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %64 = ttir.empty() : tensor<3072xbf16>
    %65 = "ttir.mesh_shard"(%arg32, %64) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %66 = ttir.empty() : tensor<1x4x128x128xbf16>
    %67 = "ttir.mesh_shard"(%arg33, %66) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %68 = ttir.empty() : tensor<512x3072xbf16>
    %69 = "ttir.mesh_shard"(%arg34, %68) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %70 = ttir.empty() : tensor<1x4x128x128xbf16>
    %71 = "ttir.mesh_shard"(%arg35, %70) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %72 = ttir.empty() : tensor<512x3072xbf16>
    %73 = "ttir.mesh_shard"(%arg36, %72) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %74 = ttir.empty() : tensor<3072x4096xbf16>
    %75 = "ttir.mesh_shard"(%arg37, %74) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %76 = ttir.empty() : tensor<4096x3072xbf16>
    %77 = "ttir.mesh_shard"(%arg38, %76) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %78 = ttir.empty() : tensor<3072x1536xbf16>
    %79 = "ttir.mesh_shard"(%arg39, %78) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %80 = ttir.empty() : tensor<1536x3072xbf16>
    %81 = "ttir.mesh_shard"(%arg40, %80) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %82 = ttir.empty() : tensor<3072xbf16>
    %83 = "ttir.mesh_shard"(%arg41, %82) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %84 = ttir.empty() : tensor<4096x3072xbf16>
    %85 = "ttir.mesh_shard"(%arg42, %84) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %86 = ttir.empty() : tensor<3072xbf16>
    %87 = "ttir.mesh_shard"(%arg43, %86) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %88 = ttir.empty() : tensor<1x4x128x128xbf16>
    %89 = "ttir.mesh_shard"(%arg44, %88) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %90 = ttir.empty() : tensor<512x3072xbf16>
    %91 = "ttir.mesh_shard"(%arg45, %90) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %92 = ttir.empty() : tensor<1x4x128x128xbf16>
    %93 = "ttir.mesh_shard"(%arg46, %92) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %94 = ttir.empty() : tensor<3072x4096xbf16>
    %95 = "ttir.mesh_shard"(%arg47, %94) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %96 = ttir.empty() : tensor<4096x3072xbf16>
    %97 = "ttir.mesh_shard"(%arg48, %96) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %98 = ttir.empty() : tensor<3072x1536xbf16>
    %99 = "ttir.mesh_shard"(%arg49, %98) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %100 = ttir.empty() : tensor<1536x3072xbf16>
    %101 = "ttir.mesh_shard"(%arg50, %100) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %102 = ttir.empty() : tensor<3072xbf16>
    %103 = "ttir.mesh_shard"(%arg51, %102) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %104 = ttir.empty() : tensor<4096x3072xbf16>
    %105 = "ttir.mesh_shard"(%arg52, %104) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %106 = ttir.empty() : tensor<3072xbf16>
    %107 = "ttir.mesh_shard"(%arg53, %106) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %108 = "ttir.constant"() <{value = dense<0> : tensor<7xi64>}> : () -> tensor<7xi64>
    %109 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32>
    %110 = "ttir.constant"() <{value = dense<0xFF800000> : tensor<f32>}> : () -> tensor<f32>
    %111 = "ttir.constant"() <{value = dense<3.25520843E-4> : tensor<1x7xf32>}> : () -> tensor<1x7xf32>
    %112 = "ttir.constant"() <{value = dense<2.000000e+00> : tensor<f32>}> : () -> tensor<f32>
    %113 = ttir.empty() : tensor<1x1x1xf32>
    %114 = "ttir.reshape"(%112, %113) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %115 = ttir.empty() : tensor<1x7x3072xf32>
    %116 = "ttir.broadcast"(%114, %115) <{broadcast_dimensions = array<i64: 1, 7, 3072>}> : (tensor<1x1x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %117 = ttir.empty() : tensor<7xi1>
    %118 = "ttir.lt"(%1, %108, %117) : (tensor<7xi64>, tensor<7xi64>, tensor<7xi1>) -> tensor<7xi1>
    %119 = ttir.empty() : tensor<1xi64>
    %120 = "ttir.reshape"(%15, %119) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64>
    %121 = ttir.empty() : tensor<7xi64>
    %122 = "ttir.broadcast"(%120, %121) <{broadcast_dimensions = array<i64: 7>}> : (tensor<1xi64>, tensor<7xi64>) -> tensor<7xi64>
    %123 = ttir.empty() : tensor<7xi64>
    %124 = "ttir.add"(%1, %122, %123) : (tensor<7xi64>, tensor<7xi64>, tensor<7xi64>) -> tensor<7xi64>
    %125 = ttir.empty() : tensor<7xi64>
    %126 = "ttir.where"(%118, %124, %1, %125) : (tensor<7xi1>, tensor<7xi64>, tensor<7xi64>, tensor<7xi64>) -> tensor<7xi64>
    %127 = ttir.empty() : tensor<7x1xi64>
    %128 = "ttir.reshape"(%126, %127) <{shape = [7 : i32, 1 : i32]}> : (tensor<7xi64>, tensor<7x1xi64>) -> tensor<7x1xi64>
    %129 = ttir.empty() : tensor<3072xf32>
    %130 = "ttir.typecast"(%13, %129) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %131 = ttir.empty() : tensor<1x1x3072xf32>
    %132 = "ttir.reshape"(%130, %131) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %133 = ttir.empty() : tensor<1x7x3072xf32>
    %134 = "ttir.broadcast"(%132, %133) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %135 = ttir.empty() : tensor<1x7xui32>
    %136 = "ttir.typecast"(%9, %135) <{conservative_folding = false}> : (tensor<1x7xi64>, tensor<1x7xui32>) -> tensor<1x7xui32>
    %137 = ttir.empty() : tensor<7xui32>
    %138 = "ttir.reshape"(%136, %137) <{shape = [7 : i32]}> : (tensor<1x7xui32>, tensor<7xui32>) -> tensor<7xui32>
    %139 = ttir.empty() : tensor<7x3072xbf16>
    %140 = "ttir.gather"(%11, %138, %139) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3072>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<64128x3072xbf16>, tensor<7xui32>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %141 = ttir.empty() : tensor<7x3072xbf16>
    %142 = "ttir.all_reduce"(%140, %141) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %143 = ttir.empty() : tensor<1x7x3072xbf16>
    %144 = "ttir.reshape"(%142, %143) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %145 = ttir.empty() : tensor<1x7x3072xf32>
    %146 = "ttir.typecast"(%144, %145) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %147 = ttir.empty() : tensor<1x7x3072xf32>
    %148 = "ttir.pow"(%146, %116, %147) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %149 = ttir.empty() : tensor<1x7xf32>
    %150 = "ttir.sum"(%148, %149) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %151 = ttir.empty() : tensor<1x7xf32>
    %152 = "ttir.multiply"(%150, %111, %151) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %153 = ttir.empty() : tensor<1x7x1xf32>
    %154 = "ttir.reshape"(%152, %153) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %155 = ttir.empty() : tensor<1x1x1xf32>
    %156 = "ttir.reshape"(%7, %155) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %157 = ttir.empty() : tensor<1x7x1xf32>
    %158 = "ttir.broadcast"(%156, %157) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %159 = ttir.empty() : tensor<1x7x1xf32>
    %160 = "ttir.add"(%154, %158, %159) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %161 = ttir.empty() : tensor<1x7x1xf32>
    %162 = "ttir.rsqrt"(%160, %161) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %163 = ttir.empty() : tensor<1x7xf32>
    %164 = "ttir.reshape"(%162, %163) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %165 = ttir.empty() : tensor<1x7x1xf32>
    %166 = "ttir.reshape"(%164, %165) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %167 = ttir.empty() : tensor<1x7x3072xf32>
    %168 = "ttir.broadcast"(%166, %167) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %169 = ttir.empty() : tensor<1x7x3072xf32>
    %170 = "ttir.multiply"(%146, %168, %169) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %171 = ttir.empty() : tensor<1x7x3072xbf16>
    %172 = "ttir.typecast"(%170, %171) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %173 = ttir.empty() : tensor<1x7x3072xf32>
    %174 = "ttir.typecast"(%172, %173) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %175 = ttir.empty() : tensor<1x7x3072xf32>
    %176 = "ttir.multiply"(%134, %174, %175) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %177 = ttir.empty() : tensor<1x7x3072xbf16>
    %178 = "ttir.typecast"(%176, %177) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %179 = ttir.empty() : tensor<7x3072xbf16>
    %180 = "ttir.reshape"(%178, %179) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %181 = ttir.empty() : tensor<3072x512xbf16>
    %182 = "ttir.permute"(%5, %181) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %183 = "ttir.dot_general"(%180, %182) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
    %184 = ttir.empty() : tensor<1x7x4x128xbf16>
    %185 = "ttir.reshape"(%183, %184) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16>, tensor<1x7x4x128xbf16>) -> tensor<1x7x4x128xbf16>
    %186 = ttir.empty() : tensor<1x4x7x128xbf16>
    %187 = "ttir.permute"(%185, %186) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %188 = ttir.empty() : tensor<1x4x7x128xf32>
    %189 = "ttir.typecast"(%187, %188) <{conservative_folding = false}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %190 = ttir.empty() : tensor<1x64x1xf32>
    %191 = "ttir.reshape"(%3, %190) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32>, tensor<1x64x1xf32>) -> tensor<1x64x1xf32>
    %192 = ttir.empty() : tensor<7xf32>
    %193 = "ttir.typecast"(%1, %192) <{conservative_folding = false}> : (tensor<7xi64>, tensor<7xf32>) -> tensor<7xf32>
    %194 = ttir.empty() : tensor<1x1x7xf32>
    %195 = "ttir.reshape"(%193, %194) <{shape = [1 : i32, 1 : i32, 7 : i32]}> : (tensor<7xf32>, tensor<1x1x7xf32>) -> tensor<1x1x7xf32>
    %196 = "ttir.dot_general"(%191, %195) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %197 = ttir.empty() : tensor<1x7x64xf32>
    %198 = "ttir.permute"(%196, %197) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x7xf32>, tensor<1x7x64xf32>) -> tensor<1x7x64xf32>
    %199 = ttir.empty() : tensor<1x7x128xf32>
    %200 = "ttir.concat"(%198, %198, %199) <{dim = 2 : si32}> : (tensor<1x7x64xf32>, tensor<1x7x64xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %201 = ttir.empty() : tensor<1x7x128xf32>
    %202 = "ttir.cos"(%200, %201) : (tensor<1x7x128xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %203 = ttir.empty() : tensor<1x7x128xbf16>
    %204 = "ttir.typecast"(%202, %203) <{conservative_folding = false}> : (tensor<1x7x128xf32>, tensor<1x7x128xbf16>) -> tensor<1x7x128xbf16>
    %205 = ttir.empty() : tensor<1x7x128xf32>
    %206 = "ttir.typecast"(%204, %205) <{conservative_folding = false}> : (tensor<1x7x128xbf16>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %207 = ttir.empty() : tensor<1x1x7x128xf32>
    %208 = "ttir.reshape"(%206, %207) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %209 = ttir.empty() : tensor<1x4x7x128xf32>
    %210 = "ttir.broadcast"(%208, %209) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %211 = ttir.empty() : tensor<1x4x7x128xf32>
    %212 = "ttir.multiply"(%189, %210, %211) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %213 = ttir.empty() : tensor<1x4x7x128xbf16>
    %214 = "ttir.typecast"(%212, %213) <{conservative_folding = false}> : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %215 = ttir.empty() : tensor<1x4x7x64xbf16>
    %216 = "ttir.slice_static"(%187, %215) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %217 = ttir.empty() : tensor<1x4x7x64xbf16>
    %218 = "ttir.neg"(%216, %217) : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %219 = ttir.empty() : tensor<1x4x7x64xbf16>
    %220 = "ttir.slice_static"(%187, %219) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %221 = ttir.empty() : tensor<1x4x7x128xbf16>
    %222 = "ttir.concat"(%218, %220, %221) <{dim = 3 : si32}> : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %223 = ttir.empty() : tensor<1x4x7x128xf32>
    %224 = "ttir.typecast"(%222, %223) <{conservative_folding = false}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %225 = ttir.empty() : tensor<1x7x128xf32>
    %226 = "ttir.sin"(%200, %225) : (tensor<1x7x128xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %227 = ttir.empty() : tensor<1x7x128xbf16>
    %228 = "ttir.typecast"(%226, %227) <{conservative_folding = false}> : (tensor<1x7x128xf32>, tensor<1x7x128xbf16>) -> tensor<1x7x128xbf16>
    %229 = ttir.empty() : tensor<1x7x128xf32>
    %230 = "ttir.typecast"(%228, %229) <{conservative_folding = false}> : (tensor<1x7x128xbf16>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %231 = ttir.empty() : tensor<1x1x7x128xf32>
    %232 = "ttir.reshape"(%230, %231) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %233 = ttir.empty() : tensor<1x4x7x128xf32>
    %234 = "ttir.broadcast"(%232, %233) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %235 = ttir.empty() : tensor<1x4x7x128xf32>
    %236 = "ttir.multiply"(%224, %234, %235) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %237 = ttir.empty() : tensor<1x4x7x128xbf16>
    %238 = "ttir.typecast"(%236, %237) <{conservative_folding = false}> : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %239 = ttir.empty() : tensor<1x4x7x128xbf16>
    %240 = "ttir.add"(%214, %238, %239) : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %241 = ttir.empty() : tensor<1x4x128x128xbf16>
    %242 = "ttir.scatter"(%17, %128, %240, %241) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %243 = ttir.empty() : tensor<3072x512xbf16>
    %244 = "ttir.permute"(%19, %243) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %245 = "ttir.dot_general"(%180, %244) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
    %246 = ttir.empty() : tensor<1x7x4x128xbf16>
    %247 = "ttir.reshape"(%245, %246) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16>, tensor<1x7x4x128xbf16>) -> tensor<1x7x4x128xbf16>
    %248 = ttir.empty() : tensor<1x4x7x128xbf16>
    %249 = "ttir.permute"(%247, %248) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %250 = ttir.empty() : tensor<1x4x128x128xbf16>
    %251 = "ttir.scatter"(%21, %128, %249, %250) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %252 = ttir.empty() : tensor<3072xf32>
    %253 = "ttir.typecast"(%43, %252) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %254 = ttir.empty() : tensor<1x1x3072xf32>
    %255 = "ttir.reshape"(%253, %254) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %256 = ttir.empty() : tensor<1x7x3072xf32>
    %257 = "ttir.broadcast"(%255, %256) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %258 = ttir.empty() : tensor<3072x1536xbf16>
    %259 = "ttir.permute"(%37, %258) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %260 = "ttir.dot_general"(%180, %259) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<7x1536xbf16>
    %261 = ttir.empty() : tensor<1x7x12x128xbf16>
    %262 = "ttir.reshape"(%260, %261) <{shape = [1 : i32, 7 : i32, 12 : i32, 128 : i32]}> : (tensor<7x1536xbf16>, tensor<1x7x12x128xbf16>) -> tensor<1x7x12x128xbf16>
    %263 = ttir.empty() : tensor<1x12x7x128xbf16>
    %264 = "ttir.permute"(%262, %263) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x12x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %265 = ttir.empty() : tensor<1x12x7x128xf32>
    %266 = "ttir.typecast"(%264, %265) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %267 = ttir.empty() : tensor<1x1x7x128xf32>
    %268 = "ttir.reshape"(%206, %267) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %269 = ttir.empty() : tensor<1x12x7x128xf32>
    %270 = "ttir.broadcast"(%268, %269) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %271 = ttir.empty() : tensor<1x12x7x128xf32>
    %272 = "ttir.multiply"(%266, %270, %271) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %273 = ttir.empty() : tensor<1x12x7x128xbf16>
    %274 = "ttir.typecast"(%272, %273) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %275 = ttir.empty() : tensor<1x12x7x64xbf16>
    %276 = "ttir.slice_static"(%264, %275) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %277 = ttir.empty() : tensor<1x12x7x64xbf16>
    %278 = "ttir.neg"(%276, %277) : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %279 = ttir.empty() : tensor<1x12x7x64xbf16>
    %280 = "ttir.slice_static"(%264, %279) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %281 = ttir.empty() : tensor<1x12x7x128xbf16>
    %282 = "ttir.concat"(%278, %280, %281) <{dim = 3 : si32}> : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %283 = ttir.empty() : tensor<1x12x7x128xf32>
    %284 = "ttir.typecast"(%282, %283) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %285 = ttir.empty() : tensor<1x1x7x128xf32>
    %286 = "ttir.reshape"(%230, %285) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %287 = ttir.empty() : tensor<1x12x7x128xf32>
    %288 = "ttir.broadcast"(%286, %287) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %289 = ttir.empty() : tensor<1x12x7x128xf32>
    %290 = "ttir.multiply"(%284, %288, %289) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %291 = ttir.empty() : tensor<1x12x7x128xbf16>
    %292 = "ttir.typecast"(%290, %291) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %293 = ttir.empty() : tensor<1x12x7x128xbf16>
    %294 = "ttir.add"(%274, %292, %293) : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %295 = ttir.empty() : tensor<12x7x128xbf16>
    %296 = "ttir.reshape"(%294, %295) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<12x7x128xbf16>) -> tensor<12x7x128xbf16>
    %297 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %298 = "ttir.reshape"(%242, %297) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %299 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %300 = "ttir.broadcast"(%298, %299) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %301 = ttir.empty() : tensor<1x12x128x128xbf16>
    %302 = "ttir.reshape"(%300, %301) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %303 = ttir.empty() : tensor<1x12x128x128xbf16>
    %304 = "ttir.permute"(%302, %303) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %305 = ttir.empty() : tensor<12x128x128xbf16>
    %306 = "ttir.reshape"(%304, %305) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %307 = "ttir.dot_general"(%296, %306) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
    %308 = ttir.empty() : tensor<12x7x128xf32>
    %309 = "ttir.typecast"(%307, %308) <{conservative_folding = false}> : (tensor<12x7x128xbf16>, tensor<12x7x128xf32>) -> tensor<12x7x128xf32>
    %310 = ttir.empty() : tensor<1x12x7x128xf32>
    %311 = "ttir.reshape"(%309, %310) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %312 = ttir.empty() : tensor<1x1x1x1xf32>
    %313 = "ttir.reshape"(%35, %312) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>
    %314 = ttir.empty() : tensor<1x12x7x128xf32>
    %315 = "ttir.broadcast"(%313, %314) <{broadcast_dimensions = array<i64: 1, 12, 7, 128>}> : (tensor<1x1x1x1xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %316 = ttir.empty() : tensor<1x12x7x128xf32>
    %317 = "ttir.multiply"(%311, %315, %316) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %318 = ttir.empty() : tensor<1x12x7x128xbf16>
    %319 = "ttir.typecast"(%317, %318) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %320 = ttir.empty() : tensor<7x128xf32>
    %321 = "ttir.typecast"(%33, %320) <{conservative_folding = false}> : (tensor<7x128xbf16>, tensor<7x128xf32>) -> tensor<7x128xf32>
    %322 = ttir.empty() : tensor<1x128xi64>
    %323 = "ttir.reshape"(%31, %322) <{shape = [1 : i32, 128 : i32]}> : (tensor<128xi64>, tensor<1x128xi64>) -> tensor<1x128xi64>
    %324 = ttir.empty() : tensor<7x128xi64>
    %325 = "ttir.broadcast"(%323, %324) <{broadcast_dimensions = array<i64: 7, 1>}> : (tensor<1x128xi64>, tensor<7x128xi64>) -> tensor<7x128xi64>
    %326 = ttir.empty() : tensor<7x1xi64>
    %327 = "ttir.reshape"(%1, %326) <{shape = [7 : i32, 1 : i32]}> : (tensor<7xi64>, tensor<7x1xi64>) -> tensor<7x1xi64>
    %328 = ttir.empty() : tensor<7x128xi64>
    %329 = "ttir.broadcast"(%327, %328) <{broadcast_dimensions = array<i64: 1, 128>}> : (tensor<7x1xi64>, tensor<7x128xi64>) -> tensor<7x128xi64>
    %330 = ttir.empty() : tensor<7x128xi1>
    %331 = "ttir.gt"(%325, %329, %330) : (tensor<7x128xi64>, tensor<7x128xi64>, tensor<7x128xi1>) -> tensor<7x128xi1>
    %332 = ttir.empty() : tensor<7x128xf32>
    %333 = "ttir.typecast"(%331, %332) <{conservative_folding = false}> : (tensor<7x128xi1>, tensor<7x128xf32>) -> tensor<7x128xf32>
    %334 = ttir.empty() : tensor<7x128xf32>
    %335 = "ttir.multiply"(%321, %333, %334) : (tensor<7x128xf32>, tensor<7x128xf32>, tensor<7x128xf32>) -> tensor<7x128xf32>
    %336 = ttir.empty() : tensor<7x128xbf16>
    %337 = "ttir.typecast"(%335, %336) <{conservative_folding = false}> : (tensor<7x128xf32>, tensor<7x128xbf16>) -> tensor<7x128xbf16>
    %338 = ttir.empty() : tensor<1x7x128xbf16>
    %339 = "ttir.reshape"(%337, %338) <{shape = [1 : i32, 7 : i32, 128 : i32]}> : (tensor<7x128xbf16>, tensor<1x7x128xbf16>) -> tensor<1x7x128xbf16>
    %340 = ttir.empty() : tensor<1x1x7x128xbf16>
    %341 = "ttir.reshape"(%339, %340) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xbf16>, tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xbf16>
    %342 = ttir.empty() : tensor<1x12x7x128xbf16>
    %343 = "ttir.broadcast"(%341, %342) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %344 = ttir.empty() : tensor<1x12x7x128xbf16>
    %345 = "ttir.add"(%319, %343, %344) : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %346 = ttir.empty() : tensor<1x12x7x128xf32>
    %347 = "ttir.typecast"(%345, %346) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %348 = ttir.empty() : tensor<1x12x7xf32>
    %349 = "ttir.max"(%347, %348) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7xf32>) -> tensor<1x12x7xf32>
    %350 = ttir.empty() : tensor<1x12x7x1xf32>
    %351 = "ttir.reshape"(%349, %350) <{shape = [1 : i32, 12 : i32, 7 : i32, 1 : i32]}> : (tensor<1x12x7xf32>, tensor<1x12x7x1xf32>) -> tensor<1x12x7x1xf32>
    %352 = ttir.empty() : tensor<1x12x7x128xf32>
    %353 = "ttir.broadcast"(%351, %352) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x7x1xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %354 = ttir.empty() : tensor<1x12x7x128xf32>
    %355 = "ttir.subtract"(%347, %353, %354) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %356 = ttir.empty() : tensor<1x12x7x128xf32>
    %357 = "ttir.exp"(%355, %356) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %358 = ttir.empty() : tensor<1x12x7xf32>
    %359 = "ttir.sum"(%357, %358) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7xf32>) -> tensor<1x12x7xf32>
    %360 = ttir.empty() : tensor<1x12x7x1xf32>
    %361 = "ttir.reshape"(%359, %360) <{shape = [1 : i32, 12 : i32, 7 : i32, 1 : i32]}> : (tensor<1x12x7xf32>, tensor<1x12x7x1xf32>) -> tensor<1x12x7x1xf32>
    %362 = ttir.empty() : tensor<1x12x7x128xf32>
    %363 = "ttir.broadcast"(%361, %362) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x7x1xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %364 = ttir.empty() : tensor<1x12x7x128xf32>
    %365 = "ttir.div"(%357, %363, %364) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %366 = ttir.empty() : tensor<1x12x7x128xbf16>
    %367 = "ttir.typecast"(%365, %366) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %368 = ttir.empty() : tensor<12x7x128xbf16>
    %369 = "ttir.reshape"(%367, %368) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<12x7x128xbf16>) -> tensor<12x7x128xbf16>
    %370 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %371 = "ttir.reshape"(%251, %370) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %372 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %373 = "ttir.broadcast"(%371, %372) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %374 = ttir.empty() : tensor<12x128x128xbf16>
    %375 = "ttir.reshape"(%373, %374) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %376 = "ttir.dot_general"(%369, %375) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
    %377 = ttir.empty() : tensor<1x12x7x128xbf16>
    %378 = "ttir.reshape"(%376, %377) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %379 = ttir.empty() : tensor<1x7x12x128xbf16>
    %380 = "ttir.permute"(%378, %379) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x12x7x128xbf16>, tensor<1x7x12x128xbf16>) -> tensor<1x7x12x128xbf16>
    %381 = ttir.empty() : tensor<7x1536xbf16>
    %382 = "ttir.reshape"(%380, %381) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x7x12x128xbf16>, tensor<7x1536xbf16>) -> tensor<7x1536xbf16>
    %383 = ttir.empty() : tensor<1536x3072xbf16>
    %384 = "ttir.permute"(%29, %383) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %385 = "ttir.dot_general"(%382, %384) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<7x3072xbf16>
    %386 = ttir.empty() : tensor<7x3072xbf16>
    %387 = "ttir.all_reduce"(%385, %386) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %388 = ttir.empty() : tensor<1x7x3072xbf16>
    %389 = "ttir.reshape"(%387, %388) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %390 = ttir.empty() : tensor<1x7x3072xbf16>
    %391 = "ttir.add"(%144, %389, %390) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %392 = ttir.empty() : tensor<3072xf32>
    %393 = "ttir.typecast"(%39, %392) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %394 = ttir.empty() : tensor<1x1x3072xf32>
    %395 = "ttir.reshape"(%393, %394) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %396 = ttir.empty() : tensor<1x7x3072xf32>
    %397 = "ttir.broadcast"(%395, %396) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %398 = ttir.empty() : tensor<1x7x3072xf32>
    %399 = "ttir.typecast"(%391, %398) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %400 = ttir.empty() : tensor<1x7x3072xf32>
    %401 = "ttir.pow"(%399, %116, %400) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %402 = ttir.empty() : tensor<1x7xf32>
    %403 = "ttir.sum"(%401, %402) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %404 = ttir.empty() : tensor<1x7xf32>
    %405 = "ttir.multiply"(%403, %111, %404) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %406 = ttir.empty() : tensor<1x7x1xf32>
    %407 = "ttir.reshape"(%405, %406) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %408 = ttir.empty() : tensor<1x7x1xf32>
    %409 = "ttir.add"(%407, %158, %408) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %410 = ttir.empty() : tensor<1x7x1xf32>
    %411 = "ttir.rsqrt"(%409, %410) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %412 = ttir.empty() : tensor<1x7xf32>
    %413 = "ttir.reshape"(%411, %412) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %414 = ttir.empty() : tensor<1x7x1xf32>
    %415 = "ttir.reshape"(%413, %414) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %416 = ttir.empty() : tensor<1x7x3072xf32>
    %417 = "ttir.broadcast"(%415, %416) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %418 = ttir.empty() : tensor<1x7x3072xf32>
    %419 = "ttir.multiply"(%399, %417, %418) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %420 = ttir.empty() : tensor<1x7x3072xbf16>
    %421 = "ttir.typecast"(%419, %420) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %422 = ttir.empty() : tensor<1x7x3072xf32>
    %423 = "ttir.typecast"(%421, %422) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %424 = ttir.empty() : tensor<1x7x3072xf32>
    %425 = "ttir.multiply"(%397, %423, %424) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %426 = ttir.empty() : tensor<1x7x3072xbf16>
    %427 = "ttir.typecast"(%425, %426) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %428 = ttir.empty() : tensor<7x3072xbf16>
    %429 = "ttir.reshape"(%427, %428) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %430 = ttir.empty() : tensor<3072x4096xbf16>
    %431 = "ttir.permute"(%41, %430) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %432 = "ttir.dot_general"(%429, %431) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
    %433 = ttir.empty() : tensor<1x7x4096xbf16>
    %434 = "ttir.reshape"(%432, %433) <{shape = [1 : i32, 7 : i32, 4096 : i32]}> : (tensor<7x4096xbf16>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %435 = ttir.empty() : tensor<1x7x4096xf32>
    %436 = "ttir.typecast"(%434, %435) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %437 = ttir.empty() : tensor<1x7x4096xbf16>
    %438 = "ttir.sigmoid"(%434, %437) : (tensor<1x7x4096xbf16>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %439 = ttir.empty() : tensor<1x7x4096xf32>
    %440 = "ttir.typecast"(%438, %439) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %441 = ttir.empty() : tensor<1x7x4096xf32>
    %442 = "ttir.multiply"(%436, %440, %441) : (tensor<1x7x4096xf32>, tensor<1x7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %443 = ttir.empty() : tensor<1x7x4096xbf16>
    %444 = "ttir.typecast"(%442, %443) <{conservative_folding = false}> : (tensor<1x7x4096xf32>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %445 = ttir.empty() : tensor<1x7x4096xf32>
    %446 = "ttir.typecast"(%444, %445) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %447 = ttir.empty() : tensor<3072x4096xbf16>
    %448 = "ttir.permute"(%27, %447) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %449 = "ttir.dot_general"(%429, %448) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
    %450 = ttir.empty() : tensor<7x4096xf32>
    %451 = "ttir.typecast"(%449, %450) <{conservative_folding = false}> : (tensor<7x4096xbf16>, tensor<7x4096xf32>) -> tensor<7x4096xf32>
    %452 = ttir.empty() : tensor<1x7x4096xf32>
    %453 = "ttir.reshape"(%451, %452) <{shape = [1 : i32, 7 : i32, 4096 : i32]}> : (tensor<7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %454 = ttir.empty() : tensor<1x7x4096xf32>
    %455 = "ttir.multiply"(%446, %453, %454) : (tensor<1x7x4096xf32>, tensor<1x7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %456 = ttir.empty() : tensor<1x7x4096xbf16>
    %457 = "ttir.typecast"(%455, %456) <{conservative_folding = false}> : (tensor<1x7x4096xf32>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %458 = ttir.empty() : tensor<7x4096xbf16>
    %459 = "ttir.reshape"(%457, %458) <{shape = [7 : i32, 4096 : i32]}> : (tensor<1x7x4096xbf16>, tensor<7x4096xbf16>) -> tensor<7x4096xbf16>
    %460 = ttir.empty() : tensor<4096x3072xbf16>
    %461 = "ttir.permute"(%25, %460) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %462 = "ttir.dot_general"(%459, %461) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<7x3072xbf16>
    %463 = ttir.empty() : tensor<7x3072xbf16>
    %464 = "ttir.all_reduce"(%462, %463) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %465 = ttir.empty() : tensor<1x7x3072xbf16>
    %466 = "ttir.reshape"(%464, %465) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %467 = ttir.empty() : tensor<1x7x3072xbf16>
    %468 = "ttir.add"(%391, %466, %467) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %469 = ttir.empty() : tensor<1x7x3072xf32>
    %470 = "ttir.typecast"(%468, %469) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %471 = ttir.empty() : tensor<1x7x3072xf32>
    %472 = "ttir.pow"(%470, %116, %471) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %473 = ttir.empty() : tensor<1x7xf32>
    %474 = "ttir.sum"(%472, %473) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %475 = ttir.empty() : tensor<1x7xf32>
    %476 = "ttir.multiply"(%474, %111, %475) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %477 = ttir.empty() : tensor<1x7x1xf32>
    %478 = "ttir.reshape"(%476, %477) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %479 = ttir.empty() : tensor<1x7x1xf32>
    %480 = "ttir.add"(%478, %158, %479) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %481 = ttir.empty() : tensor<1x7x1xf32>
    %482 = "ttir.rsqrt"(%480, %481) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %483 = ttir.empty() : tensor<1x7xf32>
    %484 = "ttir.reshape"(%482, %483) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %485 = ttir.empty() : tensor<1x7x1xf32>
    %486 = "ttir.reshape"(%484, %485) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %487 = ttir.empty() : tensor<1x7x3072xf32>
    %488 = "ttir.broadcast"(%486, %487) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %489 = ttir.empty() : tensor<1x7x3072xf32>
    %490 = "ttir.multiply"(%470, %488, %489) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %491 = ttir.empty() : tensor<1x7x3072xbf16>
    %492 = "ttir.typecast"(%490, %491) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %493 = ttir.empty() : tensor<1x7x3072xf32>
    %494 = "ttir.typecast"(%492, %493) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %495 = ttir.empty() : tensor<1x7x3072xf32>
    %496 = "ttir.multiply"(%257, %494, %495) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %497 = ttir.empty() : tensor<1x7x3072xbf16>
    %498 = "ttir.typecast"(%496, %497) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %499 = ttir.empty() : tensor<7x3072xbf16>
    %500 = "ttir.reshape"(%498, %499) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %501 = ttir.empty() : tensor<3072x512xbf16>
    %502 = "ttir.permute"(%23, %501) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %503 = "ttir.dot_general"(%500, %502) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
    %504 = ttir.empty() : tensor<1x7x4x128xbf16>
    %505 = "ttir.reshape"(%503, %504) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16>, tensor<1x7x4x128xbf16>) -> tensor<1x7x4x128xbf16>
    %506 = ttir.empty() : tensor<1x4x7x128xbf16>
    %507 = "ttir.permute"(%505, %506) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %508 = ttir.empty() : tensor<1x4x7x128xf32>
    %509 = "ttir.typecast"(%507, %508) <{conservative_folding = false}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %510 = ttir.empty() : tensor<1x4x7x128xf32>
    %511 = "ttir.multiply"(%509, %210, %510) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %512 = ttir.empty() : tensor<1x4x7x128xbf16>
    %513 = "ttir.typecast"(%511, %512) <{conservative_folding = false}> : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %514 = ttir.empty() : tensor<1x4x7x64xbf16>
    %515 = "ttir.slice_static"(%507, %514) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %516 = ttir.empty() : tensor<1x4x7x64xbf16>
    %517 = "ttir.neg"(%515, %516) : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %518 = ttir.empty() : tensor<1x4x7x64xbf16>
    %519 = "ttir.slice_static"(%507, %518) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %520 = ttir.empty() : tensor<1x4x7x128xbf16>
    %521 = "ttir.concat"(%517, %519, %520) <{dim = 3 : si32}> : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %522 = ttir.empty() : tensor<1x4x7x128xf32>
    %523 = "ttir.typecast"(%521, %522) <{conservative_folding = false}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %524 = ttir.empty() : tensor<1x4x7x128xf32>
    %525 = "ttir.multiply"(%523, %234, %524) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %526 = ttir.empty() : tensor<1x4x7x128xbf16>
    %527 = "ttir.typecast"(%525, %526) <{conservative_folding = false}> : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %528 = ttir.empty() : tensor<1x4x7x128xbf16>
    %529 = "ttir.add"(%513, %527, %528) : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %530 = ttir.empty() : tensor<1x4x128x128xbf16>
    %531 = "ttir.scatter"(%45, %128, %529, %530) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %532 = ttir.empty() : tensor<3072x512xbf16>
    %533 = "ttir.permute"(%47, %532) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %534 = "ttir.dot_general"(%500, %533) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
    %535 = ttir.empty() : tensor<1x7x4x128xbf16>
    %536 = "ttir.reshape"(%534, %535) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16>, tensor<1x7x4x128xbf16>) -> tensor<1x7x4x128xbf16>
    %537 = ttir.empty() : tensor<1x4x7x128xbf16>
    %538 = "ttir.permute"(%536, %537) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %539 = ttir.empty() : tensor<1x4x128x128xbf16>
    %540 = "ttir.scatter"(%49, %128, %538, %539) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %541 = ttir.empty() : tensor<3072xf32>
    %542 = "ttir.typecast"(%65, %541) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %543 = ttir.empty() : tensor<1x1x3072xf32>
    %544 = "ttir.reshape"(%542, %543) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %545 = ttir.empty() : tensor<1x7x3072xf32>
    %546 = "ttir.broadcast"(%544, %545) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %547 = ttir.empty() : tensor<3072x1536xbf16>
    %548 = "ttir.permute"(%59, %547) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %549 = "ttir.dot_general"(%500, %548) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<7x1536xbf16>
    %550 = ttir.empty() : tensor<1x7x12x128xbf16>
    %551 = "ttir.reshape"(%549, %550) <{shape = [1 : i32, 7 : i32, 12 : i32, 128 : i32]}> : (tensor<7x1536xbf16>, tensor<1x7x12x128xbf16>) -> tensor<1x7x12x128xbf16>
    %552 = ttir.empty() : tensor<1x12x7x128xbf16>
    %553 = "ttir.permute"(%551, %552) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x12x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %554 = ttir.empty() : tensor<1x12x7x128xf32>
    %555 = "ttir.typecast"(%553, %554) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %556 = ttir.empty() : tensor<1x12x7x128xf32>
    %557 = "ttir.multiply"(%555, %270, %556) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %558 = ttir.empty() : tensor<1x12x7x128xbf16>
    %559 = "ttir.typecast"(%557, %558) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %560 = ttir.empty() : tensor<1x12x7x64xbf16>
    %561 = "ttir.slice_static"(%553, %560) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %562 = ttir.empty() : tensor<1x12x7x64xbf16>
    %563 = "ttir.neg"(%561, %562) : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %564 = ttir.empty() : tensor<1x12x7x64xbf16>
    %565 = "ttir.slice_static"(%553, %564) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %566 = ttir.empty() : tensor<1x12x7x128xbf16>
    %567 = "ttir.concat"(%563, %565, %566) <{dim = 3 : si32}> : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %568 = ttir.empty() : tensor<1x12x7x128xf32>
    %569 = "ttir.typecast"(%567, %568) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %570 = ttir.empty() : tensor<1x12x7x128xf32>
    %571 = "ttir.multiply"(%569, %288, %570) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %572 = ttir.empty() : tensor<1x12x7x128xbf16>
    %573 = "ttir.typecast"(%571, %572) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %574 = ttir.empty() : tensor<1x12x7x128xbf16>
    %575 = "ttir.add"(%559, %573, %574) : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %576 = ttir.empty() : tensor<12x7x128xbf16>
    %577 = "ttir.reshape"(%575, %576) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<12x7x128xbf16>) -> tensor<12x7x128xbf16>
    %578 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %579 = "ttir.reshape"(%531, %578) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %580 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %581 = "ttir.broadcast"(%579, %580) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %582 = ttir.empty() : tensor<1x12x128x128xbf16>
    %583 = "ttir.reshape"(%581, %582) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %584 = ttir.empty() : tensor<1x12x128x128xbf16>
    %585 = "ttir.permute"(%583, %584) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %586 = ttir.empty() : tensor<12x128x128xbf16>
    %587 = "ttir.reshape"(%585, %586) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %588 = "ttir.dot_general"(%577, %587) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
    %589 = ttir.empty() : tensor<12x7x128xf32>
    %590 = "ttir.typecast"(%588, %589) <{conservative_folding = false}> : (tensor<12x7x128xbf16>, tensor<12x7x128xf32>) -> tensor<12x7x128xf32>
    %591 = ttir.empty() : tensor<1x12x7x128xf32>
    %592 = "ttir.reshape"(%590, %591) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %593 = ttir.empty() : tensor<1x12x7x128xf32>
    %594 = "ttir.multiply"(%592, %315, %593) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %595 = ttir.empty() : tensor<1x12x7x128xbf16>
    %596 = "ttir.typecast"(%594, %595) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %597 = ttir.empty() : tensor<1x12x7x128xbf16>
    %598 = "ttir.add"(%596, %343, %597) : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %599 = ttir.empty() : tensor<1x12x7x128xf32>
    %600 = "ttir.typecast"(%598, %599) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %601 = ttir.empty() : tensor<1x12x7xf32>
    %602 = "ttir.max"(%600, %601) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7xf32>) -> tensor<1x12x7xf32>
    %603 = ttir.empty() : tensor<1x12x7x1xf32>
    %604 = "ttir.reshape"(%602, %603) <{shape = [1 : i32, 12 : i32, 7 : i32, 1 : i32]}> : (tensor<1x12x7xf32>, tensor<1x12x7x1xf32>) -> tensor<1x12x7x1xf32>
    %605 = ttir.empty() : tensor<1x12x7x128xf32>
    %606 = "ttir.broadcast"(%604, %605) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x7x1xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %607 = ttir.empty() : tensor<1x12x7x128xf32>
    %608 = "ttir.subtract"(%600, %606, %607) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %609 = ttir.empty() : tensor<1x12x7x128xf32>
    %610 = "ttir.exp"(%608, %609) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %611 = ttir.empty() : tensor<1x12x7xf32>
    %612 = "ttir.sum"(%610, %611) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7xf32>) -> tensor<1x12x7xf32>
    %613 = ttir.empty() : tensor<1x12x7x1xf32>
    %614 = "ttir.reshape"(%612, %613) <{shape = [1 : i32, 12 : i32, 7 : i32, 1 : i32]}> : (tensor<1x12x7xf32>, tensor<1x12x7x1xf32>) -> tensor<1x12x7x1xf32>
    %615 = ttir.empty() : tensor<1x12x7x128xf32>
    %616 = "ttir.broadcast"(%614, %615) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x7x1xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %617 = ttir.empty() : tensor<1x12x7x128xf32>
    %618 = "ttir.div"(%610, %616, %617) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %619 = ttir.empty() : tensor<1x12x7x128xbf16>
    %620 = "ttir.typecast"(%618, %619) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %621 = ttir.empty() : tensor<12x7x128xbf16>
    %622 = "ttir.reshape"(%620, %621) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<12x7x128xbf16>) -> tensor<12x7x128xbf16>
    %623 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %624 = "ttir.reshape"(%540, %623) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %625 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %626 = "ttir.broadcast"(%624, %625) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %627 = ttir.empty() : tensor<12x128x128xbf16>
    %628 = "ttir.reshape"(%626, %627) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %629 = "ttir.dot_general"(%622, %628) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
    %630 = ttir.empty() : tensor<1x12x7x128xbf16>
    %631 = "ttir.reshape"(%629, %630) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %632 = ttir.empty() : tensor<1x7x12x128xbf16>
    %633 = "ttir.permute"(%631, %632) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x12x7x128xbf16>, tensor<1x7x12x128xbf16>) -> tensor<1x7x12x128xbf16>
    %634 = ttir.empty() : tensor<7x1536xbf16>
    %635 = "ttir.reshape"(%633, %634) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x7x12x128xbf16>, tensor<7x1536xbf16>) -> tensor<7x1536xbf16>
    %636 = ttir.empty() : tensor<1536x3072xbf16>
    %637 = "ttir.permute"(%57, %636) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %638 = "ttir.dot_general"(%635, %637) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<7x3072xbf16>
    %639 = ttir.empty() : tensor<7x3072xbf16>
    %640 = "ttir.all_reduce"(%638, %639) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %641 = ttir.empty() : tensor<1x7x3072xbf16>
    %642 = "ttir.reshape"(%640, %641) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %643 = ttir.empty() : tensor<1x7x3072xbf16>
    %644 = "ttir.add"(%468, %642, %643) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %645 = ttir.empty() : tensor<3072xf32>
    %646 = "ttir.typecast"(%61, %645) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %647 = ttir.empty() : tensor<1x1x3072xf32>
    %648 = "ttir.reshape"(%646, %647) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %649 = ttir.empty() : tensor<1x7x3072xf32>
    %650 = "ttir.broadcast"(%648, %649) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %651 = ttir.empty() : tensor<1x7x3072xf32>
    %652 = "ttir.typecast"(%644, %651) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %653 = ttir.empty() : tensor<1x7x3072xf32>
    %654 = "ttir.pow"(%652, %116, %653) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %655 = ttir.empty() : tensor<1x7xf32>
    %656 = "ttir.sum"(%654, %655) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %657 = ttir.empty() : tensor<1x7xf32>
    %658 = "ttir.multiply"(%656, %111, %657) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %659 = ttir.empty() : tensor<1x7x1xf32>
    %660 = "ttir.reshape"(%658, %659) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %661 = ttir.empty() : tensor<1x7x1xf32>
    %662 = "ttir.add"(%660, %158, %661) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %663 = ttir.empty() : tensor<1x7x1xf32>
    %664 = "ttir.rsqrt"(%662, %663) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %665 = ttir.empty() : tensor<1x7xf32>
    %666 = "ttir.reshape"(%664, %665) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %667 = ttir.empty() : tensor<1x7x1xf32>
    %668 = "ttir.reshape"(%666, %667) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %669 = ttir.empty() : tensor<1x7x3072xf32>
    %670 = "ttir.broadcast"(%668, %669) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %671 = ttir.empty() : tensor<1x7x3072xf32>
    %672 = "ttir.multiply"(%652, %670, %671) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %673 = ttir.empty() : tensor<1x7x3072xbf16>
    %674 = "ttir.typecast"(%672, %673) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %675 = ttir.empty() : tensor<1x7x3072xf32>
    %676 = "ttir.typecast"(%674, %675) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %677 = ttir.empty() : tensor<1x7x3072xf32>
    %678 = "ttir.multiply"(%650, %676, %677) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %679 = ttir.empty() : tensor<1x7x3072xbf16>
    %680 = "ttir.typecast"(%678, %679) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %681 = ttir.empty() : tensor<7x3072xbf16>
    %682 = "ttir.reshape"(%680, %681) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %683 = ttir.empty() : tensor<3072x4096xbf16>
    %684 = "ttir.permute"(%63, %683) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %685 = "ttir.dot_general"(%682, %684) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
    %686 = ttir.empty() : tensor<1x7x4096xbf16>
    %687 = "ttir.reshape"(%685, %686) <{shape = [1 : i32, 7 : i32, 4096 : i32]}> : (tensor<7x4096xbf16>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %688 = ttir.empty() : tensor<1x7x4096xf32>
    %689 = "ttir.typecast"(%687, %688) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %690 = ttir.empty() : tensor<1x7x4096xbf16>
    %691 = "ttir.sigmoid"(%687, %690) : (tensor<1x7x4096xbf16>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %692 = ttir.empty() : tensor<1x7x4096xf32>
    %693 = "ttir.typecast"(%691, %692) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %694 = ttir.empty() : tensor<1x7x4096xf32>
    %695 = "ttir.multiply"(%689, %693, %694) : (tensor<1x7x4096xf32>, tensor<1x7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %696 = ttir.empty() : tensor<1x7x4096xbf16>
    %697 = "ttir.typecast"(%695, %696) <{conservative_folding = false}> : (tensor<1x7x4096xf32>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %698 = ttir.empty() : tensor<1x7x4096xf32>
    %699 = "ttir.typecast"(%697, %698) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %700 = ttir.empty() : tensor<3072x4096xbf16>
    %701 = "ttir.permute"(%55, %700) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %702 = "ttir.dot_general"(%682, %701) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
    %703 = ttir.empty() : tensor<7x4096xf32>
    %704 = "ttir.typecast"(%702, %703) <{conservative_folding = false}> : (tensor<7x4096xbf16>, tensor<7x4096xf32>) -> tensor<7x4096xf32>
    %705 = ttir.empty() : tensor<1x7x4096xf32>
    %706 = "ttir.reshape"(%704, %705) <{shape = [1 : i32, 7 : i32, 4096 : i32]}> : (tensor<7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %707 = ttir.empty() : tensor<1x7x4096xf32>
    %708 = "ttir.multiply"(%699, %706, %707) : (tensor<1x7x4096xf32>, tensor<1x7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %709 = ttir.empty() : tensor<1x7x4096xbf16>
    %710 = "ttir.typecast"(%708, %709) <{conservative_folding = false}> : (tensor<1x7x4096xf32>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %711 = ttir.empty() : tensor<7x4096xbf16>
    %712 = "ttir.reshape"(%710, %711) <{shape = [7 : i32, 4096 : i32]}> : (tensor<1x7x4096xbf16>, tensor<7x4096xbf16>) -> tensor<7x4096xbf16>
    %713 = ttir.empty() : tensor<4096x3072xbf16>
    %714 = "ttir.permute"(%53, %713) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %715 = "ttir.dot_general"(%712, %714) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<7x3072xbf16>
    %716 = ttir.empty() : tensor<7x3072xbf16>
    %717 = "ttir.all_reduce"(%715, %716) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %718 = ttir.empty() : tensor<1x7x3072xbf16>
    %719 = "ttir.reshape"(%717, %718) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %720 = ttir.empty() : tensor<1x7x3072xbf16>
    %721 = "ttir.add"(%644, %719, %720) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %722 = ttir.empty() : tensor<1x7x3072xf32>
    %723 = "ttir.typecast"(%721, %722) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %724 = ttir.empty() : tensor<1x7x3072xf32>
    %725 = "ttir.pow"(%723, %116, %724) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %726 = ttir.empty() : tensor<1x7xf32>
    %727 = "ttir.sum"(%725, %726) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %728 = ttir.empty() : tensor<1x7xf32>
    %729 = "ttir.multiply"(%727, %111, %728) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %730 = ttir.empty() : tensor<1x7x1xf32>
    %731 = "ttir.reshape"(%729, %730) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %732 = ttir.empty() : tensor<1x7x1xf32>
    %733 = "ttir.add"(%731, %158, %732) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %734 = ttir.empty() : tensor<1x7x1xf32>
    %735 = "ttir.rsqrt"(%733, %734) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %736 = ttir.empty() : tensor<1x7xf32>
    %737 = "ttir.reshape"(%735, %736) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %738 = ttir.empty() : tensor<1x7x1xf32>
    %739 = "ttir.reshape"(%737, %738) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %740 = ttir.empty() : tensor<1x7x3072xf32>
    %741 = "ttir.broadcast"(%739, %740) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %742 = ttir.empty() : tensor<1x7x3072xf32>
    %743 = "ttir.multiply"(%723, %741, %742) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %744 = ttir.empty() : tensor<1x7x3072xbf16>
    %745 = "ttir.typecast"(%743, %744) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %746 = ttir.empty() : tensor<1x7x3072xf32>
    %747 = "ttir.typecast"(%745, %746) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %748 = ttir.empty() : tensor<1x7x3072xf32>
    %749 = "ttir.multiply"(%546, %747, %748) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %750 = ttir.empty() : tensor<1x7x3072xbf16>
    %751 = "ttir.typecast"(%749, %750) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %752 = ttir.empty() : tensor<7x3072xbf16>
    %753 = "ttir.reshape"(%751, %752) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %754 = ttir.empty() : tensor<3072x512xbf16>
    %755 = "ttir.permute"(%51, %754) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %756 = "ttir.dot_general"(%753, %755) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
    %757 = ttir.empty() : tensor<1x7x4x128xbf16>
    %758 = "ttir.reshape"(%756, %757) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16>, tensor<1x7x4x128xbf16>) -> tensor<1x7x4x128xbf16>
    %759 = ttir.empty() : tensor<1x4x7x128xbf16>
    %760 = "ttir.permute"(%758, %759) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %761 = ttir.empty() : tensor<1x4x7x128xf32>
    %762 = "ttir.typecast"(%760, %761) <{conservative_folding = false}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %763 = ttir.empty() : tensor<1x4x7x128xf32>
    %764 = "ttir.multiply"(%762, %210, %763) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %765 = ttir.empty() : tensor<1x4x7x128xbf16>
    %766 = "ttir.typecast"(%764, %765) <{conservative_folding = false}> : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %767 = ttir.empty() : tensor<1x4x7x64xbf16>
    %768 = "ttir.slice_static"(%760, %767) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %769 = ttir.empty() : tensor<1x4x7x64xbf16>
    %770 = "ttir.neg"(%768, %769) : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %771 = ttir.empty() : tensor<1x4x7x64xbf16>
    %772 = "ttir.slice_static"(%760, %771) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %773 = ttir.empty() : tensor<1x4x7x128xbf16>
    %774 = "ttir.concat"(%770, %772, %773) <{dim = 3 : si32}> : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %775 = ttir.empty() : tensor<1x4x7x128xf32>
    %776 = "ttir.typecast"(%774, %775) <{conservative_folding = false}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %777 = ttir.empty() : tensor<1x4x7x128xf32>
    %778 = "ttir.multiply"(%776, %234, %777) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %779 = ttir.empty() : tensor<1x4x7x128xbf16>
    %780 = "ttir.typecast"(%778, %779) <{conservative_folding = false}> : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %781 = ttir.empty() : tensor<1x4x7x128xbf16>
    %782 = "ttir.add"(%766, %780, %781) : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %783 = ttir.empty() : tensor<1x4x128x128xbf16>
    %784 = "ttir.scatter"(%67, %128, %782, %783) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %785 = ttir.empty() : tensor<3072x512xbf16>
    %786 = "ttir.permute"(%69, %785) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %787 = "ttir.dot_general"(%753, %786) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
    %788 = ttir.empty() : tensor<1x7x4x128xbf16>
    %789 = "ttir.reshape"(%787, %788) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16>, tensor<1x7x4x128xbf16>) -> tensor<1x7x4x128xbf16>
    %790 = ttir.empty() : tensor<1x4x7x128xbf16>
    %791 = "ttir.permute"(%789, %790) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %792 = ttir.empty() : tensor<1x4x128x128xbf16>
    %793 = "ttir.scatter"(%71, %128, %791, %792) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %794 = ttir.empty() : tensor<3072xf32>
    %795 = "ttir.typecast"(%87, %794) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %796 = ttir.empty() : tensor<1x1x3072xf32>
    %797 = "ttir.reshape"(%795, %796) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %798 = ttir.empty() : tensor<1x7x3072xf32>
    %799 = "ttir.broadcast"(%797, %798) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %800 = ttir.empty() : tensor<3072x1536xbf16>
    %801 = "ttir.permute"(%81, %800) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %802 = "ttir.dot_general"(%753, %801) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<7x1536xbf16>
    %803 = ttir.empty() : tensor<1x7x12x128xbf16>
    %804 = "ttir.reshape"(%802, %803) <{shape = [1 : i32, 7 : i32, 12 : i32, 128 : i32]}> : (tensor<7x1536xbf16>, tensor<1x7x12x128xbf16>) -> tensor<1x7x12x128xbf16>
    %805 = ttir.empty() : tensor<1x12x7x128xbf16>
    %806 = "ttir.permute"(%804, %805) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x12x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %807 = ttir.empty() : tensor<1x12x7x128xf32>
    %808 = "ttir.typecast"(%806, %807) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %809 = ttir.empty() : tensor<1x12x7x128xf32>
    %810 = "ttir.multiply"(%808, %270, %809) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %811 = ttir.empty() : tensor<1x12x7x128xbf16>
    %812 = "ttir.typecast"(%810, %811) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %813 = ttir.empty() : tensor<1x12x7x64xbf16>
    %814 = "ttir.slice_static"(%806, %813) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %815 = ttir.empty() : tensor<1x12x7x64xbf16>
    %816 = "ttir.neg"(%814, %815) : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %817 = ttir.empty() : tensor<1x12x7x64xbf16>
    %818 = "ttir.slice_static"(%806, %817) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %819 = ttir.empty() : tensor<1x12x7x128xbf16>
    %820 = "ttir.concat"(%816, %818, %819) <{dim = 3 : si32}> : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %821 = ttir.empty() : tensor<1x12x7x128xf32>
    %822 = "ttir.typecast"(%820, %821) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %823 = ttir.empty() : tensor<1x12x7x128xf32>
    %824 = "ttir.multiply"(%822, %288, %823) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %825 = ttir.empty() : tensor<1x12x7x128xbf16>
    %826 = "ttir.typecast"(%824, %825) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %827 = ttir.empty() : tensor<1x12x7x128xbf16>
    %828 = "ttir.add"(%812, %826, %827) : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %829 = ttir.empty() : tensor<12x7x128xbf16>
    %830 = "ttir.reshape"(%828, %829) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<12x7x128xbf16>) -> tensor<12x7x128xbf16>
    %831 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %832 = "ttir.reshape"(%784, %831) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %833 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %834 = "ttir.broadcast"(%832, %833) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %835 = ttir.empty() : tensor<1x12x128x128xbf16>
    %836 = "ttir.reshape"(%834, %835) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %837 = ttir.empty() : tensor<1x12x128x128xbf16>
    %838 = "ttir.permute"(%836, %837) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %839 = ttir.empty() : tensor<12x128x128xbf16>
    %840 = "ttir.reshape"(%838, %839) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %841 = "ttir.dot_general"(%830, %840) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
    %842 = ttir.empty() : tensor<12x7x128xf32>
    %843 = "ttir.typecast"(%841, %842) <{conservative_folding = false}> : (tensor<12x7x128xbf16>, tensor<12x7x128xf32>) -> tensor<12x7x128xf32>
    %844 = ttir.empty() : tensor<1x12x7x128xf32>
    %845 = "ttir.reshape"(%843, %844) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %846 = ttir.empty() : tensor<1x12x7x128xf32>
    %847 = "ttir.multiply"(%845, %315, %846) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %848 = ttir.empty() : tensor<1x12x7x128xbf16>
    %849 = "ttir.typecast"(%847, %848) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %850 = ttir.empty() : tensor<1x12x7x128xbf16>
    %851 = "ttir.add"(%849, %343, %850) : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %852 = ttir.empty() : tensor<1x12x7x128xf32>
    %853 = "ttir.typecast"(%851, %852) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %854 = ttir.empty() : tensor<1x12x7xf32>
    %855 = "ttir.max"(%853, %854) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7xf32>) -> tensor<1x12x7xf32>
    %856 = ttir.empty() : tensor<1x12x7x1xf32>
    %857 = "ttir.reshape"(%855, %856) <{shape = [1 : i32, 12 : i32, 7 : i32, 1 : i32]}> : (tensor<1x12x7xf32>, tensor<1x12x7x1xf32>) -> tensor<1x12x7x1xf32>
    %858 = ttir.empty() : tensor<1x12x7x128xf32>
    %859 = "ttir.broadcast"(%857, %858) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x7x1xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %860 = ttir.empty() : tensor<1x12x7x128xf32>
    %861 = "ttir.subtract"(%853, %859, %860) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %862 = ttir.empty() : tensor<1x12x7x128xf32>
    %863 = "ttir.exp"(%861, %862) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %864 = ttir.empty() : tensor<1x12x7xf32>
    %865 = "ttir.sum"(%863, %864) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7xf32>) -> tensor<1x12x7xf32>
    %866 = ttir.empty() : tensor<1x12x7x1xf32>
    %867 = "ttir.reshape"(%865, %866) <{shape = [1 : i32, 12 : i32, 7 : i32, 1 : i32]}> : (tensor<1x12x7xf32>, tensor<1x12x7x1xf32>) -> tensor<1x12x7x1xf32>
    %868 = ttir.empty() : tensor<1x12x7x128xf32>
    %869 = "ttir.broadcast"(%867, %868) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x7x1xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %870 = ttir.empty() : tensor<1x12x7x128xf32>
    %871 = "ttir.div"(%863, %869, %870) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %872 = ttir.empty() : tensor<1x12x7x128xbf16>
    %873 = "ttir.typecast"(%871, %872) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %874 = ttir.empty() : tensor<12x7x128xbf16>
    %875 = "ttir.reshape"(%873, %874) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<12x7x128xbf16>) -> tensor<12x7x128xbf16>
    %876 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %877 = "ttir.reshape"(%793, %876) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %878 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %879 = "ttir.broadcast"(%877, %878) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %880 = ttir.empty() : tensor<12x128x128xbf16>
    %881 = "ttir.reshape"(%879, %880) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %882 = "ttir.dot_general"(%875, %881) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
    %883 = ttir.empty() : tensor<1x12x7x128xbf16>
    %884 = "ttir.reshape"(%882, %883) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %885 = ttir.empty() : tensor<1x7x12x128xbf16>
    %886 = "ttir.permute"(%884, %885) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x12x7x128xbf16>, tensor<1x7x12x128xbf16>) -> tensor<1x7x12x128xbf16>
    %887 = ttir.empty() : tensor<7x1536xbf16>
    %888 = "ttir.reshape"(%886, %887) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x7x12x128xbf16>, tensor<7x1536xbf16>) -> tensor<7x1536xbf16>
    %889 = ttir.empty() : tensor<1536x3072xbf16>
    %890 = "ttir.permute"(%79, %889) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %891 = "ttir.dot_general"(%888, %890) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<7x3072xbf16>
    %892 = ttir.empty() : tensor<7x3072xbf16>
    %893 = "ttir.all_reduce"(%891, %892) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %894 = ttir.empty() : tensor<1x7x3072xbf16>
    %895 = "ttir.reshape"(%893, %894) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %896 = ttir.empty() : tensor<1x7x3072xbf16>
    %897 = "ttir.add"(%721, %895, %896) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %898 = ttir.empty() : tensor<3072xf32>
    %899 = "ttir.typecast"(%83, %898) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %900 = ttir.empty() : tensor<1x1x3072xf32>
    %901 = "ttir.reshape"(%899, %900) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %902 = ttir.empty() : tensor<1x7x3072xf32>
    %903 = "ttir.broadcast"(%901, %902) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %904 = ttir.empty() : tensor<1x7x3072xf32>
    %905 = "ttir.typecast"(%897, %904) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %906 = ttir.empty() : tensor<1x7x3072xf32>
    %907 = "ttir.pow"(%905, %116, %906) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %908 = ttir.empty() : tensor<1x7xf32>
    %909 = "ttir.sum"(%907, %908) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %910 = ttir.empty() : tensor<1x7xf32>
    %911 = "ttir.multiply"(%909, %111, %910) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %912 = ttir.empty() : tensor<1x7x1xf32>
    %913 = "ttir.reshape"(%911, %912) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %914 = ttir.empty() : tensor<1x7x1xf32>
    %915 = "ttir.add"(%913, %158, %914) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %916 = ttir.empty() : tensor<1x7x1xf32>
    %917 = "ttir.rsqrt"(%915, %916) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %918 = ttir.empty() : tensor<1x7xf32>
    %919 = "ttir.reshape"(%917, %918) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %920 = ttir.empty() : tensor<1x7x1xf32>
    %921 = "ttir.reshape"(%919, %920) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %922 = ttir.empty() : tensor<1x7x3072xf32>
    %923 = "ttir.broadcast"(%921, %922) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %924 = ttir.empty() : tensor<1x7x3072xf32>
    %925 = "ttir.multiply"(%905, %923, %924) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %926 = ttir.empty() : tensor<1x7x3072xbf16>
    %927 = "ttir.typecast"(%925, %926) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %928 = ttir.empty() : tensor<1x7x3072xf32>
    %929 = "ttir.typecast"(%927, %928) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %930 = ttir.empty() : tensor<1x7x3072xf32>
    %931 = "ttir.multiply"(%903, %929, %930) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %932 = ttir.empty() : tensor<1x7x3072xbf16>
    %933 = "ttir.typecast"(%931, %932) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %934 = ttir.empty() : tensor<7x3072xbf16>
    %935 = "ttir.reshape"(%933, %934) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %936 = ttir.empty() : tensor<3072x4096xbf16>
    %937 = "ttir.permute"(%85, %936) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %938 = "ttir.dot_general"(%935, %937) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
    %939 = ttir.empty() : tensor<1x7x4096xbf16>
    %940 = "ttir.reshape"(%938, %939) <{shape = [1 : i32, 7 : i32, 4096 : i32]}> : (tensor<7x4096xbf16>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %941 = ttir.empty() : tensor<1x7x4096xf32>
    %942 = "ttir.typecast"(%940, %941) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %943 = ttir.empty() : tensor<1x7x4096xbf16>
    %944 = "ttir.sigmoid"(%940, %943) : (tensor<1x7x4096xbf16>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %945 = ttir.empty() : tensor<1x7x4096xf32>
    %946 = "ttir.typecast"(%944, %945) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %947 = ttir.empty() : tensor<1x7x4096xf32>
    %948 = "ttir.multiply"(%942, %946, %947) : (tensor<1x7x4096xf32>, tensor<1x7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %949 = ttir.empty() : tensor<1x7x4096xbf16>
    %950 = "ttir.typecast"(%948, %949) <{conservative_folding = false}> : (tensor<1x7x4096xf32>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %951 = ttir.empty() : tensor<1x7x4096xf32>
    %952 = "ttir.typecast"(%950, %951) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %953 = ttir.empty() : tensor<3072x4096xbf16>
    %954 = "ttir.permute"(%77, %953) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %955 = "ttir.dot_general"(%935, %954) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
    %956 = ttir.empty() : tensor<7x4096xf32>
    %957 = "ttir.typecast"(%955, %956) <{conservative_folding = false}> : (tensor<7x4096xbf16>, tensor<7x4096xf32>) -> tensor<7x4096xf32>
    %958 = ttir.empty() : tensor<1x7x4096xf32>
    %959 = "ttir.reshape"(%957, %958) <{shape = [1 : i32, 7 : i32, 4096 : i32]}> : (tensor<7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %960 = ttir.empty() : tensor<1x7x4096xf32>
    %961 = "ttir.multiply"(%952, %959, %960) : (tensor<1x7x4096xf32>, tensor<1x7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %962 = ttir.empty() : tensor<1x7x4096xbf16>
    %963 = "ttir.typecast"(%961, %962) <{conservative_folding = false}> : (tensor<1x7x4096xf32>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %964 = ttir.empty() : tensor<7x4096xbf16>
    %965 = "ttir.reshape"(%963, %964) <{shape = [7 : i32, 4096 : i32]}> : (tensor<1x7x4096xbf16>, tensor<7x4096xbf16>) -> tensor<7x4096xbf16>
    %966 = ttir.empty() : tensor<4096x3072xbf16>
    %967 = "ttir.permute"(%75, %966) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %968 = "ttir.dot_general"(%965, %967) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<7x3072xbf16>
    %969 = ttir.empty() : tensor<7x3072xbf16>
    %970 = "ttir.all_reduce"(%968, %969) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %971 = ttir.empty() : tensor<1x7x3072xbf16>
    %972 = "ttir.reshape"(%970, %971) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %973 = ttir.empty() : tensor<1x7x3072xbf16>
    %974 = "ttir.add"(%897, %972, %973) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %975 = ttir.empty() : tensor<1x7x3072xf32>
    %976 = "ttir.typecast"(%974, %975) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %977 = ttir.empty() : tensor<1x7x3072xf32>
    %978 = "ttir.pow"(%976, %116, %977) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %979 = ttir.empty() : tensor<1x7xf32>
    %980 = "ttir.sum"(%978, %979) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %981 = ttir.empty() : tensor<1x7xf32>
    %982 = "ttir.multiply"(%980, %111, %981) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %983 = ttir.empty() : tensor<1x7x1xf32>
    %984 = "ttir.reshape"(%982, %983) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %985 = ttir.empty() : tensor<1x7x1xf32>
    %986 = "ttir.add"(%984, %158, %985) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %987 = ttir.empty() : tensor<1x7x1xf32>
    %988 = "ttir.rsqrt"(%986, %987) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %989 = ttir.empty() : tensor<1x7xf32>
    %990 = "ttir.reshape"(%988, %989) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %991 = ttir.empty() : tensor<1x7x1xf32>
    %992 = "ttir.reshape"(%990, %991) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %993 = ttir.empty() : tensor<1x7x3072xf32>
    %994 = "ttir.broadcast"(%992, %993) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %995 = ttir.empty() : tensor<1x7x3072xf32>
    %996 = "ttir.multiply"(%976, %994, %995) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %997 = ttir.empty() : tensor<1x7x3072xbf16>
    %998 = "ttir.typecast"(%996, %997) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %999 = ttir.empty() : tensor<1x7x3072xf32>
    %1000 = "ttir.typecast"(%998, %999) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1001 = ttir.empty() : tensor<1x7x3072xf32>
    %1002 = "ttir.multiply"(%799, %1000, %1001) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1003 = ttir.empty() : tensor<1x7x3072xbf16>
    %1004 = "ttir.typecast"(%1002, %1003) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %1005 = ttir.empty() : tensor<7x3072xbf16>
    %1006 = "ttir.reshape"(%1004, %1005) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %1007 = ttir.empty() : tensor<3072x512xbf16>
    %1008 = "ttir.permute"(%73, %1007) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %1009 = "ttir.dot_general"(%1006, %1008) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
    %1010 = ttir.empty() : tensor<1x7x4x128xbf16>
    %1011 = "ttir.reshape"(%1009, %1010) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16>, tensor<1x7x4x128xbf16>) -> tensor<1x7x4x128xbf16>
    %1012 = ttir.empty() : tensor<1x4x7x128xbf16>
    %1013 = "ttir.permute"(%1011, %1012) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %1014 = ttir.empty() : tensor<1x4x7x128xf32>
    %1015 = "ttir.typecast"(%1013, %1014) <{conservative_folding = false}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %1016 = ttir.empty() : tensor<1x4x7x128xf32>
    %1017 = "ttir.multiply"(%1015, %210, %1016) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %1018 = ttir.empty() : tensor<1x4x7x128xbf16>
    %1019 = "ttir.typecast"(%1017, %1018) <{conservative_folding = false}> : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %1020 = ttir.empty() : tensor<1x4x7x64xbf16>
    %1021 = "ttir.slice_static"(%1013, %1020) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %1022 = ttir.empty() : tensor<1x4x7x64xbf16>
    %1023 = "ttir.neg"(%1021, %1022) : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %1024 = ttir.empty() : tensor<1x4x7x64xbf16>
    %1025 = "ttir.slice_static"(%1013, %1024) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %1026 = ttir.empty() : tensor<1x4x7x128xbf16>
    %1027 = "ttir.concat"(%1023, %1025, %1026) <{dim = 3 : si32}> : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %1028 = ttir.empty() : tensor<1x4x7x128xf32>
    %1029 = "ttir.typecast"(%1027, %1028) <{conservative_folding = false}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %1030 = ttir.empty() : tensor<1x4x7x128xf32>
    %1031 = "ttir.multiply"(%1029, %234, %1030) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %1032 = ttir.empty() : tensor<1x4x7x128xbf16>
    %1033 = "ttir.typecast"(%1031, %1032) <{conservative_folding = false}> : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %1034 = ttir.empty() : tensor<1x4x7x128xbf16>
    %1035 = "ttir.add"(%1019, %1033, %1034) : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %1036 = ttir.empty() : tensor<1x4x128x128xbf16>
    %1037 = "ttir.scatter"(%89, %128, %1035, %1036) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %1038 = ttir.empty() : tensor<3072x512xbf16>
    %1039 = "ttir.permute"(%91, %1038) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %1040 = "ttir.dot_general"(%1006, %1039) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
    %1041 = ttir.empty() : tensor<1x7x4x128xbf16>
    %1042 = "ttir.reshape"(%1040, %1041) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16>, tensor<1x7x4x128xbf16>) -> tensor<1x7x4x128xbf16>
    %1043 = ttir.empty() : tensor<1x4x7x128xbf16>
    %1044 = "ttir.permute"(%1042, %1043) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %1045 = ttir.empty() : tensor<1x4x128x128xbf16>
    %1046 = "ttir.scatter"(%93, %128, %1044, %1045) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %1047 = ttir.empty() : tensor<3072xf32>
    %1048 = "ttir.typecast"(%107, %1047) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %1049 = ttir.empty() : tensor<1x1x3072xf32>
    %1050 = "ttir.reshape"(%1048, %1049) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1051 = ttir.empty() : tensor<1x7x3072xf32>
    %1052 = "ttir.broadcast"(%1050, %1051) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1053 = ttir.empty() : tensor<3072x1536xbf16>
    %1054 = "ttir.permute"(%101, %1053) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %1055 = "ttir.dot_general"(%1006, %1054) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<7x1536xbf16>
    %1056 = ttir.empty() : tensor<1x7x12x128xbf16>
    %1057 = "ttir.reshape"(%1055, %1056) <{shape = [1 : i32, 7 : i32, 12 : i32, 128 : i32]}> : (tensor<7x1536xbf16>, tensor<1x7x12x128xbf16>) -> tensor<1x7x12x128xbf16>
    %1058 = ttir.empty() : tensor<1x12x7x128xbf16>
    %1059 = "ttir.permute"(%1057, %1058) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x12x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %1060 = ttir.empty() : tensor<1x12x7x128xf32>
    %1061 = "ttir.typecast"(%1059, %1060) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %1062 = ttir.empty() : tensor<1x12x7x128xf32>
    %1063 = "ttir.multiply"(%1061, %270, %1062) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %1064 = ttir.empty() : tensor<1x12x7x128xbf16>
    %1065 = "ttir.typecast"(%1063, %1064) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %1066 = ttir.empty() : tensor<1x12x7x64xbf16>
    %1067 = "ttir.slice_static"(%1059, %1066) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %1068 = ttir.empty() : tensor<1x12x7x64xbf16>
    %1069 = "ttir.neg"(%1067, %1068) : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %1070 = ttir.empty() : tensor<1x12x7x64xbf16>
    %1071 = "ttir.slice_static"(%1059, %1070) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %1072 = ttir.empty() : tensor<1x12x7x128xbf16>
    %1073 = "ttir.concat"(%1069, %1071, %1072) <{dim = 3 : si32}> : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %1074 = ttir.empty() : tensor<1x12x7x128xf32>
    %1075 = "ttir.typecast"(%1073, %1074) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %1076 = ttir.empty() : tensor<1x12x7x128xf32>
    %1077 = "ttir.multiply"(%1075, %288, %1076) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %1078 = ttir.empty() : tensor<1x12x7x128xbf16>
    %1079 = "ttir.typecast"(%1077, %1078) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %1080 = ttir.empty() : tensor<1x12x7x128xbf16>
    %1081 = "ttir.add"(%1065, %1079, %1080) : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %1082 = ttir.empty() : tensor<12x7x128xbf16>
    %1083 = "ttir.reshape"(%1081, %1082) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<12x7x128xbf16>) -> tensor<12x7x128xbf16>
    %1084 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %1085 = "ttir.reshape"(%1037, %1084) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %1086 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %1087 = "ttir.broadcast"(%1085, %1086) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %1088 = ttir.empty() : tensor<1x12x128x128xbf16>
    %1089 = "ttir.reshape"(%1087, %1088) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %1090 = ttir.empty() : tensor<1x12x128x128xbf16>
    %1091 = "ttir.permute"(%1089, %1090) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %1092 = ttir.empty() : tensor<12x128x128xbf16>
    %1093 = "ttir.reshape"(%1091, %1092) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %1094 = "ttir.dot_general"(%1083, %1093) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
    %1095 = ttir.empty() : tensor<12x7x128xf32>
    %1096 = "ttir.typecast"(%1094, %1095) <{conservative_folding = false}> : (tensor<12x7x128xbf16>, tensor<12x7x128xf32>) -> tensor<12x7x128xf32>
    %1097 = ttir.empty() : tensor<1x12x7x128xf32>
    %1098 = "ttir.reshape"(%1096, %1097) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %1099 = ttir.empty() : tensor<1x12x7x128xf32>
    %1100 = "ttir.multiply"(%1098, %315, %1099) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %1101 = ttir.empty() : tensor<1x12x7x128xbf16>
    %1102 = "ttir.typecast"(%1100, %1101) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %1103 = ttir.empty() : tensor<1x12x7x128xbf16>
    %1104 = "ttir.add"(%1102, %343, %1103) : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %1105 = ttir.empty() : tensor<1x12x7x128xf32>
    %1106 = "ttir.typecast"(%1104, %1105) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %1107 = ttir.empty() : tensor<1x12x7xf32>
    %1108 = "ttir.max"(%1106, %1107) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7xf32>) -> tensor<1x12x7xf32>
    %1109 = ttir.empty() : tensor<1x12x7x1xf32>
    %1110 = "ttir.reshape"(%1108, %1109) <{shape = [1 : i32, 12 : i32, 7 : i32, 1 : i32]}> : (tensor<1x12x7xf32>, tensor<1x12x7x1xf32>) -> tensor<1x12x7x1xf32>
    %1111 = ttir.empty() : tensor<1x12x7x128xf32>
    %1112 = "ttir.broadcast"(%1110, %1111) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x7x1xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %1113 = ttir.empty() : tensor<1x12x7x128xf32>
    %1114 = "ttir.subtract"(%1106, %1112, %1113) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %1115 = ttir.empty() : tensor<1x12x7x128xf32>
    %1116 = "ttir.exp"(%1114, %1115) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %1117 = ttir.empty() : tensor<1x12x7xf32>
    %1118 = "ttir.sum"(%1116, %1117) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7xf32>) -> tensor<1x12x7xf32>
    %1119 = ttir.empty() : tensor<1x12x7x1xf32>
    %1120 = "ttir.reshape"(%1118, %1119) <{shape = [1 : i32, 12 : i32, 7 : i32, 1 : i32]}> : (tensor<1x12x7xf32>, tensor<1x12x7x1xf32>) -> tensor<1x12x7x1xf32>
    %1121 = ttir.empty() : tensor<1x12x7x128xf32>
    %1122 = "ttir.broadcast"(%1120, %1121) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x7x1xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %1123 = ttir.empty() : tensor<1x12x7x128xf32>
    %1124 = "ttir.div"(%1116, %1122, %1123) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %1125 = ttir.empty() : tensor<1x12x7x128xbf16>
    %1126 = "ttir.typecast"(%1124, %1125) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %1127 = ttir.empty() : tensor<12x7x128xbf16>
    %1128 = "ttir.reshape"(%1126, %1127) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<12x7x128xbf16>) -> tensor<12x7x128xbf16>
    %1129 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %1130 = "ttir.reshape"(%1046, %1129) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %1131 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %1132 = "ttir.broadcast"(%1130, %1131) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %1133 = ttir.empty() : tensor<12x128x128xbf16>
    %1134 = "ttir.reshape"(%1132, %1133) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %1135 = "ttir.dot_general"(%1128, %1134) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
    %1136 = ttir.empty() : tensor<1x12x7x128xbf16>
    %1137 = "ttir.reshape"(%1135, %1136) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %1138 = ttir.empty() : tensor<1x7x12x128xbf16>
    %1139 = "ttir.permute"(%1137, %1138) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x12x7x128xbf16>, tensor<1x7x12x128xbf16>) -> tensor<1x7x12x128xbf16>
    %1140 = ttir.empty() : tensor<7x1536xbf16>
    %1141 = "ttir.reshape"(%1139, %1140) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x7x12x128xbf16>, tensor<7x1536xbf16>) -> tensor<7x1536xbf16>
    %1142 = ttir.empty() : tensor<1536x3072xbf16>
    %1143 = "ttir.permute"(%99, %1142) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %1144 = "ttir.dot_general"(%1141, %1143) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<7x3072xbf16>
    %1145 = ttir.empty() : tensor<7x3072xbf16>
    %1146 = "ttir.all_reduce"(%1144, %1145) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %1147 = ttir.empty() : tensor<1x7x3072xbf16>
    %1148 = "ttir.reshape"(%1146, %1147) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %1149 = ttir.empty() : tensor<1x7x3072xbf16>
    %1150 = "ttir.add"(%974, %1148, %1149) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %1151 = ttir.empty() : tensor<3072xf32>
    %1152 = "ttir.typecast"(%103, %1151) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %1153 = ttir.empty() : tensor<1x1x3072xf32>
    %1154 = "ttir.reshape"(%1152, %1153) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1155 = ttir.empty() : tensor<1x7x3072xf32>
    %1156 = "ttir.broadcast"(%1154, %1155) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1157 = ttir.empty() : tensor<1x7x3072xf32>
    %1158 = "ttir.typecast"(%1150, %1157) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1159 = ttir.empty() : tensor<1x7x3072xf32>
    %1160 = "ttir.pow"(%1158, %116, %1159) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1161 = ttir.empty() : tensor<1x7xf32>
    %1162 = "ttir.sum"(%1160, %1161) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %1163 = ttir.empty() : tensor<1x7xf32>
    %1164 = "ttir.multiply"(%1162, %111, %1163) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %1165 = ttir.empty() : tensor<1x7x1xf32>
    %1166 = "ttir.reshape"(%1164, %1165) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %1167 = ttir.empty() : tensor<1x7x1xf32>
    %1168 = "ttir.add"(%1166, %158, %1167) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %1169 = ttir.empty() : tensor<1x7x1xf32>
    %1170 = "ttir.rsqrt"(%1168, %1169) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %1171 = ttir.empty() : tensor<1x7xf32>
    %1172 = "ttir.reshape"(%1170, %1171) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %1173 = ttir.empty() : tensor<1x7x1xf32>
    %1174 = "ttir.reshape"(%1172, %1173) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %1175 = ttir.empty() : tensor<1x7x3072xf32>
    %1176 = "ttir.broadcast"(%1174, %1175) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1177 = ttir.empty() : tensor<1x7x3072xf32>
    %1178 = "ttir.multiply"(%1158, %1176, %1177) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1179 = ttir.empty() : tensor<1x7x3072xbf16>
    %1180 = "ttir.typecast"(%1178, %1179) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %1181 = ttir.empty() : tensor<1x7x3072xf32>
    %1182 = "ttir.typecast"(%1180, %1181) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1183 = ttir.empty() : tensor<1x7x3072xf32>
    %1184 = "ttir.multiply"(%1156, %1182, %1183) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1185 = ttir.empty() : tensor<1x7x3072xbf16>
    %1186 = "ttir.typecast"(%1184, %1185) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %1187 = ttir.empty() : tensor<7x3072xbf16>
    %1188 = "ttir.reshape"(%1186, %1187) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %1189 = ttir.empty() : tensor<3072x4096xbf16>
    %1190 = "ttir.permute"(%105, %1189) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %1191 = "ttir.dot_general"(%1188, %1190) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
    %1192 = ttir.empty() : tensor<1x7x4096xbf16>
    %1193 = "ttir.reshape"(%1191, %1192) <{shape = [1 : i32, 7 : i32, 4096 : i32]}> : (tensor<7x4096xbf16>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %1194 = ttir.empty() : tensor<1x7x4096xf32>
    %1195 = "ttir.typecast"(%1193, %1194) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %1196 = ttir.empty() : tensor<1x7x4096xbf16>
    %1197 = "ttir.sigmoid"(%1193, %1196) : (tensor<1x7x4096xbf16>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %1198 = ttir.empty() : tensor<1x7x4096xf32>
    %1199 = "ttir.typecast"(%1197, %1198) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %1200 = ttir.empty() : tensor<1x7x4096xf32>
    %1201 = "ttir.multiply"(%1195, %1199, %1200) : (tensor<1x7x4096xf32>, tensor<1x7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %1202 = ttir.empty() : tensor<1x7x4096xbf16>
    %1203 = "ttir.typecast"(%1201, %1202) <{conservative_folding = false}> : (tensor<1x7x4096xf32>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %1204 = ttir.empty() : tensor<1x7x4096xf32>
    %1205 = "ttir.typecast"(%1203, %1204) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %1206 = ttir.empty() : tensor<3072x4096xbf16>
    %1207 = "ttir.permute"(%97, %1206) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %1208 = "ttir.dot_general"(%1188, %1207) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
    %1209 = ttir.empty() : tensor<7x4096xf32>
    %1210 = "ttir.typecast"(%1208, %1209) <{conservative_folding = false}> : (tensor<7x4096xbf16>, tensor<7x4096xf32>) -> tensor<7x4096xf32>
    %1211 = ttir.empty() : tensor<1x7x4096xf32>
    %1212 = "ttir.reshape"(%1210, %1211) <{shape = [1 : i32, 7 : i32, 4096 : i32]}> : (tensor<7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %1213 = ttir.empty() : tensor<1x7x4096xf32>
    %1214 = "ttir.multiply"(%1205, %1212, %1213) : (tensor<1x7x4096xf32>, tensor<1x7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %1215 = ttir.empty() : tensor<1x7x4096xbf16>
    %1216 = "ttir.typecast"(%1214, %1215) <{conservative_folding = false}> : (tensor<1x7x4096xf32>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %1217 = ttir.empty() : tensor<7x4096xbf16>
    %1218 = "ttir.reshape"(%1216, %1217) <{shape = [7 : i32, 4096 : i32]}> : (tensor<1x7x4096xbf16>, tensor<7x4096xbf16>) -> tensor<7x4096xbf16>
    %1219 = ttir.empty() : tensor<4096x3072xbf16>
    %1220 = "ttir.permute"(%95, %1219) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %1221 = "ttir.dot_general"(%1218, %1220) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<7x3072xbf16>
    %1222 = ttir.empty() : tensor<7x3072xbf16>
    %1223 = "ttir.all_reduce"(%1221, %1222) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %1224 = ttir.empty() : tensor<1x7x3072xbf16>
    %1225 = "ttir.reshape"(%1223, %1224) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %1226 = ttir.empty() : tensor<1x7x3072xbf16>
    %1227 = "ttir.add"(%1150, %1225, %1226) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %1228 = ttir.empty() : tensor<1x7x3072xf32>
    %1229 = "ttir.typecast"(%1227, %1228) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1230 = ttir.empty() : tensor<1x7x3072xf32>
    %1231 = "ttir.pow"(%1229, %116, %1230) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1232 = ttir.empty() : tensor<1x7xf32>
    %1233 = "ttir.sum"(%1231, %1232) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %1234 = ttir.empty() : tensor<1x7xf32>
    %1235 = "ttir.multiply"(%1233, %111, %1234) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %1236 = ttir.empty() : tensor<1x7x1xf32>
    %1237 = "ttir.reshape"(%1235, %1236) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %1238 = ttir.empty() : tensor<1x7x1xf32>
    %1239 = "ttir.add"(%1237, %158, %1238) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %1240 = ttir.empty() : tensor<1x7x1xf32>
    %1241 = "ttir.rsqrt"(%1239, %1240) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %1242 = ttir.empty() : tensor<1x7xf32>
    %1243 = "ttir.reshape"(%1241, %1242) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %1244 = ttir.empty() : tensor<1x7x1xf32>
    %1245 = "ttir.reshape"(%1243, %1244) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %1246 = ttir.empty() : tensor<1x7x3072xf32>
    %1247 = "ttir.broadcast"(%1245, %1246) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1248 = ttir.empty() : tensor<1x7x3072xf32>
    %1249 = "ttir.multiply"(%1229, %1247, %1248) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1250 = ttir.empty() : tensor<1x7x3072xbf16>
    %1251 = "ttir.typecast"(%1249, %1250) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %1252 = ttir.empty() : tensor<1x7x3072xf32>
    %1253 = "ttir.typecast"(%1251, %1252) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1254 = ttir.empty() : tensor<1x7x3072xf32>
    %1255 = "ttir.multiply"(%1052, %1253, %1254) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %1256 = ttir.empty() : tensor<1x7x3072xbf16>
    %1257 = "ttir.typecast"(%1255, %1256) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %1258 = ttir.empty() : tensor<7x3072xbf16>
    %1259 = "ttir.reshape"(%1257, %1258) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %1260 = ttir.empty() : tensor<3072x64128xbf16>
    %1261 = "ttir.permute"(%11, %1260) <{permutation = array<i64: 1, 0>}> : (tensor<64128x3072xbf16>, tensor<3072x64128xbf16>) -> tensor<3072x64128xbf16>
    %1262 = "ttir.dot_general"(%1259, %1261) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x64128xbf16>) -> tensor<7x64128xbf16>
    %1263 = ttir.empty() : tensor<1x7x64128xbf16>
    %1264 = "ttir.reshape"(%1262, %1263) <{shape = [1 : i32, 7 : i32, 64128 : i32]}> : (tensor<7x64128xbf16>, tensor<1x7x64128xbf16>) -> tensor<1x7x64128xbf16>
    %1265 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1266 = "ttir.mesh_shard"(%242, %1265) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1267 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1268 = "ttir.mesh_shard"(%251, %1267) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1269 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1270 = "ttir.mesh_shard"(%531, %1269) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1271 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1272 = "ttir.mesh_shard"(%540, %1271) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1273 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1274 = "ttir.mesh_shard"(%784, %1273) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1275 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1276 = "ttir.mesh_shard"(%793, %1275) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1277 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1278 = "ttir.mesh_shard"(%1037, %1277) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1279 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1280 = "ttir.mesh_shard"(%1046, %1279) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1281 = ttir.empty() : tensor<7x128256xbf16>
    %1282 = "ttir.mesh_shard"(%1262, %1281) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<7x64128xbf16>, tensor<7x128256xbf16>) -> tensor<7x128256xbf16>
    %1283 = ttir.empty() : tensor<1x7x128256xbf16>
    %1284 = "ttir.mesh_shard"(%1264, %1283) <{shard_dims = array<i64: -1, 2>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x7x64128xbf16>, tensor<1x7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %1266, %1268, %1270, %1272, %1274, %1276, %1278, %1280, %1282, %1284 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>
  }
}
module @SyncTensorsGraph.1220 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.1220 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99776, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184736, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99776, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193056, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main_const_eval_0() -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 2.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        return %2 : tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
      }
      func.func @main(%arg0: tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg3: tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg4: tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg5: tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg6: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg7: tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg8: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg9: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg10: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg11: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg12: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg13: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg14: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg15: tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg16: tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg17: tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg18: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg19: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg20: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg21: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg22: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg23: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg24: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg25: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg26: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg27: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg28: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg29: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg30: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg31: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg32: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg33: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg34: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg35: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg36: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg37: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg38: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg39: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg40: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg41: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg42: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg43: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg44: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg45: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg46: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg47: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg48: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg49: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg50: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg51: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg52: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg53: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<7x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x7x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %1 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %2 = "ttnn.full"(%1) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 3.25520843E-4 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<1x7>}> : (!ttnn.device) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %3 = "ttnn.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %4 = "ttnn.mesh_shard"(%arg1, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %5 = "ttnn.mesh_shard"(%arg2, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %6 = "ttnn.mesh_shard"(%arg3, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %7 = "ttnn.mesh_shard"(%arg4, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %8 = "ttnn.mesh_shard"(%arg5, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg5) <{force = false}> : (tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %9 = "ttnn.mesh_shard"(%arg6, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %10 = "ttnn.mesh_shard"(%arg8, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg8) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %11 = "ttnn.mesh_shard"(%arg9, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %12 = "ttnn.mesh_shard"(%arg10, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %13 = "ttnn.mesh_shard"(%arg11, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg11) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %14 = "ttnn.mesh_shard"(%arg12, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg12) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %15 = "ttnn.mesh_shard"(%arg13, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg13) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %16 = "ttnn.mesh_shard"(%arg14, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg14) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %17 = "ttnn.mesh_shard"(%arg15, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg15) <{force = false}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %18 = "ttnn.mesh_shard"(%arg16, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg16) <{force = false}> : (tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %19 = "ttnn.mesh_shard"(%arg17, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg17) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %20 = "ttnn.mesh_shard"(%arg18, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg18) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %21 = "ttnn.mesh_shard"(%arg19, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg19) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %22 = "ttnn.mesh_shard"(%arg20, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg20) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %23 = "ttnn.mesh_shard"(%arg21, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg21) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %24 = "ttnn.mesh_shard"(%arg22, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg22) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %25 = "ttnn.mesh_shard"(%arg23, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg23) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %26 = "ttnn.mesh_shard"(%arg24, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg24) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %27 = "ttnn.mesh_shard"(%arg25, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg25) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %28 = "ttnn.mesh_shard"(%arg26, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg26) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %29 = "ttnn.mesh_shard"(%arg27, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg27) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %30 = "ttnn.mesh_shard"(%arg28, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg28) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %31 = "ttnn.mesh_shard"(%arg29, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg29) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %32 = "ttnn.mesh_shard"(%arg30, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg30) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %33 = "ttnn.mesh_shard"(%arg31, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg31) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %34 = "ttnn.mesh_shard"(%arg32, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg32) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %35 = "ttnn.mesh_shard"(%arg33, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg33) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %36 = "ttnn.mesh_shard"(%arg34, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg34) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %37 = "ttnn.mesh_shard"(%arg35, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg35) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %38 = "ttnn.mesh_shard"(%arg36, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg36) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %39 = "ttnn.mesh_shard"(%arg37, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg37) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %40 = "ttnn.mesh_shard"(%arg38, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg38) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %41 = "ttnn.mesh_shard"(%arg39, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg39) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %42 = "ttnn.mesh_shard"(%arg40, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg40) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %43 = "ttnn.mesh_shard"(%arg41, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg41) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %44 = "ttnn.mesh_shard"(%arg42, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg42) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %45 = "ttnn.mesh_shard"(%arg43, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg43) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %46 = "ttnn.mesh_shard"(%arg44, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg44) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %47 = "ttnn.mesh_shard"(%arg45, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg45) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %48 = "ttnn.mesh_shard"(%arg46, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg46) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %49 = "ttnn.mesh_shard"(%arg47, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg47) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %50 = "ttnn.mesh_shard"(%arg48, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg48) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %51 = "ttnn.mesh_shard"(%arg49, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg49) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %52 = "ttnn.mesh_shard"(%arg50, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg50) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %53 = "ttnn.mesh_shard"(%arg51, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg51) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %54 = "ttnn.mesh_shard"(%arg52, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg52) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %55 = "ttnn.mesh_shard"(%arg53, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg53) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %56 = "ttnn.typecast"(%9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %57 = "ttnn.reshape"(%56) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%56) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %58 = "ttnn.typecast"(%7) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %59 = "ttnn.reshape"(%58) <{shape = [7 : i32]}> : (tensor<1x7xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%58) <{force = false}> : (tensor<1x7xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %60 = "ttnn.from_device"(%59) : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%59) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %61 = "ttnn.to_layout"(%60) <{layout = #ttnn.layout<row_major>}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%60) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>) -> ()
        %62 = "ttnn.to_device"(%61, %1) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%61) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<system_memory>>>>) -> ()
        %63 = "ttnn.embedding"(%62, %8) : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%62) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %64 = "ttnn.reshape"(%63) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%63) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %65 = "ttnn.reduce_scatter"(%64, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%64) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %66 = "ttnn.all_gather"(%65, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%65) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %67 = "ttnn.reshape"(%66) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%66) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %68 = "ttnn.typecast"(%67) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %69 = "ttnn.reshape"(%68) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %70 = "ttnn.pow"(%69, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%69) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %71 = "ttnn.sum"(%70) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%70) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %72 = "ttnn.multiply"(%71, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%71) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %73 = "ttnn.reshape"(%72) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%72) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %74 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %75 = "ttnn.add"(%73, %74) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%73) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %76 = "ttnn.rsqrt"(%75) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%75) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %77 = "ttnn.multiply"(%68, %76) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%76) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%68) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %78 = "ttnn.multiply"(%57, %77) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%77) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%57) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %79 = "ttnn.typecast"(%78) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%78) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %80 = "ttnn.matmul"(%79, %5) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %81 = "ttnn.reshape"(%80) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%80) <{force = false}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %82 = "ttnn.permute"(%81) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%81) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %83 = "ttnn.typecast"(%82) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %84 = "ttnn.reshape"(%4) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %85 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %86 = "ttnn.reshape"(%85) <{shape = [1 : i32, 1 : i32, 7 : i32]}> : (tensor<7xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%85) <{force = false}> : (tensor<7xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %87 = "ttnn.matmul"(%84, %86) <{transpose_a = false, transpose_b = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%86) <{force = false}> : (tensor<1x1x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%84) <{force = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %88 = "ttnn.permute"(%87) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%87) <{force = false}> : (tensor<1x64x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %89 = "ttnn.concat"(%88, %88) <{dim = 2 : si32}> : (tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%88) <{force = false}> : (tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %90 = "ttnn.cos"(%89) : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %91 = "ttnn.reshape"(%90) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %92 = "ttnn.multiply"(%83, %91) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%83) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %93 = "ttnn.typecast"(%92) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%92) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %94 = "ttnn.slice_static"(%82) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %95 = "ttnn.neg"(%94) : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%94) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %96 = "ttnn.slice_static"(%82) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%82) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %97 = "ttnn.concat"(%95, %96) <{dim = 3 : si32}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%96) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%95) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %98 = "ttnn.typecast"(%97) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%97) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %99 = "ttnn.sin"(%89) : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%89) <{force = false}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %100 = "ttnn.reshape"(%99) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %101 = "ttnn.multiply"(%98, %100) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%98) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %102 = "ttnn.typecast"(%101) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%101) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %103 = "ttnn.add"(%93, %102) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%102) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%93) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.fill_cache"(%10, %103) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%103) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %104 = "ttnn.matmul"(%79, %11) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %105 = "ttnn.reshape"(%104) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%104) <{force = false}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %106 = "ttnn.permute"(%105) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%105) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.fill_cache"(%12, %106) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%106) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %107 = "ttnn.typecast"(%23) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %108 = "ttnn.reshape"(%107) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%107) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %109 = "ttnn.matmul"(%79, %20) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%79) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %110 = "ttnn.reshape"(%109) <{shape = [1 : i32, 7 : i32, 12 : i32, 128 : i32]}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%109) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %111 = "ttnn.permute"(%110) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%110) <{force = false}> : (tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %112 = "ttnn.typecast"(%111) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %113 = "ttnn.reshape"(%112) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%112) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %114 = "ttnn.multiply"(%113, %90) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%113) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %115 = "ttnn.typecast"(%114) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%114) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %116 = "ttnn.slice_static"(%111) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %117 = "ttnn.neg"(%116) : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%116) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %118 = "ttnn.reshape"(%117) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%117) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %119 = "ttnn.slice_static"(%111) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%111) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %120 = "ttnn.reshape"(%119) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%119) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %121 = "ttnn.concat"(%118, %120) <{dim = 2 : si32}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%120) <{force = false}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%118) <{force = false}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %122 = "ttnn.typecast"(%121) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%121) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %123 = "ttnn.multiply"(%122, %99) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%122) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %124 = "ttnn.typecast"(%123) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%123) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %125 = "ttnn.add"(%115, %124) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%124) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%115) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %126 = "ttnn.reshape"(%10) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %127 = "ttnn.repeat"(%126) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%126) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %128 = "ttnn.reshape"(%127) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%127) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %129 = "ttnn.permute"(%128) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%128) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %130 = "ttnn.reshape"(%129) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%129) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %131 = "ttnn.matmul"(%125, %130) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%130) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%125) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %132 = "ttnn.typecast"(%131) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%131) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %133 = "ttnn.reshape"(%132) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%132) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %134 = "ttnn.reshape"(%19) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %135 = "ttnn.multiply"(%133, %134) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%133) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %136 = "ttnn.typecast"(%135) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%135) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %137 = "ttnn.typecast"(%18) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %138 = "ttnn.reshape"(%137) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<7x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%137) <{force = false}> : (tensor<7x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %139 = "ttnn.reshape"(%17) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %140 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32, 7 : i32, 1 : i32]}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %141 = "ttnn.typecast"(%139) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%139) <{force = false}> : (tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %142 = "ttnn.typecast"(%140) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%140) <{force = false}> : (tensor<1x1x7x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %143 = "ttnn.gt"(%141, %142) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%142) <{force = false}> : (tensor<1x1x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%141) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %144 = "ttnn.typecast"(%143) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%143) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %145 = "ttnn.typecast"(%144) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%144) <{force = false}> : (tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %146 = "ttnn.multiply"(%138, %145) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%145) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%138) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %147 = "ttnn.typecast"(%146) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%146) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %148 = "ttnn.add"(%136, %147) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%136) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %149 = "ttnn.typecast"(%148) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%148) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %150 = "ttnn.max"(%149) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %151 = "ttnn.neg"(%150) : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%150) <{force = false}> : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %152 = "ttnn.add"(%149, %151) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%151) <{force = false}> : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%149) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %153 = "ttnn.softmax"(%152) <{dimension = 3 : si32}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%152) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %154 = "ttnn.typecast"(%153) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%153) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %155 = "ttnn.reshape"(%154) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%154) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %156 = "ttnn.reshape"(%12) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %157 = "ttnn.repeat"(%156) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%156) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %158 = "ttnn.reshape"(%157) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%157) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %159 = "ttnn.matmul"(%155, %158) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%158) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%155) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %160 = "ttnn.reshape"(%159) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%159) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %161 = "ttnn.concatenate_heads"(%160) : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%160) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %162 = "ttnn.reshape"(%161) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%161) <{force = false}> : (tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %163 = "ttnn.matmul"(%162, %16) <{transpose_a = false, transpose_b = true}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%162) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %164 = "ttnn.reshape"(%163) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%163) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %165 = "ttnn.reduce_scatter"(%164, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%164) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %166 = "ttnn.all_gather"(%165, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%165) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %167 = "ttnn.reshape"(%166) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%166) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %168 = "ttnn.add"(%67, %167) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%167) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%67) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %169 = "ttnn.typecast"(%21) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %170 = "ttnn.reshape"(%169) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%169) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %171 = "ttnn.typecast"(%168) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %172 = "ttnn.reshape"(%171) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %173 = "ttnn.pow"(%172, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%172) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %174 = "ttnn.sum"(%173) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%173) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %175 = "ttnn.multiply"(%174, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%174) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %176 = "ttnn.reshape"(%175) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%175) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %177 = "ttnn.add"(%176, %74) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%176) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %178 = "ttnn.rsqrt"(%177) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%177) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %179 = "ttnn.multiply"(%171, %178) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%178) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%171) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %180 = "ttnn.multiply"(%170, %179) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%179) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%170) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %181 = "ttnn.typecast"(%180) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%180) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %182 = "ttnn.matmul"(%181, %22) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%22) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %183 = "ttnn.typecast"(%182) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %184 = "ttnn.sigmoid"(%182) : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%182) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %185 = "ttnn.typecast"(%184) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%184) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %186 = "ttnn.multiply"(%183, %185) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%185) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%183) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %187 = "ttnn.matmul"(%181, %15) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%181) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %188 = "ttnn.typecast"(%187) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%187) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %189 = "ttnn.multiply"(%186, %188) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%188) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%186) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %190 = "ttnn.typecast"(%189) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%189) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %191 = "ttnn.matmul"(%190, %14) <{transpose_a = false, transpose_b = true}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%190) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %192 = "ttnn.reshape"(%191) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%191) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %193 = "ttnn.reduce_scatter"(%192, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%192) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %194 = "ttnn.all_gather"(%193, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%193) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %195 = "ttnn.reshape"(%194) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%194) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %196 = "ttnn.add"(%168, %195) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%195) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%168) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %197 = "ttnn.typecast"(%196) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %198 = "ttnn.reshape"(%197) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %199 = "ttnn.pow"(%198, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%198) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %200 = "ttnn.sum"(%199) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%199) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %201 = "ttnn.multiply"(%200, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%200) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %202 = "ttnn.reshape"(%201) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%201) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %203 = "ttnn.add"(%202, %74) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%202) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %204 = "ttnn.rsqrt"(%203) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%203) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %205 = "ttnn.multiply"(%197, %204) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%204) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%197) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %206 = "ttnn.multiply"(%108, %205) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%205) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%108) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %207 = "ttnn.typecast"(%206) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%206) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %208 = "ttnn.matmul"(%207, %13) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %209 = "ttnn.reshape"(%208) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%208) <{force = false}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %210 = "ttnn.permute"(%209) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%209) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %211 = "ttnn.typecast"(%210) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %212 = "ttnn.multiply"(%211, %91) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%211) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %213 = "ttnn.typecast"(%212) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%212) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %214 = "ttnn.slice_static"(%210) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %215 = "ttnn.neg"(%214) : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%214) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %216 = "ttnn.slice_static"(%210) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%210) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %217 = "ttnn.concat"(%215, %216) <{dim = 3 : si32}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%216) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%215) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %218 = "ttnn.typecast"(%217) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%217) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %219 = "ttnn.multiply"(%218, %100) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%218) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %220 = "ttnn.typecast"(%219) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%219) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %221 = "ttnn.add"(%213, %220) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%220) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%213) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.fill_cache"(%24, %221) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%221) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %222 = "ttnn.matmul"(%207, %25) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%25) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %223 = "ttnn.reshape"(%222) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%222) <{force = false}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %224 = "ttnn.permute"(%223) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%223) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.fill_cache"(%26, %224) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%224) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %225 = "ttnn.typecast"(%34) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%34) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %226 = "ttnn.reshape"(%225) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%225) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %227 = "ttnn.matmul"(%207, %31) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%207) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%31) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %228 = "ttnn.reshape"(%227) <{shape = [1 : i32, 7 : i32, 12 : i32, 128 : i32]}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%227) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %229 = "ttnn.permute"(%228) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%228) <{force = false}> : (tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %230 = "ttnn.typecast"(%229) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %231 = "ttnn.reshape"(%230) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%230) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %232 = "ttnn.multiply"(%231, %90) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%231) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %233 = "ttnn.typecast"(%232) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%232) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %234 = "ttnn.slice_static"(%229) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %235 = "ttnn.neg"(%234) : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%234) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %236 = "ttnn.reshape"(%235) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%235) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %237 = "ttnn.slice_static"(%229) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%229) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %238 = "ttnn.reshape"(%237) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%237) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %239 = "ttnn.concat"(%236, %238) <{dim = 2 : si32}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%238) <{force = false}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%236) <{force = false}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %240 = "ttnn.typecast"(%239) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%239) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %241 = "ttnn.multiply"(%240, %99) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%240) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %242 = "ttnn.typecast"(%241) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%241) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %243 = "ttnn.add"(%233, %242) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%242) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%233) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %244 = "ttnn.reshape"(%24) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %245 = "ttnn.repeat"(%244) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%244) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %246 = "ttnn.reshape"(%245) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%245) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %247 = "ttnn.permute"(%246) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%246) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %248 = "ttnn.reshape"(%247) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%247) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %249 = "ttnn.matmul"(%243, %248) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%248) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%243) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %250 = "ttnn.typecast"(%249) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%249) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %251 = "ttnn.reshape"(%250) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%250) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %252 = "ttnn.multiply"(%251, %134) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%251) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %253 = "ttnn.typecast"(%252) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%252) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %254 = "ttnn.add"(%253, %147) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%253) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %255 = "ttnn.typecast"(%254) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%254) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %256 = "ttnn.max"(%255) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %257 = "ttnn.neg"(%256) : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%256) <{force = false}> : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %258 = "ttnn.add"(%255, %257) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%257) <{force = false}> : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%255) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %259 = "ttnn.softmax"(%258) <{dimension = 3 : si32}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%258) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %260 = "ttnn.typecast"(%259) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%259) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %261 = "ttnn.reshape"(%260) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%260) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %262 = "ttnn.reshape"(%26) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %263 = "ttnn.repeat"(%262) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%262) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %264 = "ttnn.reshape"(%263) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%263) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %265 = "ttnn.matmul"(%261, %264) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%264) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%261) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %266 = "ttnn.reshape"(%265) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%265) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %267 = "ttnn.concatenate_heads"(%266) : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%266) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %268 = "ttnn.reshape"(%267) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%267) <{force = false}> : (tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %269 = "ttnn.matmul"(%268, %30) <{transpose_a = false, transpose_b = true}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%268) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%30) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %270 = "ttnn.reshape"(%269) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%269) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %271 = "ttnn.reduce_scatter"(%270, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%270) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %272 = "ttnn.all_gather"(%271, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%271) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %273 = "ttnn.reshape"(%272) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%272) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %274 = "ttnn.add"(%196, %273) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%273) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%196) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %275 = "ttnn.typecast"(%32) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%32) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %276 = "ttnn.reshape"(%275) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%275) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %277 = "ttnn.typecast"(%274) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %278 = "ttnn.reshape"(%277) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %279 = "ttnn.pow"(%278, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%278) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %280 = "ttnn.sum"(%279) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%279) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %281 = "ttnn.multiply"(%280, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%280) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %282 = "ttnn.reshape"(%281) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%281) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %283 = "ttnn.add"(%282, %74) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%282) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %284 = "ttnn.rsqrt"(%283) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%283) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %285 = "ttnn.multiply"(%277, %284) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%284) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%277) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %286 = "ttnn.multiply"(%276, %285) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%285) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%276) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %287 = "ttnn.typecast"(%286) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%286) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %288 = "ttnn.matmul"(%287, %33) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%33) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %289 = "ttnn.typecast"(%288) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %290 = "ttnn.sigmoid"(%288) : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%288) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %291 = "ttnn.typecast"(%290) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%290) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %292 = "ttnn.multiply"(%289, %291) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%291) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%289) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %293 = "ttnn.matmul"(%287, %29) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%287) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%29) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %294 = "ttnn.typecast"(%293) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%293) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %295 = "ttnn.multiply"(%292, %294) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%294) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%292) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %296 = "ttnn.typecast"(%295) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%295) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %297 = "ttnn.matmul"(%296, %28) <{transpose_a = false, transpose_b = true}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%296) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%28) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %298 = "ttnn.reshape"(%297) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%297) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %299 = "ttnn.reduce_scatter"(%298, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%298) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %300 = "ttnn.all_gather"(%299, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%299) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %301 = "ttnn.reshape"(%300) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%300) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %302 = "ttnn.add"(%274, %301) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%301) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%274) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %303 = "ttnn.typecast"(%302) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %304 = "ttnn.reshape"(%303) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %305 = "ttnn.pow"(%304, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%304) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %306 = "ttnn.sum"(%305) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%305) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %307 = "ttnn.multiply"(%306, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%306) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %308 = "ttnn.reshape"(%307) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%307) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %309 = "ttnn.add"(%308, %74) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%308) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %310 = "ttnn.rsqrt"(%309) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%309) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %311 = "ttnn.multiply"(%303, %310) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%310) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%303) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %312 = "ttnn.multiply"(%226, %311) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%311) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%226) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %313 = "ttnn.typecast"(%312) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%312) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %314 = "ttnn.matmul"(%313, %27) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%27) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %315 = "ttnn.reshape"(%314) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%314) <{force = false}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %316 = "ttnn.permute"(%315) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%315) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %317 = "ttnn.typecast"(%316) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %318 = "ttnn.multiply"(%317, %91) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%317) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %319 = "ttnn.typecast"(%318) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%318) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %320 = "ttnn.slice_static"(%316) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %321 = "ttnn.neg"(%320) : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%320) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %322 = "ttnn.slice_static"(%316) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%316) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %323 = "ttnn.concat"(%321, %322) <{dim = 3 : si32}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%322) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%321) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %324 = "ttnn.typecast"(%323) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%323) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %325 = "ttnn.multiply"(%324, %100) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%324) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %326 = "ttnn.typecast"(%325) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%325) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %327 = "ttnn.add"(%319, %326) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%326) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%319) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.fill_cache"(%35, %327) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%327) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %328 = "ttnn.matmul"(%313, %36) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%36) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %329 = "ttnn.reshape"(%328) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%328) <{force = false}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %330 = "ttnn.permute"(%329) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%329) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.fill_cache"(%37, %330) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%330) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %331 = "ttnn.typecast"(%45) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%45) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %332 = "ttnn.reshape"(%331) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%331) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %333 = "ttnn.matmul"(%313, %42) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%313) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%42) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %334 = "ttnn.reshape"(%333) <{shape = [1 : i32, 7 : i32, 12 : i32, 128 : i32]}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%333) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %335 = "ttnn.permute"(%334) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%334) <{force = false}> : (tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %336 = "ttnn.typecast"(%335) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %337 = "ttnn.reshape"(%336) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%336) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %338 = "ttnn.multiply"(%337, %90) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%337) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %339 = "ttnn.typecast"(%338) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%338) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %340 = "ttnn.slice_static"(%335) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %341 = "ttnn.neg"(%340) : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%340) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %342 = "ttnn.reshape"(%341) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%341) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %343 = "ttnn.slice_static"(%335) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%335) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %344 = "ttnn.reshape"(%343) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%343) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %345 = "ttnn.concat"(%342, %344) <{dim = 2 : si32}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%344) <{force = false}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%342) <{force = false}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %346 = "ttnn.typecast"(%345) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%345) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %347 = "ttnn.multiply"(%346, %99) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%346) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %348 = "ttnn.typecast"(%347) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%347) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %349 = "ttnn.add"(%339, %348) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%348) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%339) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %350 = "ttnn.reshape"(%35) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %351 = "ttnn.repeat"(%350) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%350) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %352 = "ttnn.reshape"(%351) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%351) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %353 = "ttnn.permute"(%352) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%352) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %354 = "ttnn.reshape"(%353) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%353) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %355 = "ttnn.matmul"(%349, %354) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%354) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%349) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %356 = "ttnn.typecast"(%355) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%355) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %357 = "ttnn.reshape"(%356) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%356) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %358 = "ttnn.multiply"(%357, %134) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%357) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %359 = "ttnn.typecast"(%358) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%358) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %360 = "ttnn.add"(%359, %147) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%359) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %361 = "ttnn.typecast"(%360) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%360) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %362 = "ttnn.max"(%361) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %363 = "ttnn.neg"(%362) : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%362) <{force = false}> : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %364 = "ttnn.add"(%361, %363) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%363) <{force = false}> : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%361) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %365 = "ttnn.softmax"(%364) <{dimension = 3 : si32}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%364) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %366 = "ttnn.typecast"(%365) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%365) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %367 = "ttnn.reshape"(%366) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%366) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %368 = "ttnn.reshape"(%37) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %369 = "ttnn.repeat"(%368) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%368) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %370 = "ttnn.reshape"(%369) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%369) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %371 = "ttnn.matmul"(%367, %370) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%370) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%367) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %372 = "ttnn.reshape"(%371) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%371) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %373 = "ttnn.concatenate_heads"(%372) : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%372) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %374 = "ttnn.reshape"(%373) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%373) <{force = false}> : (tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %375 = "ttnn.matmul"(%374, %41) <{transpose_a = false, transpose_b = true}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%374) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%41) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %376 = "ttnn.reshape"(%375) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%375) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %377 = "ttnn.reduce_scatter"(%376, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%376) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %378 = "ttnn.all_gather"(%377, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%377) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %379 = "ttnn.reshape"(%378) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%378) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %380 = "ttnn.add"(%302, %379) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%379) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%302) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %381 = "ttnn.typecast"(%43) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%43) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %382 = "ttnn.reshape"(%381) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%381) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %383 = "ttnn.typecast"(%380) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %384 = "ttnn.reshape"(%383) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %385 = "ttnn.pow"(%384, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%384) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %386 = "ttnn.sum"(%385) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%385) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %387 = "ttnn.multiply"(%386, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%386) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %388 = "ttnn.reshape"(%387) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%387) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %389 = "ttnn.add"(%388, %74) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%388) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %390 = "ttnn.rsqrt"(%389) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%389) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %391 = "ttnn.multiply"(%383, %390) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%390) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%383) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %392 = "ttnn.multiply"(%382, %391) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%391) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%382) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %393 = "ttnn.typecast"(%392) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%392) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %394 = "ttnn.matmul"(%393, %44) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%44) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %395 = "ttnn.typecast"(%394) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %396 = "ttnn.sigmoid"(%394) : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%394) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %397 = "ttnn.typecast"(%396) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%396) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %398 = "ttnn.multiply"(%395, %397) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%397) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%395) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %399 = "ttnn.matmul"(%393, %40) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%393) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%40) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %400 = "ttnn.typecast"(%399) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%399) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %401 = "ttnn.multiply"(%398, %400) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%400) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%398) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %402 = "ttnn.typecast"(%401) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%401) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %403 = "ttnn.matmul"(%402, %39) <{transpose_a = false, transpose_b = true}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%402) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%39) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %404 = "ttnn.reshape"(%403) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%403) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %405 = "ttnn.reduce_scatter"(%404, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%404) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %406 = "ttnn.all_gather"(%405, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%405) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %407 = "ttnn.reshape"(%406) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%406) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %408 = "ttnn.add"(%380, %407) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%407) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%380) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %409 = "ttnn.typecast"(%408) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %410 = "ttnn.reshape"(%409) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %411 = "ttnn.pow"(%410, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%410) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %412 = "ttnn.sum"(%411) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%411) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %413 = "ttnn.multiply"(%412, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%412) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %414 = "ttnn.reshape"(%413) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%413) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %415 = "ttnn.add"(%414, %74) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%414) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %416 = "ttnn.rsqrt"(%415) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%415) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %417 = "ttnn.multiply"(%409, %416) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%416) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%409) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %418 = "ttnn.multiply"(%332, %417) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%417) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%332) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %419 = "ttnn.typecast"(%418) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%418) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %420 = "ttnn.matmul"(%419, %38) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%38) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %421 = "ttnn.reshape"(%420) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%420) <{force = false}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %422 = "ttnn.permute"(%421) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%421) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %423 = "ttnn.typecast"(%422) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %424 = "ttnn.multiply"(%423, %91) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%423) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%91) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %425 = "ttnn.typecast"(%424) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%424) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %426 = "ttnn.slice_static"(%422) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %427 = "ttnn.neg"(%426) : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%426) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %428 = "ttnn.slice_static"(%422) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%422) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %429 = "ttnn.concat"(%427, %428) <{dim = 3 : si32}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%428) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%427) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %430 = "ttnn.typecast"(%429) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%429) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %431 = "ttnn.multiply"(%430, %100) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%430) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%100) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %432 = "ttnn.typecast"(%431) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%431) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %433 = "ttnn.add"(%425, %432) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%432) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%425) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.fill_cache"(%46, %433) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%433) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %434 = "ttnn.matmul"(%419, %47) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%47) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %435 = "ttnn.reshape"(%434) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%434) <{force = false}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %436 = "ttnn.permute"(%435) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%435) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.fill_cache"(%48, %436) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%436) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %437 = "ttnn.typecast"(%55) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%55) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %438 = "ttnn.reshape"(%437) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%437) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %439 = "ttnn.matmul"(%419, %52) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%419) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%52) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %440 = "ttnn.reshape"(%439) <{shape = [1 : i32, 7 : i32, 12 : i32, 128 : i32]}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%439) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %441 = "ttnn.permute"(%440) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%440) <{force = false}> : (tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %442 = "ttnn.typecast"(%441) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %443 = "ttnn.reshape"(%442) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%442) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %444 = "ttnn.multiply"(%443, %90) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%443) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%90) <{force = false}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %445 = "ttnn.typecast"(%444) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%444) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %446 = "ttnn.slice_static"(%441) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %447 = "ttnn.neg"(%446) : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%446) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %448 = "ttnn.reshape"(%447) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%447) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %449 = "ttnn.slice_static"(%441) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%441) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %450 = "ttnn.reshape"(%449) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%449) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %451 = "ttnn.concat"(%448, %450) <{dim = 2 : si32}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%450) <{force = false}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%448) <{force = false}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %452 = "ttnn.typecast"(%451) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%451) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %453 = "ttnn.multiply"(%452, %99) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%452) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%99) <{force = false}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %454 = "ttnn.typecast"(%453) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%453) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %455 = "ttnn.add"(%445, %454) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%454) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%445) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %456 = "ttnn.reshape"(%46) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %457 = "ttnn.repeat"(%456) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%456) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %458 = "ttnn.reshape"(%457) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%457) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %459 = "ttnn.permute"(%458) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%458) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %460 = "ttnn.reshape"(%459) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%459) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %461 = "ttnn.matmul"(%455, %460) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%460) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%455) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %462 = "ttnn.typecast"(%461) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%461) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %463 = "ttnn.reshape"(%462) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%462) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %464 = "ttnn.multiply"(%463, %134) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%463) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%134) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %465 = "ttnn.typecast"(%464) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%464) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %466 = "ttnn.add"(%465, %147) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%465) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%147) <{force = false}> : (tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %467 = "ttnn.typecast"(%466) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%466) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %468 = "ttnn.max"(%467) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %469 = "ttnn.neg"(%468) : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%468) <{force = false}> : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %470 = "ttnn.add"(%467, %469) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%469) <{force = false}> : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%467) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %471 = "ttnn.softmax"(%470) <{dimension = 3 : si32}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%470) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %472 = "ttnn.typecast"(%471) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%471) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %473 = "ttnn.reshape"(%472) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%472) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %474 = "ttnn.reshape"(%48) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %475 = "ttnn.repeat"(%474) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%474) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %476 = "ttnn.reshape"(%475) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%475) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %477 = "ttnn.matmul"(%473, %476) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%476) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%473) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %478 = "ttnn.reshape"(%477) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%477) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %479 = "ttnn.concatenate_heads"(%478) : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%478) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %480 = "ttnn.reshape"(%479) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%479) <{force = false}> : (tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %481 = "ttnn.matmul"(%480, %51) <{transpose_a = false, transpose_b = true}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%480) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%51) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %482 = "ttnn.reshape"(%481) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%481) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %483 = "ttnn.reduce_scatter"(%482, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%482) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %484 = "ttnn.all_gather"(%483, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%483) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %485 = "ttnn.reshape"(%484) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%484) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %486 = "ttnn.add"(%408, %485) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%485) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%408) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %487 = "ttnn.typecast"(%53) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%53) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %488 = "ttnn.reshape"(%487) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%487) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %489 = "ttnn.typecast"(%486) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %490 = "ttnn.reshape"(%489) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %491 = "ttnn.pow"(%490, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%490) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %492 = "ttnn.sum"(%491) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%491) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %493 = "ttnn.multiply"(%492, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%492) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %494 = "ttnn.reshape"(%493) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%493) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %495 = "ttnn.add"(%494, %74) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%494) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %496 = "ttnn.rsqrt"(%495) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%495) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %497 = "ttnn.multiply"(%489, %496) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%496) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%489) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %498 = "ttnn.multiply"(%488, %497) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%497) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%488) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %499 = "ttnn.typecast"(%498) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%498) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %500 = "ttnn.matmul"(%499, %54) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%54) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %501 = "ttnn.typecast"(%500) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %502 = "ttnn.sigmoid"(%500) : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%500) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %503 = "ttnn.typecast"(%502) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%502) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %504 = "ttnn.multiply"(%501, %503) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%503) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%501) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %505 = "ttnn.matmul"(%499, %50) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%499) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%50) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %506 = "ttnn.typecast"(%505) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%505) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %507 = "ttnn.multiply"(%504, %506) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%506) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%504) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %508 = "ttnn.typecast"(%507) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%507) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %509 = "ttnn.matmul"(%508, %49) <{transpose_a = false, transpose_b = true}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%508) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%49) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %510 = "ttnn.reshape"(%509) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%509) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %511 = "ttnn.reduce_scatter"(%510, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%510) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %512 = "ttnn.all_gather"(%511, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%511) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %513 = "ttnn.reshape"(%512) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%512) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %514 = "ttnn.add"(%486, %513) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%513) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%486) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %515 = "ttnn.typecast"(%514) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%514) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %516 = "ttnn.reshape"(%515) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %517 = "ttnn.pow"(%516, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%516) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %518 = "ttnn.sum"(%517) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%517) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %519 = "ttnn.multiply"(%518, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%518) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %520 = "ttnn.reshape"(%519) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%519) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %521 = "ttnn.add"(%520, %74) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%520) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%74) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %522 = "ttnn.rsqrt"(%521) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%521) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %523 = "ttnn.multiply"(%515, %522) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%522) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%515) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %524 = "ttnn.multiply"(%438, %523) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%523) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%438) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %525 = "ttnn.typecast"(%524) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%524) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %526 = "ttnn.matmul"(%525, %8) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%525) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %527 = "ttnn.reshape"(%526) <{shape = [1 : i32, 7 : i32, 64128 : i32]}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %528 = "ttnn.to_layout"(%10) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %529 = "ttnn.from_device"(%528) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%528) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %530 = "ttnn.mesh_shard"(%529, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%529) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %531 = "ttnn.to_layout"(%12) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %532 = "ttnn.from_device"(%531) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%531) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %533 = "ttnn.mesh_shard"(%532, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%532) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %534 = "ttnn.to_layout"(%24) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%24) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %535 = "ttnn.from_device"(%534) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%534) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %536 = "ttnn.mesh_shard"(%535, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%535) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %537 = "ttnn.to_layout"(%26) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%26) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %538 = "ttnn.from_device"(%537) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%537) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %539 = "ttnn.mesh_shard"(%538, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%538) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %540 = "ttnn.to_layout"(%35) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%35) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %541 = "ttnn.from_device"(%540) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%540) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %542 = "ttnn.mesh_shard"(%541, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%541) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %543 = "ttnn.to_layout"(%37) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%37) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %544 = "ttnn.from_device"(%543) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%543) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %545 = "ttnn.mesh_shard"(%544, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%544) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %546 = "ttnn.to_layout"(%46) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%46) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %547 = "ttnn.from_device"(%546) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%546) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %548 = "ttnn.mesh_shard"(%547, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%547) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %549 = "ttnn.to_layout"(%48) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%48) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %550 = "ttnn.from_device"(%549) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%549) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %551 = "ttnn.mesh_shard"(%550, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%550) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %552 = "ttnn.to_layout"(%526) <{layout = #ttnn.layout<row_major>}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%526) <{force = false}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %553 = "ttnn.from_device"(%552) : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%552) <{force = false}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %554 = "ttnn.mesh_shard"(%553, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<7x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%553) <{force = false}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %555 = "ttnn.to_layout"(%527) <{layout = #ttnn.layout<row_major>}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%527) <{force = false}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %556 = "ttnn.from_device"(%555) : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%555) <{force = false}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %557 = "ttnn.mesh_shard"(%556, %1) <{shard_dims = array<i64: -1, 2>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x7x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%556) <{force = false}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        return %530, %533, %536, %539, %542, %545, %548, %551, %554, %557 : tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<7x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x7x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>>
      }
    }
  }
}
input 0: device = xla:0, shape torch.Size([128]) and shard spec {replicated}
input 1: device = xla:0, shape torch.Size([7, 128]) and shard spec {replicated}
input 2: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 2 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0791,  0.1982,  0.0928, -0.0488, -0.1318, -0.2119,  0.0471,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 3: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 3 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0022, -0.0092,  0.0094,  0.0027, -0.0072, -0.0029, -0.0015,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 4: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 4 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0486,  0.0708,  0.0170, -0.0243, -0.1235, -0.1123, -0.0933,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 5: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 5 and shape torch.Size([1, 8, 128, 128]): tensor([0.0099, 0.0069, 0.0079, 0.0128, 0.0036, 0.0089, 0.0055, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000], dtype=torch.bfloat16)
input 6: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 6 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0156, -0.1123, -0.1484, -0.1128, -0.0540, -0.0371,  0.0737,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 7: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 7 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0055, -0.0099,  0.0272,  0.0189, -0.0014,  0.0098, -0.0119,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 8: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 8 and shape torch.Size([1, 8, 128, 128]): tensor([-0.2139, -0.2988, -0.1260, -0.0457,  0.0356,  0.0403, -0.0269,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 9: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 9 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0045, -0.0027,  0.0211,  0.0121,  0.0044, -0.0535, -0.0464,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 10: device = xla:0, shape torch.Size([1, 7]) and shard spec {replicated}
input 11: device = xla:0, shape torch.Size([128256, 3072]) and shard spec {devices=[2,1]<=[2]}
input 12: device = xla:0, shape torch.Size([7]) and shard spec {replicated}
input 13: device = xla:0, shape torch.Size([64]) and shard spec {replicated}
input 14: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 15: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 16: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 17: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 18: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 19: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 20: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 21: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 22: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 23: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 24: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 25: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 26: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 27: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 28: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 29: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 30: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 31: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 32: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 33: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 34: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 35: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 36: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 37: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 38: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 39: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 40: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 41: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 42: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 43: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 44: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 45: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 46: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 47: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 48: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 49: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 50: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
CPU logit shape:  torch.Size([1, 7, 128256]) XLA logit shape:  torch.Size([1, 7, 128256])
\(Generated tokens: ['\\(']
Note: Using experimental XLA backend.
[XLA Debug] Processing 51 input specs:
[XLA Debug] Input 0: kind=InputKind.PARAMETER, arg=TensorArgument(name='p__fx_const_folded_attrs_0'), target=_FX_CONST_FOLDED_ATTRS.0

[XLA Debug] Input 1: kind=InputKind.PARAMETER, arg=TensorArgument(name='p__fx_const_folded_attrs_1'), target=_FX_CONST_FOLDED_ATTRS.1

[XLA Debug] Input 2: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___key_cache_0'), target=kwargs____past_key_values___key_cache_0
[XLA Debug] Input 3: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___value_cache_0'), target=kwargs____past_key_values___value_cache_0
[XLA Debug] Input 4: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___key_cache_1'), target=kwargs____past_key_values___key_cache_1
[XLA Debug] Input 5: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___value_cache_1'), target=kwargs____past_key_values___value_cache_1
[XLA Debug] Input 6: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___key_cache_2'), target=kwargs____past_key_values___key_cache_2
[XLA Debug] Input 7: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___value_cache_2'), target=kwargs____past_key_values___value_cache_2
[XLA Debug] Input 8: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___key_cache_3'), target=kwargs____past_key_values___key_cache_3
[XLA Debug] Input 9: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___value_cache_3'), target=kwargs____past_key_values___value_cache_3
[XLA Debug] Input 10: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_0'), target=None
[XLA Debug] Input 11: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_1'), target=None
[XLA Debug] Input 12: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_2'), target=None
[XLA Debug] Input 13: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_3'), target=None
[XLA Debug] Input 14: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_4'), target=None
[XLA Debug] Input 15: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_5'), target=None
[XLA Debug] Input 16: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_6'), target=None
[XLA Debug] Input 17: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_7'), target=None
[XLA Debug] Input 18: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_8'), target=None
[XLA Debug] Input 19: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_9'), target=None
[XLA Debug] Input 20: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_10'), target=None
[XLA Debug] Input 21: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_11'), target=None
[XLA Debug] Input 22: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_12'), target=None
[XLA Debug] Input 23: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_13'), target=None
[XLA Debug] Input 24: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_14'), target=None
[XLA Debug] Input 25: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_15'), target=None
[XLA Debug] Input 26: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_16'), target=None
[XLA Debug] Input 27: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_17'), target=None
[XLA Debug] Input 28: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_18'), target=None
[XLA Debug] Input 29: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_19'), target=None
[XLA Debug] Input 30: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_20'), target=None
[XLA Debug] Input 31: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_21'), target=None
[XLA Debug] Input 32: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_22'), target=None
[XLA Debug] Input 33: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_23'), target=None
[XLA Debug] Input 34: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_24'), target=None
[XLA Debug] Input 35: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_25'), target=None
[XLA Debug] Input 36: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_26'), target=None
[XLA Debug] Input 37: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_27'), target=None
[XLA Debug] Input 38: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_28'), target=None
[XLA Debug] Input 39: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_29'), target=None
[XLA Debug] Input 40: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_30'), target=None
[XLA Debug] Input 41: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_31'), target=None
[XLA Debug] Input 42: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_32'), target=None
[XLA Debug] Input 43: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_33'), target=None
[XLA Debug] Input 44: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_34'), target=None
[XLA Debug] Input 45: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_35'), target=None
[XLA Debug] Input 46: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_36'), target=None
[XLA Debug] Input 47: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_37'), target=None
[XLA Debug] Input 48: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_38'), target=None
[XLA Debug] Input 49: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_39'), target=None
[XLA Debug] Input 50: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_40'), target=None
[XLA Debug] Initialization complete - total inputs: 51, user input indices: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1x!vhlo.i64_v1>, %arg1: !vhlo.tensor_v1<64x!vhlo.f32_v1>, %arg2: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg3: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg4: !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, %arg5: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, %arg6: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg7: !vhlo.tensor_v1<!vhlo.i64_v1>, %arg8: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg9: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg10: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg11: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg12: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg13: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg14: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg15: !vhlo.tensor_v1<128x!vhlo.i64_v1>, %arg16: !vhlo.tensor_v1<1x128x!vhlo.bf16_v1>, %arg17: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg18: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg19: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg20: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg21: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg23: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg24: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg25: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg26: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg27: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg28: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg29: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg30: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg31: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg32: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg33: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg34: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg35: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg36: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg37: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg38: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg39: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg40: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg41: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg42: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg43: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg44: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg45: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg46: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg47: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg48: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg49: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg50: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg51: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg52: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg53: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : () -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<3.25520843E-4> : tensor<1x1xf32>>}> : () -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %5 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %6 = "vhlo.compare_v1"(%arg0, %0) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.bool_v1>
    %7 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %8 = "vhlo.add_v1"(%arg0, %7) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %9 = "vhlo.select_v1"(%6, %8, %arg0) : (!vhlo.tensor_v1<1x!vhlo.bool_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.i64_v1>
    %11 = "vhlo.convert_v1"(%arg6) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %12 = "vhlo.reshape_v1"(%11) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %13 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %14 = "vhlo.convert_v1"(%13) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.ui32_v1>
    %15 = "vhlo.gather_v2"(%arg5, %14) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3072]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %16 = "vhlo.reshape_v1"(%15) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %17 = "vhlo.convert_v1"(%16) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %18 = "vhlo.power_v1"(%17, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %19 = "vhlo.reduce_v1"(%18, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %20 = "vhlo.multiply_v1"(%19, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %21 = "vhlo.reshape_v1"(%20) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %22 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %23 = "vhlo.add_v1"(%21, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %24 = "vhlo.rsqrt_v2"(%23) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %25 = "vhlo.reshape_v1"(%24) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %26 = "vhlo.broadcast_in_dim_v1"(%25) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %27 = "vhlo.multiply_v1"(%17, %26) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %28 = "vhlo.convert_v1"(%27) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %29 = "vhlo.convert_v1"(%28) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %30 = "vhlo.multiply_v1"(%12, %29) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %31 = "vhlo.convert_v1"(%30) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %32 = "vhlo.reshape_v1"(%31) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %33 = "vhlo.transpose_v1"(%arg2) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %34 = "vhlo.dot_general_v2"(%32, %33) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %35 = "vhlo.reshape_v1"(%34) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %36 = "vhlo.convert_v1"(%35) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %37 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %38 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>
    %39 = "vhlo.convert_v1"(%38) : (!vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %40 = "vhlo.dot_general_v2"(%37, %39) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %41 = "vhlo.reshape_v1"(%40) : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %42 = "vhlo.concatenate_v1"(%41, %41) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %43 = "vhlo.cosine_v2"(%42) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %44 = "vhlo.convert_v1"(%43) : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>
    %45 = "vhlo.reshape_v1"(%44) : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>
    %46 = "vhlo.convert_v1"(%45) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>
    %47 = "vhlo.reshape_v1"(%46) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %48 = "vhlo.broadcast_in_dim_v1"(%47) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %49 = "vhlo.multiply_v1"(%36, %48) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %50 = "vhlo.convert_v1"(%49) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %51 = "vhlo.slice_v1"(%35) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %52 = "vhlo.negate_v1"(%51) : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %53 = "vhlo.slice_v1"(%35) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %54 = "vhlo.concatenate_v1"(%52, %53) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %55 = "vhlo.convert_v1"(%54) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %56 = "vhlo.sine_v2"(%42) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %57 = "vhlo.convert_v1"(%56) : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>
    %58 = "vhlo.reshape_v1"(%57) : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>
    %59 = "vhlo.convert_v1"(%58) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>
    %60 = "vhlo.reshape_v1"(%59) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %61 = "vhlo.broadcast_in_dim_v1"(%60) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %62 = "vhlo.multiply_v1"(%55, %61) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %63 = "vhlo.convert_v1"(%62) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %64 = "vhlo.add_v1"(%50, %63) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %65 = "vhlo.scatter_v2"(%arg8, %10, %64) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %66 = "vhlo.custom_call_v1"(%65) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %67 = "vhlo.transpose_v1"(%arg9) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %68 = "vhlo.dot_general_v2"(%32, %67) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %69 = "vhlo.reshape_v1"(%68) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %70 = "vhlo.scatter_v2"(%arg10, %10, %69) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %71 = "vhlo.custom_call_v1"(%70) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %72 = "vhlo.convert_v1"(%arg21) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %73 = "vhlo.reshape_v1"(%72) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %74 = "vhlo.transpose_v1"(%arg18) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %75 = "vhlo.dot_general_v2"(%32, %74) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %76 = "vhlo.reshape_v1"(%75) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %77 = "vhlo.convert_v1"(%76) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %78 = "vhlo.broadcast_in_dim_v1"(%47) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %79 = "vhlo.multiply_v1"(%77, %78) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %80 = "vhlo.convert_v1"(%79) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %81 = "vhlo.slice_v1"(%76) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %82 = "vhlo.negate_v1"(%81) : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %83 = "vhlo.slice_v1"(%76) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %84 = "vhlo.concatenate_v1"(%82, %83) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %85 = "vhlo.convert_v1"(%84) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %86 = "vhlo.broadcast_in_dim_v1"(%60) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %87 = "vhlo.multiply_v1"(%85, %86) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %88 = "vhlo.convert_v1"(%87) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %89 = "vhlo.add_v1"(%80, %88) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %90 = "vhlo.reshape_v1"(%89) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %91 = "vhlo.broadcast_in_dim_v1"(%65) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %92 = "vhlo.reshape_v1"(%91) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %93 = "vhlo.transpose_v1"(%92) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %94 = "vhlo.reshape_v1"(%93) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %95 = "vhlo.dot_general_v2"(%90, %94) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %96 = "vhlo.reshape_v1"(%95) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %97 = "vhlo.convert_v1"(%96) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %98 = "vhlo.broadcast_in_dim_v1"(%arg17) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %99 = "vhlo.multiply_v1"(%97, %98) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %100 = "vhlo.convert_v1"(%99) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %101 = "vhlo.convert_v1"(%arg16) : (!vhlo.tensor_v1<1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.f32_v1>
    %102 = "vhlo.reshape_v1"(%arg15) : (!vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.i64_v1>
    %103 = "vhlo.broadcast_in_dim_v1"(%arg0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.i64_v1>
    %104 = "vhlo.compare_v1"(%102, %103) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<1x128x!vhlo.i64_v1>, !vhlo.tensor_v1<1x128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.bool_v1>
    %105 = "vhlo.convert_v1"(%104) : (!vhlo.tensor_v1<1x128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.f32_v1>
    %106 = "vhlo.multiply_v1"(%101, %105) : (!vhlo.tensor_v1<1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.f32_v1>
    %107 = "vhlo.convert_v1"(%106) : (!vhlo.tensor_v1<1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.bf16_v1>
    %108 = "vhlo.reshape_v1"(%107) : (!vhlo.tensor_v1<1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>
    %109 = "vhlo.broadcast_in_dim_v1"(%108) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %110 = "vhlo.add_v1"(%100, %109) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %111 = "vhlo.convert_v1"(%110) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %112 = "vhlo.reduce_v1"(%111, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.maximum_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %113 = "vhlo.broadcast_in_dim_v1"(%112) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %114 = "vhlo.subtract_v1"(%111, %113) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %115 = "vhlo.exponential_v2"(%114) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %116 = "vhlo.reduce_v1"(%115, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %117 = "vhlo.broadcast_in_dim_v1"(%116) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %118 = "vhlo.divide_v1"(%115, %117) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %119 = "vhlo.convert_v1"(%118) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %120 = "vhlo.reshape_v1"(%119) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %121 = "vhlo.broadcast_in_dim_v1"(%70) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %122 = "vhlo.reshape_v1"(%121) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %123 = "vhlo.dot_general_v2"(%120, %122) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %124 = "vhlo.reshape_v1"(%123) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %125 = "vhlo.transpose_v1"(%arg14) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %126 = "vhlo.dot_general_v2"(%124, %125) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %127 = "vhlo.reshape_v1"(%126) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %128 = "vhlo.add_v1"(%16, %127) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %129 = "vhlo.convert_v1"(%arg19) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %130 = "vhlo.reshape_v1"(%129) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %131 = "vhlo.convert_v1"(%128) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %132 = "vhlo.power_v1"(%131, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %133 = "vhlo.reduce_v1"(%132, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %134 = "vhlo.multiply_v1"(%133, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %135 = "vhlo.reshape_v1"(%134) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %136 = "vhlo.add_v1"(%135, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %137 = "vhlo.rsqrt_v2"(%136) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %138 = "vhlo.reshape_v1"(%137) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %139 = "vhlo.broadcast_in_dim_v1"(%138) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %140 = "vhlo.multiply_v1"(%131, %139) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %141 = "vhlo.convert_v1"(%140) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %142 = "vhlo.convert_v1"(%141) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %143 = "vhlo.multiply_v1"(%130, %142) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %144 = "vhlo.convert_v1"(%143) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %145 = "vhlo.reshape_v1"(%144) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %146 = "vhlo.transpose_v1"(%arg20) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %147 = "vhlo.dot_general_v2"(%145, %146) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %148 = "vhlo.reshape_v1"(%147) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %149 = "vhlo.convert_v1"(%148) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %150 = "vhlo.logistic_v2"(%148) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %151 = "vhlo.convert_v1"(%150) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %152 = "vhlo.multiply_v1"(%149, %151) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %153 = "vhlo.convert_v1"(%152) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %154 = "vhlo.convert_v1"(%153) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %155 = "vhlo.transpose_v1"(%arg13) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %156 = "vhlo.dot_general_v2"(%145, %155) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %157 = "vhlo.reshape_v1"(%156) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %158 = "vhlo.convert_v1"(%157) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %159 = "vhlo.multiply_v1"(%154, %158) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %160 = "vhlo.convert_v1"(%159) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %161 = "vhlo.reshape_v1"(%160) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %162 = "vhlo.transpose_v1"(%arg12) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %163 = "vhlo.dot_general_v2"(%161, %162) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %164 = "vhlo.reshape_v1"(%163) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %165 = "vhlo.add_v1"(%128, %164) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %166 = "vhlo.convert_v1"(%165) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %167 = "vhlo.power_v1"(%166, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %168 = "vhlo.reduce_v1"(%167, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %169 = "vhlo.multiply_v1"(%168, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %170 = "vhlo.reshape_v1"(%169) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %171 = "vhlo.add_v1"(%170, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %172 = "vhlo.rsqrt_v2"(%171) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %173 = "vhlo.reshape_v1"(%172) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %174 = "vhlo.broadcast_in_dim_v1"(%173) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %175 = "vhlo.multiply_v1"(%166, %174) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %176 = "vhlo.convert_v1"(%175) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %177 = "vhlo.convert_v1"(%176) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %178 = "vhlo.multiply_v1"(%73, %177) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %179 = "vhlo.convert_v1"(%178) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %180 = "vhlo.reshape_v1"(%179) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %181 = "vhlo.transpose_v1"(%arg11) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %182 = "vhlo.dot_general_v2"(%180, %181) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %183 = "vhlo.reshape_v1"(%182) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %184 = "vhlo.convert_v1"(%183) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %185 = "vhlo.multiply_v1"(%184, %48) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %186 = "vhlo.convert_v1"(%185) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %187 = "vhlo.slice_v1"(%183) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %188 = "vhlo.negate_v1"(%187) : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %189 = "vhlo.slice_v1"(%183) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %190 = "vhlo.concatenate_v1"(%188, %189) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %191 = "vhlo.convert_v1"(%190) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %192 = "vhlo.multiply_v1"(%191, %61) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %193 = "vhlo.convert_v1"(%192) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %194 = "vhlo.add_v1"(%186, %193) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %195 = "vhlo.scatter_v2"(%arg22, %10, %194) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %196 = "vhlo.custom_call_v1"(%195) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %197 = "vhlo.transpose_v1"(%arg23) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %198 = "vhlo.dot_general_v2"(%180, %197) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %199 = "vhlo.reshape_v1"(%198) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %200 = "vhlo.scatter_v2"(%arg24, %10, %199) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %201 = "vhlo.custom_call_v1"(%200) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %202 = "vhlo.convert_v1"(%arg32) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %203 = "vhlo.reshape_v1"(%202) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %204 = "vhlo.transpose_v1"(%arg29) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %205 = "vhlo.dot_general_v2"(%180, %204) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %206 = "vhlo.reshape_v1"(%205) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %207 = "vhlo.convert_v1"(%206) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %208 = "vhlo.multiply_v1"(%207, %78) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %209 = "vhlo.convert_v1"(%208) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %210 = "vhlo.slice_v1"(%206) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %211 = "vhlo.negate_v1"(%210) : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %212 = "vhlo.slice_v1"(%206) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %213 = "vhlo.concatenate_v1"(%211, %212) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %214 = "vhlo.convert_v1"(%213) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %215 = "vhlo.multiply_v1"(%214, %86) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %216 = "vhlo.convert_v1"(%215) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %217 = "vhlo.add_v1"(%209, %216) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %218 = "vhlo.reshape_v1"(%217) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %219 = "vhlo.broadcast_in_dim_v1"(%195) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %220 = "vhlo.reshape_v1"(%219) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %221 = "vhlo.transpose_v1"(%220) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %222 = "vhlo.reshape_v1"(%221) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %223 = "vhlo.dot_general_v2"(%218, %222) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %224 = "vhlo.reshape_v1"(%223) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %225 = "vhlo.convert_v1"(%224) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %226 = "vhlo.multiply_v1"(%225, %98) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %227 = "vhlo.convert_v1"(%226) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %228 = "vhlo.add_v1"(%227, %109) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %229 = "vhlo.convert_v1"(%228) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %230 = "vhlo.reduce_v1"(%229, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.maximum_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %231 = "vhlo.broadcast_in_dim_v1"(%230) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %232 = "vhlo.subtract_v1"(%229, %231) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %233 = "vhlo.exponential_v2"(%232) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %234 = "vhlo.reduce_v1"(%233, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %235 = "vhlo.broadcast_in_dim_v1"(%234) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %236 = "vhlo.divide_v1"(%233, %235) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %237 = "vhlo.convert_v1"(%236) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %238 = "vhlo.reshape_v1"(%237) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %239 = "vhlo.broadcast_in_dim_v1"(%200) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %240 = "vhlo.reshape_v1"(%239) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %241 = "vhlo.dot_general_v2"(%238, %240) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %242 = "vhlo.reshape_v1"(%241) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %243 = "vhlo.transpose_v1"(%arg28) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %244 = "vhlo.dot_general_v2"(%242, %243) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %245 = "vhlo.reshape_v1"(%244) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %246 = "vhlo.add_v1"(%165, %245) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %247 = "vhlo.convert_v1"(%arg30) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %248 = "vhlo.reshape_v1"(%247) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %249 = "vhlo.convert_v1"(%246) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %250 = "vhlo.power_v1"(%249, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %251 = "vhlo.reduce_v1"(%250, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %252 = "vhlo.multiply_v1"(%251, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %253 = "vhlo.reshape_v1"(%252) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %254 = "vhlo.add_v1"(%253, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %255 = "vhlo.rsqrt_v2"(%254) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %256 = "vhlo.reshape_v1"(%255) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %257 = "vhlo.broadcast_in_dim_v1"(%256) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %258 = "vhlo.multiply_v1"(%249, %257) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %259 = "vhlo.convert_v1"(%258) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %260 = "vhlo.convert_v1"(%259) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %261 = "vhlo.multiply_v1"(%248, %260) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %262 = "vhlo.convert_v1"(%261) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %263 = "vhlo.reshape_v1"(%262) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %264 = "vhlo.transpose_v1"(%arg31) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %265 = "vhlo.dot_general_v2"(%263, %264) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %266 = "vhlo.reshape_v1"(%265) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %267 = "vhlo.convert_v1"(%266) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %268 = "vhlo.logistic_v2"(%266) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %269 = "vhlo.convert_v1"(%268) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %270 = "vhlo.multiply_v1"(%267, %269) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %271 = "vhlo.convert_v1"(%270) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %272 = "vhlo.convert_v1"(%271) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %273 = "vhlo.transpose_v1"(%arg27) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %274 = "vhlo.dot_general_v2"(%263, %273) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %275 = "vhlo.reshape_v1"(%274) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %276 = "vhlo.convert_v1"(%275) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %277 = "vhlo.multiply_v1"(%272, %276) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %278 = "vhlo.convert_v1"(%277) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %279 = "vhlo.reshape_v1"(%278) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %280 = "vhlo.transpose_v1"(%arg26) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %281 = "vhlo.dot_general_v2"(%279, %280) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %282 = "vhlo.reshape_v1"(%281) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %283 = "vhlo.add_v1"(%246, %282) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %284 = "vhlo.convert_v1"(%283) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %285 = "vhlo.power_v1"(%284, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %286 = "vhlo.reduce_v1"(%285, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %287 = "vhlo.multiply_v1"(%286, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %288 = "vhlo.reshape_v1"(%287) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %289 = "vhlo.add_v1"(%288, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %290 = "vhlo.rsqrt_v2"(%289) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %291 = "vhlo.reshape_v1"(%290) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %292 = "vhlo.broadcast_in_dim_v1"(%291) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %293 = "vhlo.multiply_v1"(%284, %292) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %294 = "vhlo.convert_v1"(%293) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %295 = "vhlo.convert_v1"(%294) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %296 = "vhlo.multiply_v1"(%203, %295) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %297 = "vhlo.convert_v1"(%296) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %298 = "vhlo.reshape_v1"(%297) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %299 = "vhlo.transpose_v1"(%arg25) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %300 = "vhlo.dot_general_v2"(%298, %299) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %301 = "vhlo.reshape_v1"(%300) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %302 = "vhlo.convert_v1"(%301) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %303 = "vhlo.multiply_v1"(%302, %48) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %304 = "vhlo.convert_v1"(%303) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %305 = "vhlo.slice_v1"(%301) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %306 = "vhlo.negate_v1"(%305) : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %307 = "vhlo.slice_v1"(%301) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %308 = "vhlo.concatenate_v1"(%306, %307) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %309 = "vhlo.convert_v1"(%308) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %310 = "vhlo.multiply_v1"(%309, %61) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %311 = "vhlo.convert_v1"(%310) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %312 = "vhlo.add_v1"(%304, %311) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %313 = "vhlo.scatter_v2"(%arg33, %10, %312) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %314 = "vhlo.custom_call_v1"(%313) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %315 = "vhlo.transpose_v1"(%arg34) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %316 = "vhlo.dot_general_v2"(%298, %315) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %317 = "vhlo.reshape_v1"(%316) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %318 = "vhlo.scatter_v2"(%arg35, %10, %317) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %319 = "vhlo.custom_call_v1"(%318) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %320 = "vhlo.convert_v1"(%arg43) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %321 = "vhlo.reshape_v1"(%320) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %322 = "vhlo.transpose_v1"(%arg40) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %323 = "vhlo.dot_general_v2"(%298, %322) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %324 = "vhlo.reshape_v1"(%323) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %325 = "vhlo.convert_v1"(%324) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %326 = "vhlo.multiply_v1"(%325, %78) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %327 = "vhlo.convert_v1"(%326) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %328 = "vhlo.slice_v1"(%324) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %329 = "vhlo.negate_v1"(%328) : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %330 = "vhlo.slice_v1"(%324) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %331 = "vhlo.concatenate_v1"(%329, %330) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %332 = "vhlo.convert_v1"(%331) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %333 = "vhlo.multiply_v1"(%332, %86) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %334 = "vhlo.convert_v1"(%333) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %335 = "vhlo.add_v1"(%327, %334) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %336 = "vhlo.reshape_v1"(%335) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %337 = "vhlo.broadcast_in_dim_v1"(%313) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %338 = "vhlo.reshape_v1"(%337) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %339 = "vhlo.transpose_v1"(%338) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %340 = "vhlo.reshape_v1"(%339) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %341 = "vhlo.dot_general_v2"(%336, %340) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %342 = "vhlo.reshape_v1"(%341) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %343 = "vhlo.convert_v1"(%342) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %344 = "vhlo.multiply_v1"(%343, %98) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %345 = "vhlo.convert_v1"(%344) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %346 = "vhlo.add_v1"(%345, %109) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %347 = "vhlo.convert_v1"(%346) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %348 = "vhlo.reduce_v1"(%347, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.maximum_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %349 = "vhlo.broadcast_in_dim_v1"(%348) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %350 = "vhlo.subtract_v1"(%347, %349) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %351 = "vhlo.exponential_v2"(%350) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %352 = "vhlo.reduce_v1"(%351, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %353 = "vhlo.broadcast_in_dim_v1"(%352) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %354 = "vhlo.divide_v1"(%351, %353) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %355 = "vhlo.convert_v1"(%354) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %356 = "vhlo.reshape_v1"(%355) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %357 = "vhlo.broadcast_in_dim_v1"(%318) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %358 = "vhlo.reshape_v1"(%357) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %359 = "vhlo.dot_general_v2"(%356, %358) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %360 = "vhlo.reshape_v1"(%359) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %361 = "vhlo.transpose_v1"(%arg39) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %362 = "vhlo.dot_general_v2"(%360, %361) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %363 = "vhlo.reshape_v1"(%362) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %364 = "vhlo.add_v1"(%283, %363) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %365 = "vhlo.convert_v1"(%arg41) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %366 = "vhlo.reshape_v1"(%365) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %367 = "vhlo.convert_v1"(%364) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %368 = "vhlo.power_v1"(%367, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %369 = "vhlo.reduce_v1"(%368, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %370 = "vhlo.multiply_v1"(%369, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %371 = "vhlo.reshape_v1"(%370) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %372 = "vhlo.add_v1"(%371, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %373 = "vhlo.rsqrt_v2"(%372) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %374 = "vhlo.reshape_v1"(%373) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %375 = "vhlo.broadcast_in_dim_v1"(%374) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %376 = "vhlo.multiply_v1"(%367, %375) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %377 = "vhlo.convert_v1"(%376) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %378 = "vhlo.convert_v1"(%377) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %379 = "vhlo.multiply_v1"(%366, %378) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %380 = "vhlo.convert_v1"(%379) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %381 = "vhlo.reshape_v1"(%380) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %382 = "vhlo.transpose_v1"(%arg42) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %383 = "vhlo.dot_general_v2"(%381, %382) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %384 = "vhlo.reshape_v1"(%383) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %385 = "vhlo.convert_v1"(%384) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %386 = "vhlo.logistic_v2"(%384) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %387 = "vhlo.convert_v1"(%386) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %388 = "vhlo.multiply_v1"(%385, %387) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %389 = "vhlo.convert_v1"(%388) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %390 = "vhlo.convert_v1"(%389) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %391 = "vhlo.transpose_v1"(%arg38) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %392 = "vhlo.dot_general_v2"(%381, %391) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %393 = "vhlo.reshape_v1"(%392) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %394 = "vhlo.convert_v1"(%393) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %395 = "vhlo.multiply_v1"(%390, %394) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %396 = "vhlo.convert_v1"(%395) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %397 = "vhlo.reshape_v1"(%396) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %398 = "vhlo.transpose_v1"(%arg37) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %399 = "vhlo.dot_general_v2"(%397, %398) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %400 = "vhlo.reshape_v1"(%399) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %401 = "vhlo.add_v1"(%364, %400) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %402 = "vhlo.convert_v1"(%401) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %403 = "vhlo.power_v1"(%402, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %404 = "vhlo.reduce_v1"(%403, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %405 = "vhlo.multiply_v1"(%404, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %406 = "vhlo.reshape_v1"(%405) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %407 = "vhlo.add_v1"(%406, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %408 = "vhlo.rsqrt_v2"(%407) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %409 = "vhlo.reshape_v1"(%408) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %410 = "vhlo.broadcast_in_dim_v1"(%409) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %411 = "vhlo.multiply_v1"(%402, %410) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %412 = "vhlo.convert_v1"(%411) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %413 = "vhlo.convert_v1"(%412) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %414 = "vhlo.multiply_v1"(%321, %413) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %415 = "vhlo.convert_v1"(%414) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %416 = "vhlo.reshape_v1"(%415) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %417 = "vhlo.transpose_v1"(%arg36) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %418 = "vhlo.dot_general_v2"(%416, %417) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %419 = "vhlo.reshape_v1"(%418) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %420 = "vhlo.convert_v1"(%419) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %421 = "vhlo.multiply_v1"(%420, %48) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %422 = "vhlo.convert_v1"(%421) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %423 = "vhlo.slice_v1"(%419) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %424 = "vhlo.negate_v1"(%423) : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %425 = "vhlo.slice_v1"(%419) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %426 = "vhlo.concatenate_v1"(%424, %425) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %427 = "vhlo.convert_v1"(%426) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %428 = "vhlo.multiply_v1"(%427, %61) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %429 = "vhlo.convert_v1"(%428) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %430 = "vhlo.add_v1"(%422, %429) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %431 = "vhlo.scatter_v2"(%arg44, %10, %430) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %432 = "vhlo.custom_call_v1"(%431) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %433 = "vhlo.transpose_v1"(%arg45) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %434 = "vhlo.dot_general_v2"(%416, %433) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %435 = "vhlo.reshape_v1"(%434) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %436 = "vhlo.scatter_v2"(%arg46, %10, %435) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %437 = "vhlo.custom_call_v1"(%436) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %438 = "vhlo.convert_v1"(%arg53) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %439 = "vhlo.reshape_v1"(%438) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %440 = "vhlo.transpose_v1"(%arg50) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %441 = "vhlo.dot_general_v2"(%416, %440) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %442 = "vhlo.reshape_v1"(%441) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %443 = "vhlo.convert_v1"(%442) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %444 = "vhlo.multiply_v1"(%443, %78) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %445 = "vhlo.convert_v1"(%444) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %446 = "vhlo.slice_v1"(%442) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %447 = "vhlo.negate_v1"(%446) : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %448 = "vhlo.slice_v1"(%442) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %449 = "vhlo.concatenate_v1"(%447, %448) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %450 = "vhlo.convert_v1"(%449) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %451 = "vhlo.multiply_v1"(%450, %86) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %452 = "vhlo.convert_v1"(%451) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %453 = "vhlo.add_v1"(%445, %452) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %454 = "vhlo.reshape_v1"(%453) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %455 = "vhlo.broadcast_in_dim_v1"(%431) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %456 = "vhlo.reshape_v1"(%455) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %457 = "vhlo.transpose_v1"(%456) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %458 = "vhlo.reshape_v1"(%457) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %459 = "vhlo.dot_general_v2"(%454, %458) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %460 = "vhlo.reshape_v1"(%459) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %461 = "vhlo.convert_v1"(%460) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %462 = "vhlo.multiply_v1"(%461, %98) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %463 = "vhlo.convert_v1"(%462) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %464 = "vhlo.add_v1"(%463, %109) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %465 = "vhlo.convert_v1"(%464) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %466 = "vhlo.reduce_v1"(%465, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.maximum_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %467 = "vhlo.broadcast_in_dim_v1"(%466) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %468 = "vhlo.subtract_v1"(%465, %467) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %469 = "vhlo.exponential_v2"(%468) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %470 = "vhlo.reduce_v1"(%469, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %471 = "vhlo.broadcast_in_dim_v1"(%470) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %472 = "vhlo.divide_v1"(%469, %471) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %473 = "vhlo.convert_v1"(%472) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %474 = "vhlo.reshape_v1"(%473) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %475 = "vhlo.broadcast_in_dim_v1"(%436) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %476 = "vhlo.reshape_v1"(%475) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %477 = "vhlo.dot_general_v2"(%474, %476) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %478 = "vhlo.reshape_v1"(%477) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %479 = "vhlo.transpose_v1"(%arg49) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %480 = "vhlo.dot_general_v2"(%478, %479) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %481 = "vhlo.reshape_v1"(%480) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %482 = "vhlo.add_v1"(%401, %481) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %483 = "vhlo.convert_v1"(%arg51) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %484 = "vhlo.reshape_v1"(%483) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %485 = "vhlo.convert_v1"(%482) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %486 = "vhlo.power_v1"(%485, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %487 = "vhlo.reduce_v1"(%486, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %488 = "vhlo.multiply_v1"(%487, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %489 = "vhlo.reshape_v1"(%488) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %490 = "vhlo.add_v1"(%489, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %491 = "vhlo.rsqrt_v2"(%490) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %492 = "vhlo.reshape_v1"(%491) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %493 = "vhlo.broadcast_in_dim_v1"(%492) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %494 = "vhlo.multiply_v1"(%485, %493) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %495 = "vhlo.convert_v1"(%494) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %496 = "vhlo.convert_v1"(%495) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %497 = "vhlo.multiply_v1"(%484, %496) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %498 = "vhlo.convert_v1"(%497) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %499 = "vhlo.reshape_v1"(%498) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %500 = "vhlo.transpose_v1"(%arg52) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %501 = "vhlo.dot_general_v2"(%499, %500) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %502 = "vhlo.reshape_v1"(%501) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %503 = "vhlo.convert_v1"(%502) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %504 = "vhlo.logistic_v2"(%502) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %505 = "vhlo.convert_v1"(%504) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %506 = "vhlo.multiply_v1"(%503, %505) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %507 = "vhlo.convert_v1"(%506) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %508 = "vhlo.convert_v1"(%507) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %509 = "vhlo.transpose_v1"(%arg48) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %510 = "vhlo.dot_general_v2"(%499, %509) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %511 = "vhlo.reshape_v1"(%510) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %512 = "vhlo.convert_v1"(%511) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %513 = "vhlo.multiply_v1"(%508, %512) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %514 = "vhlo.convert_v1"(%513) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %515 = "vhlo.reshape_v1"(%514) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %516 = "vhlo.transpose_v1"(%arg47) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %517 = "vhlo.dot_general_v2"(%515, %516) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %518 = "vhlo.reshape_v1"(%517) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %519 = "vhlo.add_v1"(%482, %518) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %520 = "vhlo.convert_v1"(%519) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %521 = "vhlo.power_v1"(%520, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %522 = "vhlo.reduce_v1"(%521, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %523 = "vhlo.multiply_v1"(%522, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %524 = "vhlo.reshape_v1"(%523) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %525 = "vhlo.add_v1"(%524, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %526 = "vhlo.rsqrt_v2"(%525) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %527 = "vhlo.reshape_v1"(%526) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %528 = "vhlo.broadcast_in_dim_v1"(%527) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %529 = "vhlo.multiply_v1"(%520, %528) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %530 = "vhlo.convert_v1"(%529) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %531 = "vhlo.convert_v1"(%530) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %532 = "vhlo.multiply_v1"(%439, %531) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %533 = "vhlo.convert_v1"(%532) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %534 = "vhlo.reshape_v1"(%533) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %535 = "vhlo.transpose_v1"(%arg5) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,128256]{0,1}">} : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>
    %536 = "vhlo.dot_general_v2"(%534, %535) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>
    %537 = "vhlo.reshape_v1"(%536) : (!vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1>
    "vhlo.return_v1"(%66, %71, %196, %201, %314, %319, %432, %437, %536, %537) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}
module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<1xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg2: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg3: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg4: tensor<1x1xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg5: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg6: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg7: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg8: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg9: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg10: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg11: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg12: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg13: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg14: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg15: tensor<128xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg16: tensor<1x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg17: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg18: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg19: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg20: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg21: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg22: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg23: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg24: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg25: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg26: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg27: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg28: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg29: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg30: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg31: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg32: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg33: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg34: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg35: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg36: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg37: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg38: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg39: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg40: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg41: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg42: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg43: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg44: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg45: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg46: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg47: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg48: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg49: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg50: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg51: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg52: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg53: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) {
    %c = stablehlo.constant dense<0> : tensor<1xi64>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x1xf32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32>
    %1 = stablehlo.compare  LT, %arg0, %c : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1>
    %2 = stablehlo.reshape %arg7 : (tensor<i64>) -> tensor<1xi64>
    %3 = stablehlo.add %arg0, %2 : tensor<1xi64>
    %4 = stablehlo.select %1, %3, %arg0 : tensor<1xi1>, tensor<1xi64>
    %5 = stablehlo.reshape %4 : (tensor<1xi64>) -> tensor<1x1xi64>
    %6 = stablehlo.convert %arg6 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %7 = stablehlo.reshape %6 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %8 = stablehlo.convert %arg4 : (tensor<1x1xi64>) -> tensor<1x1xui32>
    %9 = stablehlo.reshape %8 : (tensor<1x1xui32>) -> tensor<1xui32>
    %10 = "stablehlo.gather"(%arg5, %9) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16>
    %11 = stablehlo.reshape %10 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %12 = stablehlo.convert %11 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %13 = stablehlo.power %12, %0 : tensor<1x1x3072xf32>
    %14 = stablehlo.reduce(%13 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %15 = stablehlo.multiply %14, %cst_1 : tensor<1x1xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %17 = stablehlo.reshape %arg3 : (tensor<f32>) -> tensor<1x1x1xf32>
    %18 = stablehlo.add %16, %17 : tensor<1x1x1xf32>
    %19 = stablehlo.rsqrt %18 : tensor<1x1x1xf32>
    %20 = stablehlo.reshape %19 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %21 = stablehlo.broadcast_in_dim %20, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %22 = stablehlo.multiply %12, %21 : tensor<1x1x3072xf32>
    %23 = stablehlo.convert %22 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %24 = stablehlo.convert %23 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %25 = stablehlo.multiply %7, %24 : tensor<1x1x3072xf32>
    %26 = stablehlo.convert %25 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %27 = stablehlo.reshape %26 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %28 = stablehlo.transpose %arg2, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %29 = stablehlo.dot_general %27, %28, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %30 = stablehlo.reshape %29 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %31 = stablehlo.convert %30 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %32 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x64x1xf32>
    %33 = stablehlo.convert %arg0 : (tensor<1xi64>) -> tensor<1xf32>
    %34 = stablehlo.reshape %33 : (tensor<1xf32>) -> tensor<1x1x1xf32>
    %35 = stablehlo.dot_general %32, %34, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32>
    %36 = stablehlo.reshape %35 : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32>
    %37 = stablehlo.concatenate %36, %36, dim = 2 : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32>
    %38 = stablehlo.cosine %37 : tensor<1x1x128xf32>
    %39 = stablehlo.convert %38 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
    %40 = stablehlo.convert %39 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
    %41 = stablehlo.broadcast_in_dim %40, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32>
    %42 = stablehlo.multiply %31, %41 : tensor<1x8x1x128xf32>
    %43 = stablehlo.convert %42 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %44 = stablehlo.slice %30 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %45 = stablehlo.negate %44 : tensor<1x8x1x64xbf16>
    %46 = stablehlo.slice %30 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %47 = stablehlo.concatenate %45, %46, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %48 = stablehlo.convert %47 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %49 = stablehlo.sine %37 : tensor<1x1x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32>
    %53 = stablehlo.multiply %48, %52 : tensor<1x8x1x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %55 = stablehlo.add %43, %54 : tensor<1x8x1x128xbf16>
    %56 = "stablehlo.scatter"(%arg8, %5, %55) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %57 = sdy.sharding_constraint %56 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %58 = stablehlo.transpose %arg9, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %59 = stablehlo.dot_general %27, %58, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %61 = "stablehlo.scatter"(%arg10, %5, %60) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %62 = sdy.sharding_constraint %61 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %63 = stablehlo.convert %arg21 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %64 = stablehlo.reshape %63 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %65 = stablehlo.transpose %arg18, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %66 = stablehlo.dot_general %27, %65, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %68 = stablehlo.convert %67 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %69 = stablehlo.broadcast_in_dim %40, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32>
    %70 = stablehlo.multiply %68, %69 : tensor<1x24x1x128xf32>
    %71 = stablehlo.convert %70 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %72 = stablehlo.slice %67 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %73 = stablehlo.negate %72 : tensor<1x24x1x64xbf16>
    %74 = stablehlo.slice %67 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %75 = stablehlo.concatenate %73, %74, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %76 = stablehlo.convert %75 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %77 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32>
    %78 = stablehlo.multiply %76, %77 : tensor<1x24x1x128xf32>
    %79 = stablehlo.convert %78 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %80 = stablehlo.add %71, %79 : tensor<1x24x1x128xbf16>
    %81 = stablehlo.reshape %80 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %82 = stablehlo.broadcast_in_dim %56, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %83 = stablehlo.reshape %82 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %84 = stablehlo.transpose %83, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %85 = stablehlo.reshape %84 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %86 = stablehlo.dot_general %81, %85, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %88 = stablehlo.reshape %87 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %89 = stablehlo.broadcast_in_dim %arg17, dims = [] : (tensor<f32>) -> tensor<1x24x1x128xf32>
    %90 = stablehlo.multiply %88, %89 : tensor<1x24x1x128xf32>
    %91 = stablehlo.convert %90 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %92 = stablehlo.convert %arg16 : (tensor<1x128xbf16>) -> tensor<1x128xf32>
    %93 = stablehlo.reshape %arg15 : (tensor<128xi64>) -> tensor<1x128xi64>
    %94 = stablehlo.broadcast_in_dim %arg0, dims = [0] : (tensor<1xi64>) -> tensor<1x128xi64>
    %95 = stablehlo.compare  GT, %93, %94 : (tensor<1x128xi64>, tensor<1x128xi64>) -> tensor<1x128xi1>
    %96 = stablehlo.convert %95 : (tensor<1x128xi1>) -> tensor<1x128xf32>
    %97 = stablehlo.multiply %92, %96 : tensor<1x128xf32>
    %98 = stablehlo.convert %97 : (tensor<1x128xf32>) -> tensor<1x128xbf16>
    %99 = stablehlo.reshape %98 : (tensor<1x128xbf16>) -> tensor<1x1x128xbf16>
    %100 = stablehlo.broadcast_in_dim %99, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x24x1x128xbf16>
    %101 = stablehlo.add %91, %100 : tensor<1x24x1x128xbf16>
    %102 = stablehlo.convert %101 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %103 = stablehlo.reduce(%102 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %105 = stablehlo.subtract %102, %104 : tensor<1x24x1x128xf32>
    %106 = stablehlo.exponential %105 : tensor<1x24x1x128xf32>
    %107 = stablehlo.reduce(%106 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %108 = stablehlo.broadcast_in_dim %107, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %109 = stablehlo.divide %106, %108 : tensor<1x24x1x128xf32>
    %110 = stablehlo.convert %109 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %111 = stablehlo.reshape %110 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %112 = stablehlo.broadcast_in_dim %61, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %113 = stablehlo.reshape %112 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %114 = stablehlo.dot_general %111, %113, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %115 = stablehlo.reshape %114 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %116 = stablehlo.transpose %arg14, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %117 = stablehlo.dot_general %115, %116, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %118 = stablehlo.reshape %117 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %119 = stablehlo.add %11, %118 : tensor<1x1x3072xbf16>
    %120 = stablehlo.convert %arg19 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %121 = stablehlo.reshape %120 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %122 = stablehlo.convert %119 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %123 = stablehlo.power %122, %0 : tensor<1x1x3072xf32>
    %124 = stablehlo.reduce(%123 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %125 = stablehlo.multiply %124, %cst_1 : tensor<1x1xf32>
    %126 = stablehlo.reshape %125 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %127 = stablehlo.add %126, %17 : tensor<1x1x1xf32>
    %128 = stablehlo.rsqrt %127 : tensor<1x1x1xf32>
    %129 = stablehlo.reshape %128 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %131 = stablehlo.multiply %122, %130 : tensor<1x1x3072xf32>
    %132 = stablehlo.convert %131 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %133 = stablehlo.convert %132 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %134 = stablehlo.multiply %121, %133 : tensor<1x1x3072xf32>
    %135 = stablehlo.convert %134 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %137 = stablehlo.transpose %arg20, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %138 = stablehlo.dot_general %136, %137, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %139 = stablehlo.reshape %138 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %140 = stablehlo.convert %139 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %141 = stablehlo.logistic %139 : tensor<1x1x8192xbf16>
    %142 = stablehlo.convert %141 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %143 = stablehlo.multiply %140, %142 : tensor<1x1x8192xf32>
    %144 = stablehlo.convert %143 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %145 = stablehlo.convert %144 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %146 = stablehlo.transpose %arg13, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %147 = stablehlo.dot_general %136, %146, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %150 = stablehlo.multiply %145, %149 : tensor<1x1x8192xf32>
    %151 = stablehlo.convert %150 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %152 = stablehlo.reshape %151 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %153 = stablehlo.transpose %arg12, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %154 = stablehlo.dot_general %152, %153, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %155 = stablehlo.reshape %154 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %156 = stablehlo.add %119, %155 : tensor<1x1x3072xbf16>
    %157 = stablehlo.convert %156 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %158 = stablehlo.power %157, %0 : tensor<1x1x3072xf32>
    %159 = stablehlo.reduce(%158 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %160 = stablehlo.multiply %159, %cst_1 : tensor<1x1xf32>
    %161 = stablehlo.reshape %160 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %162 = stablehlo.add %161, %17 : tensor<1x1x1xf32>
    %163 = stablehlo.rsqrt %162 : tensor<1x1x1xf32>
    %164 = stablehlo.reshape %163 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %166 = stablehlo.multiply %157, %165 : tensor<1x1x3072xf32>
    %167 = stablehlo.convert %166 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %168 = stablehlo.convert %167 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %169 = stablehlo.multiply %64, %168 : tensor<1x1x3072xf32>
    %170 = stablehlo.convert %169 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %171 = stablehlo.reshape %170 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %172 = stablehlo.transpose %arg11, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %173 = stablehlo.dot_general %171, %172, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %174 = stablehlo.reshape %173 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %175 = stablehlo.convert %174 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %176 = stablehlo.multiply %175, %41 : tensor<1x8x1x128xf32>
    %177 = stablehlo.convert %176 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %178 = stablehlo.slice %174 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %179 = stablehlo.negate %178 : tensor<1x8x1x64xbf16>
    %180 = stablehlo.slice %174 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %181 = stablehlo.concatenate %179, %180, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %182 = stablehlo.convert %181 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %183 = stablehlo.multiply %182, %52 : tensor<1x8x1x128xf32>
    %184 = stablehlo.convert %183 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %185 = stablehlo.add %177, %184 : tensor<1x8x1x128xbf16>
    %186 = "stablehlo.scatter"(%arg22, %5, %185) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %187 = sdy.sharding_constraint %186 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %188 = stablehlo.transpose %arg23, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %189 = stablehlo.dot_general %171, %188, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %190 = stablehlo.reshape %189 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %191 = "stablehlo.scatter"(%arg24, %5, %190) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %192 = sdy.sharding_constraint %191 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %193 = stablehlo.convert %arg32 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %194 = stablehlo.reshape %193 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %195 = stablehlo.transpose %arg29, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %196 = stablehlo.dot_general %171, %195, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %197 = stablehlo.reshape %196 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %198 = stablehlo.convert %197 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %199 = stablehlo.multiply %198, %69 : tensor<1x24x1x128xf32>
    %200 = stablehlo.convert %199 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %201 = stablehlo.slice %197 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %202 = stablehlo.negate %201 : tensor<1x24x1x64xbf16>
    %203 = stablehlo.slice %197 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %204 = stablehlo.concatenate %202, %203, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %205 = stablehlo.convert %204 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %206 = stablehlo.multiply %205, %77 : tensor<1x24x1x128xf32>
    %207 = stablehlo.convert %206 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %208 = stablehlo.add %200, %207 : tensor<1x24x1x128xbf16>
    %209 = stablehlo.reshape %208 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %210 = stablehlo.broadcast_in_dim %186, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %211 = stablehlo.reshape %210 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %212 = stablehlo.transpose %211, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %213 = stablehlo.reshape %212 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %214 = stablehlo.dot_general %209, %213, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %215 = stablehlo.convert %214 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %216 = stablehlo.reshape %215 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %217 = stablehlo.multiply %216, %89 : tensor<1x24x1x128xf32>
    %218 = stablehlo.convert %217 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %219 = stablehlo.add %218, %100 : tensor<1x24x1x128xbf16>
    %220 = stablehlo.convert %219 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %221 = stablehlo.reduce(%220 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %222 = stablehlo.broadcast_in_dim %221, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %223 = stablehlo.subtract %220, %222 : tensor<1x24x1x128xf32>
    %224 = stablehlo.exponential %223 : tensor<1x24x1x128xf32>
    %225 = stablehlo.reduce(%224 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %226 = stablehlo.broadcast_in_dim %225, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %227 = stablehlo.divide %224, %226 : tensor<1x24x1x128xf32>
    %228 = stablehlo.convert %227 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %229 = stablehlo.reshape %228 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %230 = stablehlo.broadcast_in_dim %191, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %231 = stablehlo.reshape %230 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %232 = stablehlo.dot_general %229, %231, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %233 = stablehlo.reshape %232 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %234 = stablehlo.transpose %arg28, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %235 = stablehlo.dot_general %233, %234, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %236 = stablehlo.reshape %235 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %237 = stablehlo.add %156, %236 : tensor<1x1x3072xbf16>
    %238 = stablehlo.convert %arg30 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %239 = stablehlo.reshape %238 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %240 = stablehlo.convert %237 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %241 = stablehlo.power %240, %0 : tensor<1x1x3072xf32>
    %242 = stablehlo.reduce(%241 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %243 = stablehlo.multiply %242, %cst_1 : tensor<1x1xf32>
    %244 = stablehlo.reshape %243 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %245 = stablehlo.add %244, %17 : tensor<1x1x1xf32>
    %246 = stablehlo.rsqrt %245 : tensor<1x1x1xf32>
    %247 = stablehlo.reshape %246 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %248 = stablehlo.broadcast_in_dim %247, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %249 = stablehlo.multiply %240, %248 : tensor<1x1x3072xf32>
    %250 = stablehlo.convert %249 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %251 = stablehlo.convert %250 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %252 = stablehlo.multiply %239, %251 : tensor<1x1x3072xf32>
    %253 = stablehlo.convert %252 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %254 = stablehlo.reshape %253 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %255 = stablehlo.transpose %arg31, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %256 = stablehlo.dot_general %254, %255, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %257 = stablehlo.reshape %256 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %258 = stablehlo.convert %257 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %259 = stablehlo.logistic %257 : tensor<1x1x8192xbf16>
    %260 = stablehlo.convert %259 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %261 = stablehlo.multiply %258, %260 : tensor<1x1x8192xf32>
    %262 = stablehlo.convert %261 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %263 = stablehlo.convert %262 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %264 = stablehlo.transpose %arg27, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %265 = stablehlo.dot_general %254, %264, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %266 = stablehlo.convert %265 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %267 = stablehlo.reshape %266 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %268 = stablehlo.multiply %263, %267 : tensor<1x1x8192xf32>
    %269 = stablehlo.convert %268 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %270 = stablehlo.reshape %269 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %271 = stablehlo.transpose %arg26, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %272 = stablehlo.dot_general %270, %271, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %273 = stablehlo.reshape %272 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %274 = stablehlo.add %237, %273 : tensor<1x1x3072xbf16>
    %275 = stablehlo.convert %274 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %276 = stablehlo.power %275, %0 : tensor<1x1x3072xf32>
    %277 = stablehlo.reduce(%276 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %278 = stablehlo.multiply %277, %cst_1 : tensor<1x1xf32>
    %279 = stablehlo.reshape %278 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %280 = stablehlo.add %279, %17 : tensor<1x1x1xf32>
    %281 = stablehlo.rsqrt %280 : tensor<1x1x1xf32>
    %282 = stablehlo.reshape %281 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %283 = stablehlo.broadcast_in_dim %282, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %284 = stablehlo.multiply %275, %283 : tensor<1x1x3072xf32>
    %285 = stablehlo.convert %284 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %286 = stablehlo.convert %285 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %287 = stablehlo.multiply %194, %286 : tensor<1x1x3072xf32>
    %288 = stablehlo.convert %287 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %289 = stablehlo.reshape %288 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %290 = stablehlo.transpose %arg25, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %291 = stablehlo.dot_general %289, %290, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %292 = stablehlo.reshape %291 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %293 = stablehlo.convert %292 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %294 = stablehlo.multiply %293, %41 : tensor<1x8x1x128xf32>
    %295 = stablehlo.convert %294 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %296 = stablehlo.slice %292 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %297 = stablehlo.negate %296 : tensor<1x8x1x64xbf16>
    %298 = stablehlo.slice %292 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %299 = stablehlo.concatenate %297, %298, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %300 = stablehlo.convert %299 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %301 = stablehlo.multiply %300, %52 : tensor<1x8x1x128xf32>
    %302 = stablehlo.convert %301 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %303 = stablehlo.add %295, %302 : tensor<1x8x1x128xbf16>
    %304 = "stablehlo.scatter"(%arg33, %5, %303) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %305 = sdy.sharding_constraint %304 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %306 = stablehlo.transpose %arg34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %307 = stablehlo.dot_general %289, %306, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %308 = stablehlo.reshape %307 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %309 = "stablehlo.scatter"(%arg35, %5, %308) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %310 = sdy.sharding_constraint %309 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %311 = stablehlo.convert %arg43 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %312 = stablehlo.reshape %311 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %313 = stablehlo.transpose %arg40, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %314 = stablehlo.dot_general %289, %313, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %315 = stablehlo.reshape %314 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %316 = stablehlo.convert %315 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %317 = stablehlo.multiply %316, %69 : tensor<1x24x1x128xf32>
    %318 = stablehlo.convert %317 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %319 = stablehlo.slice %315 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %320 = stablehlo.negate %319 : tensor<1x24x1x64xbf16>
    %321 = stablehlo.slice %315 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %322 = stablehlo.concatenate %320, %321, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %323 = stablehlo.convert %322 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %324 = stablehlo.multiply %323, %77 : tensor<1x24x1x128xf32>
    %325 = stablehlo.convert %324 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %326 = stablehlo.add %318, %325 : tensor<1x24x1x128xbf16>
    %327 = stablehlo.reshape %326 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %328 = stablehlo.broadcast_in_dim %304, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %329 = stablehlo.reshape %328 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %330 = stablehlo.transpose %329, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %331 = stablehlo.reshape %330 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %332 = stablehlo.dot_general %327, %331, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %333 = stablehlo.convert %332 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %334 = stablehlo.reshape %333 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %335 = stablehlo.multiply %334, %89 : tensor<1x24x1x128xf32>
    %336 = stablehlo.convert %335 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %337 = stablehlo.add %336, %100 : tensor<1x24x1x128xbf16>
    %338 = stablehlo.convert %337 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %339 = stablehlo.reduce(%338 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %340 = stablehlo.broadcast_in_dim %339, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %341 = stablehlo.subtract %338, %340 : tensor<1x24x1x128xf32>
    %342 = stablehlo.exponential %341 : tensor<1x24x1x128xf32>
    %343 = stablehlo.reduce(%342 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %344 = stablehlo.broadcast_in_dim %343, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %345 = stablehlo.divide %342, %344 : tensor<1x24x1x128xf32>
    %346 = stablehlo.convert %345 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %347 = stablehlo.reshape %346 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %348 = stablehlo.broadcast_in_dim %309, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %349 = stablehlo.reshape %348 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %350 = stablehlo.dot_general %347, %349, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %351 = stablehlo.reshape %350 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %352 = stablehlo.transpose %arg39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %353 = stablehlo.dot_general %351, %352, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %354 = stablehlo.reshape %353 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %355 = stablehlo.add %274, %354 : tensor<1x1x3072xbf16>
    %356 = stablehlo.convert %arg41 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %357 = stablehlo.reshape %356 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %358 = stablehlo.convert %355 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %359 = stablehlo.power %358, %0 : tensor<1x1x3072xf32>
    %360 = stablehlo.reduce(%359 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %361 = stablehlo.multiply %360, %cst_1 : tensor<1x1xf32>
    %362 = stablehlo.reshape %361 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %363 = stablehlo.add %362, %17 : tensor<1x1x1xf32>
    %364 = stablehlo.rsqrt %363 : tensor<1x1x1xf32>
    %365 = stablehlo.reshape %364 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %366 = stablehlo.broadcast_in_dim %365, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %367 = stablehlo.multiply %358, %366 : tensor<1x1x3072xf32>
    %368 = stablehlo.convert %367 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %369 = stablehlo.convert %368 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %370 = stablehlo.multiply %357, %369 : tensor<1x1x3072xf32>
    %371 = stablehlo.convert %370 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %372 = stablehlo.reshape %371 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %373 = stablehlo.transpose %arg42, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %374 = stablehlo.dot_general %372, %373, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %375 = stablehlo.reshape %374 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %376 = stablehlo.convert %375 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %377 = stablehlo.logistic %375 : tensor<1x1x8192xbf16>
    %378 = stablehlo.convert %377 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %379 = stablehlo.multiply %376, %378 : tensor<1x1x8192xf32>
    %380 = stablehlo.convert %379 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %381 = stablehlo.convert %380 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %382 = stablehlo.transpose %arg38, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %383 = stablehlo.dot_general %372, %382, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %384 = stablehlo.convert %383 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %385 = stablehlo.reshape %384 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %386 = stablehlo.multiply %381, %385 : tensor<1x1x8192xf32>
    %387 = stablehlo.convert %386 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %388 = stablehlo.reshape %387 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %389 = stablehlo.transpose %arg37, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %390 = stablehlo.dot_general %388, %389, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %391 = stablehlo.reshape %390 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %392 = stablehlo.add %355, %391 : tensor<1x1x3072xbf16>
    %393 = stablehlo.convert %392 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %394 = stablehlo.power %393, %0 : tensor<1x1x3072xf32>
    %395 = stablehlo.reduce(%394 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %396 = stablehlo.multiply %395, %cst_1 : tensor<1x1xf32>
    %397 = stablehlo.reshape %396 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %398 = stablehlo.add %397, %17 : tensor<1x1x1xf32>
    %399 = stablehlo.rsqrt %398 : tensor<1x1x1xf32>
    %400 = stablehlo.reshape %399 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %401 = stablehlo.broadcast_in_dim %400, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %402 = stablehlo.multiply %393, %401 : tensor<1x1x3072xf32>
    %403 = stablehlo.convert %402 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %404 = stablehlo.convert %403 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %405 = stablehlo.multiply %312, %404 : tensor<1x1x3072xf32>
    %406 = stablehlo.convert %405 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %407 = stablehlo.reshape %406 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %408 = stablehlo.transpose %arg36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %409 = stablehlo.dot_general %407, %408, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %410 = stablehlo.reshape %409 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %411 = stablehlo.convert %410 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %412 = stablehlo.multiply %411, %41 : tensor<1x8x1x128xf32>
    %413 = stablehlo.convert %412 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %414 = stablehlo.slice %410 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %415 = stablehlo.negate %414 : tensor<1x8x1x64xbf16>
    %416 = stablehlo.slice %410 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %417 = stablehlo.concatenate %415, %416, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %418 = stablehlo.convert %417 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %419 = stablehlo.multiply %418, %52 : tensor<1x8x1x128xf32>
    %420 = stablehlo.convert %419 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %421 = stablehlo.add %413, %420 : tensor<1x8x1x128xbf16>
    %422 = "stablehlo.scatter"(%arg44, %5, %421) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %423 = sdy.sharding_constraint %422 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %424 = stablehlo.transpose %arg45, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %425 = stablehlo.dot_general %407, %424, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %426 = stablehlo.reshape %425 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %427 = "stablehlo.scatter"(%arg46, %5, %426) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %428 = sdy.sharding_constraint %427 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %429 = stablehlo.convert %arg53 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %430 = stablehlo.reshape %429 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %431 = stablehlo.transpose %arg50, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %432 = stablehlo.dot_general %407, %431, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %433 = stablehlo.reshape %432 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %434 = stablehlo.convert %433 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %435 = stablehlo.multiply %434, %69 : tensor<1x24x1x128xf32>
    %436 = stablehlo.convert %435 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %437 = stablehlo.slice %433 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %438 = stablehlo.negate %437 : tensor<1x24x1x64xbf16>
    %439 = stablehlo.slice %433 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %440 = stablehlo.concatenate %438, %439, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %441 = stablehlo.convert %440 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %442 = stablehlo.multiply %441, %77 : tensor<1x24x1x128xf32>
    %443 = stablehlo.convert %442 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %444 = stablehlo.add %436, %443 : tensor<1x24x1x128xbf16>
    %445 = stablehlo.reshape %444 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %446 = stablehlo.broadcast_in_dim %422, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %447 = stablehlo.reshape %446 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %448 = stablehlo.transpose %447, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %449 = stablehlo.reshape %448 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %450 = stablehlo.dot_general %445, %449, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %451 = stablehlo.convert %450 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %452 = stablehlo.reshape %451 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %453 = stablehlo.multiply %452, %89 : tensor<1x24x1x128xf32>
    %454 = stablehlo.convert %453 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %455 = stablehlo.add %454, %100 : tensor<1x24x1x128xbf16>
    %456 = stablehlo.convert %455 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %457 = stablehlo.reduce(%456 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %458 = stablehlo.broadcast_in_dim %457, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %459 = stablehlo.subtract %456, %458 : tensor<1x24x1x128xf32>
    %460 = stablehlo.exponential %459 : tensor<1x24x1x128xf32>
    %461 = stablehlo.reduce(%460 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %462 = stablehlo.broadcast_in_dim %461, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %463 = stablehlo.divide %460, %462 : tensor<1x24x1x128xf32>
    %464 = stablehlo.convert %463 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %465 = stablehlo.reshape %464 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %466 = stablehlo.broadcast_in_dim %427, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %467 = stablehlo.reshape %466 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %468 = stablehlo.dot_general %465, %467, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %469 = stablehlo.reshape %468 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %470 = stablehlo.transpose %arg49, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %471 = stablehlo.dot_general %469, %470, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %472 = stablehlo.reshape %471 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %473 = stablehlo.add %392, %472 : tensor<1x1x3072xbf16>
    %474 = stablehlo.convert %arg51 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %475 = stablehlo.reshape %474 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %476 = stablehlo.convert %473 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %477 = stablehlo.power %476, %0 : tensor<1x1x3072xf32>
    %478 = stablehlo.reduce(%477 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %479 = stablehlo.multiply %478, %cst_1 : tensor<1x1xf32>
    %480 = stablehlo.reshape %479 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %481 = stablehlo.add %480, %17 : tensor<1x1x1xf32>
    %482 = stablehlo.rsqrt %481 : tensor<1x1x1xf32>
    %483 = stablehlo.reshape %482 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %484 = stablehlo.broadcast_in_dim %483, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %485 = stablehlo.multiply %476, %484 : tensor<1x1x3072xf32>
    %486 = stablehlo.convert %485 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %487 = stablehlo.convert %486 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %488 = stablehlo.multiply %475, %487 : tensor<1x1x3072xf32>
    %489 = stablehlo.convert %488 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %490 = stablehlo.reshape %489 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %491 = stablehlo.transpose %arg52, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %492 = stablehlo.dot_general %490, %491, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %493 = stablehlo.reshape %492 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %494 = stablehlo.convert %493 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %495 = stablehlo.logistic %493 : tensor<1x1x8192xbf16>
    %496 = stablehlo.convert %495 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %497 = stablehlo.multiply %494, %496 : tensor<1x1x8192xf32>
    %498 = stablehlo.convert %497 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %499 = stablehlo.convert %498 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %500 = stablehlo.transpose %arg48, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %501 = stablehlo.dot_general %490, %500, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %502 = stablehlo.convert %501 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %503 = stablehlo.reshape %502 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %504 = stablehlo.multiply %499, %503 : tensor<1x1x8192xf32>
    %505 = stablehlo.convert %504 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %506 = stablehlo.reshape %505 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %507 = stablehlo.transpose %arg47, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %508 = stablehlo.dot_general %506, %507, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %509 = stablehlo.reshape %508 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %510 = stablehlo.add %473, %509 : tensor<1x1x3072xbf16>
    %511 = stablehlo.convert %510 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %512 = stablehlo.power %511, %0 : tensor<1x1x3072xf32>
    %513 = stablehlo.reduce(%512 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %514 = stablehlo.multiply %513, %cst_1 : tensor<1x1xf32>
    %515 = stablehlo.reshape %514 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %516 = stablehlo.add %515, %17 : tensor<1x1x1xf32>
    %517 = stablehlo.rsqrt %516 : tensor<1x1x1xf32>
    %518 = stablehlo.reshape %517 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %519 = stablehlo.broadcast_in_dim %518, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %520 = stablehlo.multiply %511, %519 : tensor<1x1x3072xf32>
    %521 = stablehlo.convert %520 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %522 = stablehlo.convert %521 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %523 = stablehlo.multiply %430, %522 : tensor<1x1x3072xf32>
    %524 = stablehlo.convert %523 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %525 = stablehlo.reshape %524 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %526 = stablehlo.transpose %arg5, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %527 = stablehlo.dot_general %525, %526, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<1x128256xbf16>
    %528 = stablehlo.reshape %527 : (tensor<1x128256xbf16>) -> tensor<1x1x128256xbf16>
    return %57, %62, %187, %192, %305, %310, %423, %428, %527, %528 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>
  }
}
module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<1xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg2: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg3: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg4: tensor<1x1xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg5: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg6: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg7: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg8: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg9: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg10: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg11: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg12: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg13: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg14: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg15: tensor<128xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg16: tensor<1x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg17: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg18: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg19: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg20: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg21: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg22: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg23: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg24: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg25: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg26: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg27: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg28: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg29: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg30: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg31: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg32: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg33: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg34: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg35: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg36: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg37: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg38: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg39: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg40: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg41: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg42: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg43: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg44: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg45: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg46: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg47: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg48: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg49: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg50: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg51: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg52: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg53: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) {
    %c = stablehlo.constant dense<0> : tensor<1xi64>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x1xf32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32>
    %1 = stablehlo.compare  LT, %arg0, %c : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1>
    %2 = stablehlo.reshape %arg7 : (tensor<i64>) -> tensor<1xi64>
    %3 = stablehlo.add %arg0, %2 : tensor<1xi64>
    %4 = stablehlo.select %1, %3, %arg0 : tensor<1xi1>, tensor<1xi64>
    %5 = stablehlo.reshape %4 : (tensor<1xi64>) -> tensor<1x1xi64>
    %6 = stablehlo.convert %arg6 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %7 = stablehlo.reshape %6 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %8 = stablehlo.convert %arg4 : (tensor<1x1xi64>) -> tensor<1x1xui32>
    %9 = stablehlo.reshape %8 : (tensor<1x1xui32>) -> tensor<1xui32>
    %10 = "stablehlo.gather"(%arg5, %9) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16>
    %11 = stablehlo.reshape %10 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %12 = stablehlo.convert %11 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %13 = stablehlo.power %12, %0 : tensor<1x1x3072xf32>
    %14 = stablehlo.reduce(%13 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %15 = stablehlo.multiply %14, %cst_1 : tensor<1x1xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %17 = stablehlo.reshape %arg3 : (tensor<f32>) -> tensor<1x1x1xf32>
    %18 = stablehlo.add %16, %17 : tensor<1x1x1xf32>
    %19 = stablehlo.rsqrt %18 : tensor<1x1x1xf32>
    %20 = stablehlo.reshape %19 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %21 = stablehlo.broadcast_in_dim %20, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %22 = stablehlo.multiply %12, %21 : tensor<1x1x3072xf32>
    %23 = stablehlo.convert %22 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %24 = stablehlo.convert %23 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %25 = stablehlo.multiply %7, %24 : tensor<1x1x3072xf32>
    %26 = stablehlo.convert %25 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %27 = stablehlo.reshape %26 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %28 = stablehlo.transpose %arg2, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %29 = stablehlo.dot_general %27, %28, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %30 = stablehlo.reshape %29 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %31 = stablehlo.convert %30 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %32 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x64x1xf32>
    %33 = stablehlo.convert %arg0 : (tensor<1xi64>) -> tensor<1xf32>
    %34 = stablehlo.reshape %33 : (tensor<1xf32>) -> tensor<1x1x1xf32>
    %35 = stablehlo.dot_general %32, %34, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32>
    %36 = stablehlo.reshape %35 : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32>
    %37 = stablehlo.concatenate %36, %36, dim = 2 : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32>
    %38 = stablehlo.cosine %37 : tensor<1x1x128xf32>
    %39 = stablehlo.convert %38 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
    %40 = stablehlo.convert %39 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
    %41 = stablehlo.broadcast_in_dim %40, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32>
    %42 = stablehlo.multiply %31, %41 : tensor<1x8x1x128xf32>
    %43 = stablehlo.convert %42 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %44 = stablehlo.slice %30 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %45 = stablehlo.negate %44 : tensor<1x8x1x64xbf16>
    %46 = stablehlo.slice %30 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %47 = stablehlo.concatenate %45, %46, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %48 = stablehlo.convert %47 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %49 = stablehlo.sine %37 : tensor<1x1x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32>
    %53 = stablehlo.multiply %48, %52 : tensor<1x8x1x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %55 = stablehlo.add %43, %54 : tensor<1x8x1x128xbf16>
    %56 = "stablehlo.scatter"(%arg8, %5, %55) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %57 = sdy.sharding_constraint %56 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %58 = stablehlo.transpose %arg9, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %59 = stablehlo.dot_general %27, %58, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %61 = "stablehlo.scatter"(%arg10, %5, %60) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %62 = sdy.sharding_constraint %61 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %63 = stablehlo.convert %arg21 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %64 = stablehlo.reshape %63 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %65 = stablehlo.transpose %arg18, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %66 = stablehlo.dot_general %27, %65, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %68 = stablehlo.convert %67 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %69 = stablehlo.broadcast_in_dim %40, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32>
    %70 = stablehlo.multiply %68, %69 : tensor<1x24x1x128xf32>
    %71 = stablehlo.convert %70 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %72 = stablehlo.slice %67 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %73 = stablehlo.negate %72 : tensor<1x24x1x64xbf16>
    %74 = stablehlo.slice %67 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %75 = stablehlo.concatenate %73, %74, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %76 = stablehlo.convert %75 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %77 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32>
    %78 = stablehlo.multiply %76, %77 : tensor<1x24x1x128xf32>
    %79 = stablehlo.convert %78 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %80 = stablehlo.add %71, %79 : tensor<1x24x1x128xbf16>
    %81 = stablehlo.reshape %80 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %82 = stablehlo.broadcast_in_dim %56, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %83 = stablehlo.reshape %82 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %84 = stablehlo.transpose %83, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %85 = stablehlo.reshape %84 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %86 = stablehlo.dot_general %81, %85, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %88 = stablehlo.reshape %87 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %89 = stablehlo.broadcast_in_dim %arg17, dims = [] : (tensor<f32>) -> tensor<1x24x1x128xf32>
    %90 = stablehlo.multiply %88, %89 : tensor<1x24x1x128xf32>
    %91 = stablehlo.convert %90 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %92 = stablehlo.convert %arg16 : (tensor<1x128xbf16>) -> tensor<1x128xf32>
    %93 = stablehlo.reshape %arg15 : (tensor<128xi64>) -> tensor<1x128xi64>
    %94 = stablehlo.broadcast_in_dim %arg0, dims = [0] : (tensor<1xi64>) -> tensor<1x128xi64>
    %95 = stablehlo.compare  GT, %93, %94 : (tensor<1x128xi64>, tensor<1x128xi64>) -> tensor<1x128xi1>
    %96 = stablehlo.convert %95 : (tensor<1x128xi1>) -> tensor<1x128xf32>
    %97 = stablehlo.multiply %92, %96 : tensor<1x128xf32>
    %98 = stablehlo.convert %97 : (tensor<1x128xf32>) -> tensor<1x128xbf16>
    %99 = stablehlo.reshape %98 : (tensor<1x128xbf16>) -> tensor<1x1x128xbf16>
    %100 = stablehlo.broadcast_in_dim %99, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x24x1x128xbf16>
    %101 = stablehlo.add %91, %100 : tensor<1x24x1x128xbf16>
    %102 = stablehlo.convert %101 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %103 = stablehlo.reduce(%102 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %105 = stablehlo.subtract %102, %104 : tensor<1x24x1x128xf32>
    %106 = stablehlo.exponential %105 : tensor<1x24x1x128xf32>
    %107 = stablehlo.reduce(%106 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %108 = stablehlo.broadcast_in_dim %107, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %109 = stablehlo.divide %106, %108 : tensor<1x24x1x128xf32>
    %110 = stablehlo.convert %109 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %111 = stablehlo.reshape %110 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %112 = stablehlo.broadcast_in_dim %61, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %113 = stablehlo.reshape %112 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %114 = stablehlo.dot_general %111, %113, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %115 = stablehlo.reshape %114 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %116 = stablehlo.transpose %arg14, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %117 = stablehlo.dot_general %115, %116, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %118 = stablehlo.reshape %117 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %119 = stablehlo.add %11, %118 : tensor<1x1x3072xbf16>
    %120 = stablehlo.convert %arg19 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %121 = stablehlo.reshape %120 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %122 = stablehlo.convert %119 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %123 = stablehlo.power %122, %0 : tensor<1x1x3072xf32>
    %124 = stablehlo.reduce(%123 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %125 = stablehlo.multiply %124, %cst_1 : tensor<1x1xf32>
    %126 = stablehlo.reshape %125 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %127 = stablehlo.add %126, %17 : tensor<1x1x1xf32>
    %128 = stablehlo.rsqrt %127 : tensor<1x1x1xf32>
    %129 = stablehlo.reshape %128 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %131 = stablehlo.multiply %122, %130 : tensor<1x1x3072xf32>
    %132 = stablehlo.convert %131 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %133 = stablehlo.convert %132 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %134 = stablehlo.multiply %121, %133 : tensor<1x1x3072xf32>
    %135 = stablehlo.convert %134 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %137 = stablehlo.transpose %arg20, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %138 = stablehlo.dot_general %136, %137, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %139 = stablehlo.reshape %138 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %140 = stablehlo.convert %139 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %141 = stablehlo.logistic %139 : tensor<1x1x8192xbf16>
    %142 = stablehlo.convert %141 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %143 = stablehlo.multiply %140, %142 : tensor<1x1x8192xf32>
    %144 = stablehlo.convert %143 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %145 = stablehlo.convert %144 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %146 = stablehlo.transpose %arg13, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %147 = stablehlo.dot_general %136, %146, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %150 = stablehlo.multiply %145, %149 : tensor<1x1x8192xf32>
    %151 = stablehlo.convert %150 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %152 = stablehlo.reshape %151 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %153 = stablehlo.transpose %arg12, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %154 = stablehlo.dot_general %152, %153, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %155 = stablehlo.reshape %154 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %156 = stablehlo.add %119, %155 : tensor<1x1x3072xbf16>
    %157 = stablehlo.convert %156 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %158 = stablehlo.power %157, %0 : tensor<1x1x3072xf32>
    %159 = stablehlo.reduce(%158 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %160 = stablehlo.multiply %159, %cst_1 : tensor<1x1xf32>
    %161 = stablehlo.reshape %160 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %162 = stablehlo.add %161, %17 : tensor<1x1x1xf32>
    %163 = stablehlo.rsqrt %162 : tensor<1x1x1xf32>
    %164 = stablehlo.reshape %163 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %166 = stablehlo.multiply %157, %165 : tensor<1x1x3072xf32>
    %167 = stablehlo.convert %166 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %168 = stablehlo.convert %167 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %169 = stablehlo.multiply %64, %168 : tensor<1x1x3072xf32>
    %170 = stablehlo.convert %169 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %171 = stablehlo.reshape %170 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %172 = stablehlo.transpose %arg11, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %173 = stablehlo.dot_general %171, %172, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %174 = stablehlo.reshape %173 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %175 = stablehlo.convert %174 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %176 = stablehlo.multiply %175, %41 : tensor<1x8x1x128xf32>
    %177 = stablehlo.convert %176 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %178 = stablehlo.slice %174 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %179 = stablehlo.negate %178 : tensor<1x8x1x64xbf16>
    %180 = stablehlo.slice %174 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %181 = stablehlo.concatenate %179, %180, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %182 = stablehlo.convert %181 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %183 = stablehlo.multiply %182, %52 : tensor<1x8x1x128xf32>
    %184 = stablehlo.convert %183 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %185 = stablehlo.add %177, %184 : tensor<1x8x1x128xbf16>
    %186 = "stablehlo.scatter"(%arg22, %5, %185) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %187 = sdy.sharding_constraint %186 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %188 = stablehlo.transpose %arg23, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %189 = stablehlo.dot_general %171, %188, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %190 = stablehlo.reshape %189 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %191 = "stablehlo.scatter"(%arg24, %5, %190) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %192 = sdy.sharding_constraint %191 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %193 = stablehlo.convert %arg32 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %194 = stablehlo.reshape %193 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %195 = stablehlo.transpose %arg29, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %196 = stablehlo.dot_general %171, %195, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %197 = stablehlo.reshape %196 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %198 = stablehlo.convert %197 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %199 = stablehlo.multiply %198, %69 : tensor<1x24x1x128xf32>
    %200 = stablehlo.convert %199 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %201 = stablehlo.slice %197 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %202 = stablehlo.negate %201 : tensor<1x24x1x64xbf16>
    %203 = stablehlo.slice %197 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %204 = stablehlo.concatenate %202, %203, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %205 = stablehlo.convert %204 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %206 = stablehlo.multiply %205, %77 : tensor<1x24x1x128xf32>
    %207 = stablehlo.convert %206 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %208 = stablehlo.add %200, %207 : tensor<1x24x1x128xbf16>
    %209 = stablehlo.reshape %208 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %210 = stablehlo.broadcast_in_dim %186, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %211 = stablehlo.reshape %210 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %212 = stablehlo.transpose %211, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %213 = stablehlo.reshape %212 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %214 = stablehlo.dot_general %209, %213, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %215 = stablehlo.convert %214 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %216 = stablehlo.reshape %215 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %217 = stablehlo.multiply %216, %89 : tensor<1x24x1x128xf32>
    %218 = stablehlo.convert %217 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %219 = stablehlo.add %218, %100 : tensor<1x24x1x128xbf16>
    %220 = stablehlo.convert %219 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %221 = stablehlo.reduce(%220 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %222 = stablehlo.broadcast_in_dim %221, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %223 = stablehlo.subtract %220, %222 : tensor<1x24x1x128xf32>
    %224 = stablehlo.exponential %223 : tensor<1x24x1x128xf32>
    %225 = stablehlo.reduce(%224 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %226 = stablehlo.broadcast_in_dim %225, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %227 = stablehlo.divide %224, %226 : tensor<1x24x1x128xf32>
    %228 = stablehlo.convert %227 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %229 = stablehlo.reshape %228 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %230 = stablehlo.broadcast_in_dim %191, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %231 = stablehlo.reshape %230 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %232 = stablehlo.dot_general %229, %231, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %233 = stablehlo.reshape %232 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %234 = stablehlo.transpose %arg28, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %235 = stablehlo.dot_general %233, %234, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %236 = stablehlo.reshape %235 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %237 = stablehlo.add %156, %236 : tensor<1x1x3072xbf16>
    %238 = stablehlo.convert %arg30 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %239 = stablehlo.reshape %238 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %240 = stablehlo.convert %237 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %241 = stablehlo.power %240, %0 : tensor<1x1x3072xf32>
    %242 = stablehlo.reduce(%241 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %243 = stablehlo.multiply %242, %cst_1 : tensor<1x1xf32>
    %244 = stablehlo.reshape %243 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %245 = stablehlo.add %244, %17 : tensor<1x1x1xf32>
    %246 = stablehlo.rsqrt %245 : tensor<1x1x1xf32>
    %247 = stablehlo.reshape %246 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %248 = stablehlo.broadcast_in_dim %247, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %249 = stablehlo.multiply %240, %248 : tensor<1x1x3072xf32>
    %250 = stablehlo.convert %249 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %251 = stablehlo.convert %250 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %252 = stablehlo.multiply %239, %251 : tensor<1x1x3072xf32>
    %253 = stablehlo.convert %252 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %254 = stablehlo.reshape %253 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %255 = stablehlo.transpose %arg31, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %256 = stablehlo.dot_general %254, %255, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %257 = stablehlo.reshape %256 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %258 = stablehlo.convert %257 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %259 = stablehlo.logistic %257 : tensor<1x1x8192xbf16>
    %260 = stablehlo.convert %259 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %261 = stablehlo.multiply %258, %260 : tensor<1x1x8192xf32>
    %262 = stablehlo.convert %261 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %263 = stablehlo.convert %262 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %264 = stablehlo.transpose %arg27, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %265 = stablehlo.dot_general %254, %264, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %266 = stablehlo.convert %265 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %267 = stablehlo.reshape %266 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %268 = stablehlo.multiply %263, %267 : tensor<1x1x8192xf32>
    %269 = stablehlo.convert %268 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %270 = stablehlo.reshape %269 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %271 = stablehlo.transpose %arg26, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %272 = stablehlo.dot_general %270, %271, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %273 = stablehlo.reshape %272 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %274 = stablehlo.add %237, %273 : tensor<1x1x3072xbf16>
    %275 = stablehlo.convert %274 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %276 = stablehlo.power %275, %0 : tensor<1x1x3072xf32>
    %277 = stablehlo.reduce(%276 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %278 = stablehlo.multiply %277, %cst_1 : tensor<1x1xf32>
    %279 = stablehlo.reshape %278 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %280 = stablehlo.add %279, %17 : tensor<1x1x1xf32>
    %281 = stablehlo.rsqrt %280 : tensor<1x1x1xf32>
    %282 = stablehlo.reshape %281 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %283 = stablehlo.broadcast_in_dim %282, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %284 = stablehlo.multiply %275, %283 : tensor<1x1x3072xf32>
    %285 = stablehlo.convert %284 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %286 = stablehlo.convert %285 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %287 = stablehlo.multiply %194, %286 : tensor<1x1x3072xf32>
    %288 = stablehlo.convert %287 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %289 = stablehlo.reshape %288 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %290 = stablehlo.transpose %arg25, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %291 = stablehlo.dot_general %289, %290, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %292 = stablehlo.reshape %291 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %293 = stablehlo.convert %292 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %294 = stablehlo.multiply %293, %41 : tensor<1x8x1x128xf32>
    %295 = stablehlo.convert %294 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %296 = stablehlo.slice %292 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %297 = stablehlo.negate %296 : tensor<1x8x1x64xbf16>
    %298 = stablehlo.slice %292 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %299 = stablehlo.concatenate %297, %298, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %300 = stablehlo.convert %299 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %301 = stablehlo.multiply %300, %52 : tensor<1x8x1x128xf32>
    %302 = stablehlo.convert %301 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %303 = stablehlo.add %295, %302 : tensor<1x8x1x128xbf16>
    %304 = "stablehlo.scatter"(%arg33, %5, %303) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %305 = sdy.sharding_constraint %304 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %306 = stablehlo.transpose %arg34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %307 = stablehlo.dot_general %289, %306, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %308 = stablehlo.reshape %307 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %309 = "stablehlo.scatter"(%arg35, %5, %308) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %310 = sdy.sharding_constraint %309 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %311 = stablehlo.convert %arg43 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %312 = stablehlo.reshape %311 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %313 = stablehlo.transpose %arg40, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %314 = stablehlo.dot_general %289, %313, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %315 = stablehlo.reshape %314 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %316 = stablehlo.convert %315 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %317 = stablehlo.multiply %316, %69 : tensor<1x24x1x128xf32>
    %318 = stablehlo.convert %317 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %319 = stablehlo.slice %315 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %320 = stablehlo.negate %319 : tensor<1x24x1x64xbf16>
    %321 = stablehlo.slice %315 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %322 = stablehlo.concatenate %320, %321, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %323 = stablehlo.convert %322 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %324 = stablehlo.multiply %323, %77 : tensor<1x24x1x128xf32>
    %325 = stablehlo.convert %324 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %326 = stablehlo.add %318, %325 : tensor<1x24x1x128xbf16>
    %327 = stablehlo.reshape %326 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %328 = stablehlo.broadcast_in_dim %304, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %329 = stablehlo.reshape %328 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %330 = stablehlo.transpose %329, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %331 = stablehlo.reshape %330 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %332 = stablehlo.dot_general %327, %331, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %333 = stablehlo.convert %332 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %334 = stablehlo.reshape %333 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %335 = stablehlo.multiply %334, %89 : tensor<1x24x1x128xf32>
    %336 = stablehlo.convert %335 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %337 = stablehlo.add %336, %100 : tensor<1x24x1x128xbf16>
    %338 = stablehlo.convert %337 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %339 = stablehlo.reduce(%338 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %340 = stablehlo.broadcast_in_dim %339, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %341 = stablehlo.subtract %338, %340 : tensor<1x24x1x128xf32>
    %342 = stablehlo.exponential %341 : tensor<1x24x1x128xf32>
    %343 = stablehlo.reduce(%342 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %344 = stablehlo.broadcast_in_dim %343, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %345 = stablehlo.divide %342, %344 : tensor<1x24x1x128xf32>
    %346 = stablehlo.convert %345 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %347 = stablehlo.reshape %346 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %348 = stablehlo.broadcast_in_dim %309, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %349 = stablehlo.reshape %348 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %350 = stablehlo.dot_general %347, %349, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %351 = stablehlo.reshape %350 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %352 = stablehlo.transpose %arg39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %353 = stablehlo.dot_general %351, %352, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %354 = stablehlo.reshape %353 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %355 = stablehlo.add %274, %354 : tensor<1x1x3072xbf16>
    %356 = stablehlo.convert %arg41 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %357 = stablehlo.reshape %356 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %358 = stablehlo.convert %355 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %359 = stablehlo.power %358, %0 : tensor<1x1x3072xf32>
    %360 = stablehlo.reduce(%359 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %361 = stablehlo.multiply %360, %cst_1 : tensor<1x1xf32>
    %362 = stablehlo.reshape %361 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %363 = stablehlo.add %362, %17 : tensor<1x1x1xf32>
    %364 = stablehlo.rsqrt %363 : tensor<1x1x1xf32>
    %365 = stablehlo.reshape %364 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %366 = stablehlo.broadcast_in_dim %365, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %367 = stablehlo.multiply %358, %366 : tensor<1x1x3072xf32>
    %368 = stablehlo.convert %367 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %369 = stablehlo.convert %368 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %370 = stablehlo.multiply %357, %369 : tensor<1x1x3072xf32>
    %371 = stablehlo.convert %370 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %372 = stablehlo.reshape %371 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %373 = stablehlo.transpose %arg42, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %374 = stablehlo.dot_general %372, %373, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %375 = stablehlo.reshape %374 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %376 = stablehlo.convert %375 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %377 = stablehlo.logistic %375 : tensor<1x1x8192xbf16>
    %378 = stablehlo.convert %377 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %379 = stablehlo.multiply %376, %378 : tensor<1x1x8192xf32>
    %380 = stablehlo.convert %379 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %381 = stablehlo.convert %380 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %382 = stablehlo.transpose %arg38, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %383 = stablehlo.dot_general %372, %382, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %384 = stablehlo.convert %383 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %385 = stablehlo.reshape %384 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %386 = stablehlo.multiply %381, %385 : tensor<1x1x8192xf32>
    %387 = stablehlo.convert %386 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %388 = stablehlo.reshape %387 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %389 = stablehlo.transpose %arg37, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %390 = stablehlo.dot_general %388, %389, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %391 = stablehlo.reshape %390 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %392 = stablehlo.add %355, %391 : tensor<1x1x3072xbf16>
    %393 = stablehlo.convert %392 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %394 = stablehlo.power %393, %0 : tensor<1x1x3072xf32>
    %395 = stablehlo.reduce(%394 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %396 = stablehlo.multiply %395, %cst_1 : tensor<1x1xf32>
    %397 = stablehlo.reshape %396 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %398 = stablehlo.add %397, %17 : tensor<1x1x1xf32>
    %399 = stablehlo.rsqrt %398 : tensor<1x1x1xf32>
    %400 = stablehlo.reshape %399 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %401 = stablehlo.broadcast_in_dim %400, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %402 = stablehlo.multiply %393, %401 : tensor<1x1x3072xf32>
    %403 = stablehlo.convert %402 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %404 = stablehlo.convert %403 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %405 = stablehlo.multiply %312, %404 : tensor<1x1x3072xf32>
    %406 = stablehlo.convert %405 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %407 = stablehlo.reshape %406 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %408 = stablehlo.transpose %arg36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %409 = stablehlo.dot_general %407, %408, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %410 = stablehlo.reshape %409 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %411 = stablehlo.convert %410 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %412 = stablehlo.multiply %411, %41 : tensor<1x8x1x128xf32>
    %413 = stablehlo.convert %412 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %414 = stablehlo.slice %410 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %415 = stablehlo.negate %414 : tensor<1x8x1x64xbf16>
    %416 = stablehlo.slice %410 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %417 = stablehlo.concatenate %415, %416, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %418 = stablehlo.convert %417 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %419 = stablehlo.multiply %418, %52 : tensor<1x8x1x128xf32>
    %420 = stablehlo.convert %419 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %421 = stablehlo.add %413, %420 : tensor<1x8x1x128xbf16>
    %422 = "stablehlo.scatter"(%arg44, %5, %421) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %423 = sdy.sharding_constraint %422 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %424 = stablehlo.transpose %arg45, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %425 = stablehlo.dot_general %407, %424, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %426 = stablehlo.reshape %425 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %427 = "stablehlo.scatter"(%arg46, %5, %426) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %428 = sdy.sharding_constraint %427 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %429 = stablehlo.convert %arg53 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %430 = stablehlo.reshape %429 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %431 = stablehlo.transpose %arg50, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %432 = stablehlo.dot_general %407, %431, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %433 = stablehlo.reshape %432 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %434 = stablehlo.convert %433 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %435 = stablehlo.multiply %434, %69 : tensor<1x24x1x128xf32>
    %436 = stablehlo.convert %435 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %437 = stablehlo.slice %433 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %438 = stablehlo.negate %437 : tensor<1x24x1x64xbf16>
    %439 = stablehlo.slice %433 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %440 = stablehlo.concatenate %438, %439, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %441 = stablehlo.convert %440 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %442 = stablehlo.multiply %441, %77 : tensor<1x24x1x128xf32>
    %443 = stablehlo.convert %442 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %444 = stablehlo.add %436, %443 : tensor<1x24x1x128xbf16>
    %445 = stablehlo.reshape %444 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %446 = stablehlo.broadcast_in_dim %422, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %447 = stablehlo.reshape %446 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %448 = stablehlo.transpose %447, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %449 = stablehlo.reshape %448 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %450 = stablehlo.dot_general %445, %449, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %451 = stablehlo.convert %450 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %452 = stablehlo.reshape %451 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %453 = stablehlo.multiply %452, %89 : tensor<1x24x1x128xf32>
    %454 = stablehlo.convert %453 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %455 = stablehlo.add %454, %100 : tensor<1x24x1x128xbf16>
    %456 = stablehlo.convert %455 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %457 = stablehlo.reduce(%456 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %458 = stablehlo.broadcast_in_dim %457, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %459 = stablehlo.subtract %456, %458 : tensor<1x24x1x128xf32>
    %460 = stablehlo.exponential %459 : tensor<1x24x1x128xf32>
    %461 = stablehlo.reduce(%460 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %462 = stablehlo.broadcast_in_dim %461, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %463 = stablehlo.divide %460, %462 : tensor<1x24x1x128xf32>
    %464 = stablehlo.convert %463 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %465 = stablehlo.reshape %464 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %466 = stablehlo.broadcast_in_dim %427, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %467 = stablehlo.reshape %466 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %468 = stablehlo.dot_general %465, %467, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %469 = stablehlo.reshape %468 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %470 = stablehlo.transpose %arg49, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %471 = stablehlo.dot_general %469, %470, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %472 = stablehlo.reshape %471 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %473 = stablehlo.add %392, %472 : tensor<1x1x3072xbf16>
    %474 = stablehlo.convert %arg51 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %475 = stablehlo.reshape %474 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %476 = stablehlo.convert %473 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %477 = stablehlo.power %476, %0 : tensor<1x1x3072xf32>
    %478 = stablehlo.reduce(%477 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %479 = stablehlo.multiply %478, %cst_1 : tensor<1x1xf32>
    %480 = stablehlo.reshape %479 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %481 = stablehlo.add %480, %17 : tensor<1x1x1xf32>
    %482 = stablehlo.rsqrt %481 : tensor<1x1x1xf32>
    %483 = stablehlo.reshape %482 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %484 = stablehlo.broadcast_in_dim %483, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %485 = stablehlo.multiply %476, %484 : tensor<1x1x3072xf32>
    %486 = stablehlo.convert %485 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %487 = stablehlo.convert %486 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %488 = stablehlo.multiply %475, %487 : tensor<1x1x3072xf32>
    %489 = stablehlo.convert %488 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %490 = stablehlo.reshape %489 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %491 = stablehlo.transpose %arg52, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %492 = stablehlo.dot_general %490, %491, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %493 = stablehlo.reshape %492 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %494 = stablehlo.convert %493 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %495 = stablehlo.logistic %493 : tensor<1x1x8192xbf16>
    %496 = stablehlo.convert %495 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %497 = stablehlo.multiply %494, %496 : tensor<1x1x8192xf32>
    %498 = stablehlo.convert %497 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %499 = stablehlo.convert %498 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %500 = stablehlo.transpose %arg48, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %501 = stablehlo.dot_general %490, %500, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %502 = stablehlo.convert %501 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %503 = stablehlo.reshape %502 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %504 = stablehlo.multiply %499, %503 : tensor<1x1x8192xf32>
    %505 = stablehlo.convert %504 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %506 = stablehlo.reshape %505 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %507 = stablehlo.transpose %arg47, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %508 = stablehlo.dot_general %506, %507, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %509 = stablehlo.reshape %508 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %510 = stablehlo.add %473, %509 : tensor<1x1x3072xbf16>
    %511 = stablehlo.convert %510 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %512 = stablehlo.power %511, %0 : tensor<1x1x3072xf32>
    %513 = stablehlo.reduce(%512 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %514 = stablehlo.multiply %513, %cst_1 : tensor<1x1xf32>
    %515 = stablehlo.reshape %514 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %516 = stablehlo.add %515, %17 : tensor<1x1x1xf32>
    %517 = stablehlo.rsqrt %516 : tensor<1x1x1xf32>
    %518 = stablehlo.reshape %517 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %519 = stablehlo.broadcast_in_dim %518, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %520 = stablehlo.multiply %511, %519 : tensor<1x1x3072xf32>
    %521 = stablehlo.convert %520 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %522 = stablehlo.convert %521 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %523 = stablehlo.multiply %430, %522 : tensor<1x1x3072xf32>
    %524 = stablehlo.convert %523 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %525 = stablehlo.reshape %524 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %526 = stablehlo.transpose %arg5, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %527 = stablehlo.dot_general %525, %526, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<1x128256xbf16>
    %528 = stablehlo.reshape %527 : (tensor<1x128256xbf16>) -> tensor<1x1x128256xbf16>
    return %57, %62, %187, %192, %305, %310, %423, %428, %527, %528 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>
  }
}
module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<64xf32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg3: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg4: tensor<1x1xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg5: tensor<128256x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg6: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg7: tensor<i64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg8: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg9: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg10: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg11: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg12: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg13: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg14: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg15: tensor<128xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg16: tensor<1x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg17: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg18: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg19: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg20: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg21: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg22: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg23: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg24: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg25: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg26: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg27: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg28: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg29: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg30: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg31: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg32: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg33: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg34: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg35: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg36: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg37: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg38: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg39: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg40: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg41: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg42: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg43: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg44: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg45: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg46: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg47: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg48: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg49: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg50: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg51: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg52: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg53: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:10 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18, %arg19, %arg20, %arg21, %arg22, %arg23, %arg24, %arg25, %arg26, %arg27, %arg28, %arg29, %arg30, %arg31, %arg32, %arg33, %arg34, %arg35, %arg36, %arg37, %arg38, %arg39, %arg40, %arg41, %arg42, %arg43, %arg44, %arg45, %arg46, %arg47, %arg48, %arg49, %arg50, %arg51, %arg52, %arg53) in_shardings=[<@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>, <@mesh, []>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{}, {}, {"_axis_0"}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg54: tensor<1xi64>, %arg55: tensor<64xf32>, %arg56: tensor<512x3072xbf16>, %arg57: tensor<f32>, %arg58: tensor<1x1xi64>, %arg59: tensor<64128x3072xbf16>, %arg60: tensor<3072xbf16>, %arg61: tensor<i64>, %arg62: tensor<1x4x128x128xbf16>, %arg63: tensor<512x3072xbf16>, %arg64: tensor<1x4x128x128xbf16>, %arg65: tensor<512x3072xbf16>, %arg66: tensor<3072x4096xbf16>, %arg67: tensor<4096x3072xbf16>, %arg68: tensor<3072x1536xbf16>, %arg69: tensor<128xi64>, %arg70: tensor<1x128xbf16>, %arg71: tensor<f32>, %arg72: tensor<1536x3072xbf16>, %arg73: tensor<3072xbf16>, %arg74: tensor<4096x3072xbf16>, %arg75: tensor<3072xbf16>, %arg76: tensor<1x4x128x128xbf16>, %arg77: tensor<512x3072xbf16>, %arg78: tensor<1x4x128x128xbf16>, %arg79: tensor<512x3072xbf16>, %arg80: tensor<3072x4096xbf16>, %arg81: tensor<4096x3072xbf16>, %arg82: tensor<3072x1536xbf16>, %arg83: tensor<1536x3072xbf16>, %arg84: tensor<3072xbf16>, %arg85: tensor<4096x3072xbf16>, %arg86: tensor<3072xbf16>, %arg87: tensor<1x4x128x128xbf16>, %arg88: tensor<512x3072xbf16>, %arg89: tensor<1x4x128x128xbf16>, %arg90: tensor<512x3072xbf16>, %arg91: tensor<3072x4096xbf16>, %arg92: tensor<4096x3072xbf16>, %arg93: tensor<3072x1536xbf16>, %arg94: tensor<1536x3072xbf16>, %arg95: tensor<3072xbf16>, %arg96: tensor<4096x3072xbf16>, %arg97: tensor<3072xbf16>, %arg98: tensor<1x4x128x128xbf16>, %arg99: tensor<512x3072xbf16>, %arg100: tensor<1x4x128x128xbf16>, %arg101: tensor<3072x4096xbf16>, %arg102: tensor<4096x3072xbf16>, %arg103: tensor<3072x1536xbf16>, %arg104: tensor<1536x3072xbf16>, %arg105: tensor<3072xbf16>, %arg106: tensor<4096x3072xbf16>, %arg107: tensor<3072xbf16>) {
      %c = stablehlo.constant dense<0> : tensor<1xi64>
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x1xf32>
      %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %1 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32>
      %2 = stablehlo.compare  LT, %arg54, %c : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1>
      %3 = stablehlo.reshape %arg61 : (tensor<i64>) -> tensor<1xi64>
      %4 = stablehlo.add %arg54, %3 : tensor<1xi64>
      %5 = stablehlo.select %2, %4, %arg54 : tensor<1xi1>, tensor<1xi64>
      %6 = stablehlo.reshape %5 : (tensor<1xi64>) -> tensor<1x1xi64>
      %7 = stablehlo.convert %arg60 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %8 = stablehlo.reshape %7 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %9 = stablehlo.convert %arg58 : (tensor<1x1xi64>) -> tensor<1x1xui32>
      %10 = stablehlo.reshape %9 : (tensor<1x1xui32>) -> tensor<1xui32>
      %11 = "stablehlo.gather"(%arg59, %10) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<64128x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16>
      %12 = "stablehlo.all_reduce"(%11) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %13 = stablehlo.reshape %12 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %14 = stablehlo.convert %13 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %15 = stablehlo.power %14, %1 : tensor<1x1x3072xf32>
      %16 = stablehlo.reduce(%15 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %17 = stablehlo.multiply %16, %cst_1 : tensor<1x1xf32>
      %18 = stablehlo.reshape %17 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %19 = stablehlo.reshape %arg57 : (tensor<f32>) -> tensor<1x1x1xf32>
      %20 = stablehlo.add %18, %19 : tensor<1x1x1xf32>
      %21 = stablehlo.rsqrt %20 : tensor<1x1x1xf32>
      %22 = stablehlo.reshape %21 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %23 = stablehlo.broadcast_in_dim %22, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %24 = stablehlo.multiply %14, %23 : tensor<1x1x3072xf32>
      %25 = stablehlo.convert %24 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %26 = stablehlo.convert %25 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %27 = stablehlo.multiply %8, %26 : tensor<1x1x3072xf32>
      %28 = stablehlo.convert %27 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %29 = stablehlo.reshape %28 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %30 = stablehlo.transpose %arg56, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %31 = stablehlo.dot_general %29, %30, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %32 = stablehlo.reshape %31 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %33 = stablehlo.convert %32 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %34 = stablehlo.reshape %arg55 : (tensor<64xf32>) -> tensor<1x64x1xf32>
      %35 = stablehlo.convert %arg54 : (tensor<1xi64>) -> tensor<1xf32>
      %36 = stablehlo.reshape %35 : (tensor<1xf32>) -> tensor<1x1x1xf32>
      %37 = stablehlo.dot_general %34, %36, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32>
      %38 = stablehlo.reshape %37 : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32>
      %39 = stablehlo.concatenate %38, %38, dim = 2 : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32>
      %40 = stablehlo.cosine %39 : tensor<1x1x128xf32>
      %41 = stablehlo.convert %40 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
      %42 = stablehlo.convert %41 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
      %43 = stablehlo.broadcast_in_dim %42, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x4x1x128xf32>
      %44 = stablehlo.multiply %33, %43 : tensor<1x4x1x128xf32>
      %45 = stablehlo.convert %44 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %46 = stablehlo.slice %32 [0:1, 0:4, 0:1, 64:128] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %47 = stablehlo.negate %46 : tensor<1x4x1x64xbf16>
      %48 = stablehlo.slice %32 [0:1, 0:4, 0:1, 0:64] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %49 = stablehlo.concatenate %47, %48, dim = 3 : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x128xbf16>
      %50 = stablehlo.convert %49 : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %51 = stablehlo.sine %39 : tensor<1x1x128xf32>
      %52 = stablehlo.convert %51 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
      %53 = stablehlo.convert %52 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
      %54 = stablehlo.broadcast_in_dim %53, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x4x1x128xf32>
      %55 = stablehlo.multiply %50, %54 : tensor<1x4x1x128xf32>
      %56 = stablehlo.convert %55 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %57 = stablehlo.add %45, %56 : tensor<1x4x1x128xbf16>
      %58 = "stablehlo.scatter"(%arg62, %6, %57) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %59 = stablehlo.transpose %arg63, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %60 = stablehlo.dot_general %29, %59, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %61 = stablehlo.reshape %60 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %62 = "stablehlo.scatter"(%arg64, %6, %61) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %63 = stablehlo.convert %arg75 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %64 = stablehlo.reshape %63 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %65 = stablehlo.transpose %arg72, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %66 = stablehlo.dot_general %29, %65, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
      %67 = stablehlo.reshape %66 : (tensor<1x1536xbf16>) -> tensor<1x12x1x128xbf16>
      %68 = stablehlo.convert %67 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %69 = stablehlo.broadcast_in_dim %42, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x12x1x128xf32>
      %70 = stablehlo.multiply %68, %69 : tensor<1x12x1x128xf32>
      %71 = stablehlo.convert %70 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %72 = stablehlo.slice %67 [0:1, 0:12, 0:1, 64:128] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %73 = stablehlo.negate %72 : tensor<1x12x1x64xbf16>
      %74 = stablehlo.slice %67 [0:1, 0:12, 0:1, 0:64] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %75 = stablehlo.concatenate %73, %74, dim = 3 : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x128xbf16>
      %76 = stablehlo.convert %75 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %77 = stablehlo.broadcast_in_dim %53, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x12x1x128xf32>
      %78 = stablehlo.multiply %76, %77 : tensor<1x12x1x128xf32>
      %79 = stablehlo.convert %78 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %80 = stablehlo.add %71, %79 : tensor<1x12x1x128xbf16>
      %81 = stablehlo.reshape %80 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %82 = stablehlo.broadcast_in_dim %58, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %83 = stablehlo.reshape %82 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %84 = stablehlo.transpose %83, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %85 = stablehlo.reshape %84 : (tensor<1x12x128x128xbf16>) -> tensor<12x128x128xbf16>
      %86 = stablehlo.dot_general %81, %85, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %87 = stablehlo.convert %86 : (tensor<12x1x128xbf16>) -> tensor<12x1x128xf32>
      %88 = stablehlo.reshape %87 : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>
      %89 = stablehlo.broadcast_in_dim %arg71, dims = [] : (tensor<f32>) -> tensor<1x12x1x128xf32>
      %90 = stablehlo.multiply %88, %89 : tensor<1x12x1x128xf32>
      %91 = stablehlo.convert %90 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %92 = stablehlo.convert %arg70 : (tensor<1x128xbf16>) -> tensor<1x128xf32>
      %93 = stablehlo.reshape %arg69 : (tensor<128xi64>) -> tensor<1x128xi64>
      %94 = stablehlo.broadcast_in_dim %arg54, dims = [0] : (tensor<1xi64>) -> tensor<1x128xi64>
      %95 = stablehlo.compare  GT, %93, %94 : (tensor<1x128xi64>, tensor<1x128xi64>) -> tensor<1x128xi1>
      %96 = stablehlo.convert %95 : (tensor<1x128xi1>) -> tensor<1x128xf32>
      %97 = stablehlo.multiply %92, %96 : tensor<1x128xf32>
      %98 = stablehlo.convert %97 : (tensor<1x128xf32>) -> tensor<1x128xbf16>
      %99 = stablehlo.reshape %98 : (tensor<1x128xbf16>) -> tensor<1x1x128xbf16>
      %100 = stablehlo.broadcast_in_dim %99, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x12x1x128xbf16>
      %101 = stablehlo.add %91, %100 : tensor<1x12x1x128xbf16>
      %102 = stablehlo.convert %101 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %103 = stablehlo.reduce(%102 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %105 = stablehlo.subtract %102, %104 : tensor<1x12x1x128xf32>
      %106 = stablehlo.exponential %105 : tensor<1x12x1x128xf32>
      %107 = stablehlo.reduce(%106 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %108 = stablehlo.broadcast_in_dim %107, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %109 = stablehlo.divide %106, %108 : tensor<1x12x1x128xf32>
      %110 = stablehlo.convert %109 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %111 = stablehlo.reshape %110 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %112 = stablehlo.broadcast_in_dim %62, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %113 = stablehlo.reshape %112 : (tensor<1x4x3x128x128xbf16>) -> tensor<12x128x128xbf16>
      %114 = stablehlo.dot_general %111, %113, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %115 = stablehlo.reshape %114 : (tensor<12x1x128xbf16>) -> tensor<1x1536xbf16>
      %116 = stablehlo.transpose %arg68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
      %117 = stablehlo.dot_general %115, %116, contracting_dims = [1] x [0] : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
      %118 = "stablehlo.all_reduce"(%117) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %119 = stablehlo.reshape %118 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %120 = stablehlo.add %13, %119 : tensor<1x1x3072xbf16>
      %121 = stablehlo.convert %arg73 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %122 = stablehlo.reshape %121 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %123 = stablehlo.convert %120 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %124 = stablehlo.power %123, %1 : tensor<1x1x3072xf32>
      %125 = stablehlo.reduce(%124 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %126 = stablehlo.multiply %125, %cst_1 : tensor<1x1xf32>
      %127 = stablehlo.reshape %126 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %128 = stablehlo.add %127, %19 : tensor<1x1x1xf32>
      %129 = stablehlo.rsqrt %128 : tensor<1x1x1xf32>
      %130 = stablehlo.reshape %129 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %131 = stablehlo.broadcast_in_dim %130, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %132 = stablehlo.multiply %123, %131 : tensor<1x1x3072xf32>
      %133 = stablehlo.convert %132 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %134 = stablehlo.convert %133 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %135 = stablehlo.multiply %122, %134 : tensor<1x1x3072xf32>
      %136 = stablehlo.convert %135 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %137 = stablehlo.reshape %136 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %138 = stablehlo.transpose %arg74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %139 = stablehlo.dot_general %137, %138, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %140 = stablehlo.reshape %139 : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16>
      %141 = stablehlo.convert %140 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %142 = stablehlo.logistic %140 : tensor<1x1x4096xbf16>
      %143 = stablehlo.convert %142 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %144 = stablehlo.multiply %141, %143 : tensor<1x1x4096xf32>
      %145 = stablehlo.convert %144 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %146 = stablehlo.convert %145 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %147 = stablehlo.transpose %arg67, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %148 = stablehlo.dot_general %137, %147, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %149 = stablehlo.convert %148 : (tensor<1x4096xbf16>) -> tensor<1x4096xf32>
      %150 = stablehlo.reshape %149 : (tensor<1x4096xf32>) -> tensor<1x1x4096xf32>
      %151 = stablehlo.multiply %146, %150 : tensor<1x1x4096xf32>
      %152 = stablehlo.convert %151 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %153 = stablehlo.reshape %152 : (tensor<1x1x4096xbf16>) -> tensor<1x4096xbf16>
      %154 = stablehlo.transpose %arg66, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
      %155 = stablehlo.dot_general %153, %154, contracting_dims = [1] x [0] : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
      %156 = "stablehlo.all_reduce"(%155) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %157 = stablehlo.reshape %156 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %158 = stablehlo.add %120, %157 : tensor<1x1x3072xbf16>
      %159 = stablehlo.convert %158 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %160 = stablehlo.power %159, %1 : tensor<1x1x3072xf32>
      %161 = stablehlo.reduce(%160 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %162 = stablehlo.multiply %161, %cst_1 : tensor<1x1xf32>
      %163 = stablehlo.reshape %162 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %164 = stablehlo.add %163, %19 : tensor<1x1x1xf32>
      %165 = stablehlo.rsqrt %164 : tensor<1x1x1xf32>
      %166 = stablehlo.reshape %165 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %167 = stablehlo.broadcast_in_dim %166, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %168 = stablehlo.multiply %159, %167 : tensor<1x1x3072xf32>
      %169 = stablehlo.convert %168 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %170 = stablehlo.convert %169 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %171 = stablehlo.multiply %64, %170 : tensor<1x1x3072xf32>
      %172 = stablehlo.convert %171 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %173 = stablehlo.reshape %172 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %174 = stablehlo.transpose %arg65, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %175 = stablehlo.dot_general %173, %174, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %176 = stablehlo.reshape %175 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %177 = stablehlo.convert %176 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %178 = stablehlo.multiply %177, %43 : tensor<1x4x1x128xf32>
      %179 = stablehlo.convert %178 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %180 = stablehlo.slice %176 [0:1, 0:4, 0:1, 64:128] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %181 = stablehlo.negate %180 : tensor<1x4x1x64xbf16>
      %182 = stablehlo.slice %176 [0:1, 0:4, 0:1, 0:64] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %183 = stablehlo.concatenate %181, %182, dim = 3 : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x128xbf16>
      %184 = stablehlo.convert %183 : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %185 = stablehlo.multiply %184, %54 : tensor<1x4x1x128xf32>
      %186 = stablehlo.convert %185 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %187 = stablehlo.add %179, %186 : tensor<1x4x1x128xbf16>
      %188 = "stablehlo.scatter"(%arg76, %6, %187) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %189 = stablehlo.transpose %arg77, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %190 = stablehlo.dot_general %173, %189, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %191 = stablehlo.reshape %190 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %192 = "stablehlo.scatter"(%arg78, %6, %191) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %193 = stablehlo.convert %arg86 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %194 = stablehlo.reshape %193 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %195 = stablehlo.transpose %arg83, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %196 = stablehlo.dot_general %173, %195, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
      %197 = stablehlo.reshape %196 : (tensor<1x1536xbf16>) -> tensor<1x12x1x128xbf16>
      %198 = stablehlo.convert %197 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %199 = stablehlo.multiply %198, %69 : tensor<1x12x1x128xf32>
      %200 = stablehlo.convert %199 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %201 = stablehlo.slice %197 [0:1, 0:12, 0:1, 64:128] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %202 = stablehlo.negate %201 : tensor<1x12x1x64xbf16>
      %203 = stablehlo.slice %197 [0:1, 0:12, 0:1, 0:64] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %204 = stablehlo.concatenate %202, %203, dim = 3 : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x128xbf16>
      %205 = stablehlo.convert %204 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %206 = stablehlo.multiply %205, %77 : tensor<1x12x1x128xf32>
      %207 = stablehlo.convert %206 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %208 = stablehlo.add %200, %207 : tensor<1x12x1x128xbf16>
      %209 = stablehlo.reshape %208 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %210 = stablehlo.broadcast_in_dim %188, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %211 = stablehlo.reshape %210 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %212 = stablehlo.transpose %211, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %213 = stablehlo.reshape %212 : (tensor<1x12x128x128xbf16>) -> tensor<12x128x128xbf16>
      %214 = stablehlo.dot_general %209, %213, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %215 = stablehlo.convert %214 : (tensor<12x1x128xbf16>) -> tensor<12x1x128xf32>
      %216 = stablehlo.reshape %215 : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>
      %217 = stablehlo.multiply %216, %89 : tensor<1x12x1x128xf32>
      %218 = stablehlo.convert %217 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %219 = stablehlo.add %218, %100 : tensor<1x12x1x128xbf16>
      %220 = stablehlo.convert %219 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %221 = stablehlo.reduce(%220 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %222 = stablehlo.broadcast_in_dim %221, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %223 = stablehlo.subtract %220, %222 : tensor<1x12x1x128xf32>
      %224 = stablehlo.exponential %223 : tensor<1x12x1x128xf32>
      %225 = stablehlo.reduce(%224 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %226 = stablehlo.broadcast_in_dim %225, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %227 = stablehlo.divide %224, %226 : tensor<1x12x1x128xf32>
      %228 = stablehlo.convert %227 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %229 = stablehlo.reshape %228 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %230 = stablehlo.broadcast_in_dim %192, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %231 = stablehlo.reshape %230 : (tensor<1x4x3x128x128xbf16>) -> tensor<12x128x128xbf16>
      %232 = stablehlo.dot_general %229, %231, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %233 = stablehlo.reshape %232 : (tensor<12x1x128xbf16>) -> tensor<1x1536xbf16>
      %234 = stablehlo.transpose %arg82, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
      %235 = stablehlo.dot_general %233, %234, contracting_dims = [1] x [0] : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
      %236 = "stablehlo.all_reduce"(%235) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %237 = stablehlo.reshape %236 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %238 = stablehlo.add %158, %237 : tensor<1x1x3072xbf16>
      %239 = stablehlo.convert %arg84 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %240 = stablehlo.reshape %239 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %241 = stablehlo.convert %238 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %242 = stablehlo.power %241, %1 : tensor<1x1x3072xf32>
      %243 = stablehlo.reduce(%242 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %244 = stablehlo.multiply %243, %cst_1 : tensor<1x1xf32>
      %245 = stablehlo.reshape %244 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %246 = stablehlo.add %245, %19 : tensor<1x1x1xf32>
      %247 = stablehlo.rsqrt %246 : tensor<1x1x1xf32>
      %248 = stablehlo.reshape %247 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %249 = stablehlo.broadcast_in_dim %248, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %250 = stablehlo.multiply %241, %249 : tensor<1x1x3072xf32>
      %251 = stablehlo.convert %250 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %252 = stablehlo.convert %251 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %253 = stablehlo.multiply %240, %252 : tensor<1x1x3072xf32>
      %254 = stablehlo.convert %253 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %255 = stablehlo.reshape %254 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %256 = stablehlo.transpose %arg85, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %257 = stablehlo.dot_general %255, %256, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %258 = stablehlo.reshape %257 : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16>
      %259 = stablehlo.convert %258 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %260 = stablehlo.logistic %258 : tensor<1x1x4096xbf16>
      %261 = stablehlo.convert %260 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %262 = stablehlo.multiply %259, %261 : tensor<1x1x4096xf32>
      %263 = stablehlo.convert %262 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %264 = stablehlo.convert %263 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %265 = stablehlo.transpose %arg81, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %266 = stablehlo.dot_general %255, %265, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %267 = stablehlo.convert %266 : (tensor<1x4096xbf16>) -> tensor<1x4096xf32>
      %268 = stablehlo.reshape %267 : (tensor<1x4096xf32>) -> tensor<1x1x4096xf32>
      %269 = stablehlo.multiply %264, %268 : tensor<1x1x4096xf32>
      %270 = stablehlo.convert %269 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %271 = stablehlo.reshape %270 : (tensor<1x1x4096xbf16>) -> tensor<1x4096xbf16>
      %272 = stablehlo.transpose %arg80, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
      %273 = stablehlo.dot_general %271, %272, contracting_dims = [1] x [0] : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
      %274 = "stablehlo.all_reduce"(%273) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %275 = stablehlo.reshape %274 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %276 = stablehlo.add %238, %275 : tensor<1x1x3072xbf16>
      %277 = stablehlo.convert %276 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %278 = stablehlo.power %277, %1 : tensor<1x1x3072xf32>
      %279 = stablehlo.reduce(%278 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %280 = stablehlo.multiply %279, %cst_1 : tensor<1x1xf32>
      %281 = stablehlo.reshape %280 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %282 = stablehlo.add %281, %19 : tensor<1x1x1xf32>
      %283 = stablehlo.rsqrt %282 : tensor<1x1x1xf32>
      %284 = stablehlo.reshape %283 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %285 = stablehlo.broadcast_in_dim %284, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %286 = stablehlo.multiply %277, %285 : tensor<1x1x3072xf32>
      %287 = stablehlo.convert %286 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %288 = stablehlo.convert %287 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %289 = stablehlo.multiply %194, %288 : tensor<1x1x3072xf32>
      %290 = stablehlo.convert %289 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %291 = stablehlo.reshape %290 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %292 = stablehlo.transpose %arg79, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %293 = stablehlo.dot_general %291, %292, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %294 = stablehlo.reshape %293 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %295 = stablehlo.convert %294 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %296 = stablehlo.multiply %295, %43 : tensor<1x4x1x128xf32>
      %297 = stablehlo.convert %296 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %298 = stablehlo.slice %294 [0:1, 0:4, 0:1, 64:128] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %299 = stablehlo.negate %298 : tensor<1x4x1x64xbf16>
      %300 = stablehlo.slice %294 [0:1, 0:4, 0:1, 0:64] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %301 = stablehlo.concatenate %299, %300, dim = 3 : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x128xbf16>
      %302 = stablehlo.convert %301 : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %303 = stablehlo.multiply %302, %54 : tensor<1x4x1x128xf32>
      %304 = stablehlo.convert %303 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %305 = stablehlo.add %297, %304 : tensor<1x4x1x128xbf16>
      %306 = "stablehlo.scatter"(%arg87, %6, %305) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %307 = stablehlo.transpose %arg88, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %308 = stablehlo.dot_general %291, %307, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %309 = stablehlo.reshape %308 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %310 = "stablehlo.scatter"(%arg89, %6, %309) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %311 = stablehlo.convert %arg97 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %312 = stablehlo.reshape %311 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %313 = stablehlo.transpose %arg94, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %314 = stablehlo.dot_general %291, %313, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
      %315 = stablehlo.reshape %314 : (tensor<1x1536xbf16>) -> tensor<1x12x1x128xbf16>
      %316 = stablehlo.convert %315 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %317 = stablehlo.multiply %316, %69 : tensor<1x12x1x128xf32>
      %318 = stablehlo.convert %317 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %319 = stablehlo.slice %315 [0:1, 0:12, 0:1, 64:128] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %320 = stablehlo.negate %319 : tensor<1x12x1x64xbf16>
      %321 = stablehlo.slice %315 [0:1, 0:12, 0:1, 0:64] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %322 = stablehlo.concatenate %320, %321, dim = 3 : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x128xbf16>
      %323 = stablehlo.convert %322 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %324 = stablehlo.multiply %323, %77 : tensor<1x12x1x128xf32>
      %325 = stablehlo.convert %324 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %326 = stablehlo.add %318, %325 : tensor<1x12x1x128xbf16>
      %327 = stablehlo.reshape %326 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %328 = stablehlo.broadcast_in_dim %306, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %329 = stablehlo.reshape %328 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %330 = stablehlo.transpose %329, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %331 = stablehlo.reshape %330 : (tensor<1x12x128x128xbf16>) -> tensor<12x128x128xbf16>
      %332 = stablehlo.dot_general %327, %331, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %333 = stablehlo.convert %332 : (tensor<12x1x128xbf16>) -> tensor<12x1x128xf32>
      %334 = stablehlo.reshape %333 : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>
      %335 = stablehlo.multiply %334, %89 : tensor<1x12x1x128xf32>
      %336 = stablehlo.convert %335 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %337 = stablehlo.add %336, %100 : tensor<1x12x1x128xbf16>
      %338 = stablehlo.convert %337 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %339 = stablehlo.reduce(%338 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %340 = stablehlo.broadcast_in_dim %339, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %341 = stablehlo.subtract %338, %340 : tensor<1x12x1x128xf32>
      %342 = stablehlo.exponential %341 : tensor<1x12x1x128xf32>
      %343 = stablehlo.reduce(%342 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %344 = stablehlo.broadcast_in_dim %343, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %345 = stablehlo.divide %342, %344 : tensor<1x12x1x128xf32>
      %346 = stablehlo.convert %345 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %347 = stablehlo.reshape %346 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %348 = stablehlo.broadcast_in_dim %310, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %349 = stablehlo.reshape %348 : (tensor<1x4x3x128x128xbf16>) -> tensor<12x128x128xbf16>
      %350 = stablehlo.dot_general %347, %349, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %351 = stablehlo.reshape %350 : (tensor<12x1x128xbf16>) -> tensor<1x1536xbf16>
      %352 = stablehlo.transpose %arg93, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
      %353 = stablehlo.dot_general %351, %352, contracting_dims = [1] x [0] : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
      %354 = "stablehlo.all_reduce"(%353) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %355 = stablehlo.reshape %354 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %356 = stablehlo.add %276, %355 : tensor<1x1x3072xbf16>
      %357 = stablehlo.convert %arg95 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %358 = stablehlo.reshape %357 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %359 = stablehlo.convert %356 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %360 = stablehlo.power %359, %1 : tensor<1x1x3072xf32>
      %361 = stablehlo.reduce(%360 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %362 = stablehlo.multiply %361, %cst_1 : tensor<1x1xf32>
      %363 = stablehlo.reshape %362 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %364 = stablehlo.add %363, %19 : tensor<1x1x1xf32>
      %365 = stablehlo.rsqrt %364 : tensor<1x1x1xf32>
      %366 = stablehlo.reshape %365 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %367 = stablehlo.broadcast_in_dim %366, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %368 = stablehlo.multiply %359, %367 : tensor<1x1x3072xf32>
      %369 = stablehlo.convert %368 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %370 = stablehlo.convert %369 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %371 = stablehlo.multiply %358, %370 : tensor<1x1x3072xf32>
      %372 = stablehlo.convert %371 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %373 = stablehlo.reshape %372 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %374 = stablehlo.transpose %arg96, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %375 = stablehlo.dot_general %373, %374, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %376 = stablehlo.reshape %375 : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16>
      %377 = stablehlo.convert %376 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %378 = stablehlo.logistic %376 : tensor<1x1x4096xbf16>
      %379 = stablehlo.convert %378 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %380 = stablehlo.multiply %377, %379 : tensor<1x1x4096xf32>
      %381 = stablehlo.convert %380 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %382 = stablehlo.convert %381 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %383 = stablehlo.transpose %arg92, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %384 = stablehlo.dot_general %373, %383, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %385 = stablehlo.convert %384 : (tensor<1x4096xbf16>) -> tensor<1x4096xf32>
      %386 = stablehlo.reshape %385 : (tensor<1x4096xf32>) -> tensor<1x1x4096xf32>
      %387 = stablehlo.multiply %382, %386 : tensor<1x1x4096xf32>
      %388 = stablehlo.convert %387 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %389 = stablehlo.reshape %388 : (tensor<1x1x4096xbf16>) -> tensor<1x4096xbf16>
      %390 = stablehlo.transpose %arg91, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
      %391 = stablehlo.dot_general %389, %390, contracting_dims = [1] x [0] : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
      %392 = "stablehlo.all_reduce"(%391) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %393 = stablehlo.reshape %392 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %394 = stablehlo.add %356, %393 : tensor<1x1x3072xbf16>
      %395 = stablehlo.convert %394 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %396 = stablehlo.power %395, %1 : tensor<1x1x3072xf32>
      %397 = stablehlo.reduce(%396 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %398 = stablehlo.multiply %397, %cst_1 : tensor<1x1xf32>
      %399 = stablehlo.reshape %398 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %400 = stablehlo.add %399, %19 : tensor<1x1x1xf32>
      %401 = stablehlo.rsqrt %400 : tensor<1x1x1xf32>
      %402 = stablehlo.reshape %401 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %403 = stablehlo.broadcast_in_dim %402, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %404 = stablehlo.multiply %395, %403 : tensor<1x1x3072xf32>
      %405 = stablehlo.convert %404 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %406 = stablehlo.convert %405 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %407 = stablehlo.multiply %312, %406 : tensor<1x1x3072xf32>
      %408 = stablehlo.convert %407 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %409 = stablehlo.reshape %408 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %410 = stablehlo.transpose %arg90, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %411 = stablehlo.dot_general %409, %410, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %412 = stablehlo.reshape %411 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %413 = stablehlo.convert %412 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %414 = stablehlo.multiply %413, %43 : tensor<1x4x1x128xf32>
      %415 = stablehlo.convert %414 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %416 = stablehlo.slice %412 [0:1, 0:4, 0:1, 64:128] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %417 = stablehlo.negate %416 : tensor<1x4x1x64xbf16>
      %418 = stablehlo.slice %412 [0:1, 0:4, 0:1, 0:64] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %419 = stablehlo.concatenate %417, %418, dim = 3 : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x128xbf16>
      %420 = stablehlo.convert %419 : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %421 = stablehlo.multiply %420, %54 : tensor<1x4x1x128xf32>
      %422 = stablehlo.convert %421 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %423 = stablehlo.add %415, %422 : tensor<1x4x1x128xbf16>
      %424 = "stablehlo.scatter"(%arg98, %6, %423) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %425 = stablehlo.transpose %arg99, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %426 = stablehlo.dot_general %409, %425, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %427 = stablehlo.reshape %426 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %428 = "stablehlo.scatter"(%arg100, %6, %427) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %429 = stablehlo.convert %arg107 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %430 = stablehlo.reshape %429 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %431 = stablehlo.transpose %arg104, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %432 = stablehlo.dot_general %409, %431, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
      %433 = stablehlo.reshape %432 : (tensor<1x1536xbf16>) -> tensor<1x12x1x128xbf16>
      %434 = stablehlo.convert %433 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %435 = stablehlo.multiply %434, %69 : tensor<1x12x1x128xf32>
      %436 = stablehlo.convert %435 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %437 = stablehlo.slice %433 [0:1, 0:12, 0:1, 64:128] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %438 = stablehlo.negate %437 : tensor<1x12x1x64xbf16>
      %439 = stablehlo.slice %433 [0:1, 0:12, 0:1, 0:64] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %440 = stablehlo.concatenate %438, %439, dim = 3 : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x128xbf16>
      %441 = stablehlo.convert %440 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %442 = stablehlo.multiply %441, %77 : tensor<1x12x1x128xf32>
      %443 = stablehlo.convert %442 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %444 = stablehlo.add %436, %443 : tensor<1x12x1x128xbf16>
      %445 = stablehlo.reshape %444 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %446 = stablehlo.broadcast_in_dim %424, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %447 = stablehlo.reshape %446 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %448 = stablehlo.transpose %447, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %449 = stablehlo.reshape %448 : (tensor<1x12x128x128xbf16>) -> tensor<12x128x128xbf16>
      %450 = stablehlo.dot_general %445, %449, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %451 = stablehlo.convert %450 : (tensor<12x1x128xbf16>) -> tensor<12x1x128xf32>
      %452 = stablehlo.reshape %451 : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>
      %453 = stablehlo.multiply %452, %89 : tensor<1x12x1x128xf32>
      %454 = stablehlo.convert %453 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %455 = stablehlo.add %454, %100 : tensor<1x12x1x128xbf16>
      %456 = stablehlo.convert %455 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %457 = stablehlo.reduce(%456 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %458 = stablehlo.broadcast_in_dim %457, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %459 = stablehlo.subtract %456, %458 : tensor<1x12x1x128xf32>
      %460 = stablehlo.exponential %459 : tensor<1x12x1x128xf32>
      %461 = stablehlo.reduce(%460 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %462 = stablehlo.broadcast_in_dim %461, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %463 = stablehlo.divide %460, %462 : tensor<1x12x1x128xf32>
      %464 = stablehlo.convert %463 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %465 = stablehlo.reshape %464 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %466 = stablehlo.broadcast_in_dim %428, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %467 = stablehlo.reshape %466 : (tensor<1x4x3x128x128xbf16>) -> tensor<12x128x128xbf16>
      %468 = stablehlo.dot_general %465, %467, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %469 = stablehlo.reshape %468 : (tensor<12x1x128xbf16>) -> tensor<1x1536xbf16>
      %470 = stablehlo.transpose %arg103, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
      %471 = stablehlo.dot_general %469, %470, contracting_dims = [1] x [0] : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
      %472 = "stablehlo.all_reduce"(%471) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %473 = stablehlo.reshape %472 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %474 = stablehlo.add %394, %473 : tensor<1x1x3072xbf16>
      %475 = stablehlo.convert %arg105 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %476 = stablehlo.reshape %475 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %477 = stablehlo.convert %474 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %478 = stablehlo.power %477, %1 : tensor<1x1x3072xf32>
      %479 = stablehlo.reduce(%478 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %480 = stablehlo.multiply %479, %cst_1 : tensor<1x1xf32>
      %481 = stablehlo.reshape %480 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %482 = stablehlo.add %481, %19 : tensor<1x1x1xf32>
      %483 = stablehlo.rsqrt %482 : tensor<1x1x1xf32>
      %484 = stablehlo.reshape %483 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %485 = stablehlo.broadcast_in_dim %484, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %486 = stablehlo.multiply %477, %485 : tensor<1x1x3072xf32>
      %487 = stablehlo.convert %486 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %488 = stablehlo.convert %487 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %489 = stablehlo.multiply %476, %488 : tensor<1x1x3072xf32>
      %490 = stablehlo.convert %489 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %491 = stablehlo.reshape %490 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %492 = stablehlo.transpose %arg106, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %493 = stablehlo.dot_general %491, %492, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %494 = stablehlo.reshape %493 : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16>
      %495 = stablehlo.convert %494 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %496 = stablehlo.logistic %494 : tensor<1x1x4096xbf16>
      %497 = stablehlo.convert %496 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %498 = stablehlo.multiply %495, %497 : tensor<1x1x4096xf32>
      %499 = stablehlo.convert %498 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %500 = stablehlo.convert %499 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %501 = stablehlo.transpose %arg102, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %502 = stablehlo.dot_general %491, %501, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %503 = stablehlo.convert %502 : (tensor<1x4096xbf16>) -> tensor<1x4096xf32>
      %504 = stablehlo.reshape %503 : (tensor<1x4096xf32>) -> tensor<1x1x4096xf32>
      %505 = stablehlo.multiply %500, %504 : tensor<1x1x4096xf32>
      %506 = stablehlo.convert %505 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %507 = stablehlo.reshape %506 : (tensor<1x1x4096xbf16>) -> tensor<1x4096xbf16>
      %508 = stablehlo.transpose %arg101, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
      %509 = stablehlo.dot_general %507, %508, contracting_dims = [1] x [0] : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
      %510 = "stablehlo.all_reduce"(%509) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %511 = stablehlo.reshape %510 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %512 = stablehlo.add %474, %511 : tensor<1x1x3072xbf16>
      %513 = stablehlo.convert %512 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %514 = stablehlo.power %513, %1 : tensor<1x1x3072xf32>
      %515 = stablehlo.reduce(%514 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %516 = stablehlo.multiply %515, %cst_1 : tensor<1x1xf32>
      %517 = stablehlo.reshape %516 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %518 = stablehlo.add %517, %19 : tensor<1x1x1xf32>
      %519 = stablehlo.rsqrt %518 : tensor<1x1x1xf32>
      %520 = stablehlo.reshape %519 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %521 = stablehlo.broadcast_in_dim %520, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %522 = stablehlo.multiply %513, %521 : tensor<1x1x3072xf32>
      %523 = stablehlo.convert %522 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %524 = stablehlo.convert %523 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %525 = stablehlo.multiply %430, %524 : tensor<1x1x3072xf32>
      %526 = stablehlo.convert %525 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %527 = stablehlo.reshape %526 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %528 = stablehlo.transpose %arg59, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<64128x3072xbf16>) -> tensor<3072x64128xbf16>
      %529 = stablehlo.dot_general %527, %528, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x64128xbf16>) -> tensor<1x64128xbf16>
      %530 = stablehlo.reshape %529 : (tensor<1x64128xbf16>) -> tensor<1x1x64128xbf16>
      sdy.return %58, %62, %188, %192, %306, %310, %424, %428, %529, %530 : tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x64128xbf16>, tensor<1x1x64128xbf16>
    } : (tensor<1xi64>, tensor<64xf32>, tensor<1024x3072xbf16>, tensor<f32>, tensor<1x1xi64>, tensor<128256x3072xbf16>, tensor<3072xbf16>, tensor<i64>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<128xi64>, tensor<1x128xbf16>, tensor<f32>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>)
    return %0#0, %0#1, %0#2, %0#3, %0#4, %0#5, %0#6, %0#7, %0#8, %0#9 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>
  }
}
module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<1xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<64xf32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg3: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg4: tensor<1x1xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg5: tensor<128256x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg6: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg7: tensor<i64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg8: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg9: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg10: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg11: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg12: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg13: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg14: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg15: tensor<128xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg16: tensor<1x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg17: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg18: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg19: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg20: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg21: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg22: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg23: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg24: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg25: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg26: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg27: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg28: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg29: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg30: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg31: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg32: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg33: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg34: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg35: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg36: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg37: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg38: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg39: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg40: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg41: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg42: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg43: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg44: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg45: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg46: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg47: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg48: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg49: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg50: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg51: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg52: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg53: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = ttir.empty() : tensor<1xi64>
    %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi64>
    %2 = ttir.empty() : tensor<64xf32>
    %3 = "ttir.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xf32>
    %4 = ttir.empty() : tensor<512x3072xbf16>
    %5 = "ttir.mesh_shard"(%arg2, %4) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %6 = ttir.empty() : tensor<f32>
    %7 = "ttir.mesh_shard"(%arg3, %6) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32>, tensor<f32>) -> tensor<f32>
    %8 = ttir.empty() : tensor<1x1xi64>
    %9 = "ttir.mesh_shard"(%arg4, %8) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x1xi64>, tensor<1x1xi64>) -> tensor<1x1xi64>
    %10 = ttir.empty() : tensor<64128x3072xbf16>
    %11 = "ttir.mesh_shard"(%arg5, %10) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16>, tensor<64128x3072xbf16>) -> tensor<64128x3072xbf16>
    %12 = ttir.empty() : tensor<3072xbf16>
    %13 = "ttir.mesh_shard"(%arg6, %12) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %14 = ttir.empty() : tensor<i64>
    %15 = "ttir.mesh_shard"(%arg7, %14) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<i64>, tensor<i64>) -> tensor<i64>
    %16 = ttir.empty() : tensor<1x4x128x128xbf16>
    %17 = "ttir.mesh_shard"(%arg8, %16) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %18 = ttir.empty() : tensor<512x3072xbf16>
    %19 = "ttir.mesh_shard"(%arg9, %18) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %20 = ttir.empty() : tensor<1x4x128x128xbf16>
    %21 = "ttir.mesh_shard"(%arg10, %20) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %22 = ttir.empty() : tensor<512x3072xbf16>
    %23 = "ttir.mesh_shard"(%arg11, %22) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %24 = ttir.empty() : tensor<3072x4096xbf16>
    %25 = "ttir.mesh_shard"(%arg12, %24) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %26 = ttir.empty() : tensor<4096x3072xbf16>
    %27 = "ttir.mesh_shard"(%arg13, %26) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %28 = ttir.empty() : tensor<3072x1536xbf16>
    %29 = "ttir.mesh_shard"(%arg14, %28) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %30 = ttir.empty() : tensor<128xi64>
    %31 = "ttir.mesh_shard"(%arg15, %30) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi64>
    %32 = ttir.empty() : tensor<1x128xbf16>
    %33 = "ttir.mesh_shard"(%arg16, %32) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x128xbf16>, tensor<1x128xbf16>) -> tensor<1x128xbf16>
    %34 = ttir.empty() : tensor<f32>
    %35 = "ttir.mesh_shard"(%arg17, %34) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32>, tensor<f32>) -> tensor<f32>
    %36 = ttir.empty() : tensor<1536x3072xbf16>
    %37 = "ttir.mesh_shard"(%arg18, %36) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %38 = ttir.empty() : tensor<3072xbf16>
    %39 = "ttir.mesh_shard"(%arg19, %38) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %40 = ttir.empty() : tensor<4096x3072xbf16>
    %41 = "ttir.mesh_shard"(%arg20, %40) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %42 = ttir.empty() : tensor<3072xbf16>
    %43 = "ttir.mesh_shard"(%arg21, %42) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %44 = ttir.empty() : tensor<1x4x128x128xbf16>
    %45 = "ttir.mesh_shard"(%arg22, %44) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %46 = ttir.empty() : tensor<512x3072xbf16>
    %47 = "ttir.mesh_shard"(%arg23, %46) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %48 = ttir.empty() : tensor<1x4x128x128xbf16>
    %49 = "ttir.mesh_shard"(%arg24, %48) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %50 = ttir.empty() : tensor<512x3072xbf16>
    %51 = "ttir.mesh_shard"(%arg25, %50) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %52 = ttir.empty() : tensor<3072x4096xbf16>
    %53 = "ttir.mesh_shard"(%arg26, %52) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %54 = ttir.empty() : tensor<4096x3072xbf16>
    %55 = "ttir.mesh_shard"(%arg27, %54) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %56 = ttir.empty() : tensor<3072x1536xbf16>
    %57 = "ttir.mesh_shard"(%arg28, %56) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %58 = ttir.empty() : tensor<1536x3072xbf16>
    %59 = "ttir.mesh_shard"(%arg29, %58) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %60 = ttir.empty() : tensor<3072xbf16>
    %61 = "ttir.mesh_shard"(%arg30, %60) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %62 = ttir.empty() : tensor<4096x3072xbf16>
    %63 = "ttir.mesh_shard"(%arg31, %62) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %64 = ttir.empty() : tensor<3072xbf16>
    %65 = "ttir.mesh_shard"(%arg32, %64) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %66 = ttir.empty() : tensor<1x4x128x128xbf16>
    %67 = "ttir.mesh_shard"(%arg33, %66) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %68 = ttir.empty() : tensor<512x3072xbf16>
    %69 = "ttir.mesh_shard"(%arg34, %68) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %70 = ttir.empty() : tensor<1x4x128x128xbf16>
    %71 = "ttir.mesh_shard"(%arg35, %70) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %72 = ttir.empty() : tensor<512x3072xbf16>
    %73 = "ttir.mesh_shard"(%arg36, %72) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %74 = ttir.empty() : tensor<3072x4096xbf16>
    %75 = "ttir.mesh_shard"(%arg37, %74) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %76 = ttir.empty() : tensor<4096x3072xbf16>
    %77 = "ttir.mesh_shard"(%arg38, %76) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %78 = ttir.empty() : tensor<3072x1536xbf16>
    %79 = "ttir.mesh_shard"(%arg39, %78) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %80 = ttir.empty() : tensor<1536x3072xbf16>
    %81 = "ttir.mesh_shard"(%arg40, %80) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %82 = ttir.empty() : tensor<3072xbf16>
    %83 = "ttir.mesh_shard"(%arg41, %82) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %84 = ttir.empty() : tensor<4096x3072xbf16>
    %85 = "ttir.mesh_shard"(%arg42, %84) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %86 = ttir.empty() : tensor<3072xbf16>
    %87 = "ttir.mesh_shard"(%arg43, %86) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %88 = ttir.empty() : tensor<1x4x128x128xbf16>
    %89 = "ttir.mesh_shard"(%arg44, %88) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %90 = ttir.empty() : tensor<512x3072xbf16>
    %91 = "ttir.mesh_shard"(%arg45, %90) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %92 = ttir.empty() : tensor<1x4x128x128xbf16>
    %93 = "ttir.mesh_shard"(%arg46, %92) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %94 = ttir.empty() : tensor<3072x4096xbf16>
    %95 = "ttir.mesh_shard"(%arg47, %94) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %96 = ttir.empty() : tensor<4096x3072xbf16>
    %97 = "ttir.mesh_shard"(%arg48, %96) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %98 = ttir.empty() : tensor<3072x1536xbf16>
    %99 = "ttir.mesh_shard"(%arg49, %98) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %100 = ttir.empty() : tensor<1536x3072xbf16>
    %101 = "ttir.mesh_shard"(%arg50, %100) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %102 = ttir.empty() : tensor<3072xbf16>
    %103 = "ttir.mesh_shard"(%arg51, %102) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %104 = ttir.empty() : tensor<4096x3072xbf16>
    %105 = "ttir.mesh_shard"(%arg52, %104) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %106 = ttir.empty() : tensor<3072xbf16>
    %107 = "ttir.mesh_shard"(%arg53, %106) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %108 = "ttir.constant"() <{value = dense<0> : tensor<1xi64>}> : () -> tensor<1xi64>
    %109 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32>
    %110 = "ttir.constant"() <{value = dense<0xFF800000> : tensor<f32>}> : () -> tensor<f32>
    %111 = "ttir.constant"() <{value = dense<3.25520843E-4> : tensor<1x1xf32>}> : () -> tensor<1x1xf32>
    %112 = "ttir.constant"() <{value = dense<2.000000e+00> : tensor<f32>}> : () -> tensor<f32>
    %113 = ttir.empty() : tensor<1x1x1xf32>
    %114 = "ttir.reshape"(%112, %113) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %115 = ttir.empty() : tensor<1x1x3072xf32>
    %116 = "ttir.broadcast"(%114, %115) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %117 = ttir.empty() : tensor<1xi1>
    %118 = "ttir.lt"(%1, %108, %117) : (tensor<1xi64>, tensor<1xi64>, tensor<1xi1>) -> tensor<1xi1>
    %119 = ttir.empty() : tensor<1xi64>
    %120 = "ttir.reshape"(%15, %119) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64>
    %121 = ttir.empty() : tensor<1xi64>
    %122 = "ttir.add"(%1, %120, %121) : (tensor<1xi64>, tensor<1xi64>, tensor<1xi64>) -> tensor<1xi64>
    %123 = ttir.empty() : tensor<1xi64>
    %124 = "ttir.where"(%118, %122, %1, %123) : (tensor<1xi1>, tensor<1xi64>, tensor<1xi64>, tensor<1xi64>) -> tensor<1xi64>
    %125 = ttir.empty() : tensor<1x1xi64>
    %126 = "ttir.reshape"(%124, %125) <{shape = [1 : i32, 1 : i32]}> : (tensor<1xi64>, tensor<1x1xi64>) -> tensor<1x1xi64>
    %127 = ttir.empty() : tensor<3072xf32>
    %128 = "ttir.typecast"(%13, %127) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %129 = ttir.empty() : tensor<1x1x3072xf32>
    %130 = "ttir.reshape"(%128, %129) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %131 = ttir.empty() : tensor<1x1xui32>
    %132 = "ttir.typecast"(%9, %131) <{conservative_folding = false}> : (tensor<1x1xi64>, tensor<1x1xui32>) -> tensor<1x1xui32>
    %133 = ttir.empty() : tensor<1xui32>
    %134 = "ttir.reshape"(%132, %133) <{shape = [1 : i32]}> : (tensor<1x1xui32>, tensor<1xui32>) -> tensor<1xui32>
    %135 = ttir.empty() : tensor<1x3072xbf16>
    %136 = "ttir.gather"(%11, %134, %135) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3072>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<64128x3072xbf16>, tensor<1xui32>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %137 = ttir.empty() : tensor<1x3072xbf16>
    %138 = "ttir.all_reduce"(%136, %137) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %139 = ttir.empty() : tensor<1x1x3072xbf16>
    %140 = "ttir.reshape"(%138, %139) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %141 = ttir.empty() : tensor<1x1x3072xf32>
    %142 = "ttir.typecast"(%140, %141) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %143 = ttir.empty() : tensor<1x1x3072xf32>
    %144 = "ttir.pow"(%142, %116, %143) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %145 = ttir.empty() : tensor<1x1xf32>
    %146 = "ttir.sum"(%144, %145) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %147 = ttir.empty() : tensor<1x1xf32>
    %148 = "ttir.multiply"(%146, %111, %147) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %149 = ttir.empty() : tensor<1x1x1xf32>
    %150 = "ttir.reshape"(%148, %149) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %151 = ttir.empty() : tensor<1x1x1xf32>
    %152 = "ttir.reshape"(%7, %151) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %153 = ttir.empty() : tensor<1x1x1xf32>
    %154 = "ttir.add"(%150, %152, %153) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %155 = ttir.empty() : tensor<1x1x1xf32>
    %156 = "ttir.rsqrt"(%154, %155) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %157 = ttir.empty() : tensor<1x1xf32>
    %158 = "ttir.reshape"(%156, %157) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %159 = ttir.empty() : tensor<1x1x1xf32>
    %160 = "ttir.reshape"(%158, %159) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %161 = ttir.empty() : tensor<1x1x3072xf32>
    %162 = "ttir.broadcast"(%160, %161) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %163 = ttir.empty() : tensor<1x1x3072xf32>
    %164 = "ttir.multiply"(%142, %162, %163) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %165 = ttir.empty() : tensor<1x1x3072xbf16>
    %166 = "ttir.typecast"(%164, %165) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %167 = ttir.empty() : tensor<1x1x3072xf32>
    %168 = "ttir.typecast"(%166, %167) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %169 = ttir.empty() : tensor<1x1x3072xf32>
    %170 = "ttir.multiply"(%130, %168, %169) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %171 = ttir.empty() : tensor<1x1x3072xbf16>
    %172 = "ttir.typecast"(%170, %171) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %173 = ttir.empty() : tensor<1x3072xbf16>
    %174 = "ttir.reshape"(%172, %173) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %175 = ttir.empty() : tensor<3072x512xbf16>
    %176 = "ttir.permute"(%5, %175) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %177 = "ttir.dot_general"(%174, %176) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %178 = ttir.empty() : tensor<1x4x1x128xbf16>
    %179 = "ttir.reshape"(%177, %178) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %180 = ttir.empty() : tensor<1x4x1x128xf32>
    %181 = "ttir.typecast"(%179, %180) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %182 = ttir.empty() : tensor<1x64x1xf32>
    %183 = "ttir.reshape"(%3, %182) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32>, tensor<1x64x1xf32>) -> tensor<1x64x1xf32>
    %184 = ttir.empty() : tensor<1xf32>
    %185 = "ttir.typecast"(%1, %184) <{conservative_folding = false}> : (tensor<1xi64>, tensor<1xf32>) -> tensor<1xf32>
    %186 = ttir.empty() : tensor<1x1x1xf32>
    %187 = "ttir.reshape"(%185, %186) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %188 = "ttir.dot_general"(%183, %187) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32>
    %189 = ttir.empty() : tensor<1x1x64xf32>
    %190 = "ttir.reshape"(%188, %189) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<1x64x1xf32>, tensor<1x1x64xf32>) -> tensor<1x1x64xf32>
    %191 = ttir.empty() : tensor<1x1x128xf32>
    %192 = "ttir.concat"(%190, %190, %191) <{dim = 2 : si32}> : (tensor<1x1x64xf32>, tensor<1x1x64xf32>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32>
    %193 = ttir.empty() : tensor<1x1x128xf32>
    %194 = "ttir.cos"(%192, %193) : (tensor<1x1x128xf32>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32>
    %195 = ttir.empty() : tensor<1x1x128xbf16>
    %196 = "ttir.typecast"(%194, %195) <{conservative_folding = false}> : (tensor<1x1x128xf32>, tensor<1x1x128xbf16>) -> tensor<1x1x128xbf16>
    %197 = ttir.empty() : tensor<1x1x128xf32>
    %198 = "ttir.typecast"(%196, %197) <{conservative_folding = false}> : (tensor<1x1x128xbf16>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32>
    %199 = ttir.empty() : tensor<1x1x1x128xf32>
    %200 = "ttir.reshape"(%198, %199) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>
    %201 = ttir.empty() : tensor<1x4x1x128xf32>
    %202 = "ttir.broadcast"(%200, %201) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %203 = ttir.empty() : tensor<1x4x1x128xf32>
    %204 = "ttir.multiply"(%181, %202, %203) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %205 = ttir.empty() : tensor<1x4x1x128xbf16>
    %206 = "ttir.typecast"(%204, %205) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %207 = ttir.empty() : tensor<1x4x1x64xbf16>
    %208 = "ttir.slice_static"(%179, %207) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %209 = ttir.empty() : tensor<1x4x1x64xbf16>
    %210 = "ttir.neg"(%208, %209) : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %211 = ttir.empty() : tensor<1x4x1x64xbf16>
    %212 = "ttir.slice_static"(%179, %211) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %213 = ttir.empty() : tensor<1x4x1x128xbf16>
    %214 = "ttir.concat"(%210, %212, %213) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %215 = ttir.empty() : tensor<1x4x1x128xf32>
    %216 = "ttir.typecast"(%214, %215) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %217 = ttir.empty() : tensor<1x1x128xf32>
    %218 = "ttir.sin"(%192, %217) : (tensor<1x1x128xf32>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32>
    %219 = ttir.empty() : tensor<1x1x128xbf16>
    %220 = "ttir.typecast"(%218, %219) <{conservative_folding = false}> : (tensor<1x1x128xf32>, tensor<1x1x128xbf16>) -> tensor<1x1x128xbf16>
    %221 = ttir.empty() : tensor<1x1x128xf32>
    %222 = "ttir.typecast"(%220, %221) <{conservative_folding = false}> : (tensor<1x1x128xbf16>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32>
    %223 = ttir.empty() : tensor<1x1x1x128xf32>
    %224 = "ttir.reshape"(%222, %223) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>
    %225 = ttir.empty() : tensor<1x4x1x128xf32>
    %226 = "ttir.broadcast"(%224, %225) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %227 = ttir.empty() : tensor<1x4x1x128xf32>
    %228 = "ttir.multiply"(%216, %226, %227) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %229 = ttir.empty() : tensor<1x4x1x128xbf16>
    %230 = "ttir.typecast"(%228, %229) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %231 = ttir.empty() : tensor<1x4x1x128xbf16>
    %232 = "ttir.add"(%206, %230, %231) : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %233 = ttir.empty() : tensor<1x4x128x128xbf16>
    %234 = "ttir.scatter"(%17, %126, %232, %233) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %235 = ttir.empty() : tensor<3072x512xbf16>
    %236 = "ttir.permute"(%19, %235) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %237 = "ttir.dot_general"(%174, %236) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %238 = ttir.empty() : tensor<1x4x1x128xbf16>
    %239 = "ttir.reshape"(%237, %238) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %240 = ttir.empty() : tensor<1x4x128x128xbf16>
    %241 = "ttir.scatter"(%21, %126, %239, %240) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %242 = ttir.empty() : tensor<3072xf32>
    %243 = "ttir.typecast"(%43, %242) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %244 = ttir.empty() : tensor<1x1x3072xf32>
    %245 = "ttir.reshape"(%243, %244) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %246 = ttir.empty() : tensor<3072x1536xbf16>
    %247 = "ttir.permute"(%37, %246) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %248 = "ttir.dot_general"(%174, %247) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
    %249 = ttir.empty() : tensor<1x12x1x128xbf16>
    %250 = "ttir.reshape"(%248, %249) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %251 = ttir.empty() : tensor<1x12x1x128xf32>
    %252 = "ttir.typecast"(%250, %251) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %253 = ttir.empty() : tensor<1x1x1x128xf32>
    %254 = "ttir.reshape"(%198, %253) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>
    %255 = ttir.empty() : tensor<1x12x1x128xf32>
    %256 = "ttir.broadcast"(%254, %255) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %257 = ttir.empty() : tensor<1x12x1x128xf32>
    %258 = "ttir.multiply"(%252, %256, %257) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %259 = ttir.empty() : tensor<1x12x1x128xbf16>
    %260 = "ttir.typecast"(%258, %259) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %261 = ttir.empty() : tensor<1x12x1x64xbf16>
    %262 = "ttir.slice_static"(%250, %261) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %263 = ttir.empty() : tensor<1x12x1x64xbf16>
    %264 = "ttir.neg"(%262, %263) : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %265 = ttir.empty() : tensor<1x12x1x64xbf16>
    %266 = "ttir.slice_static"(%250, %265) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %267 = ttir.empty() : tensor<1x12x1x128xbf16>
    %268 = "ttir.concat"(%264, %266, %267) <{dim = 3 : si32}> : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %269 = ttir.empty() : tensor<1x12x1x128xf32>
    %270 = "ttir.typecast"(%268, %269) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %271 = ttir.empty() : tensor<1x1x1x128xf32>
    %272 = "ttir.reshape"(%222, %271) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>
    %273 = ttir.empty() : tensor<1x12x1x128xf32>
    %274 = "ttir.broadcast"(%272, %273) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %275 = ttir.empty() : tensor<1x12x1x128xf32>
    %276 = "ttir.multiply"(%270, %274, %275) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %277 = ttir.empty() : tensor<1x12x1x128xbf16>
    %278 = "ttir.typecast"(%276, %277) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %279 = ttir.empty() : tensor<1x12x1x128xbf16>
    %280 = "ttir.add"(%260, %278, %279) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %281 = ttir.empty() : tensor<12x1x128xbf16>
    %282 = "ttir.reshape"(%280, %281) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %283 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %284 = "ttir.reshape"(%234, %283) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %285 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %286 = "ttir.broadcast"(%284, %285) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %287 = ttir.empty() : tensor<1x12x128x128xbf16>
    %288 = "ttir.reshape"(%286, %287) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %289 = ttir.empty() : tensor<1x12x128x128xbf16>
    %290 = "ttir.permute"(%288, %289) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %291 = ttir.empty() : tensor<12x128x128xbf16>
    %292 = "ttir.reshape"(%290, %291) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %293 = "ttir.dot_general"(%282, %292) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %294 = ttir.empty() : tensor<12x1x128xf32>
    %295 = "ttir.typecast"(%293, %294) <{conservative_folding = false}> : (tensor<12x1x128xbf16>, tensor<12x1x128xf32>) -> tensor<12x1x128xf32>
    %296 = ttir.empty() : tensor<1x12x1x128xf32>
    %297 = "ttir.reshape"(%295, %296) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %298 = ttir.empty() : tensor<1x1x1x1xf32>
    %299 = "ttir.reshape"(%35, %298) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>
    %300 = ttir.empty() : tensor<1x12x1x128xf32>
    %301 = "ttir.broadcast"(%299, %300) <{broadcast_dimensions = array<i64: 1, 12, 1, 128>}> : (tensor<1x1x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %302 = ttir.empty() : tensor<1x12x1x128xf32>
    %303 = "ttir.multiply"(%297, %301, %302) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %304 = ttir.empty() : tensor<1x12x1x128xbf16>
    %305 = "ttir.typecast"(%303, %304) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %306 = ttir.empty() : tensor<1x128xf32>
    %307 = "ttir.typecast"(%33, %306) <{conservative_folding = false}> : (tensor<1x128xbf16>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %308 = ttir.empty() : tensor<1x128xi64>
    %309 = "ttir.reshape"(%31, %308) <{shape = [1 : i32, 128 : i32]}> : (tensor<128xi64>, tensor<1x128xi64>) -> tensor<1x128xi64>
    %310 = ttir.empty() : tensor<1x1xi64>
    %311 = "ttir.reshape"(%1, %310) <{shape = [1 : i32, 1 : i32]}> : (tensor<1xi64>, tensor<1x1xi64>) -> tensor<1x1xi64>
    %312 = ttir.empty() : tensor<1x128xi64>
    %313 = "ttir.broadcast"(%311, %312) <{broadcast_dimensions = array<i64: 1, 128>}> : (tensor<1x1xi64>, tensor<1x128xi64>) -> tensor<1x128xi64>
    %314 = ttir.empty() : tensor<1x128xi1>
    %315 = "ttir.gt"(%309, %313, %314) : (tensor<1x128xi64>, tensor<1x128xi64>, tensor<1x128xi1>) -> tensor<1x128xi1>
    %316 = ttir.empty() : tensor<1x128xf32>
    %317 = "ttir.typecast"(%315, %316) <{conservative_folding = false}> : (tensor<1x128xi1>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %318 = ttir.empty() : tensor<1x128xf32>
    %319 = "ttir.multiply"(%307, %317, %318) : (tensor<1x128xf32>, tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %320 = ttir.empty() : tensor<1x128xbf16>
    %321 = "ttir.typecast"(%319, %320) <{conservative_folding = false}> : (tensor<1x128xf32>, tensor<1x128xbf16>) -> tensor<1x128xbf16>
    %322 = ttir.empty() : tensor<1x1x128xbf16>
    %323 = "ttir.reshape"(%321, %322) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x128xbf16>, tensor<1x1x128xbf16>) -> tensor<1x1x128xbf16>
    %324 = ttir.empty() : tensor<1x1x1x128xbf16>
    %325 = "ttir.reshape"(%323, %324) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xbf16>, tensor<1x1x1x128xbf16>) -> tensor<1x1x1x128xbf16>
    %326 = ttir.empty() : tensor<1x12x1x128xbf16>
    %327 = "ttir.broadcast"(%325, %326) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %328 = ttir.empty() : tensor<1x12x1x128xbf16>
    %329 = "ttir.add"(%305, %327, %328) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %330 = ttir.empty() : tensor<1x12x1x128xf32>
    %331 = "ttir.typecast"(%329, %330) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %332 = ttir.empty() : tensor<1x12x1xf32>
    %333 = "ttir.max"(%331, %332) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %334 = ttir.empty() : tensor<1x12x1x1xf32>
    %335 = "ttir.reshape"(%333, %334) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %336 = ttir.empty() : tensor<1x12x1x128xf32>
    %337 = "ttir.broadcast"(%335, %336) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %338 = ttir.empty() : tensor<1x12x1x128xf32>
    %339 = "ttir.subtract"(%331, %337, %338) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %340 = ttir.empty() : tensor<1x12x1x128xf32>
    %341 = "ttir.exp"(%339, %340) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %342 = ttir.empty() : tensor<1x12x1xf32>
    %343 = "ttir.sum"(%341, %342) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %344 = ttir.empty() : tensor<1x12x1x1xf32>
    %345 = "ttir.reshape"(%343, %344) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %346 = ttir.empty() : tensor<1x12x1x128xf32>
    %347 = "ttir.broadcast"(%345, %346) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %348 = ttir.empty() : tensor<1x12x1x128xf32>
    %349 = "ttir.div"(%341, %347, %348) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %350 = ttir.empty() : tensor<1x12x1x128xbf16>
    %351 = "ttir.typecast"(%349, %350) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %352 = ttir.empty() : tensor<12x1x128xbf16>
    %353 = "ttir.reshape"(%351, %352) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %354 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %355 = "ttir.reshape"(%241, %354) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %356 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %357 = "ttir.broadcast"(%355, %356) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %358 = ttir.empty() : tensor<12x128x128xbf16>
    %359 = "ttir.reshape"(%357, %358) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %360 = "ttir.dot_general"(%353, %359) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %361 = ttir.empty() : tensor<1x1536xbf16>
    %362 = "ttir.reshape"(%360, %361) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16>, tensor<1x1536xbf16>) -> tensor<1x1536xbf16>
    %363 = ttir.empty() : tensor<1536x3072xbf16>
    %364 = "ttir.permute"(%29, %363) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %365 = "ttir.dot_general"(%362, %364) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
    %366 = ttir.empty() : tensor<1x3072xbf16>
    %367 = "ttir.all_reduce"(%365, %366) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %368 = ttir.empty() : tensor<1x1x3072xbf16>
    %369 = "ttir.reshape"(%367, %368) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %370 = ttir.empty() : tensor<1x1x3072xbf16>
    %371 = "ttir.add"(%140, %369, %370) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %372 = ttir.empty() : tensor<3072xf32>
    %373 = "ttir.typecast"(%39, %372) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %374 = ttir.empty() : tensor<1x1x3072xf32>
    %375 = "ttir.reshape"(%373, %374) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %376 = ttir.empty() : tensor<1x1x3072xf32>
    %377 = "ttir.typecast"(%371, %376) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %378 = ttir.empty() : tensor<1x1x3072xf32>
    %379 = "ttir.pow"(%377, %116, %378) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %380 = ttir.empty() : tensor<1x1xf32>
    %381 = "ttir.sum"(%379, %380) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %382 = ttir.empty() : tensor<1x1xf32>
    %383 = "ttir.multiply"(%381, %111, %382) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %384 = ttir.empty() : tensor<1x1x1xf32>
    %385 = "ttir.reshape"(%383, %384) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %386 = ttir.empty() : tensor<1x1x1xf32>
    %387 = "ttir.add"(%385, %152, %386) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %388 = ttir.empty() : tensor<1x1x1xf32>
    %389 = "ttir.rsqrt"(%387, %388) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %390 = ttir.empty() : tensor<1x1xf32>
    %391 = "ttir.reshape"(%389, %390) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %392 = ttir.empty() : tensor<1x1x1xf32>
    %393 = "ttir.reshape"(%391, %392) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %394 = ttir.empty() : tensor<1x1x3072xf32>
    %395 = "ttir.broadcast"(%393, %394) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %396 = ttir.empty() : tensor<1x1x3072xf32>
    %397 = "ttir.multiply"(%377, %395, %396) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %398 = ttir.empty() : tensor<1x1x3072xbf16>
    %399 = "ttir.typecast"(%397, %398) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %400 = ttir.empty() : tensor<1x1x3072xf32>
    %401 = "ttir.typecast"(%399, %400) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %402 = ttir.empty() : tensor<1x1x3072xf32>
    %403 = "ttir.multiply"(%375, %401, %402) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %404 = ttir.empty() : tensor<1x1x3072xbf16>
    %405 = "ttir.typecast"(%403, %404) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %406 = ttir.empty() : tensor<1x3072xbf16>
    %407 = "ttir.reshape"(%405, %406) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %408 = ttir.empty() : tensor<3072x4096xbf16>
    %409 = "ttir.permute"(%41, %408) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %410 = "ttir.dot_general"(%407, %409) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %411 = ttir.empty() : tensor<1x1x4096xbf16>
    %412 = "ttir.reshape"(%410, %411) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %413 = ttir.empty() : tensor<1x1x4096xf32>
    %414 = "ttir.typecast"(%412, %413) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %415 = ttir.empty() : tensor<1x1x4096xbf16>
    %416 = "ttir.sigmoid"(%412, %415) : (tensor<1x1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %417 = ttir.empty() : tensor<1x1x4096xf32>
    %418 = "ttir.typecast"(%416, %417) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %419 = ttir.empty() : tensor<1x1x4096xf32>
    %420 = "ttir.multiply"(%414, %418, %419) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %421 = ttir.empty() : tensor<1x1x4096xbf16>
    %422 = "ttir.typecast"(%420, %421) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %423 = ttir.empty() : tensor<1x1x4096xf32>
    %424 = "ttir.typecast"(%422, %423) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %425 = ttir.empty() : tensor<3072x4096xbf16>
    %426 = "ttir.permute"(%27, %425) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %427 = "ttir.dot_general"(%407, %426) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %428 = ttir.empty() : tensor<1x4096xf32>
    %429 = "ttir.typecast"(%427, %428) <{conservative_folding = false}> : (tensor<1x4096xbf16>, tensor<1x4096xf32>) -> tensor<1x4096xf32>
    %430 = ttir.empty() : tensor<1x1x4096xf32>
    %431 = "ttir.reshape"(%429, %430) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %432 = ttir.empty() : tensor<1x1x4096xf32>
    %433 = "ttir.multiply"(%424, %431, %432) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %434 = ttir.empty() : tensor<1x1x4096xbf16>
    %435 = "ttir.typecast"(%433, %434) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %436 = ttir.empty() : tensor<1x4096xbf16>
    %437 = "ttir.reshape"(%435, %436) <{shape = [1 : i32, 4096 : i32]}> : (tensor<1x1x4096xbf16>, tensor<1x4096xbf16>) -> tensor<1x4096xbf16>
    %438 = ttir.empty() : tensor<4096x3072xbf16>
    %439 = "ttir.permute"(%25, %438) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %440 = "ttir.dot_general"(%437, %439) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
    %441 = ttir.empty() : tensor<1x3072xbf16>
    %442 = "ttir.all_reduce"(%440, %441) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %443 = ttir.empty() : tensor<1x1x3072xbf16>
    %444 = "ttir.reshape"(%442, %443) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %445 = ttir.empty() : tensor<1x1x3072xbf16>
    %446 = "ttir.add"(%371, %444, %445) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %447 = ttir.empty() : tensor<1x1x3072xf32>
    %448 = "ttir.typecast"(%446, %447) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %449 = ttir.empty() : tensor<1x1x3072xf32>
    %450 = "ttir.pow"(%448, %116, %449) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %451 = ttir.empty() : tensor<1x1xf32>
    %452 = "ttir.sum"(%450, %451) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %453 = ttir.empty() : tensor<1x1xf32>
    %454 = "ttir.multiply"(%452, %111, %453) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %455 = ttir.empty() : tensor<1x1x1xf32>
    %456 = "ttir.reshape"(%454, %455) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %457 = ttir.empty() : tensor<1x1x1xf32>
    %458 = "ttir.add"(%456, %152, %457) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %459 = ttir.empty() : tensor<1x1x1xf32>
    %460 = "ttir.rsqrt"(%458, %459) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %461 = ttir.empty() : tensor<1x1xf32>
    %462 = "ttir.reshape"(%460, %461) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %463 = ttir.empty() : tensor<1x1x1xf32>
    %464 = "ttir.reshape"(%462, %463) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %465 = ttir.empty() : tensor<1x1x3072xf32>
    %466 = "ttir.broadcast"(%464, %465) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %467 = ttir.empty() : tensor<1x1x3072xf32>
    %468 = "ttir.multiply"(%448, %466, %467) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %469 = ttir.empty() : tensor<1x1x3072xbf16>
    %470 = "ttir.typecast"(%468, %469) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %471 = ttir.empty() : tensor<1x1x3072xf32>
    %472 = "ttir.typecast"(%470, %471) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %473 = ttir.empty() : tensor<1x1x3072xf32>
    %474 = "ttir.multiply"(%245, %472, %473) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %475 = ttir.empty() : tensor<1x1x3072xbf16>
    %476 = "ttir.typecast"(%474, %475) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %477 = ttir.empty() : tensor<1x3072xbf16>
    %478 = "ttir.reshape"(%476, %477) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %479 = ttir.empty() : tensor<3072x512xbf16>
    %480 = "ttir.permute"(%23, %479) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %481 = "ttir.dot_general"(%478, %480) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %482 = ttir.empty() : tensor<1x4x1x128xbf16>
    %483 = "ttir.reshape"(%481, %482) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %484 = ttir.empty() : tensor<1x4x1x128xf32>
    %485 = "ttir.typecast"(%483, %484) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %486 = ttir.empty() : tensor<1x4x1x128xf32>
    %487 = "ttir.multiply"(%485, %202, %486) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %488 = ttir.empty() : tensor<1x4x1x128xbf16>
    %489 = "ttir.typecast"(%487, %488) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %490 = ttir.empty() : tensor<1x4x1x64xbf16>
    %491 = "ttir.slice_static"(%483, %490) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %492 = ttir.empty() : tensor<1x4x1x64xbf16>
    %493 = "ttir.neg"(%491, %492) : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %494 = ttir.empty() : tensor<1x4x1x64xbf16>
    %495 = "ttir.slice_static"(%483, %494) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %496 = ttir.empty() : tensor<1x4x1x128xbf16>
    %497 = "ttir.concat"(%493, %495, %496) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %498 = ttir.empty() : tensor<1x4x1x128xf32>
    %499 = "ttir.typecast"(%497, %498) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %500 = ttir.empty() : tensor<1x4x1x128xf32>
    %501 = "ttir.multiply"(%499, %226, %500) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %502 = ttir.empty() : tensor<1x4x1x128xbf16>
    %503 = "ttir.typecast"(%501, %502) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %504 = ttir.empty() : tensor<1x4x1x128xbf16>
    %505 = "ttir.add"(%489, %503, %504) : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %506 = ttir.empty() : tensor<1x4x128x128xbf16>
    %507 = "ttir.scatter"(%45, %126, %505, %506) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %508 = ttir.empty() : tensor<3072x512xbf16>
    %509 = "ttir.permute"(%47, %508) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %510 = "ttir.dot_general"(%478, %509) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %511 = ttir.empty() : tensor<1x4x1x128xbf16>
    %512 = "ttir.reshape"(%510, %511) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %513 = ttir.empty() : tensor<1x4x128x128xbf16>
    %514 = "ttir.scatter"(%49, %126, %512, %513) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %515 = ttir.empty() : tensor<3072xf32>
    %516 = "ttir.typecast"(%65, %515) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %517 = ttir.empty() : tensor<1x1x3072xf32>
    %518 = "ttir.reshape"(%516, %517) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %519 = ttir.empty() : tensor<3072x1536xbf16>
    %520 = "ttir.permute"(%59, %519) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %521 = "ttir.dot_general"(%478, %520) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
    %522 = ttir.empty() : tensor<1x12x1x128xbf16>
    %523 = "ttir.reshape"(%521, %522) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %524 = ttir.empty() : tensor<1x12x1x128xf32>
    %525 = "ttir.typecast"(%523, %524) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %526 = ttir.empty() : tensor<1x12x1x128xf32>
    %527 = "ttir.multiply"(%525, %256, %526) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %528 = ttir.empty() : tensor<1x12x1x128xbf16>
    %529 = "ttir.typecast"(%527, %528) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %530 = ttir.empty() : tensor<1x12x1x64xbf16>
    %531 = "ttir.slice_static"(%523, %530) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %532 = ttir.empty() : tensor<1x12x1x64xbf16>
    %533 = "ttir.neg"(%531, %532) : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %534 = ttir.empty() : tensor<1x12x1x64xbf16>
    %535 = "ttir.slice_static"(%523, %534) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %536 = ttir.empty() : tensor<1x12x1x128xbf16>
    %537 = "ttir.concat"(%533, %535, %536) <{dim = 3 : si32}> : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %538 = ttir.empty() : tensor<1x12x1x128xf32>
    %539 = "ttir.typecast"(%537, %538) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %540 = ttir.empty() : tensor<1x12x1x128xf32>
    %541 = "ttir.multiply"(%539, %274, %540) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %542 = ttir.empty() : tensor<1x12x1x128xbf16>
    %543 = "ttir.typecast"(%541, %542) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %544 = ttir.empty() : tensor<1x12x1x128xbf16>
    %545 = "ttir.add"(%529, %543, %544) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %546 = ttir.empty() : tensor<12x1x128xbf16>
    %547 = "ttir.reshape"(%545, %546) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %548 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %549 = "ttir.reshape"(%507, %548) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %550 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %551 = "ttir.broadcast"(%549, %550) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %552 = ttir.empty() : tensor<1x12x128x128xbf16>
    %553 = "ttir.reshape"(%551, %552) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %554 = ttir.empty() : tensor<1x12x128x128xbf16>
    %555 = "ttir.permute"(%553, %554) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %556 = ttir.empty() : tensor<12x128x128xbf16>
    %557 = "ttir.reshape"(%555, %556) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %558 = "ttir.dot_general"(%547, %557) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %559 = ttir.empty() : tensor<12x1x128xf32>
    %560 = "ttir.typecast"(%558, %559) <{conservative_folding = false}> : (tensor<12x1x128xbf16>, tensor<12x1x128xf32>) -> tensor<12x1x128xf32>
    %561 = ttir.empty() : tensor<1x12x1x128xf32>
    %562 = "ttir.reshape"(%560, %561) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %563 = ttir.empty() : tensor<1x12x1x128xf32>
    %564 = "ttir.multiply"(%562, %301, %563) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %565 = ttir.empty() : tensor<1x12x1x128xbf16>
    %566 = "ttir.typecast"(%564, %565) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %567 = ttir.empty() : tensor<1x12x1x128xbf16>
    %568 = "ttir.add"(%566, %327, %567) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %569 = ttir.empty() : tensor<1x12x1x128xf32>
    %570 = "ttir.typecast"(%568, %569) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %571 = ttir.empty() : tensor<1x12x1xf32>
    %572 = "ttir.max"(%570, %571) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %573 = ttir.empty() : tensor<1x12x1x1xf32>
    %574 = "ttir.reshape"(%572, %573) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %575 = ttir.empty() : tensor<1x12x1x128xf32>
    %576 = "ttir.broadcast"(%574, %575) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %577 = ttir.empty() : tensor<1x12x1x128xf32>
    %578 = "ttir.subtract"(%570, %576, %577) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %579 = ttir.empty() : tensor<1x12x1x128xf32>
    %580 = "ttir.exp"(%578, %579) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %581 = ttir.empty() : tensor<1x12x1xf32>
    %582 = "ttir.sum"(%580, %581) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %583 = ttir.empty() : tensor<1x12x1x1xf32>
    %584 = "ttir.reshape"(%582, %583) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %585 = ttir.empty() : tensor<1x12x1x128xf32>
    %586 = "ttir.broadcast"(%584, %585) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %587 = ttir.empty() : tensor<1x12x1x128xf32>
    %588 = "ttir.div"(%580, %586, %587) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %589 = ttir.empty() : tensor<1x12x1x128xbf16>
    %590 = "ttir.typecast"(%588, %589) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %591 = ttir.empty() : tensor<12x1x128xbf16>
    %592 = "ttir.reshape"(%590, %591) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %593 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %594 = "ttir.reshape"(%514, %593) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %595 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %596 = "ttir.broadcast"(%594, %595) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %597 = ttir.empty() : tensor<12x128x128xbf16>
    %598 = "ttir.reshape"(%596, %597) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %599 = "ttir.dot_general"(%592, %598) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %600 = ttir.empty() : tensor<1x1536xbf16>
    %601 = "ttir.reshape"(%599, %600) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16>, tensor<1x1536xbf16>) -> tensor<1x1536xbf16>
    %602 = ttir.empty() : tensor<1536x3072xbf16>
    %603 = "ttir.permute"(%57, %602) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %604 = "ttir.dot_general"(%601, %603) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
    %605 = ttir.empty() : tensor<1x3072xbf16>
    %606 = "ttir.all_reduce"(%604, %605) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %607 = ttir.empty() : tensor<1x1x3072xbf16>
    %608 = "ttir.reshape"(%606, %607) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %609 = ttir.empty() : tensor<1x1x3072xbf16>
    %610 = "ttir.add"(%446, %608, %609) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %611 = ttir.empty() : tensor<3072xf32>
    %612 = "ttir.typecast"(%61, %611) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %613 = ttir.empty() : tensor<1x1x3072xf32>
    %614 = "ttir.reshape"(%612, %613) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %615 = ttir.empty() : tensor<1x1x3072xf32>
    %616 = "ttir.typecast"(%610, %615) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %617 = ttir.empty() : tensor<1x1x3072xf32>
    %618 = "ttir.pow"(%616, %116, %617) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %619 = ttir.empty() : tensor<1x1xf32>
    %620 = "ttir.sum"(%618, %619) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %621 = ttir.empty() : tensor<1x1xf32>
    %622 = "ttir.multiply"(%620, %111, %621) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %623 = ttir.empty() : tensor<1x1x1xf32>
    %624 = "ttir.reshape"(%622, %623) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %625 = ttir.empty() : tensor<1x1x1xf32>
    %626 = "ttir.add"(%624, %152, %625) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %627 = ttir.empty() : tensor<1x1x1xf32>
    %628 = "ttir.rsqrt"(%626, %627) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %629 = ttir.empty() : tensor<1x1xf32>
    %630 = "ttir.reshape"(%628, %629) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %631 = ttir.empty() : tensor<1x1x1xf32>
    %632 = "ttir.reshape"(%630, %631) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %633 = ttir.empty() : tensor<1x1x3072xf32>
    %634 = "ttir.broadcast"(%632, %633) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %635 = ttir.empty() : tensor<1x1x3072xf32>
    %636 = "ttir.multiply"(%616, %634, %635) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %637 = ttir.empty() : tensor<1x1x3072xbf16>
    %638 = "ttir.typecast"(%636, %637) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %639 = ttir.empty() : tensor<1x1x3072xf32>
    %640 = "ttir.typecast"(%638, %639) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %641 = ttir.empty() : tensor<1x1x3072xf32>
    %642 = "ttir.multiply"(%614, %640, %641) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %643 = ttir.empty() : tensor<1x1x3072xbf16>
    %644 = "ttir.typecast"(%642, %643) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %645 = ttir.empty() : tensor<1x3072xbf16>
    %646 = "ttir.reshape"(%644, %645) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %647 = ttir.empty() : tensor<3072x4096xbf16>
    %648 = "ttir.permute"(%63, %647) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %649 = "ttir.dot_general"(%646, %648) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %650 = ttir.empty() : tensor<1x1x4096xbf16>
    %651 = "ttir.reshape"(%649, %650) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %652 = ttir.empty() : tensor<1x1x4096xf32>
    %653 = "ttir.typecast"(%651, %652) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %654 = ttir.empty() : tensor<1x1x4096xbf16>
    %655 = "ttir.sigmoid"(%651, %654) : (tensor<1x1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %656 = ttir.empty() : tensor<1x1x4096xf32>
    %657 = "ttir.typecast"(%655, %656) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %658 = ttir.empty() : tensor<1x1x4096xf32>
    %659 = "ttir.multiply"(%653, %657, %658) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %660 = ttir.empty() : tensor<1x1x4096xbf16>
    %661 = "ttir.typecast"(%659, %660) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %662 = ttir.empty() : tensor<1x1x4096xf32>
    %663 = "ttir.typecast"(%661, %662) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %664 = ttir.empty() : tensor<3072x4096xbf16>
    %665 = "ttir.permute"(%55, %664) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %666 = "ttir.dot_general"(%646, %665) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %667 = ttir.empty() : tensor<1x4096xf32>
    %668 = "ttir.typecast"(%666, %667) <{conservative_folding = false}> : (tensor<1x4096xbf16>, tensor<1x4096xf32>) -> tensor<1x4096xf32>
    %669 = ttir.empty() : tensor<1x1x4096xf32>
    %670 = "ttir.reshape"(%668, %669) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %671 = ttir.empty() : tensor<1x1x4096xf32>
    %672 = "ttir.multiply"(%663, %670, %671) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %673 = ttir.empty() : tensor<1x1x4096xbf16>
    %674 = "ttir.typecast"(%672, %673) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %675 = ttir.empty() : tensor<1x4096xbf16>
    %676 = "ttir.reshape"(%674, %675) <{shape = [1 : i32, 4096 : i32]}> : (tensor<1x1x4096xbf16>, tensor<1x4096xbf16>) -> tensor<1x4096xbf16>
    %677 = ttir.empty() : tensor<4096x3072xbf16>
    %678 = "ttir.permute"(%53, %677) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %679 = "ttir.dot_general"(%676, %678) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
    %680 = ttir.empty() : tensor<1x3072xbf16>
    %681 = "ttir.all_reduce"(%679, %680) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %682 = ttir.empty() : tensor<1x1x3072xbf16>
    %683 = "ttir.reshape"(%681, %682) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %684 = ttir.empty() : tensor<1x1x3072xbf16>
    %685 = "ttir.add"(%610, %683, %684) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %686 = ttir.empty() : tensor<1x1x3072xf32>
    %687 = "ttir.typecast"(%685, %686) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %688 = ttir.empty() : tensor<1x1x3072xf32>
    %689 = "ttir.pow"(%687, %116, %688) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %690 = ttir.empty() : tensor<1x1xf32>
    %691 = "ttir.sum"(%689, %690) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %692 = ttir.empty() : tensor<1x1xf32>
    %693 = "ttir.multiply"(%691, %111, %692) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %694 = ttir.empty() : tensor<1x1x1xf32>
    %695 = "ttir.reshape"(%693, %694) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %696 = ttir.empty() : tensor<1x1x1xf32>
    %697 = "ttir.add"(%695, %152, %696) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %698 = ttir.empty() : tensor<1x1x1xf32>
    %699 = "ttir.rsqrt"(%697, %698) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %700 = ttir.empty() : tensor<1x1xf32>
    %701 = "ttir.reshape"(%699, %700) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %702 = ttir.empty() : tensor<1x1x1xf32>
    %703 = "ttir.reshape"(%701, %702) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %704 = ttir.empty() : tensor<1x1x3072xf32>
    %705 = "ttir.broadcast"(%703, %704) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %706 = ttir.empty() : tensor<1x1x3072xf32>
    %707 = "ttir.multiply"(%687, %705, %706) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %708 = ttir.empty() : tensor<1x1x3072xbf16>
    %709 = "ttir.typecast"(%707, %708) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %710 = ttir.empty() : tensor<1x1x3072xf32>
    %711 = "ttir.typecast"(%709, %710) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %712 = ttir.empty() : tensor<1x1x3072xf32>
    %713 = "ttir.multiply"(%518, %711, %712) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %714 = ttir.empty() : tensor<1x1x3072xbf16>
    %715 = "ttir.typecast"(%713, %714) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %716 = ttir.empty() : tensor<1x3072xbf16>
    %717 = "ttir.reshape"(%715, %716) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %718 = ttir.empty() : tensor<3072x512xbf16>
    %719 = "ttir.permute"(%51, %718) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %720 = "ttir.dot_general"(%717, %719) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %721 = ttir.empty() : tensor<1x4x1x128xbf16>
    %722 = "ttir.reshape"(%720, %721) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %723 = ttir.empty() : tensor<1x4x1x128xf32>
    %724 = "ttir.typecast"(%722, %723) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %725 = ttir.empty() : tensor<1x4x1x128xf32>
    %726 = "ttir.multiply"(%724, %202, %725) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %727 = ttir.empty() : tensor<1x4x1x128xbf16>
    %728 = "ttir.typecast"(%726, %727) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %729 = ttir.empty() : tensor<1x4x1x64xbf16>
    %730 = "ttir.slice_static"(%722, %729) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %731 = ttir.empty() : tensor<1x4x1x64xbf16>
    %732 = "ttir.neg"(%730, %731) : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %733 = ttir.empty() : tensor<1x4x1x64xbf16>
    %734 = "ttir.slice_static"(%722, %733) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %735 = ttir.empty() : tensor<1x4x1x128xbf16>
    %736 = "ttir.concat"(%732, %734, %735) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %737 = ttir.empty() : tensor<1x4x1x128xf32>
    %738 = "ttir.typecast"(%736, %737) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %739 = ttir.empty() : tensor<1x4x1x128xf32>
    %740 = "ttir.multiply"(%738, %226, %739) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %741 = ttir.empty() : tensor<1x4x1x128xbf16>
    %742 = "ttir.typecast"(%740, %741) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %743 = ttir.empty() : tensor<1x4x1x128xbf16>
    %744 = "ttir.add"(%728, %742, %743) : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %745 = ttir.empty() : tensor<1x4x128x128xbf16>
    %746 = "ttir.scatter"(%67, %126, %744, %745) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %747 = ttir.empty() : tensor<3072x512xbf16>
    %748 = "ttir.permute"(%69, %747) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %749 = "ttir.dot_general"(%717, %748) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %750 = ttir.empty() : tensor<1x4x1x128xbf16>
    %751 = "ttir.reshape"(%749, %750) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %752 = ttir.empty() : tensor<1x4x128x128xbf16>
    %753 = "ttir.scatter"(%71, %126, %751, %752) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %754 = ttir.empty() : tensor<3072xf32>
    %755 = "ttir.typecast"(%87, %754) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %756 = ttir.empty() : tensor<1x1x3072xf32>
    %757 = "ttir.reshape"(%755, %756) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %758 = ttir.empty() : tensor<3072x1536xbf16>
    %759 = "ttir.permute"(%81, %758) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %760 = "ttir.dot_general"(%717, %759) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
    %761 = ttir.empty() : tensor<1x12x1x128xbf16>
    %762 = "ttir.reshape"(%760, %761) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %763 = ttir.empty() : tensor<1x12x1x128xf32>
    %764 = "ttir.typecast"(%762, %763) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %765 = ttir.empty() : tensor<1x12x1x128xf32>
    %766 = "ttir.multiply"(%764, %256, %765) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %767 = ttir.empty() : tensor<1x12x1x128xbf16>
    %768 = "ttir.typecast"(%766, %767) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %769 = ttir.empty() : tensor<1x12x1x64xbf16>
    %770 = "ttir.slice_static"(%762, %769) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %771 = ttir.empty() : tensor<1x12x1x64xbf16>
    %772 = "ttir.neg"(%770, %771) : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %773 = ttir.empty() : tensor<1x12x1x64xbf16>
    %774 = "ttir.slice_static"(%762, %773) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %775 = ttir.empty() : tensor<1x12x1x128xbf16>
    %776 = "ttir.concat"(%772, %774, %775) <{dim = 3 : si32}> : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %777 = ttir.empty() : tensor<1x12x1x128xf32>
    %778 = "ttir.typecast"(%776, %777) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %779 = ttir.empty() : tensor<1x12x1x128xf32>
    %780 = "ttir.multiply"(%778, %274, %779) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %781 = ttir.empty() : tensor<1x12x1x128xbf16>
    %782 = "ttir.typecast"(%780, %781) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %783 = ttir.empty() : tensor<1x12x1x128xbf16>
    %784 = "ttir.add"(%768, %782, %783) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %785 = ttir.empty() : tensor<12x1x128xbf16>
    %786 = "ttir.reshape"(%784, %785) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %787 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %788 = "ttir.reshape"(%746, %787) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %789 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %790 = "ttir.broadcast"(%788, %789) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %791 = ttir.empty() : tensor<1x12x128x128xbf16>
    %792 = "ttir.reshape"(%790, %791) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %793 = ttir.empty() : tensor<1x12x128x128xbf16>
    %794 = "ttir.permute"(%792, %793) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %795 = ttir.empty() : tensor<12x128x128xbf16>
    %796 = "ttir.reshape"(%794, %795) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %797 = "ttir.dot_general"(%786, %796) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %798 = ttir.empty() : tensor<12x1x128xf32>
    %799 = "ttir.typecast"(%797, %798) <{conservative_folding = false}> : (tensor<12x1x128xbf16>, tensor<12x1x128xf32>) -> tensor<12x1x128xf32>
    %800 = ttir.empty() : tensor<1x12x1x128xf32>
    %801 = "ttir.reshape"(%799, %800) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %802 = ttir.empty() : tensor<1x12x1x128xf32>
    %803 = "ttir.multiply"(%801, %301, %802) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %804 = ttir.empty() : tensor<1x12x1x128xbf16>
    %805 = "ttir.typecast"(%803, %804) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %806 = ttir.empty() : tensor<1x12x1x128xbf16>
    %807 = "ttir.add"(%805, %327, %806) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %808 = ttir.empty() : tensor<1x12x1x128xf32>
    %809 = "ttir.typecast"(%807, %808) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %810 = ttir.empty() : tensor<1x12x1xf32>
    %811 = "ttir.max"(%809, %810) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %812 = ttir.empty() : tensor<1x12x1x1xf32>
    %813 = "ttir.reshape"(%811, %812) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %814 = ttir.empty() : tensor<1x12x1x128xf32>
    %815 = "ttir.broadcast"(%813, %814) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %816 = ttir.empty() : tensor<1x12x1x128xf32>
    %817 = "ttir.subtract"(%809, %815, %816) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %818 = ttir.empty() : tensor<1x12x1x128xf32>
    %819 = "ttir.exp"(%817, %818) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %820 = ttir.empty() : tensor<1x12x1xf32>
    %821 = "ttir.sum"(%819, %820) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %822 = ttir.empty() : tensor<1x12x1x1xf32>
    %823 = "ttir.reshape"(%821, %822) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %824 = ttir.empty() : tensor<1x12x1x128xf32>
    %825 = "ttir.broadcast"(%823, %824) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %826 = ttir.empty() : tensor<1x12x1x128xf32>
    %827 = "ttir.div"(%819, %825, %826) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %828 = ttir.empty() : tensor<1x12x1x128xbf16>
    %829 = "ttir.typecast"(%827, %828) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %830 = ttir.empty() : tensor<12x1x128xbf16>
    %831 = "ttir.reshape"(%829, %830) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %832 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %833 = "ttir.reshape"(%753, %832) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %834 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %835 = "ttir.broadcast"(%833, %834) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %836 = ttir.empty() : tensor<12x128x128xbf16>
    %837 = "ttir.reshape"(%835, %836) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %838 = "ttir.dot_general"(%831, %837) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %839 = ttir.empty() : tensor<1x1536xbf16>
    %840 = "ttir.reshape"(%838, %839) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16>, tensor<1x1536xbf16>) -> tensor<1x1536xbf16>
    %841 = ttir.empty() : tensor<1536x3072xbf16>
    %842 = "ttir.permute"(%79, %841) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %843 = "ttir.dot_general"(%840, %842) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
    %844 = ttir.empty() : tensor<1x3072xbf16>
    %845 = "ttir.all_reduce"(%843, %844) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %846 = ttir.empty() : tensor<1x1x3072xbf16>
    %847 = "ttir.reshape"(%845, %846) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %848 = ttir.empty() : tensor<1x1x3072xbf16>
    %849 = "ttir.add"(%685, %847, %848) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %850 = ttir.empty() : tensor<3072xf32>
    %851 = "ttir.typecast"(%83, %850) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %852 = ttir.empty() : tensor<1x1x3072xf32>
    %853 = "ttir.reshape"(%851, %852) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %854 = ttir.empty() : tensor<1x1x3072xf32>
    %855 = "ttir.typecast"(%849, %854) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %856 = ttir.empty() : tensor<1x1x3072xf32>
    %857 = "ttir.pow"(%855, %116, %856) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %858 = ttir.empty() : tensor<1x1xf32>
    %859 = "ttir.sum"(%857, %858) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %860 = ttir.empty() : tensor<1x1xf32>
    %861 = "ttir.multiply"(%859, %111, %860) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %862 = ttir.empty() : tensor<1x1x1xf32>
    %863 = "ttir.reshape"(%861, %862) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %864 = ttir.empty() : tensor<1x1x1xf32>
    %865 = "ttir.add"(%863, %152, %864) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %866 = ttir.empty() : tensor<1x1x1xf32>
    %867 = "ttir.rsqrt"(%865, %866) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %868 = ttir.empty() : tensor<1x1xf32>
    %869 = "ttir.reshape"(%867, %868) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %870 = ttir.empty() : tensor<1x1x1xf32>
    %871 = "ttir.reshape"(%869, %870) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %872 = ttir.empty() : tensor<1x1x3072xf32>
    %873 = "ttir.broadcast"(%871, %872) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %874 = ttir.empty() : tensor<1x1x3072xf32>
    %875 = "ttir.multiply"(%855, %873, %874) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %876 = ttir.empty() : tensor<1x1x3072xbf16>
    %877 = "ttir.typecast"(%875, %876) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %878 = ttir.empty() : tensor<1x1x3072xf32>
    %879 = "ttir.typecast"(%877, %878) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %880 = ttir.empty() : tensor<1x1x3072xf32>
    %881 = "ttir.multiply"(%853, %879, %880) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %882 = ttir.empty() : tensor<1x1x3072xbf16>
    %883 = "ttir.typecast"(%881, %882) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %884 = ttir.empty() : tensor<1x3072xbf16>
    %885 = "ttir.reshape"(%883, %884) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %886 = ttir.empty() : tensor<3072x4096xbf16>
    %887 = "ttir.permute"(%85, %886) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %888 = "ttir.dot_general"(%885, %887) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %889 = ttir.empty() : tensor<1x1x4096xbf16>
    %890 = "ttir.reshape"(%888, %889) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %891 = ttir.empty() : tensor<1x1x4096xf32>
    %892 = "ttir.typecast"(%890, %891) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %893 = ttir.empty() : tensor<1x1x4096xbf16>
    %894 = "ttir.sigmoid"(%890, %893) : (tensor<1x1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %895 = ttir.empty() : tensor<1x1x4096xf32>
    %896 = "ttir.typecast"(%894, %895) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %897 = ttir.empty() : tensor<1x1x4096xf32>
    %898 = "ttir.multiply"(%892, %896, %897) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %899 = ttir.empty() : tensor<1x1x4096xbf16>
    %900 = "ttir.typecast"(%898, %899) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %901 = ttir.empty() : tensor<1x1x4096xf32>
    %902 = "ttir.typecast"(%900, %901) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %903 = ttir.empty() : tensor<3072x4096xbf16>
    %904 = "ttir.permute"(%77, %903) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %905 = "ttir.dot_general"(%885, %904) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %906 = ttir.empty() : tensor<1x4096xf32>
    %907 = "ttir.typecast"(%905, %906) <{conservative_folding = false}> : (tensor<1x4096xbf16>, tensor<1x4096xf32>) -> tensor<1x4096xf32>
    %908 = ttir.empty() : tensor<1x1x4096xf32>
    %909 = "ttir.reshape"(%907, %908) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %910 = ttir.empty() : tensor<1x1x4096xf32>
    %911 = "ttir.multiply"(%902, %909, %910) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %912 = ttir.empty() : tensor<1x1x4096xbf16>
    %913 = "ttir.typecast"(%911, %912) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %914 = ttir.empty() : tensor<1x4096xbf16>
    %915 = "ttir.reshape"(%913, %914) <{shape = [1 : i32, 4096 : i32]}> : (tensor<1x1x4096xbf16>, tensor<1x4096xbf16>) -> tensor<1x4096xbf16>
    %916 = ttir.empty() : tensor<4096x3072xbf16>
    %917 = "ttir.permute"(%75, %916) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %918 = "ttir.dot_general"(%915, %917) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
    %919 = ttir.empty() : tensor<1x3072xbf16>
    %920 = "ttir.all_reduce"(%918, %919) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %921 = ttir.empty() : tensor<1x1x3072xbf16>
    %922 = "ttir.reshape"(%920, %921) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %923 = ttir.empty() : tensor<1x1x3072xbf16>
    %924 = "ttir.add"(%849, %922, %923) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %925 = ttir.empty() : tensor<1x1x3072xf32>
    %926 = "ttir.typecast"(%924, %925) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %927 = ttir.empty() : tensor<1x1x3072xf32>
    %928 = "ttir.pow"(%926, %116, %927) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %929 = ttir.empty() : tensor<1x1xf32>
    %930 = "ttir.sum"(%928, %929) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %931 = ttir.empty() : tensor<1x1xf32>
    %932 = "ttir.multiply"(%930, %111, %931) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %933 = ttir.empty() : tensor<1x1x1xf32>
    %934 = "ttir.reshape"(%932, %933) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %935 = ttir.empty() : tensor<1x1x1xf32>
    %936 = "ttir.add"(%934, %152, %935) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %937 = ttir.empty() : tensor<1x1x1xf32>
    %938 = "ttir.rsqrt"(%936, %937) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %939 = ttir.empty() : tensor<1x1xf32>
    %940 = "ttir.reshape"(%938, %939) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %941 = ttir.empty() : tensor<1x1x1xf32>
    %942 = "ttir.reshape"(%940, %941) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %943 = ttir.empty() : tensor<1x1x3072xf32>
    %944 = "ttir.broadcast"(%942, %943) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %945 = ttir.empty() : tensor<1x1x3072xf32>
    %946 = "ttir.multiply"(%926, %944, %945) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %947 = ttir.empty() : tensor<1x1x3072xbf16>
    %948 = "ttir.typecast"(%946, %947) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %949 = ttir.empty() : tensor<1x1x3072xf32>
    %950 = "ttir.typecast"(%948, %949) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %951 = ttir.empty() : tensor<1x1x3072xf32>
    %952 = "ttir.multiply"(%757, %950, %951) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %953 = ttir.empty() : tensor<1x1x3072xbf16>
    %954 = "ttir.typecast"(%952, %953) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %955 = ttir.empty() : tensor<1x3072xbf16>
    %956 = "ttir.reshape"(%954, %955) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %957 = ttir.empty() : tensor<3072x512xbf16>
    %958 = "ttir.permute"(%73, %957) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %959 = "ttir.dot_general"(%956, %958) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %960 = ttir.empty() : tensor<1x4x1x128xbf16>
    %961 = "ttir.reshape"(%959, %960) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %962 = ttir.empty() : tensor<1x4x1x128xf32>
    %963 = "ttir.typecast"(%961, %962) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %964 = ttir.empty() : tensor<1x4x1x128xf32>
    %965 = "ttir.multiply"(%963, %202, %964) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %966 = ttir.empty() : tensor<1x4x1x128xbf16>
    %967 = "ttir.typecast"(%965, %966) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %968 = ttir.empty() : tensor<1x4x1x64xbf16>
    %969 = "ttir.slice_static"(%961, %968) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %970 = ttir.empty() : tensor<1x4x1x64xbf16>
    %971 = "ttir.neg"(%969, %970) : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %972 = ttir.empty() : tensor<1x4x1x64xbf16>
    %973 = "ttir.slice_static"(%961, %972) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %974 = ttir.empty() : tensor<1x4x1x128xbf16>
    %975 = "ttir.concat"(%971, %973, %974) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %976 = ttir.empty() : tensor<1x4x1x128xf32>
    %977 = "ttir.typecast"(%975, %976) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %978 = ttir.empty() : tensor<1x4x1x128xf32>
    %979 = "ttir.multiply"(%977, %226, %978) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %980 = ttir.empty() : tensor<1x4x1x128xbf16>
    %981 = "ttir.typecast"(%979, %980) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %982 = ttir.empty() : tensor<1x4x1x128xbf16>
    %983 = "ttir.add"(%967, %981, %982) : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %984 = ttir.empty() : tensor<1x4x128x128xbf16>
    %985 = "ttir.scatter"(%89, %126, %983, %984) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %986 = ttir.empty() : tensor<3072x512xbf16>
    %987 = "ttir.permute"(%91, %986) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %988 = "ttir.dot_general"(%956, %987) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %989 = ttir.empty() : tensor<1x4x1x128xbf16>
    %990 = "ttir.reshape"(%988, %989) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %991 = ttir.empty() : tensor<1x4x128x128xbf16>
    %992 = "ttir.scatter"(%93, %126, %990, %991) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %993 = ttir.empty() : tensor<3072xf32>
    %994 = "ttir.typecast"(%107, %993) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %995 = ttir.empty() : tensor<1x1x3072xf32>
    %996 = "ttir.reshape"(%994, %995) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %997 = ttir.empty() : tensor<3072x1536xbf16>
    %998 = "ttir.permute"(%101, %997) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %999 = "ttir.dot_general"(%956, %998) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
    %1000 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1001 = "ttir.reshape"(%999, %1000) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1002 = ttir.empty() : tensor<1x12x1x128xf32>
    %1003 = "ttir.typecast"(%1001, %1002) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1004 = ttir.empty() : tensor<1x12x1x128xf32>
    %1005 = "ttir.multiply"(%1003, %256, %1004) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1006 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1007 = "ttir.typecast"(%1005, %1006) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1008 = ttir.empty() : tensor<1x12x1x64xbf16>
    %1009 = "ttir.slice_static"(%1001, %1008) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %1010 = ttir.empty() : tensor<1x12x1x64xbf16>
    %1011 = "ttir.neg"(%1009, %1010) : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %1012 = ttir.empty() : tensor<1x12x1x64xbf16>
    %1013 = "ttir.slice_static"(%1001, %1012) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %1014 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1015 = "ttir.concat"(%1011, %1013, %1014) <{dim = 3 : si32}> : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1016 = ttir.empty() : tensor<1x12x1x128xf32>
    %1017 = "ttir.typecast"(%1015, %1016) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1018 = ttir.empty() : tensor<1x12x1x128xf32>
    %1019 = "ttir.multiply"(%1017, %274, %1018) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1020 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1021 = "ttir.typecast"(%1019, %1020) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1022 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1023 = "ttir.add"(%1007, %1021, %1022) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1024 = ttir.empty() : tensor<12x1x128xbf16>
    %1025 = "ttir.reshape"(%1023, %1024) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %1026 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %1027 = "ttir.reshape"(%985, %1026) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %1028 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %1029 = "ttir.broadcast"(%1027, %1028) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %1030 = ttir.empty() : tensor<1x12x128x128xbf16>
    %1031 = "ttir.reshape"(%1029, %1030) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %1032 = ttir.empty() : tensor<1x12x128x128xbf16>
    %1033 = "ttir.permute"(%1031, %1032) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %1034 = ttir.empty() : tensor<12x128x128xbf16>
    %1035 = "ttir.reshape"(%1033, %1034) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %1036 = "ttir.dot_general"(%1025, %1035) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %1037 = ttir.empty() : tensor<12x1x128xf32>
    %1038 = "ttir.typecast"(%1036, %1037) <{conservative_folding = false}> : (tensor<12x1x128xbf16>, tensor<12x1x128xf32>) -> tensor<12x1x128xf32>
    %1039 = ttir.empty() : tensor<1x12x1x128xf32>
    %1040 = "ttir.reshape"(%1038, %1039) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1041 = ttir.empty() : tensor<1x12x1x128xf32>
    %1042 = "ttir.multiply"(%1040, %301, %1041) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1043 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1044 = "ttir.typecast"(%1042, %1043) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1045 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1046 = "ttir.add"(%1044, %327, %1045) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1047 = ttir.empty() : tensor<1x12x1x128xf32>
    %1048 = "ttir.typecast"(%1046, %1047) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1049 = ttir.empty() : tensor<1x12x1xf32>
    %1050 = "ttir.max"(%1048, %1049) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %1051 = ttir.empty() : tensor<1x12x1x1xf32>
    %1052 = "ttir.reshape"(%1050, %1051) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %1053 = ttir.empty() : tensor<1x12x1x128xf32>
    %1054 = "ttir.broadcast"(%1052, %1053) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1055 = ttir.empty() : tensor<1x12x1x128xf32>
    %1056 = "ttir.subtract"(%1048, %1054, %1055) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1057 = ttir.empty() : tensor<1x12x1x128xf32>
    %1058 = "ttir.exp"(%1056, %1057) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1059 = ttir.empty() : tensor<1x12x1xf32>
    %1060 = "ttir.sum"(%1058, %1059) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %1061 = ttir.empty() : tensor<1x12x1x1xf32>
    %1062 = "ttir.reshape"(%1060, %1061) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %1063 = ttir.empty() : tensor<1x12x1x128xf32>
    %1064 = "ttir.broadcast"(%1062, %1063) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1065 = ttir.empty() : tensor<1x12x1x128xf32>
    %1066 = "ttir.div"(%1058, %1064, %1065) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1067 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1068 = "ttir.typecast"(%1066, %1067) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1069 = ttir.empty() : tensor<12x1x128xbf16>
    %1070 = "ttir.reshape"(%1068, %1069) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %1071 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %1072 = "ttir.reshape"(%992, %1071) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %1073 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %1074 = "ttir.broadcast"(%1072, %1073) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %1075 = ttir.empty() : tensor<12x128x128xbf16>
    %1076 = "ttir.reshape"(%1074, %1075) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %1077 = "ttir.dot_general"(%1070, %1076) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %1078 = ttir.empty() : tensor<1x1536xbf16>
    %1079 = "ttir.reshape"(%1077, %1078) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16>, tensor<1x1536xbf16>) -> tensor<1x1536xbf16>
    %1080 = ttir.empty() : tensor<1536x3072xbf16>
    %1081 = "ttir.permute"(%99, %1080) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %1082 = "ttir.dot_general"(%1079, %1081) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
    %1083 = ttir.empty() : tensor<1x3072xbf16>
    %1084 = "ttir.all_reduce"(%1082, %1083) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %1085 = ttir.empty() : tensor<1x1x3072xbf16>
    %1086 = "ttir.reshape"(%1084, %1085) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1087 = ttir.empty() : tensor<1x1x3072xbf16>
    %1088 = "ttir.add"(%924, %1086, %1087) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1089 = ttir.empty() : tensor<3072xf32>
    %1090 = "ttir.typecast"(%103, %1089) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %1091 = ttir.empty() : tensor<1x1x3072xf32>
    %1092 = "ttir.reshape"(%1090, %1091) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1093 = ttir.empty() : tensor<1x1x3072xf32>
    %1094 = "ttir.typecast"(%1088, %1093) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1095 = ttir.empty() : tensor<1x1x3072xf32>
    %1096 = "ttir.pow"(%1094, %116, %1095) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1097 = ttir.empty() : tensor<1x1xf32>
    %1098 = "ttir.sum"(%1096, %1097) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %1099 = ttir.empty() : tensor<1x1xf32>
    %1100 = "ttir.multiply"(%1098, %111, %1099) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %1101 = ttir.empty() : tensor<1x1x1xf32>
    %1102 = "ttir.reshape"(%1100, %1101) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1103 = ttir.empty() : tensor<1x1x1xf32>
    %1104 = "ttir.add"(%1102, %152, %1103) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1105 = ttir.empty() : tensor<1x1x1xf32>
    %1106 = "ttir.rsqrt"(%1104, %1105) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1107 = ttir.empty() : tensor<1x1xf32>
    %1108 = "ttir.reshape"(%1106, %1107) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %1109 = ttir.empty() : tensor<1x1x1xf32>
    %1110 = "ttir.reshape"(%1108, %1109) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1111 = ttir.empty() : tensor<1x1x3072xf32>
    %1112 = "ttir.broadcast"(%1110, %1111) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1113 = ttir.empty() : tensor<1x1x3072xf32>
    %1114 = "ttir.multiply"(%1094, %1112, %1113) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1115 = ttir.empty() : tensor<1x1x3072xbf16>
    %1116 = "ttir.typecast"(%1114, %1115) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1117 = ttir.empty() : tensor<1x1x3072xf32>
    %1118 = "ttir.typecast"(%1116, %1117) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1119 = ttir.empty() : tensor<1x1x3072xf32>
    %1120 = "ttir.multiply"(%1092, %1118, %1119) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1121 = ttir.empty() : tensor<1x1x3072xbf16>
    %1122 = "ttir.typecast"(%1120, %1121) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1123 = ttir.empty() : tensor<1x3072xbf16>
    %1124 = "ttir.reshape"(%1122, %1123) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %1125 = ttir.empty() : tensor<3072x4096xbf16>
    %1126 = "ttir.permute"(%105, %1125) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %1127 = "ttir.dot_general"(%1124, %1126) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %1128 = ttir.empty() : tensor<1x1x4096xbf16>
    %1129 = "ttir.reshape"(%1127, %1128) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %1130 = ttir.empty() : tensor<1x1x4096xf32>
    %1131 = "ttir.typecast"(%1129, %1130) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %1132 = ttir.empty() : tensor<1x1x4096xbf16>
    %1133 = "ttir.sigmoid"(%1129, %1132) : (tensor<1x1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %1134 = ttir.empty() : tensor<1x1x4096xf32>
    %1135 = "ttir.typecast"(%1133, %1134) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %1136 = ttir.empty() : tensor<1x1x4096xf32>
    %1137 = "ttir.multiply"(%1131, %1135, %1136) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %1138 = ttir.empty() : tensor<1x1x4096xbf16>
    %1139 = "ttir.typecast"(%1137, %1138) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %1140 = ttir.empty() : tensor<1x1x4096xf32>
    %1141 = "ttir.typecast"(%1139, %1140) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %1142 = ttir.empty() : tensor<3072x4096xbf16>
    %1143 = "ttir.permute"(%97, %1142) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %1144 = "ttir.dot_general"(%1124, %1143) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %1145 = ttir.empty() : tensor<1x4096xf32>
    %1146 = "ttir.typecast"(%1144, %1145) <{conservative_folding = false}> : (tensor<1x4096xbf16>, tensor<1x4096xf32>) -> tensor<1x4096xf32>
    %1147 = ttir.empty() : tensor<1x1x4096xf32>
    %1148 = "ttir.reshape"(%1146, %1147) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %1149 = ttir.empty() : tensor<1x1x4096xf32>
    %1150 = "ttir.multiply"(%1141, %1148, %1149) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %1151 = ttir.empty() : tensor<1x1x4096xbf16>
    %1152 = "ttir.typecast"(%1150, %1151) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %1153 = ttir.empty() : tensor<1x4096xbf16>
    %1154 = "ttir.reshape"(%1152, %1153) <{shape = [1 : i32, 4096 : i32]}> : (tensor<1x1x4096xbf16>, tensor<1x4096xbf16>) -> tensor<1x4096xbf16>
    %1155 = ttir.empty() : tensor<4096x3072xbf16>
    %1156 = "ttir.permute"(%95, %1155) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %1157 = "ttir.dot_general"(%1154, %1156) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
    %1158 = ttir.empty() : tensor<1x3072xbf16>
    %1159 = "ttir.all_reduce"(%1157, %1158) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %1160 = ttir.empty() : tensor<1x1x3072xbf16>
    %1161 = "ttir.reshape"(%1159, %1160) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1162 = ttir.empty() : tensor<1x1x3072xbf16>
    %1163 = "ttir.add"(%1088, %1161, %1162) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1164 = ttir.empty() : tensor<1x1x3072xf32>
    %1165 = "ttir.typecast"(%1163, %1164) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1166 = ttir.empty() : tensor<1x1x3072xf32>
    %1167 = "ttir.pow"(%1165, %116, %1166) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1168 = ttir.empty() : tensor<1x1xf32>
    %1169 = "ttir.sum"(%1167, %1168) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %1170 = ttir.empty() : tensor<1x1xf32>
    %1171 = "ttir.multiply"(%1169, %111, %1170) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %1172 = ttir.empty() : tensor<1x1x1xf32>
    %1173 = "ttir.reshape"(%1171, %1172) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1174 = ttir.empty() : tensor<1x1x1xf32>
    %1175 = "ttir.add"(%1173, %152, %1174) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1176 = ttir.empty() : tensor<1x1x1xf32>
    %1177 = "ttir.rsqrt"(%1175, %1176) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1178 = ttir.empty() : tensor<1x1xf32>
    %1179 = "ttir.reshape"(%1177, %1178) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %1180 = ttir.empty() : tensor<1x1x1xf32>
    %1181 = "ttir.reshape"(%1179, %1180) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1182 = ttir.empty() : tensor<1x1x3072xf32>
    %1183 = "ttir.broadcast"(%1181, %1182) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1184 = ttir.empty() : tensor<1x1x3072xf32>
    %1185 = "ttir.multiply"(%1165, %1183, %1184) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1186 = ttir.empty() : tensor<1x1x3072xbf16>
    %1187 = "ttir.typecast"(%1185, %1186) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1188 = ttir.empty() : tensor<1x1x3072xf32>
    %1189 = "ttir.typecast"(%1187, %1188) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1190 = ttir.empty() : tensor<1x1x3072xf32>
    %1191 = "ttir.multiply"(%996, %1189, %1190) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1192 = ttir.empty() : tensor<1x1x3072xbf16>
    %1193 = "ttir.typecast"(%1191, %1192) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1194 = ttir.empty() : tensor<1x3072xbf16>
    %1195 = "ttir.reshape"(%1193, %1194) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %1196 = ttir.empty() : tensor<3072x64128xbf16>
    %1197 = "ttir.permute"(%11, %1196) <{permutation = array<i64: 1, 0>}> : (tensor<64128x3072xbf16>, tensor<3072x64128xbf16>) -> tensor<3072x64128xbf16>
    %1198 = "ttir.dot_general"(%1195, %1197) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x64128xbf16>) -> tensor<1x64128xbf16>
    %1199 = ttir.empty() : tensor<1x1x64128xbf16>
    %1200 = "ttir.reshape"(%1198, %1199) <{shape = [1 : i32, 1 : i32, 64128 : i32]}> : (tensor<1x64128xbf16>, tensor<1x1x64128xbf16>) -> tensor<1x1x64128xbf16>
    %1201 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1202 = "ttir.mesh_shard"(%234, %1201) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1203 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1204 = "ttir.mesh_shard"(%241, %1203) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1205 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1206 = "ttir.mesh_shard"(%507, %1205) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1207 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1208 = "ttir.mesh_shard"(%514, %1207) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1209 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1210 = "ttir.mesh_shard"(%746, %1209) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1211 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1212 = "ttir.mesh_shard"(%753, %1211) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1213 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1214 = "ttir.mesh_shard"(%985, %1213) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1215 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1216 = "ttir.mesh_shard"(%992, %1215) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1217 = ttir.empty() : tensor<1x128256xbf16>
    %1218 = "ttir.mesh_shard"(%1198, %1217) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x64128xbf16>, tensor<1x128256xbf16>) -> tensor<1x128256xbf16>
    %1219 = ttir.empty() : tensor<1x1x128256xbf16>
    %1220 = "ttir.mesh_shard"(%1200, %1219) <{shard_dims = array<i64: -1, 2>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x64128xbf16>, tensor<1x1x128256xbf16>) -> tensor<1x1x128256xbf16>
    return %1202, %1204, %1206, %1208, %1210, %1212, %1214, %1216, %1218, %1220 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>
  }
}
module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99776, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184736, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99776, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193056, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main_const_eval_0() -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 2.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        return %2 : tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
      }
      func.func @main(%arg0: tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg3: tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg4: tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg5: tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg6: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg7: tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg8: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg9: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg10: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg11: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg12: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg13: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg14: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg15: tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg16: tensor<1x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg17: tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg18: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg19: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg20: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg21: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg22: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg23: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg24: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg25: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg26: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg27: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg28: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg29: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg30: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg31: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg32: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg33: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg34: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg35: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg36: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg37: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg38: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg39: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg40: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg41: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg42: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg43: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg44: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg45: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg46: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg47: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg48: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg49: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg50: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg51: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg52: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg53: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128256xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x1x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x128256xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %1 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %2 = "ttnn.full"(%1) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 3.25520843E-4 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<1x1>}> : (!ttnn.device) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %3 = "ttnn.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %4 = "ttnn.mesh_shard"(%arg1, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %5 = "ttnn.mesh_shard"(%arg2, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %6 = "ttnn.mesh_shard"(%arg3, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %7 = "ttnn.mesh_shard"(%arg4, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %8 = "ttnn.mesh_shard"(%arg5, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg5) <{force = false}> : (tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %9 = "ttnn.mesh_shard"(%arg6, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %10 = "ttnn.mesh_shard"(%arg8, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg8) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %11 = "ttnn.mesh_shard"(%arg9, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %12 = "ttnn.mesh_shard"(%arg10, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %13 = "ttnn.mesh_shard"(%arg11, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg11) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %14 = "ttnn.mesh_shard"(%arg12, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg12) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %15 = "ttnn.mesh_shard"(%arg13, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg13) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %16 = "ttnn.mesh_shard"(%arg14, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg14) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %17 = "ttnn.mesh_shard"(%arg15, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg15) <{force = false}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %18 = "ttnn.mesh_shard"(%arg16, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg16) <{force = false}> : (tensor<1x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %19 = "ttnn.mesh_shard"(%arg17, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg17) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %20 = "ttnn.mesh_shard"(%arg18, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg18) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %21 = "ttnn.mesh_shard"(%arg19, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg19) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %22 = "ttnn.mesh_shard"(%arg20, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg20) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %23 = "ttnn.mesh_shard"(%arg21, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg21) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %24 = "ttnn.mesh_shard"(%arg22, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg22) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %25 = "ttnn.mesh_shard"(%arg23, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg23) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %26 = "ttnn.mesh_shard"(%arg24, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg24) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %27 = "ttnn.mesh_shard"(%arg25, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg25) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %28 = "ttnn.mesh_shard"(%arg26, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg26) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %29 = "ttnn.mesh_shard"(%arg27, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg27) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %30 = "ttnn.mesh_shard"(%arg28, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg28) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %31 = "ttnn.mesh_shard"(%arg29, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg29) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %32 = "ttnn.mesh_shard"(%arg30, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg30) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %33 = "ttnn.mesh_shard"(%arg31, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg31) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %34 = "ttnn.mesh_shard"(%arg32, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg32) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %35 = "ttnn.mesh_shard"(%arg33, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg33) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %36 = "ttnn.mesh_shard"(%arg34, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg34) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %37 = "ttnn.mesh_shard"(%arg35, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg35) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %38 = "ttnn.mesh_shard"(%arg36, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg36) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %39 = "ttnn.mesh_shard"(%arg37, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg37) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %40 = "ttnn.mesh_shard"(%arg38, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg38) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %41 = "ttnn.mesh_shard"(%arg39, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg39) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %42 = "ttnn.mesh_shard"(%arg40, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg40) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %43 = "ttnn.mesh_shard"(%arg41, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg41) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %44 = "ttnn.mesh_shard"(%arg42, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg42) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %45 = "ttnn.mesh_shard"(%arg43, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg43) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %46 = "ttnn.mesh_shard"(%arg44, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg44) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %47 = "ttnn.mesh_shard"(%arg45, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg45) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %48 = "ttnn.mesh_shard"(%arg46, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg46) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %49 = "ttnn.mesh_shard"(%arg47, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg47) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %50 = "ttnn.mesh_shard"(%arg48, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg48) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %51 = "ttnn.mesh_shard"(%arg49, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg49) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %52 = "ttnn.mesh_shard"(%arg50, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg50) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %53 = "ttnn.mesh_shard"(%arg51, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg51) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %54 = "ttnn.mesh_shard"(%arg52, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg52) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %55 = "ttnn.mesh_shard"(%arg53, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg53) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %56 = "ttnn.typecast"(%9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %57 = "ttnn.reshape"(%56) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%56) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %58 = "ttnn.typecast"(%7) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %59 = "ttnn.reshape"(%58) <{shape = [1 : i32]}> : (tensor<1x1xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%58) <{force = false}> : (tensor<1x1xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %60 = "ttnn.from_device"(%59) : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%59) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %61 = "ttnn.to_layout"(%60) <{layout = #ttnn.layout<row_major>}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%60) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>) -> ()
        %62 = "ttnn.to_device"(%61, %1) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%61) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #ttnn.buffer_type<system_memory>>>>) -> ()
        %63 = "ttnn.embedding"(%62, %8) : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%62) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %64 = "ttnn.reshape"(%63) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%63) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %65 = "ttnn.reduce_scatter"(%64, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%64) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %66 = "ttnn.all_gather"(%65, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%65) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %67 = "ttnn.reshape"(%66) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%66) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %68 = "ttnn.typecast"(%67) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %69 = "ttnn.reshape"(%68) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %70 = "ttnn.pow"(%69, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%69) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %71 = "ttnn.sum"(%70) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%70) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %72 = "ttnn.multiply"(%71, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%71) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %73 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %74 = "ttnn.add"(%72, %73) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%73) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%72) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %75 = "ttnn.rsqrt"(%74) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%74) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %76 = "ttnn.multiply"(%68, %75) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%75) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%68) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %77 = "ttnn.multiply"(%57, %76) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%76) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%57) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %78 = "ttnn.typecast"(%77) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%77) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %79 = "ttnn.matmul"(%78, %5) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %80 = "ttnn.reshape"(%79) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%79) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %81 = "ttnn.typecast"(%80) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %82 = "ttnn.reshape"(%4) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %83 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %84 = "ttnn.reshape"(%83) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%83) <{force = false}> : (tensor<1xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %85 = "ttnn.matmul"(%82, %84) <{transpose_a = false, transpose_b = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%84) <{force = false}> : (tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%82) <{force = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %86 = "ttnn.reshape"(%85) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%85) <{force = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %87 = "ttnn.concat"(%86, %86) <{dim = 2 : si32}> : (tensor<1x1x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%86) <{force = false}> : (tensor<1x1x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %88 = "ttnn.cos"(%87) : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %89 = "ttnn.reshape"(%88) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %90 = "ttnn.multiply"(%81, %89) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%81) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %91 = "ttnn.typecast"(%90) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%90) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %92 = "ttnn.slice_static"(%80) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %93 = "ttnn.neg"(%92) : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%92) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %94 = "ttnn.slice_static"(%80) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%80) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %95 = "ttnn.concat"(%93, %94) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%94) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%93) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %96 = "ttnn.typecast"(%95) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%95) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %97 = "ttnn.sin"(%87) : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%87) <{force = false}> : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %98 = "ttnn.reshape"(%97) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %99 = "ttnn.multiply"(%96, %98) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%96) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %100 = "ttnn.typecast"(%99) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%99) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %101 = "ttnn.add"(%91, %100) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%100) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%91) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %102 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%10, %101, %102) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%102) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%101) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %103 = "ttnn.matmul"(%78, %11) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %104 = "ttnn.reshape"(%103) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%103) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %105 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%12, %104, %105) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%105) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%104) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %106 = "ttnn.typecast"(%23) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %107 = "ttnn.reshape"(%106) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%106) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %108 = "ttnn.matmul"(%78, %20) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%78) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %109 = "ttnn.reshape"(%108) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %110 = "ttnn.typecast"(%108) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%108) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %111 = "ttnn.reshape"(%110) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%110) <{force = false}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %112 = "ttnn.multiply"(%111, %88) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%111) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %113 = "ttnn.typecast"(%112) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%112) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %114 = "ttnn.slice_static"(%109) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %115 = "ttnn.neg"(%114) : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%114) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %116 = "ttnn.reshape"(%115) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%115) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %117 = "ttnn.slice_static"(%109) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%109) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %118 = "ttnn.reshape"(%117) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%117) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %119 = "ttnn.concat"(%116, %118) <{dim = 2 : si32}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%118) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%116) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %120 = "ttnn.typecast"(%119) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%119) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %121 = "ttnn.multiply"(%120, %97) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%120) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %122 = "ttnn.typecast"(%121) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%121) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %123 = "ttnn.add"(%113, %122) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%122) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%113) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %124 = "ttnn.reshape"(%10) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %125 = "ttnn.repeat"(%124) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%124) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %126 = "ttnn.reshape"(%125) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%125) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %127 = "ttnn.permute"(%126) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%126) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %128 = "ttnn.reshape"(%127) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%127) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %129 = "ttnn.matmul"(%123, %128) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%128) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%123) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %130 = "ttnn.typecast"(%129) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%129) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %131 = "ttnn.reshape"(%130) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%130) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %132 = "ttnn.reshape"(%19) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %133 = "ttnn.multiply"(%131, %132) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%131) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %134 = "ttnn.typecast"(%133) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%133) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %135 = "ttnn.typecast"(%18) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<1x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %136 = "ttnn.reshape"(%135) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%135) <{force = false}> : (tensor<1x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %137 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %138 = "ttnn.reshape"(%17) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %139 = "ttnn.typecast"(%138) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%138) <{force = false}> : (tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %140 = "ttnn.typecast"(%137) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%137) <{force = false}> : (tensor<1x1x1x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %141 = "ttnn.gt"(%139, %140) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%140) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%139) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %142 = "ttnn.typecast"(%141) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%141) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %143 = "ttnn.typecast"(%142) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%142) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %144 = "ttnn.multiply"(%136, %143) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%143) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%136) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %145 = "ttnn.typecast"(%144) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%144) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %146 = "ttnn.add"(%134, %145) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%134) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %147 = "ttnn.typecast"(%146) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%146) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %148 = "ttnn.max"(%147) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %149 = "ttnn.neg"(%148) : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%148) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %150 = "ttnn.add"(%147, %149) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%149) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%147) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %151 = "ttnn.softmax"(%150) <{dimension = 3 : si32}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%150) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %152 = "ttnn.typecast"(%151) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%151) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %153 = "ttnn.reshape"(%152) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%152) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %154 = "ttnn.reshape"(%12) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %155 = "ttnn.repeat"(%154) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%154) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %156 = "ttnn.reshape"(%155) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%155) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %157 = "ttnn.matmul"(%153, %156) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%156) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%153) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %158 = "ttnn.reshape"(%157) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%157) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %159 = "ttnn.matmul"(%158, %16) <{transpose_a = false, transpose_b = true}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%158) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %160 = "ttnn.reshape"(%159) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%159) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %161 = "ttnn.reduce_scatter"(%160, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%160) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %162 = "ttnn.all_gather"(%161, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%161) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %163 = "ttnn.reshape"(%162) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%162) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %164 = "ttnn.add"(%67, %163) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%163) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%67) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %165 = "ttnn.typecast"(%21) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %166 = "ttnn.reshape"(%165) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%165) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %167 = "ttnn.typecast"(%164) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %168 = "ttnn.reshape"(%167) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %169 = "ttnn.pow"(%168, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%168) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %170 = "ttnn.sum"(%169) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%169) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %171 = "ttnn.multiply"(%170, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%170) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %172 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %173 = "ttnn.add"(%171, %172) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%172) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%171) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %174 = "ttnn.rsqrt"(%173) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%173) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %175 = "ttnn.multiply"(%167, %174) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%174) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%167) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %176 = "ttnn.multiply"(%166, %175) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%175) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%166) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %177 = "ttnn.typecast"(%176) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%176) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %178 = "ttnn.matmul"(%177, %22) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%22) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %179 = "ttnn.typecast"(%178) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %180 = "ttnn.sigmoid"(%178) : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%178) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %181 = "ttnn.typecast"(%180) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%180) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %182 = "ttnn.multiply"(%179, %181) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%181) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%179) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %183 = "ttnn.matmul"(%177, %15) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%177) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %184 = "ttnn.typecast"(%183) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%183) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %185 = "ttnn.multiply"(%182, %184) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%184) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%182) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %186 = "ttnn.typecast"(%185) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%185) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %187 = "ttnn.matmul"(%186, %14) <{transpose_a = false, transpose_b = true}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%186) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %188 = "ttnn.reshape"(%187) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%187) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %189 = "ttnn.reduce_scatter"(%188, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%188) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %190 = "ttnn.all_gather"(%189, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%189) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %191 = "ttnn.reshape"(%190) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%190) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %192 = "ttnn.add"(%164, %191) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%191) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%164) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %193 = "ttnn.typecast"(%192) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %194 = "ttnn.reshape"(%193) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %195 = "ttnn.pow"(%194, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%194) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %196 = "ttnn.sum"(%195) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%195) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %197 = "ttnn.multiply"(%196, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%196) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %198 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %199 = "ttnn.add"(%197, %198) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%198) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%197) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %200 = "ttnn.rsqrt"(%199) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%199) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %201 = "ttnn.multiply"(%193, %200) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%200) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%193) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %202 = "ttnn.multiply"(%107, %201) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%201) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%107) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %203 = "ttnn.typecast"(%202) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%202) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %204 = "ttnn.matmul"(%203, %13) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %205 = "ttnn.reshape"(%204) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%204) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %206 = "ttnn.typecast"(%205) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %207 = "ttnn.multiply"(%206, %89) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%206) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %208 = "ttnn.typecast"(%207) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%207) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %209 = "ttnn.slice_static"(%205) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %210 = "ttnn.neg"(%209) : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%209) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %211 = "ttnn.slice_static"(%205) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%205) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %212 = "ttnn.concat"(%210, %211) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%211) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%210) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %213 = "ttnn.typecast"(%212) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%212) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %214 = "ttnn.multiply"(%213, %98) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%213) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %215 = "ttnn.typecast"(%214) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%214) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %216 = "ttnn.add"(%208, %215) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%215) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%208) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %217 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%24, %216, %217) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%217) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%216) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %218 = "ttnn.matmul"(%203, %25) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%25) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %219 = "ttnn.reshape"(%218) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%218) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %220 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%26, %219, %220) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%220) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%219) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %221 = "ttnn.typecast"(%34) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%34) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %222 = "ttnn.reshape"(%221) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%221) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %223 = "ttnn.matmul"(%203, %31) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%203) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%31) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %224 = "ttnn.reshape"(%223) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %225 = "ttnn.typecast"(%223) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%223) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %226 = "ttnn.reshape"(%225) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%225) <{force = false}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %227 = "ttnn.multiply"(%226, %88) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%226) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %228 = "ttnn.typecast"(%227) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%227) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %229 = "ttnn.slice_static"(%224) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %230 = "ttnn.neg"(%229) : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%229) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %231 = "ttnn.reshape"(%230) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%230) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %232 = "ttnn.slice_static"(%224) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%224) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %233 = "ttnn.reshape"(%232) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%232) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %234 = "ttnn.concat"(%231, %233) <{dim = 2 : si32}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%233) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%231) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %235 = "ttnn.typecast"(%234) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%234) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %236 = "ttnn.multiply"(%235, %97) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%235) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %237 = "ttnn.typecast"(%236) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%236) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %238 = "ttnn.add"(%228, %237) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%237) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%228) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %239 = "ttnn.reshape"(%24) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %240 = "ttnn.repeat"(%239) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%239) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %241 = "ttnn.reshape"(%240) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%240) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %242 = "ttnn.permute"(%241) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%241) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %243 = "ttnn.reshape"(%242) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%242) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %244 = "ttnn.matmul"(%238, %243) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%243) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%238) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %245 = "ttnn.typecast"(%244) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%244) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %246 = "ttnn.reshape"(%245) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%245) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %247 = "ttnn.multiply"(%246, %132) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%246) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %248 = "ttnn.typecast"(%247) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%247) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %249 = "ttnn.add"(%248, %145) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%248) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %250 = "ttnn.typecast"(%249) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%249) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %251 = "ttnn.max"(%250) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %252 = "ttnn.neg"(%251) : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%251) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %253 = "ttnn.add"(%250, %252) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%252) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%250) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %254 = "ttnn.softmax"(%253) <{dimension = 3 : si32}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%253) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %255 = "ttnn.typecast"(%254) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%254) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %256 = "ttnn.reshape"(%255) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%255) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %257 = "ttnn.reshape"(%26) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %258 = "ttnn.repeat"(%257) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%257) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %259 = "ttnn.reshape"(%258) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%258) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %260 = "ttnn.matmul"(%256, %259) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%259) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%256) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %261 = "ttnn.reshape"(%260) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%260) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %262 = "ttnn.matmul"(%261, %30) <{transpose_a = false, transpose_b = true}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%261) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%30) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %263 = "ttnn.reshape"(%262) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%262) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %264 = "ttnn.reduce_scatter"(%263, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%263) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %265 = "ttnn.all_gather"(%264, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%264) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %266 = "ttnn.reshape"(%265) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%265) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %267 = "ttnn.add"(%192, %266) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%266) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%192) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %268 = "ttnn.typecast"(%32) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%32) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %269 = "ttnn.reshape"(%268) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%268) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %270 = "ttnn.typecast"(%267) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %271 = "ttnn.reshape"(%270) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %272 = "ttnn.pow"(%271, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%271) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %273 = "ttnn.sum"(%272) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%272) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %274 = "ttnn.multiply"(%273, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%273) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %275 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %276 = "ttnn.add"(%274, %275) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%275) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%274) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %277 = "ttnn.rsqrt"(%276) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%276) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %278 = "ttnn.multiply"(%270, %277) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%277) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%270) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %279 = "ttnn.multiply"(%269, %278) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%278) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%269) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %280 = "ttnn.typecast"(%279) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%279) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %281 = "ttnn.matmul"(%280, %33) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%33) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %282 = "ttnn.typecast"(%281) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %283 = "ttnn.sigmoid"(%281) : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%281) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %284 = "ttnn.typecast"(%283) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%283) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %285 = "ttnn.multiply"(%282, %284) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%284) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%282) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %286 = "ttnn.matmul"(%280, %29) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%280) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%29) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %287 = "ttnn.typecast"(%286) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%286) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %288 = "ttnn.multiply"(%285, %287) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%287) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%285) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %289 = "ttnn.typecast"(%288) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%288) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %290 = "ttnn.matmul"(%289, %28) <{transpose_a = false, transpose_b = true}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%289) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%28) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %291 = "ttnn.reshape"(%290) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%290) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %292 = "ttnn.reduce_scatter"(%291, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%291) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %293 = "ttnn.all_gather"(%292, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%292) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %294 = "ttnn.reshape"(%293) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%293) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %295 = "ttnn.add"(%267, %294) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%294) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%267) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %296 = "ttnn.typecast"(%295) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %297 = "ttnn.reshape"(%296) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %298 = "ttnn.pow"(%297, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%297) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %299 = "ttnn.sum"(%298) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%298) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %300 = "ttnn.multiply"(%299, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%299) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %301 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %302 = "ttnn.add"(%300, %301) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%301) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%300) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %303 = "ttnn.rsqrt"(%302) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%302) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %304 = "ttnn.multiply"(%296, %303) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%303) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%296) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %305 = "ttnn.multiply"(%222, %304) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%304) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%222) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %306 = "ttnn.typecast"(%305) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%305) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %307 = "ttnn.matmul"(%306, %27) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%27) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %308 = "ttnn.reshape"(%307) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%307) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %309 = "ttnn.typecast"(%308) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %310 = "ttnn.multiply"(%309, %89) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%309) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %311 = "ttnn.typecast"(%310) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%310) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %312 = "ttnn.slice_static"(%308) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %313 = "ttnn.neg"(%312) : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%312) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %314 = "ttnn.slice_static"(%308) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%308) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %315 = "ttnn.concat"(%313, %314) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%314) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%313) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %316 = "ttnn.typecast"(%315) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%315) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %317 = "ttnn.multiply"(%316, %98) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%316) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %318 = "ttnn.typecast"(%317) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%317) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %319 = "ttnn.add"(%311, %318) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%318) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%311) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %320 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%35, %319, %320) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%320) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%319) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %321 = "ttnn.matmul"(%306, %36) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%36) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %322 = "ttnn.reshape"(%321) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%321) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %323 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%37, %322, %323) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%323) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%322) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %324 = "ttnn.typecast"(%45) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%45) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %325 = "ttnn.reshape"(%324) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%324) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %326 = "ttnn.matmul"(%306, %42) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%306) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%42) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %327 = "ttnn.reshape"(%326) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %328 = "ttnn.typecast"(%326) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%326) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %329 = "ttnn.reshape"(%328) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%328) <{force = false}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %330 = "ttnn.multiply"(%329, %88) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%329) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %331 = "ttnn.typecast"(%330) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%330) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %332 = "ttnn.slice_static"(%327) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %333 = "ttnn.neg"(%332) : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%332) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %334 = "ttnn.reshape"(%333) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%333) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %335 = "ttnn.slice_static"(%327) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%327) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %336 = "ttnn.reshape"(%335) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%335) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %337 = "ttnn.concat"(%334, %336) <{dim = 2 : si32}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%336) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%334) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %338 = "ttnn.typecast"(%337) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%337) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %339 = "ttnn.multiply"(%338, %97) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%338) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %340 = "ttnn.typecast"(%339) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%339) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %341 = "ttnn.add"(%331, %340) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%340) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%331) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %342 = "ttnn.reshape"(%35) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %343 = "ttnn.repeat"(%342) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%342) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %344 = "ttnn.reshape"(%343) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%343) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %345 = "ttnn.permute"(%344) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%344) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %346 = "ttnn.reshape"(%345) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%345) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %347 = "ttnn.matmul"(%341, %346) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%346) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%341) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %348 = "ttnn.typecast"(%347) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%347) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %349 = "ttnn.reshape"(%348) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%348) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %350 = "ttnn.multiply"(%349, %132) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%349) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %351 = "ttnn.typecast"(%350) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%350) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %352 = "ttnn.add"(%351, %145) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%351) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %353 = "ttnn.typecast"(%352) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%352) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %354 = "ttnn.max"(%353) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %355 = "ttnn.neg"(%354) : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%354) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %356 = "ttnn.add"(%353, %355) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%355) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%353) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %357 = "ttnn.softmax"(%356) <{dimension = 3 : si32}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%356) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %358 = "ttnn.typecast"(%357) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%357) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %359 = "ttnn.reshape"(%358) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%358) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %360 = "ttnn.reshape"(%37) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %361 = "ttnn.repeat"(%360) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%360) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %362 = "ttnn.reshape"(%361) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%361) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %363 = "ttnn.matmul"(%359, %362) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%362) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%359) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %364 = "ttnn.reshape"(%363) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%363) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %365 = "ttnn.matmul"(%364, %41) <{transpose_a = false, transpose_b = true}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%364) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%41) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %366 = "ttnn.reshape"(%365) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%365) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %367 = "ttnn.reduce_scatter"(%366, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%366) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %368 = "ttnn.all_gather"(%367, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%367) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %369 = "ttnn.reshape"(%368) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%368) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %370 = "ttnn.add"(%295, %369) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%369) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%295) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %371 = "ttnn.typecast"(%43) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%43) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %372 = "ttnn.reshape"(%371) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%371) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %373 = "ttnn.typecast"(%370) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %374 = "ttnn.reshape"(%373) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %375 = "ttnn.pow"(%374, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%374) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %376 = "ttnn.sum"(%375) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%375) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %377 = "ttnn.multiply"(%376, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%376) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %378 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %379 = "ttnn.add"(%377, %378) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%378) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%377) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %380 = "ttnn.rsqrt"(%379) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%379) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %381 = "ttnn.multiply"(%373, %380) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%380) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%373) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %382 = "ttnn.multiply"(%372, %381) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%381) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%372) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %383 = "ttnn.typecast"(%382) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%382) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %384 = "ttnn.matmul"(%383, %44) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%44) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %385 = "ttnn.typecast"(%384) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %386 = "ttnn.sigmoid"(%384) : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%384) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %387 = "ttnn.typecast"(%386) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%386) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %388 = "ttnn.multiply"(%385, %387) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%387) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%385) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %389 = "ttnn.matmul"(%383, %40) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%383) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%40) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %390 = "ttnn.typecast"(%389) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%389) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %391 = "ttnn.multiply"(%388, %390) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%390) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%388) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %392 = "ttnn.typecast"(%391) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%391) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %393 = "ttnn.matmul"(%392, %39) <{transpose_a = false, transpose_b = true}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%392) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%39) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %394 = "ttnn.reshape"(%393) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%393) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %395 = "ttnn.reduce_scatter"(%394, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%394) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %396 = "ttnn.all_gather"(%395, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%395) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %397 = "ttnn.reshape"(%396) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%396) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %398 = "ttnn.add"(%370, %397) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%397) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%370) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %399 = "ttnn.typecast"(%398) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %400 = "ttnn.reshape"(%399) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %401 = "ttnn.pow"(%400, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%400) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %402 = "ttnn.sum"(%401) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%401) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %403 = "ttnn.multiply"(%402, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%402) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %404 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %405 = "ttnn.add"(%403, %404) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%404) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%403) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %406 = "ttnn.rsqrt"(%405) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%405) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %407 = "ttnn.multiply"(%399, %406) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%406) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%399) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %408 = "ttnn.multiply"(%325, %407) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%407) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%325) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %409 = "ttnn.typecast"(%408) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%408) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %410 = "ttnn.matmul"(%409, %38) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%38) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %411 = "ttnn.reshape"(%410) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%410) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %412 = "ttnn.typecast"(%411) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %413 = "ttnn.multiply"(%412, %89) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%412) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%89) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %414 = "ttnn.typecast"(%413) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%413) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %415 = "ttnn.slice_static"(%411) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %416 = "ttnn.neg"(%415) : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%415) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %417 = "ttnn.slice_static"(%411) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%411) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %418 = "ttnn.concat"(%416, %417) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%417) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%416) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %419 = "ttnn.typecast"(%418) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%418) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %420 = "ttnn.multiply"(%419, %98) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%419) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%98) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %421 = "ttnn.typecast"(%420) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%420) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %422 = "ttnn.add"(%414, %421) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%421) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%414) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %423 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%46, %422, %423) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%423) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%422) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %424 = "ttnn.matmul"(%409, %47) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%47) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %425 = "ttnn.reshape"(%424) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%424) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %426 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.update_cache"(%48, %425, %426) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%426) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%425) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %427 = "ttnn.typecast"(%55) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%55) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %428 = "ttnn.reshape"(%427) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%427) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %429 = "ttnn.matmul"(%409, %52) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%409) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%52) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %430 = "ttnn.reshape"(%429) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %431 = "ttnn.typecast"(%429) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%429) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %432 = "ttnn.reshape"(%431) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%431) <{force = false}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %433 = "ttnn.multiply"(%432, %88) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%432) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%88) <{force = false}> : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %434 = "ttnn.typecast"(%433) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%433) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %435 = "ttnn.slice_static"(%430) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %436 = "ttnn.neg"(%435) : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%435) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %437 = "ttnn.reshape"(%436) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%436) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %438 = "ttnn.slice_static"(%430) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%430) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %439 = "ttnn.reshape"(%438) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%438) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %440 = "ttnn.concat"(%437, %439) <{dim = 2 : si32}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%439) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%437) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %441 = "ttnn.typecast"(%440) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%440) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %442 = "ttnn.multiply"(%441, %97) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%441) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%97) <{force = false}> : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %443 = "ttnn.typecast"(%442) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%442) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %444 = "ttnn.add"(%434, %443) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%443) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%434) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %445 = "ttnn.reshape"(%46) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %446 = "ttnn.repeat"(%445) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%445) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %447 = "ttnn.reshape"(%446) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%446) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %448 = "ttnn.permute"(%447) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%447) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %449 = "ttnn.reshape"(%448) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%448) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %450 = "ttnn.matmul"(%444, %449) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%449) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%444) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %451 = "ttnn.typecast"(%450) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%450) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %452 = "ttnn.reshape"(%451) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%451) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %453 = "ttnn.multiply"(%452, %132) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%452) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%132) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %454 = "ttnn.typecast"(%453) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%453) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %455 = "ttnn.add"(%454, %145) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%454) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%145) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %456 = "ttnn.typecast"(%455) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%455) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %457 = "ttnn.max"(%456) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %458 = "ttnn.neg"(%457) : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%457) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %459 = "ttnn.add"(%456, %458) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%458) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%456) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %460 = "ttnn.softmax"(%459) <{dimension = 3 : si32}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%459) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %461 = "ttnn.typecast"(%460) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%460) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %462 = "ttnn.reshape"(%461) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%461) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %463 = "ttnn.reshape"(%48) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %464 = "ttnn.repeat"(%463) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%463) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %465 = "ttnn.reshape"(%464) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%464) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %466 = "ttnn.matmul"(%462, %465) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%465) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%462) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %467 = "ttnn.reshape"(%466) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%466) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %468 = "ttnn.matmul"(%467, %51) <{transpose_a = false, transpose_b = true}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%467) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%51) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %469 = "ttnn.reshape"(%468) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%468) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %470 = "ttnn.reduce_scatter"(%469, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%469) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %471 = "ttnn.all_gather"(%470, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%470) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %472 = "ttnn.reshape"(%471) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%471) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %473 = "ttnn.add"(%398, %472) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%472) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%398) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %474 = "ttnn.typecast"(%53) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%53) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %475 = "ttnn.reshape"(%474) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%474) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %476 = "ttnn.typecast"(%473) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %477 = "ttnn.reshape"(%476) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %478 = "ttnn.pow"(%477, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%477) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %479 = "ttnn.sum"(%478) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%478) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %480 = "ttnn.multiply"(%479, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%479) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %481 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %482 = "ttnn.add"(%480, %481) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%481) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%480) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %483 = "ttnn.rsqrt"(%482) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%482) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %484 = "ttnn.multiply"(%476, %483) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%483) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%476) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %485 = "ttnn.multiply"(%475, %484) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%484) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%475) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %486 = "ttnn.typecast"(%485) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%485) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %487 = "ttnn.matmul"(%486, %54) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%54) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %488 = "ttnn.typecast"(%487) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %489 = "ttnn.sigmoid"(%487) : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%487) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %490 = "ttnn.typecast"(%489) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%489) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %491 = "ttnn.multiply"(%488, %490) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%490) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%488) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %492 = "ttnn.matmul"(%486, %50) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%486) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%50) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %493 = "ttnn.typecast"(%492) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%492) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %494 = "ttnn.multiply"(%491, %493) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%493) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%491) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %495 = "ttnn.typecast"(%494) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%494) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %496 = "ttnn.matmul"(%495, %49) <{transpose_a = false, transpose_b = true}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%495) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%49) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %497 = "ttnn.reshape"(%496) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%496) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %498 = "ttnn.reduce_scatter"(%497, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%497) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %499 = "ttnn.all_gather"(%498, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%498) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %500 = "ttnn.reshape"(%499) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%499) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %501 = "ttnn.add"(%473, %500) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%500) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%473) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %502 = "ttnn.typecast"(%501) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%501) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %503 = "ttnn.reshape"(%502) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %504 = "ttnn.pow"(%503, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%503) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %505 = "ttnn.sum"(%504) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%504) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %506 = "ttnn.multiply"(%505, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%505) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %507 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %508 = "ttnn.add"(%506, %507) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%507) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%506) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %509 = "ttnn.rsqrt"(%508) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%508) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %510 = "ttnn.multiply"(%502, %509) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%509) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%502) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %511 = "ttnn.multiply"(%428, %510) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%510) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%428) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %512 = "ttnn.typecast"(%511) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%511) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %513 = "ttnn.matmul"(%512, %8) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%512) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %514 = "ttnn.reshape"(%513) <{shape = [1 : i32, 1 : i32, 64128 : i32]}> : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %515 = "ttnn.to_layout"(%10) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %516 = "ttnn.from_device"(%515) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%515) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %517 = "ttnn.mesh_shard"(%516, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%516) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %518 = "ttnn.to_layout"(%12) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %519 = "ttnn.from_device"(%518) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%518) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %520 = "ttnn.mesh_shard"(%519, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%519) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %521 = "ttnn.to_layout"(%24) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%24) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %522 = "ttnn.from_device"(%521) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%521) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %523 = "ttnn.mesh_shard"(%522, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%522) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %524 = "ttnn.to_layout"(%26) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%26) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %525 = "ttnn.from_device"(%524) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%524) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %526 = "ttnn.mesh_shard"(%525, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%525) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %527 = "ttnn.to_layout"(%35) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%35) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %528 = "ttnn.from_device"(%527) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%527) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %529 = "ttnn.mesh_shard"(%528, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%528) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %530 = "ttnn.to_layout"(%37) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%37) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %531 = "ttnn.from_device"(%530) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%530) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %532 = "ttnn.mesh_shard"(%531, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%531) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %533 = "ttnn.to_layout"(%46) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%46) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %534 = "ttnn.from_device"(%533) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%533) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %535 = "ttnn.mesh_shard"(%534, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%534) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %536 = "ttnn.to_layout"(%48) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%48) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %537 = "ttnn.from_device"(%536) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%536) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %538 = "ttnn.mesh_shard"(%537, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%537) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %539 = "ttnn.to_layout"(%513) <{layout = #ttnn.layout<row_major>}> : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%513) <{force = false}> : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %540 = "ttnn.from_device"(%539) : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%539) <{force = false}> : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %541 = "ttnn.mesh_shard"(%540, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128256xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%540) <{force = false}> : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %542 = "ttnn.to_layout"(%514) <{layout = #ttnn.layout<row_major>}> : (tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%514) <{force = false}> : (tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %543 = "ttnn.from_device"(%542) : (tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%542) <{force = false}> : (tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %544 = "ttnn.mesh_shard"(%543, %1) <{shard_dims = array<i64: -1, 2>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x1x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x128256xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%543) <{force = false}> : (tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        return %517, %520, %523, %526, %529, %532, %535, %538, %541, %544 : tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128256xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x1x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x128256xbf16, #ttnn.buffer_type<system_memory>>>>
      }
    }
  }
}
input 0: device = xla:0, shape torch.Size([128]) and shard spec {replicated}
input 1: device = xla:0, shape torch.Size([1, 128]) and shard spec {replicated}
input 2: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 2 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0791,  0.1982,  0.0928, -0.0488, -0.1318, -0.2119,  0.0471,  0.2295,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 3: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 3 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0022, -0.0092,  0.0094,  0.0027, -0.0072, -0.0029, -0.0015, -0.0018,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 4: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 4 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0486,  0.0708,  0.0170, -0.0243, -0.1235, -0.1123, -0.0933, -0.0522,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 5: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 5 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0099,  0.0069,  0.0079,  0.0128,  0.0036,  0.0089,  0.0055, -0.0050,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 6: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 6 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0156, -0.1123, -0.1484, -0.1128, -0.0540, -0.0371,  0.0737,  0.0791,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 7: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 7 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0055, -0.0099,  0.0272,  0.0189, -0.0014,  0.0098, -0.0119,  0.0033,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 8: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 8 and shape torch.Size([1, 8, 128, 128]): tensor([-0.2139, -0.2988, -0.1260, -0.0457,  0.0356,  0.0403, -0.0269, -0.0972,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 9: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 9 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0045, -0.0027,  0.0211,  0.0121,  0.0044, -0.0535, -0.0464, -0.0280,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 10: device = xla:0, shape torch.Size([1, 1]) and shard spec {replicated}
input 11: device = xla:0, shape torch.Size([128256, 3072]) and shard spec {devices=[2,1]<=[2]}
input 12: device = xla:0, shape torch.Size([1]) and shard spec {replicated}
input 13: device = xla:0, shape torch.Size([64]) and shard spec {replicated}
input 14: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 15: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 16: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 17: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 18: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 19: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 20: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 21: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 22: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 23: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 24: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 25: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 26: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 27: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 28: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 29: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 30: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 31: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 32: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 33: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 34: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 35: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 36: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 37: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 38: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 39: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 40: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 41: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 42: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 43: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 44: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 45: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 46: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 47: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 48: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 49: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 50: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
CPU logit shape:  torch.Size([1, 7, 128256]) XLA logit shape:  torch.Size([1, 1, 128256])
\([32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1x!vhlo.i64_v1>, %arg1: !vhlo.tensor_v1<64x!vhlo.f32_v1>, %arg2: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg3: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg4: !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, %arg5: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, %arg6: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg7: !vhlo.tensor_v1<!vhlo.i64_v1>, %arg8: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg9: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg10: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg11: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg12: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg13: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg14: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg15: !vhlo.tensor_v1<128x!vhlo.i64_v1>, %arg16: !vhlo.tensor_v1<1x128x!vhlo.bf16_v1>, %arg17: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg18: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg19: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg20: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg21: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg23: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg24: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg25: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg26: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg27: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg28: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg29: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg30: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg31: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg32: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg33: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg34: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg35: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg36: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg37: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg38: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg39: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg40: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg41: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg42: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg43: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg44: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg45: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg46: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg47: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg48: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg49: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg50: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg51: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg52: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg53: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : () -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<3.25520843E-4> : tensor<1x1xf32>>}> : () -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %5 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %6 = "vhlo.compare_v1"(%arg0, %0) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.bool_v1>
    %7 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %8 = "vhlo.add_v1"(%arg0, %7) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %9 = "vhlo.select_v1"(%6, %8, %arg0) : (!vhlo.tensor_v1<1x!vhlo.bool_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.i64_v1>
    %11 = "vhlo.convert_v1"(%arg6) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %12 = "vhlo.reshape_v1"(%11) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %13 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %14 = "vhlo.convert_v1"(%13) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.ui32_v1>
    %15 = "vhlo.gather_v2"(%arg5, %14) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3072]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %16 = "vhlo.reshape_v1"(%15) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %17 = "vhlo.convert_v1"(%16) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %18 = "vhlo.power_v1"(%17, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %19 = "vhlo.reduce_v1"(%18, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %20 = "vhlo.multiply_v1"(%19, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %21 = "vhlo.reshape_v1"(%20) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %22 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %23 = "vhlo.add_v1"(%21, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %24 = "vhlo.rsqrt_v2"(%23) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %25 = "vhlo.reshape_v1"(%24) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %26 = "vhlo.broadcast_in_dim_v1"(%25) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %27 = "vhlo.multiply_v1"(%17, %26) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %28 = "vhlo.convert_v1"(%27) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %29 = "vhlo.convert_v1"(%28) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %30 = "vhlo.multiply_v1"(%12, %29) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %31 = "vhlo.convert_v1"(%30) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %32 = "vhlo.reshape_v1"(%31) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %33 = "vhlo.transpose_v1"(%arg2) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %34 = "vhlo.dot_general_v2"(%32, %33) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %35 = "vhlo.reshape_v1"(%34) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %36 = "vhlo.convert_v1"(%35) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %37 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %38 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>
    %39 = "vhlo.convert_v1"(%38) : (!vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %40 = "vhlo.dot_general_v2"(%37, %39) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %41 = "vhlo.reshape_v1"(%40) : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %42 = "vhlo.concatenate_v1"(%41, %41) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %43 = "vhlo.cosine_v2"(%42) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %44 = "vhlo.convert_v1"(%43) : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>
    %45 = "vhlo.reshape_v1"(%44) : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>
    %46 = "vhlo.convert_v1"(%45) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>
    %47 = "vhlo.reshape_v1"(%46) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %48 = "vhlo.broadcast_in_dim_v1"(%47) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %49 = "vhlo.multiply_v1"(%36, %48) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %50 = "vhlo.convert_v1"(%49) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %51 = "vhlo.slice_v1"(%35) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %52 = "vhlo.negate_v1"(%51) : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %53 = "vhlo.slice_v1"(%35) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %54 = "vhlo.concatenate_v1"(%52, %53) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %55 = "vhlo.convert_v1"(%54) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %56 = "vhlo.sine_v2"(%42) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %57 = "vhlo.convert_v1"(%56) : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>
    %58 = "vhlo.reshape_v1"(%57) : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>
    %59 = "vhlo.convert_v1"(%58) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>
    %60 = "vhlo.reshape_v1"(%59) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %61 = "vhlo.broadcast_in_dim_v1"(%60) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %62 = "vhlo.multiply_v1"(%55, %61) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %63 = "vhlo.convert_v1"(%62) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %64 = "vhlo.add_v1"(%50, %63) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %65 = "vhlo.scatter_v2"(%arg8, %10, %64) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %66 = "vhlo.custom_call_v1"(%65) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %67 = "vhlo.transpose_v1"(%arg9) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %68 = "vhlo.dot_general_v2"(%32, %67) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %69 = "vhlo.reshape_v1"(%68) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %70 = "vhlo.scatter_v2"(%arg10, %10, %69) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %71 = "vhlo.custom_call_v1"(%70) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %72 = "vhlo.convert_v1"(%arg21) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %73 = "vhlo.reshape_v1"(%72) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %74 = "vhlo.transpose_v1"(%arg18) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %75 = "vhlo.dot_general_v2"(%32, %74) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %76 = "vhlo.reshape_v1"(%75) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %77 = "vhlo.convert_v1"(%76) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %78 = "vhlo.broadcast_in_dim_v1"(%47) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %79 = "vhlo.multiply_v1"(%77, %78) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %80 = "vhlo.convert_v1"(%79) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %81 = "vhlo.slice_v1"(%76) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %82 = "vhlo.negate_v1"(%81) : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %83 = "vhlo.slice_v1"(%76) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %84 = "vhlo.concatenate_v1"(%82, %83) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %85 = "vhlo.convert_v1"(%84) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %86 = "vhlo.broadcast_in_dim_v1"(%60) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %87 = "vhlo.multiply_v1"(%85, %86) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %88 = "vhlo.convert_v1"(%87) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %89 = "vhlo.add_v1"(%80, %88) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %90 = "vhlo.reshape_v1"(%89) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %91 = "vhlo.broadcast_in_dim_v1"(%65) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %92 = "vhlo.reshape_v1"(%91) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %93 = "vhlo.transpose_v1"(%92) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %94 = "vhlo.reshape_v1"(%93) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %95 = "vhlo.dot_general_v2"(%90, %94) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %96 = "vhlo.reshape_v1"(%95) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %97 = "vhlo.convert_v1"(%96) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %98 = "vhlo.broadcast_in_dim_v1"(%arg17) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %99 = "vhlo.multiply_v1"(%97, %98) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %100 = "vhlo.convert_v1"(%99) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %101 = "vhlo.convert_v1"(%arg16) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.f32_v1>
    %102 = "vhlo.reshape_v1"(%arg15) : (!vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.i64_v1>
    %103 = "vhlo.broadcast_in_dim_v1"(%arg0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.i64_v1>
    %104 = "vhlo.compare_v1"(%102, %103) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<1x128x!vhlo.i64_v1>, !vhlo.tensor_v1<1x128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.bool_v1>
    %105 = "vhlo.convert_v1"(%104) : (!vhlo.tensor_v1<1x128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.f32_v1>
    %106 = "vhlo.multiply_v1"(%101, %105) : (!vhlo.tensor_v1<1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.f32_v1>
    %107 = "vhlo.convert_v1"(%106) : (!vhlo.tensor_v1<1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.bf16_v1>
    %108 = "vhlo.reshape_v1"(%107) : (!vhlo.tensor_v1<1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>
    %109 = "vhlo.broadcast_in_dim_v1"(%108) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %110 = "vhlo.add_v1"(%100, %109) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %111 = "vhlo.convert_v1"(%110) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %112 = "vhlo.reduce_v1"(%111, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.maximum_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %113 = "vhlo.broadcast_in_dim_v1"(%112) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %114 = "vhlo.subtract_v1"(%111, %113) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %115 = "vhlo.exponential_v2"(%114) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %116 = "vhlo.reduce_v1"(%115, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %117 = "vhlo.broadcast_in_dim_v1"(%116) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %118 = "vhlo.divide_v1"(%115, %117) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %119 = "vhlo.convert_v1"(%118) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %120 = "vhlo.reshape_v1"(%119) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %121 = "vhlo.broadcast_in_dim_v1"(%70) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %122 = "vhlo.reshape_v1"(%121) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %123 = "vhlo.dot_general_v2"(%120, %122) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %124 = "vhlo.reshape_v1"(%123) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %125 = "vhlo.transpose_v1"(%arg14) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %126 = "vhlo.dot_general_v2"(%124, %125) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %127 = "vhlo.reshape_v1"(%126) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %128 = "vhlo.add_v1"(%16, %127) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %129 = "vhlo.convert_v1"(%arg19) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %130 = "vhlo.reshape_v1"(%129) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %131 = "vhlo.convert_v1"(%128) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %132 = "vhlo.power_v1"(%131, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %133 = "vhlo.reduce_v1"(%132, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %134 = "vhlo.multiply_v1"(%133, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %135 = "vhlo.reshape_v1"(%134) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %136 = "vhlo.add_v1"(%135, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %137 = "vhlo.rsqrt_v2"(%136) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %138 = "vhlo.reshape_v1"(%137) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %139 = "vhlo.broadcast_in_dim_v1"(%138) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %140 = "vhlo.multiply_v1"(%131, %139) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %141 = "vhlo.convert_v1"(%140) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %142 = "vhlo.convert_v1"(%141) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %143 = "vhlo.multiply_v1"(%130, %142) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %144 = "vhlo.convert_v1"(%143) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %145 = "vhlo.reshape_v1"(%144) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %146 = "vhlo.transpose_v1"(%arg20) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %147 = "vhlo.dot_general_v2"(%145, %146) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %148 = "vhlo.reshape_v1"(%147) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %149 = "vhlo.convert_v1"(%148) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %150 = "vhlo.logistic_v2"(%148) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %151 = "vhlo.convert_v1"(%150) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %152 = "vhlo.multiply_v1"(%149, %151) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %153 = "vhlo.convert_v1"(%152) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %154 = "vhlo.convert_v1"(%153) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %155 = "vhlo.transpose_v1"(%arg13) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %156 = "vhlo.dot_general_v2"(%145, %155) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %157 = "vhlo.reshape_v1"(%156) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %158 = "vhlo.convert_v1"(%157) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %159 = "vhlo.multiply_v1"(%154, %158) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %160 = "vhlo.convert_v1"(%159) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %161 = "vhlo.reshape_v1"(%160) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %162 = "vhlo.transpose_v1"(%arg12) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %163 = "vhlo.dot_general_v2"(%161, %162) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %164 = "vhlo.reshape_v1"(%163) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %165 = "vhlo.add_v1"(%128, %164) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %166 = "vhlo.convert_v1"(%165) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %167 = "vhlo.power_v1"(%166, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %168 = "vhlo.reduce_v1"(%167, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %169 = "vhlo.multiply_v1"(%168, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %170 = "vhlo.reshape_v1"(%169) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %171 = "vhlo.add_v1"(%170, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %172 = "vhlo.rsqrt_v2"(%171) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %173 = "vhlo.reshape_v1"(%172) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %174 = "vhlo.broadcast_in_dim_v1"(%173) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %175 = "vhlo.multiply_v1"(%166, %174) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %176 = "vhlo.convert_v1"(%175) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %177 = "vhlo.convert_v1"(%176) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %178 = "vhlo.multiply_v1"(%73, %177) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %179 = "vhlo.convert_v1"(%178) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %180 = "vhlo.reshape_v1"(%179) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %181 = "vhlo.transpose_v1"(%arg11) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %182 = "vhlo.dot_general_v2"(%180, %181) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %183 = "vhlo.reshape_v1"(%182) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %184 = "vhlo.convert_v1"(%183) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %185 = "vhlo.multiply_v1"(%184, %48) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %186 = "vhlo.convert_v1"(%185) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %187 = "vhlo.slice_v1"(%183) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %188 = "vhlo.negate_v1"(%187) : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %189 = "vhlo.slice_v1"(%183) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %190 = "vhlo.concatenate_v1"(%188, %189) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %191 = "vhlo.convert_v1"(%190) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %192 = "vhlo.multiply_v1"(%191, %61) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %193 = "vhlo.convert_v1"(%192) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %194 = "vhlo.add_v1"(%186, %193) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %195 = "vhlo.scatter_v2"(%arg22, %10, %194) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %196 = "vhlo.custom_call_v1"(%195) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %197 = "vhlo.transpose_v1"(%arg23) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %198 = "vhlo.dot_general_v2"(%180, %197) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %199 = "vhlo.reshape_v1"(%198) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %200 = "vhlo.scatter_v2"(%arg24, %10, %199) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %201 = "vhlo.custom_call_v1"(%200) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %202 = "vhlo.convert_v1"(%arg32) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %203 = "vhlo.reshape_v1"(%202) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %204 = "vhlo.transpose_v1"(%arg29) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %205 = "vhlo.dot_general_v2"(%180, %204) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %206 = "vhlo.reshape_v1"(%205) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %207 = "vhlo.convert_v1"(%206) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %208 = "vhlo.multiply_v1"(%207, %78) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %209 = "vhlo.convert_v1"(%208) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %210 = "vhlo.slice_v1"(%206) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %211 = "vhlo.negate_v1"(%210) : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %212 = "vhlo.slice_v1"(%206) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %213 = "vhlo.concatenate_v1"(%211, %212) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %214 = "vhlo.convert_v1"(%213) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %215 = "vhlo.multiply_v1"(%214, %86) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %216 = "vhlo.convert_v1"(%215) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %217 = "vhlo.add_v1"(%209, %216) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %218 = "vhlo.reshape_v1"(%217) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %219 = "vhlo.broadcast_in_dim_v1"(%195) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %220 = "vhlo.reshape_v1"(%219) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %221 = "vhlo.transpose_v1"(%220) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %222 = "vhlo.reshape_v1"(%221) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %223 = "vhlo.dot_general_v2"(%218, %222) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %224 = "vhlo.reshape_v1"(%223) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %225 = "vhlo.convert_v1"(%224) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %226 = "vhlo.multiply_v1"(%225, %98) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %227 = "vhlo.convert_v1"(%226) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %228 = "vhlo.add_v1"(%227, %109) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %229 = "vhlo.convert_v1"(%228) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %230 = "vhlo.reduce_v1"(%229, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.maximum_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %231 = "vhlo.broadcast_in_dim_v1"(%230) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %232 = "vhlo.subtract_v1"(%229, %231) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %233 = "vhlo.exponential_v2"(%232) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %234 = "vhlo.reduce_v1"(%233, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %235 = "vhlo.broadcast_in_dim_v1"(%234) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %236 = "vhlo.divide_v1"(%233, %235) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %237 = "vhlo.convert_v1"(%236) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %238 = "vhlo.reshape_v1"(%237) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %239 = "vhlo.broadcast_in_dim_v1"(%200) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %240 = "vhlo.reshape_v1"(%239) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %241 = "vhlo.dot_general_v2"(%238, %240) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %242 = "vhlo.reshape_v1"(%241) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %243 = "vhlo.transpose_v1"(%arg28) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %244 = "vhlo.dot_general_v2"(%242, %243) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %245 = "vhlo.reshape_v1"(%244) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %246 = "vhlo.add_v1"(%165, %245) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %247 = "vhlo.convert_v1"(%arg30) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %248 = "vhlo.reshape_v1"(%247) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %249 = "vhlo.convert_v1"(%246) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %250 = "vhlo.power_v1"(%249, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %251 = "vhlo.reduce_v1"(%250, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %252 = "vhlo.multiply_v1"(%251, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %253 = "vhlo.reshape_v1"(%252) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %254 = "vhlo.add_v1"(%253, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %255 = "vhlo.rsqrt_v2"(%254) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %256 = "vhlo.reshape_v1"(%255) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %257 = "vhlo.broadcast_in_dim_v1"(%256) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %258 = "vhlo.multiply_v1"(%249, %257) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %259 = "vhlo.convert_v1"(%258) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %260 = "vhlo.convert_v1"(%259) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %261 = "vhlo.multiply_v1"(%248, %260) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %262 = "vhlo.convert_v1"(%261) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %263 = "vhlo.reshape_v1"(%262) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %264 = "vhlo.transpose_v1"(%arg31) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %265 = "vhlo.dot_general_v2"(%263, %264) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %266 = "vhlo.reshape_v1"(%265) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %267 = "vhlo.convert_v1"(%266) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %268 = "vhlo.logistic_v2"(%266) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %269 = "vhlo.convert_v1"(%268) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %270 = "vhlo.multiply_v1"(%267, %269) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %271 = "vhlo.convert_v1"(%270) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %272 = "vhlo.convert_v1"(%271) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %273 = "vhlo.transpose_v1"(%arg27) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %274 = "vhlo.dot_general_v2"(%263, %273) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %275 = "vhlo.reshape_v1"(%274) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %276 = "vhlo.convert_v1"(%275) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %277 = "vhlo.multiply_v1"(%272, %276) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %278 = "vhlo.convert_v1"(%277) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %279 = "vhlo.reshape_v1"(%278) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %280 = "vhlo.transpose_v1"(%arg26) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %281 = "vhlo.dot_general_v2"(%279, %280) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %282 = "vhlo.reshape_v1"(%281) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %283 = "vhlo.add_v1"(%246, %282) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %284 = "vhlo.convert_v1"(%283) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %285 = "vhlo.power_v1"(%284, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %286 = "vhlo.reduce_v1"(%285, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %287 = "vhlo.multiply_v1"(%286, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %288 = "vhlo.reshape_v1"(%287) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %289 = "vhlo.add_v1"(%288, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %290 = "vhlo.rsqrt_v2"(%289) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %291 = "vhlo.reshape_v1"(%290) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %292 = "vhlo.broadcast_in_dim_v1"(%291) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %293 = "vhlo.multiply_v1"(%284, %292) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %294 = "vhlo.convert_v1"(%293) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %295 = "vhlo.convert_v1"(%294) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %296 = "vhlo.multiply_v1"(%203, %295) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %297 = "vhlo.convert_v1"(%296) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %298 = "vhlo.reshape_v1"(%297) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %299 = "vhlo.transpose_v1"(%arg25) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %300 = "vhlo.dot_general_v2"(%298, %299) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %301 = "vhlo.reshape_v1"(%300) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %302 = "vhlo.convert_v1"(%301) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %303 = "vhlo.multiply_v1"(%302, %48) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %304 = "vhlo.convert_v1"(%303) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %305 = "vhlo.slice_v1"(%301) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %306 = "vhlo.negate_v1"(%305) : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %307 = "vhlo.slice_v1"(%301) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %308 = "vhlo.concatenate_v1"(%306, %307) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %309 = "vhlo.convert_v1"(%308) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %310 = "vhlo.multiply_v1"(%309, %61) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %311 = "vhlo.convert_v1"(%310) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %312 = "vhlo.add_v1"(%304, %311) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %313 = "vhlo.scatter_v2"(%arg33, %10, %312) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %314 = "vhlo.custom_call_v1"(%313) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %315 = "vhlo.transpose_v1"(%arg34) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %316 = "vhlo.dot_general_v2"(%298, %315) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %317 = "vhlo.reshape_v1"(%316) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %318 = "vhlo.scatter_v2"(%arg35, %10, %317) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %319 = "vhlo.custom_call_v1"(%318) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %320 = "vhlo.convert_v1"(%arg43) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %321 = "vhlo.reshape_v1"(%320) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %322 = "vhlo.transpose_v1"(%arg40) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %323 = "vhlo.dot_general_v2"(%298, %322) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %324 = "vhlo.reshape_v1"(%323) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %325 = "vhlo.convert_v1"(%324) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %326 = "vhlo.multiply_v1"(%325, %78) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %327 = "vhlo.convert_v1"(%326) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %328 = "vhlo.slice_v1"(%324) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %329 = "vhlo.negate_v1"(%328) : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %330 = "vhlo.slice_v1"(%324) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %331 = "vhlo.concatenate_v1"(%329, %330) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %332 = "vhlo.convert_v1"(%331) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %333 = "vhlo.multiply_v1"(%332, %86) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %334 = "vhlo.convert_v1"(%333) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %335 = "vhlo.add_v1"(%327, %334) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %336 = "vhlo.reshape_v1"(%335) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %337 = "vhlo.broadcast_in_dim_v1"(%313) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %338 = "vhlo.reshape_v1"(%337) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %339 = "vhlo.transpose_v1"(%338) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %340 = "vhlo.reshape_v1"(%339) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %341 = "vhlo.dot_general_v2"(%336, %340) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %342 = "vhlo.reshape_v1"(%341) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %343 = "vhlo.convert_v1"(%342) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %344 = "vhlo.multiply_v1"(%343, %98) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %345 = "vhlo.convert_v1"(%344) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %346 = "vhlo.add_v1"(%345, %109) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %347 = "vhlo.convert_v1"(%346) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %348 = "vhlo.reduce_v1"(%347, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.maximum_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %349 = "vhlo.broadcast_in_dim_v1"(%348) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %350 = "vhlo.subtract_v1"(%347, %349) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %351 = "vhlo.exponential_v2"(%350) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %352 = "vhlo.reduce_v1"(%351, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %353 = "vhlo.broadcast_in_dim_v1"(%352) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %354 = "vhlo.divide_v1"(%351, %353) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %355 = "vhlo.convert_v1"(%354) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %356 = "vhlo.reshape_v1"(%355) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %357 = "vhlo.broadcast_in_dim_v1"(%318) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %358 = "vhlo.reshape_v1"(%357) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %359 = "vhlo.dot_general_v2"(%356, %358) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %360 = "vhlo.reshape_v1"(%359) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %361 = "vhlo.transpose_v1"(%arg39) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %362 = "vhlo.dot_general_v2"(%360, %361) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %363 = "vhlo.reshape_v1"(%362) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %364 = "vhlo.add_v1"(%283, %363) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %365 = "vhlo.convert_v1"(%arg41) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %366 = "vhlo.reshape_v1"(%365) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %367 = "vhlo.convert_v1"(%364) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %368 = "vhlo.power_v1"(%367, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %369 = "vhlo.reduce_v1"(%368, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %370 = "vhlo.multiply_v1"(%369, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %371 = "vhlo.reshape_v1"(%370) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %372 = "vhlo.add_v1"(%371, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %373 = "vhlo.rsqrt_v2"(%372) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %374 = "vhlo.reshape_v1"(%373) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %375 = "vhlo.broadcast_in_dim_v1"(%374) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %376 = "vhlo.multiply_v1"(%367, %375) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %377 = "vhlo.convert_v1"(%376) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %378 = "vhlo.convert_v1"(%377) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %379 = "vhlo.multiply_v1"(%366, %378) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %380 = "vhlo.convert_v1"(%379) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %381 = "vhlo.reshape_v1"(%380) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %382 = "vhlo.transpose_v1"(%arg42) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %383 = "vhlo.dot_general_v2"(%381, %382) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %384 = "vhlo.reshape_v1"(%383) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %385 = "vhlo.convert_v1"(%384) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %386 = "vhlo.logistic_v2"(%384) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %387 = "vhlo.convert_v1"(%386) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %388 = "vhlo.multiply_v1"(%385, %387) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %389 = "vhlo.convert_v1"(%388) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %390 = "vhlo.convert_v1"(%389) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %391 = "vhlo.transpose_v1"(%arg38) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %392 = "vhlo.dot_general_v2"(%381, %391) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %393 = "vhlo.reshape_v1"(%392) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %394 = "vhlo.convert_v1"(%393) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %395 = "vhlo.multiply_v1"(%390, %394) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %396 = "vhlo.convert_v1"(%395) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %397 = "vhlo.reshape_v1"(%396) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %398 = "vhlo.transpose_v1"(%arg37) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %399 = "vhlo.dot_general_v2"(%397, %398) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %400 = "vhlo.reshape_v1"(%399) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %401 = "vhlo.add_v1"(%364, %400) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %402 = "vhlo.convert_v1"(%401) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %403 = "vhlo.power_v1"(%402, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %404 = "vhlo.reduce_v1"(%403, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %405 = "vhlo.multiply_v1"(%404, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %406 = "vhlo.reshape_v1"(%405) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %407 = "vhlo.add_v1"(%406, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %408 = "vhlo.rsqrt_v2"(%407) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %409 = "vhlo.reshape_v1"(%408) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %410 = "vhlo.broadcast_in_dim_v1"(%409) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %411 = "vhlo.multiply_v1"(%402, %410) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %412 = "vhlo.convert_v1"(%411) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %413 = "vhlo.convert_v1"(%412) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %414 = "vhlo.multiply_v1"(%321, %413) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %415 = "vhlo.convert_v1"(%414) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %416 = "vhlo.reshape_v1"(%415) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %417 = "vhlo.transpose_v1"(%arg36) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %418 = "vhlo.dot_general_v2"(%416, %417) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %419 = "vhlo.reshape_v1"(%418) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %420 = "vhlo.convert_v1"(%419) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %421 = "vhlo.multiply_v1"(%420, %48) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %422 = "vhlo.convert_v1"(%421) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %423 = "vhlo.slice_v1"(%419) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %424 = "vhlo.negate_v1"(%423) : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %425 = "vhlo.slice_v1"(%419) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %426 = "vhlo.concatenate_v1"(%424, %425) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %427 = "vhlo.convert_v1"(%426) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %428 = "vhlo.multiply_v1"(%427, %61) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %429 = "vhlo.convert_v1"(%428) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %430 = "vhlo.add_v1"(%422, %429) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %431 = "vhlo.scatter_v2"(%arg44, %10, %430) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %432 = "vhlo.custom_call_v1"(%431) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %433 = "vhlo.transpose_v1"(%arg45) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %434 = "vhlo.dot_general_v2"(%416, %433) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %435 = "vhlo.reshape_v1"(%434) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %436 = "vhlo.scatter_v2"(%arg46, %10, %435) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg55: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg55) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %437 = "vhlo.custom_call_v1"(%436) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %438 = "vhlo.convert_v1"(%arg53) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %439 = "vhlo.reshape_v1"(%438) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %440 = "vhlo.transpose_v1"(%arg50) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %441 = "vhlo.dot_general_v2"(%416, %440) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %442 = "vhlo.reshape_v1"(%441) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %443 = "vhlo.convert_v1"(%442) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %444 = "vhlo.multiply_v1"(%443, %78) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %445 = "vhlo.convert_v1"(%444) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %446 = "vhlo.slice_v1"(%442) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %447 = "vhlo.negate_v1"(%446) : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %448 = "vhlo.slice_v1"(%442) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %449 = "vhlo.concatenate_v1"(%447, %448) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %450 = "vhlo.convert_v1"(%449) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %451 = "vhlo.multiply_v1"(%450, %86) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %452 = "vhlo.convert_v1"(%451) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %453 = "vhlo.add_v1"(%445, %452) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %454 = "vhlo.reshape_v1"(%453) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %455 = "vhlo.broadcast_in_dim_v1"(%431) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %456 = "vhlo.reshape_v1"(%455) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %457 = "vhlo.transpose_v1"(%456) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %458 = "vhlo.reshape_v1"(%457) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %459 = "vhlo.dot_general_v2"(%454, %458) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %460 = "vhlo.reshape_v1"(%459) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %461 = "vhlo.convert_v1"(%460) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %462 = "vhlo.multiply_v1"(%461, %98) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %463 = "vhlo.convert_v1"(%462) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %464 = "vhlo.add_v1"(%463, %109) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %465 = "vhlo.convert_v1"(%464) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %466 = "vhlo.reduce_v1"(%465, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.maximum_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %467 = "vhlo.broadcast_in_dim_v1"(%466) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %468 = "vhlo.subtract_v1"(%465, %467) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %469 = "vhlo.exponential_v2"(%468) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %470 = "vhlo.reduce_v1"(%469, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %471 = "vhlo.broadcast_in_dim_v1"(%470) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %472 = "vhlo.divide_v1"(%469, %471) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %473 = "vhlo.convert_v1"(%472) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %474 = "vhlo.reshape_v1"(%473) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %475 = "vhlo.broadcast_in_dim_v1"(%436) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %476 = "vhlo.reshape_v1"(%475) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %477 = "vhlo.dot_general_v2"(%474, %476) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %478 = "vhlo.reshape_v1"(%477) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %479 = "vhlo.transpose_v1"(%arg49) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %480 = "vhlo.dot_general_v2"(%478, %479) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %481 = "vhlo.reshape_v1"(%480) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %482 = "vhlo.add_v1"(%401, %481) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %483 = "vhlo.convert_v1"(%arg51) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %484 = "vhlo.reshape_v1"(%483) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %485 = "vhlo.convert_v1"(%482) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %486 = "vhlo.power_v1"(%485, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %487 = "vhlo.reduce_v1"(%486, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %488 = "vhlo.multiply_v1"(%487, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %489 = "vhlo.reshape_v1"(%488) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %490 = "vhlo.add_v1"(%489, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %491 = "vhlo.rsqrt_v2"(%490) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %492 = "vhlo.reshape_v1"(%491) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %493 = "vhlo.broadcast_in_dim_v1"(%492) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %494 = "vhlo.multiply_v1"(%485, %493) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %495 = "vhlo.convert_v1"(%494) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %496 = "vhlo.convert_v1"(%495) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %497 = "vhlo.multiply_v1"(%484, %496) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %498 = "vhlo.convert_v1"(%497) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %499 = "vhlo.reshape_v1"(%498) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %500 = "vhlo.transpose_v1"(%arg52) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %501 = "vhlo.dot_general_v2"(%499, %500) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %502 = "vhlo.reshape_v1"(%501) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %503 = "vhlo.convert_v1"(%502) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %504 = "vhlo.logistic_v2"(%502) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %505 = "vhlo.convert_v1"(%504) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %506 = "vhlo.multiply_v1"(%503, %505) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %507 = "vhlo.convert_v1"(%506) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %508 = "vhlo.convert_v1"(%507) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %509 = "vhlo.transpose_v1"(%arg48) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %510 = "vhlo.dot_general_v2"(%499, %509) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %511 = "vhlo.reshape_v1"(%510) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %512 = "vhlo.convert_v1"(%511) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %513 = "vhlo.multiply_v1"(%508, %512) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %514 = "vhlo.convert_v1"(%513) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %515 = "vhlo.reshape_v1"(%514) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %516 = "vhlo.transpose_v1"(%arg47) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %517 = "vhlo.dot_general_v2"(%515, %516) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %518 = "vhlo.reshape_v1"(%517) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %519 = "vhlo.add_v1"(%482, %518) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %520 = "vhlo.convert_v1"(%519) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %521 = "vhlo.power_v1"(%520, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %522 = "vhlo.reduce_v1"(%521, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg54: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg55: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %538 = "vhlo.add_v1"(%arg54, %arg55) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%538) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %523 = "vhlo.multiply_v1"(%522, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %524 = "vhlo.reshape_v1"(%523) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %525 = "vhlo.add_v1"(%524, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %526 = "vhlo.rsqrt_v2"(%525) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %527 = "vhlo.reshape_v1"(%526) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %528 = "vhlo.broadcast_in_dim_v1"(%527) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %529 = "vhlo.multiply_v1"(%520, %528) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %530 = "vhlo.convert_v1"(%529) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %531 = "vhlo.convert_v1"(%530) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %532 = "vhlo.multiply_v1"(%439, %531) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %533 = "vhlo.convert_v1"(%532) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %534 = "vhlo.reshape_v1"(%533) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %535 = "vhlo.transpose_v1"(%arg5) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,128256]{0,1}">} : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>
    %536 = "vhlo.dot_general_v2"(%534, %535) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>
    %537 = "vhlo.reshape_v1"(%536) : (!vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1>
    "vhlo.return_v1"(%66, %71, %196, %201, %314, %319, %432, %437, %536, %537) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}
module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<1xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg2: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg3: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg4: tensor<1x1xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg5: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg6: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg7: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg8: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg9: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg10: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg11: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg12: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg13: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg14: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg15: tensor<128xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg16: tensor<1x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg17: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg18: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg19: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg20: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg21: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg22: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg23: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg24: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg25: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg26: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg27: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg28: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg29: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg30: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg31: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg32: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg33: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg34: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg35: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg36: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg37: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg38: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg39: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg40: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg41: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg42: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg43: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg44: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg45: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg46: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg47: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg48: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg49: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg50: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg51: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg52: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg53: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) {
    %c = stablehlo.constant dense<0> : tensor<1xi64>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x1xf32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32>
    %1 = stablehlo.compare  LT, %arg0, %c : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1>
    %2 = stablehlo.reshape %arg7 : (tensor<i64>) -> tensor<1xi64>
    %3 = stablehlo.add %arg0, %2 : tensor<1xi64>
    %4 = stablehlo.select %1, %3, %arg0 : tensor<1xi1>, tensor<1xi64>
    %5 = stablehlo.reshape %4 : (tensor<1xi64>) -> tensor<1x1xi64>
    %6 = stablehlo.convert %arg6 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %7 = stablehlo.reshape %6 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %8 = stablehlo.convert %arg4 : (tensor<1x1xi64>) -> tensor<1x1xui32>
    %9 = stablehlo.reshape %8 : (tensor<1x1xui32>) -> tensor<1xui32>
    %10 = "stablehlo.gather"(%arg5, %9) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16>
    %11 = stablehlo.reshape %10 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %12 = stablehlo.convert %11 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %13 = stablehlo.power %12, %0 : tensor<1x1x3072xf32>
    %14 = stablehlo.reduce(%13 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %15 = stablehlo.multiply %14, %cst_1 : tensor<1x1xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %17 = stablehlo.reshape %arg3 : (tensor<f32>) -> tensor<1x1x1xf32>
    %18 = stablehlo.add %16, %17 : tensor<1x1x1xf32>
    %19 = stablehlo.rsqrt %18 : tensor<1x1x1xf32>
    %20 = stablehlo.reshape %19 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %21 = stablehlo.broadcast_in_dim %20, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %22 = stablehlo.multiply %12, %21 : tensor<1x1x3072xf32>
    %23 = stablehlo.convert %22 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %24 = stablehlo.convert %23 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %25 = stablehlo.multiply %7, %24 : tensor<1x1x3072xf32>
    %26 = stablehlo.convert %25 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %27 = stablehlo.reshape %26 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %28 = stablehlo.transpose %arg2, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %29 = stablehlo.dot_general %27, %28, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %30 = stablehlo.reshape %29 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %31 = stablehlo.convert %30 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %32 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x64x1xf32>
    %33 = stablehlo.convert %arg0 : (tensor<1xi64>) -> tensor<1xf32>
    %34 = stablehlo.reshape %33 : (tensor<1xf32>) -> tensor<1x1x1xf32>
    %35 = stablehlo.dot_general %32, %34, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32>
    %36 = stablehlo.reshape %35 : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32>
    %37 = stablehlo.concatenate %36, %36, dim = 2 : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32>
    %38 = stablehlo.cosine %37 : tensor<1x1x128xf32>
    %39 = stablehlo.convert %38 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
    %40 = stablehlo.convert %39 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
    %41 = stablehlo.broadcast_in_dim %40, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32>
    %42 = stablehlo.multiply %31, %41 : tensor<1x8x1x128xf32>
    %43 = stablehlo.convert %42 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %44 = stablehlo.slice %30 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %45 = stablehlo.negate %44 : tensor<1x8x1x64xbf16>
    %46 = stablehlo.slice %30 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %47 = stablehlo.concatenate %45, %46, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %48 = stablehlo.convert %47 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %49 = stablehlo.sine %37 : tensor<1x1x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32>
    %53 = stablehlo.multiply %48, %52 : tensor<1x8x1x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %55 = stablehlo.add %43, %54 : tensor<1x8x1x128xbf16>
    %56 = "stablehlo.scatter"(%arg8, %5, %55) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %57 = sdy.sharding_constraint %56 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %58 = stablehlo.transpose %arg9, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %59 = stablehlo.dot_general %27, %58, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %61 = "stablehlo.scatter"(%arg10, %5, %60) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %62 = sdy.sharding_constraint %61 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %63 = stablehlo.convert %arg21 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %64 = stablehlo.reshape %63 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %65 = stablehlo.transpose %arg18, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %66 = stablehlo.dot_general %27, %65, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %68 = stablehlo.convert %67 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %69 = stablehlo.broadcast_in_dim %40, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32>
    %70 = stablehlo.multiply %68, %69 : tensor<1x24x1x128xf32>
    %71 = stablehlo.convert %70 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %72 = stablehlo.slice %67 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %73 = stablehlo.negate %72 : tensor<1x24x1x64xbf16>
    %74 = stablehlo.slice %67 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %75 = stablehlo.concatenate %73, %74, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %76 = stablehlo.convert %75 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %77 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32>
    %78 = stablehlo.multiply %76, %77 : tensor<1x24x1x128xf32>
    %79 = stablehlo.convert %78 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %80 = stablehlo.add %71, %79 : tensor<1x24x1x128xbf16>
    %81 = stablehlo.reshape %80 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %82 = stablehlo.broadcast_in_dim %56, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %83 = stablehlo.reshape %82 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %84 = stablehlo.transpose %83, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %85 = stablehlo.reshape %84 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %86 = stablehlo.dot_general %81, %85, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %88 = stablehlo.reshape %87 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %89 = stablehlo.broadcast_in_dim %arg17, dims = [] : (tensor<f32>) -> tensor<1x24x1x128xf32>
    %90 = stablehlo.multiply %88, %89 : tensor<1x24x1x128xf32>
    %91 = stablehlo.convert %90 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %92 = stablehlo.convert %arg16 : (tensor<1x128xbf16>) -> tensor<1x128xf32>
    %93 = stablehlo.reshape %arg15 : (tensor<128xi64>) -> tensor<1x128xi64>
    %94 = stablehlo.broadcast_in_dim %arg0, dims = [0] : (tensor<1xi64>) -> tensor<1x128xi64>
    %95 = stablehlo.compare  GT, %93, %94 : (tensor<1x128xi64>, tensor<1x128xi64>) -> tensor<1x128xi1>
    %96 = stablehlo.convert %95 : (tensor<1x128xi1>) -> tensor<1x128xf32>
    %97 = stablehlo.multiply %92, %96 : tensor<1x128xf32>
    %98 = stablehlo.convert %97 : (tensor<1x128xf32>) -> tensor<1x128xbf16>
    %99 = stablehlo.reshape %98 : (tensor<1x128xbf16>) -> tensor<1x1x128xbf16>
    %100 = stablehlo.broadcast_in_dim %99, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x24x1x128xbf16>
    %101 = stablehlo.add %91, %100 : tensor<1x24x1x128xbf16>
    %102 = stablehlo.convert %101 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %103 = stablehlo.reduce(%102 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %105 = stablehlo.subtract %102, %104 : tensor<1x24x1x128xf32>
    %106 = stablehlo.exponential %105 : tensor<1x24x1x128xf32>
    %107 = stablehlo.reduce(%106 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %108 = stablehlo.broadcast_in_dim %107, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %109 = stablehlo.divide %106, %108 : tensor<1x24x1x128xf32>
    %110 = stablehlo.convert %109 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %111 = stablehlo.reshape %110 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %112 = stablehlo.broadcast_in_dim %61, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %113 = stablehlo.reshape %112 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %114 = stablehlo.dot_general %111, %113, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %115 = stablehlo.reshape %114 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %116 = stablehlo.transpose %arg14, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %117 = stablehlo.dot_general %115, %116, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %118 = stablehlo.reshape %117 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %119 = stablehlo.add %11, %118 : tensor<1x1x3072xbf16>
    %120 = stablehlo.convert %arg19 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %121 = stablehlo.reshape %120 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %122 = stablehlo.convert %119 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %123 = stablehlo.power %122, %0 : tensor<1x1x3072xf32>
    %124 = stablehlo.reduce(%123 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %125 = stablehlo.multiply %124, %cst_1 : tensor<1x1xf32>
    %126 = stablehlo.reshape %125 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %127 = stablehlo.add %126, %17 : tensor<1x1x1xf32>
    %128 = stablehlo.rsqrt %127 : tensor<1x1x1xf32>
    %129 = stablehlo.reshape %128 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %131 = stablehlo.multiply %122, %130 : tensor<1x1x3072xf32>
    %132 = stablehlo.convert %131 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %133 = stablehlo.convert %132 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %134 = stablehlo.multiply %121, %133 : tensor<1x1x3072xf32>
    %135 = stablehlo.convert %134 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %137 = stablehlo.transpose %arg20, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %138 = stablehlo.dot_general %136, %137, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %139 = stablehlo.reshape %138 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %140 = stablehlo.convert %139 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %141 = stablehlo.logistic %139 : tensor<1x1x8192xbf16>
    %142 = stablehlo.convert %141 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %143 = stablehlo.multiply %140, %142 : tensor<1x1x8192xf32>
    %144 = stablehlo.convert %143 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %145 = stablehlo.convert %144 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %146 = stablehlo.transpose %arg13, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %147 = stablehlo.dot_general %136, %146, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %150 = stablehlo.multiply %145, %149 : tensor<1x1x8192xf32>
    %151 = stablehlo.convert %150 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %152 = stablehlo.reshape %151 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %153 = stablehlo.transpose %arg12, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %154 = stablehlo.dot_general %152, %153, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %155 = stablehlo.reshape %154 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %156 = stablehlo.add %119, %155 : tensor<1x1x3072xbf16>
    %157 = stablehlo.convert %156 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %158 = stablehlo.power %157, %0 : tensor<1x1x3072xf32>
    %159 = stablehlo.reduce(%158 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %160 = stablehlo.multiply %159, %cst_1 : tensor<1x1xf32>
    %161 = stablehlo.reshape %160 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %162 = stablehlo.add %161, %17 : tensor<1x1x1xf32>
    %163 = stablehlo.rsqrt %162 : tensor<1x1x1xf32>
    %164 = stablehlo.reshape %163 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %166 = stablehlo.multiply %157, %165 : tensor<1x1x3072xf32>
    %167 = stablehlo.convert %166 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %168 = stablehlo.convert %167 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %169 = stablehlo.multiply %64, %168 : tensor<1x1x3072xf32>
    %170 = stablehlo.convert %169 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %171 = stablehlo.reshape %170 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %172 = stablehlo.transpose %arg11, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %173 = stablehlo.dot_general %171, %172, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %174 = stablehlo.reshape %173 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %175 = stablehlo.convert %174 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %176 = stablehlo.multiply %175, %41 : tensor<1x8x1x128xf32>
    %177 = stablehlo.convert %176 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %178 = stablehlo.slice %174 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %179 = stablehlo.negate %178 : tensor<1x8x1x64xbf16>
    %180 = stablehlo.slice %174 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %181 = stablehlo.concatenate %179, %180, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %182 = stablehlo.convert %181 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %183 = stablehlo.multiply %182, %52 : tensor<1x8x1x128xf32>
    %184 = stablehlo.convert %183 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %185 = stablehlo.add %177, %184 : tensor<1x8x1x128xbf16>
    %186 = "stablehlo.scatter"(%arg22, %5, %185) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %187 = sdy.sharding_constraint %186 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %188 = stablehlo.transpose %arg23, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %189 = stablehlo.dot_general %171, %188, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %190 = stablehlo.reshape %189 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %191 = "stablehlo.scatter"(%arg24, %5, %190) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %192 = sdy.sharding_constraint %191 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %193 = stablehlo.convert %arg32 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %194 = stablehlo.reshape %193 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %195 = stablehlo.transpose %arg29, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %196 = stablehlo.dot_general %171, %195, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %197 = stablehlo.reshape %196 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %198 = stablehlo.convert %197 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %199 = stablehlo.multiply %198, %69 : tensor<1x24x1x128xf32>
    %200 = stablehlo.convert %199 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %201 = stablehlo.slice %197 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %202 = stablehlo.negate %201 : tensor<1x24x1x64xbf16>
    %203 = stablehlo.slice %197 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %204 = stablehlo.concatenate %202, %203, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %205 = stablehlo.convert %204 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %206 = stablehlo.multiply %205, %77 : tensor<1x24x1x128xf32>
    %207 = stablehlo.convert %206 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %208 = stablehlo.add %200, %207 : tensor<1x24x1x128xbf16>
    %209 = stablehlo.reshape %208 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %210 = stablehlo.broadcast_in_dim %186, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %211 = stablehlo.reshape %210 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %212 = stablehlo.transpose %211, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %213 = stablehlo.reshape %212 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %214 = stablehlo.dot_general %209, %213, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %215 = stablehlo.convert %214 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %216 = stablehlo.reshape %215 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %217 = stablehlo.multiply %216, %89 : tensor<1x24x1x128xf32>
    %218 = stablehlo.convert %217 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %219 = stablehlo.add %218, %100 : tensor<1x24x1x128xbf16>
    %220 = stablehlo.convert %219 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %221 = stablehlo.reduce(%220 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %222 = stablehlo.broadcast_in_dim %221, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %223 = stablehlo.subtract %220, %222 : tensor<1x24x1x128xf32>
    %224 = stablehlo.exponential %223 : tensor<1x24x1x128xf32>
    %225 = stablehlo.reduce(%224 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %226 = stablehlo.broadcast_in_dim %225, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %227 = stablehlo.divide %224, %226 : tensor<1x24x1x128xf32>
    %228 = stablehlo.convert %227 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %229 = stablehlo.reshape %228 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %230 = stablehlo.broadcast_in_dim %191, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %231 = stablehlo.reshape %230 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %232 = stablehlo.dot_general %229, %231, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %233 = stablehlo.reshape %232 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %234 = stablehlo.transpose %arg28, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %235 = stablehlo.dot_general %233, %234, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %236 = stablehlo.reshape %235 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %237 = stablehlo.add %156, %236 : tensor<1x1x3072xbf16>
    %238 = stablehlo.convert %arg30 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %239 = stablehlo.reshape %238 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %240 = stablehlo.convert %237 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %241 = stablehlo.power %240, %0 : tensor<1x1x3072xf32>
    %242 = stablehlo.reduce(%241 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %243 = stablehlo.multiply %242, %cst_1 : tensor<1x1xf32>
    %244 = stablehlo.reshape %243 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %245 = stablehlo.add %244, %17 : tensor<1x1x1xf32>
    %246 = stablehlo.rsqrt %245 : tensor<1x1x1xf32>
    %247 = stablehlo.reshape %246 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %248 = stablehlo.broadcast_in_dim %247, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %249 = stablehlo.multiply %240, %248 : tensor<1x1x3072xf32>
    %250 = stablehlo.convert %249 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %251 = stablehlo.convert %250 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %252 = stablehlo.multiply %239, %251 : tensor<1x1x3072xf32>
    %253 = stablehlo.convert %252 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %254 = stablehlo.reshape %253 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %255 = stablehlo.transpose %arg31, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %256 = stablehlo.dot_general %254, %255, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %257 = stablehlo.reshape %256 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %258 = stablehlo.convert %257 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %259 = stablehlo.logistic %257 : tensor<1x1x8192xbf16>
    %260 = stablehlo.convert %259 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %261 = stablehlo.multiply %258, %260 : tensor<1x1x8192xf32>
    %262 = stablehlo.convert %261 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %263 = stablehlo.convert %262 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %264 = stablehlo.transpose %arg27, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %265 = stablehlo.dot_general %254, %264, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %266 = stablehlo.convert %265 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %267 = stablehlo.reshape %266 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %268 = stablehlo.multiply %263, %267 : tensor<1x1x8192xf32>
    %269 = stablehlo.convert %268 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %270 = stablehlo.reshape %269 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %271 = stablehlo.transpose %arg26, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %272 = stablehlo.dot_general %270, %271, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %273 = stablehlo.reshape %272 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %274 = stablehlo.add %237, %273 : tensor<1x1x3072xbf16>
    %275 = stablehlo.convert %274 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %276 = stablehlo.power %275, %0 : tensor<1x1x3072xf32>
    %277 = stablehlo.reduce(%276 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %278 = stablehlo.multiply %277, %cst_1 : tensor<1x1xf32>
    %279 = stablehlo.reshape %278 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %280 = stablehlo.add %279, %17 : tensor<1x1x1xf32>
    %281 = stablehlo.rsqrt %280 : tensor<1x1x1xf32>
    %282 = stablehlo.reshape %281 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %283 = stablehlo.broadcast_in_dim %282, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %284 = stablehlo.multiply %275, %283 : tensor<1x1x3072xf32>
    %285 = stablehlo.convert %284 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %286 = stablehlo.convert %285 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %287 = stablehlo.multiply %194, %286 : tensor<1x1x3072xf32>
    %288 = stablehlo.convert %287 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %289 = stablehlo.reshape %288 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %290 = stablehlo.transpose %arg25, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %291 = stablehlo.dot_general %289, %290, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %292 = stablehlo.reshape %291 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %293 = stablehlo.convert %292 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %294 = stablehlo.multiply %293, %41 : tensor<1x8x1x128xf32>
    %295 = stablehlo.convert %294 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %296 = stablehlo.slice %292 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %297 = stablehlo.negate %296 : tensor<1x8x1x64xbf16>
    %298 = stablehlo.slice %292 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %299 = stablehlo.concatenate %297, %298, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %300 = stablehlo.convert %299 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %301 = stablehlo.multiply %300, %52 : tensor<1x8x1x128xf32>
    %302 = stablehlo.convert %301 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %303 = stablehlo.add %295, %302 : tensor<1x8x1x128xbf16>
    %304 = "stablehlo.scatter"(%arg33, %5, %303) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %305 = sdy.sharding_constraint %304 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %306 = stablehlo.transpose %arg34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %307 = stablehlo.dot_general %289, %306, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %308 = stablehlo.reshape %307 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %309 = "stablehlo.scatter"(%arg35, %5, %308) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %310 = sdy.sharding_constraint %309 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %311 = stablehlo.convert %arg43 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %312 = stablehlo.reshape %311 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %313 = stablehlo.transpose %arg40, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %314 = stablehlo.dot_general %289, %313, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %315 = stablehlo.reshape %314 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %316 = stablehlo.convert %315 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %317 = stablehlo.multiply %316, %69 : tensor<1x24x1x128xf32>
    %318 = stablehlo.convert %317 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %319 = stablehlo.slice %315 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %320 = stablehlo.negate %319 : tensor<1x24x1x64xbf16>
    %321 = stablehlo.slice %315 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %322 = stablehlo.concatenate %320, %321, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %323 = stablehlo.convert %322 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %324 = stablehlo.multiply %323, %77 : tensor<1x24x1x128xf32>
    %325 = stablehlo.convert %324 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %326 = stablehlo.add %318, %325 : tensor<1x24x1x128xbf16>
    %327 = stablehlo.reshape %326 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %328 = stablehlo.broadcast_in_dim %304, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %329 = stablehlo.reshape %328 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %330 = stablehlo.transpose %329, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %331 = stablehlo.reshape %330 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %332 = stablehlo.dot_general %327, %331, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %333 = stablehlo.convert %332 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %334 = stablehlo.reshape %333 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %335 = stablehlo.multiply %334, %89 : tensor<1x24x1x128xf32>
    %336 = stablehlo.convert %335 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %337 = stablehlo.add %336, %100 : tensor<1x24x1x128xbf16>
    %338 = stablehlo.convert %337 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %339 = stablehlo.reduce(%338 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %340 = stablehlo.broadcast_in_dim %339, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %341 = stablehlo.subtract %338, %340 : tensor<1x24x1x128xf32>
    %342 = stablehlo.exponential %341 : tensor<1x24x1x128xf32>
    %343 = stablehlo.reduce(%342 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %344 = stablehlo.broadcast_in_dim %343, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %345 = stablehlo.divide %342, %344 : tensor<1x24x1x128xf32>
    %346 = stablehlo.convert %345 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %347 = stablehlo.reshape %346 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %348 = stablehlo.broadcast_in_dim %309, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %349 = stablehlo.reshape %348 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %350 = stablehlo.dot_general %347, %349, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %351 = stablehlo.reshape %350 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %352 = stablehlo.transpose %arg39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %353 = stablehlo.dot_general %351, %352, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %354 = stablehlo.reshape %353 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %355 = stablehlo.add %274, %354 : tensor<1x1x3072xbf16>
    %356 = stablehlo.convert %arg41 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %357 = stablehlo.reshape %356 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %358 = stablehlo.convert %355 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %359 = stablehlo.power %358, %0 : tensor<1x1x3072xf32>
    %360 = stablehlo.reduce(%359 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %361 = stablehlo.multiply %360, %cst_1 : tensor<1x1xf32>
    %362 = stablehlo.reshape %361 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %363 = stablehlo.add %362, %17 : tensor<1x1x1xf32>
    %364 = stablehlo.rsqrt %363 : tensor<1x1x1xf32>
    %365 = stablehlo.reshape %364 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %366 = stablehlo.broadcast_in_dim %365, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %367 = stablehlo.multiply %358, %366 : tensor<1x1x3072xf32>
    %368 = stablehlo.convert %367 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %369 = stablehlo.convert %368 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %370 = stablehlo.multiply %357, %369 : tensor<1x1x3072xf32>
    %371 = stablehlo.convert %370 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %372 = stablehlo.reshape %371 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %373 = stablehlo.transpose %arg42, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %374 = stablehlo.dot_general %372, %373, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %375 = stablehlo.reshape %374 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %376 = stablehlo.convert %375 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %377 = stablehlo.logistic %375 : tensor<1x1x8192xbf16>
    %378 = stablehlo.convert %377 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %379 = stablehlo.multiply %376, %378 : tensor<1x1x8192xf32>
    %380 = stablehlo.convert %379 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %381 = stablehlo.convert %380 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %382 = stablehlo.transpose %arg38, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %383 = stablehlo.dot_general %372, %382, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %384 = stablehlo.convert %383 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %385 = stablehlo.reshape %384 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %386 = stablehlo.multiply %381, %385 : tensor<1x1x8192xf32>
    %387 = stablehlo.convert %386 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %388 = stablehlo.reshape %387 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %389 = stablehlo.transpose %arg37, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %390 = stablehlo.dot_general %388, %389, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %391 = stablehlo.reshape %390 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %392 = stablehlo.add %355, %391 : tensor<1x1x3072xbf16>
    %393 = stablehlo.convert %392 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %394 = stablehlo.power %393, %0 : tensor<1x1x3072xf32>
    %395 = stablehlo.reduce(%394 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %396 = stablehlo.multiply %395, %cst_1 : tensor<1x1xf32>
    %397 = stablehlo.reshape %396 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %398 = stablehlo.add %397, %17 : tensor<1x1x1xf32>
    %399 = stablehlo.rsqrt %398 : tensor<1x1x1xf32>
    %400 = stablehlo.reshape %399 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %401 = stablehlo.broadcast_in_dim %400, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %402 = stablehlo.multiply %393, %401 : tensor<1x1x3072xf32>
    %403 = stablehlo.convert %402 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %404 = stablehlo.convert %403 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %405 = stablehlo.multiply %312, %404 : tensor<1x1x3072xf32>
    %406 = stablehlo.convert %405 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %407 = stablehlo.reshape %406 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %408 = stablehlo.transpose %arg36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %409 = stablehlo.dot_general %407, %408, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %410 = stablehlo.reshape %409 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %411 = stablehlo.convert %410 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %412 = stablehlo.multiply %411, %41 : tensor<1x8x1x128xf32>
    %413 = stablehlo.convert %412 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %414 = stablehlo.slice %410 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %415 = stablehlo.negate %414 : tensor<1x8x1x64xbf16>
    %416 = stablehlo.slice %410 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %417 = stablehlo.concatenate %415, %416, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %418 = stablehlo.convert %417 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %419 = stablehlo.multiply %418, %52 : tensor<1x8x1x128xf32>
    %420 = stablehlo.convert %419 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %421 = stablehlo.add %413, %420 : tensor<1x8x1x128xbf16>
    %422 = "stablehlo.scatter"(%arg44, %5, %421) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %423 = sdy.sharding_constraint %422 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %424 = stablehlo.transpose %arg45, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %425 = stablehlo.dot_general %407, %424, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %426 = stablehlo.reshape %425 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %427 = "stablehlo.scatter"(%arg46, %5, %426) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %428 = sdy.sharding_constraint %427 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %429 = stablehlo.convert %arg53 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %430 = stablehlo.reshape %429 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %431 = stablehlo.transpose %arg50, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %432 = stablehlo.dot_general %407, %431, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %433 = stablehlo.reshape %432 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %434 = stablehlo.convert %433 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %435 = stablehlo.multiply %434, %69 : tensor<1x24x1x128xf32>
    %436 = stablehlo.convert %435 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %437 = stablehlo.slice %433 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %438 = stablehlo.negate %437 : tensor<1x24x1x64xbf16>
    %439 = stablehlo.slice %433 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %440 = stablehlo.concatenate %438, %439, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %441 = stablehlo.convert %440 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %442 = stablehlo.multiply %441, %77 : tensor<1x24x1x128xf32>
    %443 = stablehlo.convert %442 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %444 = stablehlo.add %436, %443 : tensor<1x24x1x128xbf16>
    %445 = stablehlo.reshape %444 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %446 = stablehlo.broadcast_in_dim %422, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %447 = stablehlo.reshape %446 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %448 = stablehlo.transpose %447, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %449 = stablehlo.reshape %448 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %450 = stablehlo.dot_general %445, %449, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %451 = stablehlo.convert %450 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %452 = stablehlo.reshape %451 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %453 = stablehlo.multiply %452, %89 : tensor<1x24x1x128xf32>
    %454 = stablehlo.convert %453 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %455 = stablehlo.add %454, %100 : tensor<1x24x1x128xbf16>
    %456 = stablehlo.convert %455 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %457 = stablehlo.reduce(%456 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %458 = stablehlo.broadcast_in_dim %457, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %459 = stablehlo.subtract %456, %458 : tensor<1x24x1x128xf32>
    %460 = stablehlo.exponential %459 : tensor<1x24x1x128xf32>
    %461 = stablehlo.reduce(%460 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %462 = stablehlo.broadcast_in_dim %461, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %463 = stablehlo.divide %460, %462 : tensor<1x24x1x128xf32>
    %464 = stablehlo.convert %463 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %465 = stablehlo.reshape %464 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %466 = stablehlo.broadcast_in_dim %427, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %467 = stablehlo.reshape %466 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %468 = stablehlo.dot_general %465, %467, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %469 = stablehlo.reshape %468 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %470 = stablehlo.transpose %arg49, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %471 = stablehlo.dot_general %469, %470, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %472 = stablehlo.reshape %471 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %473 = stablehlo.add %392, %472 : tensor<1x1x3072xbf16>
    %474 = stablehlo.convert %arg51 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %475 = stablehlo.reshape %474 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %476 = stablehlo.convert %473 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %477 = stablehlo.power %476, %0 : tensor<1x1x3072xf32>
    %478 = stablehlo.reduce(%477 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %479 = stablehlo.multiply %478, %cst_1 : tensor<1x1xf32>
    %480 = stablehlo.reshape %479 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %481 = stablehlo.add %480, %17 : tensor<1x1x1xf32>
    %482 = stablehlo.rsqrt %481 : tensor<1x1x1xf32>
    %483 = stablehlo.reshape %482 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %484 = stablehlo.broadcast_in_dim %483, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %485 = stablehlo.multiply %476, %484 : tensor<1x1x3072xf32>
    %486 = stablehlo.convert %485 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %487 = stablehlo.convert %486 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %488 = stablehlo.multiply %475, %487 : tensor<1x1x3072xf32>
    %489 = stablehlo.convert %488 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %490 = stablehlo.reshape %489 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %491 = stablehlo.transpose %arg52, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %492 = stablehlo.dot_general %490, %491, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %493 = stablehlo.reshape %492 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %494 = stablehlo.convert %493 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %495 = stablehlo.logistic %493 : tensor<1x1x8192xbf16>
    %496 = stablehlo.convert %495 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %497 = stablehlo.multiply %494, %496 : tensor<1x1x8192xf32>
    %498 = stablehlo.convert %497 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %499 = stablehlo.convert %498 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %500 = stablehlo.transpose %arg48, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %501 = stablehlo.dot_general %490, %500, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %502 = stablehlo.convert %501 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %503 = stablehlo.reshape %502 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %504 = stablehlo.multiply %499, %503 : tensor<1x1x8192xf32>
    %505 = stablehlo.convert %504 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %506 = stablehlo.reshape %505 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %507 = stablehlo.transpose %arg47, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %508 = stablehlo.dot_general %506, %507, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %509 = stablehlo.reshape %508 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %510 = stablehlo.add %473, %509 : tensor<1x1x3072xbf16>
    %511 = stablehlo.convert %510 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %512 = stablehlo.power %511, %0 : tensor<1x1x3072xf32>
    %513 = stablehlo.reduce(%512 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %514 = stablehlo.multiply %513, %cst_1 : tensor<1x1xf32>
    %515 = stablehlo.reshape %514 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %516 = stablehlo.add %515, %17 : tensor<1x1x1xf32>
    %517 = stablehlo.rsqrt %516 : tensor<1x1x1xf32>
    %518 = stablehlo.reshape %517 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %519 = stablehlo.broadcast_in_dim %518, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %520 = stablehlo.multiply %511, %519 : tensor<1x1x3072xf32>
    %521 = stablehlo.convert %520 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %522 = stablehlo.convert %521 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %523 = stablehlo.multiply %430, %522 : tensor<1x1x3072xf32>
    %524 = stablehlo.convert %523 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %525 = stablehlo.reshape %524 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %526 = stablehlo.transpose %arg5, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %527 = stablehlo.dot_general %525, %526, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<1x128256xbf16>
    %528 = stablehlo.reshape %527 : (tensor<1x128256xbf16>) -> tensor<1x1x128256xbf16>
    return %57, %62, %187, %192, %305, %310, %423, %428, %527, %528 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>
  }
}
module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<1xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg2: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg3: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg4: tensor<1x1xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg5: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg6: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg7: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg8: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg9: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg10: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg11: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg12: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg13: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg14: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg15: tensor<128xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg16: tensor<1x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg17: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg18: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg19: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg20: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg21: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg22: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg23: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg24: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg25: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg26: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg27: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg28: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg29: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg30: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg31: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg32: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg33: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg34: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg35: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg36: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg37: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg38: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg39: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg40: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg41: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg42: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg43: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg44: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg45: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg46: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg47: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg48: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg49: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg50: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg51: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg52: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg53: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) {
    %c = stablehlo.constant dense<0> : tensor<1xi64>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x1xf32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32>
    %1 = stablehlo.compare  LT, %arg0, %c : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1>
    %2 = stablehlo.reshape %arg7 : (tensor<i64>) -> tensor<1xi64>
    %3 = stablehlo.add %arg0, %2 : tensor<1xi64>
    %4 = stablehlo.select %1, %3, %arg0 : tensor<1xi1>, tensor<1xi64>
    %5 = stablehlo.reshape %4 : (tensor<1xi64>) -> tensor<1x1xi64>
    %6 = stablehlo.convert %arg6 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %7 = stablehlo.reshape %6 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %8 = stablehlo.convert %arg4 : (tensor<1x1xi64>) -> tensor<1x1xui32>
    %9 = stablehlo.reshape %8 : (tensor<1x1xui32>) -> tensor<1xui32>
    %10 = "stablehlo.gather"(%arg5, %9) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16>
    %11 = stablehlo.reshape %10 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %12 = stablehlo.convert %11 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %13 = stablehlo.power %12, %0 : tensor<1x1x3072xf32>
    %14 = stablehlo.reduce(%13 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %15 = stablehlo.multiply %14, %cst_1 : tensor<1x1xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %17 = stablehlo.reshape %arg3 : (tensor<f32>) -> tensor<1x1x1xf32>
    %18 = stablehlo.add %16, %17 : tensor<1x1x1xf32>
    %19 = stablehlo.rsqrt %18 : tensor<1x1x1xf32>
    %20 = stablehlo.reshape %19 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %21 = stablehlo.broadcast_in_dim %20, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %22 = stablehlo.multiply %12, %21 : tensor<1x1x3072xf32>
    %23 = stablehlo.convert %22 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %24 = stablehlo.convert %23 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %25 = stablehlo.multiply %7, %24 : tensor<1x1x3072xf32>
    %26 = stablehlo.convert %25 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %27 = stablehlo.reshape %26 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %28 = stablehlo.transpose %arg2, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %29 = stablehlo.dot_general %27, %28, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %30 = stablehlo.reshape %29 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %31 = stablehlo.convert %30 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %32 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x64x1xf32>
    %33 = stablehlo.convert %arg0 : (tensor<1xi64>) -> tensor<1xf32>
    %34 = stablehlo.reshape %33 : (tensor<1xf32>) -> tensor<1x1x1xf32>
    %35 = stablehlo.dot_general %32, %34, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32>
    %36 = stablehlo.reshape %35 : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32>
    %37 = stablehlo.concatenate %36, %36, dim = 2 : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32>
    %38 = stablehlo.cosine %37 : tensor<1x1x128xf32>
    %39 = stablehlo.convert %38 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
    %40 = stablehlo.convert %39 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
    %41 = stablehlo.broadcast_in_dim %40, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32>
    %42 = stablehlo.multiply %31, %41 : tensor<1x8x1x128xf32>
    %43 = stablehlo.convert %42 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %44 = stablehlo.slice %30 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %45 = stablehlo.negate %44 : tensor<1x8x1x64xbf16>
    %46 = stablehlo.slice %30 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %47 = stablehlo.concatenate %45, %46, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %48 = stablehlo.convert %47 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %49 = stablehlo.sine %37 : tensor<1x1x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32>
    %53 = stablehlo.multiply %48, %52 : tensor<1x8x1x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %55 = stablehlo.add %43, %54 : tensor<1x8x1x128xbf16>
    %56 = "stablehlo.scatter"(%arg8, %5, %55) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %57 = sdy.sharding_constraint %56 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %58 = stablehlo.transpose %arg9, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %59 = stablehlo.dot_general %27, %58, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %61 = "stablehlo.scatter"(%arg10, %5, %60) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %62 = sdy.sharding_constraint %61 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %63 = stablehlo.convert %arg21 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %64 = stablehlo.reshape %63 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %65 = stablehlo.transpose %arg18, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %66 = stablehlo.dot_general %27, %65, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %68 = stablehlo.convert %67 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %69 = stablehlo.broadcast_in_dim %40, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32>
    %70 = stablehlo.multiply %68, %69 : tensor<1x24x1x128xf32>
    %71 = stablehlo.convert %70 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %72 = stablehlo.slice %67 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %73 = stablehlo.negate %72 : tensor<1x24x1x64xbf16>
    %74 = stablehlo.slice %67 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %75 = stablehlo.concatenate %73, %74, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %76 = stablehlo.convert %75 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %77 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32>
    %78 = stablehlo.multiply %76, %77 : tensor<1x24x1x128xf32>
    %79 = stablehlo.convert %78 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %80 = stablehlo.add %71, %79 : tensor<1x24x1x128xbf16>
    %81 = stablehlo.reshape %80 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %82 = stablehlo.broadcast_in_dim %56, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %83 = stablehlo.reshape %82 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %84 = stablehlo.transpose %83, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %85 = stablehlo.reshape %84 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %86 = stablehlo.dot_general %81, %85, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %88 = stablehlo.reshape %87 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %89 = stablehlo.broadcast_in_dim %arg17, dims = [] : (tensor<f32>) -> tensor<1x24x1x128xf32>
    %90 = stablehlo.multiply %88, %89 : tensor<1x24x1x128xf32>
    %91 = stablehlo.convert %90 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %92 = stablehlo.convert %arg16 : (tensor<1x128xbf16>) -> tensor<1x128xf32>
    %93 = stablehlo.reshape %arg15 : (tensor<128xi64>) -> tensor<1x128xi64>
    %94 = stablehlo.broadcast_in_dim %arg0, dims = [0] : (tensor<1xi64>) -> tensor<1x128xi64>
    %95 = stablehlo.compare  GT, %93, %94 : (tensor<1x128xi64>, tensor<1x128xi64>) -> tensor<1x128xi1>
    %96 = stablehlo.convert %95 : (tensor<1x128xi1>) -> tensor<1x128xf32>
    %97 = stablehlo.multiply %92, %96 : tensor<1x128xf32>
    %98 = stablehlo.convert %97 : (tensor<1x128xf32>) -> tensor<1x128xbf16>
    %99 = stablehlo.reshape %98 : (tensor<1x128xbf16>) -> tensor<1x1x128xbf16>
    %100 = stablehlo.broadcast_in_dim %99, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x24x1x128xbf16>
    %101 = stablehlo.add %91, %100 : tensor<1x24x1x128xbf16>
    %102 = stablehlo.convert %101 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %103 = stablehlo.reduce(%102 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %105 = stablehlo.subtract %102, %104 : tensor<1x24x1x128xf32>
    %106 = stablehlo.exponential %105 : tensor<1x24x1x128xf32>
    %107 = stablehlo.reduce(%106 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %108 = stablehlo.broadcast_in_dim %107, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %109 = stablehlo.divide %106, %108 : tensor<1x24x1x128xf32>
    %110 = stablehlo.convert %109 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %111 = stablehlo.reshape %110 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %112 = stablehlo.broadcast_in_dim %61, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %113 = stablehlo.reshape %112 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %114 = stablehlo.dot_general %111, %113, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %115 = stablehlo.reshape %114 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %116 = stablehlo.transpose %arg14, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %117 = stablehlo.dot_general %115, %116, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %118 = stablehlo.reshape %117 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %119 = stablehlo.add %11, %118 : tensor<1x1x3072xbf16>
    %120 = stablehlo.convert %arg19 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %121 = stablehlo.reshape %120 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %122 = stablehlo.convert %119 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %123 = stablehlo.power %122, %0 : tensor<1x1x3072xf32>
    %124 = stablehlo.reduce(%123 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %125 = stablehlo.multiply %124, %cst_1 : tensor<1x1xf32>
    %126 = stablehlo.reshape %125 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %127 = stablehlo.add %126, %17 : tensor<1x1x1xf32>
    %128 = stablehlo.rsqrt %127 : tensor<1x1x1xf32>
    %129 = stablehlo.reshape %128 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %131 = stablehlo.multiply %122, %130 : tensor<1x1x3072xf32>
    %132 = stablehlo.convert %131 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %133 = stablehlo.convert %132 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %134 = stablehlo.multiply %121, %133 : tensor<1x1x3072xf32>
    %135 = stablehlo.convert %134 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %137 = stablehlo.transpose %arg20, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %138 = stablehlo.dot_general %136, %137, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %139 = stablehlo.reshape %138 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %140 = stablehlo.convert %139 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %141 = stablehlo.logistic %139 : tensor<1x1x8192xbf16>
    %142 = stablehlo.convert %141 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %143 = stablehlo.multiply %140, %142 : tensor<1x1x8192xf32>
    %144 = stablehlo.convert %143 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %145 = stablehlo.convert %144 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %146 = stablehlo.transpose %arg13, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %147 = stablehlo.dot_general %136, %146, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %150 = stablehlo.multiply %145, %149 : tensor<1x1x8192xf32>
    %151 = stablehlo.convert %150 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %152 = stablehlo.reshape %151 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %153 = stablehlo.transpose %arg12, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %154 = stablehlo.dot_general %152, %153, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %155 = stablehlo.reshape %154 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %156 = stablehlo.add %119, %155 : tensor<1x1x3072xbf16>
    %157 = stablehlo.convert %156 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %158 = stablehlo.power %157, %0 : tensor<1x1x3072xf32>
    %159 = stablehlo.reduce(%158 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %160 = stablehlo.multiply %159, %cst_1 : tensor<1x1xf32>
    %161 = stablehlo.reshape %160 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %162 = stablehlo.add %161, %17 : tensor<1x1x1xf32>
    %163 = stablehlo.rsqrt %162 : tensor<1x1x1xf32>
    %164 = stablehlo.reshape %163 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %166 = stablehlo.multiply %157, %165 : tensor<1x1x3072xf32>
    %167 = stablehlo.convert %166 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %168 = stablehlo.convert %167 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %169 = stablehlo.multiply %64, %168 : tensor<1x1x3072xf32>
    %170 = stablehlo.convert %169 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %171 = stablehlo.reshape %170 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %172 = stablehlo.transpose %arg11, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %173 = stablehlo.dot_general %171, %172, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %174 = stablehlo.reshape %173 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %175 = stablehlo.convert %174 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %176 = stablehlo.multiply %175, %41 : tensor<1x8x1x128xf32>
    %177 = stablehlo.convert %176 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %178 = stablehlo.slice %174 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %179 = stablehlo.negate %178 : tensor<1x8x1x64xbf16>
    %180 = stablehlo.slice %174 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %181 = stablehlo.concatenate %179, %180, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %182 = stablehlo.convert %181 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %183 = stablehlo.multiply %182, %52 : tensor<1x8x1x128xf32>
    %184 = stablehlo.convert %183 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %185 = stablehlo.add %177, %184 : tensor<1x8x1x128xbf16>
    %186 = "stablehlo.scatter"(%arg22, %5, %185) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %187 = sdy.sharding_constraint %186 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %188 = stablehlo.transpose %arg23, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %189 = stablehlo.dot_general %171, %188, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %190 = stablehlo.reshape %189 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %191 = "stablehlo.scatter"(%arg24, %5, %190) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %192 = sdy.sharding_constraint %191 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %193 = stablehlo.convert %arg32 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %194 = stablehlo.reshape %193 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %195 = stablehlo.transpose %arg29, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %196 = stablehlo.dot_general %171, %195, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %197 = stablehlo.reshape %196 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %198 = stablehlo.convert %197 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %199 = stablehlo.multiply %198, %69 : tensor<1x24x1x128xf32>
    %200 = stablehlo.convert %199 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %201 = stablehlo.slice %197 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %202 = stablehlo.negate %201 : tensor<1x24x1x64xbf16>
    %203 = stablehlo.slice %197 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %204 = stablehlo.concatenate %202, %203, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %205 = stablehlo.convert %204 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %206 = stablehlo.multiply %205, %77 : tensor<1x24x1x128xf32>
    %207 = stablehlo.convert %206 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %208 = stablehlo.add %200, %207 : tensor<1x24x1x128xbf16>
    %209 = stablehlo.reshape %208 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %210 = stablehlo.broadcast_in_dim %186, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %211 = stablehlo.reshape %210 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %212 = stablehlo.transpose %211, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %213 = stablehlo.reshape %212 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %214 = stablehlo.dot_general %209, %213, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %215 = stablehlo.convert %214 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %216 = stablehlo.reshape %215 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %217 = stablehlo.multiply %216, %89 : tensor<1x24x1x128xf32>
    %218 = stablehlo.convert %217 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %219 = stablehlo.add %218, %100 : tensor<1x24x1x128xbf16>
    %220 = stablehlo.convert %219 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %221 = stablehlo.reduce(%220 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %222 = stablehlo.broadcast_in_dim %221, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %223 = stablehlo.subtract %220, %222 : tensor<1x24x1x128xf32>
    %224 = stablehlo.exponential %223 : tensor<1x24x1x128xf32>
    %225 = stablehlo.reduce(%224 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %226 = stablehlo.broadcast_in_dim %225, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %227 = stablehlo.divide %224, %226 : tensor<1x24x1x128xf32>
    %228 = stablehlo.convert %227 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %229 = stablehlo.reshape %228 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %230 = stablehlo.broadcast_in_dim %191, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %231 = stablehlo.reshape %230 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %232 = stablehlo.dot_general %229, %231, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %233 = stablehlo.reshape %232 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %234 = stablehlo.transpose %arg28, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %235 = stablehlo.dot_general %233, %234, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %236 = stablehlo.reshape %235 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %237 = stablehlo.add %156, %236 : tensor<1x1x3072xbf16>
    %238 = stablehlo.convert %arg30 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %239 = stablehlo.reshape %238 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %240 = stablehlo.convert %237 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %241 = stablehlo.power %240, %0 : tensor<1x1x3072xf32>
    %242 = stablehlo.reduce(%241 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %243 = stablehlo.multiply %242, %cst_1 : tensor<1x1xf32>
    %244 = stablehlo.reshape %243 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %245 = stablehlo.add %244, %17 : tensor<1x1x1xf32>
    %246 = stablehlo.rsqrt %245 : tensor<1x1x1xf32>
    %247 = stablehlo.reshape %246 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %248 = stablehlo.broadcast_in_dim %247, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %249 = stablehlo.multiply %240, %248 : tensor<1x1x3072xf32>
    %250 = stablehlo.convert %249 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %251 = stablehlo.convert %250 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %252 = stablehlo.multiply %239, %251 : tensor<1x1x3072xf32>
    %253 = stablehlo.convert %252 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %254 = stablehlo.reshape %253 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %255 = stablehlo.transpose %arg31, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %256 = stablehlo.dot_general %254, %255, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %257 = stablehlo.reshape %256 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %258 = stablehlo.convert %257 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %259 = stablehlo.logistic %257 : tensor<1x1x8192xbf16>
    %260 = stablehlo.convert %259 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %261 = stablehlo.multiply %258, %260 : tensor<1x1x8192xf32>
    %262 = stablehlo.convert %261 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %263 = stablehlo.convert %262 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %264 = stablehlo.transpose %arg27, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %265 = stablehlo.dot_general %254, %264, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %266 = stablehlo.convert %265 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %267 = stablehlo.reshape %266 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %268 = stablehlo.multiply %263, %267 : tensor<1x1x8192xf32>
    %269 = stablehlo.convert %268 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %270 = stablehlo.reshape %269 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %271 = stablehlo.transpose %arg26, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %272 = stablehlo.dot_general %270, %271, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %273 = stablehlo.reshape %272 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %274 = stablehlo.add %237, %273 : tensor<1x1x3072xbf16>
    %275 = stablehlo.convert %274 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %276 = stablehlo.power %275, %0 : tensor<1x1x3072xf32>
    %277 = stablehlo.reduce(%276 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %278 = stablehlo.multiply %277, %cst_1 : tensor<1x1xf32>
    %279 = stablehlo.reshape %278 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %280 = stablehlo.add %279, %17 : tensor<1x1x1xf32>
    %281 = stablehlo.rsqrt %280 : tensor<1x1x1xf32>
    %282 = stablehlo.reshape %281 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %283 = stablehlo.broadcast_in_dim %282, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %284 = stablehlo.multiply %275, %283 : tensor<1x1x3072xf32>
    %285 = stablehlo.convert %284 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %286 = stablehlo.convert %285 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %287 = stablehlo.multiply %194, %286 : tensor<1x1x3072xf32>
    %288 = stablehlo.convert %287 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %289 = stablehlo.reshape %288 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %290 = stablehlo.transpose %arg25, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %291 = stablehlo.dot_general %289, %290, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %292 = stablehlo.reshape %291 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %293 = stablehlo.convert %292 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %294 = stablehlo.multiply %293, %41 : tensor<1x8x1x128xf32>
    %295 = stablehlo.convert %294 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %296 = stablehlo.slice %292 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %297 = stablehlo.negate %296 : tensor<1x8x1x64xbf16>
    %298 = stablehlo.slice %292 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %299 = stablehlo.concatenate %297, %298, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %300 = stablehlo.convert %299 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %301 = stablehlo.multiply %300, %52 : tensor<1x8x1x128xf32>
    %302 = stablehlo.convert %301 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %303 = stablehlo.add %295, %302 : tensor<1x8x1x128xbf16>
    %304 = "stablehlo.scatter"(%arg33, %5, %303) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %305 = sdy.sharding_constraint %304 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %306 = stablehlo.transpose %arg34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %307 = stablehlo.dot_general %289, %306, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %308 = stablehlo.reshape %307 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %309 = "stablehlo.scatter"(%arg35, %5, %308) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %310 = sdy.sharding_constraint %309 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %311 = stablehlo.convert %arg43 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %312 = stablehlo.reshape %311 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %313 = stablehlo.transpose %arg40, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %314 = stablehlo.dot_general %289, %313, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %315 = stablehlo.reshape %314 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %316 = stablehlo.convert %315 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %317 = stablehlo.multiply %316, %69 : tensor<1x24x1x128xf32>
    %318 = stablehlo.convert %317 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %319 = stablehlo.slice %315 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %320 = stablehlo.negate %319 : tensor<1x24x1x64xbf16>
    %321 = stablehlo.slice %315 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %322 = stablehlo.concatenate %320, %321, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %323 = stablehlo.convert %322 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %324 = stablehlo.multiply %323, %77 : tensor<1x24x1x128xf32>
    %325 = stablehlo.convert %324 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %326 = stablehlo.add %318, %325 : tensor<1x24x1x128xbf16>
    %327 = stablehlo.reshape %326 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %328 = stablehlo.broadcast_in_dim %304, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %329 = stablehlo.reshape %328 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %330 = stablehlo.transpose %329, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %331 = stablehlo.reshape %330 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %332 = stablehlo.dot_general %327, %331, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %333 = stablehlo.convert %332 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %334 = stablehlo.reshape %333 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %335 = stablehlo.multiply %334, %89 : tensor<1x24x1x128xf32>
    %336 = stablehlo.convert %335 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %337 = stablehlo.add %336, %100 : tensor<1x24x1x128xbf16>
    %338 = stablehlo.convert %337 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %339 = stablehlo.reduce(%338 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %340 = stablehlo.broadcast_in_dim %339, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %341 = stablehlo.subtract %338, %340 : tensor<1x24x1x128xf32>
    %342 = stablehlo.exponential %341 : tensor<1x24x1x128xf32>
    %343 = stablehlo.reduce(%342 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %344 = stablehlo.broadcast_in_dim %343, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %345 = stablehlo.divide %342, %344 : tensor<1x24x1x128xf32>
    %346 = stablehlo.convert %345 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %347 = stablehlo.reshape %346 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %348 = stablehlo.broadcast_in_dim %309, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %349 = stablehlo.reshape %348 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %350 = stablehlo.dot_general %347, %349, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %351 = stablehlo.reshape %350 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %352 = stablehlo.transpose %arg39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %353 = stablehlo.dot_general %351, %352, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %354 = stablehlo.reshape %353 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %355 = stablehlo.add %274, %354 : tensor<1x1x3072xbf16>
    %356 = stablehlo.convert %arg41 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %357 = stablehlo.reshape %356 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %358 = stablehlo.convert %355 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %359 = stablehlo.power %358, %0 : tensor<1x1x3072xf32>
    %360 = stablehlo.reduce(%359 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %361 = stablehlo.multiply %360, %cst_1 : tensor<1x1xf32>
    %362 = stablehlo.reshape %361 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %363 = stablehlo.add %362, %17 : tensor<1x1x1xf32>
    %364 = stablehlo.rsqrt %363 : tensor<1x1x1xf32>
    %365 = stablehlo.reshape %364 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %366 = stablehlo.broadcast_in_dim %365, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %367 = stablehlo.multiply %358, %366 : tensor<1x1x3072xf32>
    %368 = stablehlo.convert %367 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %369 = stablehlo.convert %368 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %370 = stablehlo.multiply %357, %369 : tensor<1x1x3072xf32>
    %371 = stablehlo.convert %370 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %372 = stablehlo.reshape %371 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %373 = stablehlo.transpose %arg42, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %374 = stablehlo.dot_general %372, %373, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %375 = stablehlo.reshape %374 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %376 = stablehlo.convert %375 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %377 = stablehlo.logistic %375 : tensor<1x1x8192xbf16>
    %378 = stablehlo.convert %377 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %379 = stablehlo.multiply %376, %378 : tensor<1x1x8192xf32>
    %380 = stablehlo.convert %379 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %381 = stablehlo.convert %380 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %382 = stablehlo.transpose %arg38, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %383 = stablehlo.dot_general %372, %382, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %384 = stablehlo.convert %383 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %385 = stablehlo.reshape %384 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %386 = stablehlo.multiply %381, %385 : tensor<1x1x8192xf32>
    %387 = stablehlo.convert %386 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %388 = stablehlo.reshape %387 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %389 = stablehlo.transpose %arg37, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %390 = stablehlo.dot_general %388, %389, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %391 = stablehlo.reshape %390 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %392 = stablehlo.add %355, %391 : tensor<1x1x3072xbf16>
    %393 = stablehlo.convert %392 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %394 = stablehlo.power %393, %0 : tensor<1x1x3072xf32>
    %395 = stablehlo.reduce(%394 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %396 = stablehlo.multiply %395, %cst_1 : tensor<1x1xf32>
    %397 = stablehlo.reshape %396 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %398 = stablehlo.add %397, %17 : tensor<1x1x1xf32>
    %399 = stablehlo.rsqrt %398 : tensor<1x1x1xf32>
    %400 = stablehlo.reshape %399 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %401 = stablehlo.broadcast_in_dim %400, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %402 = stablehlo.multiply %393, %401 : tensor<1x1x3072xf32>
    %403 = stablehlo.convert %402 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %404 = stablehlo.convert %403 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %405 = stablehlo.multiply %312, %404 : tensor<1x1x3072xf32>
    %406 = stablehlo.convert %405 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %407 = stablehlo.reshape %406 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %408 = stablehlo.transpose %arg36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %409 = stablehlo.dot_general %407, %408, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %410 = stablehlo.reshape %409 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %411 = stablehlo.convert %410 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %412 = stablehlo.multiply %411, %41 : tensor<1x8x1x128xf32>
    %413 = stablehlo.convert %412 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %414 = stablehlo.slice %410 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %415 = stablehlo.negate %414 : tensor<1x8x1x64xbf16>
    %416 = stablehlo.slice %410 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %417 = stablehlo.concatenate %415, %416, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %418 = stablehlo.convert %417 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %419 = stablehlo.multiply %418, %52 : tensor<1x8x1x128xf32>
    %420 = stablehlo.convert %419 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %421 = stablehlo.add %413, %420 : tensor<1x8x1x128xbf16>
    %422 = "stablehlo.scatter"(%arg44, %5, %421) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %423 = sdy.sharding_constraint %422 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %424 = stablehlo.transpose %arg45, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %425 = stablehlo.dot_general %407, %424, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %426 = stablehlo.reshape %425 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %427 = "stablehlo.scatter"(%arg46, %5, %426) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg54: tensor<bf16>, %arg55: tensor<bf16>):
      stablehlo.return %arg55 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %428 = sdy.sharding_constraint %427 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %429 = stablehlo.convert %arg53 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %430 = stablehlo.reshape %429 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %431 = stablehlo.transpose %arg50, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %432 = stablehlo.dot_general %407, %431, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %433 = stablehlo.reshape %432 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %434 = stablehlo.convert %433 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %435 = stablehlo.multiply %434, %69 : tensor<1x24x1x128xf32>
    %436 = stablehlo.convert %435 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %437 = stablehlo.slice %433 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %438 = stablehlo.negate %437 : tensor<1x24x1x64xbf16>
    %439 = stablehlo.slice %433 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %440 = stablehlo.concatenate %438, %439, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %441 = stablehlo.convert %440 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %442 = stablehlo.multiply %441, %77 : tensor<1x24x1x128xf32>
    %443 = stablehlo.convert %442 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %444 = stablehlo.add %436, %443 : tensor<1x24x1x128xbf16>
    %445 = stablehlo.reshape %444 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %446 = stablehlo.broadcast_in_dim %422, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %447 = stablehlo.reshape %446 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %448 = stablehlo.transpose %447, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %449 = stablehlo.reshape %448 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %450 = stablehlo.dot_general %445, %449, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %451 = stablehlo.convert %450 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %452 = stablehlo.reshape %451 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %453 = stablehlo.multiply %452, %89 : tensor<1x24x1x128xf32>
    %454 = stablehlo.convert %453 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %455 = stablehlo.add %454, %100 : tensor<1x24x1x128xbf16>
    %456 = stablehlo.convert %455 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %457 = stablehlo.reduce(%456 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %458 = stablehlo.broadcast_in_dim %457, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %459 = stablehlo.subtract %456, %458 : tensor<1x24x1x128xf32>
    %460 = stablehlo.exponential %459 : tensor<1x24x1x128xf32>
    %461 = stablehlo.reduce(%460 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %462 = stablehlo.broadcast_in_dim %461, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %463 = stablehlo.divide %460, %462 : tensor<1x24x1x128xf32>
    %464 = stablehlo.convert %463 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %465 = stablehlo.reshape %464 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %466 = stablehlo.broadcast_in_dim %427, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %467 = stablehlo.reshape %466 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %468 = stablehlo.dot_general %465, %467, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %469 = stablehlo.reshape %468 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %470 = stablehlo.transpose %arg49, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %471 = stablehlo.dot_general %469, %470, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %472 = stablehlo.reshape %471 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %473 = stablehlo.add %392, %472 : tensor<1x1x3072xbf16>
    %474 = stablehlo.convert %arg51 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %475 = stablehlo.reshape %474 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %476 = stablehlo.convert %473 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %477 = stablehlo.power %476, %0 : tensor<1x1x3072xf32>
    %478 = stablehlo.reduce(%477 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %479 = stablehlo.multiply %478, %cst_1 : tensor<1x1xf32>
    %480 = stablehlo.reshape %479 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %481 = stablehlo.add %480, %17 : tensor<1x1x1xf32>
    %482 = stablehlo.rsqrt %481 : tensor<1x1x1xf32>
    %483 = stablehlo.reshape %482 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %484 = stablehlo.broadcast_in_dim %483, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %485 = stablehlo.multiply %476, %484 : tensor<1x1x3072xf32>
    %486 = stablehlo.convert %485 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %487 = stablehlo.convert %486 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %488 = stablehlo.multiply %475, %487 : tensor<1x1x3072xf32>
    %489 = stablehlo.convert %488 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %490 = stablehlo.reshape %489 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %491 = stablehlo.transpose %arg52, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %492 = stablehlo.dot_general %490, %491, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %493 = stablehlo.reshape %492 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %494 = stablehlo.convert %493 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %495 = stablehlo.logistic %493 : tensor<1x1x8192xbf16>
    %496 = stablehlo.convert %495 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %497 = stablehlo.multiply %494, %496 : tensor<1x1x8192xf32>
    %498 = stablehlo.convert %497 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %499 = stablehlo.convert %498 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %500 = stablehlo.transpose %arg48, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %501 = stablehlo.dot_general %490, %500, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %502 = stablehlo.convert %501 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %503 = stablehlo.reshape %502 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %504 = stablehlo.multiply %499, %503 : tensor<1x1x8192xf32>
    %505 = stablehlo.convert %504 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %506 = stablehlo.reshape %505 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %507 = stablehlo.transpose %arg47, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %508 = stablehlo.dot_general %506, %507, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %509 = stablehlo.reshape %508 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %510 = stablehlo.add %473, %509 : tensor<1x1x3072xbf16>
    %511 = stablehlo.convert %510 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %512 = stablehlo.power %511, %0 : tensor<1x1x3072xf32>
    %513 = stablehlo.reduce(%512 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %514 = stablehlo.multiply %513, %cst_1 : tensor<1x1xf32>
    %515 = stablehlo.reshape %514 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %516 = stablehlo.add %515, %17 : tensor<1x1x1xf32>
    %517 = stablehlo.rsqrt %516 : tensor<1x1x1xf32>
    %518 = stablehlo.reshape %517 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %519 = stablehlo.broadcast_in_dim %518, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %520 = stablehlo.multiply %511, %519 : tensor<1x1x3072xf32>
    %521 = stablehlo.convert %520 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %522 = stablehlo.convert %521 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %523 = stablehlo.multiply %430, %522 : tensor<1x1x3072xf32>
    %524 = stablehlo.convert %523 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %525 = stablehlo.reshape %524 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %526 = stablehlo.transpose %arg5, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %527 = stablehlo.dot_general %525, %526, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<1x128256xbf16>
    %528 = stablehlo.reshape %527 : (tensor<1x128256xbf16>) -> tensor<1x1x128256xbf16>
    return %57, %62, %187, %192, %305, %310, %423, %428, %527, %528 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>
  }
}
module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<64xf32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg3: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg4: tensor<1x1xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg5: tensor<128256x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg6: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg7: tensor<i64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg8: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg9: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg10: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg11: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg12: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg13: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg14: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg15: tensor<128xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg16: tensor<1x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg17: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg18: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg19: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg20: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg21: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg22: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg23: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg24: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg25: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg26: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg27: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg28: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg29: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg30: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg31: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg32: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg33: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg34: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg35: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg36: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg37: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg38: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg39: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg40: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg41: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg42: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg43: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg44: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg45: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg46: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg47: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg48: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg49: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg50: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg51: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg52: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg53: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:10 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18, %arg19, %arg20, %arg21, %arg22, %arg23, %arg24, %arg25, %arg26, %arg27, %arg28, %arg29, %arg30, %arg31, %arg32, %arg33, %arg34, %arg35, %arg36, %arg37, %arg38, %arg39, %arg40, %arg41, %arg42, %arg43, %arg44, %arg45, %arg46, %arg47, %arg48, %arg49, %arg50, %arg51, %arg52, %arg53) in_shardings=[<@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>, <@mesh, []>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{}, {}, {"_axis_0"}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg54: tensor<1xi64>, %arg55: tensor<64xf32>, %arg56: tensor<512x3072xbf16>, %arg57: tensor<f32>, %arg58: tensor<1x1xi64>, %arg59: tensor<64128x3072xbf16>, %arg60: tensor<3072xbf16>, %arg61: tensor<i64>, %arg62: tensor<1x4x128x128xbf16>, %arg63: tensor<512x3072xbf16>, %arg64: tensor<1x4x128x128xbf16>, %arg65: tensor<512x3072xbf16>, %arg66: tensor<3072x4096xbf16>, %arg67: tensor<4096x3072xbf16>, %arg68: tensor<3072x1536xbf16>, %arg69: tensor<128xi64>, %arg70: tensor<1x128xbf16>, %arg71: tensor<f32>, %arg72: tensor<1536x3072xbf16>, %arg73: tensor<3072xbf16>, %arg74: tensor<4096x3072xbf16>, %arg75: tensor<3072xbf16>, %arg76: tensor<1x4x128x128xbf16>, %arg77: tensor<512x3072xbf16>, %arg78: tensor<1x4x128x128xbf16>, %arg79: tensor<512x3072xbf16>, %arg80: tensor<3072x4096xbf16>, %arg81: tensor<4096x3072xbf16>, %arg82: tensor<3072x1536xbf16>, %arg83: tensor<1536x3072xbf16>, %arg84: tensor<3072xbf16>, %arg85: tensor<4096x3072xbf16>, %arg86: tensor<3072xbf16>, %arg87: tensor<1x4x128x128xbf16>, %arg88: tensor<512x3072xbf16>, %arg89: tensor<1x4x128x128xbf16>, %arg90: tensor<512x3072xbf16>, %arg91: tensor<3072x4096xbf16>, %arg92: tensor<4096x3072xbf16>, %arg93: tensor<3072x1536xbf16>, %arg94: tensor<1536x3072xbf16>, %arg95: tensor<3072xbf16>, %arg96: tensor<4096x3072xbf16>, %arg97: tensor<3072xbf16>, %arg98: tensor<1x4x128x128xbf16>, %arg99: tensor<512x3072xbf16>, %arg100: tensor<1x4x128x128xbf16>, %arg101: tensor<3072x4096xbf16>, %arg102: tensor<4096x3072xbf16>, %arg103: tensor<3072x1536xbf16>, %arg104: tensor<1536x3072xbf16>, %arg105: tensor<3072xbf16>, %arg106: tensor<4096x3072xbf16>, %arg107: tensor<3072xbf16>) {
      %c = stablehlo.constant dense<0> : tensor<1xi64>
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x1xf32>
      %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %1 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32>
      %2 = stablehlo.compare  LT, %arg54, %c : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1>
      %3 = stablehlo.reshape %arg61 : (tensor<i64>) -> tensor<1xi64>
      %4 = stablehlo.add %arg54, %3 : tensor<1xi64>
      %5 = stablehlo.select %2, %4, %arg54 : tensor<1xi1>, tensor<1xi64>
      %6 = stablehlo.reshape %5 : (tensor<1xi64>) -> tensor<1x1xi64>
      %7 = stablehlo.convert %arg60 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %8 = stablehlo.reshape %7 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %9 = stablehlo.convert %arg58 : (tensor<1x1xi64>) -> tensor<1x1xui32>
      %10 = stablehlo.reshape %9 : (tensor<1x1xui32>) -> tensor<1xui32>
      %11 = "stablehlo.gather"(%arg59, %10) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<64128x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16>
      %12 = "stablehlo.all_reduce"(%11) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %13 = stablehlo.reshape %12 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %14 = stablehlo.convert %13 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %15 = stablehlo.power %14, %1 : tensor<1x1x3072xf32>
      %16 = stablehlo.reduce(%15 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %17 = stablehlo.multiply %16, %cst_1 : tensor<1x1xf32>
      %18 = stablehlo.reshape %17 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %19 = stablehlo.reshape %arg57 : (tensor<f32>) -> tensor<1x1x1xf32>
      %20 = stablehlo.add %18, %19 : tensor<1x1x1xf32>
      %21 = stablehlo.rsqrt %20 : tensor<1x1x1xf32>
      %22 = stablehlo.reshape %21 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %23 = stablehlo.broadcast_in_dim %22, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %24 = stablehlo.multiply %14, %23 : tensor<1x1x3072xf32>
      %25 = stablehlo.convert %24 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %26 = stablehlo.convert %25 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %27 = stablehlo.multiply %8, %26 : tensor<1x1x3072xf32>
      %28 = stablehlo.convert %27 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %29 = stablehlo.reshape %28 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %30 = stablehlo.transpose %arg56, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %31 = stablehlo.dot_general %29, %30, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %32 = stablehlo.reshape %31 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %33 = stablehlo.convert %32 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %34 = stablehlo.reshape %arg55 : (tensor<64xf32>) -> tensor<1x64x1xf32>
      %35 = stablehlo.convert %arg54 : (tensor<1xi64>) -> tensor<1xf32>
      %36 = stablehlo.reshape %35 : (tensor<1xf32>) -> tensor<1x1x1xf32>
      %37 = stablehlo.dot_general %34, %36, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32>
      %38 = stablehlo.reshape %37 : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32>
      %39 = stablehlo.concatenate %38, %38, dim = 2 : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32>
      %40 = stablehlo.cosine %39 : tensor<1x1x128xf32>
      %41 = stablehlo.convert %40 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
      %42 = stablehlo.convert %41 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
      %43 = stablehlo.broadcast_in_dim %42, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x4x1x128xf32>
      %44 = stablehlo.multiply %33, %43 : tensor<1x4x1x128xf32>
      %45 = stablehlo.convert %44 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %46 = stablehlo.slice %32 [0:1, 0:4, 0:1, 64:128] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %47 = stablehlo.negate %46 : tensor<1x4x1x64xbf16>
      %48 = stablehlo.slice %32 [0:1, 0:4, 0:1, 0:64] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %49 = stablehlo.concatenate %47, %48, dim = 3 : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x128xbf16>
      %50 = stablehlo.convert %49 : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %51 = stablehlo.sine %39 : tensor<1x1x128xf32>
      %52 = stablehlo.convert %51 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
      %53 = stablehlo.convert %52 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
      %54 = stablehlo.broadcast_in_dim %53, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x4x1x128xf32>
      %55 = stablehlo.multiply %50, %54 : tensor<1x4x1x128xf32>
      %56 = stablehlo.convert %55 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %57 = stablehlo.add %45, %56 : tensor<1x4x1x128xbf16>
      %58 = "stablehlo.scatter"(%arg62, %6, %57) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %59 = stablehlo.transpose %arg63, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %60 = stablehlo.dot_general %29, %59, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %61 = stablehlo.reshape %60 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %62 = "stablehlo.scatter"(%arg64, %6, %61) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %63 = stablehlo.convert %arg75 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %64 = stablehlo.reshape %63 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %65 = stablehlo.transpose %arg72, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %66 = stablehlo.dot_general %29, %65, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
      %67 = stablehlo.reshape %66 : (tensor<1x1536xbf16>) -> tensor<1x12x1x128xbf16>
      %68 = stablehlo.convert %67 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %69 = stablehlo.broadcast_in_dim %42, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x12x1x128xf32>
      %70 = stablehlo.multiply %68, %69 : tensor<1x12x1x128xf32>
      %71 = stablehlo.convert %70 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %72 = stablehlo.slice %67 [0:1, 0:12, 0:1, 64:128] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %73 = stablehlo.negate %72 : tensor<1x12x1x64xbf16>
      %74 = stablehlo.slice %67 [0:1, 0:12, 0:1, 0:64] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %75 = stablehlo.concatenate %73, %74, dim = 3 : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x128xbf16>
      %76 = stablehlo.convert %75 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %77 = stablehlo.broadcast_in_dim %53, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x12x1x128xf32>
      %78 = stablehlo.multiply %76, %77 : tensor<1x12x1x128xf32>
      %79 = stablehlo.convert %78 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %80 = stablehlo.add %71, %79 : tensor<1x12x1x128xbf16>
      %81 = stablehlo.reshape %80 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %82 = stablehlo.broadcast_in_dim %58, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %83 = stablehlo.reshape %82 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %84 = stablehlo.transpose %83, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %85 = stablehlo.reshape %84 : (tensor<1x12x128x128xbf16>) -> tensor<12x128x128xbf16>
      %86 = stablehlo.dot_general %81, %85, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %87 = stablehlo.convert %86 : (tensor<12x1x128xbf16>) -> tensor<12x1x128xf32>
      %88 = stablehlo.reshape %87 : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>
      %89 = stablehlo.broadcast_in_dim %arg71, dims = [] : (tensor<f32>) -> tensor<1x12x1x128xf32>
      %90 = stablehlo.multiply %88, %89 : tensor<1x12x1x128xf32>
      %91 = stablehlo.convert %90 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %92 = stablehlo.convert %arg70 : (tensor<1x128xbf16>) -> tensor<1x128xf32>
      %93 = stablehlo.reshape %arg69 : (tensor<128xi64>) -> tensor<1x128xi64>
      %94 = stablehlo.broadcast_in_dim %arg54, dims = [0] : (tensor<1xi64>) -> tensor<1x128xi64>
      %95 = stablehlo.compare  GT, %93, %94 : (tensor<1x128xi64>, tensor<1x128xi64>) -> tensor<1x128xi1>
      %96 = stablehlo.convert %95 : (tensor<1x128xi1>) -> tensor<1x128xf32>
      %97 = stablehlo.multiply %92, %96 : tensor<1x128xf32>
      %98 = stablehlo.convert %97 : (tensor<1x128xf32>) -> tensor<1x128xbf16>
      %99 = stablehlo.reshape %98 : (tensor<1x128xbf16>) -> tensor<1x1x128xbf16>
      %100 = stablehlo.broadcast_in_dim %99, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x12x1x128xbf16>
      %101 = stablehlo.add %91, %100 : tensor<1x12x1x128xbf16>
      %102 = stablehlo.convert %101 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %103 = stablehlo.reduce(%102 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %105 = stablehlo.subtract %102, %104 : tensor<1x12x1x128xf32>
      %106 = stablehlo.exponential %105 : tensor<1x12x1x128xf32>
      %107 = stablehlo.reduce(%106 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %108 = stablehlo.broadcast_in_dim %107, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %109 = stablehlo.divide %106, %108 : tensor<1x12x1x128xf32>
      %110 = stablehlo.convert %109 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %111 = stablehlo.reshape %110 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %112 = stablehlo.broadcast_in_dim %62, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %113 = stablehlo.reshape %112 : (tensor<1x4x3x128x128xbf16>) -> tensor<12x128x128xbf16>
      %114 = stablehlo.dot_general %111, %113, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %115 = stablehlo.reshape %114 : (tensor<12x1x128xbf16>) -> tensor<1x1536xbf16>
      %116 = stablehlo.transpose %arg68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
      %117 = stablehlo.dot_general %115, %116, contracting_dims = [1] x [0] : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
      %118 = "stablehlo.all_reduce"(%117) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %119 = stablehlo.reshape %118 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %120 = stablehlo.add %13, %119 : tensor<1x1x3072xbf16>
      %121 = stablehlo.convert %arg73 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %122 = stablehlo.reshape %121 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %123 = stablehlo.convert %120 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %124 = stablehlo.power %123, %1 : tensor<1x1x3072xf32>
      %125 = stablehlo.reduce(%124 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %126 = stablehlo.multiply %125, %cst_1 : tensor<1x1xf32>
      %127 = stablehlo.reshape %126 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %128 = stablehlo.add %127, %19 : tensor<1x1x1xf32>
      %129 = stablehlo.rsqrt %128 : tensor<1x1x1xf32>
      %130 = stablehlo.reshape %129 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %131 = stablehlo.broadcast_in_dim %130, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %132 = stablehlo.multiply %123, %131 : tensor<1x1x3072xf32>
      %133 = stablehlo.convert %132 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %134 = stablehlo.convert %133 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %135 = stablehlo.multiply %122, %134 : tensor<1x1x3072xf32>
      %136 = stablehlo.convert %135 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %137 = stablehlo.reshape %136 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %138 = stablehlo.transpose %arg74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %139 = stablehlo.dot_general %137, %138, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %140 = stablehlo.reshape %139 : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16>
      %141 = stablehlo.convert %140 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %142 = stablehlo.logistic %140 : tensor<1x1x4096xbf16>
      %143 = stablehlo.convert %142 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %144 = stablehlo.multiply %141, %143 : tensor<1x1x4096xf32>
      %145 = stablehlo.convert %144 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %146 = stablehlo.convert %145 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %147 = stablehlo.transpose %arg67, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %148 = stablehlo.dot_general %137, %147, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %149 = stablehlo.convert %148 : (tensor<1x4096xbf16>) -> tensor<1x4096xf32>
      %150 = stablehlo.reshape %149 : (tensor<1x4096xf32>) -> tensor<1x1x4096xf32>
      %151 = stablehlo.multiply %146, %150 : tensor<1x1x4096xf32>
      %152 = stablehlo.convert %151 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %153 = stablehlo.reshape %152 : (tensor<1x1x4096xbf16>) -> tensor<1x4096xbf16>
      %154 = stablehlo.transpose %arg66, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
      %155 = stablehlo.dot_general %153, %154, contracting_dims = [1] x [0] : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
      %156 = "stablehlo.all_reduce"(%155) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %157 = stablehlo.reshape %156 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %158 = stablehlo.add %120, %157 : tensor<1x1x3072xbf16>
      %159 = stablehlo.convert %158 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %160 = stablehlo.power %159, %1 : tensor<1x1x3072xf32>
      %161 = stablehlo.reduce(%160 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %162 = stablehlo.multiply %161, %cst_1 : tensor<1x1xf32>
      %163 = stablehlo.reshape %162 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %164 = stablehlo.add %163, %19 : tensor<1x1x1xf32>
      %165 = stablehlo.rsqrt %164 : tensor<1x1x1xf32>
      %166 = stablehlo.reshape %165 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %167 = stablehlo.broadcast_in_dim %166, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %168 = stablehlo.multiply %159, %167 : tensor<1x1x3072xf32>
      %169 = stablehlo.convert %168 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %170 = stablehlo.convert %169 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %171 = stablehlo.multiply %64, %170 : tensor<1x1x3072xf32>
      %172 = stablehlo.convert %171 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %173 = stablehlo.reshape %172 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %174 = stablehlo.transpose %arg65, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %175 = stablehlo.dot_general %173, %174, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %176 = stablehlo.reshape %175 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %177 = stablehlo.convert %176 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %178 = stablehlo.multiply %177, %43 : tensor<1x4x1x128xf32>
      %179 = stablehlo.convert %178 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %180 = stablehlo.slice %176 [0:1, 0:4, 0:1, 64:128] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %181 = stablehlo.negate %180 : tensor<1x4x1x64xbf16>
      %182 = stablehlo.slice %176 [0:1, 0:4, 0:1, 0:64] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %183 = stablehlo.concatenate %181, %182, dim = 3 : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x128xbf16>
      %184 = stablehlo.convert %183 : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %185 = stablehlo.multiply %184, %54 : tensor<1x4x1x128xf32>
      %186 = stablehlo.convert %185 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %187 = stablehlo.add %179, %186 : tensor<1x4x1x128xbf16>
      %188 = "stablehlo.scatter"(%arg76, %6, %187) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %189 = stablehlo.transpose %arg77, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %190 = stablehlo.dot_general %173, %189, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %191 = stablehlo.reshape %190 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %192 = "stablehlo.scatter"(%arg78, %6, %191) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %193 = stablehlo.convert %arg86 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %194 = stablehlo.reshape %193 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %195 = stablehlo.transpose %arg83, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %196 = stablehlo.dot_general %173, %195, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
      %197 = stablehlo.reshape %196 : (tensor<1x1536xbf16>) -> tensor<1x12x1x128xbf16>
      %198 = stablehlo.convert %197 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %199 = stablehlo.multiply %198, %69 : tensor<1x12x1x128xf32>
      %200 = stablehlo.convert %199 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %201 = stablehlo.slice %197 [0:1, 0:12, 0:1, 64:128] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %202 = stablehlo.negate %201 : tensor<1x12x1x64xbf16>
      %203 = stablehlo.slice %197 [0:1, 0:12, 0:1, 0:64] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %204 = stablehlo.concatenate %202, %203, dim = 3 : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x128xbf16>
      %205 = stablehlo.convert %204 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %206 = stablehlo.multiply %205, %77 : tensor<1x12x1x128xf32>
      %207 = stablehlo.convert %206 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %208 = stablehlo.add %200, %207 : tensor<1x12x1x128xbf16>
      %209 = stablehlo.reshape %208 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %210 = stablehlo.broadcast_in_dim %188, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %211 = stablehlo.reshape %210 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %212 = stablehlo.transpose %211, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %213 = stablehlo.reshape %212 : (tensor<1x12x128x128xbf16>) -> tensor<12x128x128xbf16>
      %214 = stablehlo.dot_general %209, %213, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %215 = stablehlo.convert %214 : (tensor<12x1x128xbf16>) -> tensor<12x1x128xf32>
      %216 = stablehlo.reshape %215 : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>
      %217 = stablehlo.multiply %216, %89 : tensor<1x12x1x128xf32>
      %218 = stablehlo.convert %217 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %219 = stablehlo.add %218, %100 : tensor<1x12x1x128xbf16>
      %220 = stablehlo.convert %219 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %221 = stablehlo.reduce(%220 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %222 = stablehlo.broadcast_in_dim %221, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %223 = stablehlo.subtract %220, %222 : tensor<1x12x1x128xf32>
      %224 = stablehlo.exponential %223 : tensor<1x12x1x128xf32>
      %225 = stablehlo.reduce(%224 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %226 = stablehlo.broadcast_in_dim %225, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %227 = stablehlo.divide %224, %226 : tensor<1x12x1x128xf32>
      %228 = stablehlo.convert %227 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %229 = stablehlo.reshape %228 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %230 = stablehlo.broadcast_in_dim %192, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %231 = stablehlo.reshape %230 : (tensor<1x4x3x128x128xbf16>) -> tensor<12x128x128xbf16>
      %232 = stablehlo.dot_general %229, %231, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %233 = stablehlo.reshape %232 : (tensor<12x1x128xbf16>) -> tensor<1x1536xbf16>
      %234 = stablehlo.transpose %arg82, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
      %235 = stablehlo.dot_general %233, %234, contracting_dims = [1] x [0] : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
      %236 = "stablehlo.all_reduce"(%235) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %237 = stablehlo.reshape %236 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %238 = stablehlo.add %158, %237 : tensor<1x1x3072xbf16>
      %239 = stablehlo.convert %arg84 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %240 = stablehlo.reshape %239 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %241 = stablehlo.convert %238 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %242 = stablehlo.power %241, %1 : tensor<1x1x3072xf32>
      %243 = stablehlo.reduce(%242 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %244 = stablehlo.multiply %243, %cst_1 : tensor<1x1xf32>
      %245 = stablehlo.reshape %244 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %246 = stablehlo.add %245, %19 : tensor<1x1x1xf32>
      %247 = stablehlo.rsqrt %246 : tensor<1x1x1xf32>
      %248 = stablehlo.reshape %247 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %249 = stablehlo.broadcast_in_dim %248, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %250 = stablehlo.multiply %241, %249 : tensor<1x1x3072xf32>
      %251 = stablehlo.convert %250 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %252 = stablehlo.convert %251 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %253 = stablehlo.multiply %240, %252 : tensor<1x1x3072xf32>
      %254 = stablehlo.convert %253 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %255 = stablehlo.reshape %254 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %256 = stablehlo.transpose %arg85, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %257 = stablehlo.dot_general %255, %256, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %258 = stablehlo.reshape %257 : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16>
      %259 = stablehlo.convert %258 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %260 = stablehlo.logistic %258 : tensor<1x1x4096xbf16>
      %261 = stablehlo.convert %260 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %262 = stablehlo.multiply %259, %261 : tensor<1x1x4096xf32>
      %263 = stablehlo.convert %262 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %264 = stablehlo.convert %263 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %265 = stablehlo.transpose %arg81, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %266 = stablehlo.dot_general %255, %265, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %267 = stablehlo.convert %266 : (tensor<1x4096xbf16>) -> tensor<1x4096xf32>
      %268 = stablehlo.reshape %267 : (tensor<1x4096xf32>) -> tensor<1x1x4096xf32>
      %269 = stablehlo.multiply %264, %268 : tensor<1x1x4096xf32>
      %270 = stablehlo.convert %269 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %271 = stablehlo.reshape %270 : (tensor<1x1x4096xbf16>) -> tensor<1x4096xbf16>
      %272 = stablehlo.transpose %arg80, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
      %273 = stablehlo.dot_general %271, %272, contracting_dims = [1] x [0] : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
      %274 = "stablehlo.all_reduce"(%273) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %275 = stablehlo.reshape %274 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %276 = stablehlo.add %238, %275 : tensor<1x1x3072xbf16>
      %277 = stablehlo.convert %276 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %278 = stablehlo.power %277, %1 : tensor<1x1x3072xf32>
      %279 = stablehlo.reduce(%278 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %280 = stablehlo.multiply %279, %cst_1 : tensor<1x1xf32>
      %281 = stablehlo.reshape %280 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %282 = stablehlo.add %281, %19 : tensor<1x1x1xf32>
      %283 = stablehlo.rsqrt %282 : tensor<1x1x1xf32>
      %284 = stablehlo.reshape %283 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %285 = stablehlo.broadcast_in_dim %284, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %286 = stablehlo.multiply %277, %285 : tensor<1x1x3072xf32>
      %287 = stablehlo.convert %286 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %288 = stablehlo.convert %287 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %289 = stablehlo.multiply %194, %288 : tensor<1x1x3072xf32>
      %290 = stablehlo.convert %289 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %291 = stablehlo.reshape %290 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %292 = stablehlo.transpose %arg79, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %293 = stablehlo.dot_general %291, %292, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %294 = stablehlo.reshape %293 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %295 = stablehlo.convert %294 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %296 = stablehlo.multiply %295, %43 : tensor<1x4x1x128xf32>
      %297 = stablehlo.convert %296 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %298 = stablehlo.slice %294 [0:1, 0:4, 0:1, 64:128] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %299 = stablehlo.negate %298 : tensor<1x4x1x64xbf16>
      %300 = stablehlo.slice %294 [0:1, 0:4, 0:1, 0:64] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %301 = stablehlo.concatenate %299, %300, dim = 3 : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x128xbf16>
      %302 = stablehlo.convert %301 : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %303 = stablehlo.multiply %302, %54 : tensor<1x4x1x128xf32>
      %304 = stablehlo.convert %303 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %305 = stablehlo.add %297, %304 : tensor<1x4x1x128xbf16>
      %306 = "stablehlo.scatter"(%arg87, %6, %305) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %307 = stablehlo.transpose %arg88, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %308 = stablehlo.dot_general %291, %307, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %309 = stablehlo.reshape %308 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %310 = "stablehlo.scatter"(%arg89, %6, %309) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %311 = stablehlo.convert %arg97 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %312 = stablehlo.reshape %311 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %313 = stablehlo.transpose %arg94, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %314 = stablehlo.dot_general %291, %313, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
      %315 = stablehlo.reshape %314 : (tensor<1x1536xbf16>) -> tensor<1x12x1x128xbf16>
      %316 = stablehlo.convert %315 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %317 = stablehlo.multiply %316, %69 : tensor<1x12x1x128xf32>
      %318 = stablehlo.convert %317 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %319 = stablehlo.slice %315 [0:1, 0:12, 0:1, 64:128] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %320 = stablehlo.negate %319 : tensor<1x12x1x64xbf16>
      %321 = stablehlo.slice %315 [0:1, 0:12, 0:1, 0:64] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %322 = stablehlo.concatenate %320, %321, dim = 3 : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x128xbf16>
      %323 = stablehlo.convert %322 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %324 = stablehlo.multiply %323, %77 : tensor<1x12x1x128xf32>
      %325 = stablehlo.convert %324 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %326 = stablehlo.add %318, %325 : tensor<1x12x1x128xbf16>
      %327 = stablehlo.reshape %326 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %328 = stablehlo.broadcast_in_dim %306, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %329 = stablehlo.reshape %328 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %330 = stablehlo.transpose %329, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %331 = stablehlo.reshape %330 : (tensor<1x12x128x128xbf16>) -> tensor<12x128x128xbf16>
      %332 = stablehlo.dot_general %327, %331, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %333 = stablehlo.convert %332 : (tensor<12x1x128xbf16>) -> tensor<12x1x128xf32>
      %334 = stablehlo.reshape %333 : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>
      %335 = stablehlo.multiply %334, %89 : tensor<1x12x1x128xf32>
      %336 = stablehlo.convert %335 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %337 = stablehlo.add %336, %100 : tensor<1x12x1x128xbf16>
      %338 = stablehlo.convert %337 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %339 = stablehlo.reduce(%338 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %340 = stablehlo.broadcast_in_dim %339, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %341 = stablehlo.subtract %338, %340 : tensor<1x12x1x128xf32>
      %342 = stablehlo.exponential %341 : tensor<1x12x1x128xf32>
      %343 = stablehlo.reduce(%342 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %344 = stablehlo.broadcast_in_dim %343, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %345 = stablehlo.divide %342, %344 : tensor<1x12x1x128xf32>
      %346 = stablehlo.convert %345 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %347 = stablehlo.reshape %346 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %348 = stablehlo.broadcast_in_dim %310, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %349 = stablehlo.reshape %348 : (tensor<1x4x3x128x128xbf16>) -> tensor<12x128x128xbf16>
      %350 = stablehlo.dot_general %347, %349, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %351 = stablehlo.reshape %350 : (tensor<12x1x128xbf16>) -> tensor<1x1536xbf16>
      %352 = stablehlo.transpose %arg93, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
      %353 = stablehlo.dot_general %351, %352, contracting_dims = [1] x [0] : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
      %354 = "stablehlo.all_reduce"(%353) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %355 = stablehlo.reshape %354 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %356 = stablehlo.add %276, %355 : tensor<1x1x3072xbf16>
      %357 = stablehlo.convert %arg95 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %358 = stablehlo.reshape %357 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %359 = stablehlo.convert %356 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %360 = stablehlo.power %359, %1 : tensor<1x1x3072xf32>
      %361 = stablehlo.reduce(%360 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %362 = stablehlo.multiply %361, %cst_1 : tensor<1x1xf32>
      %363 = stablehlo.reshape %362 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %364 = stablehlo.add %363, %19 : tensor<1x1x1xf32>
      %365 = stablehlo.rsqrt %364 : tensor<1x1x1xf32>
      %366 = stablehlo.reshape %365 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %367 = stablehlo.broadcast_in_dim %366, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %368 = stablehlo.multiply %359, %367 : tensor<1x1x3072xf32>
      %369 = stablehlo.convert %368 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %370 = stablehlo.convert %369 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %371 = stablehlo.multiply %358, %370 : tensor<1x1x3072xf32>
      %372 = stablehlo.convert %371 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %373 = stablehlo.reshape %372 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %374 = stablehlo.transpose %arg96, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %375 = stablehlo.dot_general %373, %374, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %376 = stablehlo.reshape %375 : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16>
      %377 = stablehlo.convert %376 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %378 = stablehlo.logistic %376 : tensor<1x1x4096xbf16>
      %379 = stablehlo.convert %378 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %380 = stablehlo.multiply %377, %379 : tensor<1x1x4096xf32>
      %381 = stablehlo.convert %380 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %382 = stablehlo.convert %381 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %383 = stablehlo.transpose %arg92, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %384 = stablehlo.dot_general %373, %383, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %385 = stablehlo.convert %384 : (tensor<1x4096xbf16>) -> tensor<1x4096xf32>
      %386 = stablehlo.reshape %385 : (tensor<1x4096xf32>) -> tensor<1x1x4096xf32>
      %387 = stablehlo.multiply %382, %386 : tensor<1x1x4096xf32>
      %388 = stablehlo.convert %387 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %389 = stablehlo.reshape %388 : (tensor<1x1x4096xbf16>) -> tensor<1x4096xbf16>
      %390 = stablehlo.transpose %arg91, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
      %391 = stablehlo.dot_general %389, %390, contracting_dims = [1] x [0] : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
      %392 = "stablehlo.all_reduce"(%391) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %393 = stablehlo.reshape %392 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %394 = stablehlo.add %356, %393 : tensor<1x1x3072xbf16>
      %395 = stablehlo.convert %394 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %396 = stablehlo.power %395, %1 : tensor<1x1x3072xf32>
      %397 = stablehlo.reduce(%396 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %398 = stablehlo.multiply %397, %cst_1 : tensor<1x1xf32>
      %399 = stablehlo.reshape %398 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %400 = stablehlo.add %399, %19 : tensor<1x1x1xf32>
      %401 = stablehlo.rsqrt %400 : tensor<1x1x1xf32>
      %402 = stablehlo.reshape %401 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %403 = stablehlo.broadcast_in_dim %402, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %404 = stablehlo.multiply %395, %403 : tensor<1x1x3072xf32>
      %405 = stablehlo.convert %404 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %406 = stablehlo.convert %405 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %407 = stablehlo.multiply %312, %406 : tensor<1x1x3072xf32>
      %408 = stablehlo.convert %407 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %409 = stablehlo.reshape %408 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %410 = stablehlo.transpose %arg90, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %411 = stablehlo.dot_general %409, %410, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %412 = stablehlo.reshape %411 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %413 = stablehlo.convert %412 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %414 = stablehlo.multiply %413, %43 : tensor<1x4x1x128xf32>
      %415 = stablehlo.convert %414 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %416 = stablehlo.slice %412 [0:1, 0:4, 0:1, 64:128] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %417 = stablehlo.negate %416 : tensor<1x4x1x64xbf16>
      %418 = stablehlo.slice %412 [0:1, 0:4, 0:1, 0:64] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16>
      %419 = stablehlo.concatenate %417, %418, dim = 3 : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x128xbf16>
      %420 = stablehlo.convert %419 : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32>
      %421 = stablehlo.multiply %420, %54 : tensor<1x4x1x128xf32>
      %422 = stablehlo.convert %421 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16>
      %423 = stablehlo.add %415, %422 : tensor<1x4x1x128xbf16>
      %424 = "stablehlo.scatter"(%arg98, %6, %423) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %425 = stablehlo.transpose %arg99, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %426 = stablehlo.dot_general %409, %425, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
      %427 = stablehlo.reshape %426 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16>
      %428 = "stablehlo.scatter"(%arg100, %6, %427) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        stablehlo.return %arg109 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16>
      %429 = stablehlo.convert %arg107 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %430 = stablehlo.reshape %429 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %431 = stablehlo.transpose %arg104, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %432 = stablehlo.dot_general %409, %431, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
      %433 = stablehlo.reshape %432 : (tensor<1x1536xbf16>) -> tensor<1x12x1x128xbf16>
      %434 = stablehlo.convert %433 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %435 = stablehlo.multiply %434, %69 : tensor<1x12x1x128xf32>
      %436 = stablehlo.convert %435 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %437 = stablehlo.slice %433 [0:1, 0:12, 0:1, 64:128] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %438 = stablehlo.negate %437 : tensor<1x12x1x64xbf16>
      %439 = stablehlo.slice %433 [0:1, 0:12, 0:1, 0:64] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16>
      %440 = stablehlo.concatenate %438, %439, dim = 3 : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x128xbf16>
      %441 = stablehlo.convert %440 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %442 = stablehlo.multiply %441, %77 : tensor<1x12x1x128xf32>
      %443 = stablehlo.convert %442 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %444 = stablehlo.add %436, %443 : tensor<1x12x1x128xbf16>
      %445 = stablehlo.reshape %444 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %446 = stablehlo.broadcast_in_dim %424, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %447 = stablehlo.reshape %446 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %448 = stablehlo.transpose %447, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %449 = stablehlo.reshape %448 : (tensor<1x12x128x128xbf16>) -> tensor<12x128x128xbf16>
      %450 = stablehlo.dot_general %445, %449, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %451 = stablehlo.convert %450 : (tensor<12x1x128xbf16>) -> tensor<12x1x128xf32>
      %452 = stablehlo.reshape %451 : (tensor<12x1x128xf32>) -> tensor<1x12x1x128xf32>
      %453 = stablehlo.multiply %452, %89 : tensor<1x12x1x128xf32>
      %454 = stablehlo.convert %453 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %455 = stablehlo.add %454, %100 : tensor<1x12x1x128xbf16>
      %456 = stablehlo.convert %455 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32>
      %457 = stablehlo.reduce(%456 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %458 = stablehlo.broadcast_in_dim %457, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %459 = stablehlo.subtract %456, %458 : tensor<1x12x1x128xf32>
      %460 = stablehlo.exponential %459 : tensor<1x12x1x128xf32>
      %461 = stablehlo.reduce(%460 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32>
      %462 = stablehlo.broadcast_in_dim %461, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32>
      %463 = stablehlo.divide %460, %462 : tensor<1x12x1x128xf32>
      %464 = stablehlo.convert %463 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16>
      %465 = stablehlo.reshape %464 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16>
      %466 = stablehlo.broadcast_in_dim %428, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %467 = stablehlo.reshape %466 : (tensor<1x4x3x128x128xbf16>) -> tensor<12x128x128xbf16>
      %468 = stablehlo.dot_general %465, %467, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
      %469 = stablehlo.reshape %468 : (tensor<12x1x128xbf16>) -> tensor<1x1536xbf16>
      %470 = stablehlo.transpose %arg103, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
      %471 = stablehlo.dot_general %469, %470, contracting_dims = [1] x [0] : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
      %472 = "stablehlo.all_reduce"(%471) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %473 = stablehlo.reshape %472 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %474 = stablehlo.add %394, %473 : tensor<1x1x3072xbf16>
      %475 = stablehlo.convert %arg105 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %476 = stablehlo.reshape %475 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
      %477 = stablehlo.convert %474 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %478 = stablehlo.power %477, %1 : tensor<1x1x3072xf32>
      %479 = stablehlo.reduce(%478 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %480 = stablehlo.multiply %479, %cst_1 : tensor<1x1xf32>
      %481 = stablehlo.reshape %480 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %482 = stablehlo.add %481, %19 : tensor<1x1x1xf32>
      %483 = stablehlo.rsqrt %482 : tensor<1x1x1xf32>
      %484 = stablehlo.reshape %483 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %485 = stablehlo.broadcast_in_dim %484, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %486 = stablehlo.multiply %477, %485 : tensor<1x1x3072xf32>
      %487 = stablehlo.convert %486 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %488 = stablehlo.convert %487 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %489 = stablehlo.multiply %476, %488 : tensor<1x1x3072xf32>
      %490 = stablehlo.convert %489 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %491 = stablehlo.reshape %490 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %492 = stablehlo.transpose %arg106, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %493 = stablehlo.dot_general %491, %492, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %494 = stablehlo.reshape %493 : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16>
      %495 = stablehlo.convert %494 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %496 = stablehlo.logistic %494 : tensor<1x1x4096xbf16>
      %497 = stablehlo.convert %496 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %498 = stablehlo.multiply %495, %497 : tensor<1x1x4096xf32>
      %499 = stablehlo.convert %498 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %500 = stablehlo.convert %499 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32>
      %501 = stablehlo.transpose %arg102, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %502 = stablehlo.dot_general %491, %501, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
      %503 = stablehlo.convert %502 : (tensor<1x4096xbf16>) -> tensor<1x4096xf32>
      %504 = stablehlo.reshape %503 : (tensor<1x4096xf32>) -> tensor<1x1x4096xf32>
      %505 = stablehlo.multiply %500, %504 : tensor<1x1x4096xf32>
      %506 = stablehlo.convert %505 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16>
      %507 = stablehlo.reshape %506 : (tensor<1x1x4096xbf16>) -> tensor<1x4096xbf16>
      %508 = stablehlo.transpose %arg101, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
      %509 = stablehlo.dot_general %507, %508, contracting_dims = [1] x [0] : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
      %510 = "stablehlo.all_reduce"(%509) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg108: tensor<bf16>, %arg109: tensor<bf16>):
        %531 = stablehlo.add %arg108, %arg109 : tensor<bf16>
        stablehlo.return %531 : tensor<bf16>
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
      %511 = stablehlo.reshape %510 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
      %512 = stablehlo.add %474, %511 : tensor<1x1x3072xbf16>
      %513 = stablehlo.convert %512 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %514 = stablehlo.power %513, %1 : tensor<1x1x3072xf32>
      %515 = stablehlo.reduce(%514 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
      %516 = stablehlo.multiply %515, %cst_1 : tensor<1x1xf32>
      %517 = stablehlo.reshape %516 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
      %518 = stablehlo.add %517, %19 : tensor<1x1x1xf32>
      %519 = stablehlo.rsqrt %518 : tensor<1x1x1xf32>
      %520 = stablehlo.reshape %519 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
      %521 = stablehlo.broadcast_in_dim %520, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
      %522 = stablehlo.multiply %513, %521 : tensor<1x1x3072xf32>
      %523 = stablehlo.convert %522 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %524 = stablehlo.convert %523 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %525 = stablehlo.multiply %430, %524 : tensor<1x1x3072xf32>
      %526 = stablehlo.convert %525 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
      %527 = stablehlo.reshape %526 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
      %528 = stablehlo.transpose %arg59, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<64128x3072xbf16>) -> tensor<3072x64128xbf16>
      %529 = stablehlo.dot_general %527, %528, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x64128xbf16>) -> tensor<1x64128xbf16>
      %530 = stablehlo.reshape %529 : (tensor<1x64128xbf16>) -> tensor<1x1x64128xbf16>
      sdy.return %58, %62, %188, %192, %306, %310, %424, %428, %529, %530 : tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x64128xbf16>, tensor<1x1x64128xbf16>
    } : (tensor<1xi64>, tensor<64xf32>, tensor<1024x3072xbf16>, tensor<f32>, tensor<1x1xi64>, tensor<128256x3072xbf16>, tensor<3072xbf16>, tensor<i64>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<128xi64>, tensor<1x128xbf16>, tensor<f32>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>)
    return %0#0, %0#1, %0#2, %0#3, %0#4, %0#5, %0#6, %0#7, %0#8, %0#9 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>
  }
}
module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<1xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<64xf32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg3: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg4: tensor<1x1xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg5: tensor<128256x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg6: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg7: tensor<i64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg8: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg9: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg10: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg11: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg12: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg13: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg14: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg15: tensor<128xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg16: tensor<1x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg17: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg18: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg19: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg20: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg21: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg22: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg23: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg24: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg25: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg26: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg27: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg28: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg29: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg30: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg31: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg32: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg33: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg34: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg35: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg36: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg37: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg38: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg39: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg40: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg41: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg42: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg43: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg44: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg45: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg46: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg47: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg48: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg49: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg50: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg51: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg52: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg53: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = ttir.empty() : tensor<1xi64>
    %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi64>
    %2 = ttir.empty() : tensor<64xf32>
    %3 = "ttir.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xf32>
    %4 = ttir.empty() : tensor<512x3072xbf16>
    %5 = "ttir.mesh_shard"(%arg2, %4) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %6 = ttir.empty() : tensor<f32>
    %7 = "ttir.mesh_shard"(%arg3, %6) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32>, tensor<f32>) -> tensor<f32>
    %8 = ttir.empty() : tensor<1x1xi64>
    %9 = "ttir.mesh_shard"(%arg4, %8) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x1xi64>, tensor<1x1xi64>) -> tensor<1x1xi64>
    %10 = ttir.empty() : tensor<64128x3072xbf16>
    %11 = "ttir.mesh_shard"(%arg5, %10) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16>, tensor<64128x3072xbf16>) -> tensor<64128x3072xbf16>
    %12 = ttir.empty() : tensor<3072xbf16>
    %13 = "ttir.mesh_shard"(%arg6, %12) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %14 = ttir.empty() : tensor<i64>
    %15 = "ttir.mesh_shard"(%arg7, %14) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<i64>, tensor<i64>) -> tensor<i64>
    %16 = ttir.empty() : tensor<1x4x128x128xbf16>
    %17 = "ttir.mesh_shard"(%arg8, %16) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %18 = ttir.empty() : tensor<512x3072xbf16>
    %19 = "ttir.mesh_shard"(%arg9, %18) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %20 = ttir.empty() : tensor<1x4x128x128xbf16>
    %21 = "ttir.mesh_shard"(%arg10, %20) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %22 = ttir.empty() : tensor<512x3072xbf16>
    %23 = "ttir.mesh_shard"(%arg11, %22) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %24 = ttir.empty() : tensor<3072x4096xbf16>
    %25 = "ttir.mesh_shard"(%arg12, %24) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %26 = ttir.empty() : tensor<4096x3072xbf16>
    %27 = "ttir.mesh_shard"(%arg13, %26) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %28 = ttir.empty() : tensor<3072x1536xbf16>
    %29 = "ttir.mesh_shard"(%arg14, %28) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %30 = ttir.empty() : tensor<128xi64>
    %31 = "ttir.mesh_shard"(%arg15, %30) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi64>
    %32 = ttir.empty() : tensor<1x128xbf16>
    %33 = "ttir.mesh_shard"(%arg16, %32) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x128xbf16>, tensor<1x128xbf16>) -> tensor<1x128xbf16>
    %34 = ttir.empty() : tensor<f32>
    %35 = "ttir.mesh_shard"(%arg17, %34) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32>, tensor<f32>) -> tensor<f32>
    %36 = ttir.empty() : tensor<1536x3072xbf16>
    %37 = "ttir.mesh_shard"(%arg18, %36) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %38 = ttir.empty() : tensor<3072xbf16>
    %39 = "ttir.mesh_shard"(%arg19, %38) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %40 = ttir.empty() : tensor<4096x3072xbf16>
    %41 = "ttir.mesh_shard"(%arg20, %40) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %42 = ttir.empty() : tensor<3072xbf16>
    %43 = "ttir.mesh_shard"(%arg21, %42) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %44 = ttir.empty() : tensor<1x4x128x128xbf16>
    %45 = "ttir.mesh_shard"(%arg22, %44) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %46 = ttir.empty() : tensor<512x3072xbf16>
    %47 = "ttir.mesh_shard"(%arg23, %46) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %48 = ttir.empty() : tensor<1x4x128x128xbf16>
    %49 = "ttir.mesh_shard"(%arg24, %48) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %50 = ttir.empty() : tensor<512x3072xbf16>
    %51 = "ttir.mesh_shard"(%arg25, %50) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %52 = ttir.empty() : tensor<3072x4096xbf16>
    %53 = "ttir.mesh_shard"(%arg26, %52) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %54 = ttir.empty() : tensor<4096x3072xbf16>
    %55 = "ttir.mesh_shard"(%arg27, %54) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %56 = ttir.empty() : tensor<3072x1536xbf16>
    %57 = "ttir.mesh_shard"(%arg28, %56) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %58 = ttir.empty() : tensor<1536x3072xbf16>
    %59 = "ttir.mesh_shard"(%arg29, %58) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %60 = ttir.empty() : tensor<3072xbf16>
    %61 = "ttir.mesh_shard"(%arg30, %60) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %62 = ttir.empty() : tensor<4096x3072xbf16>
    %63 = "ttir.mesh_shard"(%arg31, %62) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %64 = ttir.empty() : tensor<3072xbf16>
    %65 = "ttir.mesh_shard"(%arg32, %64) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %66 = ttir.empty() : tensor<1x4x128x128xbf16>
    %67 = "ttir.mesh_shard"(%arg33, %66) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %68 = ttir.empty() : tensor<512x3072xbf16>
    %69 = "ttir.mesh_shard"(%arg34, %68) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %70 = ttir.empty() : tensor<1x4x128x128xbf16>
    %71 = "ttir.mesh_shard"(%arg35, %70) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %72 = ttir.empty() : tensor<512x3072xbf16>
    %73 = "ttir.mesh_shard"(%arg36, %72) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %74 = ttir.empty() : tensor<3072x4096xbf16>
    %75 = "ttir.mesh_shard"(%arg37, %74) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %76 = ttir.empty() : tensor<4096x3072xbf16>
    %77 = "ttir.mesh_shard"(%arg38, %76) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %78 = ttir.empty() : tensor<3072x1536xbf16>
    %79 = "ttir.mesh_shard"(%arg39, %78) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %80 = ttir.empty() : tensor<1536x3072xbf16>
    %81 = "ttir.mesh_shard"(%arg40, %80) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %82 = ttir.empty() : tensor<3072xbf16>
    %83 = "ttir.mesh_shard"(%arg41, %82) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %84 = ttir.empty() : tensor<4096x3072xbf16>
    %85 = "ttir.mesh_shard"(%arg42, %84) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %86 = ttir.empty() : tensor<3072xbf16>
    %87 = "ttir.mesh_shard"(%arg43, %86) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %88 = ttir.empty() : tensor<1x4x128x128xbf16>
    %89 = "ttir.mesh_shard"(%arg44, %88) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %90 = ttir.empty() : tensor<512x3072xbf16>
    %91 = "ttir.mesh_shard"(%arg45, %90) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %92 = ttir.empty() : tensor<1x4x128x128xbf16>
    %93 = "ttir.mesh_shard"(%arg46, %92) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %94 = ttir.empty() : tensor<3072x4096xbf16>
    %95 = "ttir.mesh_shard"(%arg47, %94) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %96 = ttir.empty() : tensor<4096x3072xbf16>
    %97 = "ttir.mesh_shard"(%arg48, %96) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %98 = ttir.empty() : tensor<3072x1536xbf16>
    %99 = "ttir.mesh_shard"(%arg49, %98) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %100 = ttir.empty() : tensor<1536x3072xbf16>
    %101 = "ttir.mesh_shard"(%arg50, %100) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %102 = ttir.empty() : tensor<3072xbf16>
    %103 = "ttir.mesh_shard"(%arg51, %102) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %104 = ttir.empty() : tensor<4096x3072xbf16>
    %105 = "ttir.mesh_shard"(%arg52, %104) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %106 = ttir.empty() : tensor<3072xbf16>
    %107 = "ttir.mesh_shard"(%arg53, %106) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %108 = "ttir.constant"() <{value = dense<0> : tensor<1xi64>}> : () -> tensor<1xi64>
    %109 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32>
    %110 = "ttir.constant"() <{value = dense<0xFF800000> : tensor<f32>}> : () -> tensor<f32>
    %111 = "ttir.constant"() <{value = dense<3.25520843E-4> : tensor<1x1xf32>}> : () -> tensor<1x1xf32>
    %112 = "ttir.constant"() <{value = dense<2.000000e+00> : tensor<f32>}> : () -> tensor<f32>
    %113 = ttir.empty() : tensor<1x1x1xf32>
    %114 = "ttir.reshape"(%112, %113) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %115 = ttir.empty() : tensor<1x1x3072xf32>
    %116 = "ttir.broadcast"(%114, %115) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %117 = ttir.empty() : tensor<1xi1>
    %118 = "ttir.lt"(%1, %108, %117) : (tensor<1xi64>, tensor<1xi64>, tensor<1xi1>) -> tensor<1xi1>
    %119 = ttir.empty() : tensor<1xi64>
    %120 = "ttir.reshape"(%15, %119) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64>
    %121 = ttir.empty() : tensor<1xi64>
    %122 = "ttir.add"(%1, %120, %121) : (tensor<1xi64>, tensor<1xi64>, tensor<1xi64>) -> tensor<1xi64>
    %123 = ttir.empty() : tensor<1xi64>
    %124 = "ttir.where"(%118, %122, %1, %123) : (tensor<1xi1>, tensor<1xi64>, tensor<1xi64>, tensor<1xi64>) -> tensor<1xi64>
    %125 = ttir.empty() : tensor<1x1xi64>
    %126 = "ttir.reshape"(%124, %125) <{shape = [1 : i32, 1 : i32]}> : (tensor<1xi64>, tensor<1x1xi64>) -> tensor<1x1xi64>
    %127 = ttir.empty() : tensor<3072xf32>
    %128 = "ttir.typecast"(%13, %127) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %129 = ttir.empty() : tensor<1x1x3072xf32>
    %130 = "ttir.reshape"(%128, %129) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %131 = ttir.empty() : tensor<1x1xui32>
    %132 = "ttir.typecast"(%9, %131) <{conservative_folding = false}> : (tensor<1x1xi64>, tensor<1x1xui32>) -> tensor<1x1xui32>
    %133 = ttir.empty() : tensor<1xui32>
    %134 = "ttir.reshape"(%132, %133) <{shape = [1 : i32]}> : (tensor<1x1xui32>, tensor<1xui32>) -> tensor<1xui32>
    %135 = ttir.empty() : tensor<1x3072xbf16>
    %136 = "ttir.gather"(%11, %134, %135) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3072>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<64128x3072xbf16>, tensor<1xui32>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %137 = ttir.empty() : tensor<1x3072xbf16>
    %138 = "ttir.all_reduce"(%136, %137) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %139 = ttir.empty() : tensor<1x1x3072xbf16>
    %140 = "ttir.reshape"(%138, %139) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %141 = ttir.empty() : tensor<1x1x3072xf32>
    %142 = "ttir.typecast"(%140, %141) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %143 = ttir.empty() : tensor<1x1x3072xf32>
    %144 = "ttir.pow"(%142, %116, %143) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %145 = ttir.empty() : tensor<1x1xf32>
    %146 = "ttir.sum"(%144, %145) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %147 = ttir.empty() : tensor<1x1xf32>
    %148 = "ttir.multiply"(%146, %111, %147) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %149 = ttir.empty() : tensor<1x1x1xf32>
    %150 = "ttir.reshape"(%148, %149) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %151 = ttir.empty() : tensor<1x1x1xf32>
    %152 = "ttir.reshape"(%7, %151) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %153 = ttir.empty() : tensor<1x1x1xf32>
    %154 = "ttir.add"(%150, %152, %153) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %155 = ttir.empty() : tensor<1x1x1xf32>
    %156 = "ttir.rsqrt"(%154, %155) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %157 = ttir.empty() : tensor<1x1xf32>
    %158 = "ttir.reshape"(%156, %157) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %159 = ttir.empty() : tensor<1x1x1xf32>
    %160 = "ttir.reshape"(%158, %159) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %161 = ttir.empty() : tensor<1x1x3072xf32>
    %162 = "ttir.broadcast"(%160, %161) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %163 = ttir.empty() : tensor<1x1x3072xf32>
    %164 = "ttir.multiply"(%142, %162, %163) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %165 = ttir.empty() : tensor<1x1x3072xbf16>
    %166 = "ttir.typecast"(%164, %165) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %167 = ttir.empty() : tensor<1x1x3072xf32>
    %168 = "ttir.typecast"(%166, %167) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %169 = ttir.empty() : tensor<1x1x3072xf32>
    %170 = "ttir.multiply"(%130, %168, %169) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %171 = ttir.empty() : tensor<1x1x3072xbf16>
    %172 = "ttir.typecast"(%170, %171) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %173 = ttir.empty() : tensor<1x3072xbf16>
    %174 = "ttir.reshape"(%172, %173) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %175 = ttir.empty() : tensor<3072x512xbf16>
    %176 = "ttir.permute"(%5, %175) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %177 = "ttir.dot_general"(%174, %176) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %178 = ttir.empty() : tensor<1x4x1x128xbf16>
    %179 = "ttir.reshape"(%177, %178) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %180 = ttir.empty() : tensor<1x4x1x128xf32>
    %181 = "ttir.typecast"(%179, %180) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %182 = ttir.empty() : tensor<1x64x1xf32>
    %183 = "ttir.reshape"(%3, %182) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32>, tensor<1x64x1xf32>) -> tensor<1x64x1xf32>
    %184 = ttir.empty() : tensor<1xf32>
    %185 = "ttir.typecast"(%1, %184) <{conservative_folding = false}> : (tensor<1xi64>, tensor<1xf32>) -> tensor<1xf32>
    %186 = ttir.empty() : tensor<1x1x1xf32>
    %187 = "ttir.reshape"(%185, %186) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %188 = "ttir.dot_general"(%183, %187) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32>
    %189 = ttir.empty() : tensor<1x1x64xf32>
    %190 = "ttir.reshape"(%188, %189) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<1x64x1xf32>, tensor<1x1x64xf32>) -> tensor<1x1x64xf32>
    %191 = ttir.empty() : tensor<1x1x128xf32>
    %192 = "ttir.concat"(%190, %190, %191) <{dim = 2 : si32}> : (tensor<1x1x64xf32>, tensor<1x1x64xf32>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32>
    %193 = ttir.empty() : tensor<1x1x128xf32>
    %194 = "ttir.cos"(%192, %193) : (tensor<1x1x128xf32>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32>
    %195 = ttir.empty() : tensor<1x1x128xbf16>
    %196 = "ttir.typecast"(%194, %195) <{conservative_folding = false}> : (tensor<1x1x128xf32>, tensor<1x1x128xbf16>) -> tensor<1x1x128xbf16>
    %197 = ttir.empty() : tensor<1x1x128xf32>
    %198 = "ttir.typecast"(%196, %197) <{conservative_folding = false}> : (tensor<1x1x128xbf16>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32>
    %199 = ttir.empty() : tensor<1x1x1x128xf32>
    %200 = "ttir.reshape"(%198, %199) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>
    %201 = ttir.empty() : tensor<1x4x1x128xf32>
    %202 = "ttir.broadcast"(%200, %201) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %203 = ttir.empty() : tensor<1x4x1x128xf32>
    %204 = "ttir.multiply"(%181, %202, %203) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %205 = ttir.empty() : tensor<1x4x1x128xbf16>
    %206 = "ttir.typecast"(%204, %205) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %207 = ttir.empty() : tensor<1x4x1x64xbf16>
    %208 = "ttir.slice_static"(%179, %207) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %209 = ttir.empty() : tensor<1x4x1x64xbf16>
    %210 = "ttir.neg"(%208, %209) : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %211 = ttir.empty() : tensor<1x4x1x64xbf16>
    %212 = "ttir.slice_static"(%179, %211) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %213 = ttir.empty() : tensor<1x4x1x128xbf16>
    %214 = "ttir.concat"(%210, %212, %213) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %215 = ttir.empty() : tensor<1x4x1x128xf32>
    %216 = "ttir.typecast"(%214, %215) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %217 = ttir.empty() : tensor<1x1x128xf32>
    %218 = "ttir.sin"(%192, %217) : (tensor<1x1x128xf32>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32>
    %219 = ttir.empty() : tensor<1x1x128xbf16>
    %220 = "ttir.typecast"(%218, %219) <{conservative_folding = false}> : (tensor<1x1x128xf32>, tensor<1x1x128xbf16>) -> tensor<1x1x128xbf16>
    %221 = ttir.empty() : tensor<1x1x128xf32>
    %222 = "ttir.typecast"(%220, %221) <{conservative_folding = false}> : (tensor<1x1x128xbf16>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32>
    %223 = ttir.empty() : tensor<1x1x1x128xf32>
    %224 = "ttir.reshape"(%222, %223) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>
    %225 = ttir.empty() : tensor<1x4x1x128xf32>
    %226 = "ttir.broadcast"(%224, %225) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %227 = ttir.empty() : tensor<1x4x1x128xf32>
    %228 = "ttir.multiply"(%216, %226, %227) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %229 = ttir.empty() : tensor<1x4x1x128xbf16>
    %230 = "ttir.typecast"(%228, %229) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %231 = ttir.empty() : tensor<1x4x1x128xbf16>
    %232 = "ttir.add"(%206, %230, %231) : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %233 = ttir.empty() : tensor<1x4x128x128xbf16>
    %234 = "ttir.scatter"(%17, %126, %232, %233) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %235 = ttir.empty() : tensor<3072x512xbf16>
    %236 = "ttir.permute"(%19, %235) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %237 = "ttir.dot_general"(%174, %236) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %238 = ttir.empty() : tensor<1x4x1x128xbf16>
    %239 = "ttir.reshape"(%237, %238) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %240 = ttir.empty() : tensor<1x4x128x128xbf16>
    %241 = "ttir.scatter"(%21, %126, %239, %240) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %242 = ttir.empty() : tensor<3072xf32>
    %243 = "ttir.typecast"(%43, %242) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %244 = ttir.empty() : tensor<1x1x3072xf32>
    %245 = "ttir.reshape"(%243, %244) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %246 = ttir.empty() : tensor<3072x1536xbf16>
    %247 = "ttir.permute"(%37, %246) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %248 = "ttir.dot_general"(%174, %247) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
    %249 = ttir.empty() : tensor<1x12x1x128xbf16>
    %250 = "ttir.reshape"(%248, %249) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %251 = ttir.empty() : tensor<1x12x1x128xf32>
    %252 = "ttir.typecast"(%250, %251) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %253 = ttir.empty() : tensor<1x1x1x128xf32>
    %254 = "ttir.reshape"(%198, %253) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>
    %255 = ttir.empty() : tensor<1x12x1x128xf32>
    %256 = "ttir.broadcast"(%254, %255) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %257 = ttir.empty() : tensor<1x12x1x128xf32>
    %258 = "ttir.multiply"(%252, %256, %257) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %259 = ttir.empty() : tensor<1x12x1x128xbf16>
    %260 = "ttir.typecast"(%258, %259) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %261 = ttir.empty() : tensor<1x12x1x64xbf16>
    %262 = "ttir.slice_static"(%250, %261) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %263 = ttir.empty() : tensor<1x12x1x64xbf16>
    %264 = "ttir.neg"(%262, %263) : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %265 = ttir.empty() : tensor<1x12x1x64xbf16>
    %266 = "ttir.slice_static"(%250, %265) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %267 = ttir.empty() : tensor<1x12x1x128xbf16>
    %268 = "ttir.concat"(%264, %266, %267) <{dim = 3 : si32}> : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %269 = ttir.empty() : tensor<1x12x1x128xf32>
    %270 = "ttir.typecast"(%268, %269) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %271 = ttir.empty() : tensor<1x1x1x128xf32>
    %272 = "ttir.reshape"(%222, %271) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32>
    %273 = ttir.empty() : tensor<1x12x1x128xf32>
    %274 = "ttir.broadcast"(%272, %273) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %275 = ttir.empty() : tensor<1x12x1x128xf32>
    %276 = "ttir.multiply"(%270, %274, %275) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %277 = ttir.empty() : tensor<1x12x1x128xbf16>
    %278 = "ttir.typecast"(%276, %277) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %279 = ttir.empty() : tensor<1x12x1x128xbf16>
    %280 = "ttir.add"(%260, %278, %279) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %281 = ttir.empty() : tensor<12x1x128xbf16>
    %282 = "ttir.reshape"(%280, %281) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %283 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %284 = "ttir.reshape"(%234, %283) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %285 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %286 = "ttir.broadcast"(%284, %285) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %287 = ttir.empty() : tensor<1x12x128x128xbf16>
    %288 = "ttir.reshape"(%286, %287) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %289 = ttir.empty() : tensor<1x12x128x128xbf16>
    %290 = "ttir.permute"(%288, %289) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %291 = ttir.empty() : tensor<12x128x128xbf16>
    %292 = "ttir.reshape"(%290, %291) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %293 = "ttir.dot_general"(%282, %292) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %294 = ttir.empty() : tensor<12x1x128xf32>
    %295 = "ttir.typecast"(%293, %294) <{conservative_folding = false}> : (tensor<12x1x128xbf16>, tensor<12x1x128xf32>) -> tensor<12x1x128xf32>
    %296 = ttir.empty() : tensor<1x12x1x128xf32>
    %297 = "ttir.reshape"(%295, %296) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %298 = ttir.empty() : tensor<1x1x1x1xf32>
    %299 = "ttir.reshape"(%35, %298) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>
    %300 = ttir.empty() : tensor<1x12x1x128xf32>
    %301 = "ttir.broadcast"(%299, %300) <{broadcast_dimensions = array<i64: 1, 12, 1, 128>}> : (tensor<1x1x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %302 = ttir.empty() : tensor<1x12x1x128xf32>
    %303 = "ttir.multiply"(%297, %301, %302) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %304 = ttir.empty() : tensor<1x12x1x128xbf16>
    %305 = "ttir.typecast"(%303, %304) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %306 = ttir.empty() : tensor<1x128xf32>
    %307 = "ttir.typecast"(%33, %306) <{conservative_folding = false}> : (tensor<1x128xbf16>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %308 = ttir.empty() : tensor<1x128xi64>
    %309 = "ttir.reshape"(%31, %308) <{shape = [1 : i32, 128 : i32]}> : (tensor<128xi64>, tensor<1x128xi64>) -> tensor<1x128xi64>
    %310 = ttir.empty() : tensor<1x1xi64>
    %311 = "ttir.reshape"(%1, %310) <{shape = [1 : i32, 1 : i32]}> : (tensor<1xi64>, tensor<1x1xi64>) -> tensor<1x1xi64>
    %312 = ttir.empty() : tensor<1x128xi64>
    %313 = "ttir.broadcast"(%311, %312) <{broadcast_dimensions = array<i64: 1, 128>}> : (tensor<1x1xi64>, tensor<1x128xi64>) -> tensor<1x128xi64>
    %314 = ttir.empty() : tensor<1x128xi1>
    %315 = "ttir.gt"(%309, %313, %314) : (tensor<1x128xi64>, tensor<1x128xi64>, tensor<1x128xi1>) -> tensor<1x128xi1>
    %316 = ttir.empty() : tensor<1x128xf32>
    %317 = "ttir.typecast"(%315, %316) <{conservative_folding = false}> : (tensor<1x128xi1>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %318 = ttir.empty() : tensor<1x128xf32>
    %319 = "ttir.multiply"(%307, %317, %318) : (tensor<1x128xf32>, tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %320 = ttir.empty() : tensor<1x128xbf16>
    %321 = "ttir.typecast"(%319, %320) <{conservative_folding = false}> : (tensor<1x128xf32>, tensor<1x128xbf16>) -> tensor<1x128xbf16>
    %322 = ttir.empty() : tensor<1x1x128xbf16>
    %323 = "ttir.reshape"(%321, %322) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x128xbf16>, tensor<1x1x128xbf16>) -> tensor<1x1x128xbf16>
    %324 = ttir.empty() : tensor<1x1x1x128xbf16>
    %325 = "ttir.reshape"(%323, %324) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xbf16>, tensor<1x1x1x128xbf16>) -> tensor<1x1x1x128xbf16>
    %326 = ttir.empty() : tensor<1x12x1x128xbf16>
    %327 = "ttir.broadcast"(%325, %326) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %328 = ttir.empty() : tensor<1x12x1x128xbf16>
    %329 = "ttir.add"(%305, %327, %328) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %330 = ttir.empty() : tensor<1x12x1x128xf32>
    %331 = "ttir.typecast"(%329, %330) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %332 = ttir.empty() : tensor<1x12x1xf32>
    %333 = "ttir.max"(%331, %332) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %334 = ttir.empty() : tensor<1x12x1x1xf32>
    %335 = "ttir.reshape"(%333, %334) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %336 = ttir.empty() : tensor<1x12x1x128xf32>
    %337 = "ttir.broadcast"(%335, %336) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %338 = ttir.empty() : tensor<1x12x1x128xf32>
    %339 = "ttir.subtract"(%331, %337, %338) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %340 = ttir.empty() : tensor<1x12x1x128xf32>
    %341 = "ttir.exp"(%339, %340) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %342 = ttir.empty() : tensor<1x12x1xf32>
    %343 = "ttir.sum"(%341, %342) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %344 = ttir.empty() : tensor<1x12x1x1xf32>
    %345 = "ttir.reshape"(%343, %344) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %346 = ttir.empty() : tensor<1x12x1x128xf32>
    %347 = "ttir.broadcast"(%345, %346) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %348 = ttir.empty() : tensor<1x12x1x128xf32>
    %349 = "ttir.div"(%341, %347, %348) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %350 = ttir.empty() : tensor<1x12x1x128xbf16>
    %351 = "ttir.typecast"(%349, %350) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %352 = ttir.empty() : tensor<12x1x128xbf16>
    %353 = "ttir.reshape"(%351, %352) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %354 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %355 = "ttir.reshape"(%241, %354) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %356 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %357 = "ttir.broadcast"(%355, %356) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %358 = ttir.empty() : tensor<12x128x128xbf16>
    %359 = "ttir.reshape"(%357, %358) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %360 = "ttir.dot_general"(%353, %359) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %361 = ttir.empty() : tensor<1x1536xbf16>
    %362 = "ttir.reshape"(%360, %361) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16>, tensor<1x1536xbf16>) -> tensor<1x1536xbf16>
    %363 = ttir.empty() : tensor<1536x3072xbf16>
    %364 = "ttir.permute"(%29, %363) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %365 = "ttir.dot_general"(%362, %364) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
    %366 = ttir.empty() : tensor<1x3072xbf16>
    %367 = "ttir.all_reduce"(%365, %366) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %368 = ttir.empty() : tensor<1x1x3072xbf16>
    %369 = "ttir.reshape"(%367, %368) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %370 = ttir.empty() : tensor<1x1x3072xbf16>
    %371 = "ttir.add"(%140, %369, %370) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %372 = ttir.empty() : tensor<3072xf32>
    %373 = "ttir.typecast"(%39, %372) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %374 = ttir.empty() : tensor<1x1x3072xf32>
    %375 = "ttir.reshape"(%373, %374) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %376 = ttir.empty() : tensor<1x1x3072xf32>
    %377 = "ttir.typecast"(%371, %376) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %378 = ttir.empty() : tensor<1x1x3072xf32>
    %379 = "ttir.pow"(%377, %116, %378) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %380 = ttir.empty() : tensor<1x1xf32>
    %381 = "ttir.sum"(%379, %380) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %382 = ttir.empty() : tensor<1x1xf32>
    %383 = "ttir.multiply"(%381, %111, %382) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %384 = ttir.empty() : tensor<1x1x1xf32>
    %385 = "ttir.reshape"(%383, %384) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %386 = ttir.empty() : tensor<1x1x1xf32>
    %387 = "ttir.add"(%385, %152, %386) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %388 = ttir.empty() : tensor<1x1x1xf32>
    %389 = "ttir.rsqrt"(%387, %388) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %390 = ttir.empty() : tensor<1x1xf32>
    %391 = "ttir.reshape"(%389, %390) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %392 = ttir.empty() : tensor<1x1x1xf32>
    %393 = "ttir.reshape"(%391, %392) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %394 = ttir.empty() : tensor<1x1x3072xf32>
    %395 = "ttir.broadcast"(%393, %394) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %396 = ttir.empty() : tensor<1x1x3072xf32>
    %397 = "ttir.multiply"(%377, %395, %396) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %398 = ttir.empty() : tensor<1x1x3072xbf16>
    %399 = "ttir.typecast"(%397, %398) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %400 = ttir.empty() : tensor<1x1x3072xf32>
    %401 = "ttir.typecast"(%399, %400) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %402 = ttir.empty() : tensor<1x1x3072xf32>
    %403 = "ttir.multiply"(%375, %401, %402) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %404 = ttir.empty() : tensor<1x1x3072xbf16>
    %405 = "ttir.typecast"(%403, %404) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %406 = ttir.empty() : tensor<1x3072xbf16>
    %407 = "ttir.reshape"(%405, %406) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %408 = ttir.empty() : tensor<3072x4096xbf16>
    %409 = "ttir.permute"(%41, %408) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %410 = "ttir.dot_general"(%407, %409) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %411 = ttir.empty() : tensor<1x1x4096xbf16>
    %412 = "ttir.reshape"(%410, %411) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %413 = ttir.empty() : tensor<1x1x4096xf32>
    %414 = "ttir.typecast"(%412, %413) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %415 = ttir.empty() : tensor<1x1x4096xbf16>
    %416 = "ttir.sigmoid"(%412, %415) : (tensor<1x1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %417 = ttir.empty() : tensor<1x1x4096xf32>
    %418 = "ttir.typecast"(%416, %417) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %419 = ttir.empty() : tensor<1x1x4096xf32>
    %420 = "ttir.multiply"(%414, %418, %419) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %421 = ttir.empty() : tensor<1x1x4096xbf16>
    %422 = "ttir.typecast"(%420, %421) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %423 = ttir.empty() : tensor<1x1x4096xf32>
    %424 = "ttir.typecast"(%422, %423) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %425 = ttir.empty() : tensor<3072x4096xbf16>
    %426 = "ttir.permute"(%27, %425) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %427 = "ttir.dot_general"(%407, %426) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %428 = ttir.empty() : tensor<1x4096xf32>
    %429 = "ttir.typecast"(%427, %428) <{conservative_folding = false}> : (tensor<1x4096xbf16>, tensor<1x4096xf32>) -> tensor<1x4096xf32>
    %430 = ttir.empty() : tensor<1x1x4096xf32>
    %431 = "ttir.reshape"(%429, %430) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %432 = ttir.empty() : tensor<1x1x4096xf32>
    %433 = "ttir.multiply"(%424, %431, %432) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %434 = ttir.empty() : tensor<1x1x4096xbf16>
    %435 = "ttir.typecast"(%433, %434) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %436 = ttir.empty() : tensor<1x4096xbf16>
    %437 = "ttir.reshape"(%435, %436) <{shape = [1 : i32, 4096 : i32]}> : (tensor<1x1x4096xbf16>, tensor<1x4096xbf16>) -> tensor<1x4096xbf16>
    %438 = ttir.empty() : tensor<4096x3072xbf16>
    %439 = "ttir.permute"(%25, %438) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %440 = "ttir.dot_general"(%437, %439) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
    %441 = ttir.empty() : tensor<1x3072xbf16>
    %442 = "ttir.all_reduce"(%440, %441) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %443 = ttir.empty() : tensor<1x1x3072xbf16>
    %444 = "ttir.reshape"(%442, %443) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %445 = ttir.empty() : tensor<1x1x3072xbf16>
    %446 = "ttir.add"(%371, %444, %445) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %447 = ttir.empty() : tensor<1x1x3072xf32>
    %448 = "ttir.typecast"(%446, %447) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %449 = ttir.empty() : tensor<1x1x3072xf32>
    %450 = "ttir.pow"(%448, %116, %449) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %451 = ttir.empty() : tensor<1x1xf32>
    %452 = "ttir.sum"(%450, %451) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %453 = ttir.empty() : tensor<1x1xf32>
    %454 = "ttir.multiply"(%452, %111, %453) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %455 = ttir.empty() : tensor<1x1x1xf32>
    %456 = "ttir.reshape"(%454, %455) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %457 = ttir.empty() : tensor<1x1x1xf32>
    %458 = "ttir.add"(%456, %152, %457) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %459 = ttir.empty() : tensor<1x1x1xf32>
    %460 = "ttir.rsqrt"(%458, %459) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %461 = ttir.empty() : tensor<1x1xf32>
    %462 = "ttir.reshape"(%460, %461) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %463 = ttir.empty() : tensor<1x1x1xf32>
    %464 = "ttir.reshape"(%462, %463) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %465 = ttir.empty() : tensor<1x1x3072xf32>
    %466 = "ttir.broadcast"(%464, %465) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %467 = ttir.empty() : tensor<1x1x3072xf32>
    %468 = "ttir.multiply"(%448, %466, %467) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %469 = ttir.empty() : tensor<1x1x3072xbf16>
    %470 = "ttir.typecast"(%468, %469) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %471 = ttir.empty() : tensor<1x1x3072xf32>
    %472 = "ttir.typecast"(%470, %471) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %473 = ttir.empty() : tensor<1x1x3072xf32>
    %474 = "ttir.multiply"(%245, %472, %473) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %475 = ttir.empty() : tensor<1x1x3072xbf16>
    %476 = "ttir.typecast"(%474, %475) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %477 = ttir.empty() : tensor<1x3072xbf16>
    %478 = "ttir.reshape"(%476, %477) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %479 = ttir.empty() : tensor<3072x512xbf16>
    %480 = "ttir.permute"(%23, %479) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %481 = "ttir.dot_general"(%478, %480) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %482 = ttir.empty() : tensor<1x4x1x128xbf16>
    %483 = "ttir.reshape"(%481, %482) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %484 = ttir.empty() : tensor<1x4x1x128xf32>
    %485 = "ttir.typecast"(%483, %484) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %486 = ttir.empty() : tensor<1x4x1x128xf32>
    %487 = "ttir.multiply"(%485, %202, %486) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %488 = ttir.empty() : tensor<1x4x1x128xbf16>
    %489 = "ttir.typecast"(%487, %488) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %490 = ttir.empty() : tensor<1x4x1x64xbf16>
    %491 = "ttir.slice_static"(%483, %490) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %492 = ttir.empty() : tensor<1x4x1x64xbf16>
    %493 = "ttir.neg"(%491, %492) : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %494 = ttir.empty() : tensor<1x4x1x64xbf16>
    %495 = "ttir.slice_static"(%483, %494) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %496 = ttir.empty() : tensor<1x4x1x128xbf16>
    %497 = "ttir.concat"(%493, %495, %496) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %498 = ttir.empty() : tensor<1x4x1x128xf32>
    %499 = "ttir.typecast"(%497, %498) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %500 = ttir.empty() : tensor<1x4x1x128xf32>
    %501 = "ttir.multiply"(%499, %226, %500) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %502 = ttir.empty() : tensor<1x4x1x128xbf16>
    %503 = "ttir.typecast"(%501, %502) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %504 = ttir.empty() : tensor<1x4x1x128xbf16>
    %505 = "ttir.add"(%489, %503, %504) : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %506 = ttir.empty() : tensor<1x4x128x128xbf16>
    %507 = "ttir.scatter"(%45, %126, %505, %506) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %508 = ttir.empty() : tensor<3072x512xbf16>
    %509 = "ttir.permute"(%47, %508) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %510 = "ttir.dot_general"(%478, %509) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %511 = ttir.empty() : tensor<1x4x1x128xbf16>
    %512 = "ttir.reshape"(%510, %511) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %513 = ttir.empty() : tensor<1x4x128x128xbf16>
    %514 = "ttir.scatter"(%49, %126, %512, %513) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %515 = ttir.empty() : tensor<3072xf32>
    %516 = "ttir.typecast"(%65, %515) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %517 = ttir.empty() : tensor<1x1x3072xf32>
    %518 = "ttir.reshape"(%516, %517) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %519 = ttir.empty() : tensor<3072x1536xbf16>
    %520 = "ttir.permute"(%59, %519) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %521 = "ttir.dot_general"(%478, %520) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
    %522 = ttir.empty() : tensor<1x12x1x128xbf16>
    %523 = "ttir.reshape"(%521, %522) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %524 = ttir.empty() : tensor<1x12x1x128xf32>
    %525 = "ttir.typecast"(%523, %524) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %526 = ttir.empty() : tensor<1x12x1x128xf32>
    %527 = "ttir.multiply"(%525, %256, %526) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %528 = ttir.empty() : tensor<1x12x1x128xbf16>
    %529 = "ttir.typecast"(%527, %528) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %530 = ttir.empty() : tensor<1x12x1x64xbf16>
    %531 = "ttir.slice_static"(%523, %530) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %532 = ttir.empty() : tensor<1x12x1x64xbf16>
    %533 = "ttir.neg"(%531, %532) : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %534 = ttir.empty() : tensor<1x12x1x64xbf16>
    %535 = "ttir.slice_static"(%523, %534) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %536 = ttir.empty() : tensor<1x12x1x128xbf16>
    %537 = "ttir.concat"(%533, %535, %536) <{dim = 3 : si32}> : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %538 = ttir.empty() : tensor<1x12x1x128xf32>
    %539 = "ttir.typecast"(%537, %538) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %540 = ttir.empty() : tensor<1x12x1x128xf32>
    %541 = "ttir.multiply"(%539, %274, %540) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %542 = ttir.empty() : tensor<1x12x1x128xbf16>
    %543 = "ttir.typecast"(%541, %542) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %544 = ttir.empty() : tensor<1x12x1x128xbf16>
    %545 = "ttir.add"(%529, %543, %544) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %546 = ttir.empty() : tensor<12x1x128xbf16>
    %547 = "ttir.reshape"(%545, %546) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %548 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %549 = "ttir.reshape"(%507, %548) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %550 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %551 = "ttir.broadcast"(%549, %550) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %552 = ttir.empty() : tensor<1x12x128x128xbf16>
    %553 = "ttir.reshape"(%551, %552) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %554 = ttir.empty() : tensor<1x12x128x128xbf16>
    %555 = "ttir.permute"(%553, %554) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %556 = ttir.empty() : tensor<12x128x128xbf16>
    %557 = "ttir.reshape"(%555, %556) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %558 = "ttir.dot_general"(%547, %557) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %559 = ttir.empty() : tensor<12x1x128xf32>
    %560 = "ttir.typecast"(%558, %559) <{conservative_folding = false}> : (tensor<12x1x128xbf16>, tensor<12x1x128xf32>) -> tensor<12x1x128xf32>
    %561 = ttir.empty() : tensor<1x12x1x128xf32>
    %562 = "ttir.reshape"(%560, %561) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %563 = ttir.empty() : tensor<1x12x1x128xf32>
    %564 = "ttir.multiply"(%562, %301, %563) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %565 = ttir.empty() : tensor<1x12x1x128xbf16>
    %566 = "ttir.typecast"(%564, %565) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %567 = ttir.empty() : tensor<1x12x1x128xbf16>
    %568 = "ttir.add"(%566, %327, %567) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %569 = ttir.empty() : tensor<1x12x1x128xf32>
    %570 = "ttir.typecast"(%568, %569) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %571 = ttir.empty() : tensor<1x12x1xf32>
    %572 = "ttir.max"(%570, %571) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %573 = ttir.empty() : tensor<1x12x1x1xf32>
    %574 = "ttir.reshape"(%572, %573) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %575 = ttir.empty() : tensor<1x12x1x128xf32>
    %576 = "ttir.broadcast"(%574, %575) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %577 = ttir.empty() : tensor<1x12x1x128xf32>
    %578 = "ttir.subtract"(%570, %576, %577) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %579 = ttir.empty() : tensor<1x12x1x128xf32>
    %580 = "ttir.exp"(%578, %579) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %581 = ttir.empty() : tensor<1x12x1xf32>
    %582 = "ttir.sum"(%580, %581) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %583 = ttir.empty() : tensor<1x12x1x1xf32>
    %584 = "ttir.reshape"(%582, %583) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %585 = ttir.empty() : tensor<1x12x1x128xf32>
    %586 = "ttir.broadcast"(%584, %585) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %587 = ttir.empty() : tensor<1x12x1x128xf32>
    %588 = "ttir.div"(%580, %586, %587) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %589 = ttir.empty() : tensor<1x12x1x128xbf16>
    %590 = "ttir.typecast"(%588, %589) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %591 = ttir.empty() : tensor<12x1x128xbf16>
    %592 = "ttir.reshape"(%590, %591) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %593 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %594 = "ttir.reshape"(%514, %593) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %595 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %596 = "ttir.broadcast"(%594, %595) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %597 = ttir.empty() : tensor<12x128x128xbf16>
    %598 = "ttir.reshape"(%596, %597) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %599 = "ttir.dot_general"(%592, %598) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %600 = ttir.empty() : tensor<1x1536xbf16>
    %601 = "ttir.reshape"(%599, %600) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16>, tensor<1x1536xbf16>) -> tensor<1x1536xbf16>
    %602 = ttir.empty() : tensor<1536x3072xbf16>
    %603 = "ttir.permute"(%57, %602) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %604 = "ttir.dot_general"(%601, %603) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
    %605 = ttir.empty() : tensor<1x3072xbf16>
    %606 = "ttir.all_reduce"(%604, %605) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %607 = ttir.empty() : tensor<1x1x3072xbf16>
    %608 = "ttir.reshape"(%606, %607) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %609 = ttir.empty() : tensor<1x1x3072xbf16>
    %610 = "ttir.add"(%446, %608, %609) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %611 = ttir.empty() : tensor<3072xf32>
    %612 = "ttir.typecast"(%61, %611) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %613 = ttir.empty() : tensor<1x1x3072xf32>
    %614 = "ttir.reshape"(%612, %613) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %615 = ttir.empty() : tensor<1x1x3072xf32>
    %616 = "ttir.typecast"(%610, %615) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %617 = ttir.empty() : tensor<1x1x3072xf32>
    %618 = "ttir.pow"(%616, %116, %617) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %619 = ttir.empty() : tensor<1x1xf32>
    %620 = "ttir.sum"(%618, %619) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %621 = ttir.empty() : tensor<1x1xf32>
    %622 = "ttir.multiply"(%620, %111, %621) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %623 = ttir.empty() : tensor<1x1x1xf32>
    %624 = "ttir.reshape"(%622, %623) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %625 = ttir.empty() : tensor<1x1x1xf32>
    %626 = "ttir.add"(%624, %152, %625) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %627 = ttir.empty() : tensor<1x1x1xf32>
    %628 = "ttir.rsqrt"(%626, %627) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %629 = ttir.empty() : tensor<1x1xf32>
    %630 = "ttir.reshape"(%628, %629) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %631 = ttir.empty() : tensor<1x1x1xf32>
    %632 = "ttir.reshape"(%630, %631) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %633 = ttir.empty() : tensor<1x1x3072xf32>
    %634 = "ttir.broadcast"(%632, %633) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %635 = ttir.empty() : tensor<1x1x3072xf32>
    %636 = "ttir.multiply"(%616, %634, %635) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %637 = ttir.empty() : tensor<1x1x3072xbf16>
    %638 = "ttir.typecast"(%636, %637) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %639 = ttir.empty() : tensor<1x1x3072xf32>
    %640 = "ttir.typecast"(%638, %639) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %641 = ttir.empty() : tensor<1x1x3072xf32>
    %642 = "ttir.multiply"(%614, %640, %641) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %643 = ttir.empty() : tensor<1x1x3072xbf16>
    %644 = "ttir.typecast"(%642, %643) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %645 = ttir.empty() : tensor<1x3072xbf16>
    %646 = "ttir.reshape"(%644, %645) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %647 = ttir.empty() : tensor<3072x4096xbf16>
    %648 = "ttir.permute"(%63, %647) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %649 = "ttir.dot_general"(%646, %648) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %650 = ttir.empty() : tensor<1x1x4096xbf16>
    %651 = "ttir.reshape"(%649, %650) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %652 = ttir.empty() : tensor<1x1x4096xf32>
    %653 = "ttir.typecast"(%651, %652) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %654 = ttir.empty() : tensor<1x1x4096xbf16>
    %655 = "ttir.sigmoid"(%651, %654) : (tensor<1x1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %656 = ttir.empty() : tensor<1x1x4096xf32>
    %657 = "ttir.typecast"(%655, %656) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %658 = ttir.empty() : tensor<1x1x4096xf32>
    %659 = "ttir.multiply"(%653, %657, %658) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %660 = ttir.empty() : tensor<1x1x4096xbf16>
    %661 = "ttir.typecast"(%659, %660) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %662 = ttir.empty() : tensor<1x1x4096xf32>
    %663 = "ttir.typecast"(%661, %662) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %664 = ttir.empty() : tensor<3072x4096xbf16>
    %665 = "ttir.permute"(%55, %664) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %666 = "ttir.dot_general"(%646, %665) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %667 = ttir.empty() : tensor<1x4096xf32>
    %668 = "ttir.typecast"(%666, %667) <{conservative_folding = false}> : (tensor<1x4096xbf16>, tensor<1x4096xf32>) -> tensor<1x4096xf32>
    %669 = ttir.empty() : tensor<1x1x4096xf32>
    %670 = "ttir.reshape"(%668, %669) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %671 = ttir.empty() : tensor<1x1x4096xf32>
    %672 = "ttir.multiply"(%663, %670, %671) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %673 = ttir.empty() : tensor<1x1x4096xbf16>
    %674 = "ttir.typecast"(%672, %673) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %675 = ttir.empty() : tensor<1x4096xbf16>
    %676 = "ttir.reshape"(%674, %675) <{shape = [1 : i32, 4096 : i32]}> : (tensor<1x1x4096xbf16>, tensor<1x4096xbf16>) -> tensor<1x4096xbf16>
    %677 = ttir.empty() : tensor<4096x3072xbf16>
    %678 = "ttir.permute"(%53, %677) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %679 = "ttir.dot_general"(%676, %678) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
    %680 = ttir.empty() : tensor<1x3072xbf16>
    %681 = "ttir.all_reduce"(%679, %680) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %682 = ttir.empty() : tensor<1x1x3072xbf16>
    %683 = "ttir.reshape"(%681, %682) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %684 = ttir.empty() : tensor<1x1x3072xbf16>
    %685 = "ttir.add"(%610, %683, %684) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %686 = ttir.empty() : tensor<1x1x3072xf32>
    %687 = "ttir.typecast"(%685, %686) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %688 = ttir.empty() : tensor<1x1x3072xf32>
    %689 = "ttir.pow"(%687, %116, %688) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %690 = ttir.empty() : tensor<1x1xf32>
    %691 = "ttir.sum"(%689, %690) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %692 = ttir.empty() : tensor<1x1xf32>
    %693 = "ttir.multiply"(%691, %111, %692) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %694 = ttir.empty() : tensor<1x1x1xf32>
    %695 = "ttir.reshape"(%693, %694) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %696 = ttir.empty() : tensor<1x1x1xf32>
    %697 = "ttir.add"(%695, %152, %696) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %698 = ttir.empty() : tensor<1x1x1xf32>
    %699 = "ttir.rsqrt"(%697, %698) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %700 = ttir.empty() : tensor<1x1xf32>
    %701 = "ttir.reshape"(%699, %700) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %702 = ttir.empty() : tensor<1x1x1xf32>
    %703 = "ttir.reshape"(%701, %702) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %704 = ttir.empty() : tensor<1x1x3072xf32>
    %705 = "ttir.broadcast"(%703, %704) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %706 = ttir.empty() : tensor<1x1x3072xf32>
    %707 = "ttir.multiply"(%687, %705, %706) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %708 = ttir.empty() : tensor<1x1x3072xbf16>
    %709 = "ttir.typecast"(%707, %708) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %710 = ttir.empty() : tensor<1x1x3072xf32>
    %711 = "ttir.typecast"(%709, %710) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %712 = ttir.empty() : tensor<1x1x3072xf32>
    %713 = "ttir.multiply"(%518, %711, %712) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %714 = ttir.empty() : tensor<1x1x3072xbf16>
    %715 = "ttir.typecast"(%713, %714) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %716 = ttir.empty() : tensor<1x3072xbf16>
    %717 = "ttir.reshape"(%715, %716) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %718 = ttir.empty() : tensor<3072x512xbf16>
    %719 = "ttir.permute"(%51, %718) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %720 = "ttir.dot_general"(%717, %719) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %721 = ttir.empty() : tensor<1x4x1x128xbf16>
    %722 = "ttir.reshape"(%720, %721) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %723 = ttir.empty() : tensor<1x4x1x128xf32>
    %724 = "ttir.typecast"(%722, %723) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %725 = ttir.empty() : tensor<1x4x1x128xf32>
    %726 = "ttir.multiply"(%724, %202, %725) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %727 = ttir.empty() : tensor<1x4x1x128xbf16>
    %728 = "ttir.typecast"(%726, %727) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %729 = ttir.empty() : tensor<1x4x1x64xbf16>
    %730 = "ttir.slice_static"(%722, %729) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %731 = ttir.empty() : tensor<1x4x1x64xbf16>
    %732 = "ttir.neg"(%730, %731) : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %733 = ttir.empty() : tensor<1x4x1x64xbf16>
    %734 = "ttir.slice_static"(%722, %733) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %735 = ttir.empty() : tensor<1x4x1x128xbf16>
    %736 = "ttir.concat"(%732, %734, %735) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %737 = ttir.empty() : tensor<1x4x1x128xf32>
    %738 = "ttir.typecast"(%736, %737) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %739 = ttir.empty() : tensor<1x4x1x128xf32>
    %740 = "ttir.multiply"(%738, %226, %739) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %741 = ttir.empty() : tensor<1x4x1x128xbf16>
    %742 = "ttir.typecast"(%740, %741) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %743 = ttir.empty() : tensor<1x4x1x128xbf16>
    %744 = "ttir.add"(%728, %742, %743) : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %745 = ttir.empty() : tensor<1x4x128x128xbf16>
    %746 = "ttir.scatter"(%67, %126, %744, %745) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %747 = ttir.empty() : tensor<3072x512xbf16>
    %748 = "ttir.permute"(%69, %747) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %749 = "ttir.dot_general"(%717, %748) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %750 = ttir.empty() : tensor<1x4x1x128xbf16>
    %751 = "ttir.reshape"(%749, %750) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %752 = ttir.empty() : tensor<1x4x128x128xbf16>
    %753 = "ttir.scatter"(%71, %126, %751, %752) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %754 = ttir.empty() : tensor<3072xf32>
    %755 = "ttir.typecast"(%87, %754) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %756 = ttir.empty() : tensor<1x1x3072xf32>
    %757 = "ttir.reshape"(%755, %756) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %758 = ttir.empty() : tensor<3072x1536xbf16>
    %759 = "ttir.permute"(%81, %758) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %760 = "ttir.dot_general"(%717, %759) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
    %761 = ttir.empty() : tensor<1x12x1x128xbf16>
    %762 = "ttir.reshape"(%760, %761) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %763 = ttir.empty() : tensor<1x12x1x128xf32>
    %764 = "ttir.typecast"(%762, %763) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %765 = ttir.empty() : tensor<1x12x1x128xf32>
    %766 = "ttir.multiply"(%764, %256, %765) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %767 = ttir.empty() : tensor<1x12x1x128xbf16>
    %768 = "ttir.typecast"(%766, %767) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %769 = ttir.empty() : tensor<1x12x1x64xbf16>
    %770 = "ttir.slice_static"(%762, %769) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %771 = ttir.empty() : tensor<1x12x1x64xbf16>
    %772 = "ttir.neg"(%770, %771) : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %773 = ttir.empty() : tensor<1x12x1x64xbf16>
    %774 = "ttir.slice_static"(%762, %773) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %775 = ttir.empty() : tensor<1x12x1x128xbf16>
    %776 = "ttir.concat"(%772, %774, %775) <{dim = 3 : si32}> : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %777 = ttir.empty() : tensor<1x12x1x128xf32>
    %778 = "ttir.typecast"(%776, %777) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %779 = ttir.empty() : tensor<1x12x1x128xf32>
    %780 = "ttir.multiply"(%778, %274, %779) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %781 = ttir.empty() : tensor<1x12x1x128xbf16>
    %782 = "ttir.typecast"(%780, %781) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %783 = ttir.empty() : tensor<1x12x1x128xbf16>
    %784 = "ttir.add"(%768, %782, %783) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %785 = ttir.empty() : tensor<12x1x128xbf16>
    %786 = "ttir.reshape"(%784, %785) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %787 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %788 = "ttir.reshape"(%746, %787) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %789 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %790 = "ttir.broadcast"(%788, %789) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %791 = ttir.empty() : tensor<1x12x128x128xbf16>
    %792 = "ttir.reshape"(%790, %791) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %793 = ttir.empty() : tensor<1x12x128x128xbf16>
    %794 = "ttir.permute"(%792, %793) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %795 = ttir.empty() : tensor<12x128x128xbf16>
    %796 = "ttir.reshape"(%794, %795) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %797 = "ttir.dot_general"(%786, %796) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %798 = ttir.empty() : tensor<12x1x128xf32>
    %799 = "ttir.typecast"(%797, %798) <{conservative_folding = false}> : (tensor<12x1x128xbf16>, tensor<12x1x128xf32>) -> tensor<12x1x128xf32>
    %800 = ttir.empty() : tensor<1x12x1x128xf32>
    %801 = "ttir.reshape"(%799, %800) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %802 = ttir.empty() : tensor<1x12x1x128xf32>
    %803 = "ttir.multiply"(%801, %301, %802) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %804 = ttir.empty() : tensor<1x12x1x128xbf16>
    %805 = "ttir.typecast"(%803, %804) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %806 = ttir.empty() : tensor<1x12x1x128xbf16>
    %807 = "ttir.add"(%805, %327, %806) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %808 = ttir.empty() : tensor<1x12x1x128xf32>
    %809 = "ttir.typecast"(%807, %808) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %810 = ttir.empty() : tensor<1x12x1xf32>
    %811 = "ttir.max"(%809, %810) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %812 = ttir.empty() : tensor<1x12x1x1xf32>
    %813 = "ttir.reshape"(%811, %812) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %814 = ttir.empty() : tensor<1x12x1x128xf32>
    %815 = "ttir.broadcast"(%813, %814) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %816 = ttir.empty() : tensor<1x12x1x128xf32>
    %817 = "ttir.subtract"(%809, %815, %816) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %818 = ttir.empty() : tensor<1x12x1x128xf32>
    %819 = "ttir.exp"(%817, %818) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %820 = ttir.empty() : tensor<1x12x1xf32>
    %821 = "ttir.sum"(%819, %820) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %822 = ttir.empty() : tensor<1x12x1x1xf32>
    %823 = "ttir.reshape"(%821, %822) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %824 = ttir.empty() : tensor<1x12x1x128xf32>
    %825 = "ttir.broadcast"(%823, %824) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %826 = ttir.empty() : tensor<1x12x1x128xf32>
    %827 = "ttir.div"(%819, %825, %826) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %828 = ttir.empty() : tensor<1x12x1x128xbf16>
    %829 = "ttir.typecast"(%827, %828) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %830 = ttir.empty() : tensor<12x1x128xbf16>
    %831 = "ttir.reshape"(%829, %830) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %832 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %833 = "ttir.reshape"(%753, %832) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %834 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %835 = "ttir.broadcast"(%833, %834) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %836 = ttir.empty() : tensor<12x128x128xbf16>
    %837 = "ttir.reshape"(%835, %836) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %838 = "ttir.dot_general"(%831, %837) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %839 = ttir.empty() : tensor<1x1536xbf16>
    %840 = "ttir.reshape"(%838, %839) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16>, tensor<1x1536xbf16>) -> tensor<1x1536xbf16>
    %841 = ttir.empty() : tensor<1536x3072xbf16>
    %842 = "ttir.permute"(%79, %841) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %843 = "ttir.dot_general"(%840, %842) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
    %844 = ttir.empty() : tensor<1x3072xbf16>
    %845 = "ttir.all_reduce"(%843, %844) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %846 = ttir.empty() : tensor<1x1x3072xbf16>
    %847 = "ttir.reshape"(%845, %846) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %848 = ttir.empty() : tensor<1x1x3072xbf16>
    %849 = "ttir.add"(%685, %847, %848) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %850 = ttir.empty() : tensor<3072xf32>
    %851 = "ttir.typecast"(%83, %850) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %852 = ttir.empty() : tensor<1x1x3072xf32>
    %853 = "ttir.reshape"(%851, %852) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %854 = ttir.empty() : tensor<1x1x3072xf32>
    %855 = "ttir.typecast"(%849, %854) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %856 = ttir.empty() : tensor<1x1x3072xf32>
    %857 = "ttir.pow"(%855, %116, %856) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %858 = ttir.empty() : tensor<1x1xf32>
    %859 = "ttir.sum"(%857, %858) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %860 = ttir.empty() : tensor<1x1xf32>
    %861 = "ttir.multiply"(%859, %111, %860) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %862 = ttir.empty() : tensor<1x1x1xf32>
    %863 = "ttir.reshape"(%861, %862) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %864 = ttir.empty() : tensor<1x1x1xf32>
    %865 = "ttir.add"(%863, %152, %864) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %866 = ttir.empty() : tensor<1x1x1xf32>
    %867 = "ttir.rsqrt"(%865, %866) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %868 = ttir.empty() : tensor<1x1xf32>
    %869 = "ttir.reshape"(%867, %868) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %870 = ttir.empty() : tensor<1x1x1xf32>
    %871 = "ttir.reshape"(%869, %870) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %872 = ttir.empty() : tensor<1x1x3072xf32>
    %873 = "ttir.broadcast"(%871, %872) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %874 = ttir.empty() : tensor<1x1x3072xf32>
    %875 = "ttir.multiply"(%855, %873, %874) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %876 = ttir.empty() : tensor<1x1x3072xbf16>
    %877 = "ttir.typecast"(%875, %876) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %878 = ttir.empty() : tensor<1x1x3072xf32>
    %879 = "ttir.typecast"(%877, %878) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %880 = ttir.empty() : tensor<1x1x3072xf32>
    %881 = "ttir.multiply"(%853, %879, %880) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %882 = ttir.empty() : tensor<1x1x3072xbf16>
    %883 = "ttir.typecast"(%881, %882) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %884 = ttir.empty() : tensor<1x3072xbf16>
    %885 = "ttir.reshape"(%883, %884) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %886 = ttir.empty() : tensor<3072x4096xbf16>
    %887 = "ttir.permute"(%85, %886) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %888 = "ttir.dot_general"(%885, %887) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %889 = ttir.empty() : tensor<1x1x4096xbf16>
    %890 = "ttir.reshape"(%888, %889) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %891 = ttir.empty() : tensor<1x1x4096xf32>
    %892 = "ttir.typecast"(%890, %891) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %893 = ttir.empty() : tensor<1x1x4096xbf16>
    %894 = "ttir.sigmoid"(%890, %893) : (tensor<1x1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %895 = ttir.empty() : tensor<1x1x4096xf32>
    %896 = "ttir.typecast"(%894, %895) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %897 = ttir.empty() : tensor<1x1x4096xf32>
    %898 = "ttir.multiply"(%892, %896, %897) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %899 = ttir.empty() : tensor<1x1x4096xbf16>
    %900 = "ttir.typecast"(%898, %899) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %901 = ttir.empty() : tensor<1x1x4096xf32>
    %902 = "ttir.typecast"(%900, %901) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %903 = ttir.empty() : tensor<3072x4096xbf16>
    %904 = "ttir.permute"(%77, %903) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %905 = "ttir.dot_general"(%885, %904) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %906 = ttir.empty() : tensor<1x4096xf32>
    %907 = "ttir.typecast"(%905, %906) <{conservative_folding = false}> : (tensor<1x4096xbf16>, tensor<1x4096xf32>) -> tensor<1x4096xf32>
    %908 = ttir.empty() : tensor<1x1x4096xf32>
    %909 = "ttir.reshape"(%907, %908) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %910 = ttir.empty() : tensor<1x1x4096xf32>
    %911 = "ttir.multiply"(%902, %909, %910) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %912 = ttir.empty() : tensor<1x1x4096xbf16>
    %913 = "ttir.typecast"(%911, %912) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %914 = ttir.empty() : tensor<1x4096xbf16>
    %915 = "ttir.reshape"(%913, %914) <{shape = [1 : i32, 4096 : i32]}> : (tensor<1x1x4096xbf16>, tensor<1x4096xbf16>) -> tensor<1x4096xbf16>
    %916 = ttir.empty() : tensor<4096x3072xbf16>
    %917 = "ttir.permute"(%75, %916) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %918 = "ttir.dot_general"(%915, %917) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
    %919 = ttir.empty() : tensor<1x3072xbf16>
    %920 = "ttir.all_reduce"(%918, %919) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %921 = ttir.empty() : tensor<1x1x3072xbf16>
    %922 = "ttir.reshape"(%920, %921) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %923 = ttir.empty() : tensor<1x1x3072xbf16>
    %924 = "ttir.add"(%849, %922, %923) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %925 = ttir.empty() : tensor<1x1x3072xf32>
    %926 = "ttir.typecast"(%924, %925) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %927 = ttir.empty() : tensor<1x1x3072xf32>
    %928 = "ttir.pow"(%926, %116, %927) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %929 = ttir.empty() : tensor<1x1xf32>
    %930 = "ttir.sum"(%928, %929) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %931 = ttir.empty() : tensor<1x1xf32>
    %932 = "ttir.multiply"(%930, %111, %931) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %933 = ttir.empty() : tensor<1x1x1xf32>
    %934 = "ttir.reshape"(%932, %933) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %935 = ttir.empty() : tensor<1x1x1xf32>
    %936 = "ttir.add"(%934, %152, %935) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %937 = ttir.empty() : tensor<1x1x1xf32>
    %938 = "ttir.rsqrt"(%936, %937) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %939 = ttir.empty() : tensor<1x1xf32>
    %940 = "ttir.reshape"(%938, %939) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %941 = ttir.empty() : tensor<1x1x1xf32>
    %942 = "ttir.reshape"(%940, %941) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %943 = ttir.empty() : tensor<1x1x3072xf32>
    %944 = "ttir.broadcast"(%942, %943) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %945 = ttir.empty() : tensor<1x1x3072xf32>
    %946 = "ttir.multiply"(%926, %944, %945) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %947 = ttir.empty() : tensor<1x1x3072xbf16>
    %948 = "ttir.typecast"(%946, %947) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %949 = ttir.empty() : tensor<1x1x3072xf32>
    %950 = "ttir.typecast"(%948, %949) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %951 = ttir.empty() : tensor<1x1x3072xf32>
    %952 = "ttir.multiply"(%757, %950, %951) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %953 = ttir.empty() : tensor<1x1x3072xbf16>
    %954 = "ttir.typecast"(%952, %953) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %955 = ttir.empty() : tensor<1x3072xbf16>
    %956 = "ttir.reshape"(%954, %955) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %957 = ttir.empty() : tensor<3072x512xbf16>
    %958 = "ttir.permute"(%73, %957) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %959 = "ttir.dot_general"(%956, %958) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %960 = ttir.empty() : tensor<1x4x1x128xbf16>
    %961 = "ttir.reshape"(%959, %960) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %962 = ttir.empty() : tensor<1x4x1x128xf32>
    %963 = "ttir.typecast"(%961, %962) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %964 = ttir.empty() : tensor<1x4x1x128xf32>
    %965 = "ttir.multiply"(%963, %202, %964) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %966 = ttir.empty() : tensor<1x4x1x128xbf16>
    %967 = "ttir.typecast"(%965, %966) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %968 = ttir.empty() : tensor<1x4x1x64xbf16>
    %969 = "ttir.slice_static"(%961, %968) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %970 = ttir.empty() : tensor<1x4x1x64xbf16>
    %971 = "ttir.neg"(%969, %970) : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %972 = ttir.empty() : tensor<1x4x1x64xbf16>
    %973 = "ttir.slice_static"(%961, %972) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16>
    %974 = ttir.empty() : tensor<1x4x1x128xbf16>
    %975 = "ttir.concat"(%971, %973, %974) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %976 = ttir.empty() : tensor<1x4x1x128xf32>
    %977 = "ttir.typecast"(%975, %976) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %978 = ttir.empty() : tensor<1x4x1x128xf32>
    %979 = "ttir.multiply"(%977, %226, %978) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32>
    %980 = ttir.empty() : tensor<1x4x1x128xbf16>
    %981 = "ttir.typecast"(%979, %980) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %982 = ttir.empty() : tensor<1x4x1x128xbf16>
    %983 = "ttir.add"(%967, %981, %982) : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %984 = ttir.empty() : tensor<1x4x128x128xbf16>
    %985 = "ttir.scatter"(%89, %126, %983, %984) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %986 = ttir.empty() : tensor<3072x512xbf16>
    %987 = "ttir.permute"(%91, %986) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %988 = "ttir.dot_general"(%956, %987) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16>
    %989 = ttir.empty() : tensor<1x4x1x128xbf16>
    %990 = "ttir.reshape"(%988, %989) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16>
    %991 = ttir.empty() : tensor<1x4x128x128xbf16>
    %992 = "ttir.scatter"(%93, %126, %990, %991) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %993 = ttir.empty() : tensor<3072xf32>
    %994 = "ttir.typecast"(%107, %993) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %995 = ttir.empty() : tensor<1x1x3072xf32>
    %996 = "ttir.reshape"(%994, %995) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %997 = ttir.empty() : tensor<3072x1536xbf16>
    %998 = "ttir.permute"(%101, %997) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %999 = "ttir.dot_general"(%956, %998) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16>
    %1000 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1001 = "ttir.reshape"(%999, %1000) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1002 = ttir.empty() : tensor<1x12x1x128xf32>
    %1003 = "ttir.typecast"(%1001, %1002) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1004 = ttir.empty() : tensor<1x12x1x128xf32>
    %1005 = "ttir.multiply"(%1003, %256, %1004) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1006 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1007 = "ttir.typecast"(%1005, %1006) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1008 = ttir.empty() : tensor<1x12x1x64xbf16>
    %1009 = "ttir.slice_static"(%1001, %1008) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %1010 = ttir.empty() : tensor<1x12x1x64xbf16>
    %1011 = "ttir.neg"(%1009, %1010) : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %1012 = ttir.empty() : tensor<1x12x1x64xbf16>
    %1013 = "ttir.slice_static"(%1001, %1012) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16>
    %1014 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1015 = "ttir.concat"(%1011, %1013, %1014) <{dim = 3 : si32}> : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1016 = ttir.empty() : tensor<1x12x1x128xf32>
    %1017 = "ttir.typecast"(%1015, %1016) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1018 = ttir.empty() : tensor<1x12x1x128xf32>
    %1019 = "ttir.multiply"(%1017, %274, %1018) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1020 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1021 = "ttir.typecast"(%1019, %1020) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1022 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1023 = "ttir.add"(%1007, %1021, %1022) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1024 = ttir.empty() : tensor<12x1x128xbf16>
    %1025 = "ttir.reshape"(%1023, %1024) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %1026 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %1027 = "ttir.reshape"(%985, %1026) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %1028 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %1029 = "ttir.broadcast"(%1027, %1028) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %1030 = ttir.empty() : tensor<1x12x128x128xbf16>
    %1031 = "ttir.reshape"(%1029, %1030) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %1032 = ttir.empty() : tensor<1x12x128x128xbf16>
    %1033 = "ttir.permute"(%1031, %1032) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %1034 = ttir.empty() : tensor<12x128x128xbf16>
    %1035 = "ttir.reshape"(%1033, %1034) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %1036 = "ttir.dot_general"(%1025, %1035) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %1037 = ttir.empty() : tensor<12x1x128xf32>
    %1038 = "ttir.typecast"(%1036, %1037) <{conservative_folding = false}> : (tensor<12x1x128xbf16>, tensor<12x1x128xf32>) -> tensor<12x1x128xf32>
    %1039 = ttir.empty() : tensor<1x12x1x128xf32>
    %1040 = "ttir.reshape"(%1038, %1039) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1041 = ttir.empty() : tensor<1x12x1x128xf32>
    %1042 = "ttir.multiply"(%1040, %301, %1041) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1043 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1044 = "ttir.typecast"(%1042, %1043) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1045 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1046 = "ttir.add"(%1044, %327, %1045) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1047 = ttir.empty() : tensor<1x12x1x128xf32>
    %1048 = "ttir.typecast"(%1046, %1047) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1049 = ttir.empty() : tensor<1x12x1xf32>
    %1050 = "ttir.max"(%1048, %1049) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %1051 = ttir.empty() : tensor<1x12x1x1xf32>
    %1052 = "ttir.reshape"(%1050, %1051) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %1053 = ttir.empty() : tensor<1x12x1x128xf32>
    %1054 = "ttir.broadcast"(%1052, %1053) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1055 = ttir.empty() : tensor<1x12x1x128xf32>
    %1056 = "ttir.subtract"(%1048, %1054, %1055) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1057 = ttir.empty() : tensor<1x12x1x128xf32>
    %1058 = "ttir.exp"(%1056, %1057) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1059 = ttir.empty() : tensor<1x12x1xf32>
    %1060 = "ttir.sum"(%1058, %1059) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32>
    %1061 = ttir.empty() : tensor<1x12x1x1xf32>
    %1062 = "ttir.reshape"(%1060, %1061) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32>
    %1063 = ttir.empty() : tensor<1x12x1x128xf32>
    %1064 = "ttir.broadcast"(%1062, %1063) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1065 = ttir.empty() : tensor<1x12x1x128xf32>
    %1066 = "ttir.div"(%1058, %1064, %1065) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32>
    %1067 = ttir.empty() : tensor<1x12x1x128xbf16>
    %1068 = "ttir.typecast"(%1066, %1067) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16>
    %1069 = ttir.empty() : tensor<12x1x128xbf16>
    %1070 = "ttir.reshape"(%1068, %1069) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16>
    %1071 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %1072 = "ttir.reshape"(%992, %1071) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %1073 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %1074 = "ttir.broadcast"(%1072, %1073) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %1075 = ttir.empty() : tensor<12x128x128xbf16>
    %1076 = "ttir.reshape"(%1074, %1075) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %1077 = "ttir.dot_general"(%1070, %1076) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x1x128xbf16>
    %1078 = ttir.empty() : tensor<1x1536xbf16>
    %1079 = "ttir.reshape"(%1077, %1078) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16>, tensor<1x1536xbf16>) -> tensor<1x1536xbf16>
    %1080 = ttir.empty() : tensor<1536x3072xbf16>
    %1081 = "ttir.permute"(%99, %1080) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %1082 = "ttir.dot_general"(%1079, %1081) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16>
    %1083 = ttir.empty() : tensor<1x3072xbf16>
    %1084 = "ttir.all_reduce"(%1082, %1083) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %1085 = ttir.empty() : tensor<1x1x3072xbf16>
    %1086 = "ttir.reshape"(%1084, %1085) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1087 = ttir.empty() : tensor<1x1x3072xbf16>
    %1088 = "ttir.add"(%924, %1086, %1087) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1089 = ttir.empty() : tensor<3072xf32>
    %1090 = "ttir.typecast"(%103, %1089) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %1091 = ttir.empty() : tensor<1x1x3072xf32>
    %1092 = "ttir.reshape"(%1090, %1091) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1093 = ttir.empty() : tensor<1x1x3072xf32>
    %1094 = "ttir.typecast"(%1088, %1093) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1095 = ttir.empty() : tensor<1x1x3072xf32>
    %1096 = "ttir.pow"(%1094, %116, %1095) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1097 = ttir.empty() : tensor<1x1xf32>
    %1098 = "ttir.sum"(%1096, %1097) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %1099 = ttir.empty() : tensor<1x1xf32>
    %1100 = "ttir.multiply"(%1098, %111, %1099) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %1101 = ttir.empty() : tensor<1x1x1xf32>
    %1102 = "ttir.reshape"(%1100, %1101) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1103 = ttir.empty() : tensor<1x1x1xf32>
    %1104 = "ttir.add"(%1102, %152, %1103) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1105 = ttir.empty() : tensor<1x1x1xf32>
    %1106 = "ttir.rsqrt"(%1104, %1105) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1107 = ttir.empty() : tensor<1x1xf32>
    %1108 = "ttir.reshape"(%1106, %1107) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %1109 = ttir.empty() : tensor<1x1x1xf32>
    %1110 = "ttir.reshape"(%1108, %1109) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1111 = ttir.empty() : tensor<1x1x3072xf32>
    %1112 = "ttir.broadcast"(%1110, %1111) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1113 = ttir.empty() : tensor<1x1x3072xf32>
    %1114 = "ttir.multiply"(%1094, %1112, %1113) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1115 = ttir.empty() : tensor<1x1x3072xbf16>
    %1116 = "ttir.typecast"(%1114, %1115) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1117 = ttir.empty() : tensor<1x1x3072xf32>
    %1118 = "ttir.typecast"(%1116, %1117) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1119 = ttir.empty() : tensor<1x1x3072xf32>
    %1120 = "ttir.multiply"(%1092, %1118, %1119) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1121 = ttir.empty() : tensor<1x1x3072xbf16>
    %1122 = "ttir.typecast"(%1120, %1121) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1123 = ttir.empty() : tensor<1x3072xbf16>
    %1124 = "ttir.reshape"(%1122, %1123) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %1125 = ttir.empty() : tensor<3072x4096xbf16>
    %1126 = "ttir.permute"(%105, %1125) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %1127 = "ttir.dot_general"(%1124, %1126) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %1128 = ttir.empty() : tensor<1x1x4096xbf16>
    %1129 = "ttir.reshape"(%1127, %1128) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %1130 = ttir.empty() : tensor<1x1x4096xf32>
    %1131 = "ttir.typecast"(%1129, %1130) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %1132 = ttir.empty() : tensor<1x1x4096xbf16>
    %1133 = "ttir.sigmoid"(%1129, %1132) : (tensor<1x1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %1134 = ttir.empty() : tensor<1x1x4096xf32>
    %1135 = "ttir.typecast"(%1133, %1134) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %1136 = ttir.empty() : tensor<1x1x4096xf32>
    %1137 = "ttir.multiply"(%1131, %1135, %1136) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %1138 = ttir.empty() : tensor<1x1x4096xbf16>
    %1139 = "ttir.typecast"(%1137, %1138) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %1140 = ttir.empty() : tensor<1x1x4096xf32>
    %1141 = "ttir.typecast"(%1139, %1140) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %1142 = ttir.empty() : tensor<3072x4096xbf16>
    %1143 = "ttir.permute"(%97, %1142) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %1144 = "ttir.dot_general"(%1124, %1143) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16>
    %1145 = ttir.empty() : tensor<1x4096xf32>
    %1146 = "ttir.typecast"(%1144, %1145) <{conservative_folding = false}> : (tensor<1x4096xbf16>, tensor<1x4096xf32>) -> tensor<1x4096xf32>
    %1147 = ttir.empty() : tensor<1x1x4096xf32>
    %1148 = "ttir.reshape"(%1146, %1147) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %1149 = ttir.empty() : tensor<1x1x4096xf32>
    %1150 = "ttir.multiply"(%1141, %1148, %1149) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32>
    %1151 = ttir.empty() : tensor<1x1x4096xbf16>
    %1152 = "ttir.typecast"(%1150, %1151) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16>
    %1153 = ttir.empty() : tensor<1x4096xbf16>
    %1154 = "ttir.reshape"(%1152, %1153) <{shape = [1 : i32, 4096 : i32]}> : (tensor<1x1x4096xbf16>, tensor<1x4096xbf16>) -> tensor<1x4096xbf16>
    %1155 = ttir.empty() : tensor<4096x3072xbf16>
    %1156 = "ttir.permute"(%95, %1155) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %1157 = "ttir.dot_general"(%1154, %1156) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16>
    %1158 = ttir.empty() : tensor<1x3072xbf16>
    %1159 = "ttir.all_reduce"(%1157, %1158) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %1160 = ttir.empty() : tensor<1x1x3072xbf16>
    %1161 = "ttir.reshape"(%1159, %1160) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1162 = ttir.empty() : tensor<1x1x3072xbf16>
    %1163 = "ttir.add"(%1088, %1161, %1162) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1164 = ttir.empty() : tensor<1x1x3072xf32>
    %1165 = "ttir.typecast"(%1163, %1164) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1166 = ttir.empty() : tensor<1x1x3072xf32>
    %1167 = "ttir.pow"(%1165, %116, %1166) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1168 = ttir.empty() : tensor<1x1xf32>
    %1169 = "ttir.sum"(%1167, %1168) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %1170 = ttir.empty() : tensor<1x1xf32>
    %1171 = "ttir.multiply"(%1169, %111, %1170) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %1172 = ttir.empty() : tensor<1x1x1xf32>
    %1173 = "ttir.reshape"(%1171, %1172) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1174 = ttir.empty() : tensor<1x1x1xf32>
    %1175 = "ttir.add"(%1173, %152, %1174) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1176 = ttir.empty() : tensor<1x1x1xf32>
    %1177 = "ttir.rsqrt"(%1175, %1176) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1178 = ttir.empty() : tensor<1x1xf32>
    %1179 = "ttir.reshape"(%1177, %1178) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32>
    %1180 = ttir.empty() : tensor<1x1x1xf32>
    %1181 = "ttir.reshape"(%1179, %1180) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %1182 = ttir.empty() : tensor<1x1x3072xf32>
    %1183 = "ttir.broadcast"(%1181, %1182) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1184 = ttir.empty() : tensor<1x1x3072xf32>
    %1185 = "ttir.multiply"(%1165, %1183, %1184) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1186 = ttir.empty() : tensor<1x1x3072xbf16>
    %1187 = "ttir.typecast"(%1185, %1186) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1188 = ttir.empty() : tensor<1x1x3072xf32>
    %1189 = "ttir.typecast"(%1187, %1188) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1190 = ttir.empty() : tensor<1x1x3072xf32>
    %1191 = "ttir.multiply"(%996, %1189, %1190) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %1192 = ttir.empty() : tensor<1x1x3072xbf16>
    %1193 = "ttir.typecast"(%1191, %1192) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %1194 = ttir.empty() : tensor<1x3072xbf16>
    %1195 = "ttir.reshape"(%1193, %1194) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16>
    %1196 = ttir.empty() : tensor<3072x64128xbf16>
    %1197 = "ttir.permute"(%11, %1196) <{permutation = array<i64: 1, 0>}> : (tensor<64128x3072xbf16>, tensor<3072x64128xbf16>) -> tensor<3072x64128xbf16>
    %1198 = "ttir.dot_general"(%1195, %1197) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x64128xbf16>) -> tensor<1x64128xbf16>
    %1199 = ttir.empty() : tensor<1x1x64128xbf16>
    %1200 = "ttir.reshape"(%1198, %1199) <{shape = [1 : i32, 1 : i32, 64128 : i32]}> : (tensor<1x64128xbf16>, tensor<1x1x64128xbf16>) -> tensor<1x1x64128xbf16>
    %1201 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1202 = "ttir.mesh_shard"(%234, %1201) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1203 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1204 = "ttir.mesh_shard"(%241, %1203) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1205 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1206 = "ttir.mesh_shard"(%507, %1205) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1207 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1208 = "ttir.mesh_shard"(%514, %1207) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1209 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1210 = "ttir.mesh_shard"(%746, %1209) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1211 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1212 = "ttir.mesh_shard"(%753, %1211) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1213 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1214 = "ttir.mesh_shard"(%985, %1213) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1215 = ttir.empty() : tensor<1x8x128x128xbf16>
    %1216 = "ttir.mesh_shard"(%992, %1215) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %1217 = ttir.empty() : tensor<1x128256xbf16>
    %1218 = "ttir.mesh_shard"(%1198, %1217) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x64128xbf16>, tensor<1x128256xbf16>) -> tensor<1x128256xbf16>
    %1219 = ttir.empty() : tensor<1x1x128256xbf16>
    %1220 = "ttir.mesh_shard"(%1200, %1219) <{shard_dims = array<i64: -1, 2>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x64128xbf16>, tensor<1x1x128256xbf16>) -> tensor<1x1x128256xbf16>
    return %1202, %1204, %1206, %1208, %1210, %1212, %1214, %1216, %1218, %1220 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>
  }
}
module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.1204 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99776, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184736, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99776, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193056, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main_const_eval_0() -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 2.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        return %2 : tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
      }
      func.func @main(%arg0: tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg3: tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg4: tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg5: tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg6: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg7: tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg8: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg9: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg10: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg11: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg12: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg13: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg14: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg15: tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg16: tensor<1x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg17: tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg18: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg19: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg20: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg21: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg22: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg23: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg24: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg25: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg26: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg27: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg28: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg29: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg30: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg31: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg32: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg33: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg34: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg35: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg36: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg37: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg38: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg39: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg40: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg41: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg42: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg43: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg44: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg45: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg46: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg47: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg48: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg49: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg50: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg51: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg52: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg53: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128256xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x1x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x128256xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %1 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %2 = "ttnn.full"(%1) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 3.25520843E-4 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<1x1>}> : (!ttnn.device) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %3 = "ttnn.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %4 = "ttnn.mesh_shard"(%arg1, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %5 = "ttnn.mesh_shard"(%arg2, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %6 = "ttnn.mesh_shard"(%arg3, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %7 = "ttnn.mesh_shard"(%arg4, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %8 = "ttnn.mesh_shard"(%arg5, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg5) <{force = false}> : (tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %9 = "ttnn.mesh_shard"(%arg6, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %10 = "ttnn.mesh_shard"(%arg8, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg8) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %11 = "ttnn.mesh_shard"(%arg9, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %12 = "ttnn.mesh_shard"(%arg10, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %13 = "ttnn.mesh_shard"(%arg11, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg11) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %14 = "ttnn.mesh_shard"(%arg12, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg12) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %15 = "ttnn.mesh_shard"(%arg13, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg13) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %16 = "ttnn.mesh_shard"(%arg14, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg14) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %17 = "ttnn.mesh_shard"(%arg15, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg15) <{force = false}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %18 = "ttnn.mesh_shard"(%arg16, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg16) <{force = false}> : (tensor<1x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %19 = "ttnn.mesh_shard"(%arg17, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg17) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %20 = "ttnn.mesh_shard"(%arg18, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg18) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %21 = "ttnn.mesh_shard"(%arg19, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg19) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %22 = "ttnn.mesh_shard"(%arg20, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg20) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %23 = "ttnn.mesh_shard"(%arg21, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg21) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %24 = "ttnn.mesh_shard"(%arg22, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg22) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %25 = "ttnn.mesh_shard"(%arg23, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg23) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %26 = "ttnn.mesh_shard"(%arg24, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg24) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %27 = "ttnn.mesh_shard"(%arg25, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg25) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %28 = "ttnn.mesh_shard"(%arg26, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg26) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %29 = "ttnn.mesh_shard"(%arg27, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg27) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %30 = "ttnn.mesh_shard"(%arg28, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg28) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %31 = "ttnn.mesh_shard"(%arg29, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg29) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %32 = "ttnn.mesh_shard"(%arg30, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg30) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %33 = "ttnn.mesh_shard"(%arg31, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg31) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %34 = "ttnn.mesh_shard"(%arg32, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg32) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %35 = "ttnn.mesh_shard"(%arg33, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg33) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %36 = "ttnn.mesh_shard"(%arg34, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg34) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %37 = "ttnn.mesh_shard"(%arg35, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg35) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %38 = "ttnn.mesh_shard"(%arg36, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg36) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %39 = "ttnn.mesh_shard"(%arg37, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg37) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %40 = "ttnn.mesh_shard"(%arg38, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg38) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %41 = "ttnn.mesh_shard"(%arg39, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg39) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %42 = "ttnn.mesh_shard"(%arg40, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg40) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %43 = "ttnn.mesh_shard"(%arg41, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg41) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %44 = "ttnn.mesh_shard"(%arg42, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg42) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %45 = "ttnn.mesh_shard"(%arg43, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg43) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %46 = "ttnn.mesh_shard"(%arg44, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg44) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %47 = "ttnn.mesh_shard"(%arg45, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg45) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %48 = "ttnn.mesh_shard"(%arg46, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg46) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %49 = "ttnn.mesh_shard"(%arg47, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg47) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %50 = "ttnn.mesh_shard"(%arg48, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg48) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %51 = "ttnn.mesh_shard"(%arg49, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg49) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %52 = "ttnn.mesh_shard"(%arg50, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg50) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %53 = "ttnn.mesh_shard"(%arg51, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg51) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %54 = "ttnn.mesh_shard"(%arg52, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg52) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %55 = "ttnn.mesh_shard"(%arg53, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg53) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %56 = "ttnn.typecast"(%9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %57 = "ttnn.reshape"(%56) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%56) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %58 = "ttnn.typecast"(%7) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %59 = "ttnn.reshape"(%58) <{shape = [1 : i32]}> : (tensor<1x1xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%58) <{force = false}> : (tensor<1x1xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %60 = "ttnn.from_device"(%59) : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%59) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %61 = "ttnn.to_layout"(%60) <{layout = #ttnn.layout<row_major>}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%60) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>) -> ()
        %62 = "ttnn.to_device"(%61, %1) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%61) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #ttnn.buffer_type<system_memory>>>>) -> ()
        %63 = "ttnn.embedding"(%62, %8) : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%62) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %64 = "ttnn.reshape"(%63) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%63) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %65 = "ttnn.reduce_scatter"(%64, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%64) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %66 = "ttnn.all_gather"(%65, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%65) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %67 = "ttnn.reshape"(%66) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%66) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %68 = "ttnn.typecast"(%67) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %69 = "ttnn.reshape"(%68) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %70 = "ttnn.pow"(%69, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%69) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %71 = "ttnn.sum"(%70) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%70) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %72 = "ttnn.multiply"(%71, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%71) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %73 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %74 = "ttnn.add"(%72, %73) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%73) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%72) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %75 = "ttnn.rsqrt"(%74) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%74) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %76 = "ttnn.multiply"(%68, %75) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%75) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%68) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %77 = "ttnn.multiply"(%57, %76) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%76) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%57) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %78 = "ttnn.typecast"(%77) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%77) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %79 = "ttnn.matmul"(%78, %5) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %80 = "ttnn.reshape"(%79) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%79) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %81 = "ttnn.typecast"(%80) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %82 = "ttnn.reshape"(%4) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %83 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %84 = "ttnn.reshape"(%83) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%83) <{force = false}> : (tensor<1xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %85 = "ttnn.matmul"(%82, %84) <{transpose_a = false, transpose_b = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%84) <{force = false}> : (tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%82) <{force = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %86 = "ttnn.reshape"(%85) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%85) <{force = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %87 = "ttnn.concat"(%86, %86) <{dim = 2 : si32}> : (tensor<1x1x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%86) <{force = false}> : (tensor<1x1x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %88 = "ttnn.cos"(%87) : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %89 = "ttnn.reshape"(%88) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %90 = "ttnn.multiply"(%81, %89) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%81) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %91 = "ttnn.typecast"(%90) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%90) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %92 = "ttnn.slice_static"(%80) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %93 = "ttnn.neg"(%92) : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%92) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %94 = "ttnn.slice_static"(%80) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%80) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %95 = "ttnn.concat"(%93, %94) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%94) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%93) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %96 = "ttnn.typecast"(%95) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%95) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %97 = "ttnn.sin"(%87) : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%87) <{force = false}> : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %98 = "ttnn.reshape"(%97) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %99 = "ttnn.multiply"(%96, %98) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%96) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %100 = "ttnn.typecast"(%99) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%99) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %101 = "ttnn.add"(%91, %100) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%100) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%91) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %102 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%10, %101, %102) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%102) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%101) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %103 = "ttnn.matmul"(%78, %11) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %104 = "ttnn.reshape"(%103) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%103) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %105 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%12, %104, %105) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%105) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%104) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %106 = "ttnn.typecast"(%23) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %107 = "ttnn.reshape"(%106) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%106) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %108 = "ttnn.matmul"(%78, %20) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%78) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %109 = "ttnn.reshape"(%108) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %110 = "ttnn.typecast"(%108) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%108) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %111 = "ttnn.reshape"(%110) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%110) <{force = false}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %112 = "ttnn.multiply"(%111, %88) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%111) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %113 = "ttnn.typecast"(%112) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%112) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %114 = "ttnn.slice_static"(%109) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %115 = "ttnn.neg"(%114) : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%114) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %116 = "ttnn.reshape"(%115) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%115) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %117 = "ttnn.slice_static"(%109) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%109) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %118 = "ttnn.reshape"(%117) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%117) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %119 = "ttnn.concat"(%116, %118) <{dim = 2 : si32}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%118) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%116) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %120 = "ttnn.typecast"(%119) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%119) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %121 = "ttnn.multiply"(%120, %97) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%120) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %122 = "ttnn.typecast"(%121) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%121) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %123 = "ttnn.add"(%113, %122) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%122) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%113) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %124 = "ttnn.reshape"(%10) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %125 = "ttnn.repeat"(%124) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%124) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %126 = "ttnn.reshape"(%125) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%125) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %127 = "ttnn.permute"(%126) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%126) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %128 = "ttnn.reshape"(%127) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%127) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %129 = "ttnn.matmul"(%123, %128) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%128) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%123) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %130 = "ttnn.typecast"(%129) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%129) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %131 = "ttnn.reshape"(%130) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%130) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %132 = "ttnn.reshape"(%19) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %133 = "ttnn.multiply"(%131, %132) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%131) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %134 = "ttnn.typecast"(%133) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%133) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %135 = "ttnn.typecast"(%18) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<1x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %136 = "ttnn.reshape"(%135) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%135) <{force = false}> : (tensor<1x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %137 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %138 = "ttnn.reshape"(%17) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %139 = "ttnn.typecast"(%138) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%138) <{force = false}> : (tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %140 = "ttnn.typecast"(%137) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%137) <{force = false}> : (tensor<1x1x1x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %141 = "ttnn.gt"(%139, %140) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%140) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%139) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %142 = "ttnn.typecast"(%141) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%141) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %143 = "ttnn.typecast"(%142) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%142) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %144 = "ttnn.multiply"(%136, %143) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%143) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%136) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %145 = "ttnn.typecast"(%144) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%144) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %146 = "ttnn.add"(%134, %145) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%134) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %147 = "ttnn.typecast"(%146) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%146) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %148 = "ttnn.max"(%147) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %149 = "ttnn.neg"(%148) : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%148) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %150 = "ttnn.add"(%147, %149) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%149) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%147) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %151 = "ttnn.softmax"(%150) <{dimension = 3 : si32}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%150) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %152 = "ttnn.typecast"(%151) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%151) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %153 = "ttnn.reshape"(%152) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%152) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %154 = "ttnn.reshape"(%12) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %155 = "ttnn.repeat"(%154) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%154) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %156 = "ttnn.reshape"(%155) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%155) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %157 = "ttnn.matmul"(%153, %156) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%156) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%153) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %158 = "ttnn.reshape"(%157) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%157) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %159 = "ttnn.matmul"(%158, %16) <{transpose_a = false, transpose_b = true}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%158) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %160 = "ttnn.reshape"(%159) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%159) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %161 = "ttnn.reduce_scatter"(%160, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%160) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %162 = "ttnn.all_gather"(%161, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%161) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %163 = "ttnn.reshape"(%162) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%162) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %164 = "ttnn.add"(%67, %163) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%163) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%67) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %165 = "ttnn.typecast"(%21) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %166 = "ttnn.reshape"(%165) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%165) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %167 = "ttnn.typecast"(%164) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %168 = "ttnn.reshape"(%167) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %169 = "ttnn.pow"(%168, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%168) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %170 = "ttnn.sum"(%169) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%169) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %171 = "ttnn.multiply"(%170, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%170) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %172 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %173 = "ttnn.add"(%171, %172) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%172) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%171) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %174 = "ttnn.rsqrt"(%173) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%173) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %175 = "ttnn.multiply"(%167, %174) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%174) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%167) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %176 = "ttnn.multiply"(%166, %175) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%175) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%166) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %177 = "ttnn.typecast"(%176) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%176) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %178 = "ttnn.matmul"(%177, %22) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%22) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %179 = "ttnn.typecast"(%178) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %180 = "ttnn.sigmoid"(%178) : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%178) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %181 = "ttnn.typecast"(%180) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%180) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %182 = "ttnn.multiply"(%179, %181) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%181) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%179) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %183 = "ttnn.matmul"(%177, %15) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%177) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %184 = "ttnn.typecast"(%183) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%183) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %185 = "ttnn.multiply"(%182, %184) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%184) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%182) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %186 = "ttnn.typecast"(%185) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%185) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %187 = "ttnn.matmul"(%186, %14) <{transpose_a = false, transpose_b = true}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%186) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %188 = "ttnn.reshape"(%187) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%187) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %189 = "ttnn.reduce_scatter"(%188, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%188) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %190 = "ttnn.all_gather"(%189, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%189) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %191 = "ttnn.reshape"(%190) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%190) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %192 = "ttnn.add"(%164, %191) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%191) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%164) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %193 = "ttnn.typecast"(%192) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %194 = "ttnn.reshape"(%193) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %195 = "ttnn.pow"(%194, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%194) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %196 = "ttnn.sum"(%195) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%195) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %197 = "ttnn.multiply"(%196, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%196) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %198 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %199 = "ttnn.add"(%197, %198) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%198) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%197) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %200 = "ttnn.rsqrt"(%199) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%199) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %201 = "ttnn.multiply"(%193, %200) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%200) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%193) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %202 = "ttnn.multiply"(%107, %201) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%201) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%107) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %203 = "ttnn.typecast"(%202) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%202) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %204 = "ttnn.matmul"(%203, %13) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %205 = "ttnn.reshape"(%204) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%204) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %206 = "ttnn.typecast"(%205) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %207 = "ttnn.multiply"(%206, %89) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%206) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %208 = "ttnn.typecast"(%207) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%207) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %209 = "ttnn.slice_static"(%205) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %210 = "ttnn.neg"(%209) : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%209) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %211 = "ttnn.slice_static"(%205) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%205) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %212 = "ttnn.concat"(%210, %211) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%211) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%210) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %213 = "ttnn.typecast"(%212) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%212) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %214 = "ttnn.multiply"(%213, %98) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%213) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %215 = "ttnn.typecast"(%214) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%214) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %216 = "ttnn.add"(%208, %215) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%215) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%208) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %217 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%24, %216, %217) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%217) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%216) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %218 = "ttnn.matmul"(%203, %25) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%25) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %219 = "ttnn.reshape"(%218) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%218) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %220 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%26, %219, %220) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%220) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%219) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %221 = "ttnn.typecast"(%34) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%34) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %222 = "ttnn.reshape"(%221) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%221) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %223 = "ttnn.matmul"(%203, %31) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%203) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%31) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %224 = "ttnn.reshape"(%223) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %225 = "ttnn.typecast"(%223) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%223) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %226 = "ttnn.reshape"(%225) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%225) <{force = false}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %227 = "ttnn.multiply"(%226, %88) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%226) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %228 = "ttnn.typecast"(%227) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%227) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %229 = "ttnn.slice_static"(%224) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %230 = "ttnn.neg"(%229) : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%229) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %231 = "ttnn.reshape"(%230) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%230) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %232 = "ttnn.slice_static"(%224) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%224) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %233 = "ttnn.reshape"(%232) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%232) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %234 = "ttnn.concat"(%231, %233) <{dim = 2 : si32}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%233) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%231) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %235 = "ttnn.typecast"(%234) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%234) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %236 = "ttnn.multiply"(%235, %97) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%235) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %237 = "ttnn.typecast"(%236) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%236) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %238 = "ttnn.add"(%228, %237) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%237) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%228) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %239 = "ttnn.reshape"(%24) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %240 = "ttnn.repeat"(%239) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%239) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %241 = "ttnn.reshape"(%240) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%240) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %242 = "ttnn.permute"(%241) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%241) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %243 = "ttnn.reshape"(%242) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%242) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %244 = "ttnn.matmul"(%238, %243) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%243) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%238) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %245 = "ttnn.typecast"(%244) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%244) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %246 = "ttnn.reshape"(%245) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%245) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %247 = "ttnn.multiply"(%246, %132) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%246) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %248 = "ttnn.typecast"(%247) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%247) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %249 = "ttnn.add"(%248, %145) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%248) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %250 = "ttnn.typecast"(%249) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%249) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %251 = "ttnn.max"(%250) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %252 = "ttnn.neg"(%251) : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%251) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %253 = "ttnn.add"(%250, %252) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%252) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%250) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %254 = "ttnn.softmax"(%253) <{dimension = 3 : si32}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%253) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %255 = "ttnn.typecast"(%254) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%254) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %256 = "ttnn.reshape"(%255) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%255) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %257 = "ttnn.reshape"(%26) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %258 = "ttnn.repeat"(%257) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%257) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %259 = "ttnn.reshape"(%258) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%258) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %260 = "ttnn.matmul"(%256, %259) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%259) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%256) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %261 = "ttnn.reshape"(%260) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%260) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %262 = "ttnn.matmul"(%261, %30) <{transpose_a = false, transpose_b = true}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%261) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%30) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %263 = "ttnn.reshape"(%262) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%262) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %264 = "ttnn.reduce_scatter"(%263, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%263) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %265 = "ttnn.all_gather"(%264, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%264) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %266 = "ttnn.reshape"(%265) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%265) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %267 = "ttnn.add"(%192, %266) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%266) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%192) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %268 = "ttnn.typecast"(%32) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%32) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %269 = "ttnn.reshape"(%268) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%268) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %270 = "ttnn.typecast"(%267) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %271 = "ttnn.reshape"(%270) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %272 = "ttnn.pow"(%271, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%271) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %273 = "ttnn.sum"(%272) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%272) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %274 = "ttnn.multiply"(%273, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%273) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %275 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %276 = "ttnn.add"(%274, %275) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%275) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%274) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %277 = "ttnn.rsqrt"(%276) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%276) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %278 = "ttnn.multiply"(%270, %277) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%277) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%270) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %279 = "ttnn.multiply"(%269, %278) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%278) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%269) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %280 = "ttnn.typecast"(%279) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%279) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %281 = "ttnn.matmul"(%280, %33) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%33) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %282 = "ttnn.typecast"(%281) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %283 = "ttnn.sigmoid"(%281) : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%281) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %284 = "ttnn.typecast"(%283) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%283) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %285 = "ttnn.multiply"(%282, %284) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%284) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%282) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %286 = "ttnn.matmul"(%280, %29) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%280) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%29) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %287 = "ttnn.typecast"(%286) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%286) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %288 = "ttnn.multiply"(%285, %287) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%287) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%285) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %289 = "ttnn.typecast"(%288) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%288) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %290 = "ttnn.matmul"(%289, %28) <{transpose_a = false, transpose_b = true}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%289) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%28) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %291 = "ttnn.reshape"(%290) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%290) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %292 = "ttnn.reduce_scatter"(%291, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%291) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %293 = "ttnn.all_gather"(%292, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%292) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %294 = "ttnn.reshape"(%293) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%293) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %295 = "ttnn.add"(%267, %294) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%294) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%267) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %296 = "ttnn.typecast"(%295) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %297 = "ttnn.reshape"(%296) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %298 = "ttnn.pow"(%297, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%297) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %299 = "ttnn.sum"(%298) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%298) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %300 = "ttnn.multiply"(%299, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%299) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %301 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %302 = "ttnn.add"(%300, %301) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%301) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%300) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %303 = "ttnn.rsqrt"(%302) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%302) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %304 = "ttnn.multiply"(%296, %303) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%303) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%296) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %305 = "ttnn.multiply"(%222, %304) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%304) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%222) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %306 = "ttnn.typecast"(%305) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%305) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %307 = "ttnn.matmul"(%306, %27) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%27) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %308 = "ttnn.reshape"(%307) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%307) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %309 = "ttnn.typecast"(%308) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %310 = "ttnn.multiply"(%309, %89) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%309) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %311 = "ttnn.typecast"(%310) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%310) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %312 = "ttnn.slice_static"(%308) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %313 = "ttnn.neg"(%312) : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%312) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %314 = "ttnn.slice_static"(%308) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%308) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %315 = "ttnn.concat"(%313, %314) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%314) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%313) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %316 = "ttnn.typecast"(%315) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%315) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %317 = "ttnn.multiply"(%316, %98) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%316) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %318 = "ttnn.typecast"(%317) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%317) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %319 = "ttnn.add"(%311, %318) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%318) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%311) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %320 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%35, %319, %320) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%320) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%319) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %321 = "ttnn.matmul"(%306, %36) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%36) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %322 = "ttnn.reshape"(%321) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%321) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %323 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%37, %322, %323) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%323) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%322) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %324 = "ttnn.typecast"(%45) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%45) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %325 = "ttnn.reshape"(%324) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%324) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %326 = "ttnn.matmul"(%306, %42) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%306) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%42) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %327 = "ttnn.reshape"(%326) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %328 = "ttnn.typecast"(%326) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%326) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %329 = "ttnn.reshape"(%328) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%328) <{force = false}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %330 = "ttnn.multiply"(%329, %88) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%329) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %331 = "ttnn.typecast"(%330) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%330) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %332 = "ttnn.slice_static"(%327) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %333 = "ttnn.neg"(%332) : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%332) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %334 = "ttnn.reshape"(%333) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%333) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %335 = "ttnn.slice_static"(%327) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%327) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %336 = "ttnn.reshape"(%335) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%335) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %337 = "ttnn.concat"(%334, %336) <{dim = 2 : si32}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%336) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%334) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %338 = "ttnn.typecast"(%337) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%337) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %339 = "ttnn.multiply"(%338, %97) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%338) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %340 = "ttnn.typecast"(%339) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%339) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %341 = "ttnn.add"(%331, %340) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%340) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%331) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %342 = "ttnn.reshape"(%35) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %343 = "ttnn.repeat"(%342) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%342) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %344 = "ttnn.reshape"(%343) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%343) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %345 = "ttnn.permute"(%344) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%344) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %346 = "ttnn.reshape"(%345) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%345) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %347 = "ttnn.matmul"(%341, %346) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%346) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%341) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %348 = "ttnn.typecast"(%347) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%347) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %349 = "ttnn.reshape"(%348) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%348) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %350 = "ttnn.multiply"(%349, %132) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%349) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %351 = "ttnn.typecast"(%350) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%350) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %352 = "ttnn.add"(%351, %145) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%351) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %353 = "ttnn.typecast"(%352) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%352) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %354 = "ttnn.max"(%353) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %355 = "ttnn.neg"(%354) : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%354) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %356 = "ttnn.add"(%353, %355) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%355) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%353) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %357 = "ttnn.softmax"(%356) <{dimension = 3 : si32}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%356) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %358 = "ttnn.typecast"(%357) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%357) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %359 = "ttnn.reshape"(%358) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%358) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %360 = "ttnn.reshape"(%37) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %361 = "ttnn.repeat"(%360) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%360) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %362 = "ttnn.reshape"(%361) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%361) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %363 = "ttnn.matmul"(%359, %362) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%362) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%359) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %364 = "ttnn.reshape"(%363) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%363) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %365 = "ttnn.matmul"(%364, %41) <{transpose_a = false, transpose_b = true}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%364) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%41) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %366 = "ttnn.reshape"(%365) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%365) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %367 = "ttnn.reduce_scatter"(%366, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%366) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %368 = "ttnn.all_gather"(%367, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%367) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %369 = "ttnn.reshape"(%368) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%368) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %370 = "ttnn.add"(%295, %369) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%369) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%295) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %371 = "ttnn.typecast"(%43) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%43) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %372 = "ttnn.reshape"(%371) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%371) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %373 = "ttnn.typecast"(%370) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %374 = "ttnn.reshape"(%373) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %375 = "ttnn.pow"(%374, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%374) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %376 = "ttnn.sum"(%375) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%375) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %377 = "ttnn.multiply"(%376, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%376) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %378 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %379 = "ttnn.add"(%377, %378) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%378) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%377) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %380 = "ttnn.rsqrt"(%379) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%379) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %381 = "ttnn.multiply"(%373, %380) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%380) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%373) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %382 = "ttnn.multiply"(%372, %381) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%381) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%372) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %383 = "ttnn.typecast"(%382) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%382) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %384 = "ttnn.matmul"(%383, %44) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%44) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %385 = "ttnn.typecast"(%384) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %386 = "ttnn.sigmoid"(%384) : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%384) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %387 = "ttnn.typecast"(%386) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%386) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %388 = "ttnn.multiply"(%385, %387) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%387) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%385) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %389 = "ttnn.matmul"(%383, %40) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%383) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%40) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %390 = "ttnn.typecast"(%389) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%389) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %391 = "ttnn.multiply"(%388, %390) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%390) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%388) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %392 = "ttnn.typecast"(%391) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%391) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %393 = "ttnn.matmul"(%392, %39) <{transpose_a = false, transpose_b = true}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%392) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%39) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %394 = "ttnn.reshape"(%393) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%393) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %395 = "ttnn.reduce_scatter"(%394, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%394) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %396 = "ttnn.all_gather"(%395, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%395) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %397 = "ttnn.reshape"(%396) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%396) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %398 = "ttnn.add"(%370, %397) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%397) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%370) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %399 = "ttnn.typecast"(%398) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %400 = "ttnn.reshape"(%399) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %401 = "ttnn.pow"(%400, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%400) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %402 = "ttnn.sum"(%401) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%401) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %403 = "ttnn.multiply"(%402, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%402) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %404 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %405 = "ttnn.add"(%403, %404) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%404) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%403) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %406 = "ttnn.rsqrt"(%405) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%405) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %407 = "ttnn.multiply"(%399, %406) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%406) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%399) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %408 = "ttnn.multiply"(%325, %407) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%407) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%325) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %409 = "ttnn.typecast"(%408) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%408) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %410 = "ttnn.matmul"(%409, %38) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%38) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %411 = "ttnn.reshape"(%410) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%410) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %412 = "ttnn.typecast"(%411) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %413 = "ttnn.multiply"(%412, %89) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%412) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%89) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %414 = "ttnn.typecast"(%413) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%413) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %415 = "ttnn.slice_static"(%411) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %416 = "ttnn.neg"(%415) : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%415) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %417 = "ttnn.slice_static"(%411) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%411) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %418 = "ttnn.concat"(%416, %417) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%417) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%416) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %419 = "ttnn.typecast"(%418) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%418) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %420 = "ttnn.multiply"(%419, %98) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%419) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%98) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %421 = "ttnn.typecast"(%420) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%420) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %422 = "ttnn.add"(%414, %421) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%421) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%414) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %423 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.update_cache"(%46, %422, %423) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%423) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%422) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %424 = "ttnn.matmul"(%409, %47) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%47) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %425 = "ttnn.reshape"(%424) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%424) <{force = false}> : (tensor<1x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %426 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<1xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.update_cache"(%48, %425, %426) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%426) <{force = false}> : (tensor<1xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%425) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %427 = "ttnn.typecast"(%55) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%55) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %428 = "ttnn.reshape"(%427) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%427) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %429 = "ttnn.matmul"(%409, %52) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%409) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%52) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %430 = "ttnn.reshape"(%429) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %431 = "ttnn.typecast"(%429) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%429) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %432 = "ttnn.reshape"(%431) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%431) <{force = false}> : (tensor<1x1536xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %433 = "ttnn.multiply"(%432, %88) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%432) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%88) <{force = false}> : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %434 = "ttnn.typecast"(%433) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%433) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %435 = "ttnn.slice_static"(%430) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %436 = "ttnn.neg"(%435) : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%435) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %437 = "ttnn.reshape"(%436) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%436) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %438 = "ttnn.slice_static"(%430) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%430) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %439 = "ttnn.reshape"(%438) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%438) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %440 = "ttnn.concat"(%437, %439) <{dim = 2 : si32}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%439) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%437) <{force = false}> : (tensor<12x1x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %441 = "ttnn.typecast"(%440) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%440) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %442 = "ttnn.multiply"(%441, %97) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%441) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%97) <{force = false}> : (tensor<1x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %443 = "ttnn.typecast"(%442) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%442) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %444 = "ttnn.add"(%434, %443) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%443) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%434) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %445 = "ttnn.reshape"(%46) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %446 = "ttnn.repeat"(%445) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%445) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %447 = "ttnn.reshape"(%446) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%446) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %448 = "ttnn.permute"(%447) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%447) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %449 = "ttnn.reshape"(%448) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%448) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %450 = "ttnn.matmul"(%444, %449) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%449) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%444) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %451 = "ttnn.typecast"(%450) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%450) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %452 = "ttnn.reshape"(%451) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%451) <{force = false}> : (tensor<12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %453 = "ttnn.multiply"(%452, %132) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%452) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%132) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %454 = "ttnn.typecast"(%453) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%453) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %455 = "ttnn.add"(%454, %145) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%454) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%145) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %456 = "ttnn.typecast"(%455) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%455) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %457 = "ttnn.max"(%456) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %458 = "ttnn.neg"(%457) : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%457) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %459 = "ttnn.add"(%456, %458) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%458) <{force = false}> : (tensor<1x12x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%456) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %460 = "ttnn.softmax"(%459) <{dimension = 3 : si32}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%459) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %461 = "ttnn.typecast"(%460) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%460) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %462 = "ttnn.reshape"(%461) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%461) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %463 = "ttnn.reshape"(%48) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %464 = "ttnn.repeat"(%463) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%463) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %465 = "ttnn.reshape"(%464) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%464) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %466 = "ttnn.matmul"(%462, %465) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%465) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%462) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %467 = "ttnn.reshape"(%466) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%466) <{force = false}> : (tensor<12x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %468 = "ttnn.matmul"(%467, %51) <{transpose_a = false, transpose_b = true}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%467) <{force = false}> : (tensor<1x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%51) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %469 = "ttnn.reshape"(%468) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%468) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %470 = "ttnn.reduce_scatter"(%469, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%469) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %471 = "ttnn.all_gather"(%470, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%470) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %472 = "ttnn.reshape"(%471) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%471) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %473 = "ttnn.add"(%398, %472) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%472) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%398) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %474 = "ttnn.typecast"(%53) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%53) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %475 = "ttnn.reshape"(%474) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%474) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %476 = "ttnn.typecast"(%473) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %477 = "ttnn.reshape"(%476) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %478 = "ttnn.pow"(%477, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%477) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %479 = "ttnn.sum"(%478) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%478) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %480 = "ttnn.multiply"(%479, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%479) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %481 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %482 = "ttnn.add"(%480, %481) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%481) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%480) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %483 = "ttnn.rsqrt"(%482) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%482) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %484 = "ttnn.multiply"(%476, %483) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%483) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%476) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %485 = "ttnn.multiply"(%475, %484) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%484) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%475) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %486 = "ttnn.typecast"(%485) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%485) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %487 = "ttnn.matmul"(%486, %54) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%54) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %488 = "ttnn.typecast"(%487) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %489 = "ttnn.sigmoid"(%487) : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%487) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %490 = "ttnn.typecast"(%489) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%489) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %491 = "ttnn.multiply"(%488, %490) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%490) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%488) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %492 = "ttnn.matmul"(%486, %50) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%486) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%50) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %493 = "ttnn.typecast"(%492) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%492) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %494 = "ttnn.multiply"(%491, %493) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%493) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%491) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %495 = "ttnn.typecast"(%494) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%494) <{force = false}> : (tensor<1x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %496 = "ttnn.matmul"(%495, %49) <{transpose_a = false, transpose_b = true}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%495) <{force = false}> : (tensor<1x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%49) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %497 = "ttnn.reshape"(%496) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%496) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %498 = "ttnn.reduce_scatter"(%497, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%497) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %499 = "ttnn.all_gather"(%498, %1) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%498) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %500 = "ttnn.reshape"(%499) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%499) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %501 = "ttnn.add"(%473, %500) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%500) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%473) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %502 = "ttnn.typecast"(%501) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%501) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %503 = "ttnn.reshape"(%502) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %504 = "ttnn.pow"(%503, %0) : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%503) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %505 = "ttnn.sum"(%504) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%504) <{force = false}> : (tensor<1x1x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %506 = "ttnn.multiply"(%505, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%505) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %507 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %508 = "ttnn.add"(%506, %507) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%507) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%506) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %509 = "ttnn.rsqrt"(%508) : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%508) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %510 = "ttnn.multiply"(%502, %509) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%509) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%502) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %511 = "ttnn.multiply"(%428, %510) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%510) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%428) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %512 = "ttnn.typecast"(%511) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%511) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %513 = "ttnn.matmul"(%512, %8) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%512) <{force = false}> : (tensor<1x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %514 = "ttnn.reshape"(%513) <{shape = [1 : i32, 1 : i32, 64128 : i32]}> : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %515 = "ttnn.to_layout"(%10) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %516 = "ttnn.from_device"(%515) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%515) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %517 = "ttnn.mesh_shard"(%516, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%516) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %518 = "ttnn.to_layout"(%12) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %519 = "ttnn.from_device"(%518) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%518) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %520 = "ttnn.mesh_shard"(%519, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%519) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %521 = "ttnn.to_layout"(%24) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%24) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %522 = "ttnn.from_device"(%521) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%521) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %523 = "ttnn.mesh_shard"(%522, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%522) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %524 = "ttnn.to_layout"(%26) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%26) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %525 = "ttnn.from_device"(%524) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%524) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %526 = "ttnn.mesh_shard"(%525, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%525) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %527 = "ttnn.to_layout"(%35) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%35) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %528 = "ttnn.from_device"(%527) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%527) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %529 = "ttnn.mesh_shard"(%528, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%528) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %530 = "ttnn.to_layout"(%37) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%37) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %531 = "ttnn.from_device"(%530) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%530) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %532 = "ttnn.mesh_shard"(%531, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%531) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %533 = "ttnn.to_layout"(%46) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%46) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %534 = "ttnn.from_device"(%533) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%533) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %535 = "ttnn.mesh_shard"(%534, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%534) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %536 = "ttnn.to_layout"(%48) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%48) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %537 = "ttnn.from_device"(%536) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%536) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %538 = "ttnn.mesh_shard"(%537, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%537) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %539 = "ttnn.to_layout"(%513) <{layout = #ttnn.layout<row_major>}> : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%513) <{force = false}> : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %540 = "ttnn.from_device"(%539) : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%539) <{force = false}> : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %541 = "ttnn.mesh_shard"(%540, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128256xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%540) <{force = false}> : (tensor<1x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %542 = "ttnn.to_layout"(%514) <{layout = #ttnn.layout<row_major>}> : (tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%514) <{force = false}> : (tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %543 = "ttnn.from_device"(%542) : (tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%542) <{force = false}> : (tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %544 = "ttnn.mesh_shard"(%543, %1) <{shard_dims = array<i64: -1, 2>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x1x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x128256xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%543) <{force = false}> : (tensor<1x1x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x64128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        return %517, %520, %523, %526, %529, %532, %535, %538, %541, %544 : tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128256xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x1x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x128256xbf16, #ttnn.buffer_type<system_memory>>>>
      }
    }
  }
}
Generated tokens: ['\\(', '\\(']
input 0: device = xla:0, shape torch.Size([128]) and shard spec {replicated}
input 1: device = xla:0, shape torch.Size([1, 128]) and shard spec {replicated}
input 2: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 2 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0791,  0.1982,  0.0928, -0.0488, -0.1318, -0.2119,  0.0471,  0.2295,
         0.2451,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 3: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 3 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0022, -0.0092,  0.0094,  0.0027, -0.0072, -0.0029, -0.0015, -0.0018,
        -0.0018,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 4: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 4 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0486,  0.0708,  0.0170, -0.0243, -0.1235, -0.1123, -0.0933, -0.0522,
        -0.0605,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 5: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 5 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0099,  0.0069,  0.0079,  0.0128,  0.0036,  0.0089,  0.0055, -0.0050,
        -0.0033,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 6: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 6 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0156, -0.1123, -0.1484, -0.1128, -0.0540, -0.0371,  0.0737,  0.0791,
         0.0374,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 7: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 7 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0055, -0.0099,  0.0272,  0.0189, -0.0014,  0.0098, -0.0119,  0.0033,
        -0.0020,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 8: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 8 and shape torch.Size([1, 8, 128, 128]): tensor([-0.2139, -0.2988, -0.1260, -0.0457,  0.0356,  0.0403, -0.0269, -0.0972,
        -0.2246,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 9: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 9 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0045, -0.0027,  0.0211,  0.0121,  0.0044, -0.0535, -0.0464, -0.0280,
        -0.0062,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 10: device = xla:0, shape torch.Size([1, 1]) and shard spec {replicated}
input 11: device = xla:0, shape torch.Size([128256, 3072]) and shard spec {devices=[2,1]<=[2]}
input 12: device = xla:0, shape torch.Size([1]) and shard spec {replicated}
input 13: device = xla:0, shape torch.Size([64]) and shard spec {replicated}
input 14: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 15: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 16: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 17: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 18: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 19: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 20: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 21: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 22: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 23: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 24: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 25: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 26: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 27: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 28: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 29: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 30: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 31: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 32: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 33: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 34: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 35: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 36: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 37: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 38: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 39: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 40: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 41: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 42: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 43: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 44: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 45: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 46: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 47: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 48: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 49: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 50: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
CPU logit shape:  torch.Size([1, 7, 128256]) XLA logit shape:  torch.Size([1, 1, 128256])
\([32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
Generated tokens: ['\\(', '\\(', '\\(']
input 0: device = xla:0, shape torch.Size([128]) and shard spec {replicated}
input 1: device = xla:0, shape torch.Size([1, 128]) and shard spec {replicated}
input 2: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 2 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0791,  0.1982,  0.0928, -0.0488, -0.1318, -0.2119,  0.0471,  0.2295,
         0.2451,  0.1660,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 3: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 3 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0022, -0.0092,  0.0094,  0.0027, -0.0072, -0.0029, -0.0015, -0.0018,
        -0.0018, -0.0018,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 4: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 4 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0486,  0.0708,  0.0170, -0.0243, -0.1235, -0.1123, -0.0933, -0.0522,
        -0.0605, -0.0525,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 5: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 5 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0099,  0.0069,  0.0079,  0.0128,  0.0036,  0.0089,  0.0055, -0.0050,
        -0.0033, -0.0031,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 6: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 6 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0156, -0.1123, -0.1484, -0.1128, -0.0540, -0.0371,  0.0737,  0.0791,
         0.0374,  0.0286,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 7: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 7 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0055, -0.0099,  0.0272,  0.0189, -0.0014,  0.0098, -0.0119,  0.0033,
        -0.0020, -0.0017,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 8: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 8 and shape torch.Size([1, 8, 128, 128]): tensor([-0.2139, -0.2988, -0.1260, -0.0457,  0.0356,  0.0403, -0.0269, -0.0972,
        -0.2246, -0.1177,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 9: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 9 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0045, -0.0027,  0.0211,  0.0121,  0.0044, -0.0535, -0.0464, -0.0280,
        -0.0062, -0.0042,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 10: device = xla:0, shape torch.Size([1, 1]) and shard spec {replicated}
input 11: device = xla:0, shape torch.Size([128256, 3072]) and shard spec {devices=[2,1]<=[2]}
input 12: device = xla:0, shape torch.Size([1]) and shard spec {replicated}
input 13: device = xla:0, shape torch.Size([64]) and shard spec {replicated}
input 14: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 15: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 16: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 17: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 18: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 19: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 20: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 21: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 22: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 23: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 24: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 25: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 26: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 27: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 28: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 29: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 30: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 31: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 32: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 33: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 34: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 35: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 36: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 37: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 38: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 39: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 40: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 41: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 42: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 43: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 44: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 45: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 46: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 47: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 48: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 49: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 50: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
CPU logit shape:  torch.Size([1, 7, 128256]) XLA logit shape:  torch.Size([1, 1, 128256])
\([32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
Generated tokens: ['\\(', '\\(', '\\(', '\\(']
input 0: device = xla:0, shape torch.Size([128]) and shard spec {replicated}
input 1: device = xla:0, shape torch.Size([1, 128]) and shard spec {replicated}
input 2: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 2 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0791,  0.1982,  0.0928, -0.0488, -0.1318, -0.2119,  0.0471,  0.2295,
         0.2451,  0.1660,  0.0620,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 3: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 3 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0022, -0.0092,  0.0094,  0.0027, -0.0072, -0.0029, -0.0015, -0.0018,
        -0.0018, -0.0018, -0.0018,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 4: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 4 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0486,  0.0708,  0.0170, -0.0243, -0.1235, -0.1123, -0.0933, -0.0522,
        -0.0605, -0.0525, -0.0486,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 5: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 5 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0099,  0.0069,  0.0079,  0.0128,  0.0036,  0.0089,  0.0055, -0.0050,
        -0.0033, -0.0031, -0.0040,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 6: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 6 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0156, -0.1123, -0.1484, -0.1128, -0.0540, -0.0371,  0.0737,  0.0791,
         0.0374,  0.0286,  0.0245,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 7: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 7 and shape torch.Size([1, 8, 128, 128]): tensor([ 0.0055, -0.0099,  0.0272,  0.0189, -0.0014,  0.0098, -0.0119,  0.0033,
        -0.0020, -0.0017, -0.0003,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 8: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 8 and shape torch.Size([1, 8, 128, 128]): tensor([-0.2139, -0.2988, -0.1260, -0.0457,  0.0356,  0.0403, -0.0269, -0.0972,
        -0.2246, -0.1177, -0.0781,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 9: device = xla:0, shape torch.Size([1, 8, 128, 128]) and shard spec {replicated}
[STATIC CACHE DUMP ]mean along seqlen for static cache @ input idx 9 and shape torch.Size([1, 8, 128, 128]): tensor([-0.0045, -0.0027,  0.0211,  0.0121,  0.0044, -0.0535, -0.0464, -0.0280,
        -0.0062, -0.0042, -0.0039,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       dtype=torch.bfloat16)
input 10: device = xla:0, shape torch.Size([1, 1]) and shard spec {replicated}
input 11: device = xla:0, shape torch.Size([128256, 3072]) and shard spec {devices=[2,1]<=[2]}
input 12: device = xla:0, shape torch.Size([1]) and shard spec {replicated}
input 13: device = xla:0, shape torch.Size([64]) and shard spec {replicated}
input 14: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 15: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 16: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 17: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 18: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 19: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 20: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 21: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 22: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 23: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 24: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 25: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 26: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 27: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 28: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 29: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 30: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 31: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 32: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 33: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 34: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 35: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 36: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 37: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 38: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 39: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 40: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 41: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 42: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[2,1]<=[2]}
input 43: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 44: device = xla:0, shape torch.Size([1024, 3072]) and shard spec {devices=[2,1]<=[2]}
input 45: device = xla:0, shape torch.Size([3072, 3072]) and shard spec {devices=[1,2]<=[2]}
input 46: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
input 47: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 48: device = xla:0, shape torch.Size([8192, 3072]) and shard spec {devices=[2,1]<=[2]}
input 49: device = xla:0, shape torch.Size([3072, 8192]) and shard spec {devices=[1,2]<=[2]}
input 50: device = xla:0, shape torch.Size([3072]) and shard spec {replicated}
CPU logit shape:  torch.Size([1, 7, 128256]) XLA logit shape:  torch.Size([1, 1, 128256])
 townGenerated tokens: ['\\(', '\\(', '\\(', '\\(', ' town']
PCCs: [0.1417515007624067, 0.09535665545136938, 0.10929091857852549, 0.1140910109360115, 0.10563158203748173]
PASSED

========================= 1 passed in 65.63s (0:01:05) =========================
