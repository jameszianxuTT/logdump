WARNING:root:Defaulting to PJRT_DEVICE=CPU
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.4.1, pluggy-1.6.0 -- /localdev/jameszianxu/test32/tt-torch/env/venv/bin/python3.10
cachedir: .pytest_cache
rootdir: /localdev/jameszianxu/test32/tt-torch
configfile: pytest.ini
plugins: cov-6.2.1, forked-1.6.0, xdist-3.8.0, split-0.10.0
collecting ... collected 1 item

tests/models/llama/test_llama3_generative.py::test_llama3_generate Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 51.87it/s]
2025-08-20 16:58:38.360 (   0.000s) [        5E2EB1C0]      dylib_platform.cc:47       1| DylibPlatform::SubclassInitialize
2025-08-20 16:58:38.362 (   0.001s) [        5E2EB1C0]     client_instance.cc:39       1| ClientInstance::ClientInstance
2025-08-20 16:58:38.362 (   0.001s) [        5E2EB1C0]              client.cc:18       1| TTClientInstance::TTClientInstance
2025-08-20 16:58:38.362 (   0.001s) [        5E2EB1C0]     client_instance.cc:60       1| ClientInstance::Initialize
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Device grid size = { 8, 8 }
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]              stubs.inc:112   WARN| STUB: PJRT_Client_TopologyDescription
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]      error_instance.cc:49       1| ErrorInstance::PJRT_Error_Message
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]      error_instance.cc:58       1| ErrorInstance::PJRT_Error_GetCode
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]      error_instance.cc:43       1| ErrorInstance::PJRT_Error_Destroy
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]     client_instance.cc:383      1| ClientInstance::PJRT_Client_PlatformVersion
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]     client_instance.cc:363      1| ClientInstance::PJRT_Client_PlatformName
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]     client_instance.cc:395      1| ClientInstance::PJRT_Client_Devices
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]     client_instance.cc:408      1| ClientInstance::PJRT_Client_AddressableDevices
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]     client_instance.cc:458      1| ClientInstance::PJRT_Client_AddressableMemories
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]        api_bindings.cc:76       1| PJRT_Plugin_Attributes
2025-08-20 16:58:42.138801: W torch_xla/csrc/runtime/profiler.cpp:88] Profiler API not found for PJRT plugin
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:42.138 (   3.778s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
Initial prompt: '<|begin_of_text|>I like taking walks in the'
Setting up XLA environment...
XLA environment configured.
Created device mesh: (1, 2) with 2 devices
<|begin_of_text|>I like taking walks in theNote: Using experimental XLA backend.
[XLA Debug] Processing 18 input specs:
[XLA Debug] Input 0: kind=InputKind.PARAMETER, arg=TensorArgument(name='p__fx_const_folded_attrs_0'), target=_FX_CONST_FOLDED_ATTRS.0
[XLA Debug] Input 0 is InputKind.PARAMETER, source tensor shape: torch.Size([128]), dtype: torch.int64, device: cpu
[XLA Debug] Input 0 not in cache - shape: torch.Size([128]), shard spec: None, moving to XLA device
[XLA Debug] Input 0 no sharding applied
[XLA Cache] Adding tensor to cache: key=(140280327987952, (128,), torch.int64, 'cpu'), xla_tensor_id=1, xla_sharding_spec=
[XLA Debug] Input 0 cached tensor with device: xla:0
[XLA Debug] Input 1: kind=InputKind.PARAMETER, arg=TensorArgument(name='p__fx_const_folded_attrs_1'), target=_FX_CONST_FOLDED_ATTRS.1
[XLA Debug] Input 1 is InputKind.PARAMETER, source tensor shape: torch.Size([7, 128]), dtype: torch.bfloat16, device: cpu
[XLA Debug] Input 1 not in cache - shape: torch.Size([7, 128]), shard spec: None, moving to XLA device
[XLA Debug] Input 1 no sharding applied
[XLA Cache] Adding tensor to cache: key=(140280327993952, (7, 128), torch.bfloat16, 'cpu'), xla_tensor_id=2, xla_sharding_spec=
[XLA Debug] Input 1 cached tensor with device: xla:0
[XLA Debug] Input 2: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___key_cache_0'), target=kwargs____past_key_values___key_cache_0
[XLA Debug] Input 2 is InputKind.BUFFER, source tensor shape: torch.Size([1, 8, 128, 128]), dtype: torch.bfloat16, device: cpu
[XLA Debug] Input 2 not in cache - shape: torch.Size([1, 8, 128, 128]), shard spec: (None, 'model', None, None), moving to XLA device
[XLA Debug] Input 2 applying shard spec: (None, 'model', None, None) with mesh: {'device_ids': [0, 1], 'mesh_shape': (1, 2), 'axis_names': ('batch', 'model')}
2025-08-20 16:58:44.162 (   5.802s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.162 (   5.802s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.163 (   5.803s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.163 (   5.803s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.163 (   5.803s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.164 (   5.803s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [1, 4, 128, 128] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.164 (   5.804s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.164 (   5.804s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.164 (   5.804s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.164 (   5.804s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.164 (   5.804s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.164 (   5.804s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [1, 4, 128, 128] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.164 (   5.804s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.165 (   5.804s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
[XLA Cache] Adding tensor to cache: key=(140279576504784, (1, 8, 128, 128), torch.bfloat16, 'cpu'), xla_tensor_id=3, xla_sharding_spec={devices=[1,2,1,1]<=[2]}
[XLA Debug] Input 2 cached tensor with device: xla:0
[XLA Debug] Input 3: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___value_cache_0'), target=kwargs____past_key_values___value_cache_0
[XLA Debug] Input 3 is InputKind.BUFFER, source tensor shape: torch.Size([1, 8, 128, 128]), dtype: torch.bfloat16, device: cpu
[XLA Debug] Input 3 not in cache - shape: torch.Size([1, 8, 128, 128]), shard spec: (None, 'model', None, None), moving to XLA device
[XLA Debug] Input 3 applying shard spec: (None, 'model', None, None) with mesh: {'device_ids': [0, 1], 'mesh_shape': (1, 2), 'axis_names': ('batch', 'model')}
2025-08-20 16:58:44.165 (   5.805s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.165 (   5.805s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.165 (   5.805s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.165 (   5.805s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.165 (   5.805s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.166 (   5.805s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [1, 4, 128, 128] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.166 (   5.805s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.166 (   5.805s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.166 (   5.805s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.166 (   5.805s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.166 (   5.805s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.166 (   5.806s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [1, 4, 128, 128] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.166 (   5.806s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.166 (   5.806s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
[XLA Cache] Adding tensor to cache: key=(140280331266032, (1, 8, 128, 128), torch.bfloat16, 'cpu'), xla_tensor_id=4, xla_sharding_spec={devices=[1,2,1,1]<=[2]}
[XLA Debug] Input 3 cached tensor with device: xla:0
[XLA Debug] Input 4: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_0'), target=None
[XLA Debug] Input 4 is USER_INPUT, adding None placeholder
[XLA Debug] Input 5: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_1'), target=None
[XLA Debug] Input 5 is USER_INPUT, adding None placeholder
[XLA Debug] Input 6: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_2'), target=None
[XLA Debug] Input 6 is USER_INPUT, adding None placeholder
[XLA Debug] Input 7: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_3'), target=None
[XLA Debug] Input 7 is USER_INPUT, adding None placeholder
[XLA Debug] Input 8: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_4'), target=None
[XLA Debug] Input 8 is USER_INPUT, adding None placeholder
[XLA Debug] Input 9: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_5'), target=None
[XLA Debug] Input 9 is USER_INPUT, adding None placeholder
[XLA Debug] Input 10: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_6'), target=None
[XLA Debug] Input 10 is USER_INPUT, adding None placeholder
[XLA Debug] Input 11: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_7'), target=None
[XLA Debug] Input 11 is USER_INPUT, adding None placeholder
[XLA Debug] Input 12: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_8'), target=None
[XLA Debug] Input 12 is USER_INPUT, adding None placeholder
[XLA Debug] Input 13: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_9'), target=None
[XLA Debug] Input 13 is USER_INPUT, adding None placeholder
[XLA Debug] Input 14: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_10'), target=None
[XLA Debug] Input 14 is USER_INPUT, adding None placeholder
[XLA Debug] Input 15: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_11'), target=None
[XLA Debug] Input 15 is USER_INPUT, adding None placeholder
[XLA Debug] Input 16: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_12'), target=None
[XLA Debug] Input 16 is USER_INPUT, adding None placeholder
[XLA Debug] Input 17: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_13'), target=None
[XLA Debug] Input 17 is USER_INPUT, adding None placeholder
[XLA Debug] Initialization complete - total inputs: 18, user input indices: [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]
2025-08-20 16:58:44.218 (   5.858s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.218 (   5.858s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.218 (   5.858s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.218 (   5.858s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.218 (   5.858s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.218 (   5.858s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [1, 7] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:58:44.219 (   5.858s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.219 (   5.858s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.219 (   5.858s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.219 (   5.858s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.219 (   5.858s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.219 (   5.858s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [1, 7] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:58:44.219 (   5.859s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.219 (   5.859s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
[james] In push tensors to device marking sharding (None, None)
[XLA Cache] Adding tensor to cache: key=(140280331271952, (1, 7), torch.int64, 'cpu'), xla_tensor_id=5, xla_sharding_spec={replicated}
2025-08-20 16:58:44.264 (   5.904s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.264 (   5.904s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.340 (   5.980s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.340 (   5.980s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.341 (   5.980s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.341 (   5.980s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [64128, 3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.341 (   5.981s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.341 (   5.981s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.341 (   5.981s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.341 (   5.981s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.341 (   5.981s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.341 (   5.981s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [64128, 3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.341 (   5.981s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.341 (   5.981s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
[james] In push tensors to device marking sharding ('model', None)
[XLA Cache] Adding tensor to cache: key=(140279541386992, (128256, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=6, xla_sharding_spec={devices=[2,1]<=[2]}
2025-08-20 16:58:44.461 (   6.101s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.461 (   6.101s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.462 (   6.101s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.462 (   6.101s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.462 (   6.101s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.462 (   6.101s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [7] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:58:44.462 (   6.102s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.462 (   6.102s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.462 (   6.102s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.462 (   6.102s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.462 (   6.102s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.462 (   6.102s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [7] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:58:44.462 (   6.102s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.462 (   6.102s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
[james] In push tensors to device marking sharding (None,)
[XLA Cache] Adding tensor to cache: key=(140280331258832, (7,), torch.int64, 'cpu'), xla_tensor_id=7, xla_sharding_spec={replicated}
[XLA Cache] Adding tensor to cache: key=(140279533236720, (64,), torch.float32, 'cpu'), xla_tensor_id=8, xla_sharding_spec=
[XLA Cache] Adding tensor to cache: key=(140279541383632, (3072,), torch.bfloat16, 'cpu'), xla_tensor_id=9, xla_sharding_spec=
2025-08-20 16:58:44.464 (   6.104s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.464 (   6.104s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.467 (   6.106s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.467 (   6.106s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.467 (   6.106s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.467 (   6.107s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [1536, 3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.467 (   6.107s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.467 (   6.107s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.467 (   6.107s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.467 (   6.107s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.467 (   6.107s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.467 (   6.107s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [1536, 3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.467 (   6.107s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.467 (   6.107s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
[james] In push tensors to device marking sharding ('model', None)
[XLA Cache] Adding tensor to cache: key=(140279532951552, (3072, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=10, xla_sharding_spec={devices=[2,1]<=[2]}
2025-08-20 16:58:44.468 (   6.108s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.468 (   6.108s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.468 (   6.108s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.468 (   6.108s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.468 (   6.108s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.469 (   6.108s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [512, 3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.469 (   6.108s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.469 (   6.108s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.469 (   6.108s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.469 (   6.108s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.469 (   6.108s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.469 (   6.109s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [512, 3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.469 (   6.109s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.469 (   6.109s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
[james] In push tensors to device marking sharding ('model', None)
[XLA Cache] Adding tensor to cache: key=(140279541383712, (1024, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=11, xla_sharding_spec={devices=[2,1]<=[2]}
2025-08-20 16:58:44.469 (   6.109s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.470 (   6.109s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.470 (   6.110s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.470 (   6.110s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.470 (   6.110s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.470 (   6.110s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [512, 3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.471 (   6.110s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.471 (   6.110s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.471 (   6.110s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.471 (   6.110s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.471 (   6.110s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.471 (   6.110s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [512, 3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.471 (   6.111s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.471 (   6.111s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
[james] In push tensors to device marking sharding ('model', None)
[XLA Cache] Adding tensor to cache: key=(140279532955392, (1024, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=12, xla_sharding_spec={devices=[2,1]<=[2]}
2025-08-20 16:58:44.472 (   6.112s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.472 (   6.112s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.476 (   6.116s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.476 (   6.116s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.476 (   6.116s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.477 (   6.116s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [3072, 1536] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.477 (   6.116s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.477 (   6.116s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.477 (   6.116s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.477 (   6.116s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.477 (   6.116s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.477 (   6.117s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [3072, 1536] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.477 (   6.117s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.477 (   6.117s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
[james] In push tensors to device marking sharding (None, 'model')
[XLA Cache] Adding tensor to cache: key=(140279532950752, (3072, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=13, xla_sharding_spec={devices=[1,2]<=[2]}
[XLA Cache] Adding tensor to cache: key=(140279541386192, (3072,), torch.bfloat16, 'cpu'), xla_tensor_id=14, xla_sharding_spec=
2025-08-20 16:58:44.480 (   6.120s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.481 (   6.120s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.487 (   6.126s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.487 (   6.126s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.487 (   6.127s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.487 (   6.127s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [4096, 3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.487 (   6.127s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.487 (   6.127s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.487 (   6.127s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.487 (   6.127s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.487 (   6.127s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.487 (   6.127s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [4096, 3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.488 (   6.127s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.488 (   6.127s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
[james] In push tensors to device marking sharding ('model', None)
[XLA Cache] Adding tensor to cache: key=(140279541384912, (8192, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=15, xla_sharding_spec={devices=[2,1]<=[2]}
2025-08-20 16:58:44.498 (   6.137s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.498 (   6.137s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.503 (   6.143s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.503 (   6.143s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.503 (   6.143s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.504 (   6.143s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [4096, 3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.504 (   6.143s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.504 (   6.143s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.504 (   6.144s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.504 (   6.144s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.504 (   6.144s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.504 (   6.144s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [4096, 3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.504 (   6.144s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.504 (   6.144s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
[james] In push tensors to device marking sharding ('model', None)
[XLA Cache] Adding tensor to cache: key=(140279541390272, (8192, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=16, xla_sharding_spec={devices=[2,1]<=[2]}
2025-08-20 16:58:44.514 (   6.153s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.514 (   6.154s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.522 (   6.161s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.522 (   6.161s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.522 (   6.161s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.522 (   6.162s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [3072, 4096] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.522 (   6.162s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.522 (   6.162s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.522 (   6.162s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.522 (   6.162s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.522 (   6.162s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.522 (   6.162s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [3072, 4096] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.523 (   6.162s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.523 (   6.162s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
[james] In push tensors to device marking sharding (None, 'model')
[XLA Cache] Adding tensor to cache: key=(140279541399072, (3072, 8192), torch.bfloat16, 'cpu'), xla_tensor_id=17, xla_sharding_spec={devices=[1,2]<=[2]}
[XLA Cache] Adding tensor to cache: key=(140279533239760, (3072,), torch.bfloat16, 'cpu'), xla_tensor_id=18, xla_sharding_spec=
2025-08-20 16:58:44.529 (   6.169s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.529 (   6.169s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.529 (   6.169s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.529 (   6.169s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.529 (   6.169s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.529 (   6.169s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [128] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:58:44.529 (   6.169s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.529 (   6.169s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.529 (   6.169s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.529 (   6.169s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.529 (   6.169s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.529 (   6.169s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [128] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:58:44.530 (   6.169s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.530 (   6.169s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.530 (   6.169s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.530 (   6.169s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [7, 128] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [7, 128] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [64] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.530 (   6.170s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.531 (   6.170s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [64] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.531 (   6.170s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.531 (   6.170s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [1] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [1] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.532 (   6.172s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.533 (   6.172s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.533 (   6.172s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.533 (   6.173s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.533 (   6.173s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.533 (   6.173s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.533 (   6.173s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.533 (   6.173s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.533 (   6.173s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.533 (   6.173s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.533 (   6.173s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.533 (   6.173s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.533 (   6.173s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.533 (   6.173s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.533 (   6.173s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.534 (   6.174s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.534 (   6.174s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.534 (   6.174s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.534 (   6.174s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.534 (   6.174s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.534 (   6.174s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [1] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:58:44.534 (   6.174s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.534 (   6.174s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.534 (   6.174s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.534 (   6.174s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.534 (   6.174s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.534 (   6.174s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [1] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:58:44.534 (   6.174s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.535 (   6.174s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.535 (   6.175s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.535 (   6.175s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.535 (   6.175s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.535 (   6.175s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.535 (   6.175s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.535 (   6.175s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [1] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.535 (   6.175s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.535 (   6.175s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.535 (   6.175s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.535 (   6.175s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.535 (   6.175s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.535 (   6.175s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [1] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.535 (   6.175s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.536 (   6.175s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.537 (   6.176s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.537 (   6.176s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.537 (   6.176s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.537 (   6.176s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.537 (   6.176s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.537 (   6.177s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.537 (   6.177s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.537 (   6.177s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.537 (   6.177s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.537 (   6.177s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.537 (   6.177s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.537 (   6.177s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.537 (   6.177s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.537 (   6.177s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [3072] (semantics: ZeroCopy/other)
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:58:44.538 (   6.178s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
BEFORE MARK STEP Enumerating input 0 with shape torch.Size([128]) and device xla:0
with xla tensor id 1 and sharding annotation 
BEFORE MARK STEP Enumerating input 1 with shape torch.Size([7, 128]) and device xla:0
with xla tensor id 2 and sharding annotation {replicated}
BEFORE MARK STEP Enumerating input 2 with shape torch.Size([1, 8, 128, 128]) and device xla:0
with xla tensor id 3 and sharding annotation {devices=[1,2,1,1]<=[2]}
BEFORE MARK STEP Enumerating input 3 with shape torch.Size([1, 8, 128, 128]) and device xla:0
with xla tensor id 4 and sharding annotation {devices=[1,2,1,1]<=[2]}
BEFORE MARK STEP Enumerating input 4 with shape torch.Size([1, 7]) and device xla:0
with xla tensor id 5 and sharding annotation {replicated}
BEFORE MARK STEP Enumerating input 5 with shape torch.Size([128256, 3072]) and device xla:0
with xla tensor id 6 and sharding annotation {devices=[2,1]<=[2]}
BEFORE MARK STEP Enumerating input 6 with shape torch.Size([7]) and device xla:0
with xla tensor id 7 and sharding annotation {replicated}
BEFORE MARK STEP Enumerating input 7 with shape torch.Size([64]) and device xla:0
with xla tensor id 8 and sharding annotation 
BEFORE MARK STEP Enumerating input 8 with shape torch.Size([3072]) and device xla:0
with xla tensor id 9 and sharding annotation {replicated}
BEFORE MARK STEP Enumerating input 9 with shape torch.Size([3072, 3072]) and device xla:0
with xla tensor id 10 and sharding annotation {devices=[2,1]<=[2]}
BEFORE MARK STEP Enumerating input 10 with shape torch.Size([1024, 3072]) and device xla:0
with xla tensor id 11 and sharding annotation {devices=[2,1]<=[2]}
BEFORE MARK STEP Enumerating input 11 with shape torch.Size([1024, 3072]) and device xla:0
with xla tensor id 12 and sharding annotation {devices=[2,1]<=[2]}
BEFORE MARK STEP Enumerating input 12 with shape torch.Size([3072, 3072]) and device xla:0
with xla tensor id 13 and sharding annotation {devices=[1,2]<=[2]}
BEFORE MARK STEP Enumerating input 13 with shape torch.Size([3072]) and device xla:0
with xla tensor id 14 and sharding annotation {replicated}
BEFORE MARK STEP Enumerating input 14 with shape torch.Size([8192, 3072]) and device xla:0
with xla tensor id 15 and sharding annotation {devices=[2,1]<=[2]}
BEFORE MARK STEP Enumerating input 15 with shape torch.Size([8192, 3072]) and device xla:0
with xla tensor id 16 and sharding annotation {devices=[2,1]<=[2]}
BEFORE MARK STEP Enumerating input 16 with shape torch.Size([3072, 8192]) and device xla:0
with xla tensor id 17 and sharding annotation {devices=[1,2]<=[2]}
BEFORE MARK STEP Enumerating input 17 with shape torch.Size([3072]) and device xla:0
with xla tensor id 18 and sharding annotation {replicated}
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.539 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.179s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.540 (   6.180s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.541 (   6.181s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.541 (   6.181s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.541 (   6.181s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:58:44.570 (   6.209s) [        5E2EB1C0]     client_instance.cc:471      1| ClientInstance::PJRT_Client_Compile
2025-08-20 16:58:44.570 (   6.209s) [        5E2EB1C0]      module_builder.cc:101      1| ModuleBuilder::buildModule
2025-08-20 16:58:44.573 (   6.213s) [        5E2EB1C0]      module_builder.cc:157      1| VHLO Module:
module @SyncTensorsGraph.374 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<7x!vhlo.i64_v1>, %arg1: !vhlo.tensor_v1<64x!vhlo.f32_v1>, %arg2: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg3: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg4: !vhlo.tensor_v1<1x7x!vhlo.i64_v1>, %arg5: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, %arg6: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg7: !vhlo.tensor_v1<!vhlo.i64_v1>, %arg8: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg9: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg10: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg11: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg12: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg13: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg14: !vhlo.tensor_v1<128x!vhlo.i64_v1>, %arg15: !vhlo.tensor_v1<7x128x!vhlo.bf16_v1>, %arg16: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg17: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg18: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg19: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg20: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<7xi64>>}> : () -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<3.25520843E-4> : tensor<1x7xf32>>}> : () -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %5 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %6 = "vhlo.compare_v1"(%arg0, %0) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.bool_v1>
    %7 = "vhlo.broadcast_in_dim_v1"(%arg7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %8 = "vhlo.add_v1"(%arg0, %7) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %9 = "vhlo.select_v1"(%6, %8, %arg0) : (!vhlo.tensor_v1<7x!vhlo.bool_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1x!vhlo.i64_v1>
    %11 = "vhlo.convert_v1"(%arg6) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %12 = "vhlo.broadcast_in_dim_v1"(%11) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %13 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %14 = "vhlo.convert_v1"(%13) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.ui32_v1>
    %15 = "vhlo.gather_v2"(%arg5, %14) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3072]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %16 = "vhlo.reshape_v1"(%15) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %17 = "vhlo.convert_v1"(%16) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %18 = "vhlo.power_v1"(%17, %5) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %19 = "vhlo.reduce_v1"(%18, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %189 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%189) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %20 = "vhlo.multiply_v1"(%19, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %21 = "vhlo.reshape_v1"(%20) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %22 = "vhlo.broadcast_in_dim_v1"(%arg3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %23 = "vhlo.add_v1"(%21, %22) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %24 = "vhlo.rsqrt_v2"(%23) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %25 = "vhlo.reshape_v1"(%24) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %26 = "vhlo.broadcast_in_dim_v1"(%25) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %27 = "vhlo.multiply_v1"(%17, %26) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %28 = "vhlo.convert_v1"(%27) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %29 = "vhlo.convert_v1"(%28) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %30 = "vhlo.multiply_v1"(%12, %29) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %31 = "vhlo.convert_v1"(%30) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %32 = "vhlo.reshape_v1"(%31) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %33 = "vhlo.transpose_v1"(%arg2) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %34 = "vhlo.dot_general_v2"(%32, %33) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %35 = "vhlo.reshape_v1"(%34) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %36 = "vhlo.transpose_v1"(%35) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %37 = "vhlo.convert_v1"(%36) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %38 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %39 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %40 = "vhlo.convert_v1"(%39) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1>
    %41 = "vhlo.dot_general_v2"(%38, %40) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x7x!vhlo.f32_v1>
    %42 = "vhlo.transpose_v1"(%41) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,7,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>
    %43 = "vhlo.concatenate_v1"(%42, %42) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %44 = "vhlo.cosine_v2"(%43) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %45 = "vhlo.convert_v1"(%44) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %46 = "vhlo.reshape_v1"(%45) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>
    %47 = "vhlo.convert_v1"(%46) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>
    %48 = "vhlo.reshape_v1"(%47) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %49 = "vhlo.broadcast_in_dim_v1"(%48) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %50 = "vhlo.multiply_v1"(%37, %49) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %51 = "vhlo.convert_v1"(%50) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %52 = "vhlo.slice_v1"(%36) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %53 = "vhlo.negate_v1"(%52) : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %54 = "vhlo.slice_v1"(%36) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %55 = "vhlo.concatenate_v1"(%53, %54) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %56 = "vhlo.convert_v1"(%55) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %57 = "vhlo.sine_v2"(%43) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %58 = "vhlo.convert_v1"(%57) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %59 = "vhlo.reshape_v1"(%58) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>
    %60 = "vhlo.convert_v1"(%59) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>
    %61 = "vhlo.reshape_v1"(%60) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %62 = "vhlo.broadcast_in_dim_v1"(%61) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %63 = "vhlo.multiply_v1"(%56, %62) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %64 = "vhlo.convert_v1"(%63) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %65 = "vhlo.add_v1"(%51, %64) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %66 = "vhlo.scatter_v2"(%arg8, %10, %65) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %67 = "vhlo.custom_call_v1"(%66) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %68 = "vhlo.transpose_v1"(%arg9) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %69 = "vhlo.dot_general_v2"(%32, %68) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %70 = "vhlo.reshape_v1"(%69) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %71 = "vhlo.transpose_v1"(%70) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %72 = "vhlo.scatter_v2"(%arg10, %10, %71) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %73 = "vhlo.custom_call_v1"(%72) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %74 = "vhlo.convert_v1"(%arg20) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %75 = "vhlo.broadcast_in_dim_v1"(%74) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %76 = "vhlo.transpose_v1"(%arg17) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %77 = "vhlo.dot_general_v2"(%32, %76) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %78 = "vhlo.reshape_v1"(%77) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %79 = "vhlo.transpose_v1"(%78) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %80 = "vhlo.convert_v1"(%79) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %81 = "vhlo.broadcast_in_dim_v1"(%48) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %82 = "vhlo.multiply_v1"(%80, %81) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %83 = "vhlo.convert_v1"(%82) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %84 = "vhlo.slice_v1"(%79) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %85 = "vhlo.negate_v1"(%84) : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %86 = "vhlo.slice_v1"(%79) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %87 = "vhlo.concatenate_v1"(%85, %86) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %88 = "vhlo.convert_v1"(%87) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %89 = "vhlo.broadcast_in_dim_v1"(%61) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %90 = "vhlo.multiply_v1"(%88, %89) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %91 = "vhlo.convert_v1"(%90) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %92 = "vhlo.add_v1"(%83, %91) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %93 = "vhlo.reshape_v1"(%92) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %94 = "vhlo.broadcast_in_dim_v1"(%66) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %95 = "vhlo.reshape_v1"(%94) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %96 = "vhlo.transpose_v1"(%95) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %97 = "vhlo.reshape_v1"(%96) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %98 = "vhlo.dot_general_v2"(%93, %97) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %99 = "vhlo.reshape_v1"(%98) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %100 = "vhlo.convert_v1"(%99) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %101 = "vhlo.broadcast_in_dim_v1"(%arg16) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %102 = "vhlo.multiply_v1"(%100, %101) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %103 = "vhlo.convert_v1"(%102) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %104 = "vhlo.convert_v1"(%arg15) : (!vhlo.tensor_v1<7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.f32_v1>
    %105 = "vhlo.broadcast_in_dim_v1"(%arg14) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.i64_v1>
    %106 = "vhlo.broadcast_in_dim_v1"(%arg0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.i64_v1>
    %107 = "vhlo.compare_v1"(%105, %106) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<7x128x!vhlo.i64_v1>, !vhlo.tensor_v1<7x128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.bool_v1>
    %108 = "vhlo.convert_v1"(%107) : (!vhlo.tensor_v1<7x128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.f32_v1>
    %109 = "vhlo.multiply_v1"(%104, %108) : (!vhlo.tensor_v1<7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.f32_v1>
    %110 = "vhlo.convert_v1"(%109) : (!vhlo.tensor_v1<7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x128x!vhlo.bf16_v1>
    %111 = "vhlo.reshape_v1"(%110) : (!vhlo.tensor_v1<7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %112 = "vhlo.broadcast_in_dim_v1"(%111) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %113 = "vhlo.add_v1"(%103, %112) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %114 = "vhlo.convert_v1"(%113) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %115 = "vhlo.reduce_v1"(%114, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %189 = "vhlo.maximum_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%189) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %116 = "vhlo.broadcast_in_dim_v1"(%115) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %117 = "vhlo.subtract_v1"(%114, %116) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %118 = "vhlo.exponential_v2"(%117) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %119 = "vhlo.reduce_v1"(%118, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %189 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%189) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %120 = "vhlo.broadcast_in_dim_v1"(%119) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %121 = "vhlo.divide_v1"(%118, %120) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %122 = "vhlo.convert_v1"(%121) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %123 = "vhlo.reshape_v1"(%122) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %124 = "vhlo.broadcast_in_dim_v1"(%72) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %125 = "vhlo.reshape_v1"(%124) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %126 = "vhlo.dot_general_v2"(%123, %125) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %127 = "vhlo.reshape_v1"(%126) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %128 = "vhlo.transpose_v1"(%127) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,7,24,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %129 = "vhlo.reshape_v1"(%128) : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %130 = "vhlo.transpose_v1"(%arg13) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %131 = "vhlo.dot_general_v2"(%129, %130) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %132 = "vhlo.reshape_v1"(%131) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %133 = "vhlo.add_v1"(%16, %132) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %134 = "vhlo.convert_v1"(%arg18) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %135 = "vhlo.broadcast_in_dim_v1"(%134) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %136 = "vhlo.convert_v1"(%133) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %137 = "vhlo.power_v1"(%136, %5) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %138 = "vhlo.reduce_v1"(%137, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %189 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%189) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %139 = "vhlo.multiply_v1"(%138, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %140 = "vhlo.reshape_v1"(%139) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %141 = "vhlo.add_v1"(%140, %22) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %142 = "vhlo.rsqrt_v2"(%141) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %143 = "vhlo.reshape_v1"(%142) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %144 = "vhlo.broadcast_in_dim_v1"(%143) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %145 = "vhlo.multiply_v1"(%136, %144) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %146 = "vhlo.convert_v1"(%145) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %147 = "vhlo.convert_v1"(%146) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %148 = "vhlo.multiply_v1"(%135, %147) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %149 = "vhlo.convert_v1"(%148) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %150 = "vhlo.reshape_v1"(%149) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %151 = "vhlo.transpose_v1"(%arg19) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %152 = "vhlo.dot_general_v2"(%150, %151) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %153 = "vhlo.reshape_v1"(%152) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %154 = "vhlo.convert_v1"(%153) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %155 = "vhlo.logistic_v2"(%153) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %156 = "vhlo.convert_v1"(%155) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %157 = "vhlo.multiply_v1"(%154, %156) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %158 = "vhlo.convert_v1"(%157) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %159 = "vhlo.convert_v1"(%158) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %160 = "vhlo.transpose_v1"(%arg12) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %161 = "vhlo.dot_general_v2"(%150, %160) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %162 = "vhlo.reshape_v1"(%161) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %163 = "vhlo.convert_v1"(%162) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %164 = "vhlo.multiply_v1"(%159, %163) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %165 = "vhlo.convert_v1"(%164) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %166 = "vhlo.reshape_v1"(%165) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %167 = "vhlo.transpose_v1"(%arg11) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %168 = "vhlo.dot_general_v2"(%166, %167) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %169 = "vhlo.reshape_v1"(%168) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %170 = "vhlo.add_v1"(%133, %169) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %171 = "vhlo.convert_v1"(%170) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %172 = "vhlo.power_v1"(%171, %5) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %173 = "vhlo.reduce_v1"(%172, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %189 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%189) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %174 = "vhlo.multiply_v1"(%173, %3) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %175 = "vhlo.reshape_v1"(%174) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %176 = "vhlo.add_v1"(%175, %22) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %177 = "vhlo.rsqrt_v2"(%176) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %178 = "vhlo.reshape_v1"(%177) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %179 = "vhlo.broadcast_in_dim_v1"(%178) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %180 = "vhlo.multiply_v1"(%171, %179) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %181 = "vhlo.convert_v1"(%180) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %182 = "vhlo.convert_v1"(%181) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %183 = "vhlo.multiply_v1"(%75, %182) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %184 = "vhlo.convert_v1"(%183) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %185 = "vhlo.reshape_v1"(%184) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %186 = "vhlo.transpose_v1"(%arg5) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,128256]{0,1}">} : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>
    %187 = "vhlo.dot_general_v2"(%185, %186) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>
    %188 = "vhlo.reshape_v1"(%187) : (!vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>
    "vhlo.return_v1"(%67, %73, %187, %188) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}
2025-08-20 16:58:44.617 (   6.257s) [        5E2EB1C0]      module_builder.cc:196      1| SHLO Module:
module @SyncTensorsGraph.374 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg2: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg3: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg4: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg5: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg6: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg7: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg8: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg9: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg10: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg11: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg12: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg13: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg14: tensor<128xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg15: tensor<7x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg16: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>) {
    %c = stablehlo.constant dense<0> : tensor<7xi64>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %1 = stablehlo.compare  LT, %arg0, %c : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %2 = stablehlo.broadcast_in_dim %arg7, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %3 = stablehlo.add %arg0, %2 : tensor<7xi64>
    %4 = stablehlo.select %1, %3, %arg0 : tensor<7xi1>, tensor<7xi64>
    %5 = stablehlo.reshape %4 : (tensor<7xi64>) -> tensor<7x1xi64>
    %6 = stablehlo.convert %arg6 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %7 = stablehlo.broadcast_in_dim %6, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %8 = stablehlo.convert %arg4 : (tensor<1x7xi64>) -> tensor<1x7xui32>
    %9 = stablehlo.reshape %8 : (tensor<1x7xui32>) -> tensor<7xui32>
    %10 = "stablehlo.gather"(%arg5, %9) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %11 = stablehlo.reshape %10 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %12 = stablehlo.convert %11 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %13 = stablehlo.power %12, %0 : tensor<1x7x3072xf32>
    %14 = stablehlo.reduce(%13 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %15 = stablehlo.multiply %14, %cst_1 : tensor<1x7xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %17 = stablehlo.broadcast_in_dim %arg3, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %18 = stablehlo.add %16, %17 : tensor<1x7x1xf32>
    %19 = stablehlo.rsqrt %18 : tensor<1x7x1xf32>
    %20 = stablehlo.reshape %19 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %21 = stablehlo.broadcast_in_dim %20, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %22 = stablehlo.multiply %12, %21 : tensor<1x7x3072xf32>
    %23 = stablehlo.convert %22 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %24 = stablehlo.convert %23 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %25 = stablehlo.multiply %7, %24 : tensor<1x7x3072xf32>
    %26 = stablehlo.convert %25 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %27 = stablehlo.reshape %26 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %28 = stablehlo.transpose %arg2, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %29 = stablehlo.dot_general %27, %28, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %30 = stablehlo.reshape %29 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %31 = stablehlo.transpose %30, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %32 = stablehlo.convert %31 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %33 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x64x1xf32>
    %34 = stablehlo.convert %arg0 : (tensor<7xi64>) -> tensor<7xf32>
    %35 = stablehlo.reshape %34 : (tensor<7xf32>) -> tensor<1x1x7xf32>
    %36 = stablehlo.dot_general %33, %35, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %37 = stablehlo.transpose %36, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %38 = stablehlo.concatenate %37, %37, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %39 = stablehlo.cosine %38 : tensor<1x7x128xf32>
    %40 = stablehlo.convert %39 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %41 = stablehlo.convert %40 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %42 = stablehlo.broadcast_in_dim %41, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %43 = stablehlo.multiply %32, %42 : tensor<1x8x7x128xf32>
    %44 = stablehlo.convert %43 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %45 = stablehlo.slice %31 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %46 = stablehlo.negate %45 : tensor<1x8x7x64xbf16>
    %47 = stablehlo.slice %31 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %48 = stablehlo.concatenate %46, %47, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %49 = stablehlo.convert %48 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %50 = stablehlo.sine %38 : tensor<1x7x128xf32>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %52 = stablehlo.convert %51 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %53 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %54 = stablehlo.multiply %49, %53 : tensor<1x8x7x128xf32>
    %55 = stablehlo.convert %54 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %56 = stablehlo.add %44, %55 : tensor<1x8x7x128xbf16>
    %57 = "stablehlo.scatter"(%arg8, %5, %56) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %58 = sdy.sharding_constraint %57 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %59 = stablehlo.transpose %arg9, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %60 = stablehlo.dot_general %27, %59, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %61 = stablehlo.reshape %60 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %62 = stablehlo.transpose %61, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %63 = "stablehlo.scatter"(%arg10, %5, %62) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x128x128xbf16>
    %64 = sdy.sharding_constraint %63 <@mesh, [{}, {"_axis_0"}, {}, {}]> : tensor<1x8x128x128xbf16>
    %65 = stablehlo.convert %arg20 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %67 = stablehlo.transpose %arg17, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %68 = stablehlo.dot_general %27, %67, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %69 = stablehlo.reshape %68 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %70 = stablehlo.transpose %69, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %71 = stablehlo.convert %70 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %72 = stablehlo.broadcast_in_dim %41, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %73 = stablehlo.multiply %71, %72 : tensor<1x24x7x128xf32>
    %74 = stablehlo.convert %73 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %75 = stablehlo.slice %70 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %76 = stablehlo.negate %75 : tensor<1x24x7x64xbf16>
    %77 = stablehlo.slice %70 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %79 = stablehlo.convert %78 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %81 = stablehlo.multiply %79, %80 : tensor<1x24x7x128xf32>
    %82 = stablehlo.convert %81 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %83 = stablehlo.add %74, %82 : tensor<1x24x7x128xbf16>
    %84 = stablehlo.reshape %83 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %85 = stablehlo.broadcast_in_dim %57, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %86 = stablehlo.reshape %85 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %87 = stablehlo.transpose %86, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %88 = stablehlo.reshape %87 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %89 = stablehlo.dot_general %84, %88, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %90 = stablehlo.convert %89 : (tensor<24x7x128xbf16>) -> tensor<24x7x128xf32>
    %91 = stablehlo.reshape %90 : (tensor<24x7x128xf32>) -> tensor<1x24x7x128xf32>
    %92 = stablehlo.broadcast_in_dim %arg16, dims = [] : (tensor<f32>) -> tensor<1x24x7x128xf32>
    %93 = stablehlo.multiply %91, %92 : tensor<1x24x7x128xf32>
    %94 = stablehlo.convert %93 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %95 = stablehlo.convert %arg15 : (tensor<7x128xbf16>) -> tensor<7x128xf32>
    %96 = stablehlo.broadcast_in_dim %arg14, dims = [1] : (tensor<128xi64>) -> tensor<7x128xi64>
    %97 = stablehlo.broadcast_in_dim %arg0, dims = [0] : (tensor<7xi64>) -> tensor<7x128xi64>
    %98 = stablehlo.compare  GT, %96, %97 : (tensor<7x128xi64>, tensor<7x128xi64>) -> tensor<7x128xi1>
    %99 = stablehlo.convert %98 : (tensor<7x128xi1>) -> tensor<7x128xf32>
    %100 = stablehlo.multiply %95, %99 : tensor<7x128xf32>
    %101 = stablehlo.convert %100 : (tensor<7x128xf32>) -> tensor<7x128xbf16>
    %102 = stablehlo.reshape %101 : (tensor<7x128xbf16>) -> tensor<1x7x128xbf16>
    %103 = stablehlo.broadcast_in_dim %102, dims = [0, 2, 3] : (tensor<1x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %104 = stablehlo.add %94, %103 : tensor<1x24x7x128xbf16>
    %105 = stablehlo.convert %104 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %106 = stablehlo.reduce(%105 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %107 = stablehlo.broadcast_in_dim %106, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %108 = stablehlo.subtract %105, %107 : tensor<1x24x7x128xf32>
    %109 = stablehlo.exponential %108 : tensor<1x24x7x128xf32>
    %110 = stablehlo.reduce(%109 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x128xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %111 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x128xf32>
    %112 = stablehlo.divide %109, %111 : tensor<1x24x7x128xf32>
    %113 = stablehlo.convert %112 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %114 = stablehlo.reshape %113 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %115 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %116 = stablehlo.reshape %115 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %117 = stablehlo.dot_general %114, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x7x128xbf16>
    %118 = stablehlo.reshape %117 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %119 = stablehlo.transpose %118, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %120 = stablehlo.reshape %119 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %121 = stablehlo.transpose %arg13, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %122 = stablehlo.dot_general %120, %121, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %123 = stablehlo.reshape %122 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %124 = stablehlo.add %11, %123 : tensor<1x7x3072xbf16>
    %125 = stablehlo.convert %arg18 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %126 = stablehlo.broadcast_in_dim %125, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %127 = stablehlo.convert %124 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %128 = stablehlo.power %127, %0 : tensor<1x7x3072xf32>
    %129 = stablehlo.reduce(%128 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %130 = stablehlo.multiply %129, %cst_1 : tensor<1x7xf32>
    %131 = stablehlo.reshape %130 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %132 = stablehlo.add %131, %17 : tensor<1x7x1xf32>
    %133 = stablehlo.rsqrt %132 : tensor<1x7x1xf32>
    %134 = stablehlo.reshape %133 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %136 = stablehlo.multiply %127, %135 : tensor<1x7x3072xf32>
    %137 = stablehlo.convert %136 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %138 = stablehlo.convert %137 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %139 = stablehlo.multiply %126, %138 : tensor<1x7x3072xf32>
    %140 = stablehlo.convert %139 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %141 = stablehlo.reshape %140 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %142 = stablehlo.transpose %arg19, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %143 = stablehlo.dot_general %141, %142, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %144 = stablehlo.reshape %143 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %145 = stablehlo.convert %144 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %146 = stablehlo.logistic %144 : tensor<1x7x8192xbf16>
    %147 = stablehlo.convert %146 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %148 = stablehlo.multiply %145, %147 : tensor<1x7x8192xf32>
    %149 = stablehlo.convert %148 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %150 = stablehlo.convert %149 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %151 = stablehlo.transpose %arg12, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %152 = stablehlo.dot_general %141, %151, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %153 = stablehlo.convert %152 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %154 = stablehlo.reshape %153 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %155 = stablehlo.multiply %150, %154 : tensor<1x7x8192xf32>
    %156 = stablehlo.convert %155 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %157 = stablehlo.reshape %156 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %158 = stablehlo.transpose %arg11, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %159 = stablehlo.dot_general %157, %158, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %160 = stablehlo.reshape %159 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %161 = stablehlo.add %124, %160 : tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.power %162, %0 : tensor<1x7x3072xf32>
    %164 = stablehlo.reduce(%163 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %165 = stablehlo.multiply %164, %cst_1 : tensor<1x7xf32>
    %166 = stablehlo.reshape %165 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %167 = stablehlo.add %166, %17 : tensor<1x7x1xf32>
    %168 = stablehlo.rsqrt %167 : tensor<1x7x1xf32>
    %169 = stablehlo.reshape %168 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %170 = stablehlo.broadcast_in_dim %169, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %171 = stablehlo.multiply %162, %170 : tensor<1x7x3072xf32>
    %172 = stablehlo.convert %171 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %173 = stablehlo.convert %172 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %174 = stablehlo.multiply %66, %173 : tensor<1x7x3072xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %176 = stablehlo.reshape %175 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %177 = stablehlo.transpose %arg5, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %178 = stablehlo.dot_general %176, %177, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %179 = stablehlo.reshape %178 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %58, %64, %178, %179 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>
  }
}
2025-08-20 16:58:44.727 (   6.367s) [        5E2EB1C0]      module_builder.cc:220      1| SHLO StableHLO Pipeline Module:
module @SyncTensorsGraph.374 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<7xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<64xf32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg3: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg4: tensor<1x7xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg5: tensor<128256x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg6: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg7: tensor<i64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg8: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg9: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg10: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg11: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg12: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg13: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg14: tensor<128xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg15: tensor<7x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg16: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg17: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg18: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg19: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg20: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:4 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18, %arg19, %arg20) in_shardings=[<@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{}]>, <@mesh, [{}, {}]>, <@mesh, []>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{}, {}, {"_axis_0"}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg21: tensor<7xi64>, %arg22: tensor<64xf32>, %arg23: tensor<512x3072xbf16>, %arg24: tensor<f32>, %arg25: tensor<1x7xi64>, %arg26: tensor<64128x3072xbf16>, %arg27: tensor<3072xbf16>, %arg28: tensor<i64>, %arg29: tensor<1x4x128x128xbf16>, %arg30: tensor<512x3072xbf16>, %arg31: tensor<1x4x128x128xbf16>, %arg32: tensor<3072x4096xbf16>, %arg33: tensor<4096x3072xbf16>, %arg34: tensor<3072x1536xbf16>, %arg35: tensor<128xi64>, %arg36: tensor<7x128xbf16>, %arg37: tensor<f32>, %arg38: tensor<1536x3072xbf16>, %arg39: tensor<3072xbf16>, %arg40: tensor<4096x3072xbf16>, %arg41: tensor<3072xbf16>) {
      %c = stablehlo.constant dense<0> : tensor<7xi64>
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
      %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %1 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
      %2 = stablehlo.compare  LT, %arg21, %c : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
      %3 = stablehlo.broadcast_in_dim %arg28, dims = [] : (tensor<i64>) -> tensor<7xi64>
      %4 = stablehlo.add %arg21, %3 : tensor<7xi64>
      %5 = stablehlo.select %2, %4, %arg21 : tensor<7xi1>, tensor<7xi64>
      %6 = stablehlo.reshape %5 : (tensor<7xi64>) -> tensor<7x1xi64>
      %7 = stablehlo.convert %arg27 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %8 = stablehlo.broadcast_in_dim %7, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %9 = stablehlo.convert %arg25 : (tensor<1x7xi64>) -> tensor<1x7xui32>
      %10 = stablehlo.reshape %9 : (tensor<1x7xui32>) -> tensor<7xui32>
      %11 = "stablehlo.gather"(%arg26, %10) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<64128x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
      %12 = "stablehlo.all_reduce"(%11) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg42: tensor<bf16>, %arg43: tensor<bf16>):
        %182 = stablehlo.add %arg42, %arg43 : tensor<bf16>
        stablehlo.return %182 : tensor<bf16>
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %14 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %15 = stablehlo.power %14, %1 : tensor<1x7x3072xf32>
      %16 = stablehlo.reduce(%15 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %17 = stablehlo.multiply %16, %cst_1 : tensor<1x7xf32>
      %18 = stablehlo.reshape %17 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %19 = stablehlo.broadcast_in_dim %arg24, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
      %20 = stablehlo.add %18, %19 : tensor<1x7x1xf32>
      %21 = stablehlo.rsqrt %20 : tensor<1x7x1xf32>
      %22 = stablehlo.reshape %21 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %23 = stablehlo.broadcast_in_dim %22, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %24 = stablehlo.multiply %14, %23 : tensor<1x7x3072xf32>
      %25 = stablehlo.convert %24 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %26 = stablehlo.convert %25 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %27 = stablehlo.multiply %8, %26 : tensor<1x7x3072xf32>
      %28 = stablehlo.convert %27 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %29 = stablehlo.reshape %28 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %30 = stablehlo.transpose %arg23, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %31 = stablehlo.dot_general %29, %30, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
      %32 = stablehlo.reshape %31 : (tensor<7x512xbf16>) -> tensor<1x7x4x128xbf16>
      %33 = stablehlo.transpose %32, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x4x128xbf16>) -> tensor<1x4x7x128xbf16>
      %34 = stablehlo.convert %33 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32>
      %35 = stablehlo.reshape %arg22 : (tensor<64xf32>) -> tensor<1x64x1xf32>
      %36 = stablehlo.convert %arg21 : (tensor<7xi64>) -> tensor<7xf32>
      %37 = stablehlo.reshape %36 : (tensor<7xf32>) -> tensor<1x1x7xf32>
      %38 = stablehlo.dot_general %35, %37, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
      %39 = stablehlo.transpose %38, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
      %40 = stablehlo.concatenate %39, %39, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
      %41 = stablehlo.cosine %40 : tensor<1x7x128xf32>
      %42 = stablehlo.convert %41 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
      %43 = stablehlo.convert %42 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
      %44 = stablehlo.broadcast_in_dim %43, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x4x7x128xf32>
      %45 = stablehlo.multiply %34, %44 : tensor<1x4x7x128xf32>
      %46 = stablehlo.convert %45 : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16>
      %47 = stablehlo.slice %33 [0:1, 0:4, 0:7, 64:128] : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16>
      %48 = stablehlo.negate %47 : tensor<1x4x7x64xbf16>
      %49 = stablehlo.slice %33 [0:1, 0:4, 0:7, 0:64] : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16>
      %50 = stablehlo.concatenate %48, %49, dim = 3 : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x128xbf16>
      %51 = stablehlo.convert %50 : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32>
      %52 = stablehlo.sine %40 : tensor<1x7x128xf32>
      %53 = stablehlo.convert %52 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
      %54 = stablehlo.convert %53 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
      %55 = stablehlo.broadcast_in_dim %54, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x4x7x128xf32>
      %56 = stablehlo.multiply %51, %55 : tensor<1x4x7x128xf32>
      %57 = stablehlo.convert %56 : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16>
      %58 = stablehlo.add %46, %57 : tensor<1x4x7x128xbf16>
      %59 = "stablehlo.scatter"(%arg29, %6, %58) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg42: tensor<bf16>, %arg43: tensor<bf16>):
        stablehlo.return %arg43 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>) -> tensor<1x4x128x128xbf16>
      %60 = stablehlo.transpose %arg30, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %61 = stablehlo.dot_general %29, %60, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
      %62 = stablehlo.reshape %61 : (tensor<7x512xbf16>) -> tensor<1x7x4x128xbf16>
      %63 = stablehlo.transpose %62, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x4x128xbf16>) -> tensor<1x4x7x128xbf16>
      %64 = "stablehlo.scatter"(%arg31, %6, %63) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg42: tensor<bf16>, %arg43: tensor<bf16>):
        stablehlo.return %arg43 : tensor<bf16>
      }) : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>) -> tensor<1x4x128x128xbf16>
      %65 = stablehlo.convert %arg41 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %67 = stablehlo.transpose %arg38, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %68 = stablehlo.dot_general %29, %67, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<7x1536xbf16>
      %69 = stablehlo.reshape %68 : (tensor<7x1536xbf16>) -> tensor<1x7x12x128xbf16>
      %70 = stablehlo.transpose %69, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x12x128xbf16>) -> tensor<1x12x7x128xbf16>
      %71 = stablehlo.convert %70 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %72 = stablehlo.broadcast_in_dim %43, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x12x7x128xf32>
      %73 = stablehlo.multiply %71, %72 : tensor<1x12x7x128xf32>
      %74 = stablehlo.convert %73 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %75 = stablehlo.slice %70 [0:1, 0:12, 0:7, 64:128] : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16>
      %76 = stablehlo.negate %75 : tensor<1x12x7x64xbf16>
      %77 = stablehlo.slice %70 [0:1, 0:12, 0:7, 0:64] : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16>
      %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x128xbf16>
      %79 = stablehlo.convert %78 : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %80 = stablehlo.broadcast_in_dim %54, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x12x7x128xf32>
      %81 = stablehlo.multiply %79, %80 : tensor<1x12x7x128xf32>
      %82 = stablehlo.convert %81 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %83 = stablehlo.add %74, %82 : tensor<1x12x7x128xbf16>
      %84 = stablehlo.reshape %83 : (tensor<1x12x7x128xbf16>) -> tensor<12x7x128xbf16>
      %85 = stablehlo.broadcast_in_dim %59, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %86 = stablehlo.reshape %85 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %87 = stablehlo.transpose %86, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
      %88 = stablehlo.reshape %87 : (tensor<1x12x128x128xbf16>) -> tensor<12x128x128xbf16>
      %89 = stablehlo.dot_general %84, %88, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
      %90 = stablehlo.convert %89 : (tensor<12x7x128xbf16>) -> tensor<12x7x128xf32>
      %91 = stablehlo.reshape %90 : (tensor<12x7x128xf32>) -> tensor<1x12x7x128xf32>
      %92 = stablehlo.broadcast_in_dim %arg37, dims = [] : (tensor<f32>) -> tensor<1x12x7x128xf32>
      %93 = stablehlo.multiply %91, %92 : tensor<1x12x7x128xf32>
      %94 = stablehlo.convert %93 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %95 = stablehlo.convert %arg36 : (tensor<7x128xbf16>) -> tensor<7x128xf32>
      %96 = stablehlo.broadcast_in_dim %arg35, dims = [1] : (tensor<128xi64>) -> tensor<7x128xi64>
      %97 = stablehlo.broadcast_in_dim %arg21, dims = [0] : (tensor<7xi64>) -> tensor<7x128xi64>
      %98 = stablehlo.compare  GT, %96, %97 : (tensor<7x128xi64>, tensor<7x128xi64>) -> tensor<7x128xi1>
      %99 = stablehlo.convert %98 : (tensor<7x128xi1>) -> tensor<7x128xf32>
      %100 = stablehlo.multiply %95, %99 : tensor<7x128xf32>
      %101 = stablehlo.convert %100 : (tensor<7x128xf32>) -> tensor<7x128xbf16>
      %102 = stablehlo.reshape %101 : (tensor<7x128xbf16>) -> tensor<1x7x128xbf16>
      %103 = stablehlo.broadcast_in_dim %102, dims = [0, 2, 3] : (tensor<1x7x128xbf16>) -> tensor<1x12x7x128xbf16>
      %104 = stablehlo.add %94, %103 : tensor<1x12x7x128xbf16>
      %105 = stablehlo.convert %104 : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %106 = stablehlo.reduce(%105 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x7x128xf32>, tensor<f32>) -> tensor<1x12x7xf32>
      %107 = stablehlo.broadcast_in_dim %106, dims = [0, 1, 2] : (tensor<1x12x7xf32>) -> tensor<1x12x7x128xf32>
      %108 = stablehlo.subtract %105, %107 : tensor<1x12x7x128xf32>
      %109 = stablehlo.exponential %108 : tensor<1x12x7x128xf32>
      %110 = stablehlo.reduce(%109 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x7x128xf32>, tensor<f32>) -> tensor<1x12x7xf32>
      %111 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 2] : (tensor<1x12x7xf32>) -> tensor<1x12x7x128xf32>
      %112 = stablehlo.divide %109, %111 : tensor<1x12x7x128xf32>
      %113 = stablehlo.convert %112 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %114 = stablehlo.reshape %113 : (tensor<1x12x7x128xbf16>) -> tensor<12x7x128xbf16>
      %115 = stablehlo.broadcast_in_dim %64, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
      %116 = stablehlo.reshape %115 : (tensor<1x4x3x128x128xbf16>) -> tensor<12x128x128xbf16>
      %117 = stablehlo.dot_general %114, %116, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
      %118 = stablehlo.reshape %117 : (tensor<12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
      %119 = stablehlo.transpose %118, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x12x7x128xbf16>) -> tensor<1x7x12x128xbf16>
      %120 = stablehlo.reshape %119 : (tensor<1x7x12x128xbf16>) -> tensor<7x1536xbf16>
      %121 = stablehlo.transpose %arg34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
      %122 = stablehlo.dot_general %120, %121, contracting_dims = [1] x [0] : (tensor<7x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<7x3072xbf16>
      %123 = "stablehlo.all_reduce"(%122) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg42: tensor<bf16>, %arg43: tensor<bf16>):
        %182 = stablehlo.add %arg42, %arg43 : tensor<bf16>
        stablehlo.return %182 : tensor<bf16>
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %124 = stablehlo.reshape %123 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %125 = stablehlo.add %13, %124 : tensor<1x7x3072xbf16>
      %126 = stablehlo.convert %arg39 : (tensor<3072xbf16>) -> tensor<3072xf32>
      %127 = stablehlo.broadcast_in_dim %126, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %128 = stablehlo.convert %125 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %129 = stablehlo.power %128, %1 : tensor<1x7x3072xf32>
      %130 = stablehlo.reduce(%129 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %131 = stablehlo.multiply %130, %cst_1 : tensor<1x7xf32>
      %132 = stablehlo.reshape %131 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %133 = stablehlo.add %132, %19 : tensor<1x7x1xf32>
      %134 = stablehlo.rsqrt %133 : tensor<1x7x1xf32>
      %135 = stablehlo.reshape %134 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %136 = stablehlo.broadcast_in_dim %135, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %137 = stablehlo.multiply %128, %136 : tensor<1x7x3072xf32>
      %138 = stablehlo.convert %137 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %139 = stablehlo.convert %138 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %140 = stablehlo.multiply %127, %139 : tensor<1x7x3072xf32>
      %141 = stablehlo.convert %140 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %142 = stablehlo.reshape %141 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %143 = stablehlo.transpose %arg40, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %144 = stablehlo.dot_general %142, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
      %145 = stablehlo.reshape %144 : (tensor<7x4096xbf16>) -> tensor<1x7x4096xbf16>
      %146 = stablehlo.convert %145 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %147 = stablehlo.logistic %145 : tensor<1x7x4096xbf16>
      %148 = stablehlo.convert %147 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %149 = stablehlo.multiply %146, %148 : tensor<1x7x4096xf32>
      %150 = stablehlo.convert %149 : (tensor<1x7x4096xf32>) -> tensor<1x7x4096xbf16>
      %151 = stablehlo.convert %150 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32>
      %152 = stablehlo.transpose %arg33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
      %153 = stablehlo.dot_general %142, %152, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
      %154 = stablehlo.convert %153 : (tensor<7x4096xbf16>) -> tensor<7x4096xf32>
      %155 = stablehlo.reshape %154 : (tensor<7x4096xf32>) -> tensor<1x7x4096xf32>
      %156 = stablehlo.multiply %151, %155 : tensor<1x7x4096xf32>
      %157 = stablehlo.convert %156 : (tensor<1x7x4096xf32>) -> tensor<1x7x4096xbf16>
      %158 = stablehlo.reshape %157 : (tensor<1x7x4096xbf16>) -> tensor<7x4096xbf16>
      %159 = stablehlo.transpose %arg32, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
      %160 = stablehlo.dot_general %158, %159, contracting_dims = [1] x [0] : (tensor<7x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<7x3072xbf16>
      %161 = "stablehlo.all_reduce"(%160) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg42: tensor<bf16>, %arg43: tensor<bf16>):
        %182 = stablehlo.add %arg42, %arg43 : tensor<bf16>
        stablehlo.return %182 : tensor<bf16>
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %162 = stablehlo.reshape %161 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %163 = stablehlo.add %125, %162 : tensor<1x7x3072xbf16>
      %164 = stablehlo.convert %163 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %165 = stablehlo.power %164, %1 : tensor<1x7x3072xf32>
      %166 = stablehlo.reduce(%165 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %167 = stablehlo.multiply %166, %cst_1 : tensor<1x7xf32>
      %168 = stablehlo.reshape %167 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %169 = stablehlo.add %168, %19 : tensor<1x7x1xf32>
      %170 = stablehlo.rsqrt %169 : tensor<1x7x1xf32>
      %171 = stablehlo.reshape %170 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %172 = stablehlo.broadcast_in_dim %171, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %173 = stablehlo.multiply %164, %172 : tensor<1x7x3072xf32>
      %174 = stablehlo.convert %173 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %175 = stablehlo.convert %174 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %176 = stablehlo.multiply %66, %175 : tensor<1x7x3072xf32>
      %177 = stablehlo.convert %176 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %178 = stablehlo.reshape %177 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %179 = stablehlo.transpose %arg26, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<64128x3072xbf16>) -> tensor<3072x64128xbf16>
      %180 = stablehlo.dot_general %178, %179, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x64128xbf16>) -> tensor<7x64128xbf16>
      %181 = stablehlo.reshape %180 : (tensor<7x64128xbf16>) -> tensor<1x7x64128xbf16>
      sdy.return %59, %64, %180, %181 : tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<7x64128xbf16>, tensor<1x7x64128xbf16>
    } : (tensor<7xi64>, tensor<64xf32>, tensor<1024x3072xbf16>, tensor<f32>, tensor<1x7xi64>, tensor<128256x3072xbf16>, tensor<3072xbf16>, tensor<i64>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<128xi64>, tensor<7x128xbf16>, tensor<f32>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>)
    return %0#0, %0#1, %0#2, %0#3 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>
  }
}
2025-08-20 16:58:44.756 (   6.396s) [        5E2EB1C0]      module_builder.cc:472      1| TTIR Module:
module @SyncTensorsGraph.374 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<7xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<64xf32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg3: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg4: tensor<1x7xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg5: tensor<128256x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg6: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg7: tensor<i64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg8: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg9: tensor<1024x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg10: tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg11: tensor<3072x8192xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg12: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg13: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg14: tensor<128xi64> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg15: tensor<7x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg16: tensor<f32> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg17: tensor<3072x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg18: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg19: tensor<8192x3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg20: tensor<3072xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = ttir.empty() : tensor<7xi64>
    %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi64>
    %2 = ttir.empty() : tensor<64xf32>
    %3 = "ttir.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xf32>
    %4 = ttir.empty() : tensor<512x3072xbf16>
    %5 = "ttir.mesh_shard"(%arg2, %4) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %6 = ttir.empty() : tensor<f32>
    %7 = "ttir.mesh_shard"(%arg3, %6) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32>, tensor<f32>) -> tensor<f32>
    %8 = ttir.empty() : tensor<1x7xi64>
    %9 = "ttir.mesh_shard"(%arg4, %8) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x7xi64>, tensor<1x7xi64>) -> tensor<1x7xi64>
    %10 = ttir.empty() : tensor<64128x3072xbf16>
    %11 = "ttir.mesh_shard"(%arg5, %10) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16>, tensor<64128x3072xbf16>) -> tensor<64128x3072xbf16>
    %12 = ttir.empty() : tensor<3072xbf16>
    %13 = "ttir.mesh_shard"(%arg6, %12) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %14 = ttir.empty() : tensor<i64>
    %15 = "ttir.mesh_shard"(%arg7, %14) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<i64>, tensor<i64>) -> tensor<i64>
    %16 = ttir.empty() : tensor<1x4x128x128xbf16>
    %17 = "ttir.mesh_shard"(%arg8, %16) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %18 = ttir.empty() : tensor<512x3072xbf16>
    %19 = "ttir.mesh_shard"(%arg9, %18) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16>
    %20 = ttir.empty() : tensor<1x4x128x128xbf16>
    %21 = "ttir.mesh_shard"(%arg10, %20) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %22 = ttir.empty() : tensor<3072x4096xbf16>
    %23 = "ttir.mesh_shard"(%arg11, %22) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %24 = ttir.empty() : tensor<4096x3072xbf16>
    %25 = "ttir.mesh_shard"(%arg12, %24) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %26 = ttir.empty() : tensor<3072x1536xbf16>
    %27 = "ttir.mesh_shard"(%arg13, %26) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %28 = ttir.empty() : tensor<128xi64>
    %29 = "ttir.mesh_shard"(%arg14, %28) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi64>
    %30 = ttir.empty() : tensor<7x128xbf16>
    %31 = "ttir.mesh_shard"(%arg15, %30) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<7x128xbf16>, tensor<7x128xbf16>) -> tensor<7x128xbf16>
    %32 = ttir.empty() : tensor<f32>
    %33 = "ttir.mesh_shard"(%arg16, %32) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32>, tensor<f32>) -> tensor<f32>
    %34 = ttir.empty() : tensor<1536x3072xbf16>
    %35 = "ttir.mesh_shard"(%arg17, %34) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %36 = ttir.empty() : tensor<3072xbf16>
    %37 = "ttir.mesh_shard"(%arg18, %36) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %38 = ttir.empty() : tensor<4096x3072xbf16>
    %39 = "ttir.mesh_shard"(%arg19, %38) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %40 = ttir.empty() : tensor<3072xbf16>
    %41 = "ttir.mesh_shard"(%arg20, %40) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16>
    %42 = "ttir.constant"() <{value = dense<0> : tensor<7xi64>}> : () -> tensor<7xi64>
    %43 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32>
    %44 = "ttir.constant"() <{value = dense<0xFF800000> : tensor<f32>}> : () -> tensor<f32>
    %45 = "ttir.constant"() <{value = dense<3.25520843E-4> : tensor<1x7xf32>}> : () -> tensor<1x7xf32>
    %46 = "ttir.constant"() <{value = dense<2.000000e+00> : tensor<f32>}> : () -> tensor<f32>
    %47 = ttir.empty() : tensor<1x1x1xf32>
    %48 = "ttir.reshape"(%46, %47) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %49 = ttir.empty() : tensor<1x7x3072xf32>
    %50 = "ttir.broadcast"(%48, %49) <{broadcast_dimensions = array<i64: 1, 7, 3072>}> : (tensor<1x1x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %51 = ttir.empty() : tensor<7xi1>
    %52 = "ttir.lt"(%1, %42, %51) : (tensor<7xi64>, tensor<7xi64>, tensor<7xi1>) -> tensor<7xi1>
    %53 = ttir.empty() : tensor<1xi64>
    %54 = "ttir.reshape"(%15, %53) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64>
    %55 = ttir.empty() : tensor<7xi64>
    %56 = "ttir.broadcast"(%54, %55) <{broadcast_dimensions = array<i64: 7>}> : (tensor<1xi64>, tensor<7xi64>) -> tensor<7xi64>
    %57 = ttir.empty() : tensor<7xi64>
    %58 = "ttir.add"(%1, %56, %57) : (tensor<7xi64>, tensor<7xi64>, tensor<7xi64>) -> tensor<7xi64>
    %59 = ttir.empty() : tensor<7xi64>
    %60 = "ttir.where"(%52, %58, %1, %59) : (tensor<7xi1>, tensor<7xi64>, tensor<7xi64>, tensor<7xi64>) -> tensor<7xi64>
    %61 = ttir.empty() : tensor<7x1xi64>
    %62 = "ttir.reshape"(%60, %61) <{shape = [7 : i32, 1 : i32]}> : (tensor<7xi64>, tensor<7x1xi64>) -> tensor<7x1xi64>
    %63 = ttir.empty() : tensor<3072xf32>
    %64 = "ttir.typecast"(%13, %63) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %65 = ttir.empty() : tensor<1x1x3072xf32>
    %66 = "ttir.reshape"(%64, %65) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %67 = ttir.empty() : tensor<1x7x3072xf32>
    %68 = "ttir.broadcast"(%66, %67) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %69 = ttir.empty() : tensor<1x7xui32>
    %70 = "ttir.typecast"(%9, %69) <{conservative_folding = false}> : (tensor<1x7xi64>, tensor<1x7xui32>) -> tensor<1x7xui32>
    %71 = ttir.empty() : tensor<7xui32>
    %72 = "ttir.reshape"(%70, %71) <{shape = [7 : i32]}> : (tensor<1x7xui32>, tensor<7xui32>) -> tensor<7xui32>
    %73 = ttir.empty() : tensor<7x3072xbf16>
    %74 = "ttir.gather"(%11, %72, %73) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3072>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<64128x3072xbf16>, tensor<7xui32>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %75 = ttir.empty() : tensor<7x3072xbf16>
    %76 = "ttir.all_reduce"(%74, %75) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %77 = ttir.empty() : tensor<1x7x3072xbf16>
    %78 = "ttir.reshape"(%76, %77) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %79 = ttir.empty() : tensor<1x7x3072xf32>
    %80 = "ttir.typecast"(%78, %79) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %81 = ttir.empty() : tensor<1x7x3072xf32>
    %82 = "ttir.pow"(%80, %50, %81) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %83 = ttir.empty() : tensor<1x7xf32>
    %84 = "ttir.sum"(%82, %83) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %85 = ttir.empty() : tensor<1x7xf32>
    %86 = "ttir.multiply"(%84, %45, %85) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %87 = ttir.empty() : tensor<1x7x1xf32>
    %88 = "ttir.reshape"(%86, %87) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %89 = ttir.empty() : tensor<1x1x1xf32>
    %90 = "ttir.reshape"(%7, %89) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32>
    %91 = ttir.empty() : tensor<1x7x1xf32>
    %92 = "ttir.broadcast"(%90, %91) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %93 = ttir.empty() : tensor<1x7x1xf32>
    %94 = "ttir.add"(%88, %92, %93) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %95 = ttir.empty() : tensor<1x7x1xf32>
    %96 = "ttir.rsqrt"(%94, %95) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %97 = ttir.empty() : tensor<1x7xf32>
    %98 = "ttir.reshape"(%96, %97) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %99 = ttir.empty() : tensor<1x7x1xf32>
    %100 = "ttir.reshape"(%98, %99) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %101 = ttir.empty() : tensor<1x7x3072xf32>
    %102 = "ttir.broadcast"(%100, %101) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %103 = ttir.empty() : tensor<1x7x3072xf32>
    %104 = "ttir.multiply"(%80, %102, %103) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %105 = ttir.empty() : tensor<1x7x3072xbf16>
    %106 = "ttir.typecast"(%104, %105) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %107 = ttir.empty() : tensor<1x7x3072xf32>
    %108 = "ttir.typecast"(%106, %107) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %109 = ttir.empty() : tensor<1x7x3072xf32>
    %110 = "ttir.multiply"(%68, %108, %109) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %111 = ttir.empty() : tensor<1x7x3072xbf16>
    %112 = "ttir.typecast"(%110, %111) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %113 = ttir.empty() : tensor<7x3072xbf16>
    %114 = "ttir.reshape"(%112, %113) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %115 = ttir.empty() : tensor<3072x512xbf16>
    %116 = "ttir.permute"(%5, %115) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %117 = "ttir.dot_general"(%114, %116) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
    %118 = ttir.empty() : tensor<1x7x4x128xbf16>
    %119 = "ttir.reshape"(%117, %118) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16>, tensor<1x7x4x128xbf16>) -> tensor<1x7x4x128xbf16>
    %120 = ttir.empty() : tensor<1x4x7x128xbf16>
    %121 = "ttir.permute"(%119, %120) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %122 = ttir.empty() : tensor<1x4x7x128xf32>
    %123 = "ttir.typecast"(%121, %122) <{conservative_folding = false}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %124 = ttir.empty() : tensor<1x64x1xf32>
    %125 = "ttir.reshape"(%3, %124) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32>, tensor<1x64x1xf32>) -> tensor<1x64x1xf32>
    %126 = ttir.empty() : tensor<7xf32>
    %127 = "ttir.typecast"(%1, %126) <{conservative_folding = false}> : (tensor<7xi64>, tensor<7xf32>) -> tensor<7xf32>
    %128 = ttir.empty() : tensor<1x1x7xf32>
    %129 = "ttir.reshape"(%127, %128) <{shape = [1 : i32, 1 : i32, 7 : i32]}> : (tensor<7xf32>, tensor<1x1x7xf32>) -> tensor<1x1x7xf32>
    %130 = "ttir.dot_general"(%125, %129) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %131 = ttir.empty() : tensor<1x7x64xf32>
    %132 = "ttir.permute"(%130, %131) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x7xf32>, tensor<1x7x64xf32>) -> tensor<1x7x64xf32>
    %133 = ttir.empty() : tensor<1x7x128xf32>
    %134 = "ttir.concat"(%132, %132, %133) <{dim = 2 : si32}> : (tensor<1x7x64xf32>, tensor<1x7x64xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %135 = ttir.empty() : tensor<1x7x128xf32>
    %136 = "ttir.cos"(%134, %135) : (tensor<1x7x128xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %137 = ttir.empty() : tensor<1x7x128xbf16>
    %138 = "ttir.typecast"(%136, %137) <{conservative_folding = false}> : (tensor<1x7x128xf32>, tensor<1x7x128xbf16>) -> tensor<1x7x128xbf16>
    %139 = ttir.empty() : tensor<1x7x128xf32>
    %140 = "ttir.typecast"(%138, %139) <{conservative_folding = false}> : (tensor<1x7x128xbf16>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %141 = ttir.empty() : tensor<1x1x7x128xf32>
    %142 = "ttir.reshape"(%140, %141) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %143 = ttir.empty() : tensor<1x4x7x128xf32>
    %144 = "ttir.broadcast"(%142, %143) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %145 = ttir.empty() : tensor<1x4x7x128xf32>
    %146 = "ttir.multiply"(%123, %144, %145) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %147 = ttir.empty() : tensor<1x4x7x128xbf16>
    %148 = "ttir.typecast"(%146, %147) <{conservative_folding = false}> : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %149 = ttir.empty() : tensor<1x4x7x64xbf16>
    %150 = "ttir.slice"(%121, %149) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %151 = ttir.empty() : tensor<1x4x7x64xbf16>
    %152 = "ttir.neg"(%150, %151) : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %153 = ttir.empty() : tensor<1x4x7x64xbf16>
    %154 = "ttir.slice"(%121, %153) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
    %155 = ttir.empty() : tensor<1x4x7x128xbf16>
    %156 = "ttir.concat"(%152, %154, %155) <{dim = 3 : si32}> : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %157 = ttir.empty() : tensor<1x4x7x128xf32>
    %158 = "ttir.typecast"(%156, %157) <{conservative_folding = false}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %159 = ttir.empty() : tensor<1x7x128xf32>
    %160 = "ttir.sin"(%134, %159) : (tensor<1x7x128xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %161 = ttir.empty() : tensor<1x7x128xbf16>
    %162 = "ttir.typecast"(%160, %161) <{conservative_folding = false}> : (tensor<1x7x128xf32>, tensor<1x7x128xbf16>) -> tensor<1x7x128xbf16>
    %163 = ttir.empty() : tensor<1x7x128xf32>
    %164 = "ttir.typecast"(%162, %163) <{conservative_folding = false}> : (tensor<1x7x128xbf16>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
    %165 = ttir.empty() : tensor<1x1x7x128xf32>
    %166 = "ttir.reshape"(%164, %165) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %167 = ttir.empty() : tensor<1x4x7x128xf32>
    %168 = "ttir.broadcast"(%166, %167) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %169 = ttir.empty() : tensor<1x4x7x128xf32>
    %170 = "ttir.multiply"(%158, %168, %169) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
    %171 = ttir.empty() : tensor<1x4x7x128xbf16>
    %172 = "ttir.typecast"(%170, %171) <{conservative_folding = false}> : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %173 = ttir.empty() : tensor<1x4x7x128xbf16>
    %174 = "ttir.add"(%148, %172, %173) : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %175 = ttir.empty() : tensor<1x4x128x128xbf16>
    %176 = "ttir.scatter"(%17, %62, %174, %175) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %177 = ttir.empty() : tensor<3072x512xbf16>
    %178 = "ttir.permute"(%19, %177) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16>
    %179 = "ttir.dot_general"(%114, %178) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
    %180 = ttir.empty() : tensor<1x7x4x128xbf16>
    %181 = "ttir.reshape"(%179, %180) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16>, tensor<1x7x4x128xbf16>) -> tensor<1x7x4x128xbf16>
    %182 = ttir.empty() : tensor<1x4x7x128xbf16>
    %183 = "ttir.permute"(%181, %182) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
    %184 = ttir.empty() : tensor<1x4x128x128xbf16>
    %185 = "ttir.scatter"(%21, %62, %183, %184) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x128x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>, tensor<1x4x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %186 = ttir.empty() : tensor<3072xf32>
    %187 = "ttir.typecast"(%41, %186) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %188 = ttir.empty() : tensor<1x1x3072xf32>
    %189 = "ttir.reshape"(%187, %188) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %190 = ttir.empty() : tensor<1x7x3072xf32>
    %191 = "ttir.broadcast"(%189, %190) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %192 = ttir.empty() : tensor<3072x1536xbf16>
    %193 = "ttir.permute"(%35, %192) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %194 = "ttir.dot_general"(%114, %193) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<7x1536xbf16>
    %195 = ttir.empty() : tensor<1x7x12x128xbf16>
    %196 = "ttir.reshape"(%194, %195) <{shape = [1 : i32, 7 : i32, 12 : i32, 128 : i32]}> : (tensor<7x1536xbf16>, tensor<1x7x12x128xbf16>) -> tensor<1x7x12x128xbf16>
    %197 = ttir.empty() : tensor<1x12x7x128xbf16>
    %198 = "ttir.permute"(%196, %197) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x12x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %199 = ttir.empty() : tensor<1x12x7x128xf32>
    %200 = "ttir.typecast"(%198, %199) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %201 = ttir.empty() : tensor<1x1x7x128xf32>
    %202 = "ttir.reshape"(%140, %201) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %203 = ttir.empty() : tensor<1x12x7x128xf32>
    %204 = "ttir.broadcast"(%202, %203) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %205 = ttir.empty() : tensor<1x12x7x128xf32>
    %206 = "ttir.multiply"(%200, %204, %205) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %207 = ttir.empty() : tensor<1x12x7x128xbf16>
    %208 = "ttir.typecast"(%206, %207) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %209 = ttir.empty() : tensor<1x12x7x64xbf16>
    %210 = "ttir.slice"(%198, %209) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %211 = ttir.empty() : tensor<1x12x7x64xbf16>
    %212 = "ttir.neg"(%210, %211) : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %213 = ttir.empty() : tensor<1x12x7x64xbf16>
    %214 = "ttir.slice"(%198, %213) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
    %215 = ttir.empty() : tensor<1x12x7x128xbf16>
    %216 = "ttir.concat"(%212, %214, %215) <{dim = 3 : si32}> : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %217 = ttir.empty() : tensor<1x12x7x128xf32>
    %218 = "ttir.typecast"(%216, %217) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %219 = ttir.empty() : tensor<1x1x7x128xf32>
    %220 = "ttir.reshape"(%164, %219) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32>
    %221 = ttir.empty() : tensor<1x12x7x128xf32>
    %222 = "ttir.broadcast"(%220, %221) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %223 = ttir.empty() : tensor<1x12x7x128xf32>
    %224 = "ttir.multiply"(%218, %222, %223) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %225 = ttir.empty() : tensor<1x12x7x128xbf16>
    %226 = "ttir.typecast"(%224, %225) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %227 = ttir.empty() : tensor<1x12x7x128xbf16>
    %228 = "ttir.add"(%208, %226, %227) : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %229 = ttir.empty() : tensor<12x7x128xbf16>
    %230 = "ttir.reshape"(%228, %229) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<12x7x128xbf16>) -> tensor<12x7x128xbf16>
    %231 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %232 = "ttir.reshape"(%176, %231) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %233 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %234 = "ttir.broadcast"(%232, %233) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %235 = ttir.empty() : tensor<1x12x128x128xbf16>
    %236 = "ttir.reshape"(%234, %235) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %237 = ttir.empty() : tensor<1x12x128x128xbf16>
    %238 = "ttir.permute"(%236, %237) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %239 = ttir.empty() : tensor<12x128x128xbf16>
    %240 = "ttir.reshape"(%238, %239) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %241 = "ttir.dot_general"(%230, %240) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
    %242 = ttir.empty() : tensor<12x7x128xf32>
    %243 = "ttir.typecast"(%241, %242) <{conservative_folding = false}> : (tensor<12x7x128xbf16>, tensor<12x7x128xf32>) -> tensor<12x7x128xf32>
    %244 = ttir.empty() : tensor<1x12x7x128xf32>
    %245 = "ttir.reshape"(%243, %244) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %246 = ttir.empty() : tensor<1x1x1x1xf32>
    %247 = "ttir.reshape"(%33, %246) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32>
    %248 = ttir.empty() : tensor<1x12x7x128xf32>
    %249 = "ttir.broadcast"(%247, %248) <{broadcast_dimensions = array<i64: 1, 12, 7, 128>}> : (tensor<1x1x1x1xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %250 = ttir.empty() : tensor<1x12x7x128xf32>
    %251 = "ttir.multiply"(%245, %249, %250) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %252 = ttir.empty() : tensor<1x12x7x128xbf16>
    %253 = "ttir.typecast"(%251, %252) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %254 = ttir.empty() : tensor<7x128xf32>
    %255 = "ttir.typecast"(%31, %254) <{conservative_folding = false}> : (tensor<7x128xbf16>, tensor<7x128xf32>) -> tensor<7x128xf32>
    %256 = ttir.empty() : tensor<1x128xi64>
    %257 = "ttir.reshape"(%29, %256) <{shape = [1 : i32, 128 : i32]}> : (tensor<128xi64>, tensor<1x128xi64>) -> tensor<1x128xi64>
    %258 = ttir.empty() : tensor<7x128xi64>
    %259 = "ttir.broadcast"(%257, %258) <{broadcast_dimensions = array<i64: 7, 1>}> : (tensor<1x128xi64>, tensor<7x128xi64>) -> tensor<7x128xi64>
    %260 = ttir.empty() : tensor<7x1xi64>
    %261 = "ttir.reshape"(%1, %260) <{shape = [7 : i32, 1 : i32]}> : (tensor<7xi64>, tensor<7x1xi64>) -> tensor<7x1xi64>
    %262 = ttir.empty() : tensor<7x128xi64>
    %263 = "ttir.broadcast"(%261, %262) <{broadcast_dimensions = array<i64: 1, 128>}> : (tensor<7x1xi64>, tensor<7x128xi64>) -> tensor<7x128xi64>
    %264 = ttir.empty() : tensor<7x128xi1>
    %265 = "ttir.gt"(%259, %263, %264) : (tensor<7x128xi64>, tensor<7x128xi64>, tensor<7x128xi1>) -> tensor<7x128xi1>
    %266 = ttir.empty() : tensor<7x128xf32>
    %267 = "ttir.typecast"(%265, %266) <{conservative_folding = false}> : (tensor<7x128xi1>, tensor<7x128xf32>) -> tensor<7x128xf32>
    %268 = ttir.empty() : tensor<7x128xf32>
    %269 = "ttir.multiply"(%255, %267, %268) : (tensor<7x128xf32>, tensor<7x128xf32>, tensor<7x128xf32>) -> tensor<7x128xf32>
    %270 = ttir.empty() : tensor<7x128xbf16>
    %271 = "ttir.typecast"(%269, %270) <{conservative_folding = false}> : (tensor<7x128xf32>, tensor<7x128xbf16>) -> tensor<7x128xbf16>
    %272 = ttir.empty() : tensor<1x7x128xbf16>
    %273 = "ttir.reshape"(%271, %272) <{shape = [1 : i32, 7 : i32, 128 : i32]}> : (tensor<7x128xbf16>, tensor<1x7x128xbf16>) -> tensor<1x7x128xbf16>
    %274 = ttir.empty() : tensor<1x1x7x128xbf16>
    %275 = "ttir.reshape"(%273, %274) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xbf16>, tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xbf16>
    %276 = ttir.empty() : tensor<1x12x7x128xbf16>
    %277 = "ttir.broadcast"(%275, %276) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %278 = ttir.empty() : tensor<1x12x7x128xbf16>
    %279 = "ttir.add"(%253, %277, %278) : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %280 = ttir.empty() : tensor<1x12x7x128xf32>
    %281 = "ttir.typecast"(%279, %280) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %282 = ttir.empty() : tensor<1x12x7xf32>
    %283 = "ttir.max"(%281, %282) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7xf32>) -> tensor<1x12x7xf32>
    %284 = ttir.empty() : tensor<1x12x7x1xf32>
    %285 = "ttir.reshape"(%283, %284) <{shape = [1 : i32, 12 : i32, 7 : i32, 1 : i32]}> : (tensor<1x12x7xf32>, tensor<1x12x7x1xf32>) -> tensor<1x12x7x1xf32>
    %286 = ttir.empty() : tensor<1x12x7x128xf32>
    %287 = "ttir.broadcast"(%285, %286) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x7x1xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %288 = ttir.empty() : tensor<1x12x7x128xf32>
    %289 = "ttir.subtract"(%281, %287, %288) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %290 = ttir.empty() : tensor<1x12x7x128xf32>
    %291 = "ttir.exp"(%289, %290) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %292 = ttir.empty() : tensor<1x12x7xf32>
    %293 = "ttir.sum"(%291, %292) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7xf32>) -> tensor<1x12x7xf32>
    %294 = ttir.empty() : tensor<1x12x7x1xf32>
    %295 = "ttir.reshape"(%293, %294) <{shape = [1 : i32, 12 : i32, 7 : i32, 1 : i32]}> : (tensor<1x12x7xf32>, tensor<1x12x7x1xf32>) -> tensor<1x12x7x1xf32>
    %296 = ttir.empty() : tensor<1x12x7x128xf32>
    %297 = "ttir.broadcast"(%295, %296) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x7x1xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %298 = ttir.empty() : tensor<1x12x7x128xf32>
    %299 = "ttir.div"(%291, %297, %298) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
    %300 = ttir.empty() : tensor<1x12x7x128xbf16>
    %301 = "ttir.typecast"(%299, %300) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %302 = ttir.empty() : tensor<12x7x128xbf16>
    %303 = "ttir.reshape"(%301, %302) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<12x7x128xbf16>) -> tensor<12x7x128xbf16>
    %304 = ttir.empty() : tensor<1x4x1x128x128xbf16>
    %305 = "ttir.reshape"(%185, %304) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128x128xbf16>) -> tensor<1x4x1x128x128xbf16>
    %306 = ttir.empty() : tensor<1x4x3x128x128xbf16>
    %307 = "ttir.broadcast"(%305, %306) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>, tensor<1x4x3x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %308 = ttir.empty() : tensor<12x128x128xbf16>
    %309 = "ttir.reshape"(%307, %308) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x128x128xbf16>
    %310 = "ttir.dot_general"(%303, %309) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x7x128xbf16>, tensor<12x128x128xbf16>) -> tensor<12x7x128xbf16>
    %311 = ttir.empty() : tensor<1x12x7x128xbf16>
    %312 = "ttir.reshape"(%310, %311) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
    %313 = ttir.empty() : tensor<1x7x12x128xbf16>
    %314 = "ttir.permute"(%312, %313) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x12x7x128xbf16>, tensor<1x7x12x128xbf16>) -> tensor<1x7x12x128xbf16>
    %315 = ttir.empty() : tensor<7x1536xbf16>
    %316 = "ttir.reshape"(%314, %315) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x7x12x128xbf16>, tensor<7x1536xbf16>) -> tensor<7x1536xbf16>
    %317 = ttir.empty() : tensor<1536x3072xbf16>
    %318 = "ttir.permute"(%27, %317) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %319 = "ttir.dot_general"(%316, %318) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<7x3072xbf16>
    %320 = ttir.empty() : tensor<7x3072xbf16>
    %321 = "ttir.all_reduce"(%319, %320) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %322 = ttir.empty() : tensor<1x7x3072xbf16>
    %323 = "ttir.reshape"(%321, %322) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %324 = ttir.empty() : tensor<1x7x3072xbf16>
    %325 = "ttir.add"(%78, %323, %324) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %326 = ttir.empty() : tensor<3072xf32>
    %327 = "ttir.typecast"(%37, %326) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32>
    %328 = ttir.empty() : tensor<1x1x3072xf32>
    %329 = "ttir.reshape"(%327, %328) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32>
    %330 = ttir.empty() : tensor<1x7x3072xf32>
    %331 = "ttir.broadcast"(%329, %330) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %332 = ttir.empty() : tensor<1x7x3072xf32>
    %333 = "ttir.typecast"(%325, %332) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %334 = ttir.empty() : tensor<1x7x3072xf32>
    %335 = "ttir.pow"(%333, %50, %334) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %336 = ttir.empty() : tensor<1x7xf32>
    %337 = "ttir.sum"(%335, %336) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %338 = ttir.empty() : tensor<1x7xf32>
    %339 = "ttir.multiply"(%337, %45, %338) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %340 = ttir.empty() : tensor<1x7x1xf32>
    %341 = "ttir.reshape"(%339, %340) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %342 = ttir.empty() : tensor<1x7x1xf32>
    %343 = "ttir.add"(%341, %92, %342) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %344 = ttir.empty() : tensor<1x7x1xf32>
    %345 = "ttir.rsqrt"(%343, %344) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %346 = ttir.empty() : tensor<1x7xf32>
    %347 = "ttir.reshape"(%345, %346) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %348 = ttir.empty() : tensor<1x7x1xf32>
    %349 = "ttir.reshape"(%347, %348) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %350 = ttir.empty() : tensor<1x7x3072xf32>
    %351 = "ttir.broadcast"(%349, %350) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %352 = ttir.empty() : tensor<1x7x3072xf32>
    %353 = "ttir.multiply"(%333, %351, %352) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %354 = ttir.empty() : tensor<1x7x3072xbf16>
    %355 = "ttir.typecast"(%353, %354) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %356 = ttir.empty() : tensor<1x7x3072xf32>
    %357 = "ttir.typecast"(%355, %356) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %358 = ttir.empty() : tensor<1x7x3072xf32>
    %359 = "ttir.multiply"(%331, %357, %358) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %360 = ttir.empty() : tensor<1x7x3072xbf16>
    %361 = "ttir.typecast"(%359, %360) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %362 = ttir.empty() : tensor<7x3072xbf16>
    %363 = "ttir.reshape"(%361, %362) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %364 = ttir.empty() : tensor<3072x4096xbf16>
    %365 = "ttir.permute"(%39, %364) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %366 = "ttir.dot_general"(%363, %365) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
    %367 = ttir.empty() : tensor<1x7x4096xbf16>
    %368 = "ttir.reshape"(%366, %367) <{shape = [1 : i32, 7 : i32, 4096 : i32]}> : (tensor<7x4096xbf16>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %369 = ttir.empty() : tensor<1x7x4096xf32>
    %370 = "ttir.typecast"(%368, %369) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %371 = ttir.empty() : tensor<1x7x4096xbf16>
    %372 = "ttir.sigmoid"(%368, %371) : (tensor<1x7x4096xbf16>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %373 = ttir.empty() : tensor<1x7x4096xf32>
    %374 = "ttir.typecast"(%372, %373) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %375 = ttir.empty() : tensor<1x7x4096xf32>
    %376 = "ttir.multiply"(%370, %374, %375) : (tensor<1x7x4096xf32>, tensor<1x7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %377 = ttir.empty() : tensor<1x7x4096xbf16>
    %378 = "ttir.typecast"(%376, %377) <{conservative_folding = false}> : (tensor<1x7x4096xf32>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %379 = ttir.empty() : tensor<1x7x4096xf32>
    %380 = "ttir.typecast"(%378, %379) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %381 = ttir.empty() : tensor<3072x4096xbf16>
    %382 = "ttir.permute"(%25, %381) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %383 = "ttir.dot_general"(%363, %382) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16>
    %384 = ttir.empty() : tensor<7x4096xf32>
    %385 = "ttir.typecast"(%383, %384) <{conservative_folding = false}> : (tensor<7x4096xbf16>, tensor<7x4096xf32>) -> tensor<7x4096xf32>
    %386 = ttir.empty() : tensor<1x7x4096xf32>
    %387 = "ttir.reshape"(%385, %386) <{shape = [1 : i32, 7 : i32, 4096 : i32]}> : (tensor<7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %388 = ttir.empty() : tensor<1x7x4096xf32>
    %389 = "ttir.multiply"(%380, %387, %388) : (tensor<1x7x4096xf32>, tensor<1x7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32>
    %390 = ttir.empty() : tensor<1x7x4096xbf16>
    %391 = "ttir.typecast"(%389, %390) <{conservative_folding = false}> : (tensor<1x7x4096xf32>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16>
    %392 = ttir.empty() : tensor<7x4096xbf16>
    %393 = "ttir.reshape"(%391, %392) <{shape = [7 : i32, 4096 : i32]}> : (tensor<1x7x4096xbf16>, tensor<7x4096xbf16>) -> tensor<7x4096xbf16>
    %394 = ttir.empty() : tensor<4096x3072xbf16>
    %395 = "ttir.permute"(%23, %394) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %396 = "ttir.dot_general"(%393, %395) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<7x3072xbf16>
    %397 = ttir.empty() : tensor<7x3072xbf16>
    %398 = "ttir.all_reduce"(%396, %397) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %399 = ttir.empty() : tensor<1x7x3072xbf16>
    %400 = "ttir.reshape"(%398, %399) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %401 = ttir.empty() : tensor<1x7x3072xbf16>
    %402 = "ttir.add"(%325, %400, %401) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %403 = ttir.empty() : tensor<1x7x3072xf32>
    %404 = "ttir.typecast"(%402, %403) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %405 = ttir.empty() : tensor<1x7x3072xf32>
    %406 = "ttir.pow"(%404, %50, %405) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %407 = ttir.empty() : tensor<1x7xf32>
    %408 = "ttir.sum"(%406, %407) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %409 = ttir.empty() : tensor<1x7xf32>
    %410 = "ttir.multiply"(%408, %45, %409) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %411 = ttir.empty() : tensor<1x7x1xf32>
    %412 = "ttir.reshape"(%410, %411) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %413 = ttir.empty() : tensor<1x7x1xf32>
    %414 = "ttir.add"(%412, %92, %413) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %415 = ttir.empty() : tensor<1x7x1xf32>
    %416 = "ttir.rsqrt"(%414, %415) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %417 = ttir.empty() : tensor<1x7xf32>
    %418 = "ttir.reshape"(%416, %417) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
    %419 = ttir.empty() : tensor<1x7x1xf32>
    %420 = "ttir.reshape"(%418, %419) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
    %421 = ttir.empty() : tensor<1x7x3072xf32>
    %422 = "ttir.broadcast"(%420, %421) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %423 = ttir.empty() : tensor<1x7x3072xf32>
    %424 = "ttir.multiply"(%404, %422, %423) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %425 = ttir.empty() : tensor<1x7x3072xbf16>
    %426 = "ttir.typecast"(%424, %425) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %427 = ttir.empty() : tensor<1x7x3072xf32>
    %428 = "ttir.typecast"(%426, %427) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %429 = ttir.empty() : tensor<1x7x3072xf32>
    %430 = "ttir.multiply"(%191, %428, %429) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
    %431 = ttir.empty() : tensor<1x7x3072xbf16>
    %432 = "ttir.typecast"(%430, %431) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %433 = ttir.empty() : tensor<7x3072xbf16>
    %434 = "ttir.reshape"(%432, %433) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
    %435 = ttir.empty() : tensor<3072x64128xbf16>
    %436 = "ttir.permute"(%11, %435) <{permutation = array<i64: 1, 0>}> : (tensor<64128x3072xbf16>, tensor<3072x64128xbf16>) -> tensor<3072x64128xbf16>
    %437 = "ttir.dot_general"(%434, %436) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x64128xbf16>) -> tensor<7x64128xbf16>
    %438 = ttir.empty() : tensor<1x7x64128xbf16>
    %439 = "ttir.reshape"(%437, %438) <{shape = [1 : i32, 7 : i32, 64128 : i32]}> : (tensor<7x64128xbf16>, tensor<1x7x64128xbf16>) -> tensor<1x7x64128xbf16>
    %440 = ttir.empty() : tensor<1x8x128x128xbf16>
    %441 = "ttir.mesh_shard"(%176, %440) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %442 = ttir.empty() : tensor<1x8x128x128xbf16>
    %443 = "ttir.mesh_shard"(%185, %442) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>, tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %444 = ttir.empty() : tensor<7x128256xbf16>
    %445 = "ttir.mesh_shard"(%437, %444) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<7x64128xbf16>, tensor<7x128256xbf16>) -> tensor<7x128256xbf16>
    %446 = ttir.empty() : tensor<1x7x128256xbf16>
    %447 = "ttir.mesh_shard"(%439, %446) <{shard_dims = array<i64: -1, 2>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x7x64128xbf16>, tensor<1x7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %441, %443, %445, %447 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>
  }
}
2025-08-20 16:58:44.767 (   6.407s) [        5E2EB1C0]      module_builder.cc:526   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2025-08-20 16:58:44.767 (   6.407s) [        5E2EB1C0]      module_builder.cc:540   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2025-08-20 16:58:44.767 (   6.407s) [        5E2EB1C0]      module_builder.cc:548   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
TTIRFusingPass: Starting pass on operation
TTIRFusingPass: Successfully applied Conv2dTagWeights patterns
CacheFillUpdatePattern: Attempting to match ScatterOp at loc("scatter.117")
getCacheUpdatePositions: Checking ScatterOp at loc("scatter.117")
CacheFillUpdatePattern: Successfully fusing ScatterOp into FillCacheOp
CacheFillUpdatePattern: Attempting to match ScatterOp at loc("scatter.143")
getCacheUpdatePositions: Checking ScatterOp at loc("scatter.143")
CacheFillUpdatePattern: Successfully fusing ScatterOp into FillCacheOp
TTIRFusingPass: Successfully applied all fusion patterns
TTIRFusingPass: Completed pass on operation
TTIRFusingPass: Starting pass on operation
TTIRFusingPass: Successfully applied Conv2dTagWeights patterns
TTIRFusingPass: Successfully applied all fusion patterns
TTIRFusingPass: Completed pass on operation
TTIRFusingPass: Starting pass on operation
TTIRFusingPass: Successfully applied Conv2dTagWeights patterns
TTIRFusingPass: Successfully applied all fusion patterns
TTIRFusingPass: Completed pass on operation
2025-08-20 16:58:44.990 (   6.630s) [        5E2EB1C0]      module_builder.cc:615      1| TTNN Module:
module @SyncTensorsGraph.374 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.374 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99776, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184736, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99776, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193056, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5] -> (0, 0, (((d0 * s1) * (s2 * s3) + d1 * (s2 * s3) + d2) floordiv s4) mod 12, ((d0 * s1) * (s2 * s3) + d1 * (s2 * s3) + d2) floordiv (s4 * 12) + ((d0 * s1) * (s2 * s3) + d1 * (s2 * s3) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main_const_eval_0() -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 2.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        return %2 : tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
      }
      func.func @main(%arg0: tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg2: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg3: tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg4: tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg5: tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg6: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg7: tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg8: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg9: tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg10: tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg11: tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg12: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg13: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg14: tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg15: tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg16: tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg17: tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg18: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg19: tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg20: tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<7x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x7x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %1 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %2 = "ttnn.full"(%1) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 3.25520843E-4 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<1x7>}> : (!ttnn.device) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %3 = "ttnn.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %4 = "ttnn.mesh_shard"(%arg1, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %5 = "ttnn.mesh_shard"(%arg2, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %6 = "ttnn.mesh_shard"(%arg3, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %7 = "ttnn.mesh_shard"(%arg4, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %8 = "ttnn.mesh_shard"(%arg5, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg5) <{force = false}> : (tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %9 = "ttnn.mesh_shard"(%arg6, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %10 = "ttnn.mesh_shard"(%arg8, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg8) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %11 = "ttnn.mesh_shard"(%arg9, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %12 = "ttnn.mesh_shard"(%arg10, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %13 = "ttnn.mesh_shard"(%arg11, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg11) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %14 = "ttnn.mesh_shard"(%arg12, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg12) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %15 = "ttnn.mesh_shard"(%arg13, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg13) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %16 = "ttnn.mesh_shard"(%arg14, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg14) <{force = false}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %17 = "ttnn.mesh_shard"(%arg15, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg15) <{force = false}> : (tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %18 = "ttnn.mesh_shard"(%arg16, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg16) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %19 = "ttnn.mesh_shard"(%arg17, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg17) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %20 = "ttnn.mesh_shard"(%arg18, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg18) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %21 = "ttnn.mesh_shard"(%arg19, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg19) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %22 = "ttnn.mesh_shard"(%arg20, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg20) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %23 = "ttnn.typecast"(%9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %24 = "ttnn.reshape"(%23) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %25 = "ttnn.typecast"(%7) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %26 = "ttnn.reshape"(%25) <{shape = [7 : i32]}> : (tensor<1x7xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%25) <{force = false}> : (tensor<1x7xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %27 = "ttnn.from_device"(%26) : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%26) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %28 = "ttnn.to_layout"(%27) <{layout = #ttnn.layout<row_major>}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%27) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>) -> ()
        %29 = "ttnn.to_device"(%28, %1) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%28) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<system_memory>>>>) -> ()
        %30 = "ttnn.embedding"(%29, %8) : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%29) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %31 = "ttnn.reshape"(%30) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%30) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %32 = "ttnn.reduce_scatter"(%31, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%31) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %33 = "ttnn.reshape"(%32) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%32) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %34 = "ttnn.all_gather"(%33, %1) <{all_gather_dim = 1 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> {ttir.decomposed_from_all_reduce} : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%33) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %35 = "ttnn.typecast"(%34) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %36 = "ttnn.reshape"(%35) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %37 = "ttnn.pow"(%36, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%36) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %38 = "ttnn.sum"(%37) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%37) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %39 = "ttnn.multiply"(%38, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%38) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %40 = "ttnn.reshape"(%39) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%39) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %41 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %42 = "ttnn.add"(%40, %41) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%40) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %43 = "ttnn.rsqrt"(%42) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%42) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %44 = "ttnn.multiply"(%35, %43) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%43) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%35) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %45 = "ttnn.multiply"(%24, %44) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%44) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%24) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %46 = "ttnn.typecast"(%45) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%45) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %47 = "ttnn.matmul"(%46, %5) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %48 = "ttnn.reshape"(%47) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%47) <{force = false}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %49 = "ttnn.permute"(%48) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%48) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %50 = "ttnn.typecast"(%49) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %51 = "ttnn.reshape"(%4) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %52 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %53 = "ttnn.reshape"(%52) <{shape = [1 : i32, 1 : i32, 7 : i32]}> : (tensor<7xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%52) <{force = false}> : (tensor<7xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %54 = "ttnn.matmul"(%51, %53) <{transpose_a = false, transpose_b = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%53) <{force = false}> : (tensor<1x1x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%51) <{force = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %55 = "ttnn.permute"(%54) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%54) <{force = false}> : (tensor<1x64x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %56 = "ttnn.concat"(%55, %55) <{dim = 2 : si32}> : (tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%55) <{force = false}> : (tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %57 = "ttnn.cos"(%56) : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %58 = "ttnn.reshape"(%57) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %59 = "ttnn.multiply"(%50, %58) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%58) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%50) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %60 = "ttnn.typecast"(%59) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%59) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %61 = "ttnn.slice"(%49) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %62 = "ttnn.neg"(%61) : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%61) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %63 = "ttnn.slice"(%49) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%49) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %64 = "ttnn.concat"(%62, %63) <{dim = 3 : si32}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%63) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%62) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %65 = "ttnn.typecast"(%64) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%64) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %66 = "ttnn.sin"(%56) : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%56) <{force = false}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %67 = "ttnn.reshape"(%66) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %68 = "ttnn.multiply"(%65, %67) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%67) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%65) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %69 = "ttnn.typecast"(%68) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%68) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %70 = "ttnn.add"(%60, %69) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%69) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%60) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.fill_cache"(%10, %70) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%70) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %71 = "ttnn.matmul"(%46, %11) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %72 = "ttnn.reshape"(%71) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%71) <{force = false}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %73 = "ttnn.permute"(%72) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%72) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.fill_cache"(%12, %73) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%73) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %74 = "ttnn.typecast"(%22) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%22) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %75 = "ttnn.reshape"(%74) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%74) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %76 = "ttnn.matmul"(%46, %19) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%46) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %77 = "ttnn.reshape"(%76) <{shape = [1 : i32, 7 : i32, 12 : i32, 128 : i32]}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%76) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %78 = "ttnn.permute"(%77) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%77) <{force = false}> : (tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %79 = "ttnn.typecast"(%78) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %80 = "ttnn.reshape"(%79) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%79) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %81 = "ttnn.multiply"(%80, %57) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%80) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%57) <{force = false}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %82 = "ttnn.typecast"(%81) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%81) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %83 = "ttnn.slice"(%78) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %84 = "ttnn.neg"(%83) : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%83) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %85 = "ttnn.reshape"(%84) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%84) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %86 = "ttnn.slice"(%78) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%78) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %87 = "ttnn.reshape"(%86) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%86) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %88 = "ttnn.concat"(%85, %87) <{dim = 2 : si32}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%87) <{force = false}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%85) <{force = false}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %89 = "ttnn.typecast"(%88) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%88) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %90 = "ttnn.multiply"(%89, %66) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%89) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%66) <{force = false}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %91 = "ttnn.typecast"(%90) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%90) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %92 = "ttnn.add"(%82, %91) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%91) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%82) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %93 = "ttnn.reshape"(%10) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %94 = "ttnn.repeat"(%93) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%93) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %95 = "ttnn.reshape"(%94) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%94) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %96 = "ttnn.permute"(%95) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%95) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %97 = "ttnn.reshape"(%96) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%96) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %98 = "ttnn.matmul"(%92, %97) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%97) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%92) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %99 = "ttnn.typecast"(%98) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%98) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %100 = "ttnn.reshape"(%99) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%99) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %101 = "ttnn.reshape"(%18) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %102 = "ttnn.multiply"(%100, %101) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%101) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%100) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %103 = "ttnn.typecast"(%102) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%102) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %104 = "ttnn.typecast"(%17) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %105 = "ttnn.reshape"(%104) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<7x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%104) <{force = false}> : (tensor<7x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %106 = "ttnn.reshape"(%16) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %107 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32, 7 : i32, 1 : i32]}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %108 = "ttnn.typecast"(%106) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%106) <{force = false}> : (tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %109 = "ttnn.typecast"(%107) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x7x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%107) <{force = false}> : (tensor<1x1x7x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %110 = "ttnn.gt"(%108, %109) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%109) <{force = false}> : (tensor<1x1x7x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%108) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %111 = "ttnn.typecast"(%110) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%110) <{force = false}> : (tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %112 = "ttnn.multiply"(%105, %111) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%111) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%105) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %113 = "ttnn.typecast"(%112) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%112) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %114 = "ttnn.add"(%103, %113) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%113) <{force = false}> : (tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%103) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %115 = "ttnn.typecast"(%114) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%114) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %116 = "ttnn.max"(%115) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %117 = "ttnn.neg"(%116) : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%116) <{force = false}> : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %118 = "ttnn.add"(%115, %117) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%117) <{force = false}> : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%115) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %119 = "ttnn.softmax"(%118) <{dimension = 3 : si32}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%118) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %120 = "ttnn.typecast"(%119) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%119) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %121 = "ttnn.reshape"(%120) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%120) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %122 = "ttnn.reshape"(%12) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %123 = "ttnn.repeat"(%122) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%122) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %124 = "ttnn.reshape"(%123) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%123) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %125 = "ttnn.matmul"(%121, %124) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%124) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%121) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %126 = "ttnn.reshape"(%125) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%125) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %127 = "ttnn.concatenate_heads"(%126) : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%126) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %128 = "ttnn.reshape"(%127) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%127) <{force = false}> : (tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %129 = "ttnn.matmul"(%128, %15) <{transpose_a = false, transpose_b = true}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%128) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %130 = "ttnn.reshape"(%129) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%129) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %131 = "ttnn.reduce_scatter"(%130, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%130) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %132 = "ttnn.reshape"(%131) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%131) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %133 = "ttnn.all_gather"(%132, %1) <{all_gather_dim = 1 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> {ttir.decomposed_from_all_reduce} : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%132) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %134 = "ttnn.add"(%34, %133) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%133) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%34) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %135 = "ttnn.typecast"(%20) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %136 = "ttnn.reshape"(%135) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%135) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %137 = "ttnn.typecast"(%134) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %138 = "ttnn.reshape"(%137) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %139 = "ttnn.pow"(%138, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%138) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %140 = "ttnn.sum"(%139) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%139) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %141 = "ttnn.multiply"(%140, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%140) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %142 = "ttnn.reshape"(%141) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%141) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %143 = "ttnn.add"(%142, %41) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%142) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %144 = "ttnn.rsqrt"(%143) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%143) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %145 = "ttnn.multiply"(%137, %144) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%144) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%137) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %146 = "ttnn.multiply"(%136, %145) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%145) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%136) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %147 = "ttnn.typecast"(%146) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%146) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %148 = "ttnn.matmul"(%147, %21) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %149 = "ttnn.typecast"(%148) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %150 = "ttnn.sigmoid"(%148) : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%148) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %151 = "ttnn.typecast"(%150) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%150) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %152 = "ttnn.multiply"(%149, %151) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%151) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%149) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %153 = "ttnn.matmul"(%147, %14) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%147) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %154 = "ttnn.typecast"(%153) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%153) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %155 = "ttnn.multiply"(%152, %154) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%154) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%152) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %156 = "ttnn.typecast"(%155) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%155) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %157 = "ttnn.matmul"(%156, %13) <{transpose_a = false, transpose_b = true}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%156) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %158 = "ttnn.reshape"(%157) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%157) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %159 = "ttnn.reduce_scatter"(%158, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%158) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %160 = "ttnn.reshape"(%159) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%159) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %161 = "ttnn.all_gather"(%160, %1) <{all_gather_dim = 1 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> {ttir.decomposed_from_all_reduce} : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%160) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %162 = "ttnn.add"(%134, %161) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%161) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%134) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %163 = "ttnn.typecast"(%162) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%162) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %164 = "ttnn.reshape"(%163) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %165 = "ttnn.pow"(%164, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%164) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %166 = "ttnn.sum"(%165) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%165) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %167 = "ttnn.multiply"(%166, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%166) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %168 = "ttnn.reshape"(%167) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%167) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %169 = "ttnn.add"(%168, %41) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%168) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%41) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %170 = "ttnn.rsqrt"(%169) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%169) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %171 = "ttnn.multiply"(%163, %170) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%170) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%163) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %172 = "ttnn.multiply"(%75, %171) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%171) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%75) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %173 = "ttnn.typecast"(%172) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%172) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %174 = "ttnn.matmul"(%173, %8) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%173) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %175 = "ttnn.reshape"(%174) <{shape = [1 : i32, 7 : i32, 64128 : i32]}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>
        %176 = "ttnn.to_layout"(%10) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %177 = "ttnn.from_device"(%176) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%176) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %178 = "ttnn.mesh_shard"(%177, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%177) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %179 = "ttnn.to_layout"(%12) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %180 = "ttnn.from_device"(%179) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%179) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %181 = "ttnn.mesh_shard"(%180, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%180) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %182 = "ttnn.to_layout"(%174) <{layout = #ttnn.layout<row_major>}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%174) <{force = false}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %183 = "ttnn.from_device"(%182) : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%182) <{force = false}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %184 = "ttnn.mesh_shard"(%183, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<7x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%183) <{force = false}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        %185 = "ttnn.to_layout"(%175) <{layout = #ttnn.layout<row_major>}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%175) <{force = false}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %186 = "ttnn.from_device"(%185) : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%185) <{force = false}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        %187 = "ttnn.mesh_shard"(%186, %1) <{shard_dims = array<i64: -1, 2>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x7x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>>
        "ttnn.deallocate"(%186) <{force = false}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>) -> ()
        return %178, %181, %184, %187 : tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<7x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>>, tensor<1x7x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>>
      }
    }
  }
}
2025-08-20 16:58:45.049 (   6.689s) [        5E2EB1C0]loaded_executable_insta:98       1| [LIFECYCLE] LoadedExecutableInstance constructor - instance created: 0x55afbf76d580
2025-08-20 16:58:45.049 (   6.689s) [        5E2EB1C0]loaded_executable_insta:535      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2025-08-20 16:58:45.049 (   6.689s) [        5E2EB1C0]loaded_executable_insta:554      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2025-08-20 16:58:45.050 (   6.690s) [        5E2EB1C0]              stubs.inc:76    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2025-08-20 16:58:45.050 (   6.690s) [        5E2EB1C0]      error_instance.cc:49       1| ErrorInstance::PJRT_Error_Message
2025-08-20 16:58:45.050 (   6.690s) [        5E2EB1C0]      error_instance.cc:58       1| ErrorInstance::PJRT_Error_GetCode
2025-08-20 16:58:45.050 (   6.690s) [        5E2EB1C0]      error_instance.cc:43       1| ErrorInstance::PJRT_Error_Destroy
2025-08-20 16:58:45.050 (   6.690s) [        5E2EB1C0] executable_instance.cc:106      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-08-20 16:58:45.050 (   6.690s) [        5E2EB1C0] executable_instance.cc:106      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-08-20 16:58:45.061 (   6.701s) [        5E2EB1C0] executable_instance.cc:106      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-08-20 16:58:45.061 (   6.701s) [        5E2EB1C0] executable_instance.cc:106      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-08-20 16:58:45.078 (   6.718s) [        52FFD640]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.718s) [        BB7FE640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.718s) [        D8FF9640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.718s) [        BBFFF640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.718s) [        D97FA640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.718s) [        BB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.718s) [        D8FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.718s) [        52FFD640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.718s) [        BBFFF640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        52FFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        52FFD640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        D97FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        52FFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        52FFD640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        D97FA640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        D97FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        52FFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BBFFF640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        D8FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     buffer_instance.cc:578      1| BufferInstance::PJRT_Buffer_Device
2025-08-20 16:58:45.079 (   6.719s) [        BB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-08-20 16:58:45.079 (   6.719s) [        52FFD640] executable_instance.cc:138      1| ExecutableInstance::PJRT_Executable_NumOutputs
2025-08-20 16:58:45.079 (   6.719s) [        52FFD640]loaded_executable_insta:590      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2025-08-20 16:58:45.079 (   6.719s) [        52FFD640]loaded_executable_insta:95       1| LoadedExecutableInstance::Execute
2025-08-20 16:58:45.079 (   6.719s) [        52FFD640]loaded_executable_insta:114      1| [DEVICE] Runtime device not opened, opening devices...
2025-08-20 16:58:45.079 (   6.719s) [        52FFD640]loaded_executable_insta:204      1| [DEVICE] Starting device opening process with 21 args on 2 devices
2025-08-20 16:58:45.079 (   6.719s) [        52FFD640]loaded_executable_insta:207      1| [DEVICE] Found 2 unique device IDs from arguments
2025-08-20 16:58:45.080 (   6.719s) [        52FFD640]loaded_executable_insta:249      1| [DEVICE] Opening mesh device with shape [1, 2]
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Device grid size = { 8, 8 }
2025-08-20 16:58:45.443 (   7.082s) [        52FFD640]loaded_executable_insta:253      1| [DEVICE] Mesh device opened successfully
2025-08-20 16:58:45.443 (   7.082s) [        52FFD640]loaded_executable_insta:121      1| [DEVICE] Successfully opened runtime device
2025-08-20 16:58:45.443 (   7.083s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy replicate
2025-08-20 16:58:45.443 (   7.083s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 0)
2025-08-20 16:58:45.444 (   7.084s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy replicate
2025-08-20 16:58:45.444 (   7.084s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 1)
2025-08-20 16:58:45.445 (   7.085s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy shard
2025-08-20 16:58:45.445 (   7.085s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 2)
2025-08-20 16:58:45.985 (   7.625s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy replicate
2025-08-20 16:58:45.986 (   7.625s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 3)
2025-08-20 16:58:45.986 (   7.626s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy replicate
2025-08-20 16:58:45.986 (   7.626s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 4)
2025-08-20 16:58:45.987 (   7.627s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy shard
2025-08-20 16:58:45.987 (   7.627s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 5)
2025-08-20 16:58:46.621 (   8.260s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy replicate
2025-08-20 16:58:46.621 (   8.261s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 6)
2025-08-20 16:58:47.137 (   8.777s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy replicate
2025-08-20 16:58:47.138 (   8.777s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 7)
2025-08-20 16:58:47.138 (   8.778s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy shard
2025-08-20 16:58:47.139 (   8.778s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 8)
2025-08-20 16:58:47.646 (   9.286s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy shard
2025-08-20 16:58:47.646 (   9.286s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 9)
2025-08-20 16:58:47.652 (   9.292s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy shard
2025-08-20 16:58:47.652 (   9.292s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 10)
2025-08-20 16:58:47.655 (   9.294s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy shard
2025-08-20 16:58:47.655 (   9.294s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 11)
2025-08-20 16:58:48.240 (   9.879s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy shard
2025-08-20 16:58:48.240 (   9.879s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 12)
2025-08-20 16:58:48.756 (  10.396s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy shard
2025-08-20 16:58:48.757 (  10.396s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 13)
2025-08-20 16:58:49.323 (  10.963s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy replicate
2025-08-20 16:58:49.323 (  10.963s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 14)
2025-08-20 16:58:49.324 (  10.964s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy replicate
2025-08-20 16:58:49.324 (  10.964s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 15)
2025-08-20 16:58:49.796 (  11.436s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy replicate
2025-08-20 16:58:49.796 (  11.436s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 16)
2025-08-20 16:58:49.797 (  11.437s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy shard
2025-08-20 16:58:49.797 (  11.437s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 17)
2025-08-20 16:58:50.368 (  12.008s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy replicate
2025-08-20 16:58:50.368 (  12.008s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 18)
2025-08-20 16:58:50.372 (  12.012s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy shard
2025-08-20 16:58:50.372 (  12.012s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 19)
2025-08-20 16:58:50.384 (  12.024s) [        52FFD640]loaded_executable_insta:410      1| [STRATEGY] Found tensor with strategy replicate
2025-08-20 16:58:50.384 (  12.024s) [        52FFD640]loaded_executable_insta:340      1| [LAYOUT] Converting layout for tensor handle 0x7f8b70cbea70 (arg 20)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Cache miss or invalid cache for function: main_const_eval_0
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Starting execution of program: main_const_eval_0
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 2.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main_const_eval_0
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | executed sub-func: main_const_eval_0
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<si32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %1 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %2 = "ttnn.full"(%1) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 3.25520843E-4 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<1x7>}> : (!ttnn.device) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %3 = "ttnn.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %4 = "ttnn.mesh_shard"(%arg1, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %5 = "ttnn.mesh_shard"(%arg2, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %6 = "ttnn.mesh_shard"(%arg3, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %7 = "ttnn.mesh_shard"(%arg4, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %8 = "ttnn.mesh_shard"(%arg5, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg5) <{force = false}> : (tensor<128256x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %9 = "ttnn.mesh_shard"(%arg6, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %10 = "ttnn.mesh_shard"(%arg8, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg8) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %11 = "ttnn.mesh_shard"(%arg9, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<1024x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %12 = "ttnn.mesh_shard"(%arg10, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %13 = "ttnn.mesh_shard"(%arg11, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg11) <{force = false}> : (tensor<3072x8192xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %14 = "ttnn.mesh_shard"(%arg12, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg12) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %15 = "ttnn.mesh_shard"(%arg13, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg13) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %16 = "ttnn.mesh_shard"(%arg14, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg14) <{force = false}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %17 = "ttnn.mesh_shard"(%arg15, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg15) <{force = false}> : (tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %18 = "ttnn.mesh_shard"(%arg16, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg16) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %19 = "ttnn.mesh_shard"(%arg17, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg17) <{force = false}> : (tensor<3072x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %20 = "ttnn.mesh_shard"(%arg18, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg18) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %21 = "ttnn.mesh_shard"(%arg19, %1) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg19) <{force = false}> : (tensor<8192x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %22 = "ttnn.mesh_shard"(%arg20, %1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%arg20) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %23 = "ttnn.typecast"(%9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.67")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%9) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.67")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %24 = "ttnn.reshape"(%23) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.67")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%23) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.67")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %25 = "ttnn.typecast"(%7) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.33")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x7xsi32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.33")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %26 = "ttnn.reshape"(%25) <{shape = [7 : i32]}> : (tensor<1x7xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.33")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%25) <{force = false}> : (tensor<1x7xui32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.33")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %27 = "ttnn.from_device"(%26) : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>> loc("gather.34_workaround"("gather.34"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%26) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("gather.34_workaround"("gather.34"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %28 = "ttnn.to_layout"(%27) <{layout = #ttnn.layout<row_major>}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<system_memory>>>> loc("gather.34_workaround"("gather.34"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%27) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #ttnn.buffer_type<system_memory>>>>) -> () loc("gather.34_workaround"("gather.34"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %29 = "ttnn.to_device"(%28, %1) <{memory_config = #ttnn.memory_config<<dram>, <interleaved>>}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.34_workaround"("gather.34"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%28) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<system_memory>>>>) -> () loc("gather.34_workaround"("gather.34"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %30 = "ttnn.embedding"(%29, %8) : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.34")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%29) <{force = false}> : (tensor<7xui32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("gather.34")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %31 = "ttnn.reshape"(%30) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.34_reduceScatter_reshape_to_4d"("gather.34_reduceScatter"("gather.34")))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%30) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("gather.34_reduceScatter_reshape_to_4d"("gather.34_reduceScatter"("gather.34")))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %32 = "ttnn.reduce_scatter"(%31, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.34_reduceScatter_reduce_scatter_4d"("gather.34_reduceScatter"("gather.34")))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%31) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("gather.34_reduceScatter_reduce_scatter_4d"("gather.34_reduceScatter"("gather.34")))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %33 = "ttnn.reshape"(%32) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.34_reduceScatter"("gather.34"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%32) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("gather.34_reduceScatter"("gather.34"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %34 = "ttnn.all_gather"(%33, %1) <{all_gather_dim = 1 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> {ttir.decomposed_from_all_reduce} : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("gather.34")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%33) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("gather.34")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %35 = "ttnn.typecast"(%34) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.36")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %36 = "ttnn.reshape"(%35) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.36")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %37 = "ttnn.pow"(%36, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("power.38")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%36) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("power.38")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %38 = "ttnn.sum"(%37) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reduce.45")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%37) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reduce.45")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %39 = "ttnn.multiply"(%38, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.54")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%38) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.54")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %40 = "ttnn.reshape"(%39) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.54")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%39) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.54")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %41 = "ttnn.reshape"(%6) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.71_tm0_tm1_tm1_tm0_tm1"("reshape.71_tm0_tm1_tm1_tm0"("reshape.71_tm0_tm1_tm1"("reshape.71_tm0_tm1"("reshape.71_tm0"("reshape.71"))))))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%6) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.71_tm0_tm1_tm1_tm0_tm1"("reshape.71_tm0_tm1_tm1_tm0"("reshape.71_tm0_tm1_tm1"("reshape.71_tm0_tm1"("reshape.71_tm0"("reshape.71"))))))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %42 = "ttnn.add"(%40, %41) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("add.59")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%40) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.59")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %43 = "ttnn.rsqrt"(%42) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("rsqrt.60")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%42) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("rsqrt.60")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %44 = "ttnn.multiply"(%35, %43) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.63")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%43) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.63")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%35) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.63")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %45 = "ttnn.multiply"(%24, %44) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.69")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%44) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.69")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%24) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.69")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %46 = "ttnn.typecast"(%45) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.70")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%45) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.70")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %47 = "ttnn.matmul"(%46, %5) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.72")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%5) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.72")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %48 = "ttnn.reshape"(%47) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.74")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%47) <{force = false}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.74")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %49 = "ttnn.permute"(%48) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("transpose.75")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%48) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("transpose.75")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %50 = "ttnn.typecast"(%49) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.92")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %51 = "ttnn.reshape"(%4) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.13")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%4) <{force = false}> : (tensor<64xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.13")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %52 = "ttnn.typecast"(%3) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.8")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %53 = "ttnn.reshape"(%52) <{shape = [1 : i32, 1 : i32, 7 : i32]}> : (tensor<7xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.8")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%52) <{force = false}> : (tensor<7xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.8")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %54 = "ttnn.matmul"(%51, %53) <{transpose_a = false, transpose_b = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x64x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.16")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%53) <{force = false}> : (tensor<1x1x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.16")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%51) <{force = false}> : (tensor<1x64x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.16")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %55 = "ttnn.permute"(%54) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("transpose.17")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%54) <{force = false}> : (tensor<1x64x7xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("transpose.17")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %56 = "ttnn.concat"(%55, %55) <{dim = 2 : si32}> : (tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("concatenate.18")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%55) <{force = false}> : (tensor<1x7x64xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.18")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %57 = "ttnn.cos"(%56) : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("cosine.86")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %58 = "ttnn.reshape"(%57) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("broadcast.94")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %59 = "ttnn.multiply"(%50, %58) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.95")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%58) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.95")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%50) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.95")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %60 = "ttnn.typecast"(%59) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.96")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%59) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.96")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %61 = "ttnn.slice"(%49) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("slice.77")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %62 = "ttnn.neg"(%61) : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("negate.78")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%61) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("negate.78")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %63 = "ttnn.slice"(%49) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("slice.76")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%49) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("slice.76")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %64 = "ttnn.concat"(%62, %63) <{dim = 3 : si32}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("concatenate.79")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%63) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.79")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%62) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.79")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %65 = "ttnn.typecast"(%64) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.80")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%64) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.80")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %66 = "ttnn.sin"(%56) : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("sine.19")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%56) <{force = false}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("sine.19")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %67 = "ttnn.reshape"(%66) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("broadcast.82")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %68 = "ttnn.multiply"(%65, %67) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.83")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%67) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.83")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%65) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.83")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %69 = "ttnn.typecast"(%68) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.84")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%68) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.84")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %70 = "ttnn.add"(%60, %69) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("add.99")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%69) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.99")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%60) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.99")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.fill_cache"(%10, %70) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("scatter.117")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%70) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("scatter.117")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %71 = "ttnn.matmul"(%46, %11) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.123")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%11) <{force = false}> : (tensor<512x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.123")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %72 = "ttnn.reshape"(%71) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.125")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%71) <{force = false}> : (tensor<7x512xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.125")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %73 = "ttnn.permute"(%72) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("transpose.126")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%72) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("transpose.126")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.fill_cache"(%12, %73) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("scatter.143")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%73) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("scatter.143")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %74 = "ttnn.typecast"(%22) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.363")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%22) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.363")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %75 = "ttnn.reshape"(%74) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.363")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%74) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.363")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %76 = "ttnn.matmul"(%46, %19) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.208")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%46) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.208")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%19) <{force = false}> : (tensor<1536x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.208")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %77 = "ttnn.reshape"(%76) <{shape = [1 : i32, 7 : i32, 12 : i32, 128 : i32]}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.210")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%76) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.210")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %78 = "ttnn.permute"(%77) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("transpose.211")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%77) <{force = false}> : (tensor<1x7x12x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("transpose.211")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %79 = "ttnn.typecast"(%78) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.222")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %80 = "ttnn.reshape"(%79) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.222")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%79) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.222")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %81 = "ttnn.multiply"(%80, %57) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.225")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%80) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.225")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%57) <{force = false}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.225")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %82 = "ttnn.typecast"(%81) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.226")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%81) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.226")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %83 = "ttnn.slice"(%78) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("slice.213")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %84 = "ttnn.neg"(%83) : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("negate.214")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%83) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("negate.214")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %85 = "ttnn.reshape"(%84) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("negate.214")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%84) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("negate.214")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %86 = "ttnn.slice"(%78) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("slice.212")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%78) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("slice.212")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %87 = "ttnn.reshape"(%86) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("concatenate.215")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%86) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.215")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %88 = "ttnn.concat"(%85, %87) <{dim = 2 : si32}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("concatenate.215")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%87) <{force = false}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.215")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%85) <{force = false}> : (tensor<12x7x64xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("concatenate.215")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %89 = "ttnn.typecast"(%88) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.216")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%88) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.216")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %90 = "ttnn.multiply"(%89, %66) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.219")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%89) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.219")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%66) <{force = false}> : (tensor<1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.219")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %91 = "ttnn.typecast"(%90) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.220")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%90) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.220")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %92 = "ttnn.add"(%82, %91) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("add.229")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%91) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.229")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%82) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.229")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %93 = "ttnn.reshape"(%10) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("broadcast.198")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %94 = "ttnn.repeat"(%93) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("broadcast.198")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%93) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("broadcast.198")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %95 = "ttnn.reshape"(%94) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.199")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%94) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.199")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %96 = "ttnn.permute"(%95) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("transpose.200")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%95) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("transpose.200")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %97 = "ttnn.reshape"(%96) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.202")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%96) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.202")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %98 = "ttnn.matmul"(%92, %97) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.232")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%97) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.232")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%92) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.232")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %99 = "ttnn.typecast"(%98) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.234")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%98) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.234")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %100 = "ttnn.reshape"(%99) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.234")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%99) <{force = false}> : (tensor<12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.234")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %101 = "ttnn.reshape"(%18) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("broadcast.235")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%18) <{force = false}> : (tensor<f32, #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("broadcast.235")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %102 = "ttnn.multiply"(%100, %101) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.236")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%101) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.236")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%100) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.236")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %103 = "ttnn.typecast"(%102) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.237")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%102) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.237")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %104 = "ttnn.typecast"(%17) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.179")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%17) <{force = false}> : (tensor<7x128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.179")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %105 = "ttnn.reshape"(%104) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<7x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.179")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%104) <{force = false}> : (tensor<7x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.179")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %106 = "ttnn.reshape"(%16) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("broadcast.241_tm0_tm1_tm0_tm0"("broadcast.241_tm0_tm1_tm0"("broadcast.241_tm0_tm1"("broadcast.241_tm0"("broadcast.241")))))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%16) <{force = false}> : (tensor<128xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("broadcast.241_tm0_tm1_tm0_tm0"("broadcast.241_tm0_tm1_tm0"("broadcast.241_tm0_tm1"("broadcast.241_tm0"("broadcast.241")))))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %107 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32, 7 : i32, 1 : i32]}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("broadcast.241_tm0_tm1_tm0_tm1"("broadcast.241_tm0_tm1_tm0"("broadcast.241_tm0_tm1"("broadcast.241_tm0"("broadcast.241")))))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%3) <{force = false}> : (tensor<7xsi32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("broadcast.241_tm0_tm1_tm0_tm1"("broadcast.241_tm0_tm1_tm0"("broadcast.241_tm0_tm1"("broadcast.241_tm0"("broadcast.241")))))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %108 = "ttnn.typecast"(%106) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("compare.176_workaround"("compare.176"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%106) <{force = false}> : (tensor<1x1x1x128xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("compare.176_workaround"("compare.176"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %109 = "ttnn.typecast"(%107) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x7x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("compare.176_workaround"("compare.176"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%107) <{force = false}> : (tensor<1x1x7x1xsi32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("compare.176_workaround"("compare.176"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %110 = "ttnn.gt"(%108, %109) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("compare.176")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%109) <{force = false}> : (tensor<1x1x7x1xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("compare.176")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%108) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("compare.176")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %111 = "ttnn.typecast"(%110) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.177")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%110) <{force = false}> : (tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.177")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %112 = "ttnn.multiply"(%105, %111) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.180")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%111) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.180")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%105) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.180")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %113 = "ttnn.typecast"(%112) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.181")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%112) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.181")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %114 = "ttnn.add"(%103, %113) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("add.242")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%113) <{force = false}> : (tensor<1x1x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.242")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%103) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.242")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %115 = "ttnn.typecast"(%114) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.243")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%114) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.243")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %116 = "ttnn.max"(%115) <{dim_arg = [3 : i32], keep_dim = true}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reduce.249")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %117 = "ttnn.neg"(%116) : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("subtract.251_neg"("subtract.251"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%116) <{force = false}> : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("subtract.251_neg"("subtract.251"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %118 = "ttnn.add"(%115, %117) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("subtract.251")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%117) <{force = false}> : (tensor<1x12x7x1xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("subtract.251")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%115) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("subtract.251")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %119 = "ttnn.softmax"(%118) <{dimension = 3 : si32}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("divide.260")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%118) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("divide.260")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %120 = "ttnn.typecast"(%119) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.261")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%119) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.261")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %121 = "ttnn.reshape"(%120) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.261")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%120) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.261")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %122 = "ttnn.reshape"(%12) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("broadcast.166")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %123 = "ttnn.repeat"(%122) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("broadcast.166")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%122) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("broadcast.166")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %124 = "ttnn.reshape"(%123) <{shape = [12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.169")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%123) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.169")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %125 = "ttnn.matmul"(%121, %124) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.264")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%124) <{force = false}> : (tensor<12x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.264")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%121) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.264")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %126 = "ttnn.reshape"(%125) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.265")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%125) <{force = false}> : (tensor<12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.265")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %127 = "ttnn.concatenate_heads"(%126) : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.268")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%126) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.268")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %128 = "ttnn.reshape"(%127) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.268")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%127) <{force = false}> : (tensor<1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reshape.268")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %129 = "ttnn.matmul"(%128, %15) <{transpose_a = false, transpose_b = true}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.269")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%128) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.269")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%15) <{force = false}> : (tensor<3072x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.269")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %130 = "ttnn.reshape"(%129) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.269_reduceScatter_reshape_to_4d"("dot.269_reduceScatter"("dot.269")))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%129) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.269_reduceScatter_reshape_to_4d"("dot.269_reduceScatter"("dot.269")))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %131 = "ttnn.reduce_scatter"(%130, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.269_reduceScatter_reduce_scatter_4d"("dot.269_reduceScatter"("dot.269")))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%130) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.269_reduceScatter_reduce_scatter_4d"("dot.269_reduceScatter"("dot.269")))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %132 = "ttnn.reshape"(%131) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.269_reduceScatter"("dot.269"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%131) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.269_reduceScatter"("dot.269"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %133 = "ttnn.all_gather"(%132, %1) <{all_gather_dim = 1 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> {ttir.decomposed_from_all_reduce} : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.269")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%132) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.269")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %134 = "ttnn.add"(%34, %133) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("add.273")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%133) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.273")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%34) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.273")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %135 = "ttnn.typecast"(%20) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.305")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%20) <{force = false}> : (tensor<3072xbf16, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.305")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %136 = "ttnn.reshape"(%135) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.305")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%135) <{force = false}> : (tensor<3072xf32, #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.305")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %137 = "ttnn.typecast"(%134) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.274")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %138 = "ttnn.reshape"(%137) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.274")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %139 = "ttnn.pow"(%138, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("power.276")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%138) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("power.276")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %140 = "ttnn.sum"(%139) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reduce.283")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%139) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reduce.283")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %141 = "ttnn.multiply"(%140, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.292")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%140) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.292")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %142 = "ttnn.reshape"(%141) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.292")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%141) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.292")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %143 = "ttnn.add"(%142, %41) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("add.297")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%142) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.297")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %144 = "ttnn.rsqrt"(%143) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("rsqrt.298")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%143) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("rsqrt.298")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %145 = "ttnn.multiply"(%137, %144) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.301")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%144) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.301")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%137) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.301")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %146 = "ttnn.multiply"(%136, %145) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.307")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%145) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.307")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%136) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.307")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %147 = "ttnn.typecast"(%146) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.308")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%146) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.308")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %148 = "ttnn.matmul"(%147, %21) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.316")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%21) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.316")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %149 = "ttnn.typecast"(%148) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.320")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %150 = "ttnn.sigmoid"(%148) : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("logistic.318")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%148) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("logistic.318")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %151 = "ttnn.typecast"(%150) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.319")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%150) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.319")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %152 = "ttnn.multiply"(%149, %151) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.321")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%151) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.321")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%149) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.321")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %153 = "ttnn.matmul"(%147, %14) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.310")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%147) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.310")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%14) <{force = false}> : (tensor<4096x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.310")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %154 = "ttnn.typecast"(%153) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.312")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%153) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.312")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %155 = "ttnn.multiply"(%152, %154) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.324")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%154) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.324")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%152) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.324")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %156 = "ttnn.typecast"(%155) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.325")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%155) <{force = false}> : (tensor<7x4096xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.325")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %157 = "ttnn.matmul"(%156, %13) <{transpose_a = false, transpose_b = true}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.327")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%156) <{force = false}> : (tensor<7x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.327")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%13) <{force = false}> : (tensor<3072x4096xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.327")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %158 = "ttnn.reshape"(%157) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.327_reduceScatter_reshape_to_4d"("dot.327_reduceScatter"("dot.327")))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%157) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.327_reduceScatter_reshape_to_4d"("dot.327_reduceScatter"("dot.327")))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %159 = "ttnn.reduce_scatter"(%158, %1) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.327_reduceScatter_reduce_scatter_4d"("dot.327_reduceScatter"("dot.327")))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%158) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.327_reduceScatter_reduce_scatter_4d"("dot.327_reduceScatter"("dot.327")))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %160 = "ttnn.reshape"(%159) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.327_reduceScatter"("dot.327"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%159) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.327_reduceScatter"("dot.327"))
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %161 = "ttnn.all_gather"(%160, %1) <{all_gather_dim = 1 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> {ttir.decomposed_from_all_reduce} : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, !ttnn.device) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.327")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%160) <{force = false}> : (tensor<7x1536xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.327")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %162 = "ttnn.add"(%134, %161) <{output_dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("add.331")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%161) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.331")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%134) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.331")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %163 = "ttnn.typecast"(%162) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.332")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%162) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.332")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %164 = "ttnn.reshape"(%163) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.332")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %165 = "ttnn.pow"(%164, %0) : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("power.334")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%164) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("power.334")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%0) <{force = false}> : (tensor<1x1x1xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("power.334")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %166 = "ttnn.sum"(%165) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reduce.341")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%165) <{force = false}> : (tensor<1x7x3072xf32, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("reduce.341")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %167 = "ttnn.multiply"(%166, %2) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.350")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%166) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.350")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.350")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %168 = "ttnn.reshape"(%167) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.350")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%167) <{force = false}> : (tensor<1x7xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.350")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %169 = "ttnn.add"(%168, %41) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("add.355")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%168) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.355")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%41) <{force = false}> : (tensor<1x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("add.355")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %170 = "ttnn.rsqrt"(%169) : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("rsqrt.356")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%169) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("rsqrt.356")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %171 = "ttnn.multiply"(%163, %170) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.359")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%170) <{force = false}> : (tensor<7x1xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.359")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%163) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.359")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %172 = "ttnn.multiply"(%75, %171) <{output_dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("multiply.365")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%171) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.365")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%75) <{force = false}> : (tensor<1x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("multiply.365")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %173 = "ttnn.typecast"(%172) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("convert.366")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%172) <{force = false}> : (tensor<7x3072xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("convert.366")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %174 = "ttnn.matmul"(%173, %8) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("dot.371")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%173) <{force = false}> : (tensor<7x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.371")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%8) <{force = false}> : (tensor<64128x3072xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<2004x96x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc("dot.371")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %175 = "ttnn.reshape"(%174) <{shape = [1 : i32, 7 : i32, 64128 : i32]}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>> loc("reshape.372")
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %176 = "ttnn.to_layout"(%10) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %177 = "ttnn.from_device"(%176) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%176) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %178 = "ttnn.mesh_shard"(%177, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%177) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %179 = "ttnn.to_layout"(%12) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %180 = "ttnn.from_device"(%179) : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%179) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %181 = "ttnn.mesh_shard"(%180, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #ttnn.buffer_type<system_memory>>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%180) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %182 = "ttnn.to_layout"(%174) <{layout = #ttnn.layout<row_major>}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%174) <{force = false}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %183 = "ttnn.from_device"(%182) : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%182) <{force = false}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %184 = "ttnn.mesh_shard"(%183, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<7x128256xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%183) <{force = false}> : (tensor<7x64128xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %185 = "ttnn.to_layout"(%175) <{layout = #ttnn.layout<row_major>}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%175) <{force = false}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2004x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %186 = "ttnn.from_device"(%185) : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%185) <{force = false}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<dram>>, <interleaved>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: %187 = "ttnn.mesh_shard"(%186, %1) <{shard_dims = array<i64: -1, 2>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 1, 2>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>, !ttnn.device) -> tensor<1x7x128256xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x128256xbf16, #ttnn.buffer_type<system_memory>>>> loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Executing operation: "ttnn.deallocate"(%186) <{force = false}> : (tensor<1x7x64128xbf16, #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x64128xbf16, #ttnn.buffer_type<system_memory>>>>) -> () loc(unknown)
[32m            RuntimeTTNN[0m | [1m[38;5;240m   DEBUG[0m | Finished execution of program: main
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:466      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_ElementType
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:466      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_ElementType
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:466      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_ElementType
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:466      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_ElementType
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:466      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_ElementType
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:466      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_ElementType
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:466      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_ElementType
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:466      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_ElementType
2025-08-20 16:59:20.486 (  42.126s) [        52FFD640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_Destroy
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
2025-08-20 16:59:20.487 (  42.127s) [        52FFD640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_Destroy
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
2025-08-20 16:59:20.487 (  42.127s) [        52FFD640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_Destroy
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
2025-08-20 16:59:20.487 (  42.127s) [        52FFD640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_Destroy
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
AFTER MARK STEP Enumerating input 0 with shape torch.Size([128]) and device xla:0
with xla tensor id 1 and sharding annotation {replicated}
AFTER MARK STEP Enumerating input 1 with shape torch.Size([7, 128]) and device xla:0
with xla tensor id 2 and sharding annotation {replicated}
AFTER MARK STEP Enumerating input 2 with shape torch.Size([1, 8, 128, 128]) and device xla:0
with xla tensor id 3 and sharding annotation {replicated}
AFTER MARK STEP Enumerating input 3 with shape torch.Size([1, 8, 128, 128]) and device xla:0
with xla tensor id 4 and sharding annotation {replicated}
AFTER MARK STEP Enumerating input 4 with shape torch.Size([1, 7]) and device xla:0
with xla tensor id 5 and sharding annotation {replicated}
AFTER MARK STEP Enumerating input 5 with shape torch.Size([128256, 3072]) and device xla:0
with xla tensor id 6 and sharding annotation {devices=[2,1]<=[2]}
AFTER MARK STEP Enumerating input 6 with shape torch.Size([7]) and device xla:0
with xla tensor id 7 and sharding annotation {replicated}
AFTER MARK STEP Enumerating input 7 with shape torch.Size([64]) and device xla:0
with xla tensor id 8 and sharding annotation {replicated}
AFTER MARK STEP Enumerating input 8 with shape torch.Size([3072]) and device xla:0
with xla tensor id 9 and sharding annotation {replicated}
AFTER MARK STEP Enumerating input 9 with shape torch.Size([3072, 3072]) and device xla:0
with xla tensor id 10 and sharding annotation {devices=[2,1]<=[2]}
AFTER MARK STEP Enumerating input 10 with shape torch.Size([1024, 3072]) and device xla:0
with xla tensor id 11 and sharding annotation {devices=[2,1]<=[2]}
AFTER MARK STEP Enumerating input 11 with shape torch.Size([1024, 3072]) and device xla:0
with xla tensor id 12 and sharding annotation {devices=[2,1]<=[2]}
AFTER MARK STEP Enumerating input 12 with shape torch.Size([3072, 3072]) and device xla:0
with xla tensor id 13 and sharding annotation {devices=[1,2]<=[2]}
AFTER MARK STEP Enumerating input 13 with shape torch.Size([3072]) and device xla:0
with xla tensor id 14 and sharding annotation {replicated}
AFTER MARK STEP Enumerating input 14 with shape torch.Size([8192, 3072]) and device xla:0
with xla tensor id 15 and sharding annotation {devices=[2,1]<=[2]}
AFTER MARK STEP Enumerating input 15 with shape torch.Size([8192, 3072]) and device xla:0
with xla tensor id 16 and sharding annotation {devices=[2,1]<=[2]}
AFTER MARK STEP Enumerating input 16 with shape torch.Size([3072, 8192]) and device xla:0
with xla tensor id 17 and sharding annotation {devices=[1,2]<=[2]}
AFTER MARK STEP Enumerating input 17 with shape torch.Size([3072]) and device xla:0
with xla tensor id 18 and sharding annotation {replicated}
2025-08-20 16:59:20.488 (  42.128s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:20.488 (  42.128s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:20.488 (  42.128s) [        5E2EB1C0]     buffer_instance.cc:454      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-08-20 16:59:20.488 (  42.128s) [        5E2EB1C0]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_ElementType
2025-08-20 16:59:20.488 (  42.128s) [        5E2EB1C0]     buffer_instance.cc:443      1| BufferInstance::PJRT_Buffer_Dimensions
2025-08-20 16:59:20.489 (  42.128s) [        5E2EB1C0]     buffer_instance.cc:476      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-08-20 16:59:20.489 (  42.128s) [        5E2EB1C0]     buffer_instance.cc:497      1| [BUFFER_TO_HOST] Source buffer shape: [1, 7, 128256], data_type: 13, required_size: 1795584 bytes
2025-08-20 16:59:20.489 (  42.128s) [        5E2EB1C0]     buffer_instance.cc:508      1| [BUFFER_TO_HOST] Destination buffer: dst_size=1795584 bytes, dst_ptr=0x55afc2fabe80
2025-08-20 16:59:20.489 (  42.129s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:59:20.489 (  42.129s) [        C5F8B640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
[XLA Cache] Adding tensor to cache: key=(140276321385936, (1, 7, 128256), torch.bfloat16, 'xla:0')
2025-08-20 16:59:20.491 (  42.131s) [        5E2EB1C0]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_Destroy
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
2025-08-20 16:59:20.491 (  42.131s) [        5E2EB1C0]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_Destroy
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
2025-08-20 16:59:20.491 (  42.131s) [        5E2EB1C0]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_Destroy
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
2025-08-20 16:59:20.491 (  42.131s) [        5E2EB1C0]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_Destroy
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
AFTER PUSH TENSORS TO DEVICE Enumerating input 2 with shape torch.Size([1, 8, 128, 128]) and device xla:0
with xla tensor id 3 and sharding annotation {replicated}
AFTER PUSH TENSORS TO DEVICE Enumerating input 3 with shape torch.Size([1, 8, 128, 128]) and device xla:0
with xla tensor id 4 and sharding annotation {replicated}
"valueGenerated tokens: ['"value']
Note: Using experimental XLA backend.
[XLA Debug] Processing 18 input specs:
[XLA Debug] Input 0: kind=InputKind.PARAMETER, arg=TensorArgument(name='p__fx_const_folded_attrs_0'), target=_FX_CONST_FOLDED_ATTRS.0
[XLA Debug] Input 0 is InputKind.PARAMETER, source tensor shape: torch.Size([128]), dtype: torch.int64, device: cpu
[XLA Debug] Input 0 not in cache - shape: torch.Size([128]), shard spec: None, moving to XLA device
[XLA Debug] Input 0 no sharding applied
[XLA Cache] Adding tensor to cache: key=(140276320720016, (128,), torch.int64, 'cpu'), xla_tensor_id=239, xla_sharding_spec=
[XLA Debug] Input 0 cached tensor with device: xla:0
[XLA Debug] Input 1: kind=InputKind.PARAMETER, arg=TensorArgument(name='p__fx_const_folded_attrs_1'), target=_FX_CONST_FOLDED_ATTRS.1
[XLA Debug] Input 1 is InputKind.PARAMETER, source tensor shape: torch.Size([1, 128]), dtype: torch.bfloat16, device: cpu
[XLA Debug] Input 1 not in cache - shape: torch.Size([1, 128]), shard spec: None, moving to XLA device
[XLA Debug] Input 1 no sharding applied
[XLA Cache] Adding tensor to cache: key=(140279536288288, (1, 128), torch.bfloat16, 'cpu'), xla_tensor_id=240, xla_sharding_spec=
[XLA Debug] Input 1 cached tensor with device: xla:0
[XLA Debug] Input 2: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___key_cache_0'), target=kwargs____past_key_values___key_cache_0
[XLA Debug] Input 2 is InputKind.BUFFER, source tensor shape: torch.Size([1, 8, 128, 128]), dtype: torch.bfloat16, device: cpu
[XLA Cache] Retrieved tensor from cache: key=(140279576504784, (1, 8, 128, 128), torch.bfloat16, 'cpu'), xla_tensor_id=3, xla_sharding_spec={replicated}, cached tensor device xla:0
[XLA Debug] Input 3: kind=InputKind.BUFFER, arg=TensorArgument(name='b_kwargs____past_key_values___value_cache_0'), target=kwargs____past_key_values___value_cache_0
[XLA Debug] Input 3 is InputKind.BUFFER, source tensor shape: torch.Size([1, 8, 128, 128]), dtype: torch.bfloat16, device: cpu
[XLA Cache] Retrieved tensor from cache: key=(140280331266032, (1, 8, 128, 128), torch.bfloat16, 'cpu'), xla_tensor_id=4, xla_sharding_spec={replicated}, cached tensor device xla:0
[XLA Debug] Input 4: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_0'), target=None
[XLA Debug] Input 4 is USER_INPUT, adding None placeholder
[XLA Debug] Input 5: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_1'), target=None
[XLA Debug] Input 5 is USER_INPUT, adding None placeholder
[XLA Debug] Input 6: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_2'), target=None
[XLA Debug] Input 6 is USER_INPUT, adding None placeholder
[XLA Debug] Input 7: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_3'), target=None
[XLA Debug] Input 7 is USER_INPUT, adding None placeholder
[XLA Debug] Input 8: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_4'), target=None
[XLA Debug] Input 8 is USER_INPUT, adding None placeholder
[XLA Debug] Input 9: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_5'), target=None
[XLA Debug] Input 9 is USER_INPUT, adding None placeholder
[XLA Debug] Input 10: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_6'), target=None
[XLA Debug] Input 10 is USER_INPUT, adding None placeholder
[XLA Debug] Input 11: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_7'), target=None
[XLA Debug] Input 11 is USER_INPUT, adding None placeholder
[XLA Debug] Input 12: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_8'), target=None
[XLA Debug] Input 12 is USER_INPUT, adding None placeholder
[XLA Debug] Input 13: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_9'), target=None
[XLA Debug] Input 13 is USER_INPUT, adding None placeholder
[XLA Debug] Input 14: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_10'), target=None
[XLA Debug] Input 14 is USER_INPUT, adding None placeholder
[XLA Debug] Input 15: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_11'), target=None
[XLA Debug] Input 15 is USER_INPUT, adding None placeholder
[XLA Debug] Input 16: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_12'), target=None
[XLA Debug] Input 16 is USER_INPUT, adding None placeholder
[XLA Debug] Input 17: kind=InputKind.USER_INPUT, arg=TensorArgument(name='args_13'), target=None
[XLA Debug] Input 17 is USER_INPUT, adding None placeholder
[XLA Debug] Initialization complete - total inputs: 18, user input indices: [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]
[XLA Cache] Adding tensor to cache: key=(140276321385936, (1, 1), torch.int64, 'cpu'), xla_tensor_id=241, xla_sharding_spec=
[XLA Cache] Retrieved tensor from cache: key=(140279541386992, (128256, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=6, xla_sharding_spec={devices=[2,1]<=[2]}, cached tensor device xla:0
[XLA Cache] Adding tensor to cache: key=(140275786336352, (1,), torch.int64, 'cpu'), xla_tensor_id=242, xla_sharding_spec=
[XLA Cache] Retrieved tensor from cache: key=(140279533236720, (64,), torch.float32, 'cpu'), xla_tensor_id=8, xla_sharding_spec={replicated}, cached tensor device xla:0
[XLA Cache] Retrieved tensor from cache: key=(140279541383632, (3072,), torch.bfloat16, 'cpu'), xla_tensor_id=9, xla_sharding_spec={replicated}, cached tensor device xla:0
[XLA Cache] Retrieved tensor from cache: key=(140279532951552, (3072, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=10, xla_sharding_spec={devices=[2,1]<=[2]}, cached tensor device xla:0
[XLA Cache] Retrieved tensor from cache: key=(140279541383712, (1024, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=11, xla_sharding_spec={devices=[2,1]<=[2]}, cached tensor device xla:0
[XLA Cache] Retrieved tensor from cache: key=(140279532955392, (1024, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=12, xla_sharding_spec={devices=[2,1]<=[2]}, cached tensor device xla:0
[XLA Cache] Retrieved tensor from cache: key=(140279532950752, (3072, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=13, xla_sharding_spec={devices=[1,2]<=[2]}, cached tensor device xla:0
[XLA Cache] Retrieved tensor from cache: key=(140279541386192, (3072,), torch.bfloat16, 'cpu'), xla_tensor_id=14, xla_sharding_spec={replicated}, cached tensor device xla:0
[XLA Cache] Retrieved tensor from cache: key=(140279541384912, (8192, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=15, xla_sharding_spec={devices=[2,1]<=[2]}, cached tensor device xla:0
[XLA Cache] Retrieved tensor from cache: key=(140279541390272, (8192, 3072), torch.bfloat16, 'cpu'), xla_tensor_id=16, xla_sharding_spec={devices=[2,1]<=[2]}, cached tensor device xla:0
[XLA Cache] Retrieved tensor from cache: key=(140279541399072, (3072, 8192), torch.bfloat16, 'cpu'), xla_tensor_id=17, xla_sharding_spec={devices=[1,2]<=[2]}, cached tensor device xla:0
[XLA Cache] Retrieved tensor from cache: key=(140279533239760, (3072,), torch.bfloat16, 'cpu'), xla_tensor_id=18, xla_sharding_spec={replicated}, cached tensor device xla:0
2025-08-20 16:59:21.964 (  43.604s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:59:21.964 (  43.604s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:59:21.964 (  43.604s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:59:21.964 (  43.604s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:59:21.964 (  43.604s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:59:21.964 (  43.604s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [1, 1] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:59:21.965 (  43.604s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:59:21.965 (  43.604s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [1, 1] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [1] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:59:21.965 (  43.605s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:59:21.966 (  43.605s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [1] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:59:21.966 (  43.605s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:59:21.966 (  43.605s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:59:21.966 (  43.605s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:59:21.966 (  43.605s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:59:21.966 (  43.605s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:59:21.966 (  43.605s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:59:21.966 (  43.605s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [128] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]     buffer_instance.cc:213      1| [BUFFER] Creating OWNED host tensor with shape [128] (semantics: other, supported_dtype: false)
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:59:21.966 (  43.606s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [1, 128] (semantics: ZeroCopy/other)
2025-08-20 16:59:21.967 (  43.606s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:59:21.967 (  43.606s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-08-20 16:59:21.967 (  43.606s) [        5E2EB1C0]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-08-20 16:59:21.967 (  43.606s) [        5E2EB1C0]     client_instance.cc:509      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-08-20 16:59:21.967 (  43.606s) [        5E2EB1C0]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-08-20 16:59:21.967 (  43.606s) [        5E2EB1C0]     buffer_instance.cc:228      1| [BUFFER] Creating BORROWED host tensor with shape [1, 128] (semantics: ZeroCopy/other)
2025-08-20 16:59:21.967 (  43.606s) [        5E2EB1C0]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-08-20 16:59:21.967 (  43.606s) [        5E2EB1C0]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
BEFORE MARK STEP Enumerating input 0 with shape torch.Size([128]) and device xla:0
with xla tensor id 239 and sharding annotation 
BEFORE MARK STEP Enumerating input 1 with shape torch.Size([1, 128]) and device xla:0
with xla tensor id 240 and sharding annotation {replicated}
BEFORE MARK STEP Enumerating input 2 with shape torch.Size([1, 8, 128, 128]) and device xla:0
with xla tensor id 3 and sharding annotation {replicated}
BEFORE MARK STEP Enumerating input 3 with shape torch.Size([1, 8, 128, 128]) and device xla:0
with xla tensor id 4 and sharding annotation {replicated}
BEFORE MARK STEP Enumerating input 4 with shape torch.Size([1, 1]) and device xla:0
with xla tensor id 241 and sharding annotation 
BEFORE MARK STEP Enumerating input 5 with shape torch.Size([128256, 3072]) and device xla:0
with xla tensor id 6 and sharding annotation {devices=[2,1]<=[2]}
BEFORE MARK STEP Enumerating input 6 with shape torch.Size([1]) and device xla:0
with xla tensor id 242 and sharding annotation 
BEFORE MARK STEP Enumerating input 7 with shape torch.Size([64]) and device xla:0
with xla tensor id 8 and sharding annotation {replicated}
BEFORE MARK STEP Enumerating input 8 with shape torch.Size([3072]) and device xla:0
with xla tensor id 9 and sharding annotation {replicated}
BEFORE MARK STEP Enumerating input 9 with shape torch.Size([3072, 3072]) and device xla:0
with xla tensor id 10 and sharding annotation {devices=[2,1]<=[2]}
BEFORE MARK STEP Enumerating input 10 with shape torch.Size([1024, 3072]) and device xla:0
with xla tensor id 11 and sharding annotation {devices=[2,1]<=[2]}
BEFORE MARK STEP Enumerating input 11 with shape torch.Size([1024, 3072]) and device xla:0
with xla tensor id 12 and sharding annotation {devices=[2,1]<=[2]}
BEFORE MARK STEP Enumerating input 12 with shape torch.Size([3072, 3072]) and device xla:0
with xla tensor id 13 and sharding annotation {devices=[1,2]<=[2]}
BEFORE MARK STEP Enumerating input 13 with shape torch.Size([3072]) and device xla:0
with xla tensor id 14 and sharding annotation {replicated}
BEFORE MARK STEP Enumerating input 14 with shape torch.Size([8192, 3072]) and device xla:0
with xla tensor id 15 and sharding annotation {devices=[2,1]<=[2]}
BEFORE MARK STEP Enumerating input 15 with shape torch.Size([8192, 3072]) and device xla:0
with xla tensor id 16 and sharding annotation {devices=[2,1]<=[2]}
BEFORE MARK STEP Enumerating input 16 with shape torch.Size([3072, 8192]) and device xla:0
with xla tensor id 17 and sharding annotation {devices=[1,2]<=[2]}
BEFORE MARK STEP Enumerating input 17 with shape torch.Size([3072]) and device xla:0
with xla tensor id 18 and sharding annotation {replicated}
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.972 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.612s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.973 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.974 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.974 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.974 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.974 (  43.613s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.974 (  43.614s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.974 (  43.614s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:21.974 (  43.614s) [        5E2EB1C0]     buffer_instance.cc:526      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-08-20 16:59:22.000 (  43.640s) [        5E2EB1C0]     client_instance.cc:471      1| ClientInstance::PJRT_Client_Compile
2025-08-20 16:59:22.000 (  43.640s) [        5E2EB1C0]      module_builder.cc:101      1| ModuleBuilder::buildModule
2025-08-20 16:59:22.002 (  43.642s) [        5E2EB1C0]      module_builder.cc:157      1| VHLO Module:
module @SyncTensorsGraph.370 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1x!vhlo.i64_v1>, %arg1: !vhlo.tensor_v1<64x!vhlo.f32_v1>, %arg2: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg3: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg4: !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, %arg5: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, %arg6: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg7: !vhlo.tensor_v1<!vhlo.i64_v1>, %arg8: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg9: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg10: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, %arg11: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg12: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg13: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg14: !vhlo.tensor_v1<128x!vhlo.i64_v1>, %arg15: !vhlo.tensor_v1<1x128x!vhlo.bf16_v1>, %arg16: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg17: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg18: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg19: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg20: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : () -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<3.25520843E-4> : tensor<1x1xf32>>}> : () -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %5 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %6 = "vhlo.compare_v1"(%arg0, %0) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.bool_v1>
    %7 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %8 = "vhlo.add_v1"(%arg0, %7) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %9 = "vhlo.select_v1"(%6, %8, %arg0) : (!vhlo.tensor_v1<1x!vhlo.bool_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.i64_v1>
    %11 = "vhlo.convert_v1"(%arg6) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %12 = "vhlo.reshape_v1"(%11) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %13 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1>
    %14 = "vhlo.convert_v1"(%13) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.ui32_v1>
    %15 = "vhlo.gather_v2"(%arg5, %14) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3072]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %16 = "vhlo.reshape_v1"(%15) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %17 = "vhlo.convert_v1"(%16) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %18 = "vhlo.power_v1"(%17, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %19 = "vhlo.reduce_v1"(%18, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %184 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%184) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %20 = "vhlo.multiply_v1"(%19, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %21 = "vhlo.reshape_v1"(%20) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %22 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %23 = "vhlo.add_v1"(%21, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %24 = "vhlo.rsqrt_v2"(%23) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %25 = "vhlo.reshape_v1"(%24) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %26 = "vhlo.broadcast_in_dim_v1"(%25) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %27 = "vhlo.multiply_v1"(%17, %26) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %28 = "vhlo.convert_v1"(%27) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %29 = "vhlo.convert_v1"(%28) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %30 = "vhlo.multiply_v1"(%12, %29) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %31 = "vhlo.convert_v1"(%30) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %32 = "vhlo.reshape_v1"(%31) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %33 = "vhlo.transpose_v1"(%arg2) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %34 = "vhlo.dot_general_v2"(%32, %33) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %35 = "vhlo.reshape_v1"(%34) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %36 = "vhlo.convert_v1"(%35) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %37 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %38 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>
    %39 = "vhlo.convert_v1"(%38) : (!vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %40 = "vhlo.dot_general_v2"(%37, %39) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %41 = "vhlo.reshape_v1"(%40) : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %42 = "vhlo.concatenate_v1"(%41, %41) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %43 = "vhlo.cosine_v2"(%42) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %44 = "vhlo.convert_v1"(%43) : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>
    %45 = "vhlo.reshape_v1"(%44) : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>
    %46 = "vhlo.convert_v1"(%45) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>
    %47 = "vhlo.reshape_v1"(%46) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %48 = "vhlo.broadcast_in_dim_v1"(%47) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %49 = "vhlo.multiply_v1"(%36, %48) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %50 = "vhlo.convert_v1"(%49) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %51 = "vhlo.slice_v1"(%35) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %52 = "vhlo.negate_v1"(%51) : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %53 = "vhlo.slice_v1"(%35) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>
    %54 = "vhlo.concatenate_v1"(%52, %53) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %55 = "vhlo.convert_v1"(%54) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %56 = "vhlo.sine_v2"(%42) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %57 = "vhlo.convert_v1"(%56) : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>
    %58 = "vhlo.reshape_v1"(%57) : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>
    %59 = "vhlo.convert_v1"(%58) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>
    %60 = "vhlo.reshape_v1"(%59) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>
    %61 = "vhlo.broadcast_in_dim_v1"(%60) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %62 = "vhlo.multiply_v1"(%55, %61) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>
    %63 = "vhlo.convert_v1"(%62) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %64 = "vhlo.add_v1"(%50, %63) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %65 = "vhlo.scatter_v2"(%arg8, %10, %64) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %66 = "vhlo.custom_call_v1"(%65) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %67 = "vhlo.transpose_v1"(%arg9) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %68 = "vhlo.dot_general_v2"(%32, %67) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>
    %69 = "vhlo.reshape_v1"(%68) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>
    %70 = "vhlo.scatter_v2"(%arg10, %10, %69) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %71 = "vhlo.custom_call_v1"(%70) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>
    %72 = "vhlo.convert_v1"(%arg20) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %73 = "vhlo.reshape_v1"(%72) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %74 = "vhlo.transpose_v1"(%arg17) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %75 = "vhlo.dot_general_v2"(%32, %74) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %76 = "vhlo.reshape_v1"(%75) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %77 = "vhlo.convert_v1"(%76) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %78 = "vhlo.broadcast_in_dim_v1"(%47) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %79 = "vhlo.multiply_v1"(%77, %78) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %80 = "vhlo.convert_v1"(%79) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %81 = "vhlo.slice_v1"(%76) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %82 = "vhlo.negate_v1"(%81) : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %83 = "vhlo.slice_v1"(%76) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>
    %84 = "vhlo.concatenate_v1"(%82, %83) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %85 = "vhlo.convert_v1"(%84) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %86 = "vhlo.broadcast_in_dim_v1"(%60) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %87 = "vhlo.multiply_v1"(%85, %86) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %88 = "vhlo.convert_v1"(%87) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %89 = "vhlo.add_v1"(%80, %88) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %90 = "vhlo.reshape_v1"(%89) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %91 = "vhlo.broadcast_in_dim_v1"(%65) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %92 = "vhlo.reshape_v1"(%91) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %93 = "vhlo.transpose_v1"(%92) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>
    %94 = "vhlo.reshape_v1"(%93) : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %95 = "vhlo.dot_general_v2"(%90, %94) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %96 = "vhlo.reshape_v1"(%95) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %97 = "vhlo.convert_v1"(%96) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %98 = "vhlo.broadcast_in_dim_v1"(%arg16) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %99 = "vhlo.multiply_v1"(%97, %98) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %100 = "vhlo.convert_v1"(%99) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %101 = "vhlo.convert_v1"(%arg15) : (!vhlo.tensor_v1<1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.f32_v1>
    %102 = "vhlo.reshape_v1"(%arg14) : (!vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.i64_v1>
    %103 = "vhlo.broadcast_in_dim_v1"(%arg0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.i64_v1>
    %104 = "vhlo.compare_v1"(%102, %103) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<1x128x!vhlo.i64_v1>, !vhlo.tensor_v1<1x128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.bool_v1>
    %105 = "vhlo.convert_v1"(%104) : (!vhlo.tensor_v1<1x128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.f32_v1>
    %106 = "vhlo.multiply_v1"(%101, %105) : (!vhlo.tensor_v1<1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.f32_v1>
    %107 = "vhlo.convert_v1"(%106) : (!vhlo.tensor_v1<1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.bf16_v1>
    %108 = "vhlo.reshape_v1"(%107) : (!vhlo.tensor_v1<1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>
    %109 = "vhlo.broadcast_in_dim_v1"(%108) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %110 = "vhlo.add_v1"(%100, %109) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %111 = "vhlo.convert_v1"(%110) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %112 = "vhlo.reduce_v1"(%111, %2) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %184 = "vhlo.maximum_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%184) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %113 = "vhlo.broadcast_in_dim_v1"(%112) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %114 = "vhlo.subtract_v1"(%111, %113) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %115 = "vhlo.exponential_v2"(%114) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %116 = "vhlo.reduce_v1"(%115, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %184 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%184) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>
    %117 = "vhlo.broadcast_in_dim_v1"(%116) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %118 = "vhlo.divide_v1"(%115, %117) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>
    %119 = "vhlo.convert_v1"(%118) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>
    %120 = "vhlo.reshape_v1"(%119) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %121 = "vhlo.broadcast_in_dim_v1"(%70) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>
    %122 = "vhlo.reshape_v1"(%121) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>
    %123 = "vhlo.dot_general_v2"(%120, %122) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>
    %124 = "vhlo.reshape_v1"(%123) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %125 = "vhlo.transpose_v1"(%arg13) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %126 = "vhlo.dot_general_v2"(%124, %125) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %127 = "vhlo.reshape_v1"(%126) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %128 = "vhlo.add_v1"(%16, %127) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %129 = "vhlo.convert_v1"(%arg18) {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{replicated}">} : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %130 = "vhlo.reshape_v1"(%129) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %131 = "vhlo.convert_v1"(%128) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %132 = "vhlo.power_v1"(%131, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %133 = "vhlo.reduce_v1"(%132, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %184 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%184) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %134 = "vhlo.multiply_v1"(%133, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %135 = "vhlo.reshape_v1"(%134) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %136 = "vhlo.add_v1"(%135, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %137 = "vhlo.rsqrt_v2"(%136) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %138 = "vhlo.reshape_v1"(%137) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %139 = "vhlo.broadcast_in_dim_v1"(%138) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %140 = "vhlo.multiply_v1"(%131, %139) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %141 = "vhlo.convert_v1"(%140) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %142 = "vhlo.convert_v1"(%141) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %143 = "vhlo.multiply_v1"(%130, %142) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %144 = "vhlo.convert_v1"(%143) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %145 = "vhlo.reshape_v1"(%144) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %146 = "vhlo.transpose_v1"(%arg19) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %147 = "vhlo.dot_general_v2"(%145, %146) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %148 = "vhlo.reshape_v1"(%147) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %149 = "vhlo.convert_v1"(%148) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %150 = "vhlo.logistic_v2"(%148) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %151 = "vhlo.convert_v1"(%150) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %152 = "vhlo.multiply_v1"(%149, %151) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %153 = "vhlo.convert_v1"(%152) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %154 = "vhlo.convert_v1"(%153) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %155 = "vhlo.transpose_v1"(%arg12) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %156 = "vhlo.dot_general_v2"(%145, %155) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %157 = "vhlo.reshape_v1"(%156) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %158 = "vhlo.convert_v1"(%157) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %159 = "vhlo.multiply_v1"(%154, %158) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>
    %160 = "vhlo.convert_v1"(%159) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>
    %161 = "vhlo.reshape_v1"(%160) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>
    %162 = "vhlo.transpose_v1"(%arg11) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %163 = "vhlo.dot_general_v2"(%161, %162) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %164 = "vhlo.reshape_v1"(%163) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %165 = "vhlo.add_v1"(%128, %164) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %166 = "vhlo.convert_v1"(%165) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %167 = "vhlo.power_v1"(%166, %5) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %168 = "vhlo.reduce_v1"(%167, %1) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %184 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%184) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %169 = "vhlo.multiply_v1"(%168, %3) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %170 = "vhlo.reshape_v1"(%169) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %171 = "vhlo.add_v1"(%170, %22) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %172 = "vhlo.rsqrt_v2"(%171) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>
    %173 = "vhlo.reshape_v1"(%172) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1>
    %174 = "vhlo.broadcast_in_dim_v1"(%173) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %175 = "vhlo.multiply_v1"(%166, %174) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %176 = "vhlo.convert_v1"(%175) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %177 = "vhlo.convert_v1"(%176) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %178 = "vhlo.multiply_v1"(%73, %177) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>
    %179 = "vhlo.convert_v1"(%178) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %180 = "vhlo.reshape_v1"(%179) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>
    %181 = "vhlo.transpose_v1"(%arg5) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,128256]{0,1}">} : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>
    %182 = "vhlo.dot_general_v2"(%180, %181) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>
    %183 = "vhlo.reshape_v1"(%182) : (!vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1>
    "vhlo.return_v1"(%66, %71, %182, %183) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}
2025-08-20 16:59:22.047 (  43.687s) [        5E2EB1C0]      module_builder.cc:196      1| SHLO Module:
module @SyncTensorsGraph.370 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<1xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg1: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg2: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg3: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg4: tensor<1x1xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg5: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg6: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg7: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg8: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}, {}, {}]>}, %arg9: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg10: tensor<1x8x128x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}, {}, {}]>}, %arg11: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg12: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg13: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg14: tensor<128xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg15: tensor<1x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg16: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) {
    %c = stablehlo.constant dense<0> : tensor<1xi64>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_1 = stablehlo.constant dense<3.25520843E-4> : tensor<1x1xf32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32>
    %1 = stablehlo.compare  LT, %arg0, %c : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1>
    %2 = stablehlo.reshape %arg7 : (tensor<i64>) -> tensor<1xi64>
    %3 = stablehlo.add %arg0, %2 : tensor<1xi64>
    %4 = stablehlo.select %1, %3, %arg0 : tensor<1xi1>, tensor<1xi64>
    %5 = stablehlo.reshape %4 : (tensor<1xi64>) -> tensor<1x1xi64>
    %6 = stablehlo.convert %arg6 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %7 = stablehlo.reshape %6 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %8 = stablehlo.convert %arg4 : (tensor<1x1xi64>) -> tensor<1x1xui32>
    %9 = stablehlo.reshape %8 : (tensor<1x1xui32>) -> tensor<1xui32>
    %10 = "stablehlo.gather"(%arg5, %9) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16>
    %11 = stablehlo.reshape %10 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %12 = stablehlo.convert %11 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %13 = stablehlo.power %12, %0 : tensor<1x1x3072xf32>
    %14 = stablehlo.reduce(%13 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %15 = stablehlo.multiply %14, %cst_1 : tensor<1x1xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %17 = stablehlo.reshape %arg3 : (tensor<f32>) -> tensor<1x1x1xf32>
    %18 = stablehlo.add %16, %17 : tensor<1x1x1xf32>
    %19 = stablehlo.rsqrt %18 : tensor<1x1x1xf32>
    %20 = stablehlo.reshape %19 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %21 = stablehlo.broadcast_in_dim %20, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %22 = stablehlo.multiply %12, %21 : tensor<1x1x3072xf32>
    %23 = stablehlo.convert %22 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %24 = stablehlo.convert %23 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %25 = stablehlo.multiply %7, %24 : tensor<1x1x3072xf32>
    %26 = stablehlo.convert %25 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %27 = stablehlo.reshape %26 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %28 = stablehlo.transpose %arg2, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %29 = stablehlo.dot_general %27, %28, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %30 = stablehlo.reshape %29 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %31 = stablehlo.convert %30 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %32 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x64x1xf32>
    %33 = stablehlo.convert %arg0 : (tensor<1xi64>) -> tensor<1xf32>
    %34 = stablehlo.reshape %33 : (tensor<1xf32>) -> tensor<1x1x1xf32>
    %35 = stablehlo.dot_general %32, %34, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32>
    %36 = stablehlo.reshape %35 : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32>
    %37 = stablehlo.concatenate %36, %36, dim = 2 : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32>
    %38 = stablehlo.cosine %37 : tensor<1x1x128xf32>
    %39 = stablehlo.convert %38 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
    %40 = stablehlo.convert %39 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
    %41 = stablehlo.broadcast_in_dim %40, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32>
    %42 = stablehlo.multiply %31, %41 : tensor<1x8x1x128xf32>
    %43 = stablehlo.convert %42 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %44 = stablehlo.slice %30 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %45 = stablehlo.negate %44 : tensor<1x8x1x64xbf16>
    %46 = stablehlo.slice %30 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16>
    %47 = stablehlo.concatenate %45, %46, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16>
    %48 = stablehlo.convert %47 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32>
    %49 = stablehlo.sine %37 : tensor<1x1x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x1x128xbf16>) -> tensor<1x1x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32>
    %53 = stablehlo.multiply %48, %52 : tensor<1x8x1x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16>
    %55 = stablehlo.add %43, %54 : tensor<1x8x1x128xbf16>
    %56 = "stablehlo.scatter"(%arg8, %5, %55) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %57 = sdy.sharding_constraint %56 <@mesh, [{}, {}, {}, {}]> : tensor<1x8x128x128xbf16>
    %58 = stablehlo.transpose %arg9, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %59 = stablehlo.dot_general %27, %58, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16>
    %60 = stablehlo.reshape %59 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16>
    %61 = "stablehlo.scatter"(%arg10, %5, %60) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16>
    %62 = sdy.sharding_constraint %61 <@mesh, [{}, {}, {}, {}]> : tensor<1x8x128x128xbf16>
    %63 = stablehlo.convert %arg20 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %64 = stablehlo.reshape %63 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %65 = stablehlo.transpose %arg17, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %66 = stablehlo.dot_general %27, %65, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16>
    %68 = stablehlo.convert %67 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %69 = stablehlo.broadcast_in_dim %40, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32>
    %70 = stablehlo.multiply %68, %69 : tensor<1x24x1x128xf32>
    %71 = stablehlo.convert %70 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %72 = stablehlo.slice %67 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %73 = stablehlo.negate %72 : tensor<1x24x1x64xbf16>
    %74 = stablehlo.slice %67 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16>
    %75 = stablehlo.concatenate %73, %74, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16>
    %76 = stablehlo.convert %75 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %77 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32>
    %78 = stablehlo.multiply %76, %77 : tensor<1x24x1x128xf32>
    %79 = stablehlo.convert %78 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %80 = stablehlo.add %71, %79 : tensor<1x24x1x128xbf16>
    %81 = stablehlo.reshape %80 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %82 = stablehlo.broadcast_in_dim %56, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %83 = stablehlo.reshape %82 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %84 = stablehlo.transpose %83, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16>
    %85 = stablehlo.reshape %84 : (tensor<1x24x128x128xbf16>) -> tensor<24x128x128xbf16>
    %86 = stablehlo.dot_general %81, %85, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<24x1x128xbf16>) -> tensor<24x1x128xf32>
    %88 = stablehlo.reshape %87 : (tensor<24x1x128xf32>) -> tensor<1x24x1x128xf32>
    %89 = stablehlo.broadcast_in_dim %arg16, dims = [] : (tensor<f32>) -> tensor<1x24x1x128xf32>
    %90 = stablehlo.multiply %88, %89 : tensor<1x24x1x128xf32>
    %91 = stablehlo.convert %90 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %92 = stablehlo.convert %arg15 : (tensor<1x128xbf16>) -> tensor<1x128xf32>
    %93 = stablehlo.reshape %arg14 : (tensor<128xi64>) -> tensor<1x128xi64>
    %94 = stablehlo.broadcast_in_dim %arg0, dims = [0] : (tensor<1xi64>) -> tensor<1x128xi64>
    %95 = stablehlo.compare  GT, %93, %94 : (tensor<1x128xi64>, tensor<1x128xi64>) -> tensor<1x128xi1>
    %96 = stablehlo.convert %95 : (tensor<1x128xi1>) -> tensor<1x128xf32>
    %97 = stablehlo.multiply %92, %96 : tensor<1x128xf32>
    %98 = stablehlo.convert %97 : (tensor<1x128xf32>) -> tensor<1x128xbf16>
    %99 = stablehlo.reshape %98 : (tensor<1x128xbf16>) -> tensor<1x1x128xbf16>
    %100 = stablehlo.broadcast_in_dim %99, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x24x1x128xbf16>
    %101 = stablehlo.add %91, %100 : tensor<1x24x1x128xbf16>
    %102 = stablehlo.convert %101 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32>
    %103 = stablehlo.reduce(%102 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %105 = stablehlo.subtract %102, %104 : tensor<1x24x1x128xf32>
    %106 = stablehlo.exponential %105 : tensor<1x24x1x128xf32>
    %107 = stablehlo.reduce(%106 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32>
    %108 = stablehlo.broadcast_in_dim %107, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32>
    %109 = stablehlo.divide %106, %108 : tensor<1x24x1x128xf32>
    %110 = stablehlo.convert %109 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16>
    %111 = stablehlo.reshape %110 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16>
    %112 = stablehlo.broadcast_in_dim %61, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16>
    %113 = stablehlo.reshape %112 : (tensor<1x8x3x128x128xbf16>) -> tensor<24x128x128xbf16>
    %114 = stablehlo.dot_general %111, %113, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x128xbf16>) -> tensor<24x1x128xbf16>
    %115 = stablehlo.reshape %114 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16>
    %116 = stablehlo.transpose %arg13, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %117 = stablehlo.dot_general %115, %116, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16>
    %118 = stablehlo.reshape %117 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %119 = stablehlo.add %11, %118 : tensor<1x1x3072xbf16>
    %120 = stablehlo.convert %arg18 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %121 = stablehlo.reshape %120 : (tensor<3072xf32>) -> tensor<1x1x3072xf32>
    %122 = stablehlo.convert %119 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %123 = stablehlo.power %122, %0 : tensor<1x1x3072xf32>
    %124 = stablehlo.reduce(%123 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %125 = stablehlo.multiply %124, %cst_1 : tensor<1x1xf32>
    %126 = stablehlo.reshape %125 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %127 = stablehlo.add %126, %17 : tensor<1x1x1xf32>
    %128 = stablehlo.rsqrt %127 : tensor<1x1x1xf32>
    %129 = stablehlo.reshape %128 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %131 = stablehlo.multiply %122, %130 : tensor<1x1x3072xf32>
    %132 = stablehlo.convert %131 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %133 = stablehlo.convert %132 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %134 = stablehlo.multiply %121, %133 : tensor<1x1x3072xf32>
    %135 = stablehlo.convert %134 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %137 = stablehlo.transpose %arg19, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %138 = stablehlo.dot_general %136, %137, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %139 = stablehlo.reshape %138 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16>
    %140 = stablehlo.convert %139 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %141 = stablehlo.logistic %139 : tensor<1x1x8192xbf16>
    %142 = stablehlo.convert %141 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %143 = stablehlo.multiply %140, %142 : tensor<1x1x8192xf32>
    %144 = stablehlo.convert %143 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %145 = stablehlo.convert %144 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32>
    %146 = stablehlo.transpose %arg12, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %147 = stablehlo.dot_general %136, %146, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x8192xbf16>) -> tensor<1x8192xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x8192xf32>) -> tensor<1x1x8192xf32>
    %150 = stablehlo.multiply %145, %149 : tensor<1x1x8192xf32>
    %151 = stablehlo.convert %150 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16>
    %152 = stablehlo.reshape %151 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16>
    %153 = stablehlo.transpose %arg11, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %154 = stablehlo.dot_general %152, %153, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16>
    %155 = stablehlo.reshape %154 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %156 = stablehlo.add %119, %155 : tensor<1x1x3072xbf16>
    %157 = stablehlo.convert %156 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %158 = stablehlo.power %157, %0 : tensor<1x1x3072xf32>
    %159 = stablehlo.reduce(%158 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32>
    %160 = stablehlo.multiply %159, %cst_1 : tensor<1x1xf32>
    %161 = stablehlo.reshape %160 : (tensor<1x1xf32>) -> tensor<1x1x1xf32>
    %162 = stablehlo.add %161, %17 : tensor<1x1x1xf32>
    %163 = stablehlo.rsqrt %162 : tensor<1x1x1xf32>
    %164 = stablehlo.reshape %163 : (tensor<1x1x1xf32>) -> tensor<1x1xf32>
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32>
    %166 = stablehlo.multiply %157, %165 : tensor<1x1x3072xf32>
    %167 = stablehlo.convert %166 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %168 = stablehlo.convert %167 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %169 = stablehlo.multiply %64, %168 : tensor<1x1x3072xf32>
    %170 = stablehlo.convert %169 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16>
    %171 = stablehlo.reshape %170 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16>
    %172 = stablehlo.transpose %arg5, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %173 = stablehlo.dot_general %171, %172, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<1x128256xbf16>
    %174 = stablehlo.reshape %173 : (tensor<1x128256xbf16>) -> tensor<1x1x128256xbf16>
    return %57, %62, %173, %174 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>
  }
}
loc("p8.110"): error: 'sdy.all_slice' op operates on axis "_axis_0" which is already bound by a parent sdy.manual_computation op
2025-08-20 16:59:22.157 (  43.797s) [        5E2EB1C0]      module_builder.cc:215    ERR| Failed to run stablehlo pipeline
2025-08-20 16:59:22.157 (  43.797s) [        5E2EB1C0]      error_instance.cc:49       1| ErrorInstance::PJRT_Error_Message
2025-08-20 16:59:22.157 (  43.797s) [        5E2EB1C0]      error_instance.cc:58       1| ErrorInstance::PJRT_Error_GetCode
2025-08-20 16:59:22.157 (  43.797s) [        5E2EB1C0]      error_instance.cc:43       1| ErrorInstance::PJRT_Error_Destroy
2025-08-20 16:59:22.159 (  43.799s) [        5E2EB1C0]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_Destroy
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
2025-08-20 16:59:22.159 (  43.799s) [        5E2EB1C0]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_Destroy
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
2025-08-20 16:59:22.159 (  43.799s) [        5E2EB1C0]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_Destroy
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
2025-08-20 16:59:22.159 (  43.799s) [        5E2EB1C0]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_Destroy
[32m                 Always[0m | [1m[38;5;240m   DEBUG[0m | Tensor is retained thus not deallocating. To deallocate, set retain to false first
FAILED

=================================== FAILURES ===================================
_____________________________ test_llama3_generate _____________________________

    @torch.inference_mode()
    def test_llama3_generate():
        # Initialize model and inputs
        start_time = time.time()
        model, tokenizer = load_model()
        input_args = load_inputs(model, tokenizer)
        generated_ids = input_args["input_ids"]
    
        initial_prompt = tokenizer.decode(generated_ids[0].tolist())
        print(f"Initial prompt: '{initial_prompt}'")
    
        # setup XLA environment and device mesh
        setup_xla_environment()
        mesh = create_device_mesh()
    
        ts.mark_sharding(input_args["input_ids"], (None, None))
        if use_static_cache:
            ts.mark_sharding(input_args["cache_position"], (None,))
    
            # apply shardings
            for i, (key, value) in enumerate(
                zip(
                    input_args["past_key_values"].key_cache,
                    input_args["past_key_values"].value_cache,
                )
            ):
                ts.mark_sharding(key, (None, "model", None, None))
                ts.mark_sharding(value, (None, "model", None, None))
    
        for layer in model.model.layers:
            ts.mark_sharding(layer.mlp.up_proj.weight, ("model", None))
            ts.mark_sharding(layer.mlp.gate_proj.weight, ("model", None))
            ts.mark_sharding(layer.mlp.down_proj.weight, (None, "model"))
    
            ts.mark_sharding(layer.self_attn.q_proj.weight, ("model", None))
            ts.mark_sharding(layer.self_attn.k_proj.weight, ("model", None))
            ts.mark_sharding(layer.self_attn.v_proj.weight, ("model", None))
            ts.mark_sharding(layer.self_attn.o_proj.weight, (None, "model"))
    
        ts.mark_sharding(model.lm_head.weight, ("model", None))
    
        # Setup compilation
        clear_dynamo_cache()
        cc = CompilerConfig()
        cc.mesh = mesh
    
        # Consteval disabled due to 4D Causal Attention Mask evaluation getting constant folded in torchfx
        #   due to incorrect tracing of static cache and malformed output missing static cache tensors
        cc.enable_consteval = True
        cc.consteval_parameters = False
    
        options = BackendOptions()
        options.compiler_config = cc
    
        # _backend = backend
        _backend = "tt-experimental"
    
        compiled_model = torch.compile(
            model, backend=_backend, dynamic=False, options=options
        )
    
        # Token generation with data collection
        generated_tokens = []
    
        print(initial_prompt, end="", flush=True)
    
        for i in range(tokens_to_generate):
            # Execute model
>           outputs = compiled_model(**input_args)

tests/models/llama/test_llama3_generative.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
env/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
env/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
env/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:655: in _fn
    return fn(*args, **kwargs)
env/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
env/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
env/venv/lib/python3.10/site-packages/transformers/utils/generic.py:953: in wrapper
    @wraps(func)
env/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: in _fn
    return fn(*args, **kwargs)
tt_torch/dynamo/experimental/xla_backend.py:859: in __call__
    xm.mark_step()
env/venv/lib/python3.10/site-packages/typing_extensions.py:2956: in wrapper
    return arg(*args, **kwargs)
env/venv/lib/python3.10/site-packages/torch_xla/core/xla_model.py:1035: in mark_step
    torch_xla.sync(wait, reset_scope)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

wait = False, reset_scope = True

    def sync(wait: bool = False, reset_scope: bool = True):
      """Launches all pending graph operations.
    
      Args:
        wait (bool): whether to block the current process until the execution finished.
        reset_scope (bool): whether to reset the torch::lazy::ScopeContext of the IR Nodes.
      """
      if xu.getenv_as('XLA_EMIT_STEPLOG', bool, False):
        print('torch_xla.torch_xla::sync\n', end='', file=sys.stderr, flush=True)
>     torch_xla._XLAC._xla_step_marker(
          torch_xla._XLAC._xla_get_default_device(), [],
          wait=xu.getenv_as('XLA_SYNC_WAIT', bool, wait),
          reset_scope=reset_scope)
E     ValueError: Error code: 13

env/venv/lib/python3.10/site-packages/torch_xla/torch_xla.py:87: ValueError
=============================== warnings summary ===============================
tests/models/llama/test_llama3_generative.py::test_llama3_generate
tests/models/llama/test_llama3_generative.py::test_llama3_generate
  /localdev/jameszianxu/test32/tt-torch/tt_torch/dynamo/experimental/xla_backend.py:859: DeprecationWarning: Use torch_xla.sync instead
    xm.mark_step()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/models/llama/test_llama3_generative.py::test_llama3_generate - ValueError: Error code: 13
======================== 1 failed, 2 warnings in 47.41s ========================
