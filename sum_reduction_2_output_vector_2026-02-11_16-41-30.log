2026-02-11 16:41:05.863 | INFO     | pjrt_plugin_tt:setup_tt_pjrt_plugin_dir:42 - Using PJRT plugin directory: /localdev/jameszianxu/tt-xla/python_package/pjrt_plugin_tt
2026-02-11 16:41:05.863 | INFO     | pjrt_plugin_tt:setup_tt_metal_home:103 - Using TT-Metal from the source tree: /localdev/jameszianxu/tt-xla/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
2026-02-11 16:41:05.863 | WARNING  | torch_plugin_tt:__init__:38 - TT plugin is setting XLA_STABLEHLO_COMPILE to 1. This is required for TT PJRT plugin to work correctly.
============================= test session starts ==============================
platform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0 -- /localdev/jameszianxu/tt-xla/venv/bin/python
cachedir: .pytest_cache
metadata: {'Python': '3.11.14', 'Platform': 'Linux-5.4.0-216-generic-x86_64-with-glibc2.35', 'Packages': {'pytest': '9.0.2', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.12.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'split': '0.11.0', 'forked': '1.6.0', 'jaxtyping': '0.3.7'}}
rootdir: /localdev/jameszianxu/tt-xla
configfile: pytest.ini
plugins: anyio-4.12.1, json-report-1.5.0, metadata-3.1.1, split-0.11.0, forked-1.6.0, jaxtyping-0.3.7
collecting ... collected 1 item

tests/torch/graphs/test_tensor_persistence.py::test_sharded_mean_produces_replicated_output 2026-02-11 16:41:09.532 (   0.000s) [        9F5D9000]   plugin_attributes.cc:60       1| PluginAttributes::PJRT_Plugin_Initialize
2026-02-11 16:41:09.532 (   0.000s) [        9F5D9000]     client_instance.cc:513      1| ClientInstance::PJRT_Client_Create
2026-02-11 16:41:09.535 (   0.002s) [        9F5D9000]     client_instance.cc:177      1| ClientInstance::ClientInstance
2026-02-11 16:41:09.535 (   0.002s) [        9F5D9000]     client_instance.cc:198      1| ClientInstance::Initialize
2026-02-11 16:41:10.069 (   0.537s) [        9F5D9000]              stubs.inc:103   WARN| STUB: PJRT_Client_TopologyDescription
2026-02-11 16:41:10.069 (   0.537s) [        9F5D9000]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-02-11 16:41:10.069 (   0.537s) [        9F5D9000]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-02-11 16:41:10.069 (   0.537s) [        9F5D9000]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-02-11 16:41:10.069 (   0.537s) [        9F5D9000]     client_instance.cc:567      1| ClientInstance::PJRT_Client_PlatformVersion
2026-02-11 16:41:10.069 (   0.537s) [        9F5D9000]     client_instance.cc:548      1| ClientInstance::PJRT_Client_PlatformName
2026-02-11 16:41:10.069 (   0.537s) [        9F5D9000]     client_instance.cc:578      1| ClientInstance::PJRT_Client_Devices
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:82       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:82       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]     client_instance.cc:591      1| ClientInstance::PJRT_Client_AddressableDevices
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]     client_instance.cc:641      1| ClientInstance::PJRT_Client_AddressableMemories
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]   plugin_attributes.cc:66       1| PluginAttributes::PJRT_Plugin_Attributes
2026-02-11 16:41:10.070199: W torch_xla/csrc/runtime/profiler.cpp:88] Profiler API not found for PJRT plugin
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:120      1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:120      1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.070 (   0.537s) [        9F5D9000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.082 (   0.550s) [        9F5D9000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.082 (   0.550s) [        9F5D9000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.082 (   0.550s) [        9F5D9000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-02-11 16:41:10.082 (   0.550s) [        9F5D9000]     client_instance.cc:703      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-02-11 16:41:10.082 (   0.550s) [        9F5D9000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-02-11 16:41:10.083 (   0.551s) [        9F5D9000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:41:10.083 (   0.551s) [        9F5D9000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:41:10.083 (   0.551s) [        9F5D9000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-02-11 16:41:10.083 (   0.551s) [        9F5D9000]     client_instance.cc:703      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-02-11 16:41:10.083 (   0.551s) [        9F5D9000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-02-11 16:41:10.083 (   0.551s) [        9F5D9000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:41:10.083 (   0.551s) [        9F5D9000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:41:10.371 (   0.838s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.371 (   0.838s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.371 (   0.838s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.371 (   0.838s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.371 (   0.839s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.371 (   0.839s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.371 (   0.839s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.371564: W torch_xla/csrc/runtime/pjrt_computation_client.cpp:703] Failed to deserialize executable: UNIMPLEMENTED: Deserializing serialized executable not supported.
2026-02-11 16:41:10.371 (   0.839s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.378 (   0.846s) [        9F5D9000]     client_instance.cc:654      1| ClientInstance::PJRT_Client_Compile
2026-02-11 16:41:10.378 (   0.846s) [        9F5D9000]      module_builder.cc:223      1| ModuleBuilder::buildModule
2026-02-11 16:41:10.380 (   0.848s) [        9F5D9000]      module_builder.cc:1121     1| MLIR Module vhlo:
#loc1 = loc("p0.1")
#loc5 = loc("reduce.11")
module @SyncTensorsGraph.13 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<8x8x!vhlo.f32_v1> loc("p0.1")) -> (!vhlo.tensor_v1<8x!vhlo.f32_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %1 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<8x8x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x8x!vhlo.f32_v1> loc(#loc2)
    %2 = "vhlo.custom_call_v1"(%1) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x8x8x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x8x!vhlo.f32_v1> loc(#loc3)
    %3 = "vhlo.reshape_v1"(%2) : (!vhlo.tensor_v1<1x8x8x!vhlo.f32_v1>) -> !vhlo.tensor_v1<8x8x!vhlo.f32_v1> loc(#loc4)
    %4 = "vhlo.reduce_v1"(%3, %0) <{dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> ({
    ^bb0(%arg1: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.11"), %arg2: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.11")):
      %5 = "vhlo.add_v1"(%arg1, %arg2) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc6)
      "vhlo.return_v1"(%5) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<8x8x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<8x!vhlo.f32_v1> loc(#loc5)
    "vhlo.return_v1"(%4) : (!vhlo.tensor_v1<8x!vhlo.f32_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("reshape.2")
#loc3 = loc("custom-call.3")
#loc4 = loc("reshape.4")
#loc6 = loc("add.10")
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:41:10.384 (   0.852s) [        9F5D9000]      module_builder.cc:1121     1| MLIR Module shlo:
#loc1 = loc("p0.1")
module @SyncTensorsGraph.13 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<8x8xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p0.1")) -> tensor<8xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %0 = stablehlo.reshape %arg0 : (tensor<8x8xf32>) -> tensor<1x8x8xf32> loc(#loc2)
    %1 = stablehlo.custom_call @tt.mark_argument(%0) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x8x8xf32>) -> tensor<1x8x8xf32> loc(#loc3)
    %2 = stablehlo.reshape %1 : (tensor<1x8x8xf32>) -> tensor<8x8xf32> loc(#loc4)
    %3 = stablehlo.reduce(%2 init: %cst) applies stablehlo.add across dimensions = [1] : (tensor<8x8xf32>, tensor<f32>) -> tensor<8xf32> loc(#loc5)
    return %3 : tensor<8xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("reshape.2")
#loc3 = loc("custom-call.3")
#loc4 = loc("reshape.4")
#loc5 = loc("reduce.11")
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:41:10.386 (   0.853s) [        9F5D9000]      module_builder.cc:1121     1| MLIR Module shlo_frontend:
#loc1 = loc("p0.1")
module @SyncTensorsGraph.13 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<8x8xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("p0.1")) -> tensor<8xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %0 = stablehlo.reshape %arg0 : (tensor<8x8xf32>) -> tensor<1x8x8xf32> loc(#loc2)
    %1 = stablehlo.reshape %0 : (tensor<1x8x8xf32>) -> tensor<8x8xf32> loc(#loc3)
    %2 = stablehlo.reduce(%1 init: %cst) applies stablehlo.add across dimensions = [1] : (tensor<8x8xf32>, tensor<f32>) -> tensor<8xf32> loc(#loc4)
    return %2 : tensor<8xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("reshape.2")
#loc3 = loc("reshape.4")
#loc4 = loc("reduce.11")
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:41:10.391 (   0.858s) [        9F5D9000]      module_builder.cc:1121     1| MLIR Module shlo_compiler:
#loc1 = loc("p0.1")
#loc4 = loc("reduce.11")
module @SyncTensorsGraph.13 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]> loc(#loc)
  func.func @main(%arg0: tensor<8x8xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<8x4xf32>>, ttir.name = "args_0"} loc("p0.1")) -> (tensor<8xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<8xf32>>}) {
    %0 = sdy.manual_computation(%arg0) in_shardings=[<@mesh, [{}, {"_axis_0"}]>] out_shardings=[<@mesh, [{}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg1: tensor<8x4xf32> loc("p0.1")) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
      %1 = stablehlo.reshape %arg1 : (tensor<8x4xf32>) -> tensor<1x8x4xf32> loc(#loc2)
      %2 = stablehlo.reshape %1 : (tensor<1x8x4xf32>) -> tensor<8x4xf32> loc(#loc3)
      %3 = stablehlo.reduce(%2 init: %cst) applies stablehlo.add across dimensions = [1] : (tensor<8x4xf32>, tensor<f32>) -> tensor<8xf32> loc(#loc4)
      %4 = "stablehlo.all_reduce"(%3) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg2: tensor<f32> loc("reduce.11"), %arg3: tensor<f32> loc("reduce.11")):
        %5 = stablehlo.add %arg2, %arg3 : tensor<f32> loc(#loc4)
        stablehlo.return %5 : tensor<f32> loc(#loc4)
      }) : (tensor<8xf32>) -> tensor<8xf32> loc(#loc4)
      sdy.return %4 : tensor<8xf32> loc(#loc)
    } : (tensor<8x8xf32>) -> tensor<8xf32> loc(#loc)
    return %0 : tensor<8xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("reshape.2")
#loc3 = loc("reshape.4")
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:41:10.391 (   0.859s) [        9F5D9000]      module_builder.cc:303      1| SHLO compiler pipeline run completed - is using shardy output shardings: 1
2026-02-11 16:41:10.392 (   0.860s) [        9F5D9000]      module_builder.cc:1121     1| MLIR Module shlo_compiler_cleaned:
#loc = loc(unknown)
module @SyncTensorsGraph.13 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<8x8xf32> loc(unknown)) -> tensor<8xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<8xf32> loc(#loc)
    return %cst : tensor<8xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:41:10.394 (   0.862s) [        9F5D9000]      module_builder.cc:1121     1| MLIR Module ttir:
#loc1 = loc("p0.1")
module @SyncTensorsGraph.13 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.13 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
      func.func @main(%arg0: tensor<8x8xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<8x4xf32>>, ttir.name = "args_0"} loc("p0.1")) -> (tensor<8xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<8xf32>>}) {
        %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8x8xf32>) -> tensor<8x4xf32> loc(#loc)
        %1 = "ttir.reshape"(%0) <{shape = [1 : i32, 8 : i32, 4 : i32]}> : (tensor<8x4xf32>) -> tensor<1x8x4xf32> loc(#loc2)
        %2 = "ttir.reshape"(%1) <{shape = [8 : i32, 4 : i32]}> : (tensor<1x8x4xf32>) -> tensor<8x4xf32> loc(#loc3)
        %3 = "ttir.sum"(%2) <{dim_arg = [1 : i32], keep_dim = false}> : (tensor<8x4xf32>) -> tensor<8xf32> loc(#loc4)
        %4 = "ttir.all_reduce"(%3) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<8xf32>) -> tensor<8xf32> loc(#loc4)
        %5 = "ttir.mesh_shard"(%4) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8xf32>) -> tensor<8xf32> loc(#loc)
        return %5 : tensor<8xf32> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("reshape.2")
#loc3 = loc("reshape.4")
#loc4 = loc("reduce.11")
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:41:10.395 (   0.862s) [        9F5D9000]      module_builder.cc:862   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2026-02-11 16:41:10.395 (   0.862s) [        9F5D9000]      module_builder.cc:876   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2026-02-11 16:41:10.395 (   0.862s) [        9F5D9000]      module_builder.cc:886   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2026-02-11 16:41:10.421 (   0.889s) [        9F5D9000]      module_builder.cc:1121     1| MLIR Module ttnn:
#dram = #ttnn.buffer_type<dram>
#loc1 = loc("p0.1")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 103712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073162752, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 64, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 103712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073171392, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 64, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.13 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.13 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]> loc(#loc)
      func.func @main(%arg0: tensor<8x8xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<8x4xf32>>, ttir.name = "args_0"} loc("p0.1")) -> (tensor<8xf32, #ttnn_layout1> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<8xf32>>}) attributes {tt.function_type = "forward_device"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8x8xf32, #ttnn_layout>, !ttnn.device) -> tensor<8x4xf32, #ttnn_layout> loc(#loc)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<8x8xf32, #ttnn_layout>) -> () loc(#loc)
        %2 = "ttnn.sum"(%1) <{compute_config = #ttnn.device_compute_kernel_config<math_fidelity = hifi4, fp32_dest_acc_en = true>, dim_arg = [1 : i32], keep_dim = false}> : (tensor<8x4xf32, #ttnn_layout>) -> tensor<8xf32, #ttnn_layout1> loc(#loc2)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<8x4xf32, #ttnn_layout>) -> () loc(#loc2)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 1 : i32, 1 : i32, 8 : i32]}> : (tensor<8xf32, #ttnn_layout1>) -> tensor<1x1x1x8xf32, #ttnn_layout2> loc(#loc5)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<8xf32, #ttnn_layout1>) -> () loc(#loc5)
        %4 = "ttnn.reduce_scatter"(%3) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x8xf32, #ttnn_layout2>) -> tensor<1x1x1x4xf32, #ttnn_layout2> loc(#loc6)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x1x8xf32, #ttnn_layout2>) -> () loc(#loc6)
        %5 = "ttnn.all_gather"(%4) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32}> : (tensor<1x1x1x4xf32, #ttnn_layout2>) -> tensor<1x1x1x8xf32, #ttnn_layout2> loc(#loc4)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1x1x1x4xf32, #ttnn_layout2>) -> () loc(#loc4)
        %6 = "ttnn.reshape"(%5) <{shape = [8 : i32]}> : (tensor<1x1x1x8xf32, #ttnn_layout2>) -> tensor<8xf32, #ttnn_layout1> loc(#loc2)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1x1x1x8xf32, #ttnn_layout2>) -> () loc(#loc2)
        return %6 : tensor<8xf32, #ttnn_layout1> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("reduce.11")
#loc3 = loc("reduce.11_reduceScatter"(#loc2))
#loc4 = loc("reduce.11_all_gather_4d"(#loc2))
#loc5 = loc("reduce.11_reduceScatter_reshape_to_4d"(#loc3))
#loc6 = loc("reduce.11_reduceScatter_reduce_scatter_4d"(#loc3))
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:41:10.428 (   0.895s) [        9F5D9000]loaded_executable_insta:256      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2026-02-11 16:41:10.428 (   0.895s) [        9F5D9000]loaded_executable_insta:275      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2026-02-11 16:41:10.428 (   0.896s) [        9F5D9000]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2026-02-11 16:41:10.428 (   0.896s) [        9F5D9000]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-02-11 16:41:10.428 (   0.896s) [        9F5D9000]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-02-11 16:41:10.428 (   0.896s) [        9F5D9000]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-02-11 16:41:10.428 (   0.896s) [        9F5D9000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-02-11 16:41:10.428 (   0.896s) [        9F5D9000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-02-11 16:41:10.431 (   0.899s) [        9F5D9000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-02-11 16:41:10.431 (   0.899s) [        9F5D9000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-02-11 16:41:10.434 (   0.901s) [        9F5D9000] executable_instance.cc:239      1| ExecutableInstance::PJRT_Executable_Serialize
2026-02-11 16:41:10.435 (   0.902s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.435 (   0.902s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.439 (   0.906s) [        81FFB640]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.439 (   0.906s) [        81FFB640]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:41:10.439 (   0.906s) [        81FFB640]     buffer_instance.cc:547      1| BufferInstance::PJRT_Buffer_Device
2026-02-11 16:41:10.439 (   0.906s) [        81FFB640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-02-11 16:41:10.439 (   0.906s) [        81FFB640]     buffer_instance.cc:547      1| BufferInstance::PJRT_Buffer_Device
2026-02-11 16:41:10.439 (   0.906s) [        81FFB640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-02-11 16:41:10.439 (   0.906s) [        81FFB640] executable_instance.cc:145      1| ExecutableInstance::PJRT_Executable_NumOutputs
2026-02-11 16:41:10.439 (   0.906s) [        81FFB640]loaded_executable_insta:311      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2026-02-11 16:41:10.439 (   0.906s) [        81FFB640]flatbuffer_loaded_execu:203      1| FlatbufferLoadedExecutableInstance::Execute
2026-02-11 16:41:10.439 (   0.907s) [        81FFB640]     client_instance.cc:383      1| ClientInstance::getOrCreateMeshDevice - reusing already opened mesh device [1, 2]
2026-02-11 16:41:10.439 (   0.907s) [        81FFB640]              tensor.cc:180      1| rt_tensor_from_strategy: first_shard_UID=0 num_shards=2 strategy=shard_2d shape=[8, 4]
2026-02-11 16:41:10.557 (   1.025s) [        81FFB640]flatbuffer_loaded_execu:108      1| fillPJRTOutputLists: output_index=0 is_sharded=1 num_host_tensors=2 shape=[8]
2026-02-11 16:41:10.557 (   1.025s) [        81FFB640]flatbuffer_loaded_execu:134      1| Filled output at output_index 0 device_index 0 with shape [8] and UID 2
2026-02-11 16:41:10.557 (   1.025s) [        81FFB640]flatbuffer_loaded_execu:134      1| Filled output at output_index 0 device_index 1 with shape [8] and UID 3
2026-02-11 16:41:10.557 (   1.025s) [        81FFB640]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:41:10.557 (   1.025s) [        81FFB640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:41:10.557 (   1.025s) [        81FFB640]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:41:10.557 (   1.025s) [        81FFB640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:41:10.557 (   1.025s) [        81FFB640]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:41:10.557 (   1.025s) [        81FFB640]     buffer_instance.cc:445      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-02-11 16:41:10.557 (   1.025s) [        81FFB640]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:41:10.557 (   1.025s) [        81FFB640]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_ElementType
2026-02-11 16:41:10.558 (   1.025s) [        81FFB640]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:41:10.558 (   1.025s) [        81FFB640]     buffer_instance.cc:445      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-02-11 16:41:10.558 (   1.025s) [        81FFB640]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:41:10.558 (   1.025s) [        81FFB640]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_ElementType
2026-02-11 16:41:10.558 (   1.025s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.558 (   1.025s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.558 (   1.025s) [        9F5D9000]     buffer_instance.cc:433      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2026-02-11 16:41:10.558 (   1.025s) [        9F5D9000]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_ElementType
2026-02-11 16:41:10.558 (   1.025s) [        9F5D9000]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:41:10.558 (   1.025s) [        9F5D9000]     buffer_instance.cc:455      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2026-02-11 16:41:10.558 (   1.025s) [        9F5D9000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:41:10.559 (   1.027s) [        817FA640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:41:10.561 (   1.028s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.561 (   1.028s) [        9F5D9000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:41:10.561 (   1.028s) [        9F5D9000]     buffer_instance.cc:433      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2026-02-11 16:41:10.561 (   1.028s) [        9F5D9000]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_ElementType
2026-02-11 16:41:10.561 (   1.028s) [        9F5D9000]     buffer_instance.cc:455      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2026-02-11 16:41:10.561 (   1.028s) [        9F5D9000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:41:10.561 (   1.028s) [        80FF9640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:41:10.563 (   1.030s) [        9F5D9000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_Destroy
2026-02-11 16:41:10.563 (   1.030s) [        9F5D9000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_Destroy
tensor([8., 8., 8., 8., 8., 8., 8., 8.], device='xla:0')
Input shape: torch.Size([8, 8]), sharded on dim 1
Output shape: torch.Size([8]), replicated (unsharded)
PASSED

============================== 1 passed in 1.37s ===============================
2026-02-11 16:41:13.183 (   3.651s) [        9F5D9000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_Destroy
2026-02-11 16:41:13.184 (   3.651s) [        9F5D9000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_Destroy
2026-02-11 16:41:13.326 (   3.794s) [        9F5D9000]     client_instance.cc:192      1| ClientInstance::~ClientInstance
2026-02-11 16:41:13.326 (   3.794s) [        9F5D9000]     client_instance.cc:466      1| Closing parent mesh.
