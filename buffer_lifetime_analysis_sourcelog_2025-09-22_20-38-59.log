WARNING:root:Defaulting to PJRT_DEVICE=CPU
2025-09-22 18:07:00.314 (   0.000s) [        A88F8000]      dylib_platform.cc:47       1| DylibPlatform::SubclassInitialize
2025-09-22 18:07:00.316 (   0.002s) [        A88F8000]     client_instance.cc:38       1| ClientInstance::ClientInstance
2025-09-22 18:07:00.316 (   0.002s) [        A88F8000]              client.cc:18       1| TTClientInstance::TTClientInstance
2025-09-22 18:07:00.316 (   0.002s) [        A88F8000]     client_instance.cc:59       1| ClientInstance::Initialize
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]              stubs.inc:106   WARN| STUB: PJRT_Client_TopologyDescription
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]      error_instance.cc:49       1| ErrorInstance::PJRT_Error_Message
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]      error_instance.cc:58       1| ErrorInstance::PJRT_Error_GetCode
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]      error_instance.cc:43       1| ErrorInstance::PJRT_Error_Destroy
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]     client_instance.cc:339      1| ClientInstance::PJRT_Client_PlatformVersion
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]     client_instance.cc:319      1| ClientInstance::PJRT_Client_PlatformName
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]     client_instance.cc:351      1| ClientInstance::PJRT_Client_Devices
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]     client_instance.cc:364      1| ClientInstance::PJRT_Client_AddressableDevices
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]     client_instance.cc:414      1| ClientInstance::PJRT_Client_AddressableMemories
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-09-22 18:07:04.498 (   4.183s) [        A88F8000]        api_bindings.cc:76       1| PJRT_Plugin_Attributes
2025-09-22 18:07:04.498471: W torch_xla/csrc/runtime/profiler.cpp:88] Profiler API not found for PJRT plugin
2025-09-22 18:07:04.498 (   4.184s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:04.498 (   4.184s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:04.498 (   4.184s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:04.498 (   4.184s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:04.498 (   4.184s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:04.498 (   4.184s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:04.498 (   4.184s) [        A88F8000]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-09-22 18:07:04.498 (   4.184s) [        A88F8000]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-09-22 18:07:04.498 (   4.184s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:04.498 (   4.184s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:04.498 (   4.184s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:04.498 (   4.184s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
/localdev/jameszianxu/tt-xla/examples/pytorch/llama.py:69: DeprecationWarning: Use torch_xla.device instead
  device = xm.xla_device()
Using TT-Metal from the source tree: /localdev/jameszianxu/tt-xla/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
WARNING: TT plugin is setting XLA_STABLEHLO_COMPILE to 1. This is required for TT PJRT plugin to work correctly.
Setting up XLA environment...
XLA environment configured.
Created device mesh: (1, 2) with 2 devices
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 52.19it/s]
2025-09-22 18:07:06.059 (   5.744s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:06.059 (   5.744s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:06.059 (   5.744s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:06.059 (   5.744s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:06.059 (   5.744s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-22 18:07:06.060 (   5.745s) [        A88F8000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x45847a60 copyFromHost OWNED shape=[1,7] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:06.060 (   5.745s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:06.060 (   5.745s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:06.060 (   5.745s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:06.060 (   5.745s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:06.060 (   5.745s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-22 18:07:06.060 (   5.745s) [        A88F8000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x457dba50 copyFromHost OWNED shape=[1,7] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:06.060 (   5.745s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:06.060 (   5.745s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:06.060 (   5.746s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:06.060 (   5.746s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:06.060 (   5.746s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:06.060 (   5.746s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:06.060 (   5.746s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-22 18:07:06.060 (   5.746s) [        A88F8000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x70b83860 copyFromHost OWNED shape=[7] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:06.060 (   5.746s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:06.060 (   5.746s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:06.060 (   5.746s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:06.060 (   5.746s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:06.060 (   5.746s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-22 18:07:06.061 (   5.746s) [        A88F8000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x70cb1c50 copyFromHost OWNED shape=[7] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:06.061 (   5.746s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:06.061 (   5.746s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:06.061 (   5.746s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:06.061 (   5.746s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70ba04a0 copyFromHost BORROWED shape=[1,4,16,128] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8380c550 copyFromHost BORROWED shape=[1,4,16,128] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:06.061 (   5.747s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:06.062 (   5.747s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a26480 copyFromHost BORROWED shape=[1,4,16,128] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:06.062 (   5.747s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:06.062 (   5.747s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:06.062 (   5.747s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:06.062 (   5.747s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:06.062 (   5.747s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:06.062 (   5.747s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c99d20 copyFromHost BORROWED shape=[1,4,16,128] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:06.062 (   5.747s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:06.062 (   5.747s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:06.872 (   6.558s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:06.872 (   6.558s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:06.910 (   6.596s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:06.910 (   6.596s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:06.910 (   6.596s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:06.910 (   6.596s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562879c0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:06.910 (   6.596s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:06.910 (   6.596s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:06.910 (   6.596s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:06.910 (   6.596s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:06.910 (   6.596s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:06.911 (   6.596s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56375710 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:06.911 (   6.596s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:06.911 (   6.596s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:06.916 (   6.602s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:06.916 (   6.602s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:06.969 (   6.655s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:06.969 (   6.655s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:06.969 (   6.655s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:06.970 (   6.655s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d0dda0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:06.970 (   6.655s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:06.970 (   6.655s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:06.970 (   6.655s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:06.970 (   6.656s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:06.970 (   6.656s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:06.970 (   6.656s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b9e330 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:06.970 (   6.656s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:06.970 (   6.656s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:06.974 (   6.659s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:06.974 (   6.659s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.022 (   6.707s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.022 (   6.708s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.022 (   6.708s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.022 (   6.708s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839c8d70 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.022 (   6.708s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.022 (   6.708s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.023 (   6.708s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.023 (   6.708s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.023 (   6.708s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.023 (   6.708s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x75260c70 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.023 (   6.708s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.023 (   6.708s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.025 (   6.711s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.025 (   6.711s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.031 (   6.717s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.031 (   6.717s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.031 (   6.717s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.032 (   6.717s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x75566b90 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.032 (   6.717s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.032 (   6.717s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.032 (   6.717s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.032 (   6.717s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.032 (   6.717s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.032 (   6.717s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x7521bd00 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.032 (   6.718s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.032 (   6.718s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.032 (   6.718s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.032 (   6.718s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.034 (   6.719s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.034 (   6.720s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.034 (   6.720s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.034 (   6.720s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d09dc0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.034 (   6.720s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.034 (   6.720s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.034 (   6.720s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.034 (   6.720s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.034 (   6.720s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.035 (   6.720s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x75273df0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.035 (   6.720s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.035 (   6.720s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.035 (   6.720s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.035 (   6.721s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.036 (   6.722s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.036 (   6.722s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.037 (   6.722s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.037 (   6.722s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d73bd0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.037 (   6.722s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.037 (   6.722s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.037 (   6.722s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.037 (   6.722s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.037 (   6.723s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.037 (   6.723s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x75237850 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.037 (   6.723s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.037 (   6.723s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.037 (   6.723s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.037 (   6.723s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.039 (   6.725s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.039 (   6.725s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.039 (   6.725s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.040 (   6.725s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83987740 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.040 (   6.725s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.040 (   6.725s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.040 (   6.725s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.040 (   6.725s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.040 (   6.725s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.040 (   6.726s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b7a050 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.040 (   6.726s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.040 (   6.726s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.040 (   6.726s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.040 (   6.726s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.052 (   6.738s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.052 (   6.738s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.053 (   6.738s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.053 (   6.738s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83959ca0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.053 (   6.738s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.053 (   6.738s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.053 (   6.738s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.053 (   6.738s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.053 (   6.738s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.053 (   6.739s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5649bb50 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.053 (   6.739s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.053 (   6.739s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.056 (   6.741s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.056 (   6.742s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.085 (   6.770s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.085 (   6.770s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.085 (   6.770s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.085 (   6.771s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a9ea50 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.085 (   6.771s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.085 (   6.771s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.085 (   6.771s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.085 (   6.771s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.085 (   6.771s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.086 (   6.771s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x7522f680 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.086 (   6.771s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.086 (   6.771s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.089 (   6.775s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.089 (   6.775s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.156 (   6.842s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.156 (   6.842s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.156 (   6.842s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.156 (   6.842s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b7e610 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.156 (   6.842s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.156 (   6.842s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.156 (   6.842s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.156 (   6.842s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.156 (   6.842s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.156 (   6.842s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x75291f00 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.156 (   6.842s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.157 (   6.842s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.159 (   6.844s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.159 (   6.844s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.160 (   6.846s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.160 (   6.846s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.160 (   6.846s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.160 (   6.846s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56201070 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.160 (   6.846s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.160 (   6.846s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.160 (   6.846s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.160 (   6.846s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.160 (   6.846s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.161 (   6.846s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d0d350 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.161 (   6.846s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.161 (   6.846s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.161 (   6.846s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.161 (   6.846s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.161 (   6.847s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.161 (   6.847s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.161 (   6.847s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.161 (   6.847s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5628ab40 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.161 (   6.847s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.162 (   6.847s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.162 (   6.847s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.162 (   6.847s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.162 (   6.847s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.162 (   6.847s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563e6c20 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.162 (   6.847s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.162 (   6.847s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.162 (   6.847s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.162 (   6.847s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.163 (   6.849s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.163 (   6.849s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.163 (   6.849s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.163 (   6.849s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b18d60 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.163 (   6.849s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.163 (   6.849s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.163 (   6.849s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.163 (   6.849s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.163 (   6.849s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.163 (   6.849s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8397e380 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.163 (   6.849s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.163 (   6.849s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.164 (   6.849s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.164 (   6.849s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.165 (   6.850s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.165 (   6.850s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.165 (   6.850s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.165 (   6.851s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562aae50 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.165 (   6.851s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.165 (   6.851s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.165 (   6.851s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.165 (   6.851s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.165 (   6.851s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.165 (   6.851s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562aafd0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.165 (   6.851s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.165 (   6.851s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.165 (   6.851s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.165 (   6.851s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.173 (   6.858s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.173 (   6.858s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.173 (   6.858s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.173 (   6.858s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83aa58a0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.173 (   6.858s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.173 (   6.858s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.173 (   6.858s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.173 (   6.858s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.173 (   6.858s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.173 (   6.858s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56282430 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.173 (   6.858s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.173 (   6.858s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.175 (   6.860s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.175 (   6.861s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.183 (   6.868s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.183 (   6.868s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.183 (   6.868s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.183 (   6.868s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c96b70 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.183 (   6.868s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.183 (   6.868s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.183 (   6.868s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.183 (   6.868s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.183 (   6.868s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.183 (   6.869s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x561e5bd0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.183 (   6.869s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.183 (   6.869s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.185 (   6.871s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.185 (   6.871s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.193 (   6.878s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.193 (   6.878s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.193 (   6.878s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.193 (   6.878s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562794b0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.193 (   6.878s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.193 (   6.878s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.193 (   6.878s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.193 (   6.878s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.193 (   6.878s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.193 (   6.878s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838ccb20 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.193 (   6.878s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.193 (   6.878s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.195 (   6.880s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.195 (   6.880s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.197 (   6.882s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.197 (   6.882s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.197 (   6.882s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.197 (   6.882s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83864e00 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.197 (   6.882s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.197 (   6.882s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.197 (   6.882s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.197 (   6.882s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.197 (   6.882s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.197 (   6.883s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83ab0050 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.197 (   6.883s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.197 (   6.883s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.197 (   6.883s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.197 (   6.883s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.198 (   6.883s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.198 (   6.884s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.198 (   6.884s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.198 (   6.884s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b4a8a0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.198 (   6.884s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.198 (   6.884s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.198 (   6.884s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.198 (   6.884s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.198 (   6.884s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.198 (   6.884s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x7524fd60 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.198 (   6.884s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.198 (   6.884s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.198 (   6.884s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.198 (   6.884s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.199 (   6.885s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.199 (   6.885s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.199 (   6.885s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.200 (   6.885s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c97580 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.200 (   6.885s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.200 (   6.885s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.200 (   6.885s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.200 (   6.885s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.200 (   6.885s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.200 (   6.885s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5647dd40 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.200 (   6.885s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.200 (   6.885s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.200 (   6.885s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.200 (   6.885s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.201 (   6.887s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.201 (   6.887s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.201 (   6.887s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.202 (   6.887s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56450440 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.202 (   6.887s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.202 (   6.887s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.202 (   6.887s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.202 (   6.887s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.202 (   6.887s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.202 (   6.887s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5647b880 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.202 (   6.887s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.202 (   6.887s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.202 (   6.887s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.202 (   6.887s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.209 (   6.895s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.209 (   6.895s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.209 (   6.895s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.209 (   6.895s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70adc810 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.209 (   6.895s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.209 (   6.895s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.209 (   6.895s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.209 (   6.895s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.209 (   6.895s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.209 (   6.895s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b82ab0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.209 (   6.895s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.209 (   6.895s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.211 (   6.897s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.211 (   6.897s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.219 (   6.904s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.219 (   6.904s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.219 (   6.904s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.219 (   6.904s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83824820 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.219 (   6.904s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.219 (   6.904s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.219 (   6.904s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.219 (   6.904s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.219 (   6.904s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.219 (   6.905s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d2e410 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.219 (   6.905s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.219 (   6.905s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.221 (   6.907s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.221 (   6.907s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.229 (   6.914s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.229 (   6.914s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.229 (   6.914s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.229 (   6.914s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56270b70 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.229 (   6.914s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.229 (   6.914s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.229 (   6.914s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.229 (   6.914s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.229 (   6.914s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.229 (   6.914s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839efab0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.229 (   6.914s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.229 (   6.914s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.231 (   6.916s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.231 (   6.916s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.232 (   6.918s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.232 (   6.918s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.232 (   6.918s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.232 (   6.918s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a690c0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.232 (   6.918s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.232 (   6.918s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.232 (   6.918s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.232 (   6.918s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.232 (   6.918s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.232 (   6.918s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x75224150 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.232 (   6.918s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.232 (   6.918s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.233 (   6.918s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.233 (   6.918s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b57520 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56470550 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.233 (   6.919s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.235 (   6.920s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.235 (   6.920s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.235 (   6.920s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.235 (   6.920s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84cb5080 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.235 (   6.920s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.235 (   6.920s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.235 (   6.920s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.235 (   6.920s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.235 (   6.920s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.235 (   6.920s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83947140 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.235 (   6.920s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.235 (   6.920s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.235 (   6.921s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.235 (   6.921s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.237 (   6.922s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.237 (   6.922s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.237 (   6.922s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.237 (   6.922s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70bec390 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.237 (   6.922s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.237 (   6.922s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.237 (   6.923s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.237 (   6.923s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.237 (   6.923s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.237 (   6.923s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837a9980 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.237 (   6.923s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.237 (   6.923s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.237 (   6.923s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.237 (   6.923s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.248 (   6.934s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.248 (   6.934s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.248 (   6.934s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.248 (   6.934s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83958860 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.248 (   6.934s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.248 (   6.934s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.248 (   6.934s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.248 (   6.934s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.248 (   6.934s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.248 (   6.934s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839be8e0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.248 (   6.934s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.248 (   6.934s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.250 (   6.936s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.250 (   6.936s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.258 (   6.943s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.258 (   6.943s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.258 (   6.943s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.258 (   6.944s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84beb010 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.258 (   6.944s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.258 (   6.944s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.258 (   6.944s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.258 (   6.944s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.258 (   6.944s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.258 (   6.944s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a23d00 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.258 (   6.944s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.258 (   6.944s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.260 (   6.946s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.260 (   6.946s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.268 (   6.953s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.268 (   6.953s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.268 (   6.953s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.268 (   6.954s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8382a940 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.268 (   6.954s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.268 (   6.954s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.268 (   6.954s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.268 (   6.954s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.268 (   6.954s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.268 (   6.954s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5633bca0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.268 (   6.954s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.268 (   6.954s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.270 (   6.956s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.270 (   6.956s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.271 (   6.957s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.271 (   6.957s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.271 (   6.957s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.272 (   6.957s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8392fe10 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.272 (   6.957s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.272 (   6.957s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.272 (   6.957s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.272 (   6.957s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.272 (   6.958s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.272 (   6.958s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838ac870 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.272 (   6.958s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.272 (   6.958s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.272 (   6.958s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.272 (   6.958s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.273 (   6.958s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.273 (   6.958s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.273 (   6.958s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.273 (   6.958s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b8a960 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.273 (   6.958s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.273 (   6.958s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.273 (   6.958s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.273 (   6.958s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.273 (   6.958s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.273 (   6.958s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838506a0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.273 (   6.958s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.273 (   6.958s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.273 (   6.959s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.273 (   6.959s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.274 (   6.960s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.274 (   6.960s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.274 (   6.960s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.274 (   6.960s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x4c93ed40 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.274 (   6.960s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.274 (   6.960s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.274 (   6.960s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.274 (   6.960s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.275 (   6.960s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.275 (   6.960s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x7520d8b0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.275 (   6.960s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.275 (   6.960s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.275 (   6.960s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.275 (   6.960s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.277 (   6.962s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.277 (   6.962s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.277 (   6.962s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.277 (   6.962s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563d05a0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.277 (   6.962s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.277 (   6.962s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.277 (   6.962s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.277 (   6.962s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.277 (   6.962s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.277 (   6.962s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x561a77b0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.277 (   6.962s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.277 (   6.962s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.277 (   6.963s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.277 (   6.963s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.284 (   6.970s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.284 (   6.970s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.284 (   6.970s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.285 (   6.970s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5635a980 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.285 (   6.970s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.285 (   6.970s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.285 (   6.970s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.285 (   6.970s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.285 (   6.970s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.285 (   6.970s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70ae98a0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.285 (   6.970s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.285 (   6.970s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.287 (   6.972s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.287 (   6.972s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.295 (   6.980s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.295 (   6.980s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.295 (   6.980s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.295 (   6.980s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c94510 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.295 (   6.980s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.295 (   6.980s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.295 (   6.980s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.295 (   6.980s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.295 (   6.980s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.295 (   6.980s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83916ba0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.295 (   6.980s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.295 (   6.980s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.297 (   6.982s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.297 (   6.982s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.308 (   6.993s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.308 (   6.993s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.308 (   6.993s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.308 (   6.993s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b9b720 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.308 (   6.993s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.308 (   6.993s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.308 (   6.993s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.308 (   6.993s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.308 (   6.993s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.308 (   6.994s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838fecd0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.308 (   6.994s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.308 (   6.994s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.310 (   6.996s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.310 (   6.996s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.311 (   6.997s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.311 (   6.997s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.311 (   6.997s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.312 (   6.997s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d7e1d0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.312 (   6.997s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.312 (   6.997s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.312 (   6.997s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.312 (   6.997s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.312 (   6.997s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.312 (   6.997s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70ca6730 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.312 (   6.997s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.312 (   6.997s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.312 (   6.997s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.312 (   6.997s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.312 (   6.998s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.312 (   6.998s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.312 (   6.998s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.312 (   6.998s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83960490 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.312 (   6.998s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.312 (   6.998s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.312 (   6.998s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.312 (   6.998s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.312 (   6.998s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.312 (   6.998s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84bc1ae0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.312 (   6.998s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.312 (   6.998s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.313 (   6.998s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.313 (   6.998s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a93b40 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c09890 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.314 (   7.000s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.316 (   7.002s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.316 (   7.002s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.316 (   7.002s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.316 (   7.002s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x564681f0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.316 (   7.002s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.316 (   7.002s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.316 (   7.002s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.316 (   7.002s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.316 (   7.002s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.317 (   7.002s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c5f040 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.317 (   7.002s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.317 (   7.002s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.317 (   7.002s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.317 (   7.002s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.324 (   7.010s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.324 (   7.010s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.324 (   7.010s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.324 (   7.010s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83943d30 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.324 (   7.010s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.324 (   7.010s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.324 (   7.010s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.324 (   7.010s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.324 (   7.010s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.325 (   7.010s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c14a40 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.325 (   7.010s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.325 (   7.010s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.326 (   7.012s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.326 (   7.012s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.334 (   7.020s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.334 (   7.020s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.334 (   7.020s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.334 (   7.020s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83990570 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.334 (   7.020s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.334 (   7.020s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.334 (   7.020s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.334 (   7.020s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.334 (   7.020s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.334 (   7.020s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84bd44f0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.334 (   7.020s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.334 (   7.020s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.336 (   7.022s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.336 (   7.022s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.344 (   7.030s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.344 (   7.030s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.344 (   7.030s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.344 (   7.030s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56312850 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.344 (   7.030s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.344 (   7.030s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.344 (   7.030s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.344 (   7.030s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.344 (   7.030s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.344 (   7.030s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563129d0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.344 (   7.030s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.344 (   7.030s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.346 (   7.032s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.346 (   7.032s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.348 (   7.033s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.348 (   7.033s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.348 (   7.033s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.348 (   7.033s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b8ef30 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.348 (   7.033s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.348 (   7.033s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.348 (   7.033s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.348 (   7.033s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.348 (   7.033s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.348 (   7.033s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70bde940 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.348 (   7.033s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.348 (   7.033s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.348 (   7.034s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.348 (   7.034s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.348 (   7.034s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.348 (   7.034s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.348 (   7.034s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.349 (   7.034s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563ac980 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.349 (   7.034s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.349 (   7.034s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.349 (   7.034s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.349 (   7.034s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.349 (   7.034s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.349 (   7.034s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83971160 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.349 (   7.034s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.349 (   7.034s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.349 (   7.034s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.349 (   7.034s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5633b190 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b14330 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.350 (   7.036s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56366660 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563773b0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.352 (   7.038s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.360 (   7.046s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.360 (   7.046s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.360 (   7.046s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.360 (   7.046s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a313d0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.360 (   7.046s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.360 (   7.046s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.360 (   7.046s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.360 (   7.046s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.360 (   7.046s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.360 (   7.046s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84cca2f0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.360 (   7.046s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.360 (   7.046s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.362 (   7.048s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.362 (   7.048s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.370 (   7.055s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.370 (   7.055s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.370 (   7.055s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.370 (   7.055s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563edbc0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.370 (   7.056s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.370 (   7.056s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.370 (   7.056s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.370 (   7.056s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.370 (   7.056s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.370 (   7.056s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837f3040 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.370 (   7.056s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.370 (   7.056s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.372 (   7.058s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.372 (   7.058s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.380 (   7.065s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.380 (   7.065s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.380 (   7.065s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.380 (   7.066s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8382fe10 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.380 (   7.066s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.380 (   7.066s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.380 (   7.066s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.380 (   7.066s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.380 (   7.066s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.380 (   7.066s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56458db0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.380 (   7.066s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.380 (   7.066s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.382 (   7.068s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.382 (   7.068s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.383 (   7.069s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.383 (   7.069s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.383 (   7.069s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.384 (   7.069s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8378ce00 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.384 (   7.069s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.384 (   7.069s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.384 (   7.069s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.384 (   7.069s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.384 (   7.069s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.384 (   7.069s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d05670 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.384 (   7.069s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.384 (   7.069s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.384 (   7.069s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.384 (   7.069s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.384 (   7.070s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.384 (   7.070s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.384 (   7.070s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.384 (   7.070s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70cc33d0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.384 (   7.070s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.384 (   7.070s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.384 (   7.070s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.384 (   7.070s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.384 (   7.070s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.384 (   7.070s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c99530 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.384 (   7.070s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.384 (   7.070s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.385 (   7.070s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.385 (   7.070s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.386 (   7.071s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.386 (   7.071s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.386 (   7.071s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.386 (   7.071s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70cc4130 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.386 (   7.071s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.386 (   7.071s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.386 (   7.071s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.386 (   7.071s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.386 (   7.071s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.386 (   7.071s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563b7530 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.386 (   7.071s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.386 (   7.071s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.386 (   7.072s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.386 (   7.072s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.388 (   7.073s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.388 (   7.073s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.388 (   7.073s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.388 (   7.074s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56424050 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.388 (   7.074s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.388 (   7.074s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.388 (   7.074s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.388 (   7.074s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.388 (   7.074s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.388 (   7.074s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c578c0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.388 (   7.074s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.388 (   7.074s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.388 (   7.074s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.388 (   7.074s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.396 (   7.081s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.396 (   7.081s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.396 (   7.081s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.396 (   7.081s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a112d0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.396 (   7.081s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.396 (   7.081s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.396 (   7.081s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.396 (   7.081s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.396 (   7.081s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.396 (   7.082s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x561e7210 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.396 (   7.082s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.396 (   7.082s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.398 (   7.084s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.398 (   7.084s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.406 (   7.091s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.406 (   7.091s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.406 (   7.091s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.406 (   7.091s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83908ed0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.406 (   7.091s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.406 (   7.091s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.406 (   7.091s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.406 (   7.091s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.406 (   7.091s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.406 (   7.091s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56308050 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.406 (   7.091s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.406 (   7.091s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.408 (   7.094s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.408 (   7.094s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.416 (   7.102s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.416 (   7.102s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.416 (   7.102s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.416 (   7.102s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8384e550 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.416 (   7.102s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.416 (   7.102s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.416 (   7.102s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.416 (   7.102s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.416 (   7.102s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.416 (   7.102s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562c8a40 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.416 (   7.102s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.416 (   7.102s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.418 (   7.104s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.418 (   7.104s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.420 (   7.105s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.420 (   7.105s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.420 (   7.105s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.420 (   7.105s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c48f30 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.420 (   7.105s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.420 (   7.105s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.420 (   7.105s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.420 (   7.105s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.420 (   7.105s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.420 (   7.106s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d82aa0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.420 (   7.106s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.420 (   7.106s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.420 (   7.106s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.420 (   7.106s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.421 (   7.106s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.421 (   7.106s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.421 (   7.106s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.421 (   7.106s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d241e0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.421 (   7.106s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.421 (   7.106s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.421 (   7.106s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.421 (   7.106s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.421 (   7.106s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.421 (   7.106s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8378c6d0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.421 (   7.106s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.421 (   7.106s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.421 (   7.106s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.421 (   7.107s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.422 (   7.108s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.422 (   7.108s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.422 (   7.108s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.423 (   7.108s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837b2f10 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.423 (   7.108s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.423 (   7.108s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.423 (   7.108s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.423 (   7.108s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.423 (   7.108s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.423 (   7.108s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837b3090 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.423 (   7.108s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.423 (   7.108s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.423 (   7.108s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.423 (   7.108s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.425 (   7.110s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.425 (   7.110s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.425 (   7.110s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.425 (   7.110s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70ccbb90 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.425 (   7.110s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.425 (   7.110s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.425 (   7.110s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.425 (   7.110s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.425 (   7.110s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.425 (   7.110s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x564071d0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.425 (   7.110s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.425 (   7.110s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.425 (   7.111s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.425 (   7.111s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.432 (   7.118s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.432 (   7.118s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.432 (   7.118s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.433 (   7.118s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563997c0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.433 (   7.118s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.433 (   7.118s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.433 (   7.118s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.433 (   7.118s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.433 (   7.118s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.433 (   7.118s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837882b0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.433 (   7.118s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.433 (   7.118s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.435 (   7.120s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.435 (   7.120s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.442 (   7.128s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.442 (   7.128s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.442 (   7.128s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.443 (   7.128s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838e86f0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.443 (   7.128s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.443 (   7.128s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.443 (   7.128s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.443 (   7.128s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.443 (   7.128s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.443 (   7.128s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x564cf7c0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.443 (   7.128s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.443 (   7.128s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.445 (   7.130s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.445 (   7.130s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.452 (   7.138s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.452 (   7.138s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.452 (   7.138s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.453 (   7.138s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838d53b0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.453 (   7.138s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.453 (   7.138s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.453 (   7.138s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.453 (   7.138s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.453 (   7.138s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.453 (   7.138s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837b1340 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.453 (   7.138s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.453 (   7.138s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.455 (   7.140s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.455 (   7.140s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.456 (   7.142s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.456 (   7.142s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.456 (   7.142s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.456 (   7.142s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5624a710 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.456 (   7.142s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.456 (   7.142s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.456 (   7.142s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.456 (   7.142s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.456 (   7.142s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.456 (   7.142s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d9c710 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.456 (   7.142s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.456 (   7.142s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.457 (   7.142s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.457 (   7.142s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838c7c70 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x564a7120 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.457 (   7.143s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.458 (   7.144s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.458 (   7.144s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.458 (   7.144s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.458 (   7.144s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839216d0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.459 (   7.144s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.459 (   7.144s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.459 (   7.144s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.459 (   7.144s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.459 (   7.144s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.459 (   7.144s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56254e60 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.459 (   7.144s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.459 (   7.144s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.459 (   7.144s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.459 (   7.144s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.461 (   7.146s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.461 (   7.146s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.461 (   7.146s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.461 (   7.146s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563c95d0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.461 (   7.146s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.461 (   7.146s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.461 (   7.146s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.461 (   7.146s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.461 (   7.146s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.461 (   7.146s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c59960 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.461 (   7.146s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.461 (   7.146s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.461 (   7.146s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.461 (   7.147s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.468 (   7.154s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.468 (   7.154s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.468 (   7.154s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.468 (   7.154s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70aff910 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.469 (   7.154s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.469 (   7.154s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.469 (   7.154s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.469 (   7.154s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.469 (   7.154s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.469 (   7.154s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83923580 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.469 (   7.154s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.469 (   7.154s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.471 (   7.156s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.471 (   7.156s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.478 (   7.164s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.478 (   7.164s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.478 (   7.164s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.478 (   7.164s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83aa84b0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.478 (   7.164s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.478 (   7.164s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.478 (   7.164s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.478 (   7.164s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.478 (   7.164s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.478 (   7.164s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562762e0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.478 (   7.164s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.478 (   7.164s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.480 (   7.166s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.480 (   7.166s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.488 (   7.174s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.488 (   7.174s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.488 (   7.174s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.488 (   7.174s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5639d870 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.488 (   7.174s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.488 (   7.174s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.488 (   7.174s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.488 (   7.174s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.488 (   7.174s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.488 (   7.174s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a09ac0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.488 (   7.174s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.488 (   7.174s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.490 (   7.176s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.490 (   7.176s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.492 (   7.177s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.492 (   7.177s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.492 (   7.177s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.492 (   7.177s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839cf400 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.492 (   7.177s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.492 (   7.177s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.492 (   7.177s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.492 (   7.177s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.492 (   7.177s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.492 (   7.178s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837f2d80 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.492 (   7.178s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.492 (   7.178s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.492 (   7.178s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.492 (   7.178s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d31300 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b14eb0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.493 (   7.178s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.494 (   7.180s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.494 (   7.180s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.494 (   7.180s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.494 (   7.180s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b37350 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.494 (   7.180s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.494 (   7.180s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.494 (   7.180s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.494 (   7.180s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.494 (   7.180s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.494 (   7.180s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563efa50 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.494 (   7.180s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.494 (   7.180s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.495 (   7.180s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.495 (   7.180s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d43d60 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8387a0d0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.496 (   7.182s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.504 (   7.189s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.504 (   7.190s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.504 (   7.190s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.504 (   7.190s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70bc42e0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.504 (   7.190s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.504 (   7.190s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.504 (   7.190s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.504 (   7.190s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.504 (   7.190s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.504 (   7.190s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70cdfe80 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.504 (   7.190s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.504 (   7.190s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.506 (   7.192s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.506 (   7.192s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.514 (   7.199s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.514 (   7.199s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.514 (   7.199s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.514 (   7.199s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70ae7cd0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.514 (   7.199s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.514 (   7.199s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.514 (   7.199s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.514 (   7.199s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.514 (   7.199s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.514 (   7.200s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83829b50 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.514 (   7.200s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.514 (   7.200s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.516 (   7.201s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.516 (   7.201s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.524 (   7.209s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.524 (   7.209s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.524 (   7.209s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.524 (   7.209s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c2e790 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.524 (   7.209s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.524 (   7.209s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.524 (   7.209s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.524 (   7.209s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.524 (   7.209s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.524 (   7.209s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837ecbe0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.524 (   7.209s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.524 (   7.209s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.526 (   7.211s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.526 (   7.211s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.527 (   7.213s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.527 (   7.213s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.527 (   7.213s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.527 (   7.213s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x855dfba0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.528 (   7.213s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.528 (   7.213s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.528 (   7.213s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.528 (   7.213s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.528 (   7.213s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.528 (   7.213s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c68de0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.528 (   7.213s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.528 (   7.213s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.528 (   7.213s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.528 (   7.213s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.528 (   7.214s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.528 (   7.214s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.528 (   7.214s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.529 (   7.214s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70ca1e00 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.529 (   7.214s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.529 (   7.214s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.529 (   7.214s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.529 (   7.214s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.529 (   7.214s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.529 (   7.214s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5636cc20 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.529 (   7.214s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.529 (   7.214s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.529 (   7.214s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.529 (   7.214s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.530 (   7.215s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.530 (   7.215s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.530 (   7.215s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.530 (   7.216s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839c4430 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.530 (   7.216s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.530 (   7.216s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.530 (   7.216s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.530 (   7.216s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.530 (   7.216s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.530 (   7.216s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84cb8ef0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.530 (   7.216s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.530 (   7.216s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.530 (   7.216s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.530 (   7.216s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83825960 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c71f00 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.532 (   7.218s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.540 (   7.225s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.540 (   7.225s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.540 (   7.225s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.540 (   7.226s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b83d00 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.540 (   7.226s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.540 (   7.226s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.540 (   7.226s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.540 (   7.226s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.540 (   7.226s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.540 (   7.226s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5622dda0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.540 (   7.226s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.540 (   7.226s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.542 (   7.228s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.542 (   7.228s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.550 (   7.235s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.550 (   7.235s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.550 (   7.235s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.550 (   7.235s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563bb810 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.550 (   7.235s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.550 (   7.235s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.550 (   7.235s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.550 (   7.235s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.550 (   7.235s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.550 (   7.235s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d797f0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.550 (   7.235s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.550 (   7.235s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.552 (   7.237s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.552 (   7.237s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.560 (   7.245s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.560 (   7.245s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.560 (   7.245s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.560 (   7.245s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70afe940 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.560 (   7.245s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.560 (   7.245s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.560 (   7.245s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.560 (   7.245s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.560 (   7.245s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.560 (   7.245s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x561d72d0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.560 (   7.245s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.560 (   7.245s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.562 (   7.247s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.562 (   7.247s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.563 (   7.249s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.563 (   7.249s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.563 (   7.249s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.563 (   7.249s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563fedd0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.563 (   7.249s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.563 (   7.249s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.563 (   7.249s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.563 (   7.249s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.563 (   7.249s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.563 (   7.249s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562eb3d0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.563 (   7.249s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.563 (   7.249s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.564 (   7.249s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.564 (   7.249s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b9de50 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563e21c0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.564 (   7.250s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.566 (   7.251s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.566 (   7.251s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.566 (   7.251s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.566 (   7.252s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8385bf90 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.566 (   7.252s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.566 (   7.252s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.566 (   7.252s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.566 (   7.252s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.566 (   7.252s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.566 (   7.252s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563f1050 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.566 (   7.252s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.566 (   7.252s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.566 (   7.252s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.566 (   7.252s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.568 (   7.253s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.568 (   7.254s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.568 (   7.254s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.568 (   7.254s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83882c50 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.568 (   7.254s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.568 (   7.254s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.568 (   7.254s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.568 (   7.254s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.568 (   7.254s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.568 (   7.254s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a5e4b0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.568 (   7.254s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.568 (   7.254s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.568 (   7.254s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.568 (   7.254s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.576 (   7.261s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.576 (   7.261s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.576 (   7.261s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.576 (   7.262s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b43920 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.576 (   7.262s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.576 (   7.262s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.576 (   7.262s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.576 (   7.262s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.576 (   7.262s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.576 (   7.262s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70dafe40 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.576 (   7.262s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.576 (   7.262s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.578 (   7.264s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.578 (   7.264s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.586 (   7.271s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.586 (   7.271s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.586 (   7.271s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.586 (   7.272s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x80a89400 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.586 (   7.272s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.586 (   7.272s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.586 (   7.272s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.586 (   7.272s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.586 (   7.272s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.586 (   7.272s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d56e20 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.586 (   7.272s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.586 (   7.272s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.588 (   7.274s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.588 (   7.274s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.596 (   7.281s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.596 (   7.281s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.596 (   7.281s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.596 (   7.282s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839583a0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.596 (   7.282s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.596 (   7.282s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.596 (   7.282s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.596 (   7.282s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.596 (   7.282s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.596 (   7.282s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x561ed190 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.596 (   7.282s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.596 (   7.282s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.598 (   7.284s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.598 (   7.284s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.600 (   7.285s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.600 (   7.285s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.600 (   7.285s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.600 (   7.285s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c1f480 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.600 (   7.285s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.600 (   7.285s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.600 (   7.285s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.600 (   7.285s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.600 (   7.285s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.600 (   7.285s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b2f3e0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.600 (   7.285s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.600 (   7.285s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.600 (   7.286s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.600 (   7.286s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.600 (   7.286s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.601 (   7.286s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.601 (   7.286s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.601 (   7.286s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c85330 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.601 (   7.286s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.601 (   7.286s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.601 (   7.286s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.601 (   7.286s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.601 (   7.286s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.601 (   7.286s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837ed070 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.601 (   7.286s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.601 (   7.286s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.601 (   7.286s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.601 (   7.286s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.602 (   7.287s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.602 (   7.287s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.602 (   7.287s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.602 (   7.288s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a88680 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.602 (   7.288s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.602 (   7.288s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.602 (   7.288s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.602 (   7.288s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.602 (   7.288s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.602 (   7.288s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c7b210 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.602 (   7.288s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.602 (   7.288s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.602 (   7.288s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.602 (   7.288s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x564c3360 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70ce1ce0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.604 (   7.290s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.612 (   7.298s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.612 (   7.298s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.612 (   7.298s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.612 (   7.298s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56259f60 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.612 (   7.298s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.612 (   7.298s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.612 (   7.298s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.612 (   7.298s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.612 (   7.298s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.612 (   7.298s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8394cbb0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.612 (   7.298s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.612 (   7.298s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.614 (   7.300s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.614 (   7.300s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.622 (   7.307s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.622 (   7.307s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.622 (   7.307s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.622 (   7.308s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70da7440 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.622 (   7.308s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.622 (   7.308s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.622 (   7.308s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.622 (   7.308s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.622 (   7.308s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.622 (   7.308s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56353210 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.622 (   7.308s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.622 (   7.308s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.624 (   7.310s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.624 (   7.310s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.632 (   7.317s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.632 (   7.317s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.632 (   7.317s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.632 (   7.318s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b6de10 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.632 (   7.318s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.632 (   7.318s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.632 (   7.318s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.632 (   7.318s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.632 (   7.318s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.632 (   7.318s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84cb8c30 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.632 (   7.318s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.632 (   7.318s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.634 (   7.320s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.634 (   7.320s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.635 (   7.321s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.635 (   7.321s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.635 (   7.321s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.636 (   7.321s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70da3170 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.636 (   7.321s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.636 (   7.321s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.636 (   7.321s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.636 (   7.321s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.636 (   7.321s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.636 (   7.321s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b41ea0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.636 (   7.321s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.636 (   7.321s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.636 (   7.321s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.636 (   7.321s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.636 (   7.322s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.636 (   7.322s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.636 (   7.322s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.636 (   7.322s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562095e0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.636 (   7.322s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.636 (   7.322s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.636 (   7.322s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.636 (   7.322s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.636 (   7.322s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.636 (   7.322s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b51300 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.636 (   7.322s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.636 (   7.322s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.637 (   7.322s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.637 (   7.322s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.638 (   7.323s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.638 (   7.323s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.638 (   7.323s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.638 (   7.324s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b86a60 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.638 (   7.324s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.638 (   7.324s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.638 (   7.324s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.638 (   7.324s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.638 (   7.324s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.638 (   7.324s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562789c0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.638 (   7.324s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.638 (   7.324s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.638 (   7.324s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.638 (   7.324s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.640 (   7.325s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.640 (   7.325s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.640 (   7.325s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.640 (   7.326s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838c9b90 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.640 (   7.326s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.640 (   7.326s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.640 (   7.326s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.640 (   7.326s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.640 (   7.326s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.640 (   7.326s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70db42c0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.640 (   7.326s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.640 (   7.326s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.640 (   7.326s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.640 (   7.326s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.648 (   7.333s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.648 (   7.333s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.648 (   7.333s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.648 (   7.333s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83872630 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.648 (   7.333s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.648 (   7.333s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.648 (   7.333s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.648 (   7.334s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.648 (   7.334s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.648 (   7.334s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b79b10 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.648 (   7.334s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.648 (   7.334s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.650 (   7.336s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.650 (   7.336s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.658 (   7.343s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.658 (   7.343s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.658 (   7.343s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.658 (   7.343s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x561b4630 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.658 (   7.343s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.658 (   7.343s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.658 (   7.343s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.658 (   7.343s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.658 (   7.343s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.658 (   7.343s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70cf36b0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.658 (   7.343s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.658 (   7.343s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.660 (   7.345s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.660 (   7.345s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.668 (   7.353s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.668 (   7.353s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.668 (   7.353s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.668 (   7.353s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563d6730 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.668 (   7.353s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.668 (   7.353s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.668 (   7.353s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.668 (   7.353s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.668 (   7.353s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.668 (   7.353s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c4ee20 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.668 (   7.353s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.668 (   7.353s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.670 (   7.355s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.670 (   7.355s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70cb7000 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b3d660 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.671 (   7.357s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b89e20 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c75a60 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.672 (   7.358s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c59250 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8381bd50 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.674 (   7.359s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.676 (   7.361s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.676 (   7.361s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.676 (   7.361s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.676 (   7.361s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562d6790 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.676 (   7.361s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.676 (   7.361s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.676 (   7.361s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.676 (   7.361s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.676 (   7.361s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.676 (   7.362s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b697d0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.676 (   7.362s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.676 (   7.362s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.676 (   7.362s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.676 (   7.362s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.684 (   7.369s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.684 (   7.369s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.684 (   7.369s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.684 (   7.369s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b0dfe0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.684 (   7.369s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.684 (   7.369s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.684 (   7.369s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.684 (   7.369s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.684 (   7.369s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.684 (   7.369s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a08b60 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.684 (   7.369s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.684 (   7.369s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.686 (   7.371s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.686 (   7.371s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.693 (   7.379s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.693 (   7.379s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.693 (   7.379s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.693 (   7.379s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b78020 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.693 (   7.379s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.693 (   7.379s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.694 (   7.379s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.694 (   7.379s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.694 (   7.379s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.694 (   7.379s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8391eaf0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.694 (   7.379s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.694 (   7.379s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.696 (   7.381s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.696 (   7.381s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.703 (   7.389s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.703 (   7.389s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.703 (   7.389s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.703 (   7.389s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839a7510 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.703 (   7.389s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.703 (   7.389s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.703 (   7.389s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.703 (   7.389s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.703 (   7.389s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.704 (   7.389s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a201c0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.704 (   7.389s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.704 (   7.389s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.705 (   7.391s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.705 (   7.391s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70cf38a0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562b4510 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.707 (   7.393s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.708 (   7.393s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.708 (   7.393s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.708 (   7.394s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.708 (   7.394s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56472f00 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.708 (   7.394s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.708 (   7.394s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.708 (   7.394s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.708 (   7.394s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.708 (   7.394s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.708 (   7.394s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56484740 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.708 (   7.394s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.708 (   7.394s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.708 (   7.394s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.708 (   7.394s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x561d07c0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563dfa00 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.709 (   7.395s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.711 (   7.396s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.711 (   7.396s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.711 (   7.396s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.711 (   7.397s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56364a80 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.711 (   7.397s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.711 (   7.397s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.711 (   7.397s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.711 (   7.397s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.711 (   7.397s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.711 (   7.397s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c530d0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.711 (   7.397s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.711 (   7.397s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.711 (   7.397s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.711 (   7.397s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.719 (   7.405s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.719 (   7.405s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.719 (   7.405s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.719 (   7.405s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562d3530 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.719 (   7.405s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.719 (   7.405s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.719 (   7.405s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.719 (   7.405s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.719 (   7.405s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.719 (   7.405s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83ad1d10 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.719 (   7.405s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.719 (   7.405s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.721 (   7.407s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.721 (   7.407s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.729 (   7.414s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.729 (   7.414s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.729 (   7.414s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.729 (   7.414s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c75d10 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.729 (   7.415s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.729 (   7.415s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.729 (   7.415s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.729 (   7.415s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.729 (   7.415s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.729 (   7.415s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56326fa0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.729 (   7.415s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.729 (   7.415s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.731 (   7.417s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.731 (   7.417s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.739 (   7.424s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.739 (   7.424s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.739 (   7.424s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.739 (   7.424s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x422bbf90 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.739 (   7.424s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.739 (   7.424s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.739 (   7.424s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.739 (   7.424s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.739 (   7.424s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.739 (   7.425s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5647d3f0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.739 (   7.425s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.739 (   7.425s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.741 (   7.426s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.741 (   7.426s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837be8c0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562d9f60 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.743 (   7.428s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.743 (   7.429s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.743 (   7.429s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.743 (   7.429s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.744 (   7.429s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d0e100 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.744 (   7.429s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.744 (   7.429s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.744 (   7.429s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.744 (   7.429s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.744 (   7.429s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.744 (   7.429s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837efc40 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.744 (   7.429s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.744 (   7.429s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.744 (   7.429s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.744 (   7.429s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.745 (   7.430s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.745 (   7.430s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.745 (   7.430s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.745 (   7.430s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8380d160 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.745 (   7.430s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.745 (   7.430s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.745 (   7.431s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.745 (   7.431s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.745 (   7.431s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.745 (   7.431s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b03730 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.745 (   7.431s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.745 (   7.431s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.745 (   7.431s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.745 (   7.431s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70dadd90 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5642b440 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.747 (   7.433s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.755 (   7.441s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.755 (   7.441s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.755 (   7.441s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.755 (   7.441s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562bcdb0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.755 (   7.441s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.755 (   7.441s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.755 (   7.441s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.755 (   7.441s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.755 (   7.441s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.755 (   7.441s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x561b85e0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.755 (   7.441s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.755 (   7.441s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.757 (   7.443s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.757 (   7.443s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.765 (   7.450s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.765 (   7.450s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.765 (   7.450s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.765 (   7.450s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56259950 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.765 (   7.450s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.765 (   7.450s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.765 (   7.450s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.765 (   7.450s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.765 (   7.450s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.765 (   7.451s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562a2a00 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.765 (   7.451s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.765 (   7.451s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.767 (   7.453s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.767 (   7.453s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.775 (   7.460s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.775 (   7.460s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.775 (   7.460s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.775 (   7.460s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562b38d0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.775 (   7.460s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.775 (   7.460s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.775 (   7.460s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.775 (   7.460s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.775 (   7.460s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.775 (   7.461s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562774a0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.775 (   7.461s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.775 (   7.461s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.777 (   7.462s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.777 (   7.462s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.778 (   7.464s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.778 (   7.464s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.778 (   7.464s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.779 (   7.464s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5629c290 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.779 (   7.464s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.779 (   7.464s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.779 (   7.464s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.779 (   7.464s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.779 (   7.464s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.779 (   7.464s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56267210 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.779 (   7.464s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.779 (   7.464s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.779 (   7.464s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.779 (   7.464s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.779 (   7.465s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.779 (   7.465s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.779 (   7.465s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.779 (   7.465s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5625c9b0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.779 (   7.465s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.779 (   7.465s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.779 (   7.465s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.779 (   7.465s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.779 (   7.465s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.780 (   7.465s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56266c10 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.780 (   7.465s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.780 (   7.465s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.780 (   7.465s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.780 (   7.465s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562144d0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562499d0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.781 (   7.467s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.783 (   7.469s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.783 (   7.469s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.783 (   7.469s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.783 (   7.469s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c7bdf0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.783 (   7.469s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.783 (   7.469s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.783 (   7.469s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.783 (   7.469s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.783 (   7.469s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.783 (   7.469s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56214860 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.784 (   7.469s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.784 (   7.469s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.784 (   7.469s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.784 (   7.469s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.791 (   7.477s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.791 (   7.477s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.791 (   7.477s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.791 (   7.477s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84cb8800 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.791 (   7.477s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.791 (   7.477s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.791 (   7.477s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.792 (   7.477s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.792 (   7.477s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.792 (   7.477s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c847c0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.792 (   7.477s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.792 (   7.477s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.794 (   7.479s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.794 (   7.479s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.801 (   7.487s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.801 (   7.487s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.801 (   7.487s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.801 (   7.487s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b1c550 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.801 (   7.487s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.801 (   7.487s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.801 (   7.487s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.801 (   7.487s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.801 (   7.487s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.801 (   7.487s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84bb9110 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.801 (   7.487s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.801 (   7.487s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.803 (   7.489s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.803 (   7.489s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.811 (   7.497s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.811 (   7.497s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.811 (   7.497s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.811 (   7.497s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c5db60 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.811 (   7.497s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.811 (   7.497s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.811 (   7.497s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.811 (   7.497s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.811 (   7.497s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.811 (   7.497s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562c93c0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.811 (   7.497s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.811 (   7.497s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.813 (   7.499s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.813 (   7.499s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.815 (   7.500s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.815 (   7.500s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.815 (   7.500s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.815 (   7.500s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b9d860 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.815 (   7.500s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.815 (   7.500s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.815 (   7.500s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.815 (   7.500s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.815 (   7.500s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.815 (   7.501s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562bd1a0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.815 (   7.501s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.815 (   7.501s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.815 (   7.501s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.815 (   7.501s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.816 (   7.501s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.816 (   7.501s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.816 (   7.501s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.816 (   7.501s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b21c10 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.816 (   7.501s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.816 (   7.501s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.816 (   7.501s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.816 (   7.501s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.816 (   7.501s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.816 (   7.501s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c0abe0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.816 (   7.501s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.816 (   7.501s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.816 (   7.502s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.816 (   7.502s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.817 (   7.502s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.817 (   7.503s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.817 (   7.503s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.817 (   7.503s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70da8060 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.817 (   7.503s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.817 (   7.503s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.817 (   7.503s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.817 (   7.503s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.817 (   7.503s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.817 (   7.503s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56436900 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.817 (   7.503s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.817 (   7.503s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.817 (   7.503s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.817 (   7.503s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837ba0c0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a98ae0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.819 (   7.505s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.827 (   7.513s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.827 (   7.513s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.827 (   7.513s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.827 (   7.513s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d9f6f0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.827 (   7.513s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.827 (   7.513s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.827 (   7.513s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.827 (   7.513s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.827 (   7.513s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.827 (   7.513s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5635b0f0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.827 (   7.513s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.827 (   7.513s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.829 (   7.515s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.829 (   7.515s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.837 (   7.523s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.837 (   7.523s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.837 (   7.523s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.837 (   7.523s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56234570 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.837 (   7.523s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.837 (   7.523s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.837 (   7.523s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.837 (   7.523s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.837 (   7.523s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.837 (   7.523s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d294f0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.837 (   7.523s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.837 (   7.523s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.839 (   7.525s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.839 (   7.525s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.847 (   7.533s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.847 (   7.533s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.847 (   7.533s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.847 (   7.533s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563c4fc0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.847 (   7.533s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.847 (   7.533s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.847 (   7.533s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.847 (   7.533s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.847 (   7.533s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.847 (   7.533s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563b9fd0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.847 (   7.533s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.847 (   7.533s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.849 (   7.535s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.849 (   7.535s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.851 (   7.536s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.851 (   7.536s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.851 (   7.536s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.851 (   7.536s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83ab5e00 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.851 (   7.536s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.851 (   7.536s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.851 (   7.536s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.851 (   7.536s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.851 (   7.536s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.851 (   7.537s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5634a4a0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.851 (   7.537s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.851 (   7.537s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.851 (   7.537s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.851 (   7.537s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.852 (   7.537s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.852 (   7.537s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.852 (   7.537s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.852 (   7.537s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838aa7a0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.852 (   7.537s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.852 (   7.537s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.852 (   7.537s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.852 (   7.537s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.852 (   7.537s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.852 (   7.537s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d64be0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.852 (   7.537s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.852 (   7.538s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.852 (   7.538s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.852 (   7.538s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.853 (   7.539s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.853 (   7.539s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.853 (   7.539s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.853 (   7.539s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83917e70 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.853 (   7.539s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.853 (   7.539s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.853 (   7.539s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.853 (   7.539s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.853 (   7.539s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.853 (   7.539s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70cde560 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.853 (   7.539s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.853 (   7.539s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.854 (   7.539s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.854 (   7.539s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.855 (   7.541s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.855 (   7.541s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.855 (   7.541s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.856 (   7.541s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d6c5d0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.856 (   7.541s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.856 (   7.541s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.856 (   7.541s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.856 (   7.541s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.856 (   7.541s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.856 (   7.541s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70db29b0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.856 (   7.541s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.856 (   7.541s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.856 (   7.541s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.856 (   7.541s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.864 (   7.549s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.864 (   7.549s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.864 (   7.549s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.864 (   7.549s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56295310 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.864 (   7.549s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.864 (   7.549s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.864 (   7.549s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.864 (   7.549s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.864 (   7.549s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.864 (   7.549s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x564a2c40 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.864 (   7.549s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.864 (   7.549s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.866 (   7.552s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.866 (   7.552s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.874 (   7.559s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.874 (   7.559s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.874 (   7.559s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.874 (   7.559s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c371d0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.874 (   7.559s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.874 (   7.559s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.874 (   7.559s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.874 (   7.559s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.874 (   7.559s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.874 (   7.559s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5625a6b0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.874 (   7.559s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.874 (   7.559s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.876 (   7.562s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.876 (   7.562s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.884 (   7.569s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.884 (   7.569s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.884 (   7.569s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.884 (   7.570s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c6a6d0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.884 (   7.570s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.884 (   7.570s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.884 (   7.570s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.884 (   7.570s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.884 (   7.570s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.884 (   7.570s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83809090 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.884 (   7.570s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.884 (   7.570s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.886 (   7.572s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.886 (   7.572s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.888 (   7.573s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.888 (   7.573s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.888 (   7.573s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.888 (   7.573s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70bc5c40 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.888 (   7.573s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.888 (   7.573s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.888 (   7.573s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.888 (   7.573s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.888 (   7.573s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.888 (   7.573s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839cb260 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.888 (   7.573s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.888 (   7.573s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.888 (   7.574s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.888 (   7.574s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563b4e60 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839983a0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.889 (   7.574s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8389e000 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563db6a0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.890 (   7.576s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.892 (   7.578s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.893 (   7.578s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.893 (   7.578s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.893 (   7.578s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d7c9f0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.893 (   7.578s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.893 (   7.578s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.893 (   7.578s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.893 (   7.578s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.893 (   7.578s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.893 (   7.578s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837c0a50 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.893 (   7.578s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.893 (   7.578s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.893 (   7.578s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.893 (   7.578s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.900 (   7.586s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.900 (   7.586s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.900 (   7.586s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.900 (   7.586s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84bfa750 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.900 (   7.586s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.900 (   7.586s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.900 (   7.586s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.900 (   7.586s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.900 (   7.586s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.900 (   7.586s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84cd4ef0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.900 (   7.586s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.900 (   7.586s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.903 (   7.588s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.903 (   7.588s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.910 (   7.596s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.910 (   7.596s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.910 (   7.596s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.910 (   7.596s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56427690 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.910 (   7.596s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.910 (   7.596s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.911 (   7.596s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.911 (   7.596s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.911 (   7.596s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.911 (   7.596s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70ba4510 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.911 (   7.596s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.911 (   7.596s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.913 (   7.599s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.913 (   7.599s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.921 (   7.606s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.921 (   7.606s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.921 (   7.606s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.921 (   7.607s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b99f70 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.921 (   7.607s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.921 (   7.607s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.921 (   7.607s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.921 (   7.607s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.921 (   7.607s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.921 (   7.607s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562bc1a0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.921 (   7.607s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.921 (   7.607s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.923 (   7.609s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.923 (   7.609s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83993150 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70ae4420 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.925 (   7.611s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839eb9b0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c9e210 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.926 (   7.612s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.927 (   7.613s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.927 (   7.613s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.927 (   7.613s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.928 (   7.613s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b75d10 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.928 (   7.613s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.928 (   7.613s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.928 (   7.613s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.928 (   7.613s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.928 (   7.613s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.928 (   7.613s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5649dc20 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.928 (   7.613s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.928 (   7.613s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.928 (   7.613s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.928 (   7.613s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.929 (   7.615s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.929 (   7.615s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.929 (   7.615s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.929 (   7.615s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d419a0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.929 (   7.615s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.929 (   7.615s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.929 (   7.615s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.929 (   7.615s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.929 (   7.615s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.930 (   7.615s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838da7a0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.930 (   7.615s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.930 (   7.615s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.930 (   7.615s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.930 (   7.615s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.937 (   7.622s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.937 (   7.622s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.937 (   7.622s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.937 (   7.622s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b8b5d0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.937 (   7.622s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.937 (   7.622s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.937 (   7.622s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.937 (   7.622s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.937 (   7.622s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.937 (   7.623s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c6dc60 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.937 (   7.623s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.937 (   7.623s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.939 (   7.625s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.939 (   7.625s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.947 (   7.633s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.947 (   7.633s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.947 (   7.633s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.947 (   7.633s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a6e4d0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.947 (   7.633s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.947 (   7.633s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.947 (   7.633s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.947 (   7.633s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.947 (   7.633s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.947 (   7.633s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562f82e0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.947 (   7.633s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.947 (   7.633s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.950 (   7.635s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.950 (   7.635s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.957 (   7.643s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.957 (   7.643s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.957 (   7.643s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.958 (   7.643s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563d0900 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.958 (   7.643s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.958 (   7.643s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.958 (   7.643s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.958 (   7.643s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.958 (   7.643s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.958 (   7.643s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5625ed30 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.958 (   7.643s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.958 (   7.643s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.960 (   7.646s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.960 (   7.646s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b8abe0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b25fd0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.962 (   7.647s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.962 (   7.648s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.962 (   7.648s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.962 (   7.648s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.963 (   7.648s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5637c700 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.963 (   7.648s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.963 (   7.648s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.963 (   7.648s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.963 (   7.648s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.963 (   7.648s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.963 (   7.648s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8395f240 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.963 (   7.648s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.963 (   7.648s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.963 (   7.648s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.963 (   7.648s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.964 (   7.649s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.964 (   7.649s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.964 (   7.649s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.964 (   7.649s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839bd630 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.964 (   7.649s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.964 (   7.649s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.964 (   7.649s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.964 (   7.649s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.964 (   7.649s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.964 (   7.650s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839bd7b0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.964 (   7.650s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.964 (   7.650s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.964 (   7.650s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.964 (   7.650s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.966 (   7.651s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.966 (   7.651s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.966 (   7.651s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.966 (   7.651s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56268d90 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.966 (   7.651s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.966 (   7.651s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.966 (   7.651s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.966 (   7.651s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.966 (   7.651s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.966 (   7.651s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x564c2390 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.966 (   7.652s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.966 (   7.652s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.966 (   7.652s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.966 (   7.652s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.973 (   7.658s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.973 (   7.658s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.973 (   7.658s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.973 (   7.658s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83aabac0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.973 (   7.658s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.973 (   7.658s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.973 (   7.658s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.973 (   7.658s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.973 (   7.658s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.973 (   7.659s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c29330 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.973 (   7.659s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.973 (   7.659s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.975 (   7.661s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.975 (   7.661s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.983 (   7.669s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.983 (   7.669s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.983 (   7.669s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.983 (   7.669s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a73c40 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.983 (   7.669s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.983 (   7.669s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.983 (   7.669s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.983 (   7.669s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.983 (   7.669s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.983 (   7.669s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d75540 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.983 (   7.669s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.983 (   7.669s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.986 (   7.671s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.986 (   7.671s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.993 (   7.679s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.993 (   7.679s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.993 (   7.679s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.993 (   7.679s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c13180 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.993 (   7.679s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.993 (   7.679s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.993 (   7.679s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.993 (   7.679s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.993 (   7.679s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.994 (   7.679s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5636e6e0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.994 (   7.679s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.994 (   7.679s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.996 (   7.681s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.996 (   7.681s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.997 (   7.683s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.997 (   7.683s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.997 (   7.683s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.997 (   7.683s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b19d10 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.997 (   7.683s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.997 (   7.683s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.997 (   7.683s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.997 (   7.683s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.997 (   7.683s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.997 (   7.683s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c7d7a0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.998 (   7.683s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.998 (   7.683s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.998 (   7.683s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.998 (   7.683s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b30fa0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56362990 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:07.998 (   7.684s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.000 (   7.685s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.000 (   7.685s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.000 (   7.685s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.000 (   7.685s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838b2660 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.000 (   7.685s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.000 (   7.685s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.000 (   7.685s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.000 (   7.685s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.000 (   7.685s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.000 (   7.685s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562bec40 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.000 (   7.685s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.000 (   7.685s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.000 (   7.686s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.000 (   7.686s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.002 (   7.687s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.002 (   7.687s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.002 (   7.687s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.002 (   7.687s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839a3ca0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.002 (   7.687s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.002 (   7.687s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.002 (   7.687s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.002 (   7.687s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.002 (   7.687s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.002 (   7.687s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56345a80 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.002 (   7.687s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.002 (   7.687s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.002 (   7.688s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.002 (   7.688s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.009 (   7.694s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.009 (   7.694s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.009 (   7.694s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.009 (   7.694s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8383f510 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.009 (   7.694s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.009 (   7.694s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.009 (   7.694s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.009 (   7.694s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.009 (   7.694s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.009 (   7.694s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b20580 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.009 (   7.695s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.009 (   7.695s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.011 (   7.697s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.011 (   7.697s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.019 (   7.705s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.019 (   7.705s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.019 (   7.705s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.019 (   7.705s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5646eda0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.019 (   7.705s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.019 (   7.705s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.019 (   7.705s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.019 (   7.705s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.019 (   7.705s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.019 (   7.705s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b90420 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.019 (   7.705s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.019 (   7.705s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.021 (   7.707s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.021 (   7.707s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.029 (   7.715s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.029 (   7.715s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.029 (   7.715s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.029 (   7.715s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83889680 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.029 (   7.715s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.029 (   7.715s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.029 (   7.715s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.029 (   7.715s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.029 (   7.715s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.029 (   7.715s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83aa3460 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.029 (   7.715s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.029 (   7.715s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.031 (   7.717s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.031 (   7.717s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70be9c30 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562e9fc0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.033 (   7.719s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.034 (   7.719s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.034 (   7.720s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.034 (   7.720s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.034 (   7.720s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83807480 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.034 (   7.720s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.034 (   7.720s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.034 (   7.720s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.034 (   7.720s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.034 (   7.720s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.034 (   7.720s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x561a7620 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.034 (   7.720s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.034 (   7.720s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.034 (   7.720s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.034 (   7.720s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.035 (   7.721s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.035 (   7.721s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.035 (   7.721s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.035 (   7.721s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562d0650 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.035 (   7.721s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.035 (   7.721s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.035 (   7.721s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.035 (   7.721s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.035 (   7.721s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.035 (   7.721s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c4cb30 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.035 (   7.721s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.035 (   7.721s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.036 (   7.721s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.036 (   7.721s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56424310 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5627f0a0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.037 (   7.723s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.044 (   7.729s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.044 (   7.729s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.044 (   7.729s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.044 (   7.730s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b7d890 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.044 (   7.730s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.044 (   7.730s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.044 (   7.730s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.044 (   7.730s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.044 (   7.730s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.044 (   7.730s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a0d3b0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.044 (   7.730s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.044 (   7.730s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.046 (   7.732s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.046 (   7.732s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.054 (   7.739s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.054 (   7.739s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.054 (   7.739s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.054 (   7.740s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563609c0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.054 (   7.740s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.054 (   7.740s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.054 (   7.740s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.054 (   7.740s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.054 (   7.740s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.054 (   7.740s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56360b40 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.054 (   7.740s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.054 (   7.740s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.056 (   7.742s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.056 (   7.742s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.064 (   7.749s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.064 (   7.749s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.064 (   7.749s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.064 (   7.750s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837e9070 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.064 (   7.750s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.064 (   7.750s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.064 (   7.750s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.064 (   7.750s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.064 (   7.750s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.064 (   7.750s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5624f7f0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.064 (   7.750s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.064 (   7.750s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.066 (   7.752s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.066 (   7.752s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.068 (   7.753s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.068 (   7.753s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.068 (   7.753s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.068 (   7.753s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c7ce40 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.068 (   7.753s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.068 (   7.753s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.068 (   7.753s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.068 (   7.753s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.068 (   7.753s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.068 (   7.754s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5630fce0 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.068 (   7.754s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.068 (   7.754s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.068 (   7.754s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.068 (   7.754s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.069 (   7.754s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.069 (   7.754s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.069 (   7.754s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.069 (   7.754s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84cd39a0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.069 (   7.754s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.069 (   7.754s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.069 (   7.754s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.069 (   7.754s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.069 (   7.754s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.069 (   7.754s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d8d870 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.069 (   7.755s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.069 (   7.755s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.069 (   7.755s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.069 (   7.755s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.070 (   7.756s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.070 (   7.756s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.070 (   7.756s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.070 (   7.756s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a1f830 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.070 (   7.756s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.070 (   7.756s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.070 (   7.756s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.070 (   7.756s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.070 (   7.756s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.070 (   7.756s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b97d20 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.070 (   7.756s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.070 (   7.756s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.071 (   7.756s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.071 (   7.756s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56277000 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x561f0410 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.072 (   7.758s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.079 (   7.764s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.079 (   7.764s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.079 (   7.764s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.079 (   7.764s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838273e0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.079 (   7.764s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.079 (   7.764s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.079 (   7.765s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.079 (   7.765s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.079 (   7.765s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.079 (   7.765s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562c0aa0 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.079 (   7.765s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.079 (   7.765s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.081 (   7.767s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.081 (   7.767s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.089 (   7.774s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.089 (   7.774s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.089 (   7.774s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.089 (   7.774s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b8d740 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.089 (   7.774s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.089 (   7.774s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.089 (   7.774s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.089 (   7.774s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.089 (   7.774s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.089 (   7.774s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838ba990 copyFromHost BORROWED shape=[4096,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.089 (   7.774s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.089 (   7.774s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.091 (   7.777s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.091 (   7.777s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.099 (   7.785s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.099 (   7.785s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.099 (   7.785s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.099 (   7.785s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b943c0 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.099 (   7.785s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.099 (   7.785s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.099 (   7.785s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.099 (   7.785s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.099 (   7.785s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.099 (   7.785s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562cca50 copyFromHost BORROWED shape=[3072,4096] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.099 (   7.785s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.099 (   7.785s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.101 (   7.787s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.101 (   7.787s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c0f590 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56466920 copyFromHost BORROWED shape=[1536,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.103 (   7.789s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.104 (   7.789s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.104 (   7.789s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.104 (   7.789s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.104 (   7.790s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837da860 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.104 (   7.790s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.104 (   7.790s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.104 (   7.790s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.104 (   7.790s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.104 (   7.790s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.104 (   7.790s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56336c00 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.104 (   7.790s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.104 (   7.790s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.104 (   7.790s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.104 (   7.790s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70af92e0 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d90b40 copyFromHost BORROWED shape=[512,3072] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.105 (   7.791s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:08.107 (   7.793s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.107 (   7.793s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.107 (   7.793s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.107 (   7.793s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56315250 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.107 (   7.793s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.107 (   7.793s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:08.107 (   7.793s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:08.107 (   7.793s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:08.107 (   7.793s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:08.107 (   7.793s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d4f2c0 copyFromHost BORROWED shape=[3072,1536] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:07:08.107 (   7.793s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:08.107 (   7.793s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.288 (   8.974s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.288 (   8.974s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.288 (   8.974s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.288 (   8.974s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.288 (   8.974s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.288 (   8.974s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70bdeeb0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:07:09.289 (   8.974s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.289 (   8.974s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.289 (   8.974s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.289 (   8.974s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.289 (   8.974s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.289 (   8.974s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70bb4740 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:07:09.289 (   8.974s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.289 (   8.974s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.289 (   8.974s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.289 (   8.974s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x564996d0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8377f530 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a44590 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.289 (   8.975s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.290 (   8.975s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839e0890 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:07:09.290 (   8.975s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.290 (   8.975s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.290 (   8.975s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.290 (   8.975s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.401 (   9.086s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.401 (   9.087s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.401 (   9.087s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.401 (   9.087s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70be4ad0 copyFromHost BORROWED shape=[128256,3072] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:07:09.401 (   9.087s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.401 (   9.087s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.401 (   9.087s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.401 (   9.087s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.401 (   9.087s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.401 (   9.087s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56366f40 copyFromHost BORROWED shape=[128256,3072] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:07:09.401 (   9.087s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.401 (   9.087s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.429 (   9.115s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.429 (   9.115s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.541 (   9.226s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.541 (   9.226s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.541 (   9.226s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.541 (   9.227s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a477b0 copyFromHost BORROWED shape=[128256,3072] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:07:09.541 (   9.227s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.541 (   9.227s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.541 (   9.227s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.541 (   9.227s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.541 (   9.227s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.541 (   9.227s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838479a0 copyFromHost BORROWED shape=[128256,3072] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:07:09.541 (   9.227s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.541 (   9.227s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.583 (   9.269s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.583 (   9.269s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.583 (   9.269s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.583 (   9.269s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.583 (   9.269s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.583 (   9.269s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8389c180 copyFromHost BORROWED shape=[64] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:07:09.583 (   9.269s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.583 (   9.269s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.584 (   9.269s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.584 (   9.269s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.584 (   9.269s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.584 (   9.269s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56402200 copyFromHost BORROWED shape=[64] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:07:09.584 (   9.269s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.584 (   9.269s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.584 (   9.270s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.584 (   9.270s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.585 (   9.270s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.585 (   9.270s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.585 (   9.270s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.585 (   9.270s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563f20c0 copyFromHost BORROWED shape=[] - NEW tensor.data=0x7ffc8de62420 tensor.handle=0x7ffc8de62470
2025-09-22 18:07:09.585 (   9.270s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.585 (   9.270s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.585 (   9.270s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.585 (   9.270s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.585 (   9.270s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.585 (   9.270s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x562b0440 copyFromHost BORROWED shape=[] - NEW tensor.data=0x7ffc8de62420 tensor.handle=0x7ffc8de62470
2025-09-22 18:07:09.585 (   9.270s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.585 (   9.270s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x4cb0a0f0 copyFromHost BORROWED shape=[] - NEW tensor.data=0x7ffc8de61e10 tensor.handle=0x7ffc8de61e60
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d78610 copyFromHost BORROWED shape=[] - NEW tensor.data=0x7ffc8de61e10 tensor.handle=0x7ffc8de61e60
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.588 (   9.274s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.591 (   9.276s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.591 (   9.276s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.591 (   9.276s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.591 (   9.276s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.591 (   9.276s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-22 18:07:09.591 (   9.276s) [        A88F8000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x75655cf0 copyFromHost OWNED shape=[] - NEW tensor.data=0x7ffc8de61b70 tensor.handle=0x7ffc8de61bc0
2025-09-22 18:07:09.591 (   9.276s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.591 (   9.276s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.591 (   9.276s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.591 (   9.276s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.591 (   9.276s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-22 18:07:09.591 (   9.277s) [        A88F8000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x70b99b00 copyFromHost OWNED shape=[] - NEW tensor.data=0x7ffc8de61b70 tensor.handle=0x7ffc8de61bc0
2025-09-22 18:07:09.591 (   9.277s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.591 (   9.277s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x85689af0 copyFromHost BORROWED shape=[] - NEW tensor.data=0x7ffc8de621b0 tensor.handle=0x7ffc8de62200
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x4cb02a20 copyFromHost BORROWED shape=[] - NEW tensor.data=0x7ffc8de621b0 tensor.handle=0x7ffc8de62200
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.592 (   9.278s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.596 (   9.282s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.596 (   9.282s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.596 (   9.282s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.596 (   9.282s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.596 (   9.282s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.596 (   9.282s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x3f36b210 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.596 (   9.282s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.596 (   9.282s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.596 (   9.282s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.596 (   9.282s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.596 (   9.282s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x7517c230 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x4c92e3f0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x75656470 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.597 (   9.282s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x7556b610 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70be49d0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84bdf5a0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5646e520 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84be9500 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.597 (   9.283s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b08740 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5635b3a0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70df8b20 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.598 (   9.283s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70e01300 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x4cbb3910 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x854addc0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x85519990 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c1ae70 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.598 (   9.284s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84bb02a0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838d2840 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b9b230 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.599 (   9.284s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x856b1540 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x854c5130 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b0b3b0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8558c700 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.599 (   9.285s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c28e80 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838efb40 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x564531b0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.600 (   9.285s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839b9c90 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b37c00 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.600 (   9.286s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.601 (   9.286s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83901b20 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.601 (   9.286s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.601 (   9.286s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.601 (   9.286s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.601 (   9.286s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.601 (   9.286s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.601 (   9.286s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.601 (   9.286s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.601 (   9.287s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83880aa0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.601 (   9.287s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.601 (   9.287s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.601 (   9.287s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.601 (   9.287s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.601 (   9.287s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.602 (   9.287s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x838a1d70 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.602 (   9.287s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.602 (   9.287s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.602 (   9.287s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.602 (   9.287s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.602 (   9.288s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.603 (   9.288s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.603 (   9.288s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.603 (   9.289s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b23710 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.603 (   9.289s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.603 (   9.289s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.603 (   9.289s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.603 (   9.289s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.603 (   9.289s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563bbef0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8552e3b0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.604 (   9.289s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70ca3ce0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5624c0a0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.604 (   9.290s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b1a860 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a3f0e0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b30b50 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.605 (   9.290s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c6ff30 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b60030 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70ce9dc0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5621ab80 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.605 (   9.291s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.606 (   9.291s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.606 (   9.291s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.606 (   9.291s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83884dc0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c89460 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70bf7630 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c2ccc0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.606 (   9.292s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.607 (   9.292s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.607 (   9.292s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.607 (   9.292s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83ad66e0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.607 (   9.292s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.607 (   9.292s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.607 (   9.292s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.607 (   9.292s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.607 (   9.292s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.607 (   9.292s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x564045c0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.607 (   9.292s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.607 (   9.292s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c7c850 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5649f480 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x564b67a0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70bf0ea0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.607 (   9.293s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c959a0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a06510 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.608 (   9.293s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70e93950 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c7c9d0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b19940 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70ebddf0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.608 (   9.294s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8561eba0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c317e0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8395ab90 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.609 (   9.294s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x561a6780 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x856a9230 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83828740 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8390d550 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837e4f50 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.609 (   9.295s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5639c480 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83804840 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.610 (   9.295s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a31800 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84b44710 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x561dc0e0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a8bed0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c56bb0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.610 (   9.296s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5644ebe0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83998a30 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70d44b10 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.611 (   9.296s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83824b20 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56371fe0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70e7d830 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a88cb0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.611 (   9.297s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8564d6e0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x85640610 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837c3b00 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.612 (   9.297s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a9f8b0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c99450 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56331910 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.612 (   9.298s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8563b640 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84c32c00 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70dfa1b0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83a38a40 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.613 (   9.298s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70cbbd10 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x84ba63e0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b740e0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5632df50 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.613 (   9.299s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56246240 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x85523bf0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x839f28c0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.614 (   9.299s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x56206270 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x8552ef60 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x563bb380 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b017a0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.614 (   9.300s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837712d0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x837fdb00 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x5633ab70 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.615 (   9.300s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c06df0 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x83ac4570 copyFromHost BORROWED shape=[3072] - NEW tensor.data=0x7ffc8de631b0 tensor.handle=0x7ffc8de63200
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.615 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.301s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.616 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.302s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.303s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.303s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.303s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.303s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.617 (   9.303s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.618 (   9.303s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.618 (   9.303s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.618 (   9.304s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:07:09.656 (   9.341s) [        A88F8000]     client_instance.cc:427      1| ClientInstance::PJRT_Client_Compile
2025-09-22 18:07:09.656 (   9.342s) [        A88F8000]      module_builder.cc:99       1| ModuleBuilder::buildModule
2025-09-22 18:07:09.659 (   9.344s) [        A88F8000]      module_builder.cc:161      1| VHLO Module:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.31")
#loc4 = loc("p3.37")
#loc5 = loc("p4.39")
#loc6 = loc("p5.44")
#loc7 = loc("p6.81")
#loc8 = loc("p7.118")
#loc9 = loc("p8.130")
#loc10 = loc("p9.139")
#loc11 = loc("p10.160")
#loc12 = loc("p11.169")
#loc13 = loc("p12.177")
#loc14 = loc("p13.182")
#loc15 = loc("p14.190")
#loc16 = loc("p15.220")
#loc17 = loc("p16.254")
#loc18 = loc("p17.269")
#loc19 = loc("p18.371")
#loc20 = loc("p19.383")
#loc21 = loc("p20.435")
#loc47 = loc("reduce.60")
#loc99 = loc("scatter.136")
#loc109 = loc("scatter.166")
#loc163 = loc("reduce.316")
#loc168 = loc("reduce.325")
#loc194 = loc("reduce.350")
#loc239 = loc("reduce.414")
module @SyncTensorsGraph.450 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<7x!vhlo.i64_v1> loc("p0.3"), %arg1: !vhlo.tensor_v1<64x!vhlo.f32_v1> loc("p1.13"), %arg2: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc("p2.31"), %arg3: !vhlo.tensor_v1<!vhlo.f32_v1> loc("p3.37"), %arg4: !vhlo.tensor_v1<1x7x!vhlo.i64_v1> loc("p4.39"), %arg5: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc("p5.44"), %arg6: !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc("p6.81"), %arg7: !vhlo.tensor_v1<!vhlo.i64_v1> loc("p7.118"), %arg8: !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc("p8.130"), %arg9: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc("p9.139"), %arg10: !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc("p10.160"), %arg11: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc("p11.169"), %arg12: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc("p12.177"), %arg13: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc("p13.182"), %arg14: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc("p14.190"), %arg15: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("p15.220"), %arg16: !vhlo.tensor_v1<!vhlo.f32_v1> loc("p16.254"), %arg17: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc("p17.269"), %arg18: !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc("p18.371"), %arg19: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc("p19.383"), %arg20: !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc("p20.435")) -> (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]> : tensor<16xi64>>}> : () -> !vhlo.tensor_v1<16x!vhlo.i64_v1> loc(#loc)
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>>}> : () -> !vhlo.tensor_v1<7x!vhlo.i64_v1> loc(#loc)
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<7xi64>>}> : () -> !vhlo.tensor_v1<7x!vhlo.i64_v1> loc(#loc)
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<3.25520843E-4> : tensor<1x7xf32>>}> : () -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1> loc(#loc)
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<1> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %8 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %9 = "vhlo.broadcast_in_dim_v1"(%8) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.bf16_v1> loc(#loc)
    %10 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.i64_v1> loc(#loc)
    %11 = "vhlo.broadcast_in_dim_v1"(%5) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc)
    %12 = "vhlo.custom_call_v1"(%arg8) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_2">}>} : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc(#loc22)
    %13 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1> loc(#loc23)
    %14 = "vhlo.custom_call_v1"(%13) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1> loc(#loc24)
    %15 = "vhlo.reshape_v1"(%14) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1> loc(#loc25)
    %16 = "vhlo.compare_v1"(%15, %4) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.bool_v1> loc(#loc26)
    %17 = "vhlo.broadcast_in_dim_v1"(%arg7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1> loc(#loc27)
    %18 = "vhlo.add_v1"(%15, %17) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1> loc(#loc28)
    %19 = "vhlo.select_v1"(%16, %18, %15) : (!vhlo.tensor_v1<7x!vhlo.bool_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1> loc(#loc29)
    %20 = "vhlo.reshape_v1"(%19) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1x!vhlo.i64_v1> loc(#loc30)
    %21 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc31)
    %22 = "vhlo.custom_call_v1"(%21) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc32)
    %23 = "vhlo.reshape_v1"(%22) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc(#loc33)
    %24 = "vhlo.convert_v1"(%23) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1> loc(#loc34)
    %25 = "vhlo.broadcast_in_dim_v1"(%24) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc35)
    %26 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc36)
    %27 = "vhlo.custom_call_v1"(%26) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc37)
    %28 = "vhlo.reshape_v1"(%27) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc(#loc38)
    %29 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1> loc(#loc39)
    %30 = "vhlo.custom_call_v1"(%29) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1> loc(#loc40)
    %31 = "vhlo.reshape_v1"(%30) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1> loc(#loc41)
    %32 = "vhlo.convert_v1"(%31) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.ui32_v1> loc(#loc42)
    %33 = "vhlo.gather_v2"(%28, %32) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3072]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1> loc(#loc43)
    %34 = "vhlo.reshape_v1"(%33) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1> loc(#loc44)
    %35 = "vhlo.convert_v1"(%34) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc45)
    %36 = "vhlo.power_v1"(%35, %11) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc46)
    %37 = "vhlo.reduce_v1"(%36, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.60"), %arg22: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.60")):
      %244 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc48)
      "vhlo.return_v1"(%244) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1> loc(#loc47)
    %38 = "vhlo.multiply_v1"(%37, %6) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1> loc(#loc49)
    %39 = "vhlo.reshape_v1"(%38) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1> loc(#loc50)
    %40 = "vhlo.broadcast_in_dim_v1"(%arg3) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1> loc(#loc51)
    %41 = "vhlo.add_v1"(%39, %40) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1> loc(#loc52)
    %42 = "vhlo.rsqrt_v2"(%41) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1> loc(#loc53)
    %43 = "vhlo.reshape_v1"(%42) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1> loc(#loc54)
    %44 = "vhlo.broadcast_in_dim_v1"(%43) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc55)
    %45 = "vhlo.multiply_v1"(%35, %44) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc56)
    %46 = "vhlo.convert_v1"(%45) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1> loc(#loc57)
    %47 = "vhlo.convert_v1"(%46) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc58)
    %48 = "vhlo.multiply_v1"(%25, %47) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc59)
    %49 = "vhlo.convert_v1"(%48) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1> loc(#loc60)
    %50 = "vhlo.reshape_v1"(%49) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1> loc(#loc61)
    %51 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc62)
    %52 = "vhlo.custom_call_v1"(%51) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc63)
    %53 = "vhlo.reshape_v1"(%52) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc(#loc64)
    %54 = "vhlo.transpose_v1"(%53) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1> loc(#loc65)
    %55 = "vhlo.dot_general_v2"(%50, %54) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1> loc(#loc66)
    %56 = "vhlo.reshape_v1"(%55) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1> loc(#loc67)
    %57 = "vhlo.transpose_v1"(%56) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1> loc(#loc68)
    %58 = "vhlo.convert_v1"(%57) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1> loc(#loc69)
    %59 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc70)
    %60 = "vhlo.custom_call_v1"(%59) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc71)
    %61 = "vhlo.reshape_v1"(%60) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1> loc(#loc72)
    %62 = "vhlo.convert_v1"(%14) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1> loc(#loc73)
    %63 = "vhlo.dot_general_v2"(%61, %62) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x7x!vhlo.f32_v1> loc(#loc74)
    %64 = "vhlo.transpose_v1"(%63) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,7,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1> loc(#loc75)
    %65 = "vhlo.concatenate_v1"(%64, %64) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1> loc(#loc76)
    %66 = "vhlo.cosine_v2"(%65) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1> loc(#loc77)
    %67 = "vhlo.convert_v1"(%66) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1> loc(#loc78)
    %68 = "vhlo.reshape_v1"(%67) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1> loc(#loc79)
    %69 = "vhlo.convert_v1"(%68) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1> loc(#loc80)
    %70 = "vhlo.reshape_v1"(%69) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1> loc(#loc81)
    %71 = "vhlo.broadcast_in_dim_v1"(%70) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1> loc(#loc82)
    %72 = "vhlo.multiply_v1"(%58, %71) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1> loc(#loc83)
    %73 = "vhlo.convert_v1"(%72) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1> loc(#loc84)
    %74 = "vhlo.slice_v1"(%57) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1> loc(#loc85)
    %75 = "vhlo.negate_v1"(%74) : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1> loc(#loc86)
    %76 = "vhlo.slice_v1"(%57) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1> loc(#loc87)
    %77 = "vhlo.concatenate_v1"(%75, %76) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1> loc(#loc88)
    %78 = "vhlo.convert_v1"(%77) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1> loc(#loc89)
    %79 = "vhlo.sine_v2"(%65) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1> loc(#loc90)
    %80 = "vhlo.convert_v1"(%79) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1> loc(#loc91)
    %81 = "vhlo.reshape_v1"(%80) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1> loc(#loc92)
    %82 = "vhlo.convert_v1"(%81) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1> loc(#loc93)
    %83 = "vhlo.reshape_v1"(%82) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1> loc(#loc94)
    %84 = "vhlo.broadcast_in_dim_v1"(%83) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1> loc(#loc95)
    %85 = "vhlo.multiply_v1"(%78, %84) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1> loc(#loc96)
    %86 = "vhlo.convert_v1"(%85) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1> loc(#loc97)
    %87 = "vhlo.add_v1"(%73, %86) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1> loc(#loc98)
    %88 = "vhlo.scatter_v2"(%12, %20, %87) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.136"), %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.136")):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc(#loc99)
    %89 = "vhlo.custom_call_v1"(%88) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc(#loc100)
    %90 = "vhlo.custom_call_v1"(%arg10) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_3">}>} : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc(#loc101)
    %91 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc102)
    %92 = "vhlo.custom_call_v1"(%91) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc103)
    %93 = "vhlo.reshape_v1"(%92) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc(#loc104)
    %94 = "vhlo.transpose_v1"(%93) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1> loc(#loc105)
    %95 = "vhlo.dot_general_v2"(%50, %94) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1> loc(#loc106)
    %96 = "vhlo.reshape_v1"(%95) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1> loc(#loc107)
    %97 = "vhlo.transpose_v1"(%96) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1> loc(#loc108)
    %98 = "vhlo.scatter_v2"(%90, %20, %97) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.166"), %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.166")):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc(#loc109)
    %99 = "vhlo.custom_call_v1"(%98) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc(#loc110)
    %100 = "vhlo.reshape_v1"(%arg20) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc111)
    %101 = "vhlo.custom_call_v1"(%100) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_norm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc112)
    %102 = "vhlo.reshape_v1"(%101) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc(#loc113)
    %103 = "vhlo.convert_v1"(%102) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1> loc(#loc114)
    %104 = "vhlo.broadcast_in_dim_v1"(%103) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc115)
    %105 = "vhlo.reshape_v1"(%arg17) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc116)
    %106 = "vhlo.custom_call_v1"(%105) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc117)
    %107 = "vhlo.reshape_v1"(%106) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc118)
    %108 = "vhlo.transpose_v1"(%107) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc119)
    %109 = "vhlo.dot_general_v2"(%50, %108) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1> loc(#loc120)
    %110 = "vhlo.reshape_v1"(%109) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1> loc(#loc121)
    %111 = "vhlo.transpose_v1"(%110) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1> loc(#loc122)
    %112 = "vhlo.convert_v1"(%111) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1> loc(#loc123)
    %113 = "vhlo.broadcast_in_dim_v1"(%70) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1> loc(#loc124)
    %114 = "vhlo.multiply_v1"(%112, %113) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1> loc(#loc125)
    %115 = "vhlo.convert_v1"(%114) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1> loc(#loc126)
    %116 = "vhlo.slice_v1"(%111) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1> loc(#loc127)
    %117 = "vhlo.negate_v1"(%116) : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1> loc(#loc128)
    %118 = "vhlo.slice_v1"(%111) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1> loc(#loc129)
    %119 = "vhlo.concatenate_v1"(%117, %118) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1> loc(#loc130)
    %120 = "vhlo.convert_v1"(%119) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1> loc(#loc131)
    %121 = "vhlo.broadcast_in_dim_v1"(%83) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1> loc(#loc132)
    %122 = "vhlo.multiply_v1"(%120, %121) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1> loc(#loc133)
    %123 = "vhlo.convert_v1"(%122) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1> loc(#loc134)
    %124 = "vhlo.add_v1"(%115, %123) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1> loc(#loc135)
    %125 = "vhlo.reshape_v1"(%124) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1> loc(#loc136)
    %126 = "vhlo.broadcast_in_dim_v1"(%88) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x16x128x!vhlo.bf16_v1> loc(#loc137)
    %127 = "vhlo.reshape_v1"(%126) : (!vhlo.tensor_v1<1x8x3x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x16x128x!vhlo.bf16_v1> loc(#loc138)
    %128 = "vhlo.transpose_v1"(%127) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,16]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x16x!vhlo.bf16_v1> loc(#loc139)
    %129 = "vhlo.reshape_v1"(%128) : (!vhlo.tensor_v1<1x24x128x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x16x!vhlo.bf16_v1> loc(#loc140)
    %130 = "vhlo.dot_general_v2"(%125, %129) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x16x!vhlo.bf16_v1> loc(#loc141)
    %131 = "vhlo.reshape_v1"(%130) : (!vhlo.tensor_v1<24x7x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.bf16_v1> loc(#loc142)
    %132 = "vhlo.convert_v1"(%131) : (!vhlo.tensor_v1<1x24x7x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1> loc(#loc143)
    %133 = "vhlo.broadcast_in_dim_v1"(%arg16) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1> loc(#loc144)
    %134 = "vhlo.multiply_v1"(%132, %133) : (!vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1> loc(#loc145)
    %135 = "vhlo.convert_v1"(%134) : (!vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.bf16_v1> loc(#loc146)
    %136 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<16x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.i64_v1> loc(#loc147)
    %137 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.i64_v1> loc(#loc148)
    %138 = "vhlo.subtract_v1"(%136, %137) : (!vhlo.tensor_v1<7x16x!vhlo.i64_v1>, !vhlo.tensor_v1<7x16x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.i64_v1> loc(#loc149)
    %139 = "vhlo.compare_v1"(%138, %10) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GE>}> : (!vhlo.tensor_v1<7x16x!vhlo.i64_v1>, !vhlo.tensor_v1<7x16x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.bool_v1> loc(#loc150)
    %140 = "vhlo.broadcast_in_dim_v1"(%arg15) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.bf16_v1> loc(#loc151)
    %141 = "vhlo.select_v1"(%139, %140, %9) : (!vhlo.tensor_v1<7x16x!vhlo.bool_v1>, !vhlo.tensor_v1<7x16x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.bf16_v1> loc(#loc152)
    %142 = "vhlo.convert_v1"(%141) : (!vhlo.tensor_v1<7x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.f32_v1> loc(#loc153)
    %143 = "vhlo.broadcast_in_dim_v1"(%15) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.i64_v1> loc(#loc154)
    %144 = "vhlo.compare_v1"(%136, %143) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<7x16x!vhlo.i64_v1>, !vhlo.tensor_v1<7x16x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.bool_v1> loc(#loc155)
    %145 = "vhlo.convert_v1"(%144) : (!vhlo.tensor_v1<7x16x!vhlo.bool_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.f32_v1> loc(#loc156)
    %146 = "vhlo.multiply_v1"(%142, %145) : (!vhlo.tensor_v1<7x16x!vhlo.f32_v1>, !vhlo.tensor_v1<7x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.f32_v1> loc(#loc157)
    %147 = "vhlo.convert_v1"(%146) : (!vhlo.tensor_v1<7x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x16x!vhlo.bf16_v1> loc(#loc158)
    %148 = "vhlo.reshape_v1"(%147) : (!vhlo.tensor_v1<7x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x16x!vhlo.bf16_v1> loc(#loc159)
    %149 = "vhlo.broadcast_in_dim_v1"(%148) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.bf16_v1> loc(#loc160)
    %150 = "vhlo.add_v1"(%135, %149) : (!vhlo.tensor_v1<1x24x7x16x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.bf16_v1> loc(#loc161)
    %151 = "vhlo.convert_v1"(%150) : (!vhlo.tensor_v1<1x24x7x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1> loc(#loc162)
    %152 = "vhlo.reduce_v1"(%151, %3) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.316"), %arg22: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.316")):
      %244 = "vhlo.maximum_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc164)
      "vhlo.return_v1"(%244) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1> loc(#loc163)
    %153 = "vhlo.broadcast_in_dim_v1"(%152) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1> loc(#loc165)
    %154 = "vhlo.subtract_v1"(%151, %153) : (!vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1> loc(#loc166)
    %155 = "vhlo.exponential_v2"(%154) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1> loc(#loc167)
    %156 = "vhlo.reduce_v1"(%155, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.325"), %arg22: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.325")):
      %244 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc169)
      "vhlo.return_v1"(%244) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1> loc(#loc168)
    %157 = "vhlo.broadcast_in_dim_v1"(%156) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1> loc(#loc170)
    %158 = "vhlo.divide_v1"(%155, %157) : (!vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1> loc(#loc171)
    %159 = "vhlo.convert_v1"(%158) : (!vhlo.tensor_v1<1x24x7x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x16x!vhlo.bf16_v1> loc(#loc172)
    %160 = "vhlo.reshape_v1"(%159) : (!vhlo.tensor_v1<1x24x7x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x16x!vhlo.bf16_v1> loc(#loc173)
    %161 = "vhlo.broadcast_in_dim_v1"(%98) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x16x128x!vhlo.bf16_v1> loc(#loc174)
    %162 = "vhlo.reshape_v1"(%161) : (!vhlo.tensor_v1<1x8x3x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x16x128x!vhlo.bf16_v1> loc(#loc175)
    %163 = "vhlo.dot_general_v2"(%160, %162) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x16x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1> loc(#loc176)
    %164 = "vhlo.reshape_v1"(%163) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1> loc(#loc177)
    %165 = "vhlo.transpose_v1"(%164) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,7,24,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1> loc(#loc178)
    %166 = "vhlo.reshape_v1"(%165) : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1> loc(#loc179)
    %167 = "vhlo.reshape_v1"(%arg14) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc180)
    %168 = "vhlo.custom_call_v1"(%167) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc181)
    %169 = "vhlo.reshape_v1"(%168) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc182)
    %170 = "vhlo.transpose_v1"(%169) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc183)
    %171 = "vhlo.dot_general_v2"(%166, %170) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1> loc(#loc184)
    %172 = "vhlo.reshape_v1"(%171) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1> loc(#loc185)
    %173 = "vhlo.add_v1"(%34, %172) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1> loc(#loc186)
    %174 = "vhlo.reshape_v1"(%arg18) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc187)
    %175 = "vhlo.custom_call_v1"(%174) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc188)
    %176 = "vhlo.reshape_v1"(%175) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc(#loc189)
    %177 = "vhlo.convert_v1"(%176) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1> loc(#loc190)
    %178 = "vhlo.broadcast_in_dim_v1"(%177) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc191)
    %179 = "vhlo.convert_v1"(%173) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc192)
    %180 = "vhlo.power_v1"(%179, %11) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc193)
    %181 = "vhlo.reduce_v1"(%180, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.350"), %arg22: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.350")):
      %244 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc195)
      "vhlo.return_v1"(%244) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1> loc(#loc194)
    %182 = "vhlo.multiply_v1"(%181, %6) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1> loc(#loc196)
    %183 = "vhlo.reshape_v1"(%182) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1> loc(#loc197)
    %184 = "vhlo.add_v1"(%183, %40) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1> loc(#loc198)
    %185 = "vhlo.rsqrt_v2"(%184) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1> loc(#loc199)
    %186 = "vhlo.reshape_v1"(%185) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1> loc(#loc200)
    %187 = "vhlo.broadcast_in_dim_v1"(%186) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc201)
    %188 = "vhlo.multiply_v1"(%179, %187) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc202)
    %189 = "vhlo.convert_v1"(%188) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1> loc(#loc203)
    %190 = "vhlo.convert_v1"(%189) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc204)
    %191 = "vhlo.multiply_v1"(%178, %190) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc205)
    %192 = "vhlo.convert_v1"(%191) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1> loc(#loc206)
    %193 = "vhlo.reshape_v1"(%192) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1> loc(#loc207)
    %194 = "vhlo.reshape_v1"(%arg19) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc208)
    %195 = "vhlo.custom_call_v1"(%194) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc209)
    %196 = "vhlo.reshape_v1"(%195) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc(#loc210)
    %197 = "vhlo.transpose_v1"(%196) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc(#loc211)
    %198 = "vhlo.dot_general_v2"(%193, %197) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1> loc(#loc212)
    %199 = "vhlo.reshape_v1"(%198) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1> loc(#loc213)
    %200 = "vhlo.convert_v1"(%199) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1> loc(#loc214)
    %201 = "vhlo.logistic_v2"(%199) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1> loc(#loc215)
    %202 = "vhlo.convert_v1"(%201) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1> loc(#loc216)
    %203 = "vhlo.multiply_v1"(%200, %202) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1> loc(#loc217)
    %204 = "vhlo.convert_v1"(%203) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1> loc(#loc218)
    %205 = "vhlo.convert_v1"(%204) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1> loc(#loc219)
    %206 = "vhlo.reshape_v1"(%arg13) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc220)
    %207 = "vhlo.custom_call_v1"(%206) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc221)
    %208 = "vhlo.reshape_v1"(%207) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc(#loc222)
    %209 = "vhlo.transpose_v1"(%208) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc(#loc223)
    %210 = "vhlo.dot_general_v2"(%193, %209) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1> loc(#loc224)
    %211 = "vhlo.reshape_v1"(%210) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1> loc(#loc225)
    %212 = "vhlo.convert_v1"(%211) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1> loc(#loc226)
    %213 = "vhlo.multiply_v1"(%205, %212) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1> loc(#loc227)
    %214 = "vhlo.convert_v1"(%213) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1> loc(#loc228)
    %215 = "vhlo.reshape_v1"(%214) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1> loc(#loc229)
    %216 = "vhlo.reshape_v1"(%arg12) : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1> loc(#loc230)
    %217 = "vhlo.custom_call_v1"(%216) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1> loc(#loc231)
    %218 = "vhlo.reshape_v1"(%217) : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc(#loc232)
    %219 = "vhlo.transpose_v1"(%218) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc(#loc233)
    %220 = "vhlo.dot_general_v2"(%215, %219) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1> loc(#loc234)
    %221 = "vhlo.reshape_v1"(%220) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1> loc(#loc235)
    %222 = "vhlo.add_v1"(%173, %221) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1> loc(#loc236)
    %223 = "vhlo.convert_v1"(%222) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc237)
    %224 = "vhlo.power_v1"(%223, %11) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc238)
    %225 = "vhlo.reduce_v1"(%224, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.414"), %arg22: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.414")):
      %244 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc240)
      "vhlo.return_v1"(%244) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1> loc(#loc239)
    %226 = "vhlo.multiply_v1"(%225, %6) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1> loc(#loc241)
    %227 = "vhlo.reshape_v1"(%226) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1> loc(#loc242)
    %228 = "vhlo.add_v1"(%227, %40) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1> loc(#loc243)
    %229 = "vhlo.rsqrt_v2"(%228) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1> loc(#loc244)
    %230 = "vhlo.reshape_v1"(%229) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1> loc(#loc245)
    %231 = "vhlo.broadcast_in_dim_v1"(%230) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc246)
    %232 = "vhlo.multiply_v1"(%223, %231) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc247)
    %233 = "vhlo.convert_v1"(%232) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1> loc(#loc248)
    %234 = "vhlo.convert_v1"(%233) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc249)
    %235 = "vhlo.multiply_v1"(%104, %234) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1> loc(#loc250)
    %236 = "vhlo.convert_v1"(%235) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1> loc(#loc251)
    %237 = "vhlo.reshape_v1"(%236) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1> loc(#loc252)
    %238 = "vhlo.reshape_v1"(%arg11) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc253)
    %239 = "vhlo.custom_call_v1"(%238) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___lm_head_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc254)
    %240 = "vhlo.reshape_v1"(%239) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc(#loc255)
    %241 = "vhlo.transpose_v1"(%240) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,128256]{0,1}">} : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1> loc(#loc256)
    %242 = "vhlo.dot_general_v2"(%237, %241) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x128256x!vhlo.bf16_v1> loc(#loc257)
    %243 = "vhlo.reshape_v1"(%242) : (!vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1> loc(#loc258)
    "vhlo.return_v1"(%89, %99, %242, %243) : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc22 = loc("custom-call.131")
#loc23 = loc("reshape.4")
#loc24 = loc("custom-call.5")
#loc25 = loc("reshape.6")
#loc26 = loc("compare.126")
#loc27 = loc("broadcast.122")
#loc28 = loc("add.123")
#loc29 = loc("select.127")
#loc30 = loc("reshape.128")
#loc31 = loc("reshape.82")
#loc32 = loc("custom-call.83")
#loc33 = loc("reshape.84")
#loc34 = loc("convert.85")
#loc35 = loc("broadcast.86")
#loc36 = loc("reshape.45")
#loc37 = loc("custom-call.46")
#loc38 = loc("reshape.47")
#loc39 = loc("reshape.40")
#loc40 = loc("custom-call.41")
#loc41 = loc("reshape.43")
#loc42 = loc("convert.48")
#loc43 = loc("gather.49")
#loc44 = loc("reshape.50")
#loc45 = loc("convert.51")
#loc46 = loc("power.53")
#loc48 = loc("add.59")
#loc49 = loc("multiply.69")
#loc50 = loc("reshape.70")
#loc51 = loc("broadcast.73")
#loc52 = loc("add.74")
#loc53 = loc("rsqrt.75")
#loc54 = loc("reshape.76")
#loc55 = loc("broadcast.77")
#loc56 = loc("multiply.78")
#loc57 = loc("convert.79")
#loc58 = loc("convert.80")
#loc59 = loc("multiply.87")
#loc60 = loc("convert.88")
#loc61 = loc("reshape.89")
#loc62 = loc("reshape.32")
#loc63 = loc("custom-call.33")
#loc64 = loc("reshape.34")
#loc65 = loc("transpose.35")
#loc66 = loc("dot.90")
#loc67 = loc("reshape.92")
#loc68 = loc("transpose.93")
#loc69 = loc("convert.110")
#loc70 = loc("reshape.14")
#loc71 = loc("custom-call.15")
#loc72 = loc("reshape.19")
#loc73 = loc("convert.11")
#loc74 = loc("dot.22")
#loc75 = loc("transpose.23")
#loc76 = loc("concatenate.24")
#loc77 = loc("cosine.104")
#loc78 = loc("convert.107")
#loc79 = loc("reshape.108")
#loc80 = loc("convert.109")
#loc81 = loc("reshape.111")
#loc82 = loc("broadcast.112")
#loc83 = loc("multiply.113")
#loc84 = loc("convert.114")
#loc85 = loc("slice.95")
#loc86 = loc("negate.96")
#loc87 = loc("slice.94")
#loc88 = loc("concatenate.97")
#loc89 = loc("convert.98")
#loc90 = loc("sine.25")
#loc91 = loc("convert.28")
#loc92 = loc("reshape.29")
#loc93 = loc("convert.30")
#loc94 = loc("reshape.99")
#loc95 = loc("broadcast.100")
#loc96 = loc("multiply.101")
#loc97 = loc("convert.102")
#loc98 = loc("add.117")
#loc100 = loc("custom-call.138")
#loc101 = loc("custom-call.161")
#loc102 = loc("reshape.140")
#loc103 = loc("custom-call.141")
#loc104 = loc("reshape.142")
#loc105 = loc("transpose.143")
#loc106 = loc("dot.145")
#loc107 = loc("reshape.147")
#loc108 = loc("transpose.148")
#loc110 = loc("custom-call.168")
#loc111 = loc("reshape.436")
#loc112 = loc("custom-call.437")
#loc113 = loc("reshape.438")
#loc114 = loc("convert.439")
#loc115 = loc("broadcast.440")
#loc116 = loc("reshape.270")
#loc117 = loc("custom-call.271")
#loc118 = loc("reshape.272")
#loc119 = loc("transpose.273")
#loc120 = loc("dot.275")
#loc121 = loc("reshape.277")
#loc122 = loc("transpose.278")
#loc123 = loc("convert.289")
#loc124 = loc("broadcast.291")
#loc125 = loc("multiply.292")
#loc126 = loc("convert.293")
#loc127 = loc("slice.280")
#loc128 = loc("negate.281")
#loc129 = loc("slice.279")
#loc130 = loc("concatenate.282")
#loc131 = loc("convert.283")
#loc132 = loc("broadcast.285")
#loc133 = loc("multiply.286")
#loc134 = loc("convert.287")
#loc135 = loc("add.296")
#loc136 = loc("reshape.298")
#loc137 = loc("broadcast.262")
#loc138 = loc("reshape.263")
#loc139 = loc("transpose.264")
#loc140 = loc("reshape.266")
#loc141 = loc("dot.299")
#loc142 = loc("reshape.300")
#loc143 = loc("convert.301")
#loc144 = loc("broadcast.302")
#loc145 = loc("multiply.303")
#loc146 = loc("convert.304")
#loc147 = loc("broadcast.235")
#loc148 = loc("broadcast.237")
#loc149 = loc("subtract.238")
#loc150 = loc("compare.240")
#loc151 = loc("broadcast.224")
#loc152 = loc("select.242")
#loc153 = loc("convert.243")
#loc154 = loc("broadcast.211")
#loc155 = loc("compare.212")
#loc156 = loc("convert.213")
#loc157 = loc("multiply.244")
#loc158 = loc("convert.245")
#loc159 = loc("reshape.246")
#loc160 = loc("broadcast.308")
#loc161 = loc("add.309")
#loc162 = loc("convert.310")
#loc164 = loc("maximum.315")
#loc165 = loc("broadcast.317")
#loc166 = loc("subtract.318")
#loc167 = loc("exponential.319")
#loc169 = loc("add.324")
#loc170 = loc("broadcast.326")
#loc171 = loc("divide.327")
#loc172 = loc("convert.328")
#loc173 = loc("reshape.330")
#loc174 = loc("broadcast.202")
#loc175 = loc("reshape.205")
#loc176 = loc("dot.331")
#loc177 = loc("reshape.332")
#loc178 = loc("transpose.333")
#loc179 = loc("reshape.335")
#loc180 = loc("reshape.191")
#loc181 = loc("custom-call.192")
#loc182 = loc("reshape.193")
#loc183 = loc("transpose.194")
#loc184 = loc("dot.336")
#loc185 = loc("reshape.337")
#loc186 = loc("add.340")
#loc187 = loc("reshape.372")
#loc188 = loc("custom-call.373")
#loc189 = loc("reshape.374")
#loc190 = loc("convert.375")
#loc191 = loc("broadcast.376")
#loc192 = loc("convert.341")
#loc193 = loc("power.343")
#loc195 = loc("add.349")
#loc196 = loc("multiply.359")
#loc197 = loc("reshape.360")
#loc198 = loc("add.364")
#loc199 = loc("rsqrt.365")
#loc200 = loc("reshape.366")
#loc201 = loc("broadcast.367")
#loc202 = loc("multiply.368")
#loc203 = loc("convert.369")
#loc204 = loc("convert.370")
#loc205 = loc("multiply.377")
#loc206 = loc("convert.378")
#loc207 = loc("reshape.388")
#loc208 = loc("reshape.384")
#loc209 = loc("custom-call.385")
#loc210 = loc("reshape.386")
#loc211 = loc("transpose.387")
#loc212 = loc("dot.389")
#loc213 = loc("reshape.390")
#loc214 = loc("convert.393")
#loc215 = loc("logistic.391")
#loc216 = loc("convert.392")
#loc217 = loc("multiply.394")
#loc218 = loc("convert.395")
#loc219 = loc("convert.396")
#loc220 = loc("reshape.183")
#loc221 = loc("custom-call.184")
#loc222 = loc("reshape.185")
#loc223 = loc("transpose.186")
#loc224 = loc("dot.380")
#loc225 = loc("reshape.381")
#loc226 = loc("convert.382")
#loc227 = loc("multiply.397")
#loc228 = loc("convert.398")
#loc229 = loc("reshape.399")
#loc230 = loc("reshape.178")
#loc231 = loc("custom-call.179")
#loc232 = loc("reshape.180")
#loc233 = loc("transpose.181")
#loc234 = loc("dot.400")
#loc235 = loc("reshape.401")
#loc236 = loc("add.404")
#loc237 = loc("convert.405")
#loc238 = loc("power.407")
#loc240 = loc("add.413")
#loc241 = loc("multiply.423")
#loc242 = loc("reshape.424")
#loc243 = loc("add.428")
#loc244 = loc("rsqrt.429")
#loc245 = loc("reshape.430")
#loc246 = loc("broadcast.431")
#loc247 = loc("multiply.432")
#loc248 = loc("convert.433")
#loc249 = loc("convert.434")
#loc250 = loc("multiply.441")
#loc251 = loc("convert.442")
#loc252 = loc("reshape.446")
#loc253 = loc("reshape.170")
#loc254 = loc("custom-call.171")
#loc255 = loc("reshape.172")
#loc256 = loc("transpose.173")
#loc257 = loc("dot.447")
#loc258 = loc("reshape.448")
2025-09-22 18:07:09.680 (   9.365s) [        A88F8000]      module_builder.cc:181      1| SHLO Module:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.31")
#loc4 = loc("p3.37")
#loc5 = loc("p4.39")
#loc6 = loc("p5.44")
#loc7 = loc("p6.81")
#loc8 = loc("p7.118")
#loc9 = loc("p8.130")
#loc10 = loc("p9.139")
#loc11 = loc("p10.160")
#loc12 = loc("p11.169")
#loc13 = loc("p12.177")
#loc14 = loc("p13.182")
#loc15 = loc("p14.190")
#loc16 = loc("p15.220")
#loc17 = loc("p16.254")
#loc18 = loc("p17.269")
#loc19 = loc("p18.371")
#loc20 = loc("p19.383")
#loc21 = loc("p20.435")
#loc98 = loc("scatter.136")
#loc108 = loc("scatter.166")
module @SyncTensorsGraph.450 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<7xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p0.3"), %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p2.31"), %arg3: tensor<f32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"} loc("p3.37"), %arg4: tensor<1x7xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p4.39"), %arg5: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p5.44"), %arg6: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p6.81"), %arg7: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"} loc("p7.118"), %arg8: tensor<1x8x16x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} loc("p8.130"), %arg9: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p9.139"), %arg10: tensor<1x8x16x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} loc("p10.160"), %arg11: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p11.169"), %arg12: tensor<3072x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p12.177"), %arg13: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p13.182"), %arg14: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p14.190"), %arg15: tensor<bf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"} loc("p15.220"), %arg16: tensor<f32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"} loc("p16.254"), %arg17: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p17.269"), %arg18: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p18.371"), %arg19: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p19.383"), %arg20: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p20.435")) -> (tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]> : tensor<16xi64> loc(#loc)
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64> loc(#loc)
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %c_2 = stablehlo.constant dense<0> : tensor<7xi64> loc(#loc)
    %cst_3 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_4 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32> loc(#loc)
    %c_5 = stablehlo.constant dense<1> : tensor<i64> loc(#loc)
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x16xbf16> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x16xi64> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32> loc(#loc)
    %3 = stablehlo.custom_call @tt.mark_argument(%arg8) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_2"}} : (tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc22)
    %4 = stablehlo.reshape %arg0 : (tensor<7xi64>) -> tensor<1x1x7xi64> loc(#loc23)
    %5 = stablehlo.custom_call @tt.mark_argument(%4) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<1x1x7xi64>) -> tensor<1x1x7xi64> loc(#loc24)
    %6 = stablehlo.reshape %5 : (tensor<1x1x7xi64>) -> tensor<7xi64> loc(#loc25)
    %7 = stablehlo.compare  LT, %6, %c_2 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1> loc(#loc26)
    %8 = stablehlo.broadcast_in_dim %arg7, dims = [] : (tensor<i64>) -> tensor<7xi64> loc(#loc27)
    %9 = stablehlo.add %6, %8 : tensor<7xi64> loc(#loc28)
    %10 = stablehlo.select %7, %9, %6 : tensor<7xi1>, tensor<7xi64> loc(#loc29)
    %11 = stablehlo.reshape %10 : (tensor<7xi64>) -> tensor<7x1xi64> loc(#loc30)
    %12 = stablehlo.reshape %arg6 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc31)
    %13 = stablehlo.custom_call @tt.mark_argument(%12) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc32)
    %14 = stablehlo.reshape %13 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc33)
    %15 = stablehlo.convert %14 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc34)
    %16 = stablehlo.broadcast_in_dim %15, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32> loc(#loc35)
    %17 = stablehlo.reshape %arg5 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc36)
    %18 = stablehlo.custom_call @tt.mark_argument(%17) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_embed_tokens_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc37)
    %19 = stablehlo.reshape %18 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc38)
    %20 = stablehlo.reshape %arg4 : (tensor<1x7xi64>) -> tensor<1x1x7xi64> loc(#loc39)
    %21 = stablehlo.custom_call @tt.mark_argument(%20) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x1x7xi64>) -> tensor<1x1x7xi64> loc(#loc40)
    %22 = stablehlo.reshape %21 : (tensor<1x1x7xi64>) -> tensor<7xi64> loc(#loc41)
    %23 = stablehlo.convert %22 : (tensor<7xi64>) -> tensor<7xui32> loc(#loc42)
    %24 = "stablehlo.gather"(%19, %23) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16> loc(#loc43)
    %25 = stablehlo.reshape %24 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc44)
    %26 = stablehlo.convert %25 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc45)
    %27 = stablehlo.power %26, %2 : tensor<1x7x3072xf32> loc(#loc46)
    %28 = stablehlo.reduce(%27 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32> loc(#loc47)
    %29 = stablehlo.multiply %28, %cst_4 : tensor<1x7xf32> loc(#loc48)
    %30 = stablehlo.reshape %29 : (tensor<1x7xf32>) -> tensor<1x7x1xf32> loc(#loc49)
    %31 = stablehlo.broadcast_in_dim %arg3, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32> loc(#loc50)
    %32 = stablehlo.add %30, %31 : tensor<1x7x1xf32> loc(#loc51)
    %33 = stablehlo.rsqrt %32 : tensor<1x7x1xf32> loc(#loc52)
    %34 = stablehlo.reshape %33 : (tensor<1x7x1xf32>) -> tensor<1x7xf32> loc(#loc53)
    %35 = stablehlo.broadcast_in_dim %34, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32> loc(#loc54)
    %36 = stablehlo.multiply %26, %35 : tensor<1x7x3072xf32> loc(#loc55)
    %37 = stablehlo.convert %36 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc56)
    %38 = stablehlo.convert %37 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc57)
    %39 = stablehlo.multiply %16, %38 : tensor<1x7x3072xf32> loc(#loc58)
    %40 = stablehlo.convert %39 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc59)
    %41 = stablehlo.reshape %40 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc60)
    %42 = stablehlo.reshape %arg2 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc61)
    %43 = stablehlo.custom_call @tt.mark_argument(%42) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc62)
    %44 = stablehlo.reshape %43 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc63)
    %45 = stablehlo.transpose %44, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc64)
    %46 = stablehlo.dot_general %41, %45, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16> loc(#loc65)
    %47 = stablehlo.reshape %46 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16> loc(#loc66)
    %48 = stablehlo.transpose %47, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16> loc(#loc67)
    %49 = stablehlo.convert %48 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32> loc(#loc68)
    %50 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc69)
    %51 = stablehlo.custom_call @tt.mark_argument(%50) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "l__self___model_rotary_emb_inv_freq"}} : (tensor<1x1x64xf32>) -> tensor<1x1x64xf32> loc(#loc70)
    %52 = stablehlo.reshape %51 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc71)
    %53 = stablehlo.convert %5 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32> loc(#loc72)
    %54 = stablehlo.dot_general %52, %53, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32> loc(#loc73)
    %55 = stablehlo.transpose %54, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32> loc(#loc74)
    %56 = stablehlo.concatenate %55, %55, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32> loc(#loc75)
    %57 = stablehlo.cosine %56 : tensor<1x7x128xf32> loc(#loc76)
    %58 = stablehlo.convert %57 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16> loc(#loc77)
    %59 = stablehlo.reshape %58 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16> loc(#loc78)
    %60 = stablehlo.convert %59 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32> loc(#loc79)
    %61 = stablehlo.reshape %60 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32> loc(#loc80)
    %62 = stablehlo.broadcast_in_dim %61, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32> loc(#loc81)
    %63 = stablehlo.multiply %49, %62 : tensor<1x8x7x128xf32> loc(#loc82)
    %64 = stablehlo.convert %63 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16> loc(#loc83)
    %65 = stablehlo.slice %48 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16> loc(#loc84)
    %66 = stablehlo.negate %65 : tensor<1x8x7x64xbf16> loc(#loc85)
    %67 = stablehlo.slice %48 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16> loc(#loc86)
    %68 = stablehlo.concatenate %66, %67, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16> loc(#loc87)
    %69 = stablehlo.convert %68 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32> loc(#loc88)
    %70 = stablehlo.sine %56 : tensor<1x7x128xf32> loc(#loc89)
    %71 = stablehlo.convert %70 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16> loc(#loc90)
    %72 = stablehlo.reshape %71 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16> loc(#loc91)
    %73 = stablehlo.convert %72 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32> loc(#loc92)
    %74 = stablehlo.reshape %73 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32> loc(#loc93)
    %75 = stablehlo.broadcast_in_dim %74, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32> loc(#loc94)
    %76 = stablehlo.multiply %69, %75 : tensor<1x8x7x128xf32> loc(#loc95)
    %77 = stablehlo.convert %76 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16> loc(#loc96)
    %78 = stablehlo.add %64, %77 : tensor<1x8x7x128xbf16> loc(#loc97)
    %79 = "stablehlo.scatter"(%3, %11, %78) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16> loc("scatter.136"), %arg22: tensor<bf16> loc("scatter.136")):
      stablehlo.return %arg22 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x16x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc98)
    %80 = stablehlo.custom_call @Sharding(%79) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc99)
    %81 = stablehlo.custom_call @tt.mark_argument(%arg10) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_3"}} : (tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc100)
    %82 = stablehlo.reshape %arg9 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc101)
    %83 = stablehlo.custom_call @tt.mark_argument(%82) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc102)
    %84 = stablehlo.reshape %83 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc103)
    %85 = stablehlo.transpose %84, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc104)
    %86 = stablehlo.dot_general %41, %85, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16> loc(#loc105)
    %87 = stablehlo.reshape %86 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16> loc(#loc106)
    %88 = stablehlo.transpose %87, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16> loc(#loc107)
    %89 = "stablehlo.scatter"(%81, %11, %88) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16> loc("scatter.166"), %arg22: tensor<bf16> loc("scatter.166")):
      stablehlo.return %arg22 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x16x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc108)
    %90 = stablehlo.custom_call @Sharding(%89) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc109)
    %91 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc110)
    %92 = stablehlo.custom_call @tt.mark_argument(%91) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_norm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc111)
    %93 = stablehlo.reshape %92 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc112)
    %94 = stablehlo.convert %93 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc113)
    %95 = stablehlo.broadcast_in_dim %94, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32> loc(#loc114)
    %96 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc115)
    %97 = stablehlo.custom_call @tt.mark_argument(%96) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc116)
    %98 = stablehlo.reshape %97 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc117)
    %99 = stablehlo.transpose %98, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc118)
    %100 = stablehlo.dot_general %41, %99, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc119)
    %101 = stablehlo.reshape %100 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16> loc(#loc120)
    %102 = stablehlo.transpose %101, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16> loc(#loc121)
    %103 = stablehlo.convert %102 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32> loc(#loc122)
    %104 = stablehlo.broadcast_in_dim %61, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32> loc(#loc123)
    %105 = stablehlo.multiply %103, %104 : tensor<1x24x7x128xf32> loc(#loc124)
    %106 = stablehlo.convert %105 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16> loc(#loc125)
    %107 = stablehlo.slice %102 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16> loc(#loc126)
    %108 = stablehlo.negate %107 : tensor<1x24x7x64xbf16> loc(#loc127)
    %109 = stablehlo.slice %102 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16> loc(#loc128)
    %110 = stablehlo.concatenate %108, %109, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16> loc(#loc129)
    %111 = stablehlo.convert %110 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32> loc(#loc130)
    %112 = stablehlo.broadcast_in_dim %74, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32> loc(#loc131)
    %113 = stablehlo.multiply %111, %112 : tensor<1x24x7x128xf32> loc(#loc132)
    %114 = stablehlo.convert %113 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16> loc(#loc133)
    %115 = stablehlo.add %106, %114 : tensor<1x24x7x128xbf16> loc(#loc134)
    %116 = stablehlo.reshape %115 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16> loc(#loc135)
    %117 = stablehlo.broadcast_in_dim %79, dims = [0, 1, 3, 4] : (tensor<1x8x16x128xbf16>) -> tensor<1x8x3x16x128xbf16> loc(#loc136)
    %118 = stablehlo.reshape %117 : (tensor<1x8x3x16x128xbf16>) -> tensor<1x24x16x128xbf16> loc(#loc137)
    %119 = stablehlo.transpose %118, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,16]{2,3,1,0}"} : (tensor<1x24x16x128xbf16>) -> tensor<1x24x128x16xbf16> loc(#loc138)
    %120 = stablehlo.reshape %119 : (tensor<1x24x128x16xbf16>) -> tensor<24x128x16xbf16> loc(#loc139)
    %121 = stablehlo.dot_general %116, %120, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x16xbf16>) -> tensor<24x7x16xbf16> loc(#loc140)
    %122 = stablehlo.reshape %121 : (tensor<24x7x16xbf16>) -> tensor<1x24x7x16xbf16> loc(#loc141)
    %123 = stablehlo.convert %122 : (tensor<1x24x7x16xbf16>) -> tensor<1x24x7x16xf32> loc(#loc142)
    %124 = stablehlo.broadcast_in_dim %arg16, dims = [] : (tensor<f32>) -> tensor<1x24x7x16xf32> loc(#loc143)
    %125 = stablehlo.multiply %123, %124 : tensor<1x24x7x16xf32> loc(#loc144)
    %126 = stablehlo.convert %125 : (tensor<1x24x7x16xf32>) -> tensor<1x24x7x16xbf16> loc(#loc145)
    %127 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<16xi64>) -> tensor<7x16xi64> loc(#loc146)
    %128 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x16xi64> loc(#loc147)
    %129 = stablehlo.subtract %127, %128 : tensor<7x16xi64> loc(#loc148)
    %130 = stablehlo.compare  GE, %129, %1 : (tensor<7x16xi64>, tensor<7x16xi64>) -> tensor<7x16xi1> loc(#loc149)
    %131 = stablehlo.broadcast_in_dim %arg15, dims = [] : (tensor<bf16>) -> tensor<7x16xbf16> loc(#loc150)
    %132 = stablehlo.select %130, %131, %0 : tensor<7x16xi1>, tensor<7x16xbf16> loc(#loc151)
    %133 = stablehlo.convert %132 : (tensor<7x16xbf16>) -> tensor<7x16xf32> loc(#loc152)
    %134 = stablehlo.broadcast_in_dim %6, dims = [0] : (tensor<7xi64>) -> tensor<7x16xi64> loc(#loc153)
    %135 = stablehlo.compare  GT, %127, %134 : (tensor<7x16xi64>, tensor<7x16xi64>) -> tensor<7x16xi1> loc(#loc154)
    %136 = stablehlo.convert %135 : (tensor<7x16xi1>) -> tensor<7x16xf32> loc(#loc155)
    %137 = stablehlo.multiply %133, %136 : tensor<7x16xf32> loc(#loc156)
    %138 = stablehlo.convert %137 : (tensor<7x16xf32>) -> tensor<7x16xbf16> loc(#loc157)
    %139 = stablehlo.reshape %138 : (tensor<7x16xbf16>) -> tensor<1x7x16xbf16> loc(#loc158)
    %140 = stablehlo.broadcast_in_dim %139, dims = [0, 2, 3] : (tensor<1x7x16xbf16>) -> tensor<1x24x7x16xbf16> loc(#loc159)
    %141 = stablehlo.add %126, %140 : tensor<1x24x7x16xbf16> loc(#loc160)
    %142 = stablehlo.convert %141 : (tensor<1x24x7x16xbf16>) -> tensor<1x24x7x16xf32> loc(#loc161)
    %143 = stablehlo.reduce(%142 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x16xf32>, tensor<f32>) -> tensor<1x24x7xf32> loc(#loc162)
    %144 = stablehlo.broadcast_in_dim %143, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x16xf32> loc(#loc163)
    %145 = stablehlo.subtract %142, %144 : tensor<1x24x7x16xf32> loc(#loc164)
    %146 = stablehlo.exponential %145 : tensor<1x24x7x16xf32> loc(#loc165)
    %147 = stablehlo.reduce(%146 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x16xf32>, tensor<f32>) -> tensor<1x24x7xf32> loc(#loc166)
    %148 = stablehlo.broadcast_in_dim %147, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x16xf32> loc(#loc167)
    %149 = stablehlo.divide %146, %148 : tensor<1x24x7x16xf32> loc(#loc168)
    %150 = stablehlo.convert %149 : (tensor<1x24x7x16xf32>) -> tensor<1x24x7x16xbf16> loc(#loc169)
    %151 = stablehlo.reshape %150 : (tensor<1x24x7x16xbf16>) -> tensor<24x7x16xbf16> loc(#loc170)
    %152 = stablehlo.broadcast_in_dim %89, dims = [0, 1, 3, 4] : (tensor<1x8x16x128xbf16>) -> tensor<1x8x3x16x128xbf16> loc(#loc171)
    %153 = stablehlo.reshape %152 : (tensor<1x8x3x16x128xbf16>) -> tensor<24x16x128xbf16> loc(#loc172)
    %154 = stablehlo.dot_general %151, %153, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x16xbf16>, tensor<24x16x128xbf16>) -> tensor<24x7x128xbf16> loc(#loc173)
    %155 = stablehlo.reshape %154 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16> loc(#loc174)
    %156 = stablehlo.transpose %155, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16> loc(#loc175)
    %157 = stablehlo.reshape %156 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16> loc(#loc176)
    %158 = stablehlo.reshape %arg14 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc177)
    %159 = stablehlo.custom_call @tt.mark_argument(%158) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc178)
    %160 = stablehlo.reshape %159 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc179)
    %161 = stablehlo.transpose %160, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc180)
    %162 = stablehlo.dot_general %157, %161, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc181)
    %163 = stablehlo.reshape %162 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc182)
    %164 = stablehlo.add %25, %163 : tensor<1x7x3072xbf16> loc(#loc183)
    %165 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc184)
    %166 = stablehlo.custom_call @tt.mark_argument(%165) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc185)
    %167 = stablehlo.reshape %166 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc186)
    %168 = stablehlo.convert %167 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc187)
    %169 = stablehlo.broadcast_in_dim %168, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32> loc(#loc188)
    %170 = stablehlo.convert %164 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc189)
    %171 = stablehlo.power %170, %2 : tensor<1x7x3072xf32> loc(#loc190)
    %172 = stablehlo.reduce(%171 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32> loc(#loc191)
    %173 = stablehlo.multiply %172, %cst_4 : tensor<1x7xf32> loc(#loc192)
    %174 = stablehlo.reshape %173 : (tensor<1x7xf32>) -> tensor<1x7x1xf32> loc(#loc193)
    %175 = stablehlo.add %174, %31 : tensor<1x7x1xf32> loc(#loc194)
    %176 = stablehlo.rsqrt %175 : tensor<1x7x1xf32> loc(#loc195)
    %177 = stablehlo.reshape %176 : (tensor<1x7x1xf32>) -> tensor<1x7xf32> loc(#loc196)
    %178 = stablehlo.broadcast_in_dim %177, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32> loc(#loc197)
    %179 = stablehlo.multiply %170, %178 : tensor<1x7x3072xf32> loc(#loc198)
    %180 = stablehlo.convert %179 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc199)
    %181 = stablehlo.convert %180 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc200)
    %182 = stablehlo.multiply %169, %181 : tensor<1x7x3072xf32> loc(#loc201)
    %183 = stablehlo.convert %182 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc202)
    %184 = stablehlo.reshape %183 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc203)
    %185 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc204)
    %186 = stablehlo.custom_call @tt.mark_argument(%185) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc205)
    %187 = stablehlo.reshape %186 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc206)
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc207)
    %189 = stablehlo.dot_general %184, %188, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16> loc(#loc208)
    %190 = stablehlo.reshape %189 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16> loc(#loc209)
    %191 = stablehlo.convert %190 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32> loc(#loc210)
    %192 = stablehlo.logistic %190 : tensor<1x7x8192xbf16> loc(#loc211)
    %193 = stablehlo.convert %192 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32> loc(#loc212)
    %194 = stablehlo.multiply %191, %193 : tensor<1x7x8192xf32> loc(#loc213)
    %195 = stablehlo.convert %194 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16> loc(#loc214)
    %196 = stablehlo.convert %195 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32> loc(#loc215)
    %197 = stablehlo.reshape %arg13 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc216)
    %198 = stablehlo.custom_call @tt.mark_argument(%197) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc217)
    %199 = stablehlo.reshape %198 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc218)
    %200 = stablehlo.transpose %199, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc219)
    %201 = stablehlo.dot_general %184, %200, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16> loc(#loc220)
    %202 = stablehlo.reshape %201 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16> loc(#loc221)
    %203 = stablehlo.convert %202 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32> loc(#loc222)
    %204 = stablehlo.multiply %196, %203 : tensor<1x7x8192xf32> loc(#loc223)
    %205 = stablehlo.convert %204 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16> loc(#loc224)
    %206 = stablehlo.reshape %205 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16> loc(#loc225)
    %207 = stablehlo.reshape %arg12 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16> loc(#loc226)
    %208 = stablehlo.custom_call @tt.mark_argument(%207) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}} : (tensor<1x3072x8192xbf16>) -> tensor<1x3072x8192xbf16> loc(#loc227)
    %209 = stablehlo.reshape %208 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16> loc(#loc228)
    %210 = stablehlo.transpose %209, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16> loc(#loc229)
    %211 = stablehlo.dot_general %206, %210, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc230)
    %212 = stablehlo.reshape %211 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc231)
    %213 = stablehlo.add %164, %212 : tensor<1x7x3072xbf16> loc(#loc232)
    %214 = stablehlo.convert %213 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc233)
    %215 = stablehlo.power %214, %2 : tensor<1x7x3072xf32> loc(#loc234)
    %216 = stablehlo.reduce(%215 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32> loc(#loc235)
    %217 = stablehlo.multiply %216, %cst_4 : tensor<1x7xf32> loc(#loc236)
    %218 = stablehlo.reshape %217 : (tensor<1x7xf32>) -> tensor<1x7x1xf32> loc(#loc237)
    %219 = stablehlo.add %218, %31 : tensor<1x7x1xf32> loc(#loc238)
    %220 = stablehlo.rsqrt %219 : tensor<1x7x1xf32> loc(#loc239)
    %221 = stablehlo.reshape %220 : (tensor<1x7x1xf32>) -> tensor<1x7xf32> loc(#loc240)
    %222 = stablehlo.broadcast_in_dim %221, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32> loc(#loc241)
    %223 = stablehlo.multiply %214, %222 : tensor<1x7x3072xf32> loc(#loc242)
    %224 = stablehlo.convert %223 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc243)
    %225 = stablehlo.convert %224 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc244)
    %226 = stablehlo.multiply %95, %225 : tensor<1x7x3072xf32> loc(#loc245)
    %227 = stablehlo.convert %226 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc246)
    %228 = stablehlo.reshape %227 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc247)
    %229 = stablehlo.reshape %arg11 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc248)
    %230 = stablehlo.custom_call @tt.mark_argument(%229) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___lm_head_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc249)
    %231 = stablehlo.reshape %230 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc250)
    %232 = stablehlo.transpose %231, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc251)
    %233 = stablehlo.dot_general %228, %232, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16> loc(#loc252)
    %234 = stablehlo.reshape %233 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16> loc(#loc253)
    return %80, %90, %233, %234 : tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc22 = loc("custom-call.131")
#loc23 = loc("reshape.4")
#loc24 = loc("custom-call.5")
#loc25 = loc("reshape.6")
#loc26 = loc("compare.126")
#loc27 = loc("broadcast.122")
#loc28 = loc("add.123")
#loc29 = loc("select.127")
#loc30 = loc("reshape.128")
#loc31 = loc("reshape.82")
#loc32 = loc("custom-call.83")
#loc33 = loc("reshape.84")
#loc34 = loc("convert.85")
#loc35 = loc("broadcast.86")
#loc36 = loc("reshape.45")
#loc37 = loc("custom-call.46")
#loc38 = loc("reshape.47")
#loc39 = loc("reshape.40")
#loc40 = loc("custom-call.41")
#loc41 = loc("reshape.43")
#loc42 = loc("convert.48")
#loc43 = loc("gather.49")
#loc44 = loc("reshape.50")
#loc45 = loc("convert.51")
#loc46 = loc("power.53")
#loc47 = loc("reduce.60")
#loc48 = loc("multiply.69")
#loc49 = loc("reshape.70")
#loc50 = loc("broadcast.73")
#loc51 = loc("add.74")
#loc52 = loc("rsqrt.75")
#loc53 = loc("reshape.76")
#loc54 = loc("broadcast.77")
#loc55 = loc("multiply.78")
#loc56 = loc("convert.79")
#loc57 = loc("convert.80")
#loc58 = loc("multiply.87")
#loc59 = loc("convert.88")
#loc60 = loc("reshape.89")
#loc61 = loc("reshape.32")
#loc62 = loc("custom-call.33")
#loc63 = loc("reshape.34")
#loc64 = loc("transpose.35")
#loc65 = loc("dot.90")
#loc66 = loc("reshape.92")
#loc67 = loc("transpose.93")
#loc68 = loc("convert.110")
#loc69 = loc("reshape.14")
#loc70 = loc("custom-call.15")
#loc71 = loc("reshape.19")
#loc72 = loc("convert.11")
#loc73 = loc("dot.22")
#loc74 = loc("transpose.23")
#loc75 = loc("concatenate.24")
#loc76 = loc("cosine.104")
#loc77 = loc("convert.107")
#loc78 = loc("reshape.108")
#loc79 = loc("convert.109")
#loc80 = loc("reshape.111")
#loc81 = loc("broadcast.112")
#loc82 = loc("multiply.113")
#loc83 = loc("convert.114")
#loc84 = loc("slice.95")
#loc85 = loc("negate.96")
#loc86 = loc("slice.94")
#loc87 = loc("concatenate.97")
#loc88 = loc("convert.98")
#loc89 = loc("sine.25")
#loc90 = loc("convert.28")
#loc91 = loc("reshape.29")
#loc92 = loc("convert.30")
#loc93 = loc("reshape.99")
#loc94 = loc("broadcast.100")
#loc95 = loc("multiply.101")
#loc96 = loc("convert.102")
#loc97 = loc("add.117")
#loc99 = loc("custom-call.138")
#loc100 = loc("custom-call.161")
#loc101 = loc("reshape.140")
#loc102 = loc("custom-call.141")
#loc103 = loc("reshape.142")
#loc104 = loc("transpose.143")
#loc105 = loc("dot.145")
#loc106 = loc("reshape.147")
#loc107 = loc("transpose.148")
#loc109 = loc("custom-call.168")
#loc110 = loc("reshape.436")
#loc111 = loc("custom-call.437")
#loc112 = loc("reshape.438")
#loc113 = loc("convert.439")
#loc114 = loc("broadcast.440")
#loc115 = loc("reshape.270")
#loc116 = loc("custom-call.271")
#loc117 = loc("reshape.272")
#loc118 = loc("transpose.273")
#loc119 = loc("dot.275")
#loc120 = loc("reshape.277")
#loc121 = loc("transpose.278")
#loc122 = loc("convert.289")
#loc123 = loc("broadcast.291")
#loc124 = loc("multiply.292")
#loc125 = loc("convert.293")
#loc126 = loc("slice.280")
#loc127 = loc("negate.281")
#loc128 = loc("slice.279")
#loc129 = loc("concatenate.282")
#loc130 = loc("convert.283")
#loc131 = loc("broadcast.285")
#loc132 = loc("multiply.286")
#loc133 = loc("convert.287")
#loc134 = loc("add.296")
#loc135 = loc("reshape.298")
#loc136 = loc("broadcast.262")
#loc137 = loc("reshape.263")
#loc138 = loc("transpose.264")
#loc139 = loc("reshape.266")
#loc140 = loc("dot.299")
#loc141 = loc("reshape.300")
#loc142 = loc("convert.301")
#loc143 = loc("broadcast.302")
#loc144 = loc("multiply.303")
#loc145 = loc("convert.304")
#loc146 = loc("broadcast.235")
#loc147 = loc("broadcast.237")
#loc148 = loc("subtract.238")
#loc149 = loc("compare.240")
#loc150 = loc("broadcast.224")
#loc151 = loc("select.242")
#loc152 = loc("convert.243")
#loc153 = loc("broadcast.211")
#loc154 = loc("compare.212")
#loc155 = loc("convert.213")
#loc156 = loc("multiply.244")
#loc157 = loc("convert.245")
#loc158 = loc("reshape.246")
#loc159 = loc("broadcast.308")
#loc160 = loc("add.309")
#loc161 = loc("convert.310")
#loc162 = loc("reduce.316")
#loc163 = loc("broadcast.317")
#loc164 = loc("subtract.318")
#loc165 = loc("exponential.319")
#loc166 = loc("reduce.325")
#loc167 = loc("broadcast.326")
#loc168 = loc("divide.327")
#loc169 = loc("convert.328")
#loc170 = loc("reshape.330")
#loc171 = loc("broadcast.202")
#loc172 = loc("reshape.205")
#loc173 = loc("dot.331")
#loc174 = loc("reshape.332")
#loc175 = loc("transpose.333")
#loc176 = loc("reshape.335")
#loc177 = loc("reshape.191")
#loc178 = loc("custom-call.192")
#loc179 = loc("reshape.193")
#loc180 = loc("transpose.194")
#loc181 = loc("dot.336")
#loc182 = loc("reshape.337")
#loc183 = loc("add.340")
#loc184 = loc("reshape.372")
#loc185 = loc("custom-call.373")
#loc186 = loc("reshape.374")
#loc187 = loc("convert.375")
#loc188 = loc("broadcast.376")
#loc189 = loc("convert.341")
#loc190 = loc("power.343")
#loc191 = loc("reduce.350")
#loc192 = loc("multiply.359")
#loc193 = loc("reshape.360")
#loc194 = loc("add.364")
#loc195 = loc("rsqrt.365")
#loc196 = loc("reshape.366")
#loc197 = loc("broadcast.367")
#loc198 = loc("multiply.368")
#loc199 = loc("convert.369")
#loc200 = loc("convert.370")
#loc201 = loc("multiply.377")
#loc202 = loc("convert.378")
#loc203 = loc("reshape.388")
#loc204 = loc("reshape.384")
#loc205 = loc("custom-call.385")
#loc206 = loc("reshape.386")
#loc207 = loc("transpose.387")
#loc208 = loc("dot.389")
#loc209 = loc("reshape.390")
#loc210 = loc("convert.393")
#loc211 = loc("logistic.391")
#loc212 = loc("convert.392")
#loc213 = loc("multiply.394")
#loc214 = loc("convert.395")
#loc215 = loc("convert.396")
#loc216 = loc("reshape.183")
#loc217 = loc("custom-call.184")
#loc218 = loc("reshape.185")
#loc219 = loc("transpose.186")
#loc220 = loc("dot.380")
#loc221 = loc("reshape.381")
#loc222 = loc("convert.382")
#loc223 = loc("multiply.397")
#loc224 = loc("convert.398")
#loc225 = loc("reshape.399")
#loc226 = loc("reshape.178")
#loc227 = loc("custom-call.179")
#loc228 = loc("reshape.180")
#loc229 = loc("transpose.181")
#loc230 = loc("dot.400")
#loc231 = loc("reshape.401")
#loc232 = loc("add.404")
#loc233 = loc("convert.405")
#loc234 = loc("power.407")
#loc235 = loc("reduce.414")
#loc236 = loc("multiply.423")
#loc237 = loc("reshape.424")
#loc238 = loc("add.428")
#loc239 = loc("rsqrt.429")
#loc240 = loc("reshape.430")
#loc241 = loc("broadcast.431")
#loc242 = loc("multiply.432")
#loc243 = loc("convert.433")
#loc244 = loc("convert.434")
#loc245 = loc("multiply.441")
#loc246 = loc("convert.442")
#loc247 = loc("reshape.446")
#loc248 = loc("reshape.170")
#loc249 = loc("custom-call.171")
#loc250 = loc("reshape.172")
#loc251 = loc("transpose.173")
#loc252 = loc("dot.447")
#loc253 = loc("reshape.448")
2025-09-22 18:07:09.692 (   9.378s) [        A88F8000]      module_builder.cc:190      1| SHLO Module after frontend StableHLO pipeline:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.31")
#loc4 = loc("p3.37")
#loc5 = loc("p4.39")
#loc6 = loc("p5.44")
#loc7 = loc("p6.81")
#loc8 = loc("p7.118")
#loc9 = loc("p8.130")
#loc10 = loc("p9.139")
#loc11 = loc("p10.160")
#loc12 = loc("p11.169")
#loc13 = loc("p12.177")
#loc14 = loc("p13.182")
#loc15 = loc("p14.190")
#loc16 = loc("p15.220")
#loc17 = loc("p16.254")
#loc18 = loc("p17.269")
#loc19 = loc("p18.371")
#loc20 = loc("p19.383")
#loc21 = loc("p20.435")
#loc91 = loc("scatter.136")
#loc99 = loc("scatter.166")
module @SyncTensorsGraph.450 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<7xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.31"), %arg3: tensor<f32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_0"} loc("p3.37"), %arg4: tensor<1x7xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("p4.39"), %arg5: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p5.44"), %arg6: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p6.81"), %arg7: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_1"} loc("p7.118"), %arg8: tensor<1x8x16x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"} loc("p8.130"), %arg9: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p9.139"), %arg10: tensor<1x8x16x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_3"} loc("p10.160"), %arg11: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"} loc("p11.169"), %arg12: tensor<3072x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p12.177"), %arg13: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p13.182"), %arg14: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p14.190"), %arg15: tensor<bf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_2"} loc("p15.220"), %arg16: tensor<f32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_3"} loc("p16.254"), %arg17: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p17.269"), %arg18: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p18.371"), %arg19: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p19.383"), %arg20: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"} loc("p20.435")) -> (tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]> : tensor<16xi64> loc(#loc)
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64> loc(#loc)
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %c_2 = stablehlo.constant dense<0> : tensor<7xi64> loc(#loc)
    %cst_3 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_4 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32> loc(#loc)
    %c_5 = stablehlo.constant dense<1> : tensor<i64> loc(#loc)
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x16xbf16> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x16xi64> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32> loc(#loc)
    %3 = stablehlo.reshape %arg0 : (tensor<7xi64>) -> tensor<1x1x7xi64> loc(#loc22)
    %4 = stablehlo.reshape %3 : (tensor<1x1x7xi64>) -> tensor<7xi64> loc(#loc23)
    %5 = stablehlo.compare  LT, %4, %c_2 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1> loc(#loc24)
    %6 = stablehlo.broadcast_in_dim %arg7, dims = [] : (tensor<i64>) -> tensor<7xi64> loc(#loc25)
    %7 = stablehlo.add %4, %6 : tensor<7xi64> loc(#loc26)
    %8 = stablehlo.select %5, %7, %4 : tensor<7xi1>, tensor<7xi64> loc(#loc27)
    %9 = stablehlo.reshape %8 : (tensor<7xi64>) -> tensor<7x1xi64> loc(#loc28)
    %10 = stablehlo.reshape %arg6 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc29)
    %11 = stablehlo.reshape %10 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc30)
    %12 = stablehlo.convert %11 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc31)
    %13 = stablehlo.broadcast_in_dim %12, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32> loc(#loc32)
    %14 = stablehlo.reshape %arg5 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc33)
    %15 = stablehlo.reshape %14 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc34)
    %16 = stablehlo.reshape %arg4 : (tensor<1x7xi64>) -> tensor<1x1x7xi64> loc(#loc35)
    %17 = stablehlo.reshape %16 : (tensor<1x1x7xi64>) -> tensor<7xi64> loc(#loc36)
    %18 = stablehlo.convert %17 : (tensor<7xi64>) -> tensor<7xui32> loc(#loc37)
    %19 = "stablehlo.gather"(%15, %18) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16> loc(#loc38)
    %20 = stablehlo.reshape %19 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc39)
    %21 = stablehlo.convert %20 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc40)
    %22 = stablehlo.power %21, %2 : tensor<1x7x3072xf32> loc(#loc41)
    %23 = stablehlo.reduce(%22 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32> loc(#loc42)
    %24 = stablehlo.multiply %23, %cst_4 : tensor<1x7xf32> loc(#loc43)
    %25 = stablehlo.reshape %24 : (tensor<1x7xf32>) -> tensor<1x7x1xf32> loc(#loc44)
    %26 = stablehlo.broadcast_in_dim %arg3, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32> loc(#loc45)
    %27 = stablehlo.add %25, %26 : tensor<1x7x1xf32> loc(#loc46)
    %28 = stablehlo.rsqrt %27 : tensor<1x7x1xf32> loc(#loc47)
    %29 = stablehlo.reshape %28 : (tensor<1x7x1xf32>) -> tensor<1x7xf32> loc(#loc48)
    %30 = stablehlo.broadcast_in_dim %29, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32> loc(#loc49)
    %31 = stablehlo.multiply %21, %30 : tensor<1x7x3072xf32> loc(#loc50)
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc51)
    %33 = stablehlo.convert %32 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc52)
    %34 = stablehlo.multiply %13, %33 : tensor<1x7x3072xf32> loc(#loc53)
    %35 = stablehlo.convert %34 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc54)
    %36 = stablehlo.reshape %35 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc55)
    %37 = stablehlo.reshape %arg2 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc56)
    %38 = stablehlo.reshape %37 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc57)
    %39 = stablehlo.transpose %38, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc58)
    %40 = stablehlo.dot_general %36, %39, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16> loc(#loc59)
    %41 = stablehlo.reshape %40 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16> loc(#loc60)
    %42 = stablehlo.transpose %41, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16> loc(#loc61)
    %43 = stablehlo.convert %42 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32> loc(#loc62)
    %44 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc63)
    %45 = stablehlo.reshape %44 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc64)
    %46 = stablehlo.convert %3 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32> loc(#loc65)
    %47 = stablehlo.dot_general %45, %46, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32> loc(#loc66)
    %48 = stablehlo.transpose %47, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32> loc(#loc67)
    %49 = stablehlo.concatenate %48, %48, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32> loc(#loc68)
    %50 = stablehlo.cosine %49 : tensor<1x7x128xf32> loc(#loc69)
    %51 = stablehlo.convert %50 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16> loc(#loc70)
    %52 = stablehlo.reshape %51 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16> loc(#loc71)
    %53 = stablehlo.convert %52 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32> loc(#loc72)
    %54 = stablehlo.reshape %53 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32> loc(#loc73)
    %55 = stablehlo.broadcast_in_dim %54, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32> loc(#loc74)
    %56 = stablehlo.multiply %43, %55 : tensor<1x8x7x128xf32> loc(#loc75)
    %57 = stablehlo.convert %56 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16> loc(#loc76)
    %58 = stablehlo.slice %42 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16> loc(#loc77)
    %59 = stablehlo.negate %58 : tensor<1x8x7x64xbf16> loc(#loc78)
    %60 = stablehlo.slice %42 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16> loc(#loc79)
    %61 = stablehlo.concatenate %59, %60, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16> loc(#loc80)
    %62 = stablehlo.convert %61 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32> loc(#loc81)
    %63 = stablehlo.sine %49 : tensor<1x7x128xf32> loc(#loc82)
    %64 = stablehlo.convert %63 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16> loc(#loc83)
    %65 = stablehlo.reshape %64 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16> loc(#loc84)
    %66 = stablehlo.convert %65 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32> loc(#loc85)
    %67 = stablehlo.reshape %66 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32> loc(#loc86)
    %68 = stablehlo.broadcast_in_dim %67, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32> loc(#loc87)
    %69 = stablehlo.multiply %62, %68 : tensor<1x8x7x128xf32> loc(#loc88)
    %70 = stablehlo.convert %69 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16> loc(#loc89)
    %71 = stablehlo.add %57, %70 : tensor<1x8x7x128xbf16> loc(#loc90)
    %72 = "stablehlo.scatter"(%arg8, %9, %71) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16> loc("scatter.136"), %arg22: tensor<bf16> loc("scatter.136")):
      stablehlo.return %arg22 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x16x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc91)
    %73 = stablehlo.custom_call @Sharding(%72) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc92)
    %74 = stablehlo.reshape %arg9 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc93)
    %75 = stablehlo.reshape %74 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc94)
    %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc95)
    %77 = stablehlo.dot_general %36, %76, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16> loc(#loc96)
    %78 = stablehlo.reshape %77 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16> loc(#loc97)
    %79 = stablehlo.transpose %78, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16> loc(#loc98)
    %80 = "stablehlo.scatter"(%arg10, %9, %79) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16> loc("scatter.166"), %arg22: tensor<bf16> loc("scatter.166")):
      stablehlo.return %arg22 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x16x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc99)
    %81 = stablehlo.custom_call @Sharding(%80) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc100)
    %82 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc101)
    %83 = stablehlo.reshape %82 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc102)
    %84 = stablehlo.convert %83 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc103)
    %85 = stablehlo.broadcast_in_dim %84, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32> loc(#loc104)
    %86 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc105)
    %87 = stablehlo.reshape %86 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc106)
    %88 = stablehlo.transpose %87, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc107)
    %89 = stablehlo.dot_general %36, %88, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc108)
    %90 = stablehlo.reshape %89 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16> loc(#loc109)
    %91 = stablehlo.transpose %90, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16> loc(#loc110)
    %92 = stablehlo.convert %91 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32> loc(#loc111)
    %93 = stablehlo.broadcast_in_dim %54, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32> loc(#loc112)
    %94 = stablehlo.multiply %92, %93 : tensor<1x24x7x128xf32> loc(#loc113)
    %95 = stablehlo.convert %94 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16> loc(#loc114)
    %96 = stablehlo.slice %91 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16> loc(#loc115)
    %97 = stablehlo.negate %96 : tensor<1x24x7x64xbf16> loc(#loc116)
    %98 = stablehlo.slice %91 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16> loc(#loc117)
    %99 = stablehlo.concatenate %97, %98, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16> loc(#loc118)
    %100 = stablehlo.convert %99 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32> loc(#loc119)
    %101 = stablehlo.broadcast_in_dim %67, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32> loc(#loc120)
    %102 = stablehlo.multiply %100, %101 : tensor<1x24x7x128xf32> loc(#loc121)
    %103 = stablehlo.convert %102 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16> loc(#loc122)
    %104 = stablehlo.add %95, %103 : tensor<1x24x7x128xbf16> loc(#loc123)
    %105 = stablehlo.reshape %104 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16> loc(#loc124)
    %106 = stablehlo.broadcast_in_dim %72, dims = [0, 1, 3, 4] : (tensor<1x8x16x128xbf16>) -> tensor<1x8x3x16x128xbf16> loc(#loc125)
    %107 = stablehlo.reshape %106 : (tensor<1x8x3x16x128xbf16>) -> tensor<1x24x16x128xbf16> loc(#loc126)
    %108 = stablehlo.transpose %107, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,16]{2,3,1,0}"} : (tensor<1x24x16x128xbf16>) -> tensor<1x24x128x16xbf16> loc(#loc127)
    %109 = stablehlo.reshape %108 : (tensor<1x24x128x16xbf16>) -> tensor<24x128x16xbf16> loc(#loc128)
    %110 = stablehlo.dot_general %105, %109, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x16xbf16>) -> tensor<24x7x16xbf16> loc(#loc129)
    %111 = stablehlo.reshape %110 : (tensor<24x7x16xbf16>) -> tensor<1x24x7x16xbf16> loc(#loc130)
    %112 = stablehlo.convert %111 : (tensor<1x24x7x16xbf16>) -> tensor<1x24x7x16xf32> loc(#loc131)
    %113 = stablehlo.broadcast_in_dim %arg16, dims = [] : (tensor<f32>) -> tensor<1x24x7x16xf32> loc(#loc132)
    %114 = stablehlo.multiply %112, %113 : tensor<1x24x7x16xf32> loc(#loc133)
    %115 = stablehlo.convert %114 : (tensor<1x24x7x16xf32>) -> tensor<1x24x7x16xbf16> loc(#loc134)
    %116 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<16xi64>) -> tensor<7x16xi64> loc(#loc135)
    %117 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x16xi64> loc(#loc136)
    %118 = stablehlo.subtract %116, %117 : tensor<7x16xi64> loc(#loc137)
    %119 = stablehlo.compare  GE, %118, %1 : (tensor<7x16xi64>, tensor<7x16xi64>) -> tensor<7x16xi1> loc(#loc138)
    %120 = stablehlo.broadcast_in_dim %arg15, dims = [] : (tensor<bf16>) -> tensor<7x16xbf16> loc(#loc139)
    %121 = stablehlo.select %119, %120, %0 : tensor<7x16xi1>, tensor<7x16xbf16> loc(#loc140)
    %122 = stablehlo.convert %121 : (tensor<7x16xbf16>) -> tensor<7x16xf32> loc(#loc141)
    %123 = stablehlo.broadcast_in_dim %4, dims = [0] : (tensor<7xi64>) -> tensor<7x16xi64> loc(#loc142)
    %124 = stablehlo.compare  GT, %116, %123 : (tensor<7x16xi64>, tensor<7x16xi64>) -> tensor<7x16xi1> loc(#loc143)
    %125 = stablehlo.convert %124 : (tensor<7x16xi1>) -> tensor<7x16xf32> loc(#loc144)
    %126 = stablehlo.multiply %122, %125 : tensor<7x16xf32> loc(#loc145)
    %127 = stablehlo.convert %126 : (tensor<7x16xf32>) -> tensor<7x16xbf16> loc(#loc146)
    %128 = stablehlo.reshape %127 : (tensor<7x16xbf16>) -> tensor<1x7x16xbf16> loc(#loc147)
    %129 = stablehlo.broadcast_in_dim %128, dims = [0, 2, 3] : (tensor<1x7x16xbf16>) -> tensor<1x24x7x16xbf16> loc(#loc148)
    %130 = stablehlo.add %115, %129 : tensor<1x24x7x16xbf16> loc(#loc149)
    %131 = stablehlo.convert %130 : (tensor<1x24x7x16xbf16>) -> tensor<1x24x7x16xf32> loc(#loc150)
    %132 = stablehlo.reduce(%131 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x16xf32>, tensor<f32>) -> tensor<1x24x7xf32> loc(#loc151)
    %133 = stablehlo.broadcast_in_dim %132, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x16xf32> loc(#loc152)
    %134 = stablehlo.subtract %131, %133 : tensor<1x24x7x16xf32> loc(#loc153)
    %135 = stablehlo.exponential %134 : tensor<1x24x7x16xf32> loc(#loc154)
    %136 = stablehlo.reduce(%135 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x16xf32>, tensor<f32>) -> tensor<1x24x7xf32> loc(#loc155)
    %137 = stablehlo.broadcast_in_dim %136, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x16xf32> loc(#loc156)
    %138 = stablehlo.divide %135, %137 : tensor<1x24x7x16xf32> loc(#loc157)
    %139 = stablehlo.convert %138 : (tensor<1x24x7x16xf32>) -> tensor<1x24x7x16xbf16> loc(#loc158)
    %140 = stablehlo.reshape %139 : (tensor<1x24x7x16xbf16>) -> tensor<24x7x16xbf16> loc(#loc159)
    %141 = stablehlo.broadcast_in_dim %80, dims = [0, 1, 3, 4] : (tensor<1x8x16x128xbf16>) -> tensor<1x8x3x16x128xbf16> loc(#loc160)
    %142 = stablehlo.reshape %141 : (tensor<1x8x3x16x128xbf16>) -> tensor<24x16x128xbf16> loc(#loc161)
    %143 = stablehlo.dot_general %140, %142, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x16xbf16>, tensor<24x16x128xbf16>) -> tensor<24x7x128xbf16> loc(#loc162)
    %144 = stablehlo.reshape %143 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16> loc(#loc163)
    %145 = stablehlo.transpose %144, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16> loc(#loc164)
    %146 = stablehlo.reshape %145 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16> loc(#loc165)
    %147 = stablehlo.reshape %arg14 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc166)
    %148 = stablehlo.reshape %147 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc167)
    %149 = stablehlo.transpose %148, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc168)
    %150 = stablehlo.dot_general %146, %149, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc169)
    %151 = stablehlo.reshape %150 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc170)
    %152 = stablehlo.add %20, %151 : tensor<1x7x3072xbf16> loc(#loc171)
    %153 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc172)
    %154 = stablehlo.reshape %153 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc173)
    %155 = stablehlo.convert %154 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc174)
    %156 = stablehlo.broadcast_in_dim %155, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32> loc(#loc175)
    %157 = stablehlo.convert %152 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc176)
    %158 = stablehlo.power %157, %2 : tensor<1x7x3072xf32> loc(#loc177)
    %159 = stablehlo.reduce(%158 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32> loc(#loc178)
    %160 = stablehlo.multiply %159, %cst_4 : tensor<1x7xf32> loc(#loc179)
    %161 = stablehlo.reshape %160 : (tensor<1x7xf32>) -> tensor<1x7x1xf32> loc(#loc180)
    %162 = stablehlo.add %161, %26 : tensor<1x7x1xf32> loc(#loc181)
    %163 = stablehlo.rsqrt %162 : tensor<1x7x1xf32> loc(#loc182)
    %164 = stablehlo.reshape %163 : (tensor<1x7x1xf32>) -> tensor<1x7xf32> loc(#loc183)
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32> loc(#loc184)
    %166 = stablehlo.multiply %157, %165 : tensor<1x7x3072xf32> loc(#loc185)
    %167 = stablehlo.convert %166 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc186)
    %168 = stablehlo.convert %167 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc187)
    %169 = stablehlo.multiply %156, %168 : tensor<1x7x3072xf32> loc(#loc188)
    %170 = stablehlo.convert %169 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc189)
    %171 = stablehlo.reshape %170 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc190)
    %172 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc191)
    %173 = stablehlo.reshape %172 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc192)
    %174 = stablehlo.transpose %173, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc193)
    %175 = stablehlo.dot_general %171, %174, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16> loc(#loc194)
    %176 = stablehlo.reshape %175 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16> loc(#loc195)
    %177 = stablehlo.convert %176 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32> loc(#loc196)
    %178 = stablehlo.logistic %176 : tensor<1x7x8192xbf16> loc(#loc197)
    %179 = stablehlo.convert %178 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32> loc(#loc198)
    %180 = stablehlo.multiply %177, %179 : tensor<1x7x8192xf32> loc(#loc199)
    %181 = stablehlo.convert %180 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16> loc(#loc200)
    %182 = stablehlo.convert %181 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32> loc(#loc201)
    %183 = stablehlo.reshape %arg13 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc202)
    %184 = stablehlo.reshape %183 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc203)
    %185 = stablehlo.transpose %184, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc204)
    %186 = stablehlo.dot_general %171, %185, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16> loc(#loc205)
    %187 = stablehlo.reshape %186 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16> loc(#loc206)
    %188 = stablehlo.convert %187 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32> loc(#loc207)
    %189 = stablehlo.multiply %182, %188 : tensor<1x7x8192xf32> loc(#loc208)
    %190 = stablehlo.convert %189 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16> loc(#loc209)
    %191 = stablehlo.reshape %190 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16> loc(#loc210)
    %192 = stablehlo.reshape %arg12 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16> loc(#loc211)
    %193 = stablehlo.reshape %192 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16> loc(#loc212)
    %194 = stablehlo.transpose %193, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16> loc(#loc213)
    %195 = stablehlo.dot_general %191, %194, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc214)
    %196 = stablehlo.reshape %195 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc215)
    %197 = stablehlo.add %152, %196 : tensor<1x7x3072xbf16> loc(#loc216)
    %198 = stablehlo.convert %197 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc217)
    %199 = stablehlo.power %198, %2 : tensor<1x7x3072xf32> loc(#loc218)
    %200 = stablehlo.reduce(%199 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32> loc(#loc219)
    %201 = stablehlo.multiply %200, %cst_4 : tensor<1x7xf32> loc(#loc220)
    %202 = stablehlo.reshape %201 : (tensor<1x7xf32>) -> tensor<1x7x1xf32> loc(#loc221)
    %203 = stablehlo.add %202, %26 : tensor<1x7x1xf32> loc(#loc222)
    %204 = stablehlo.rsqrt %203 : tensor<1x7x1xf32> loc(#loc223)
    %205 = stablehlo.reshape %204 : (tensor<1x7x1xf32>) -> tensor<1x7xf32> loc(#loc224)
    %206 = stablehlo.broadcast_in_dim %205, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32> loc(#loc225)
    %207 = stablehlo.multiply %198, %206 : tensor<1x7x3072xf32> loc(#loc226)
    %208 = stablehlo.convert %207 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc227)
    %209 = stablehlo.convert %208 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc228)
    %210 = stablehlo.multiply %85, %209 : tensor<1x7x3072xf32> loc(#loc229)
    %211 = stablehlo.convert %210 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc230)
    %212 = stablehlo.reshape %211 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc231)
    %213 = stablehlo.reshape %arg11 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc232)
    %214 = stablehlo.reshape %213 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc233)
    %215 = stablehlo.transpose %214, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc234)
    %216 = stablehlo.dot_general %212, %215, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16> loc(#loc235)
    %217 = stablehlo.reshape %216 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16> loc(#loc236)
    return %73, %81, %216, %217 : tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc22 = loc("reshape.4")
#loc23 = loc("reshape.6")
#loc24 = loc("compare.126")
#loc25 = loc("broadcast.122")
#loc26 = loc("add.123")
#loc27 = loc("select.127")
#loc28 = loc("reshape.128")
#loc29 = loc("reshape.82")
#loc30 = loc("reshape.84")
#loc31 = loc("convert.85")
#loc32 = loc("broadcast.86")
#loc33 = loc("reshape.45")
#loc34 = loc("reshape.47")
#loc35 = loc("reshape.40")
#loc36 = loc("reshape.43")
#loc37 = loc("convert.48")
#loc38 = loc("gather.49")
#loc39 = loc("reshape.50")
#loc40 = loc("convert.51")
#loc41 = loc("power.53")
#loc42 = loc("reduce.60")
#loc43 = loc("multiply.69")
#loc44 = loc("reshape.70")
#loc45 = loc("broadcast.73")
#loc46 = loc("add.74")
#loc47 = loc("rsqrt.75")
#loc48 = loc("reshape.76")
#loc49 = loc("broadcast.77")
#loc50 = loc("multiply.78")
#loc51 = loc("convert.79")
#loc52 = loc("convert.80")
#loc53 = loc("multiply.87")
#loc54 = loc("convert.88")
#loc55 = loc("reshape.89")
#loc56 = loc("reshape.32")
#loc57 = loc("reshape.34")
#loc58 = loc("transpose.35")
#loc59 = loc("dot.90")
#loc60 = loc("reshape.92")
#loc61 = loc("transpose.93")
#loc62 = loc("convert.110")
#loc63 = loc("reshape.14")
#loc64 = loc("reshape.19")
#loc65 = loc("convert.11")
#loc66 = loc("dot.22")
#loc67 = loc("transpose.23")
#loc68 = loc("concatenate.24")
#loc69 = loc("cosine.104")
#loc70 = loc("convert.107")
#loc71 = loc("reshape.108")
#loc72 = loc("convert.109")
#loc73 = loc("reshape.111")
#loc74 = loc("broadcast.112")
#loc75 = loc("multiply.113")
#loc76 = loc("convert.114")
#loc77 = loc("slice.95")
#loc78 = loc("negate.96")
#loc79 = loc("slice.94")
#loc80 = loc("concatenate.97")
#loc81 = loc("convert.98")
#loc82 = loc("sine.25")
#loc83 = loc("convert.28")
#loc84 = loc("reshape.29")
#loc85 = loc("convert.30")
#loc86 = loc("reshape.99")
#loc87 = loc("broadcast.100")
#loc88 = loc("multiply.101")
#loc89 = loc("convert.102")
#loc90 = loc("add.117")
#loc92 = loc("custom-call.138")
#loc93 = loc("reshape.140")
#loc94 = loc("reshape.142")
#loc95 = loc("transpose.143")
#loc96 = loc("dot.145")
#loc97 = loc("reshape.147")
#loc98 = loc("transpose.148")
#loc100 = loc("custom-call.168")
#loc101 = loc("reshape.436")
#loc102 = loc("reshape.438")
#loc103 = loc("convert.439")
#loc104 = loc("broadcast.440")
#loc105 = loc("reshape.270")
#loc106 = loc("reshape.272")
#loc107 = loc("transpose.273")
#loc108 = loc("dot.275")
#loc109 = loc("reshape.277")
#loc110 = loc("transpose.278")
#loc111 = loc("convert.289")
#loc112 = loc("broadcast.291")
#loc113 = loc("multiply.292")
#loc114 = loc("convert.293")
#loc115 = loc("slice.280")
#loc116 = loc("negate.281")
#loc117 = loc("slice.279")
#loc118 = loc("concatenate.282")
#loc119 = loc("convert.283")
#loc120 = loc("broadcast.285")
#loc121 = loc("multiply.286")
#loc122 = loc("convert.287")
#loc123 = loc("add.296")
#loc124 = loc("reshape.298")
#loc125 = loc("broadcast.262")
#loc126 = loc("reshape.263")
#loc127 = loc("transpose.264")
#loc128 = loc("reshape.266")
#loc129 = loc("dot.299")
#loc130 = loc("reshape.300")
#loc131 = loc("convert.301")
#loc132 = loc("broadcast.302")
#loc133 = loc("multiply.303")
#loc134 = loc("convert.304")
#loc135 = loc("broadcast.235")
#loc136 = loc("broadcast.237")
#loc137 = loc("subtract.238")
#loc138 = loc("compare.240")
#loc139 = loc("broadcast.224")
#loc140 = loc("select.242")
#loc141 = loc("convert.243")
#loc142 = loc("broadcast.211")
#loc143 = loc("compare.212")
#loc144 = loc("convert.213")
#loc145 = loc("multiply.244")
#loc146 = loc("convert.245")
#loc147 = loc("reshape.246")
#loc148 = loc("broadcast.308")
#loc149 = loc("add.309")
#loc150 = loc("convert.310")
#loc151 = loc("reduce.316")
#loc152 = loc("broadcast.317")
#loc153 = loc("subtract.318")
#loc154 = loc("exponential.319")
#loc155 = loc("reduce.325")
#loc156 = loc("broadcast.326")
#loc157 = loc("divide.327")
#loc158 = loc("convert.328")
#loc159 = loc("reshape.330")
#loc160 = loc("broadcast.202")
#loc161 = loc("reshape.205")
#loc162 = loc("dot.331")
#loc163 = loc("reshape.332")
#loc164 = loc("transpose.333")
#loc165 = loc("reshape.335")
#loc166 = loc("reshape.191")
#loc167 = loc("reshape.193")
#loc168 = loc("transpose.194")
#loc169 = loc("dot.336")
#loc170 = loc("reshape.337")
#loc171 = loc("add.340")
#loc172 = loc("reshape.372")
#loc173 = loc("reshape.374")
#loc174 = loc("convert.375")
#loc175 = loc("broadcast.376")
#loc176 = loc("convert.341")
#loc177 = loc("power.343")
#loc178 = loc("reduce.350")
#loc179 = loc("multiply.359")
#loc180 = loc("reshape.360")
#loc181 = loc("add.364")
#loc182 = loc("rsqrt.365")
#loc183 = loc("reshape.366")
#loc184 = loc("broadcast.367")
#loc185 = loc("multiply.368")
#loc186 = loc("convert.369")
#loc187 = loc("convert.370")
#loc188 = loc("multiply.377")
#loc189 = loc("convert.378")
#loc190 = loc("reshape.388")
#loc191 = loc("reshape.384")
#loc192 = loc("reshape.386")
#loc193 = loc("transpose.387")
#loc194 = loc("dot.389")
#loc195 = loc("reshape.390")
#loc196 = loc("convert.393")
#loc197 = loc("logistic.391")
#loc198 = loc("convert.392")
#loc199 = loc("multiply.394")
#loc200 = loc("convert.395")
#loc201 = loc("convert.396")
#loc202 = loc("reshape.183")
#loc203 = loc("reshape.185")
#loc204 = loc("transpose.186")
#loc205 = loc("dot.380")
#loc206 = loc("reshape.381")
#loc207 = loc("convert.382")
#loc208 = loc("multiply.397")
#loc209 = loc("convert.398")
#loc210 = loc("reshape.399")
#loc211 = loc("reshape.178")
#loc212 = loc("reshape.180")
#loc213 = loc("transpose.181")
#loc214 = loc("dot.400")
#loc215 = loc("reshape.401")
#loc216 = loc("add.404")
#loc217 = loc("convert.405")
#loc218 = loc("power.407")
#loc219 = loc("reduce.414")
#loc220 = loc("multiply.423")
#loc221 = loc("reshape.424")
#loc222 = loc("add.428")
#loc223 = loc("rsqrt.429")
#loc224 = loc("reshape.430")
#loc225 = loc("broadcast.431")
#loc226 = loc("multiply.432")
#loc227 = loc("convert.433")
#loc228 = loc("convert.434")
#loc229 = loc("multiply.441")
#loc230 = loc("convert.442")
#loc231 = loc("reshape.446")
#loc232 = loc("reshape.170")
#loc233 = loc("reshape.172")
#loc234 = loc("transpose.173")
#loc235 = loc("dot.447")
#loc236 = loc("reshape.448")
2025-09-22 18:07:09.731 (   9.417s) [        A88F8000]      module_builder.cc:473      1| SHLO Module after compiler StableHLO pipeline:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.31")
#loc4 = loc("p3.37")
#loc5 = loc("p4.39")
#loc6 = loc("p5.44")
#loc7 = loc("p6.81")
#loc8 = loc("p7.118")
#loc9 = loc("p8.130")
#loc10 = loc("p9.139")
#loc11 = loc("p10.160")
#loc12 = loc("p11.169")
#loc13 = loc("p12.177")
#loc14 = loc("p13.182")
#loc15 = loc("p14.190")
#loc16 = loc("p15.220")
#loc17 = loc("p16.254")
#loc18 = loc("p17.269")
#loc19 = loc("p18.371")
#loc20 = loc("p19.383")
#loc21 = loc("p20.435")
#loc91 = loc("scatter.136")
#loc98 = loc("scatter.166")
#loc167 = loc("dot.336")
#loc212 = loc("dot.400")
module @SyncTensorsGraph.450 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]> loc(#loc)
  func.func @main(%arg0: tensor<7xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.31"), %arg3: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"} loc("p3.37"), %arg4: tensor<1x7xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p4.39"), %arg5: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p5.44"), %arg6: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p6.81"), %arg7: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"} loc("p7.118"), %arg8: tensor<1x8x16x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p8.130"), %arg9: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p9.139"), %arg10: tensor<1x8x16x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p10.160"), %arg11: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"} loc("p11.169"), %arg12: tensor<3072x8192xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p12.177"), %arg13: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p13.182"), %arg14: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p14.190"), %arg15: tensor<bf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"} loc("p15.220"), %arg16: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"} loc("p16.254"), %arg17: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p17.269"), %arg18: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p18.371"), %arg19: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p19.383"), %arg20: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"} loc("p20.435")) -> (tensor<1x8x16x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x16x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:4 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18, %arg19, %arg20) in_shardings=[<@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, []>, <@mesh, []>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg21: tensor<7xi64> loc("p0.3"), %arg22: tensor<64xf32> loc("p1.13"), %arg23: tensor<512x3072xbf16> loc("p2.31"), %arg24: tensor<f32> loc("p3.37"), %arg25: tensor<1x7xi64> loc("p4.39"), %arg26: tensor<128256x3072xbf16> loc("p5.44"), %arg27: tensor<3072xbf16> loc("p6.81"), %arg28: tensor<i64> loc("p7.118"), %arg29: tensor<1x4x16x128xbf16> loc("p8.130"), %arg30: tensor<512x3072xbf16> loc("p9.139"), %arg31: tensor<1x4x16x128xbf16> loc("p10.160"), %arg32: tensor<128256x3072xbf16> loc("p11.169"), %arg33: tensor<3072x4096xbf16> loc("p12.177"), %arg34: tensor<4096x3072xbf16> loc("p13.182"), %arg35: tensor<3072x1536xbf16> loc("p14.190"), %arg36: tensor<bf16> loc("p15.220"), %arg37: tensor<f32> loc("p16.254"), %arg38: tensor<1536x3072xbf16> loc("p17.269"), %arg39: tensor<3072xbf16> loc("p18.371"), %arg40: tensor<4096x3072xbf16> loc("p19.383"), %arg41: tensor<3072xbf16> loc("p20.435")) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
      %c = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]> : tensor<16xi64> loc(#loc)
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64> loc(#loc)
      %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
      %c_2 = stablehlo.constant dense<0> : tensor<7xi64> loc(#loc)
      %cst_3 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
      %cst_4 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32> loc(#loc)
      %c_5 = stablehlo.constant dense<1> : tensor<i64> loc(#loc)
      %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
      %1 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x16xbf16> loc(#loc)
      %2 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x16xi64> loc(#loc)
      %3 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32> loc(#loc)
      %4 = stablehlo.reshape %arg21 : (tensor<7xi64>) -> tensor<1x1x7xi64> loc(#loc22)
      %5 = stablehlo.reshape %4 : (tensor<1x1x7xi64>) -> tensor<7xi64> loc(#loc23)
      %6 = stablehlo.compare  LT, %5, %c_2 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1> loc(#loc24)
      %7 = stablehlo.broadcast_in_dim %arg28, dims = [] : (tensor<i64>) -> tensor<7xi64> loc(#loc25)
      %8 = stablehlo.add %5, %7 : tensor<7xi64> loc(#loc26)
      %9 = stablehlo.select %6, %8, %5 : tensor<7xi1>, tensor<7xi64> loc(#loc27)
      %10 = stablehlo.reshape %9 : (tensor<7xi64>) -> tensor<7x1xi64> loc(#loc28)
      %11 = stablehlo.reshape %arg27 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc29)
      %12 = stablehlo.reshape %11 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc30)
      %13 = stablehlo.convert %12 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc31)
      %14 = stablehlo.broadcast_in_dim %13, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32> loc(#loc32)
      %15 = stablehlo.reshape %arg26 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc33)
      %16 = stablehlo.reshape %15 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc34)
      %17 = stablehlo.reshape %arg25 : (tensor<1x7xi64>) -> tensor<1x1x7xi64> loc(#loc35)
      %18 = stablehlo.reshape %17 : (tensor<1x1x7xi64>) -> tensor<7xi64> loc(#loc36)
      %19 = stablehlo.convert %18 : (tensor<7xi64>) -> tensor<7xui32> loc(#loc37)
      %20 = "stablehlo.gather"(%16, %19) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16> loc(#loc38)
      %21 = stablehlo.reshape %20 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc39)
      %22 = stablehlo.convert %21 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc40)
      %23 = stablehlo.power %22, %3 : tensor<1x7x3072xf32> loc(#loc41)
      %24 = stablehlo.reduce(%23 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32> loc(#loc42)
      %25 = stablehlo.multiply %24, %cst_4 : tensor<1x7xf32> loc(#loc43)
      %26 = stablehlo.reshape %25 : (tensor<1x7xf32>) -> tensor<1x7x1xf32> loc(#loc44)
      %27 = stablehlo.broadcast_in_dim %arg24, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32> loc(#loc45)
      %28 = stablehlo.add %26, %27 : tensor<1x7x1xf32> loc(#loc46)
      %29 = stablehlo.rsqrt %28 : tensor<1x7x1xf32> loc(#loc47)
      %30 = stablehlo.reshape %29 : (tensor<1x7x1xf32>) -> tensor<1x7xf32> loc(#loc48)
      %31 = stablehlo.broadcast_in_dim %30, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32> loc(#loc49)
      %32 = stablehlo.multiply %22, %31 : tensor<1x7x3072xf32> loc(#loc50)
      %33 = stablehlo.convert %32 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc51)
      %34 = stablehlo.convert %33 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc52)
      %35 = stablehlo.multiply %14, %34 : tensor<1x7x3072xf32> loc(#loc53)
      %36 = stablehlo.convert %35 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc54)
      %37 = stablehlo.reshape %36 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc55)
      %38 = stablehlo.reshape %arg23 : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc56)
      %39 = stablehlo.reshape %38 : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc57)
      %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16> loc(#loc58)
      %41 = stablehlo.dot_general %37, %40, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16> loc(#loc59)
      %42 = stablehlo.reshape %41 : (tensor<7x512xbf16>) -> tensor<1x7x4x128xbf16> loc(#loc60)
      %43 = stablehlo.transpose %42, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x4x128xbf16>) -> tensor<1x4x7x128xbf16> loc(#loc61)
      %44 = stablehlo.convert %43 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32> loc(#loc62)
      %45 = stablehlo.reshape %arg22 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc63)
      %46 = stablehlo.reshape %45 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc64)
      %47 = stablehlo.convert %4 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32> loc(#loc65)
      %48 = stablehlo.dot_general %46, %47, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32> loc(#loc66)
      %49 = stablehlo.transpose %48, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32> loc(#loc67)
      %50 = stablehlo.concatenate %49, %49, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32> loc(#loc68)
      %51 = stablehlo.cosine %50 : tensor<1x7x128xf32> loc(#loc69)
      %52 = stablehlo.convert %51 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16> loc(#loc70)
      %53 = stablehlo.reshape %52 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16> loc(#loc71)
      %54 = stablehlo.convert %53 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32> loc(#loc72)
      %55 = stablehlo.reshape %54 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32> loc(#loc73)
      %56 = stablehlo.broadcast_in_dim %55, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x4x7x128xf32> loc(#loc74)
      %57 = stablehlo.multiply %44, %56 : tensor<1x4x7x128xf32> loc(#loc75)
      %58 = stablehlo.convert %57 : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16> loc(#loc76)
      %59 = stablehlo.slice %43 [0:1, 0:4, 0:7, 64:128] : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16> loc(#loc77)
      %60 = stablehlo.negate %59 : tensor<1x4x7x64xbf16> loc(#loc78)
      %61 = stablehlo.slice %43 [0:1, 0:4, 0:7, 0:64] : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16> loc(#loc79)
      %62 = stablehlo.concatenate %60, %61, dim = 3 : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x128xbf16> loc(#loc80)
      %63 = stablehlo.convert %62 : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32> loc(#loc81)
      %64 = stablehlo.sine %50 : tensor<1x7x128xf32> loc(#loc82)
      %65 = stablehlo.convert %64 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16> loc(#loc83)
      %66 = stablehlo.reshape %65 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16> loc(#loc84)
      %67 = stablehlo.convert %66 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32> loc(#loc85)
      %68 = stablehlo.reshape %67 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32> loc(#loc86)
      %69 = stablehlo.broadcast_in_dim %68, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x4x7x128xf32> loc(#loc87)
      %70 = stablehlo.multiply %63, %69 : tensor<1x4x7x128xf32> loc(#loc88)
      %71 = stablehlo.convert %70 : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16> loc(#loc89)
      %72 = stablehlo.add %58, %71 : tensor<1x4x7x128xbf16> loc(#loc90)
      %73 = "stablehlo.scatter"(%arg29, %10, %72) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg42: tensor<bf16> loc("scatter.136"), %arg43: tensor<bf16> loc("scatter.136")):
        stablehlo.return %arg43 : tensor<bf16> loc(#loc)
      }) : (tensor<1x4x16x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>) -> tensor<1x4x16x128xbf16> loc(#loc91)
      %74 = stablehlo.reshape %arg30 : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc92)
      %75 = stablehlo.reshape %74 : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc93)
      %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16> loc(#loc94)
      %77 = stablehlo.dot_general %37, %76, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16> loc(#loc95)
      %78 = stablehlo.reshape %77 : (tensor<7x512xbf16>) -> tensor<1x7x4x128xbf16> loc(#loc96)
      %79 = stablehlo.transpose %78, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x4x128xbf16>) -> tensor<1x4x7x128xbf16> loc(#loc97)
      %80 = "stablehlo.scatter"(%arg31, %10, %79) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg42: tensor<bf16> loc("scatter.166"), %arg43: tensor<bf16> loc("scatter.166")):
        stablehlo.return %arg43 : tensor<bf16> loc(#loc)
      }) : (tensor<1x4x16x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>) -> tensor<1x4x16x128xbf16> loc(#loc98)
      %81 = stablehlo.reshape %arg41 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc99)
      %82 = stablehlo.reshape %81 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc100)
      %83 = stablehlo.convert %82 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc101)
      %84 = stablehlo.broadcast_in_dim %83, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32> loc(#loc102)
      %85 = stablehlo.reshape %arg38 : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16> loc(#loc103)
      %86 = stablehlo.reshape %85 : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc104)
      %87 = stablehlo.transpose %86, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16> loc(#loc105)
      %88 = stablehlo.dot_general %37, %87, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<7x1536xbf16> loc(#loc106)
      %89 = stablehlo.reshape %88 : (tensor<7x1536xbf16>) -> tensor<1x7x12x128xbf16> loc(#loc107)
      %90 = stablehlo.transpose %89, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x12x128xbf16>) -> tensor<1x12x7x128xbf16> loc(#loc108)
      %91 = stablehlo.convert %90 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32> loc(#loc109)
      %92 = stablehlo.broadcast_in_dim %55, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x12x7x128xf32> loc(#loc110)
      %93 = stablehlo.multiply %91, %92 : tensor<1x12x7x128xf32> loc(#loc111)
      %94 = stablehlo.convert %93 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16> loc(#loc112)
      %95 = stablehlo.slice %90 [0:1, 0:12, 0:7, 64:128] : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16> loc(#loc113)
      %96 = stablehlo.negate %95 : tensor<1x12x7x64xbf16> loc(#loc114)
      %97 = stablehlo.slice %90 [0:1, 0:12, 0:7, 0:64] : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16> loc(#loc115)
      %98 = stablehlo.concatenate %96, %97, dim = 3 : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x128xbf16> loc(#loc116)
      %99 = stablehlo.convert %98 : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32> loc(#loc117)
      %100 = stablehlo.broadcast_in_dim %68, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x12x7x128xf32> loc(#loc118)
      %101 = stablehlo.multiply %99, %100 : tensor<1x12x7x128xf32> loc(#loc119)
      %102 = stablehlo.convert %101 : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16> loc(#loc120)
      %103 = stablehlo.add %94, %102 : tensor<1x12x7x128xbf16> loc(#loc121)
      %104 = stablehlo.reshape %103 : (tensor<1x12x7x128xbf16>) -> tensor<12x7x128xbf16> loc(#loc122)
      %105 = stablehlo.broadcast_in_dim %73, dims = [0, 1, 3, 4] : (tensor<1x4x16x128xbf16>) -> tensor<1x4x3x16x128xbf16> loc(#loc123)
      %106 = stablehlo.reshape %105 : (tensor<1x4x3x16x128xbf16>) -> tensor<1x12x16x128xbf16> loc(#loc124)
      %107 = stablehlo.transpose %106, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,16]{2,3,1,0}"} : (tensor<1x12x16x128xbf16>) -> tensor<1x12x128x16xbf16> loc(#loc125)
      %108 = stablehlo.reshape %107 : (tensor<1x12x128x16xbf16>) -> tensor<12x128x16xbf16> loc(#loc126)
      %109 = stablehlo.dot_general %104, %108, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x7x128xbf16>, tensor<12x128x16xbf16>) -> tensor<12x7x16xbf16> loc(#loc127)
      %110 = stablehlo.reshape %109 : (tensor<12x7x16xbf16>) -> tensor<1x12x7x16xbf16> loc(#loc128)
      %111 = stablehlo.convert %110 : (tensor<1x12x7x16xbf16>) -> tensor<1x12x7x16xf32> loc(#loc129)
      %112 = stablehlo.broadcast_in_dim %arg37, dims = [] : (tensor<f32>) -> tensor<1x12x7x16xf32> loc(#loc130)
      %113 = stablehlo.multiply %111, %112 : tensor<1x12x7x16xf32> loc(#loc131)
      %114 = stablehlo.convert %113 : (tensor<1x12x7x16xf32>) -> tensor<1x12x7x16xbf16> loc(#loc132)
      %115 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<16xi64>) -> tensor<7x16xi64> loc(#loc133)
      %116 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x16xi64> loc(#loc134)
      %117 = stablehlo.subtract %115, %116 : tensor<7x16xi64> loc(#loc135)
      %118 = stablehlo.compare  GE, %117, %2 : (tensor<7x16xi64>, tensor<7x16xi64>) -> tensor<7x16xi1> loc(#loc136)
      %119 = stablehlo.broadcast_in_dim %arg36, dims = [] : (tensor<bf16>) -> tensor<7x16xbf16> loc(#loc137)
      %120 = stablehlo.select %118, %119, %1 : tensor<7x16xi1>, tensor<7x16xbf16> loc(#loc138)
      %121 = stablehlo.convert %120 : (tensor<7x16xbf16>) -> tensor<7x16xf32> loc(#loc139)
      %122 = stablehlo.broadcast_in_dim %5, dims = [0] : (tensor<7xi64>) -> tensor<7x16xi64> loc(#loc140)
      %123 = stablehlo.compare  GT, %115, %122 : (tensor<7x16xi64>, tensor<7x16xi64>) -> tensor<7x16xi1> loc(#loc141)
      %124 = stablehlo.convert %123 : (tensor<7x16xi1>) -> tensor<7x16xf32> loc(#loc142)
      %125 = stablehlo.multiply %121, %124 : tensor<7x16xf32> loc(#loc143)
      %126 = stablehlo.convert %125 : (tensor<7x16xf32>) -> tensor<7x16xbf16> loc(#loc144)
      %127 = stablehlo.reshape %126 : (tensor<7x16xbf16>) -> tensor<1x7x16xbf16> loc(#loc145)
      %128 = stablehlo.broadcast_in_dim %127, dims = [0, 2, 3] : (tensor<1x7x16xbf16>) -> tensor<1x12x7x16xbf16> loc(#loc146)
      %129 = stablehlo.add %114, %128 : tensor<1x12x7x16xbf16> loc(#loc147)
      %130 = stablehlo.convert %129 : (tensor<1x12x7x16xbf16>) -> tensor<1x12x7x16xf32> loc(#loc148)
      %131 = stablehlo.reduce(%130 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x7x16xf32>, tensor<f32>) -> tensor<1x12x7xf32> loc(#loc149)
      %132 = stablehlo.broadcast_in_dim %131, dims = [0, 1, 2] : (tensor<1x12x7xf32>) -> tensor<1x12x7x16xf32> loc(#loc150)
      %133 = stablehlo.subtract %130, %132 : tensor<1x12x7x16xf32> loc(#loc151)
      %134 = stablehlo.exponential %133 : tensor<1x12x7x16xf32> loc(#loc152)
      %135 = stablehlo.reduce(%134 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x7x16xf32>, tensor<f32>) -> tensor<1x12x7xf32> loc(#loc153)
      %136 = stablehlo.broadcast_in_dim %135, dims = [0, 1, 2] : (tensor<1x12x7xf32>) -> tensor<1x12x7x16xf32> loc(#loc154)
      %137 = stablehlo.divide %134, %136 : tensor<1x12x7x16xf32> loc(#loc155)
      %138 = stablehlo.convert %137 : (tensor<1x12x7x16xf32>) -> tensor<1x12x7x16xbf16> loc(#loc156)
      %139 = stablehlo.reshape %138 : (tensor<1x12x7x16xbf16>) -> tensor<12x7x16xbf16> loc(#loc157)
      %140 = stablehlo.broadcast_in_dim %80, dims = [0, 1, 3, 4] : (tensor<1x4x16x128xbf16>) -> tensor<1x4x3x16x128xbf16> loc(#loc158)
      %141 = stablehlo.reshape %140 : (tensor<1x4x3x16x128xbf16>) -> tensor<12x16x128xbf16> loc(#loc159)
      %142 = stablehlo.dot_general %139, %141, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x7x16xbf16>, tensor<12x16x128xbf16>) -> tensor<12x7x128xbf16> loc(#loc160)
      %143 = stablehlo.reshape %142 : (tensor<12x7x128xbf16>) -> tensor<1x12x7x128xbf16> loc(#loc161)
      %144 = stablehlo.transpose %143, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x12x7x128xbf16>) -> tensor<1x7x12x128xbf16> loc(#loc162)
      %145 = stablehlo.reshape %144 : (tensor<1x7x12x128xbf16>) -> tensor<7x1536xbf16> loc(#loc163)
      %146 = stablehlo.reshape %arg35 : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16> loc(#loc164)
      %147 = stablehlo.reshape %146 : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16> loc(#loc165)
      %148 = stablehlo.transpose %147, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16> loc(#loc166)
      %149 = stablehlo.dot_general %145, %148, contracting_dims = [1] x [0] : (tensor<7x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc167)
      %150 = "stablehlo.all_reduce"(%149) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg42: tensor<bf16> loc("dot.336"), %arg43: tensor<bf16> loc("dot.336")):
        %219 = stablehlo.add %arg42, %arg43 : tensor<bf16> loc(#loc167)
        stablehlo.return %219 : tensor<bf16> loc(#loc167)
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc167)
      %151 = stablehlo.reshape %150 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc168)
      %152 = stablehlo.add %21, %151 : tensor<1x7x3072xbf16> loc(#loc169)
      %153 = stablehlo.reshape %arg39 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc170)
      %154 = stablehlo.reshape %153 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc171)
      %155 = stablehlo.convert %154 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc172)
      %156 = stablehlo.broadcast_in_dim %155, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32> loc(#loc173)
      %157 = stablehlo.convert %152 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc174)
      %158 = stablehlo.power %157, %3 : tensor<1x7x3072xf32> loc(#loc175)
      %159 = stablehlo.reduce(%158 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32> loc(#loc176)
      %160 = stablehlo.multiply %159, %cst_4 : tensor<1x7xf32> loc(#loc177)
      %161 = stablehlo.reshape %160 : (tensor<1x7xf32>) -> tensor<1x7x1xf32> loc(#loc178)
      %162 = stablehlo.add %161, %27 : tensor<1x7x1xf32> loc(#loc179)
      %163 = stablehlo.rsqrt %162 : tensor<1x7x1xf32> loc(#loc180)
      %164 = stablehlo.reshape %163 : (tensor<1x7x1xf32>) -> tensor<1x7xf32> loc(#loc181)
      %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32> loc(#loc182)
      %166 = stablehlo.multiply %157, %165 : tensor<1x7x3072xf32> loc(#loc183)
      %167 = stablehlo.convert %166 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc184)
      %168 = stablehlo.convert %167 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc185)
      %169 = stablehlo.multiply %156, %168 : tensor<1x7x3072xf32> loc(#loc186)
      %170 = stablehlo.convert %169 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc187)
      %171 = stablehlo.reshape %170 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc188)
      %172 = stablehlo.reshape %arg40 : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc189)
      %173 = stablehlo.reshape %172 : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc190)
      %174 = stablehlo.transpose %173, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16> loc(#loc191)
      %175 = stablehlo.dot_general %171, %174, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16> loc(#loc192)
      %176 = stablehlo.reshape %175 : (tensor<7x4096xbf16>) -> tensor<1x7x4096xbf16> loc(#loc193)
      %177 = stablehlo.convert %176 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32> loc(#loc194)
      %178 = stablehlo.logistic %176 : tensor<1x7x4096xbf16> loc(#loc195)
      %179 = stablehlo.convert %178 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32> loc(#loc196)
      %180 = stablehlo.multiply %177, %179 : tensor<1x7x4096xf32> loc(#loc197)
      %181 = stablehlo.convert %180 : (tensor<1x7x4096xf32>) -> tensor<1x7x4096xbf16> loc(#loc198)
      %182 = stablehlo.convert %181 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32> loc(#loc199)
      %183 = stablehlo.reshape %arg34 : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc200)
      %184 = stablehlo.reshape %183 : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc201)
      %185 = stablehlo.transpose %184, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16> loc(#loc202)
      %186 = stablehlo.dot_general %171, %185, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16> loc(#loc203)
      %187 = stablehlo.reshape %186 : (tensor<7x4096xbf16>) -> tensor<1x7x4096xbf16> loc(#loc204)
      %188 = stablehlo.convert %187 : (tensor<1x7x4096xbf16>) -> tensor<1x7x4096xf32> loc(#loc205)
      %189 = stablehlo.multiply %182, %188 : tensor<1x7x4096xf32> loc(#loc206)
      %190 = stablehlo.convert %189 : (tensor<1x7x4096xf32>) -> tensor<1x7x4096xbf16> loc(#loc207)
      %191 = stablehlo.reshape %190 : (tensor<1x7x4096xbf16>) -> tensor<7x4096xbf16> loc(#loc208)
      %192 = stablehlo.reshape %arg33 : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16> loc(#loc209)
      %193 = stablehlo.reshape %192 : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc210)
      %194 = stablehlo.transpose %193, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16> loc(#loc211)
      %195 = stablehlo.dot_general %191, %194, contracting_dims = [1] x [0] : (tensor<7x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc212)
      %196 = "stablehlo.all_reduce"(%195) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg42: tensor<bf16> loc("dot.400"), %arg43: tensor<bf16> loc("dot.400")):
        %219 = stablehlo.add %arg42, %arg43 : tensor<bf16> loc(#loc212)
        stablehlo.return %219 : tensor<bf16> loc(#loc212)
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc212)
      %197 = stablehlo.reshape %196 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc213)
      %198 = stablehlo.add %152, %197 : tensor<1x7x3072xbf16> loc(#loc214)
      %199 = stablehlo.convert %198 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc215)
      %200 = stablehlo.power %199, %3 : tensor<1x7x3072xf32> loc(#loc216)
      %201 = stablehlo.reduce(%200 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32> loc(#loc217)
      %202 = stablehlo.multiply %201, %cst_4 : tensor<1x7xf32> loc(#loc218)
      %203 = stablehlo.reshape %202 : (tensor<1x7xf32>) -> tensor<1x7x1xf32> loc(#loc219)
      %204 = stablehlo.add %203, %27 : tensor<1x7x1xf32> loc(#loc220)
      %205 = stablehlo.rsqrt %204 : tensor<1x7x1xf32> loc(#loc221)
      %206 = stablehlo.reshape %205 : (tensor<1x7x1xf32>) -> tensor<1x7xf32> loc(#loc222)
      %207 = stablehlo.broadcast_in_dim %206, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32> loc(#loc223)
      %208 = stablehlo.multiply %199, %207 : tensor<1x7x3072xf32> loc(#loc224)
      %209 = stablehlo.convert %208 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc225)
      %210 = stablehlo.convert %209 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32> loc(#loc226)
      %211 = stablehlo.multiply %84, %210 : tensor<1x7x3072xf32> loc(#loc227)
      %212 = stablehlo.convert %211 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16> loc(#loc228)
      %213 = stablehlo.reshape %212 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc229)
      %214 = stablehlo.reshape %arg32 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc230)
      %215 = stablehlo.reshape %214 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc231)
      %216 = stablehlo.transpose %215, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc232)
      %217 = stablehlo.dot_general %213, %216, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16> loc(#loc233)
      %218 = stablehlo.reshape %217 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16> loc(#loc234)
      sdy.return %73, %80, %217, %218 : tensor<1x4x16x128xbf16>, tensor<1x4x16x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16> loc(#loc)
    } : (tensor<7xi64>, tensor<64xf32>, tensor<1024x3072xbf16>, tensor<f32>, tensor<1x7xi64>, tensor<128256x3072xbf16>, tensor<3072xbf16>, tensor<i64>, tensor<1x8x16x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x16x128xbf16>, tensor<128256x3072xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<bf16>, tensor<f32>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>) -> (tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16>) loc(#loc)
    return %0#0, %0#1, %0#2, %0#3 : tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc22 = loc("reshape.4")
#loc23 = loc("reshape.6")
#loc24 = loc("compare.126")
#loc25 = loc("broadcast.122")
#loc26 = loc("add.123")
#loc27 = loc("select.127")
#loc28 = loc("reshape.128")
#loc29 = loc("reshape.82")
#loc30 = loc("reshape.84")
#loc31 = loc("convert.85")
#loc32 = loc("broadcast.86")
#loc33 = loc("reshape.45")
#loc34 = loc("reshape.47")
#loc35 = loc("reshape.40")
#loc36 = loc("reshape.43")
#loc37 = loc("convert.48")
#loc38 = loc("gather.49")
#loc39 = loc("reshape.50")
#loc40 = loc("convert.51")
#loc41 = loc("power.53")
#loc42 = loc("reduce.60")
#loc43 = loc("multiply.69")
#loc44 = loc("reshape.70")
#loc45 = loc("broadcast.73")
#loc46 = loc("add.74")
#loc47 = loc("rsqrt.75")
#loc48 = loc("reshape.76")
#loc49 = loc("broadcast.77")
#loc50 = loc("multiply.78")
#loc51 = loc("convert.79")
#loc52 = loc("convert.80")
#loc53 = loc("multiply.87")
#loc54 = loc("convert.88")
#loc55 = loc("reshape.89")
#loc56 = loc("reshape.32")
#loc57 = loc("reshape.34")
#loc58 = loc("transpose.35")
#loc59 = loc("dot.90")
#loc60 = loc("reshape.92")
#loc61 = loc("transpose.93")
#loc62 = loc("convert.110")
#loc63 = loc("reshape.14")
#loc64 = loc("reshape.19")
#loc65 = loc("convert.11")
#loc66 = loc("dot.22")
#loc67 = loc("transpose.23")
#loc68 = loc("concatenate.24")
#loc69 = loc("cosine.104")
#loc70 = loc("convert.107")
#loc71 = loc("reshape.108")
#loc72 = loc("convert.109")
#loc73 = loc("reshape.111")
#loc74 = loc("broadcast.112")
#loc75 = loc("multiply.113")
#loc76 = loc("convert.114")
#loc77 = loc("slice.95")
#loc78 = loc("negate.96")
#loc79 = loc("slice.94")
#loc80 = loc("concatenate.97")
#loc81 = loc("convert.98")
#loc82 = loc("sine.25")
#loc83 = loc("convert.28")
#loc84 = loc("reshape.29")
#loc85 = loc("convert.30")
#loc86 = loc("reshape.99")
#loc87 = loc("broadcast.100")
#loc88 = loc("multiply.101")
#loc89 = loc("convert.102")
#loc90 = loc("add.117")
#loc92 = loc("reshape.140")
#loc93 = loc("reshape.142")
#loc94 = loc("transpose.143")
#loc95 = loc("dot.145")
#loc96 = loc("reshape.147")
#loc97 = loc("transpose.148")
#loc99 = loc("reshape.436")
#loc100 = loc("reshape.438")
#loc101 = loc("convert.439")
#loc102 = loc("broadcast.440")
#loc103 = loc("reshape.270")
#loc104 = loc("reshape.272")
#loc105 = loc("transpose.273")
#loc106 = loc("dot.275")
#loc107 = loc("reshape.277")
#loc108 = loc("transpose.278")
#loc109 = loc("convert.289")
#loc110 = loc("broadcast.291")
#loc111 = loc("multiply.292")
#loc112 = loc("convert.293")
#loc113 = loc("slice.280")
#loc114 = loc("negate.281")
#loc115 = loc("slice.279")
#loc116 = loc("concatenate.282")
#loc117 = loc("convert.283")
#loc118 = loc("broadcast.285")
#loc119 = loc("multiply.286")
#loc120 = loc("convert.287")
#loc121 = loc("add.296")
#loc122 = loc("reshape.298")
#loc123 = loc("broadcast.262")
#loc124 = loc("reshape.263")
#loc125 = loc("transpose.264")
#loc126 = loc("reshape.266")
#loc127 = loc("dot.299")
#loc128 = loc("reshape.300")
#loc129 = loc("convert.301")
#loc130 = loc("broadcast.302")
#loc131 = loc("multiply.303")
#loc132 = loc("convert.304")
#loc133 = loc("broadcast.235")
#loc134 = loc("broadcast.237")
#loc135 = loc("subtract.238")
#loc136 = loc("compare.240")
#loc137 = loc("broadcast.224")
#loc138 = loc("select.242")
#loc139 = loc("convert.243")
#loc140 = loc("broadcast.211")
#loc141 = loc("compare.212")
#loc142 = loc("convert.213")
#loc143 = loc("multiply.244")
#loc144 = loc("convert.245")
#loc145 = loc("reshape.246")
#loc146 = loc("broadcast.308")
#loc147 = loc("add.309")
#loc148 = loc("convert.310")
#loc149 = loc("reduce.316")
#loc150 = loc("broadcast.317")
#loc151 = loc("subtract.318")
#loc152 = loc("exponential.319")
#loc153 = loc("reduce.325")
#loc154 = loc("broadcast.326")
#loc155 = loc("divide.327")
#loc156 = loc("convert.328")
#loc157 = loc("reshape.330")
#loc158 = loc("broadcast.202")
#loc159 = loc("reshape.205")
#loc160 = loc("dot.331")
#loc161 = loc("reshape.332")
#loc162 = loc("transpose.333")
#loc163 = loc("reshape.335")
#loc164 = loc("reshape.191")
#loc165 = loc("reshape.193")
#loc166 = loc("transpose.194")
#loc168 = loc("reshape.337")
#loc169 = loc("add.340")
#loc170 = loc("reshape.372")
#loc171 = loc("reshape.374")
#loc172 = loc("convert.375")
#loc173 = loc("broadcast.376")
#loc174 = loc("convert.341")
#loc175 = loc("power.343")
#loc176 = loc("reduce.350")
#loc177 = loc("multiply.359")
#loc178 = loc("reshape.360")
#loc179 = loc("add.364")
#loc180 = loc("rsqrt.365")
#loc181 = loc("reshape.366")
#loc182 = loc("broadcast.367")
#loc183 = loc("multiply.368")
#loc184 = loc("convert.369")
#loc185 = loc("convert.370")
#loc186 = loc("multiply.377")
#loc187 = loc("convert.378")
#loc188 = loc("reshape.388")
#loc189 = loc("reshape.384")
#loc190 = loc("reshape.386")
#loc191 = loc("transpose.387")
#loc192 = loc("dot.389")
#loc193 = loc("reshape.390")
#loc194 = loc("convert.393")
#loc195 = loc("logistic.391")
#loc196 = loc("convert.392")
#loc197 = loc("multiply.394")
#loc198 = loc("convert.395")
#loc199 = loc("convert.396")
#loc200 = loc("reshape.183")
#loc201 = loc("reshape.185")
#loc202 = loc("transpose.186")
#loc203 = loc("dot.380")
#loc204 = loc("reshape.381")
#loc205 = loc("convert.382")
#loc206 = loc("multiply.397")
#loc207 = loc("convert.398")
#loc208 = loc("reshape.399")
#loc209 = loc("reshape.178")
#loc210 = loc("reshape.180")
#loc211 = loc("transpose.181")
#loc213 = loc("reshape.401")
#loc214 = loc("add.404")
#loc215 = loc("convert.405")
#loc216 = loc("power.407")
#loc217 = loc("reduce.414")
#loc218 = loc("multiply.423")
#loc219 = loc("reshape.424")
#loc220 = loc("add.428")
#loc221 = loc("rsqrt.429")
#loc222 = loc("reshape.430")
#loc223 = loc("broadcast.431")
#loc224 = loc("multiply.432")
#loc225 = loc("convert.433")
#loc226 = loc("convert.434")
#loc227 = loc("multiply.441")
#loc228 = loc("convert.442")
#loc229 = loc("reshape.446")
#loc230 = loc("reshape.170")
#loc231 = loc("reshape.172")
#loc232 = loc("transpose.173")
#loc233 = loc("dot.447")
#loc234 = loc("reshape.448")
2025-09-22 18:07:09.749 (   9.434s) [        A88F8000]      module_builder.cc:499      1| TTIR Module:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.31")
#loc4 = loc("p3.37")
#loc5 = loc("p4.39")
#loc6 = loc("p5.44")
#loc7 = loc("p6.81")
#loc8 = loc("p7.118")
#loc9 = loc("p8.130")
#loc10 = loc("p9.139")
#loc11 = loc("p10.160")
#loc12 = loc("p11.169")
#loc13 = loc("p12.177")
#loc14 = loc("p13.182")
#loc15 = loc("p14.190")
#loc16 = loc("p15.220")
#loc17 = loc("p16.254")
#loc18 = loc("p17.269")
#loc19 = loc("p18.371")
#loc20 = loc("p19.383")
#loc21 = loc("p20.435")
module @SyncTensorsGraph.450 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<7xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.31"), %arg3: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"} loc("p3.37"), %arg4: tensor<1x7xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p4.39"), %arg5: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p5.44"), %arg6: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p6.81"), %arg7: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"} loc("p7.118"), %arg8: tensor<1x8x16x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p8.130"), %arg9: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p9.139"), %arg10: tensor<1x8x16x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p10.160"), %arg11: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"} loc("p11.169"), %arg12: tensor<3072x8192xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p12.177"), %arg13: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p13.182"), %arg14: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p14.190"), %arg15: tensor<bf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"} loc("p15.220"), %arg16: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"} loc("p16.254"), %arg17: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p17.269"), %arg18: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p18.371"), %arg19: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p19.383"), %arg20: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"} loc("p20.435")) -> (tensor<1x8x16x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x16x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = ttir.empty() : tensor<7xi64> loc(#loc)
    %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi64> loc(#loc)
    %2 = ttir.empty() : tensor<64xf32> loc(#loc)
    %3 = "ttir.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xf32> loc(#loc)
    %4 = ttir.empty() : tensor<512x3072xbf16> loc(#loc)
    %5 = "ttir.mesh_shard"(%arg2, %4) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc)
    %6 = ttir.empty() : tensor<f32> loc(#loc)
    %7 = "ttir.mesh_shard"(%arg3, %6) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32>, tensor<f32>) -> tensor<f32> loc(#loc)
    %8 = ttir.empty() : tensor<1x7xi64> loc(#loc)
    %9 = "ttir.mesh_shard"(%arg4, %8) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x7xi64>, tensor<1x7xi64>) -> tensor<1x7xi64> loc(#loc)
    %10 = ttir.empty() : tensor<128256x3072xbf16> loc(#loc)
    %11 = "ttir.mesh_shard"(%arg5, %10) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16>, tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc)
    %12 = ttir.empty() : tensor<3072xbf16> loc(#loc)
    %13 = "ttir.mesh_shard"(%arg6, %12) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc)
    %14 = ttir.empty() : tensor<i64> loc(#loc)
    %15 = "ttir.mesh_shard"(%arg7, %14) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<i64>, tensor<i64>) -> tensor<i64> loc(#loc)
    %16 = ttir.empty() : tensor<1x4x16x128xbf16> loc(#loc)
    %17 = "ttir.mesh_shard"(%arg8, %16) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x16x128xbf16>, tensor<1x4x16x128xbf16>) -> tensor<1x4x16x128xbf16> loc(#loc)
    %18 = ttir.empty() : tensor<512x3072xbf16> loc(#loc)
    %19 = "ttir.mesh_shard"(%arg9, %18) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc)
    %20 = ttir.empty() : tensor<1x4x16x128xbf16> loc(#loc)
    %21 = "ttir.mesh_shard"(%arg10, %20) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x16x128xbf16>, tensor<1x4x16x128xbf16>) -> tensor<1x4x16x128xbf16> loc(#loc)
    %22 = ttir.empty() : tensor<128256x3072xbf16> loc(#loc)
    %23 = "ttir.mesh_shard"(%arg11, %22) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16>, tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc)
    %24 = ttir.empty() : tensor<3072x4096xbf16> loc(#loc)
    %25 = "ttir.mesh_shard"(%arg12, %24) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc)
    %26 = ttir.empty() : tensor<4096x3072xbf16> loc(#loc)
    %27 = "ttir.mesh_shard"(%arg13, %26) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc)
    %28 = ttir.empty() : tensor<3072x1536xbf16> loc(#loc)
    %29 = "ttir.mesh_shard"(%arg14, %28) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16> loc(#loc)
    %30 = ttir.empty() : tensor<bf16> loc(#loc)
    %31 = "ttir.mesh_shard"(%arg15, %30) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<bf16>, tensor<bf16>) -> tensor<bf16> loc(#loc)
    %32 = ttir.empty() : tensor<f32> loc(#loc)
    %33 = "ttir.mesh_shard"(%arg16, %32) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32>, tensor<f32>) -> tensor<f32> loc(#loc)
    %34 = ttir.empty() : tensor<1536x3072xbf16> loc(#loc)
    %35 = "ttir.mesh_shard"(%arg17, %34) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc)
    %36 = ttir.empty() : tensor<3072xbf16> loc(#loc)
    %37 = "ttir.mesh_shard"(%arg18, %36) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc)
    %38 = ttir.empty() : tensor<4096x3072xbf16> loc(#loc)
    %39 = "ttir.mesh_shard"(%arg19, %38) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc)
    %40 = ttir.empty() : tensor<3072xbf16> loc(#loc)
    %41 = "ttir.mesh_shard"(%arg20, %40) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc)
    %42 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
    %43 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]> : tensor<16xi64>}> : () -> tensor<16xi64> loc(#loc)
    %44 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>}> : () -> tensor<7xi64> loc(#loc)
    %45 = "ttir.constant"() <{value = dense<0xFF800000> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
    %46 = "ttir.constant"() <{value = dense<0> : tensor<7xi64>}> : () -> tensor<7xi64> loc(#loc)
    %47 = "ttir.constant"() <{value = dense<2.000000e+00> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
    %48 = "ttir.constant"() <{value = dense<3.25520843E-4> : tensor<1x7xf32>}> : () -> tensor<1x7xf32> loc(#loc)
    %49 = "ttir.constant"() <{value = dense<1> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
    %50 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<bf16>}> : () -> tensor<bf16> loc(#loc)
    %51 = ttir.empty() : tensor<1x1xbf16> loc(#loc)
    %52 = "ttir.reshape"(%50, %51) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16> loc(#loc)
    %53 = ttir.empty() : tensor<7x16xbf16> loc(#loc)
    %54 = "ttir.broadcast"(%52, %53) <{broadcast_dimensions = array<i64: 7, 16>}> : (tensor<1x1xbf16>, tensor<7x16xbf16>) -> tensor<7x16xbf16> loc(#loc)
    %55 = ttir.empty() : tensor<1x1xi64> loc(#loc)
    %56 = "ttir.reshape"(%49, %55) <{shape = [1 : i32, 1 : i32]}> : (tensor<i64>, tensor<1x1xi64>) -> tensor<1x1xi64> loc(#loc)
    %57 = ttir.empty() : tensor<7x16xi64> loc(#loc)
    %58 = "ttir.broadcast"(%56, %57) <{broadcast_dimensions = array<i64: 7, 16>}> : (tensor<1x1xi64>, tensor<7x16xi64>) -> tensor<7x16xi64> loc(#loc)
    %59 = ttir.empty() : tensor<1x1x1xf32> loc(#loc)
    %60 = "ttir.reshape"(%47, %59) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc)
    %61 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc)
    %62 = "ttir.broadcast"(%60, %61) <{broadcast_dimensions = array<i64: 1, 7, 3072>}> : (tensor<1x1x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc)
    %63 = ttir.empty() : tensor<1x1x7xi64> loc(#loc22)
    %64 = "ttir.reshape"(%1, %63) <{shape = [1 : i32, 1 : i32, 7 : i32]}> : (tensor<7xi64>, tensor<1x1x7xi64>) -> tensor<1x1x7xi64> loc(#loc22)
    %65 = ttir.empty() : tensor<7xi64> loc(#loc23)
    %66 = "ttir.reshape"(%64, %65) <{shape = [7 : i32]}> : (tensor<1x1x7xi64>, tensor<7xi64>) -> tensor<7xi64> loc(#loc23)
    %67 = ttir.empty() : tensor<7xi1> loc(#loc24)
    %68 = "ttir.lt"(%66, %46, %67) : (tensor<7xi64>, tensor<7xi64>, tensor<7xi1>) -> tensor<7xi1> loc(#loc24)
    %69 = ttir.empty() : tensor<1xi64> loc(#loc25)
    %70 = "ttir.reshape"(%15, %69) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64> loc(#loc25)
    %71 = ttir.empty() : tensor<7xi64> loc(#loc25)
    %72 = "ttir.broadcast"(%70, %71) <{broadcast_dimensions = array<i64: 7>}> : (tensor<1xi64>, tensor<7xi64>) -> tensor<7xi64> loc(#loc25)
    %73 = ttir.empty() : tensor<7xi64> loc(#loc26)
    %74 = "ttir.add"(%66, %72, %73) : (tensor<7xi64>, tensor<7xi64>, tensor<7xi64>) -> tensor<7xi64> loc(#loc26)
    %75 = ttir.empty() : tensor<7xi64> loc(#loc27)
    %76 = "ttir.where"(%68, %74, %66, %75) : (tensor<7xi1>, tensor<7xi64>, tensor<7xi64>, tensor<7xi64>) -> tensor<7xi64> loc(#loc27)
    %77 = ttir.empty() : tensor<7x1xi64> loc(#loc28)
    %78 = "ttir.reshape"(%76, %77) <{shape = [7 : i32, 1 : i32]}> : (tensor<7xi64>, tensor<7x1xi64>) -> tensor<7x1xi64> loc(#loc28)
    %79 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc29)
    %80 = "ttir.reshape"(%13, %79) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc29)
    %81 = ttir.empty() : tensor<3072xbf16> loc(#loc30)
    %82 = "ttir.reshape"(%80, %81) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc30)
    %83 = ttir.empty() : tensor<3072xf32> loc(#loc31)
    %84 = "ttir.typecast"(%82, %83) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32> loc(#loc31)
    %85 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc32)
    %86 = "ttir.reshape"(%84, %85) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc32)
    %87 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc32)
    %88 = "ttir.broadcast"(%86, %87) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc32)
    %89 = ttir.empty() : tensor<1x128256x3072xbf16> loc(#loc33)
    %90 = "ttir.reshape"(%11, %89) <{shape = [1 : i32, 128256 : i32, 3072 : i32]}> : (tensor<128256x3072xbf16>, tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc33)
    %91 = ttir.empty() : tensor<128256x3072xbf16> loc(#loc34)
    %92 = "ttir.reshape"(%90, %91) <{shape = [128256 : i32, 3072 : i32]}> : (tensor<1x128256x3072xbf16>, tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc34)
    %93 = ttir.empty() : tensor<1x1x7xi64> loc(#loc35)
    %94 = "ttir.reshape"(%9, %93) <{shape = [1 : i32, 1 : i32, 7 : i32]}> : (tensor<1x7xi64>, tensor<1x1x7xi64>) -> tensor<1x1x7xi64> loc(#loc35)
    %95 = ttir.empty() : tensor<7xi64> loc(#loc36)
    %96 = "ttir.reshape"(%94, %95) <{shape = [7 : i32]}> : (tensor<1x1x7xi64>, tensor<7xi64>) -> tensor<7xi64> loc(#loc36)
    %97 = ttir.empty() : tensor<7xui32> loc(#loc37)
    %98 = "ttir.typecast"(%96, %97) <{conservative_folding = false}> : (tensor<7xi64>, tensor<7xui32>) -> tensor<7xui32> loc(#loc37)
    %99 = ttir.empty() : tensor<7x3072xbf16> loc(#loc38)
    %100 = "ttir.gather"(%92, %98, %99) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3072>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<128256x3072xbf16>, tensor<7xui32>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc38)
    %101 = ttir.empty() : tensor<1x7x3072xbf16> loc(#loc39)
    %102 = "ttir.reshape"(%100, %101) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc39)
    %103 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc40)
    %104 = "ttir.typecast"(%102, %103) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc40)
    %105 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc41)
    %106 = "ttir.pow"(%104, %62, %105) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc41)
    %107 = ttir.empty() : tensor<1x7xf32> loc(#loc42)
    %108 = "ttir.sum"(%106, %107) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32> loc(#loc42)
    %109 = ttir.empty() : tensor<1x7xf32> loc(#loc43)
    %110 = "ttir.multiply"(%108, %48, %109) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32> loc(#loc43)
    %111 = ttir.empty() : tensor<1x7x1xf32> loc(#loc44)
    %112 = "ttir.reshape"(%110, %111) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32> loc(#loc44)
    %113 = ttir.empty() : tensor<1x1x1xf32> loc(#loc45)
    %114 = "ttir.reshape"(%7, %113) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc45)
    %115 = ttir.empty() : tensor<1x7x1xf32> loc(#loc45)
    %116 = "ttir.broadcast"(%114, %115) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32> loc(#loc45)
    %117 = ttir.empty() : tensor<1x7x1xf32> loc(#loc46)
    %118 = "ttir.add"(%112, %116, %117) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32> loc(#loc46)
    %119 = ttir.empty() : tensor<1x7x1xf32> loc(#loc47)
    %120 = "ttir.rsqrt"(%118, %119) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32> loc(#loc47)
    %121 = ttir.empty() : tensor<1x7xf32> loc(#loc48)
    %122 = "ttir.reshape"(%120, %121) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32> loc(#loc48)
    %123 = ttir.empty() : tensor<1x7x1xf32> loc(#loc49)
    %124 = "ttir.reshape"(%122, %123) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32> loc(#loc49)
    %125 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc49)
    %126 = "ttir.broadcast"(%124, %125) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc49)
    %127 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc50)
    %128 = "ttir.multiply"(%104, %126, %127) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc50)
    %129 = ttir.empty() : tensor<1x7x3072xbf16> loc(#loc51)
    %130 = "ttir.typecast"(%128, %129) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc51)
    %131 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc52)
    %132 = "ttir.typecast"(%130, %131) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc52)
    %133 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc53)
    %134 = "ttir.multiply"(%88, %132, %133) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc53)
    %135 = ttir.empty() : tensor<1x7x3072xbf16> loc(#loc54)
    %136 = "ttir.typecast"(%134, %135) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc54)
    %137 = ttir.empty() : tensor<7x3072xbf16> loc(#loc55)
    %138 = "ttir.reshape"(%136, %137) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc55)
    %139 = ttir.empty() : tensor<1x512x3072xbf16> loc(#loc56)
    %140 = "ttir.reshape"(%5, %139) <{shape = [1 : i32, 512 : i32, 3072 : i32]}> : (tensor<512x3072xbf16>, tensor<1x512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc56)
    %141 = ttir.empty() : tensor<512x3072xbf16> loc(#loc57)
    %142 = "ttir.reshape"(%140, %141) <{shape = [512 : i32, 3072 : i32]}> : (tensor<1x512x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc57)
    %143 = ttir.empty() : tensor<3072x512xbf16> loc(#loc58)
    %144 = "ttir.permute"(%142, %143) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16> loc(#loc58)
    %145 = "ttir.dot_general"(%138, %144) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16> loc(#loc59)
    %146 = ttir.empty() : tensor<1x7x4x128xbf16> loc(#loc60)
    %147 = "ttir.reshape"(%145, %146) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16>, tensor<1x7x4x128xbf16>) -> tensor<1x7x4x128xbf16> loc(#loc60)
    %148 = ttir.empty() : tensor<1x4x7x128xbf16> loc(#loc61)
    %149 = "ttir.permute"(%147, %148) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16> loc(#loc61)
    %150 = ttir.empty() : tensor<1x4x7x128xf32> loc(#loc62)
    %151 = "ttir.typecast"(%149, %150) <{conservative_folding = false}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32> loc(#loc62)
    %152 = ttir.empty() : tensor<1x1x64xf32> loc(#loc63)
    %153 = "ttir.reshape"(%3, %152) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x64xf32> loc(#loc63)
    %154 = ttir.empty() : tensor<1x64x1xf32> loc(#loc64)
    %155 = "ttir.reshape"(%153, %154) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<1x1x64xf32>, tensor<1x64x1xf32>) -> tensor<1x64x1xf32> loc(#loc64)
    %156 = ttir.empty() : tensor<1x1x7xf32> loc(#loc65)
    %157 = "ttir.typecast"(%64, %156) <{conservative_folding = false}> : (tensor<1x1x7xi64>, tensor<1x1x7xf32>) -> tensor<1x1x7xf32> loc(#loc65)
    %158 = "ttir.dot_general"(%155, %157) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32> loc(#loc66)
    %159 = ttir.empty() : tensor<1x7x64xf32> loc(#loc67)
    %160 = "ttir.permute"(%158, %159) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x7xf32>, tensor<1x7x64xf32>) -> tensor<1x7x64xf32> loc(#loc67)
    %161 = ttir.empty() : tensor<1x7x128xf32> loc(#loc68)
    %162 = "ttir.concat"(%160, %160, %161) <{dim = 2 : si32}> : (tensor<1x7x64xf32>, tensor<1x7x64xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32> loc(#loc68)
    %163 = ttir.empty() : tensor<1x7x128xf32> loc(#loc69)
    %164 = "ttir.cos"(%162, %163) : (tensor<1x7x128xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32> loc(#loc69)
    %165 = ttir.empty() : tensor<1x7x128xbf16> loc(#loc70)
    %166 = "ttir.typecast"(%164, %165) <{conservative_folding = false}> : (tensor<1x7x128xf32>, tensor<1x7x128xbf16>) -> tensor<1x7x128xbf16> loc(#loc70)
    %167 = ttir.empty() : tensor<1x1x7x128xbf16> loc(#loc71)
    %168 = "ttir.reshape"(%166, %167) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xbf16>, tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xbf16> loc(#loc71)
    %169 = ttir.empty() : tensor<1x1x7x128xf32> loc(#loc72)
    %170 = "ttir.typecast"(%168, %169) <{conservative_folding = false}> : (tensor<1x1x7x128xbf16>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32> loc(#loc72)
    %171 = ttir.empty() : tensor<1x7x128xf32> loc(#loc73)
    %172 = "ttir.reshape"(%170, %171) <{shape = [1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x1x7x128xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32> loc(#loc73)
    %173 = ttir.empty() : tensor<1x1x7x128xf32> loc(#loc74)
    %174 = "ttir.reshape"(%172, %173) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32> loc(#loc74)
    %175 = ttir.empty() : tensor<1x4x7x128xf32> loc(#loc74)
    %176 = "ttir.broadcast"(%174, %175) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32> loc(#loc74)
    %177 = ttir.empty() : tensor<1x4x7x128xf32> loc(#loc75)
    %178 = "ttir.multiply"(%151, %176, %177) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32> loc(#loc75)
    %179 = ttir.empty() : tensor<1x4x7x128xbf16> loc(#loc76)
    %180 = "ttir.typecast"(%178, %179) <{conservative_folding = false}> : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16> loc(#loc76)
    %181 = ttir.empty() : tensor<1x4x7x64xbf16> loc(#loc77)
    %182 = "ttir.slice_static"(%149, %181) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16> loc(#loc77)
    %183 = ttir.empty() : tensor<1x4x7x64xbf16> loc(#loc78)
    %184 = "ttir.neg"(%182, %183) : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16> loc(#loc78)
    %185 = ttir.empty() : tensor<1x4x7x64xbf16> loc(#loc79)
    %186 = "ttir.slice_static"(%149, %185) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16> loc(#loc79)
    %187 = ttir.empty() : tensor<1x4x7x128xbf16> loc(#loc80)
    %188 = "ttir.concat"(%184, %186, %187) <{dim = 3 : si32}> : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16> loc(#loc80)
    %189 = ttir.empty() : tensor<1x4x7x128xf32> loc(#loc81)
    %190 = "ttir.typecast"(%188, %189) <{conservative_folding = false}> : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32> loc(#loc81)
    %191 = ttir.empty() : tensor<1x7x128xf32> loc(#loc82)
    %192 = "ttir.sin"(%162, %191) : (tensor<1x7x128xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32> loc(#loc82)
    %193 = ttir.empty() : tensor<1x7x128xbf16> loc(#loc83)
    %194 = "ttir.typecast"(%192, %193) <{conservative_folding = false}> : (tensor<1x7x128xf32>, tensor<1x7x128xbf16>) -> tensor<1x7x128xbf16> loc(#loc83)
    %195 = ttir.empty() : tensor<1x1x7x128xbf16> loc(#loc84)
    %196 = "ttir.reshape"(%194, %195) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xbf16>, tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xbf16> loc(#loc84)
    %197 = ttir.empty() : tensor<1x1x7x128xf32> loc(#loc85)
    %198 = "ttir.typecast"(%196, %197) <{conservative_folding = false}> : (tensor<1x1x7x128xbf16>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32> loc(#loc85)
    %199 = ttir.empty() : tensor<1x7x128xf32> loc(#loc86)
    %200 = "ttir.reshape"(%198, %199) <{shape = [1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x1x7x128xf32>, tensor<1x7x128xf32>) -> tensor<1x7x128xf32> loc(#loc86)
    %201 = ttir.empty() : tensor<1x1x7x128xf32> loc(#loc87)
    %202 = "ttir.reshape"(%200, %201) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32> loc(#loc87)
    %203 = ttir.empty() : tensor<1x4x7x128xf32> loc(#loc87)
    %204 = "ttir.broadcast"(%202, %203) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32> loc(#loc87)
    %205 = ttir.empty() : tensor<1x4x7x128xf32> loc(#loc88)
    %206 = "ttir.multiply"(%190, %204, %205) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32> loc(#loc88)
    %207 = ttir.empty() : tensor<1x4x7x128xbf16> loc(#loc89)
    %208 = "ttir.typecast"(%206, %207) <{conservative_folding = false}> : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16> loc(#loc89)
    %209 = ttir.empty() : tensor<1x4x7x128xbf16> loc(#loc90)
    %210 = "ttir.add"(%180, %208, %209) : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16> loc(#loc90)
    %211 = ttir.empty() : tensor<1x4x16x128xbf16> loc(#loc91)
    %212 = "ttir.scatter"(%17, %78, %210, %211) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x16x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>, tensor<1x4x16x128xbf16>) -> tensor<1x4x16x128xbf16> loc(#loc91)
    %213 = ttir.empty() : tensor<1x512x3072xbf16> loc(#loc92)
    %214 = "ttir.reshape"(%19, %213) <{shape = [1 : i32, 512 : i32, 3072 : i32]}> : (tensor<512x3072xbf16>, tensor<1x512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc92)
    %215 = ttir.empty() : tensor<512x3072xbf16> loc(#loc93)
    %216 = "ttir.reshape"(%214, %215) <{shape = [512 : i32, 3072 : i32]}> : (tensor<1x512x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc93)
    %217 = ttir.empty() : tensor<3072x512xbf16> loc(#loc94)
    %218 = "ttir.permute"(%216, %217) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16> loc(#loc94)
    %219 = "ttir.dot_general"(%138, %218) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16> loc(#loc95)
    %220 = ttir.empty() : tensor<1x7x4x128xbf16> loc(#loc96)
    %221 = "ttir.reshape"(%219, %220) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16>, tensor<1x7x4x128xbf16>) -> tensor<1x7x4x128xbf16> loc(#loc96)
    %222 = ttir.empty() : tensor<1x4x7x128xbf16> loc(#loc97)
    %223 = "ttir.permute"(%221, %222) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16> loc(#loc97)
    %224 = ttir.empty() : tensor<1x4x16x128xbf16> loc(#loc98)
    %225 = "ttir.scatter"(%21, %78, %223, %224) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x16x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>, tensor<1x4x16x128xbf16>) -> tensor<1x4x16x128xbf16> loc(#loc98)
    %226 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc99)
    %227 = "ttir.reshape"(%41, %226) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc99)
    %228 = ttir.empty() : tensor<3072xbf16> loc(#loc100)
    %229 = "ttir.reshape"(%227, %228) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc100)
    %230 = ttir.empty() : tensor<3072xf32> loc(#loc101)
    %231 = "ttir.typecast"(%229, %230) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32> loc(#loc101)
    %232 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc102)
    %233 = "ttir.reshape"(%231, %232) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc102)
    %234 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc102)
    %235 = "ttir.broadcast"(%233, %234) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc102)
    %236 = ttir.empty() : tensor<1x1536x3072xbf16> loc(#loc103)
    %237 = "ttir.reshape"(%35, %236) <{shape = [1 : i32, 1536 : i32, 3072 : i32]}> : (tensor<1536x3072xbf16>, tensor<1x1536x3072xbf16>) -> tensor<1x1536x3072xbf16> loc(#loc103)
    %238 = ttir.empty() : tensor<1536x3072xbf16> loc(#loc104)
    %239 = "ttir.reshape"(%237, %238) <{shape = [1536 : i32, 3072 : i32]}> : (tensor<1x1536x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc104)
    %240 = ttir.empty() : tensor<3072x1536xbf16> loc(#loc105)
    %241 = "ttir.permute"(%239, %240) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16> loc(#loc105)
    %242 = "ttir.dot_general"(%138, %241) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<7x1536xbf16> loc(#loc106)
    %243 = ttir.empty() : tensor<1x7x12x128xbf16> loc(#loc107)
    %244 = "ttir.reshape"(%242, %243) <{shape = [1 : i32, 7 : i32, 12 : i32, 128 : i32]}> : (tensor<7x1536xbf16>, tensor<1x7x12x128xbf16>) -> tensor<1x7x12x128xbf16> loc(#loc107)
    %245 = ttir.empty() : tensor<1x12x7x128xbf16> loc(#loc108)
    %246 = "ttir.permute"(%244, %245) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x12x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16> loc(#loc108)
    %247 = ttir.empty() : tensor<1x12x7x128xf32> loc(#loc109)
    %248 = "ttir.typecast"(%246, %247) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32> loc(#loc109)
    %249 = ttir.empty() : tensor<1x1x7x128xf32> loc(#loc110)
    %250 = "ttir.reshape"(%172, %249) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32> loc(#loc110)
    %251 = ttir.empty() : tensor<1x12x7x128xf32> loc(#loc110)
    %252 = "ttir.broadcast"(%250, %251) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32> loc(#loc110)
    %253 = ttir.empty() : tensor<1x12x7x128xf32> loc(#loc111)
    %254 = "ttir.multiply"(%248, %252, %253) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32> loc(#loc111)
    %255 = ttir.empty() : tensor<1x12x7x128xbf16> loc(#loc112)
    %256 = "ttir.typecast"(%254, %255) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16> loc(#loc112)
    %257 = ttir.empty() : tensor<1x12x7x64xbf16> loc(#loc113)
    %258 = "ttir.slice_static"(%246, %257) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16> loc(#loc113)
    %259 = ttir.empty() : tensor<1x12x7x64xbf16> loc(#loc114)
    %260 = "ttir.neg"(%258, %259) : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16> loc(#loc114)
    %261 = ttir.empty() : tensor<1x12x7x64xbf16> loc(#loc115)
    %262 = "ttir.slice_static"(%246, %261) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16> loc(#loc115)
    %263 = ttir.empty() : tensor<1x12x7x128xbf16> loc(#loc116)
    %264 = "ttir.concat"(%260, %262, %263) <{dim = 3 : si32}> : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16> loc(#loc116)
    %265 = ttir.empty() : tensor<1x12x7x128xf32> loc(#loc117)
    %266 = "ttir.typecast"(%264, %265) <{conservative_folding = false}> : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32> loc(#loc117)
    %267 = ttir.empty() : tensor<1x1x7x128xf32> loc(#loc118)
    %268 = "ttir.reshape"(%200, %267) <{shape = [1 : i32, 1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x7x128xf32>, tensor<1x1x7x128xf32>) -> tensor<1x1x7x128xf32> loc(#loc118)
    %269 = ttir.empty() : tensor<1x12x7x128xf32> loc(#loc118)
    %270 = "ttir.broadcast"(%268, %269) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32> loc(#loc118)
    %271 = ttir.empty() : tensor<1x12x7x128xf32> loc(#loc119)
    %272 = "ttir.multiply"(%266, %270, %271) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32> loc(#loc119)
    %273 = ttir.empty() : tensor<1x12x7x128xbf16> loc(#loc120)
    %274 = "ttir.typecast"(%272, %273) <{conservative_folding = false}> : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16> loc(#loc120)
    %275 = ttir.empty() : tensor<1x12x7x128xbf16> loc(#loc121)
    %276 = "ttir.add"(%256, %274, %275) : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16> loc(#loc121)
    %277 = ttir.empty() : tensor<12x7x128xbf16> loc(#loc122)
    %278 = "ttir.reshape"(%276, %277) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xbf16>, tensor<12x7x128xbf16>) -> tensor<12x7x128xbf16> loc(#loc122)
    %279 = ttir.empty() : tensor<1x4x1x16x128xbf16> loc(#loc123)
    %280 = "ttir.reshape"(%212, %279) <{shape = [1 : i32, 4 : i32, 1 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x16x128xbf16>, tensor<1x4x1x16x128xbf16>) -> tensor<1x4x1x16x128xbf16> loc(#loc123)
    %281 = ttir.empty() : tensor<1x4x3x16x128xbf16> loc(#loc123)
    %282 = "ttir.broadcast"(%280, %281) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x16x128xbf16>, tensor<1x4x3x16x128xbf16>) -> tensor<1x4x3x16x128xbf16> loc(#loc123)
    %283 = ttir.empty() : tensor<1x12x16x128xbf16> loc(#loc124)
    %284 = "ttir.reshape"(%282, %283) <{shape = [1 : i32, 12 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x3x16x128xbf16>, tensor<1x12x16x128xbf16>) -> tensor<1x12x16x128xbf16> loc(#loc124)
    %285 = ttir.empty() : tensor<1x12x128x16xbf16> loc(#loc125)
    %286 = "ttir.permute"(%284, %285) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x16x128xbf16>, tensor<1x12x128x16xbf16>) -> tensor<1x12x128x16xbf16> loc(#loc125)
    %287 = ttir.empty() : tensor<12x128x16xbf16> loc(#loc126)
    %288 = "ttir.reshape"(%286, %287) <{shape = [12 : i32, 128 : i32, 16 : i32]}> : (tensor<1x12x128x16xbf16>, tensor<12x128x16xbf16>) -> tensor<12x128x16xbf16> loc(#loc126)
    %289 = "ttir.dot_general"(%278, %288) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x7x128xbf16>, tensor<12x128x16xbf16>) -> tensor<12x7x16xbf16> loc(#loc127)
    %290 = ttir.empty() : tensor<1x12x7x16xbf16> loc(#loc128)
    %291 = "ttir.reshape"(%289, %290) <{shape = [1 : i32, 12 : i32, 7 : i32, 16 : i32]}> : (tensor<12x7x16xbf16>, tensor<1x12x7x16xbf16>) -> tensor<1x12x7x16xbf16> loc(#loc128)
    %292 = ttir.empty() : tensor<1x12x7x16xf32> loc(#loc129)
    %293 = "ttir.typecast"(%291, %292) <{conservative_folding = false}> : (tensor<1x12x7x16xbf16>, tensor<1x12x7x16xf32>) -> tensor<1x12x7x16xf32> loc(#loc129)
    %294 = ttir.empty() : tensor<1x1x1x1xf32> loc(#loc130)
    %295 = "ttir.reshape"(%33, %294) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32> loc(#loc130)
    %296 = ttir.empty() : tensor<1x12x7x16xf32> loc(#loc130)
    %297 = "ttir.broadcast"(%295, %296) <{broadcast_dimensions = array<i64: 1, 12, 7, 16>}> : (tensor<1x1x1x1xf32>, tensor<1x12x7x16xf32>) -> tensor<1x12x7x16xf32> loc(#loc130)
    %298 = ttir.empty() : tensor<1x12x7x16xf32> loc(#loc131)
    %299 = "ttir.multiply"(%293, %297, %298) : (tensor<1x12x7x16xf32>, tensor<1x12x7x16xf32>, tensor<1x12x7x16xf32>) -> tensor<1x12x7x16xf32> loc(#loc131)
    %300 = ttir.empty() : tensor<1x12x7x16xbf16> loc(#loc132)
    %301 = "ttir.typecast"(%299, %300) <{conservative_folding = false}> : (tensor<1x12x7x16xf32>, tensor<1x12x7x16xbf16>) -> tensor<1x12x7x16xbf16> loc(#loc132)
    %302 = ttir.empty() : tensor<1x16xi64> loc(#loc133)
    %303 = "ttir.reshape"(%43, %302) <{shape = [1 : i32, 16 : i32]}> : (tensor<16xi64>, tensor<1x16xi64>) -> tensor<1x16xi64> loc(#loc133)
    %304 = ttir.empty() : tensor<7x16xi64> loc(#loc133)
    %305 = "ttir.broadcast"(%303, %304) <{broadcast_dimensions = array<i64: 7, 1>}> : (tensor<1x16xi64>, tensor<7x16xi64>) -> tensor<7x16xi64> loc(#loc133)
    %306 = ttir.empty() : tensor<7x1xi64> loc(#loc134)
    %307 = "ttir.reshape"(%44, %306) <{shape = [7 : i32, 1 : i32]}> : (tensor<7xi64>, tensor<7x1xi64>) -> tensor<7x1xi64> loc(#loc134)
    %308 = ttir.empty() : tensor<7x16xi64> loc(#loc134)
    %309 = "ttir.broadcast"(%307, %308) <{broadcast_dimensions = array<i64: 1, 16>}> : (tensor<7x1xi64>, tensor<7x16xi64>) -> tensor<7x16xi64> loc(#loc134)
    %310 = ttir.empty() : tensor<7x16xi64> loc(#loc135)
    %311 = "ttir.subtract"(%305, %309, %310) : (tensor<7x16xi64>, tensor<7x16xi64>, tensor<7x16xi64>) -> tensor<7x16xi64> loc(#loc135)
    %312 = ttir.empty() : tensor<7x16xi1> loc(#loc136)
    %313 = "ttir.ge"(%311, %58, %312) : (tensor<7x16xi64>, tensor<7x16xi64>, tensor<7x16xi1>) -> tensor<7x16xi1> loc(#loc136)
    %314 = ttir.empty() : tensor<1x1xbf16> loc(#loc137)
    %315 = "ttir.reshape"(%31, %314) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16> loc(#loc137)
    %316 = ttir.empty() : tensor<7x16xbf16> loc(#loc137)
    %317 = "ttir.broadcast"(%315, %316) <{broadcast_dimensions = array<i64: 7, 16>}> : (tensor<1x1xbf16>, tensor<7x16xbf16>) -> tensor<7x16xbf16> loc(#loc137)
    %318 = ttir.empty() : tensor<7x16xbf16> loc(#loc138)
    %319 = "ttir.where"(%313, %317, %54, %318) : (tensor<7x16xi1>, tensor<7x16xbf16>, tensor<7x16xbf16>, tensor<7x16xbf16>) -> tensor<7x16xbf16> loc(#loc138)
    %320 = ttir.empty() : tensor<7x16xf32> loc(#loc139)
    %321 = "ttir.typecast"(%319, %320) <{conservative_folding = false}> : (tensor<7x16xbf16>, tensor<7x16xf32>) -> tensor<7x16xf32> loc(#loc139)
    %322 = ttir.empty() : tensor<7x1xi64> loc(#loc140)
    %323 = "ttir.reshape"(%66, %322) <{shape = [7 : i32, 1 : i32]}> : (tensor<7xi64>, tensor<7x1xi64>) -> tensor<7x1xi64> loc(#loc140)
    %324 = ttir.empty() : tensor<7x16xi64> loc(#loc140)
    %325 = "ttir.broadcast"(%323, %324) <{broadcast_dimensions = array<i64: 1, 16>}> : (tensor<7x1xi64>, tensor<7x16xi64>) -> tensor<7x16xi64> loc(#loc140)
    %326 = ttir.empty() : tensor<7x16xi1> loc(#loc141)
    %327 = "ttir.gt"(%305, %325, %326) : (tensor<7x16xi64>, tensor<7x16xi64>, tensor<7x16xi1>) -> tensor<7x16xi1> loc(#loc141)
    %328 = ttir.empty() : tensor<7x16xf32> loc(#loc142)
    %329 = "ttir.typecast"(%327, %328) <{conservative_folding = false}> : (tensor<7x16xi1>, tensor<7x16xf32>) -> tensor<7x16xf32> loc(#loc142)
    %330 = ttir.empty() : tensor<7x16xf32> loc(#loc143)
    %331 = "ttir.multiply"(%321, %329, %330) : (tensor<7x16xf32>, tensor<7x16xf32>, tensor<7x16xf32>) -> tensor<7x16xf32> loc(#loc143)
    %332 = ttir.empty() : tensor<7x16xbf16> loc(#loc144)
    %333 = "ttir.typecast"(%331, %332) <{conservative_folding = false}> : (tensor<7x16xf32>, tensor<7x16xbf16>) -> tensor<7x16xbf16> loc(#loc144)
    %334 = ttir.empty() : tensor<1x7x16xbf16> loc(#loc145)
    %335 = "ttir.reshape"(%333, %334) <{shape = [1 : i32, 7 : i32, 16 : i32]}> : (tensor<7x16xbf16>, tensor<1x7x16xbf16>) -> tensor<1x7x16xbf16> loc(#loc145)
    %336 = ttir.empty() : tensor<1x1x7x16xbf16> loc(#loc146)
    %337 = "ttir.reshape"(%335, %336) <{shape = [1 : i32, 1 : i32, 7 : i32, 16 : i32]}> : (tensor<1x7x16xbf16>, tensor<1x1x7x16xbf16>) -> tensor<1x1x7x16xbf16> loc(#loc146)
    %338 = ttir.empty() : tensor<1x12x7x16xbf16> loc(#loc146)
    %339 = "ttir.broadcast"(%337, %338) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x7x16xbf16>, tensor<1x12x7x16xbf16>) -> tensor<1x12x7x16xbf16> loc(#loc146)
    %340 = ttir.empty() : tensor<1x12x7x16xbf16> loc(#loc147)
    %341 = "ttir.add"(%301, %339, %340) : (tensor<1x12x7x16xbf16>, tensor<1x12x7x16xbf16>, tensor<1x12x7x16xbf16>) -> tensor<1x12x7x16xbf16> loc(#loc147)
    %342 = ttir.empty() : tensor<1x12x7x16xf32> loc(#loc148)
    %343 = "ttir.typecast"(%341, %342) <{conservative_folding = false}> : (tensor<1x12x7x16xbf16>, tensor<1x12x7x16xf32>) -> tensor<1x12x7x16xf32> loc(#loc148)
    %344 = ttir.empty() : tensor<1x12x7xf32> loc(#loc149)
    %345 = "ttir.max"(%343, %344) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x7x16xf32>, tensor<1x12x7xf32>) -> tensor<1x12x7xf32> loc(#loc149)
    %346 = ttir.empty() : tensor<1x12x7x1xf32> loc(#loc150)
    %347 = "ttir.reshape"(%345, %346) <{shape = [1 : i32, 12 : i32, 7 : i32, 1 : i32]}> : (tensor<1x12x7xf32>, tensor<1x12x7x1xf32>) -> tensor<1x12x7x1xf32> loc(#loc150)
    %348 = ttir.empty() : tensor<1x12x7x16xf32> loc(#loc150)
    %349 = "ttir.broadcast"(%347, %348) <{broadcast_dimensions = array<i64: 1, 1, 1, 16>}> : (tensor<1x12x7x1xf32>, tensor<1x12x7x16xf32>) -> tensor<1x12x7x16xf32> loc(#loc150)
    %350 = ttir.empty() : tensor<1x12x7x16xf32> loc(#loc151)
    %351 = "ttir.subtract"(%343, %349, %350) : (tensor<1x12x7x16xf32>, tensor<1x12x7x16xf32>, tensor<1x12x7x16xf32>) -> tensor<1x12x7x16xf32> loc(#loc151)
    %352 = ttir.empty() : tensor<1x12x7x16xf32> loc(#loc152)
    %353 = "ttir.exp"(%351, %352) : (tensor<1x12x7x16xf32>, tensor<1x12x7x16xf32>) -> tensor<1x12x7x16xf32> loc(#loc152)
    %354 = ttir.empty() : tensor<1x12x7xf32> loc(#loc153)
    %355 = "ttir.sum"(%353, %354) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x7x16xf32>, tensor<1x12x7xf32>) -> tensor<1x12x7xf32> loc(#loc153)
    %356 = ttir.empty() : tensor<1x12x7x1xf32> loc(#loc154)
    %357 = "ttir.reshape"(%355, %356) <{shape = [1 : i32, 12 : i32, 7 : i32, 1 : i32]}> : (tensor<1x12x7xf32>, tensor<1x12x7x1xf32>) -> tensor<1x12x7x1xf32> loc(#loc154)
    %358 = ttir.empty() : tensor<1x12x7x16xf32> loc(#loc154)
    %359 = "ttir.broadcast"(%357, %358) <{broadcast_dimensions = array<i64: 1, 1, 1, 16>}> : (tensor<1x12x7x1xf32>, tensor<1x12x7x16xf32>) -> tensor<1x12x7x16xf32> loc(#loc154)
    %360 = ttir.empty() : tensor<1x12x7x16xf32> loc(#loc155)
    %361 = "ttir.div"(%353, %359, %360) : (tensor<1x12x7x16xf32>, tensor<1x12x7x16xf32>, tensor<1x12x7x16xf32>) -> tensor<1x12x7x16xf32> loc(#loc155)
    %362 = ttir.empty() : tensor<1x12x7x16xbf16> loc(#loc156)
    %363 = "ttir.typecast"(%361, %362) <{conservative_folding = false}> : (tensor<1x12x7x16xf32>, tensor<1x12x7x16xbf16>) -> tensor<1x12x7x16xbf16> loc(#loc156)
    %364 = ttir.empty() : tensor<12x7x16xbf16> loc(#loc157)
    %365 = "ttir.reshape"(%363, %364) <{shape = [12 : i32, 7 : i32, 16 : i32]}> : (tensor<1x12x7x16xbf16>, tensor<12x7x16xbf16>) -> tensor<12x7x16xbf16> loc(#loc157)
    %366 = ttir.empty() : tensor<1x4x1x16x128xbf16> loc(#loc158)
    %367 = "ttir.reshape"(%225, %366) <{shape = [1 : i32, 4 : i32, 1 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x16x128xbf16>, tensor<1x4x1x16x128xbf16>) -> tensor<1x4x1x16x128xbf16> loc(#loc158)
    %368 = ttir.empty() : tensor<1x4x3x16x128xbf16> loc(#loc158)
    %369 = "ttir.broadcast"(%367, %368) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x16x128xbf16>, tensor<1x4x3x16x128xbf16>) -> tensor<1x4x3x16x128xbf16> loc(#loc158)
    %370 = ttir.empty() : tensor<12x16x128xbf16> loc(#loc159)
    %371 = "ttir.reshape"(%369, %370) <{shape = [12 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x3x16x128xbf16>, tensor<12x16x128xbf16>) -> tensor<12x16x128xbf16> loc(#loc159)
    %372 = "ttir.dot_general"(%365, %371) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x7x16xbf16>, tensor<12x16x128xbf16>) -> tensor<12x7x128xbf16> loc(#loc160)
    %373 = ttir.empty() : tensor<1x12x7x128xbf16> loc(#loc161)
    %374 = "ttir.reshape"(%372, %373) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16> loc(#loc161)
    %375 = ttir.empty() : tensor<1x7x12x128xbf16> loc(#loc162)
    %376 = "ttir.permute"(%374, %375) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x12x7x128xbf16>, tensor<1x7x12x128xbf16>) -> tensor<1x7x12x128xbf16> loc(#loc162)
    %377 = ttir.empty() : tensor<7x1536xbf16> loc(#loc163)
    %378 = "ttir.reshape"(%376, %377) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x7x12x128xbf16>, tensor<7x1536xbf16>) -> tensor<7x1536xbf16> loc(#loc163)
    %379 = ttir.empty() : tensor<1x3072x1536xbf16> loc(#loc164)
    %380 = "ttir.reshape"(%29, %379) <{shape = [1 : i32, 3072 : i32, 1536 : i32]}> : (tensor<3072x1536xbf16>, tensor<1x3072x1536xbf16>) -> tensor<1x3072x1536xbf16> loc(#loc164)
    %381 = ttir.empty() : tensor<3072x1536xbf16> loc(#loc165)
    %382 = "ttir.reshape"(%380, %381) <{shape = [3072 : i32, 1536 : i32]}> : (tensor<1x3072x1536xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16> loc(#loc165)
    %383 = ttir.empty() : tensor<1536x3072xbf16> loc(#loc166)
    %384 = "ttir.permute"(%382, %383) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc166)
    %385 = "ttir.dot_general"(%378, %384) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc167)
    %386 = ttir.empty() : tensor<7x3072xbf16> loc(#loc167)
    %387 = "ttir.all_reduce"(%385, %386) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc167)
    %388 = ttir.empty() : tensor<1x7x3072xbf16> loc(#loc168)
    %389 = "ttir.reshape"(%387, %388) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc168)
    %390 = ttir.empty() : tensor<1x7x3072xbf16> loc(#loc169)
    %391 = "ttir.add"(%102, %389, %390) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc169)
    %392 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc170)
    %393 = "ttir.reshape"(%37, %392) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc170)
    %394 = ttir.empty() : tensor<3072xbf16> loc(#loc171)
    %395 = "ttir.reshape"(%393, %394) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc171)
    %396 = ttir.empty() : tensor<3072xf32> loc(#loc172)
    %397 = "ttir.typecast"(%395, %396) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32> loc(#loc172)
    %398 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc173)
    %399 = "ttir.reshape"(%397, %398) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc173)
    %400 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc173)
    %401 = "ttir.broadcast"(%399, %400) <{broadcast_dimensions = array<i64: 1, 7, 1>}> : (tensor<1x1x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc173)
    %402 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc174)
    %403 = "ttir.typecast"(%391, %402) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc174)
    %404 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc175)
    %405 = "ttir.pow"(%403, %62, %404) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc175)
    %406 = ttir.empty() : tensor<1x7xf32> loc(#loc176)
    %407 = "ttir.sum"(%405, %406) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32> loc(#loc176)
    %408 = ttir.empty() : tensor<1x7xf32> loc(#loc177)
    %409 = "ttir.multiply"(%407, %48, %408) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32> loc(#loc177)
    %410 = ttir.empty() : tensor<1x7x1xf32> loc(#loc178)
    %411 = "ttir.reshape"(%409, %410) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32> loc(#loc178)
    %412 = ttir.empty() : tensor<1x7x1xf32> loc(#loc179)
    %413 = "ttir.add"(%411, %116, %412) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32> loc(#loc179)
    %414 = ttir.empty() : tensor<1x7x1xf32> loc(#loc180)
    %415 = "ttir.rsqrt"(%413, %414) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32> loc(#loc180)
    %416 = ttir.empty() : tensor<1x7xf32> loc(#loc181)
    %417 = "ttir.reshape"(%415, %416) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32> loc(#loc181)
    %418 = ttir.empty() : tensor<1x7x1xf32> loc(#loc182)
    %419 = "ttir.reshape"(%417, %418) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32> loc(#loc182)
    %420 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc182)
    %421 = "ttir.broadcast"(%419, %420) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc182)
    %422 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc183)
    %423 = "ttir.multiply"(%403, %421, %422) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc183)
    %424 = ttir.empty() : tensor<1x7x3072xbf16> loc(#loc184)
    %425 = "ttir.typecast"(%423, %424) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc184)
    %426 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc185)
    %427 = "ttir.typecast"(%425, %426) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc185)
    %428 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc186)
    %429 = "ttir.multiply"(%401, %427, %428) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc186)
    %430 = ttir.empty() : tensor<1x7x3072xbf16> loc(#loc187)
    %431 = "ttir.typecast"(%429, %430) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc187)
    %432 = ttir.empty() : tensor<7x3072xbf16> loc(#loc188)
    %433 = "ttir.reshape"(%431, %432) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc188)
    %434 = ttir.empty() : tensor<1x4096x3072xbf16> loc(#loc189)
    %435 = "ttir.reshape"(%39, %434) <{shape = [1 : i32, 4096 : i32, 3072 : i32]}> : (tensor<4096x3072xbf16>, tensor<1x4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc189)
    %436 = ttir.empty() : tensor<4096x3072xbf16> loc(#loc190)
    %437 = "ttir.reshape"(%435, %436) <{shape = [4096 : i32, 3072 : i32]}> : (tensor<1x4096x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc190)
    %438 = ttir.empty() : tensor<3072x4096xbf16> loc(#loc191)
    %439 = "ttir.permute"(%437, %438) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc191)
    %440 = "ttir.dot_general"(%433, %439) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16> loc(#loc192)
    %441 = ttir.empty() : tensor<1x7x4096xbf16> loc(#loc193)
    %442 = "ttir.reshape"(%440, %441) <{shape = [1 : i32, 7 : i32, 4096 : i32]}> : (tensor<7x4096xbf16>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16> loc(#loc193)
    %443 = ttir.empty() : tensor<1x7x4096xf32> loc(#loc194)
    %444 = "ttir.typecast"(%442, %443) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32> loc(#loc194)
    %445 = ttir.empty() : tensor<1x7x4096xbf16> loc(#loc195)
    %446 = "ttir.sigmoid"(%442, %445) : (tensor<1x7x4096xbf16>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16> loc(#loc195)
    %447 = ttir.empty() : tensor<1x7x4096xf32> loc(#loc196)
    %448 = "ttir.typecast"(%446, %447) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32> loc(#loc196)
    %449 = ttir.empty() : tensor<1x7x4096xf32> loc(#loc197)
    %450 = "ttir.multiply"(%444, %448, %449) : (tensor<1x7x4096xf32>, tensor<1x7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32> loc(#loc197)
    %451 = ttir.empty() : tensor<1x7x4096xbf16> loc(#loc198)
    %452 = "ttir.typecast"(%450, %451) <{conservative_folding = false}> : (tensor<1x7x4096xf32>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16> loc(#loc198)
    %453 = ttir.empty() : tensor<1x7x4096xf32> loc(#loc199)
    %454 = "ttir.typecast"(%452, %453) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32> loc(#loc199)
    %455 = ttir.empty() : tensor<1x4096x3072xbf16> loc(#loc200)
    %456 = "ttir.reshape"(%27, %455) <{shape = [1 : i32, 4096 : i32, 3072 : i32]}> : (tensor<4096x3072xbf16>, tensor<1x4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc200)
    %457 = ttir.empty() : tensor<4096x3072xbf16> loc(#loc201)
    %458 = "ttir.reshape"(%456, %457) <{shape = [4096 : i32, 3072 : i32]}> : (tensor<1x4096x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc201)
    %459 = ttir.empty() : tensor<3072x4096xbf16> loc(#loc202)
    %460 = "ttir.permute"(%458, %459) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc202)
    %461 = "ttir.dot_general"(%433, %460) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<7x4096xbf16> loc(#loc203)
    %462 = ttir.empty() : tensor<1x7x4096xbf16> loc(#loc204)
    %463 = "ttir.reshape"(%461, %462) <{shape = [1 : i32, 7 : i32, 4096 : i32]}> : (tensor<7x4096xbf16>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16> loc(#loc204)
    %464 = ttir.empty() : tensor<1x7x4096xf32> loc(#loc205)
    %465 = "ttir.typecast"(%463, %464) <{conservative_folding = false}> : (tensor<1x7x4096xbf16>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32> loc(#loc205)
    %466 = ttir.empty() : tensor<1x7x4096xf32> loc(#loc206)
    %467 = "ttir.multiply"(%454, %465, %466) : (tensor<1x7x4096xf32>, tensor<1x7x4096xf32>, tensor<1x7x4096xf32>) -> tensor<1x7x4096xf32> loc(#loc206)
    %468 = ttir.empty() : tensor<1x7x4096xbf16> loc(#loc207)
    %469 = "ttir.typecast"(%467, %468) <{conservative_folding = false}> : (tensor<1x7x4096xf32>, tensor<1x7x4096xbf16>) -> tensor<1x7x4096xbf16> loc(#loc207)
    %470 = ttir.empty() : tensor<7x4096xbf16> loc(#loc208)
    %471 = "ttir.reshape"(%469, %470) <{shape = [7 : i32, 4096 : i32]}> : (tensor<1x7x4096xbf16>, tensor<7x4096xbf16>) -> tensor<7x4096xbf16> loc(#loc208)
    %472 = ttir.empty() : tensor<1x3072x4096xbf16> loc(#loc209)
    %473 = "ttir.reshape"(%25, %472) <{shape = [1 : i32, 3072 : i32, 4096 : i32]}> : (tensor<3072x4096xbf16>, tensor<1x3072x4096xbf16>) -> tensor<1x3072x4096xbf16> loc(#loc209)
    %474 = ttir.empty() : tensor<3072x4096xbf16> loc(#loc210)
    %475 = "ttir.reshape"(%473, %474) <{shape = [3072 : i32, 4096 : i32]}> : (tensor<1x3072x4096xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc210)
    %476 = ttir.empty() : tensor<4096x3072xbf16> loc(#loc211)
    %477 = "ttir.permute"(%475, %476) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc211)
    %478 = "ttir.dot_general"(%471, %477) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc212)
    %479 = ttir.empty() : tensor<7x3072xbf16> loc(#loc212)
    %480 = "ttir.all_reduce"(%478, %479) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc212)
    %481 = ttir.empty() : tensor<1x7x3072xbf16> loc(#loc213)
    %482 = "ttir.reshape"(%480, %481) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc213)
    %483 = ttir.empty() : tensor<1x7x3072xbf16> loc(#loc214)
    %484 = "ttir.add"(%391, %482, %483) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc214)
    %485 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc215)
    %486 = "ttir.typecast"(%484, %485) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc215)
    %487 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc216)
    %488 = "ttir.pow"(%486, %62, %487) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc216)
    %489 = ttir.empty() : tensor<1x7xf32> loc(#loc217)
    %490 = "ttir.sum"(%488, %489) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32>, tensor<1x7xf32>) -> tensor<1x7xf32> loc(#loc217)
    %491 = ttir.empty() : tensor<1x7xf32> loc(#loc218)
    %492 = "ttir.multiply"(%490, %48, %491) : (tensor<1x7xf32>, tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32> loc(#loc218)
    %493 = ttir.empty() : tensor<1x7x1xf32> loc(#loc219)
    %494 = "ttir.reshape"(%492, %493) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32> loc(#loc219)
    %495 = ttir.empty() : tensor<1x7x1xf32> loc(#loc220)
    %496 = "ttir.add"(%494, %116, %495) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32> loc(#loc220)
    %497 = ttir.empty() : tensor<1x7x1xf32> loc(#loc221)
    %498 = "ttir.rsqrt"(%496, %497) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32> loc(#loc221)
    %499 = ttir.empty() : tensor<1x7xf32> loc(#loc222)
    %500 = "ttir.reshape"(%498, %499) <{shape = [1 : i32, 7 : i32]}> : (tensor<1x7x1xf32>, tensor<1x7xf32>) -> tensor<1x7xf32> loc(#loc222)
    %501 = ttir.empty() : tensor<1x7x1xf32> loc(#loc223)
    %502 = "ttir.reshape"(%500, %501) <{shape = [1 : i32, 7 : i32, 1 : i32]}> : (tensor<1x7xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32> loc(#loc223)
    %503 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc223)
    %504 = "ttir.broadcast"(%502, %503) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x7x1xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc223)
    %505 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc224)
    %506 = "ttir.multiply"(%486, %504, %505) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc224)
    %507 = ttir.empty() : tensor<1x7x3072xbf16> loc(#loc225)
    %508 = "ttir.typecast"(%506, %507) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc225)
    %509 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc226)
    %510 = "ttir.typecast"(%508, %509) <{conservative_folding = false}> : (tensor<1x7x3072xbf16>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc226)
    %511 = ttir.empty() : tensor<1x7x3072xf32> loc(#loc227)
    %512 = "ttir.multiply"(%235, %510, %511) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32> loc(#loc227)
    %513 = ttir.empty() : tensor<1x7x3072xbf16> loc(#loc228)
    %514 = "ttir.typecast"(%512, %513) <{conservative_folding = false}> : (tensor<1x7x3072xf32>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16> loc(#loc228)
    %515 = ttir.empty() : tensor<7x3072xbf16> loc(#loc229)
    %516 = "ttir.reshape"(%514, %515) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x7x3072xbf16>, tensor<7x3072xbf16>) -> tensor<7x3072xbf16> loc(#loc229)
    %517 = ttir.empty() : tensor<1x128256x3072xbf16> loc(#loc230)
    %518 = "ttir.reshape"(%23, %517) <{shape = [1 : i32, 128256 : i32, 3072 : i32]}> : (tensor<128256x3072xbf16>, tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc230)
    %519 = ttir.empty() : tensor<128256x3072xbf16> loc(#loc231)
    %520 = "ttir.reshape"(%518, %519) <{shape = [128256 : i32, 3072 : i32]}> : (tensor<1x128256x3072xbf16>, tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc231)
    %521 = ttir.empty() : tensor<3072x128256xbf16> loc(#loc232)
    %522 = "ttir.permute"(%520, %521) <{permutation = array<i64: 1, 0>}> : (tensor<128256x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<3072x128256xbf16> loc(#loc232)
    %523 = "ttir.dot_general"(%516, %522) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16> loc(#loc233)
    %524 = ttir.empty() : tensor<1x7x128256xbf16> loc(#loc234)
    %525 = "ttir.reshape"(%523, %524) <{shape = [1 : i32, 7 : i32, 128256 : i32]}> : (tensor<7x128256xbf16>, tensor<1x7x128256xbf16>) -> tensor<1x7x128256xbf16> loc(#loc234)
    %526 = ttir.empty() : tensor<1x8x16x128xbf16> loc(#loc)
    %527 = "ttir.mesh_shard"(%212, %526) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x16x128xbf16>, tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc)
    %528 = ttir.empty() : tensor<1x8x16x128xbf16> loc(#loc)
    %529 = "ttir.mesh_shard"(%225, %528) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x16x128xbf16>, tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc)
    %530 = ttir.empty() : tensor<7x128256xbf16> loc(#loc)
    %531 = "ttir.mesh_shard"(%523, %530) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<7x128256xbf16>, tensor<7x128256xbf16>) -> tensor<7x128256xbf16> loc(#loc)
    %532 = ttir.empty() : tensor<1x7x128256xbf16> loc(#loc)
    %533 = "ttir.mesh_shard"(%525, %532) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x7x128256xbf16>, tensor<1x7x128256xbf16>) -> tensor<1x7x128256xbf16> loc(#loc)
    return %527, %529, %531, %533 : tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<7x128256xbf16>, tensor<1x7x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc22 = loc("reshape.4")
#loc23 = loc("reshape.6")
#loc24 = loc("compare.126")
#loc25 = loc("broadcast.122")
#loc26 = loc("add.123")
#loc27 = loc("select.127")
#loc28 = loc("reshape.128")
#loc29 = loc("reshape.82")
#loc30 = loc("reshape.84")
#loc31 = loc("convert.85")
#loc32 = loc("broadcast.86")
#loc33 = loc("reshape.45")
#loc34 = loc("reshape.47")
#loc35 = loc("reshape.40")
#loc36 = loc("reshape.43")
#loc37 = loc("convert.48")
#loc38 = loc("gather.49")
#loc39 = loc("reshape.50")
#loc40 = loc("convert.51")
#loc41 = loc("power.53")
#loc42 = loc("reduce.60")
#loc43 = loc("multiply.69")
#loc44 = loc("reshape.70")
#loc45 = loc("broadcast.73")
#loc46 = loc("add.74")
#loc47 = loc("rsqrt.75")
#loc48 = loc("reshape.76")
#loc49 = loc("broadcast.77")
#loc50 = loc("multiply.78")
#loc51 = loc("convert.79")
#loc52 = loc("convert.80")
#loc53 = loc("multiply.87")
#loc54 = loc("convert.88")
#loc55 = loc("reshape.89")
#loc56 = loc("reshape.32")
#loc57 = loc("reshape.34")
#loc58 = loc("transpose.35")
#loc59 = loc("dot.90")
#loc60 = loc("reshape.92")
#loc61 = loc("transpose.93")
#loc62 = loc("convert.110")
#loc63 = loc("reshape.14")
#loc64 = loc("reshape.19")
#loc65 = loc("convert.11")
#loc66 = loc("dot.22")
#loc67 = loc("transpose.23")
#loc68 = loc("concatenate.24")
#loc69 = loc("cosine.104")
#loc70 = loc("convert.107")
#loc71 = loc("reshape.108")
#loc72 = loc("convert.109")
#loc73 = loc("reshape.111")
#loc74 = loc("broadcast.112")
#loc75 = loc("multiply.113")
#loc76 = loc("convert.114")
#loc77 = loc("slice.95")
#loc78 = loc("negate.96")
#loc79 = loc("slice.94")
#loc80 = loc("concatenate.97")
#loc81 = loc("convert.98")
#loc82 = loc("sine.25")
#loc83 = loc("convert.28")
#loc84 = loc("reshape.29")
#loc85 = loc("convert.30")
#loc86 = loc("reshape.99")
#loc87 = loc("broadcast.100")
#loc88 = loc("multiply.101")
#loc89 = loc("convert.102")
#loc90 = loc("add.117")
#loc91 = loc("scatter.136")
#loc92 = loc("reshape.140")
#loc93 = loc("reshape.142")
#loc94 = loc("transpose.143")
#loc95 = loc("dot.145")
#loc96 = loc("reshape.147")
#loc97 = loc("transpose.148")
#loc98 = loc("scatter.166")
#loc99 = loc("reshape.436")
#loc100 = loc("reshape.438")
#loc101 = loc("convert.439")
#loc102 = loc("broadcast.440")
#loc103 = loc("reshape.270")
#loc104 = loc("reshape.272")
#loc105 = loc("transpose.273")
#loc106 = loc("dot.275")
#loc107 = loc("reshape.277")
#loc108 = loc("transpose.278")
#loc109 = loc("convert.289")
#loc110 = loc("broadcast.291")
#loc111 = loc("multiply.292")
#loc112 = loc("convert.293")
#loc113 = loc("slice.280")
#loc114 = loc("negate.281")
#loc115 = loc("slice.279")
#loc116 = loc("concatenate.282")
#loc117 = loc("convert.283")
#loc118 = loc("broadcast.285")
#loc119 = loc("multiply.286")
#loc120 = loc("convert.287")
#loc121 = loc("add.296")
#loc122 = loc("reshape.298")
#loc123 = loc("broadcast.262")
#loc124 = loc("reshape.263")
#loc125 = loc("transpose.264")
#loc126 = loc("reshape.266")
#loc127 = loc("dot.299")
#loc128 = loc("reshape.300")
#loc129 = loc("convert.301")
#loc130 = loc("broadcast.302")
#loc131 = loc("multiply.303")
#loc132 = loc("convert.304")
#loc133 = loc("broadcast.235")
#loc134 = loc("broadcast.237")
#loc135 = loc("subtract.238")
#loc136 = loc("compare.240")
#loc137 = loc("broadcast.224")
#loc138 = loc("select.242")
#loc139 = loc("convert.243")
#loc140 = loc("broadcast.211")
#loc141 = loc("compare.212")
#loc142 = loc("convert.213")
#loc143 = loc("multiply.244")
#loc144 = loc("convert.245")
#loc145 = loc("reshape.246")
#loc146 = loc("broadcast.308")
#loc147 = loc("add.309")
#loc148 = loc("convert.310")
#loc149 = loc("reduce.316")
#loc150 = loc("broadcast.317")
#loc151 = loc("subtract.318")
#loc152 = loc("exponential.319")
#loc153 = loc("reduce.325")
#loc154 = loc("broadcast.326")
#loc155 = loc("divide.327")
#loc156 = loc("convert.328")
#loc157 = loc("reshape.330")
#loc158 = loc("broadcast.202")
#loc159 = loc("reshape.205")
#loc160 = loc("dot.331")
#loc161 = loc("reshape.332")
#loc162 = loc("transpose.333")
#loc163 = loc("reshape.335")
#loc164 = loc("reshape.191")
#loc165 = loc("reshape.193")
#loc166 = loc("transpose.194")
#loc167 = loc("dot.336")
#loc168 = loc("reshape.337")
#loc169 = loc("add.340")
#loc170 = loc("reshape.372")
#loc171 = loc("reshape.374")
#loc172 = loc("convert.375")
#loc173 = loc("broadcast.376")
#loc174 = loc("convert.341")
#loc175 = loc("power.343")
#loc176 = loc("reduce.350")
#loc177 = loc("multiply.359")
#loc178 = loc("reshape.360")
#loc179 = loc("add.364")
#loc180 = loc("rsqrt.365")
#loc181 = loc("reshape.366")
#loc182 = loc("broadcast.367")
#loc183 = loc("multiply.368")
#loc184 = loc("convert.369")
#loc185 = loc("convert.370")
#loc186 = loc("multiply.377")
#loc187 = loc("convert.378")
#loc188 = loc("reshape.388")
#loc189 = loc("reshape.384")
#loc190 = loc("reshape.386")
#loc191 = loc("transpose.387")
#loc192 = loc("dot.389")
#loc193 = loc("reshape.390")
#loc194 = loc("convert.393")
#loc195 = loc("logistic.391")
#loc196 = loc("convert.392")
#loc197 = loc("multiply.394")
#loc198 = loc("convert.395")
#loc199 = loc("convert.396")
#loc200 = loc("reshape.183")
#loc201 = loc("reshape.185")
#loc202 = loc("transpose.186")
#loc203 = loc("dot.380")
#loc204 = loc("reshape.381")
#loc205 = loc("convert.382")
#loc206 = loc("multiply.397")
#loc207 = loc("convert.398")
#loc208 = loc("reshape.399")
#loc209 = loc("reshape.178")
#loc210 = loc("reshape.180")
#loc211 = loc("transpose.181")
#loc212 = loc("dot.400")
#loc213 = loc("reshape.401")
#loc214 = loc("add.404")
#loc215 = loc("convert.405")
#loc216 = loc("power.407")
#loc217 = loc("reduce.414")
#loc218 = loc("multiply.423")
#loc219 = loc("reshape.424")
#loc220 = loc("add.428")
#loc221 = loc("rsqrt.429")
#loc222 = loc("reshape.430")
#loc223 = loc("broadcast.431")
#loc224 = loc("multiply.432")
#loc225 = loc("convert.433")
#loc226 = loc("convert.434")
#loc227 = loc("multiply.441")
#loc228 = loc("convert.442")
#loc229 = loc("reshape.446")
#loc230 = loc("reshape.170")
#loc231 = loc("reshape.172")
#loc232 = loc("transpose.173")
#loc233 = loc("dot.447")
#loc234 = loc("reshape.448")
2025-09-22 18:07:09.764 (   9.450s) [        A88F8000]      module_builder.cc:550   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2025-09-22 18:07:09.764 (   9.450s) [        A88F8000]      module_builder.cc:564   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2025-09-22 18:07:09.764 (   9.450s) [        A88F8000]      module_builder.cc:574   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2025-09-22 18:07:09.858 (   9.544s) [        A88F8000]      module_builder.cc:621      1| TTNN Module:
#dram = #ttnn.buffer_type<dram>
#loc = loc(unknown)
#loc22 = loc("p0.3")
#loc23 = loc("p1.13")
#loc24 = loc("p2.31")
#loc25 = loc("p3.37")
#loc26 = loc("p4.39")
#loc27 = loc("p5.44")
#loc28 = loc("p6.81")
#loc29 = loc("p7.118")
#loc30 = loc("p8.130")
#loc31 = loc("p9.139")
#loc32 = loc("p10.160")
#loc33 = loc("p11.169")
#loc34 = loc("p12.177")
#loc35 = loc("p13.182")
#loc36 = loc("p14.190")
#loc37 = loc("p15.220")
#loc38 = loc("p16.254")
#loc39 = loc("p17.269")
#loc40 = loc("p18.371")
#loc41 = loc("p19.383")
#loc42 = loc("p20.435")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout11 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout12 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout13 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout14 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout15 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout16 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout17 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout18 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout19 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout20 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout21 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout22 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout23 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout24 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout25 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout26 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout27 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout28 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 16 + d2, d3), <1x1>, memref<128x128xbf16, #system_memory>>
#ttnn_layout29 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x128256xbf16, #system_memory>>
#ttnn_layout30 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x128256xbf16, #system_memory>>
#ttnn_layout31 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout32 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout33 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout34 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #system_memory>>
#ttnn_layout35 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #system_memory>>
#ttnn_layout36 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x7xui32, #dram>, <interleaved>>
#ttnn_layout37 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout38 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout39 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 224 + d1 * 32 + d2, d3), <1x1>, memref<7x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout40 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout41 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout42 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout43 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout44 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout45 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout46 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout47 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout48 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout49 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout50 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout51 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout52 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout53 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout54 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout55 = #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 128 + d1 * 32 + d2 * 32 + d3, d4), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout56 = #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 384 + d1 * 96 + d2 * 32 + d3, d4), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout57 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout58 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout59 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout60 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout61 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout62 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout63 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout64 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout65 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout66 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout67 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout68 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 16 + d2, d3), <1x1>, memref<64x128xbf16, #dram>, <interleaved>>
#ttnn_layout69 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 16 + d2, d3), <1x1>, memref<64x128xbf16, #system_memory>>
#ttnn_layout70 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<7x128256xbf16, #dram>, <interleaved>>
#ttnn_layout71 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 7 + d1, d2), <1x1>, memref<7x128256xbf16, #dram>, <interleaved>>
module @SyncTensorsGraph.450 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.450 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]> loc(#loc)
      func.func @main_const_eval_0(%arg0: tensor<1024x3072xbf16, #ttnn_layout> loc(unknown)) -> tensor<512x3072xbf16, #ttnn_layout1> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn_layout>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn_layout1> loc(#loc)
        return %1 : tensor<512x3072xbf16, #ttnn_layout1> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_1(%arg0: tensor<3072x8192xbf16, #ttnn_layout2> loc(unknown)) -> tensor<3072x4096xbf16, #ttnn_layout3> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn_layout2>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn_layout3> loc(#loc)
        return %1 : tensor<3072x4096xbf16, #ttnn_layout3> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_2(%arg0: tensor<f32, #ttnn_layout4> loc(unknown)) -> tensor<12x7x16xf32, #ttnn_layout5> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn_layout4>, !ttnn.device) -> tensor<f32, #ttnn_layout4> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout4>) -> tensor<1x1x1x1xf32, #ttnn_layout6> loc(#loc1)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn_layout4>) -> () loc(#loc1)
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<1x12x7x16>}> : (tensor<1x1x1x1xf32, #ttnn_layout6>) -> tensor<1x12x7x16xf32, #ttnn_layout7> loc(#loc1)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn_layout6>) -> () loc(#loc1)
        %4 = "ttnn.reshape"(%3) <{shape = [12 : i32, 7 : i32, 16 : i32]}> : (tensor<1x12x7x16xf32, #ttnn_layout7>) -> tensor<12x7x16xf32, #ttnn_layout5> loc(#loc2)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x12x7x16xf32, #ttnn_layout7>) -> () loc(#loc2)
        return %4 : tensor<12x7x16xf32, #ttnn_layout5> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_3(%arg0: tensor<3072x3072xbf16, #ttnn_layout8> loc(unknown)) -> tensor<3072x1536xbf16, #ttnn_layout9> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn_layout8>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn_layout9> loc(#loc)
        return %1 : tensor<3072x1536xbf16, #ttnn_layout9> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_4(%arg0: tensor<3072x3072xbf16, #ttnn_layout8> loc(unknown)) -> tensor<1536x3072xbf16, #ttnn_layout10> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn_layout8>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn_layout10> loc(#loc)
        return %1 : tensor<1536x3072xbf16, #ttnn_layout10> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_5(%arg0: tensor<f32, #ttnn_layout4> loc(unknown)) -> (tensor<1x7xf32, #ttnn_layout11>, tensor<1x7xf32, #ttnn_layout11>, tensor<1x7xf32, #ttnn_layout11>) attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn_layout4>, !ttnn.device) -> tensor<f32, #ttnn_layout4> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout4>) -> tensor<1x1xf32, #ttnn_layout11> loc(#loc181)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn_layout4>) -> () loc(#loc181)
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<7x1>}> : (tensor<1x1xf32, #ttnn_layout11>) -> tensor<7x1xf32, #ttnn_layout11> loc(#loc4)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1xf32, #ttnn_layout11>) -> () loc(#loc4)
        %4 = "ttnn.reshape"(%3) <{shape = [1 : i32, 7 : i32]}> : (tensor<7x1xf32, #ttnn_layout11>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc5)
        %5 = "ttnn.reshape"(%3) <{shape = [1 : i32, 7 : i32]}> : (tensor<7x1xf32, #ttnn_layout11>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc6)
        %6 = "ttnn.reshape"(%3) <{shape = [1 : i32, 7 : i32]}> : (tensor<7x1xf32, #ttnn_layout11>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc7)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<7x1xf32, #ttnn_layout11>) -> () loc(#loc7)
        return %4, %5, %6 : tensor<1x7xf32, #ttnn_layout11>, tensor<1x7xf32, #ttnn_layout11>, tensor<1x7xf32, #ttnn_layout11> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_6(%arg0: tensor<8192x3072xbf16, #ttnn_layout12> loc(unknown)) -> tensor<4096x3072xbf16, #ttnn_layout13> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn_layout12>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn_layout13> loc(#loc)
        return %1 : tensor<4096x3072xbf16, #ttnn_layout13> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_7(%arg0: tensor<3072xbf16, #ttnn_layout14> loc(unknown)) -> tensor<1x3072xf32, #ttnn_layout15> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn_layout14>, !ttnn.device) -> tensor<3072xbf16, #ttnn_layout14> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn_layout14>) -> tensor<1x3072xbf16, #ttnn_layout16> loc(#loc171)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072xbf16, #ttnn_layout14>) -> () loc(#loc171)
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn_layout16>) -> tensor<1x3072xf32, #ttnn_layout15> loc(#loc9)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout16>) -> () loc(#loc9)
        return %3 : tensor<1x3072xf32, #ttnn_layout15> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_8(%arg0: tensor<8192x3072xbf16, #ttnn_layout12> loc(unknown)) -> tensor<4096x3072xbf16, #ttnn_layout13> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn_layout12>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn_layout13> loc(#loc)
        return %1 : tensor<4096x3072xbf16, #ttnn_layout13> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_9(%arg0: tensor<128256x3072xbf16, #ttnn_layout17> loc(unknown)) -> tensor<128256x3072xbf16, #ttnn_layout17> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16, #ttnn_layout17>, !ttnn.device) -> tensor<128256x3072xbf16, #ttnn_layout17> loc(#loc)
        return %1 : tensor<128256x3072xbf16, #ttnn_layout17> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_10(%arg0: tensor<1024x3072xbf16, #ttnn_layout> loc(unknown)) -> tensor<512x3072xbf16, #ttnn_layout1> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn_layout>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn_layout1> loc(#loc)
        return %1 : tensor<512x3072xbf16, #ttnn_layout1> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_11(%arg0: tensor<3072xbf16, #ttnn_layout14> loc(unknown)) -> tensor<1x3072xf32, #ttnn_layout15> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn_layout14>, !ttnn.device) -> tensor<3072xbf16, #ttnn_layout14> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn_layout14>) -> tensor<1x3072xbf16, #ttnn_layout16> loc(#loc172)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072xbf16, #ttnn_layout14>) -> () loc(#loc172)
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn_layout16>) -> tensor<1x3072xf32, #ttnn_layout15> loc(#loc10)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout16>) -> () loc(#loc10)
        return %3 : tensor<1x3072xf32, #ttnn_layout15> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_12(%arg0: tensor<3072xbf16, #ttnn_layout14> loc(unknown)) -> tensor<1x3072xf32, #ttnn_layout15> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn_layout14>, !ttnn.device) -> tensor<3072xbf16, #ttnn_layout14> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn_layout14>) -> tensor<1x3072xbf16, #ttnn_layout16> loc(#loc173)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072xbf16, #ttnn_layout14>) -> () loc(#loc173)
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn_layout16>) -> tensor<1x3072xf32, #ttnn_layout15> loc(#loc12)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout16>) -> () loc(#loc12)
        return %3 : tensor<1x3072xf32, #ttnn_layout15> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_13() -> tensor<1x1x1xf32, #ttnn_layout18> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 2.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn_layout4> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout4>) -> tensor<1x1x1xf32, #ttnn_layout18> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn_layout4>) -> () loc(#loc)
        return %2 : tensor<1x1x1xf32, #ttnn_layout18> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_14(%arg0: tensor<128256x3072xbf16, #ttnn_layout17> loc(unknown)) -> tensor<128256x3072xbf16, #ttnn_layout17> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16, #ttnn_layout17>, !ttnn.device) -> tensor<128256x3072xbf16, #ttnn_layout17> loc(#loc)
        return %1 : tensor<128256x3072xbf16, #ttnn_layout17> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_15(%arg0: tensor<bf16, #ttnn_layout19> loc(unknown)) -> (tensor<1x1x7x16xf32, #ttnn_layout6>, tensor<1x1x7x16xf32, #ttnn_layout6>) attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]> : tensor<16xsi32>}> : (!ttnn.device) -> tensor<16xsi32, #ttnn_layout20> loc(#loc)
        %2 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xsi32>}> : (!ttnn.device) -> tensor<7xsi32, #ttnn_layout20> loc(#loc)
        %3 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout19> loc(#loc)
        %4 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = 1 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn_layout21> loc(#loc)
        %5 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<bf16, #ttnn_layout19>, !ttnn.device) -> tensor<bf16, #ttnn_layout19> loc(#loc)
        %6 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout19>) -> tensor<1x1xbf16, #ttnn_layout22> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<bf16, #ttnn_layout19>) -> () loc(#loc)
        %7 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32]}> : (tensor<si32, #ttnn_layout21>) -> tensor<1x1xsi32, #ttnn_layout23> loc(#loc)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<si32, #ttnn_layout21>) -> () loc(#loc)
        %8 = "ttnn.reshape"(%1) <{shape = [1 : i32, 16 : i32]}> : (tensor<16xsi32, #ttnn_layout20>) -> tensor<1x16xsi32, #ttnn_layout23> loc(#loc13)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<16xsi32, #ttnn_layout20>) -> () loc(#loc13)
        %9 = "ttnn.repeat"(%8) <{repeat_dims = #ttnn.shape<7x1>}> : (tensor<1x16xsi32, #ttnn_layout23>) -> tensor<7x16xsi32, #ttnn_layout23> loc(#loc13)
        %10 = "ttnn.reshape"(%2) <{shape = [7 : i32, 1 : i32]}> : (tensor<7xsi32, #ttnn_layout20>) -> tensor<7x1xsi32, #ttnn_layout23> loc(#loc14)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<7xsi32, #ttnn_layout20>) -> () loc(#loc14)
        %11 = "ttnn.neg"(%10) : (tensor<7x1xsi32, #ttnn_layout23>) -> tensor<7x1xsi32, #ttnn_layout23> loc(#loc147)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<7x1xsi32, #ttnn_layout23>) -> () loc(#loc147)
        %12 = "ttnn.add"(%8, %11) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<1x16xsi32, #ttnn_layout23>, tensor<7x1xsi32, #ttnn_layout23>) -> tensor<7x16xsi32, #ttnn_layout23> loc(#loc15)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<7x1xsi32, #ttnn_layout23>) -> () loc(#loc15)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x16xsi32, #ttnn_layout23>) -> () loc(#loc15)
        %13 = "ttnn.typecast"(%12) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x16xsi32, #ttnn_layout23>) -> tensor<7x16xf32, #ttnn_layout11> loc(#loc148)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<7x16xsi32, #ttnn_layout23>) -> () loc(#loc148)
        %14 = "ttnn.typecast"(%7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xsi32, #ttnn_layout23>) -> tensor<1x1xf32, #ttnn_layout11> loc(#loc148)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1xsi32, #ttnn_layout23>) -> () loc(#loc148)
        %15 = "ttnn.ge"(%13, %14) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x16xf32, #ttnn_layout11>, tensor<1x1xf32, #ttnn_layout11>) -> tensor<7x16xf32, #ttnn_layout11> loc(#loc16)
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<1x1xf32, #ttnn_layout11>) -> () loc(#loc16)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<7x16xf32, #ttnn_layout11>) -> () loc(#loc16)
        %16 = "ttnn.typecast"(%15) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x16xf32, #ttnn_layout11>) -> tensor<7x16xbf16, #ttnn_layout22> loc(#loc148)
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<7x16xf32, #ttnn_layout11>) -> () loc(#loc148)
        %17 = "ttnn.reshape"(%5) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout19>) -> tensor<1x1xbf16, #ttnn_layout22> loc(#loc17)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<bf16, #ttnn_layout19>) -> () loc(#loc17)
        %18 = "ttnn.repeat"(%17) <{repeat_dims = #ttnn.shape<7x16>}> : (tensor<1x1xbf16, #ttnn_layout22>) -> tensor<7x16xbf16, #ttnn_layout22> loc(#loc18)
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<1x1xbf16, #ttnn_layout22>) -> () loc(#loc18)
        %19 = "ttnn.repeat"(%6) <{repeat_dims = #ttnn.shape<7x16>}> : (tensor<1x1xbf16, #ttnn_layout22>) -> tensor<7x16xbf16, #ttnn_layout22> loc(#loc18)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1x1xbf16, #ttnn_layout22>) -> () loc(#loc18)
        %20 = "ttnn.where"(%16, %18, %19) : (tensor<7x16xbf16, #ttnn_layout22>, tensor<7x16xbf16, #ttnn_layout22>, tensor<7x16xbf16, #ttnn_layout22>) -> tensor<7x16xbf16, #ttnn_layout22> loc(#loc18)
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<7x16xbf16, #ttnn_layout22>) -> () loc(#loc18)
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<7x16xbf16, #ttnn_layout22>) -> () loc(#loc18)
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<7x16xbf16, #ttnn_layout22>) -> () loc(#loc18)
        %21 = "ttnn.reshape"(%20) <{shape = [1 : i32, 1 : i32, 7 : i32, 16 : i32]}> : (tensor<7x16xbf16, #ttnn_layout22>) -> tensor<1x1x7x16xbf16, #ttnn_layout24> loc(#loc174)
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<7x16xbf16, #ttnn_layout22>) -> () loc(#loc174)
        %22 = "ttnn.typecast"(%21) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x16xbf16, #ttnn_layout24>) -> tensor<1x1x7x16xf32, #ttnn_layout6> loc(#loc20)
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<1x1x7x16xbf16, #ttnn_layout24>) -> () loc(#loc20)
        %23 = "ttnn.reshape"(%9) <{shape = [1 : i32, 1 : i32, 7 : i32, 16 : i32]}> : (tensor<7x16xsi32, #ttnn_layout23>) -> tensor<1x1x7x16xsi32, #ttnn_layout25> loc(#loc179)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<7x16xsi32, #ttnn_layout23>) -> () loc(#loc179)
        %24 = "ttnn.typecast"(%23) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x16xsi32, #ttnn_layout25>) -> tensor<1x1x7x16xf32, #ttnn_layout6> loc(#loc150)
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<1x1x7x16xsi32, #ttnn_layout25>) -> () loc(#loc150)
        return %22, %24 : tensor<1x1x7x16xf32, #ttnn_layout6>, tensor<1x1x7x16xf32, #ttnn_layout6> loc(#loc)
      } loc(#loc)
      func.func @main(%arg0: tensor<7xsi32, #ttnn_layout20> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32, #ttnn_layout26> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.31"), %arg3: tensor<f32, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"} loc("p3.37"), %arg4: tensor<1x7xsi32, #ttnn_layout23> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p4.39"), %arg5: tensor<128256x3072xbf16, #ttnn_layout17> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p5.44"), %arg6: tensor<3072xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p6.81"), %arg7: tensor<si32, #ttnn_layout21> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"} loc("p7.118"), %arg8: tensor<1x8x16x128xbf16, #ttnn_layout27> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p8.130"), %arg9: tensor<1024x3072xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p9.139"), %arg10: tensor<1x8x16x128xbf16, #ttnn_layout27> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p10.160"), %arg11: tensor<128256x3072xbf16, #ttnn_layout17> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"} loc("p11.169"), %arg12: tensor<3072x8192xbf16, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p12.177"), %arg13: tensor<8192x3072xbf16, #ttnn_layout12> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p13.182"), %arg14: tensor<3072x3072xbf16, #ttnn_layout8> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p14.190"), %arg15: tensor<bf16, #ttnn_layout19> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"} loc("p15.220"), %arg16: tensor<f32, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"} loc("p16.254"), %arg17: tensor<3072x3072xbf16, #ttnn_layout8> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p17.269"), %arg18: tensor<3072xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p18.371"), %arg19: tensor<8192x3072xbf16, #ttnn_layout12> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p19.383"), %arg20: tensor<3072xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"} loc("p20.435")) -> (tensor<1x8x16x128xbf16, #ttnn_layout28> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x16x128xbf16, #ttnn_layout28> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<7x128256xbf16, #ttnn_layout29> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x7x128256xbf16, #ttnn_layout30> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, [%arg2]) : (tensor<1024x3072xbf16, #ttnn_layout>) -> tensor<512x3072xbf16, #ttnn_layout1> loc(#loc)
        "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<si32, #ttnn_layout21>) -> () loc(#loc)
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<1024x3072xbf16, #ttnn_layout>) -> () loc(#loc)
        %1 = ttcore.load_cached(@main_const_eval_1, [%arg12]) : (tensor<3072x8192xbf16, #ttnn_layout2>) -> tensor<3072x4096xbf16, #ttnn_layout3> loc(#loc)
        "ttnn.deallocate"(%arg12) <{force = false}> : (tensor<3072x8192xbf16, #ttnn_layout2>) -> () loc(#loc)
        %2 = ttcore.load_cached(@main_const_eval_2, [%arg16]) : (tensor<f32, #ttnn_layout4>) -> tensor<12x7x16xf32, #ttnn_layout5> loc(#loc)
        "ttnn.deallocate"(%arg16) <{force = false}> : (tensor<f32, #ttnn_layout4>) -> () loc(#loc)
        %3 = ttcore.load_cached(@main_const_eval_3, [%arg14]) : (tensor<3072x3072xbf16, #ttnn_layout8>) -> tensor<3072x1536xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%arg14) <{force = false}> : (tensor<3072x3072xbf16, #ttnn_layout8>) -> () loc(#loc)
        %4 = ttcore.load_cached(@main_const_eval_4, [%arg17]) : (tensor<3072x3072xbf16, #ttnn_layout8>) -> tensor<1536x3072xbf16, #ttnn_layout10> loc(#loc)
        "ttnn.deallocate"(%arg17) <{force = false}> : (tensor<3072x3072xbf16, #ttnn_layout8>) -> () loc(#loc)
        %5:3 = ttcore.load_cached(@main_const_eval_5, [%arg3]) : (tensor<f32, #ttnn_layout4>) -> (tensor<1x7xf32, #ttnn_layout11>, tensor<1x7xf32, #ttnn_layout11>, tensor<1x7xf32, #ttnn_layout11>) loc(#loc)
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<f32, #ttnn_layout4>) -> () loc(#loc)
        %6 = ttcore.load_cached(@main_const_eval_6, [%arg13]) : (tensor<8192x3072xbf16, #ttnn_layout12>) -> tensor<4096x3072xbf16, #ttnn_layout13> loc(#loc)
        "ttnn.deallocate"(%arg13) <{force = false}> : (tensor<8192x3072xbf16, #ttnn_layout12>) -> () loc(#loc)
        %7 = ttcore.load_cached(@main_const_eval_7, [%arg18]) : (tensor<3072xbf16, #ttnn_layout14>) -> tensor<1x3072xf32, #ttnn_layout15> loc(#loc)
        "ttnn.deallocate"(%arg18) <{force = false}> : (tensor<3072xbf16, #ttnn_layout14>) -> () loc(#loc)
        %8 = ttcore.load_cached(@main_const_eval_8, [%arg19]) : (tensor<8192x3072xbf16, #ttnn_layout12>) -> tensor<4096x3072xbf16, #ttnn_layout13> loc(#loc)
        "ttnn.deallocate"(%arg19) <{force = false}> : (tensor<8192x3072xbf16, #ttnn_layout12>) -> () loc(#loc)
        %9 = ttcore.load_cached(@main_const_eval_9, [%arg5]) : (tensor<128256x3072xbf16, #ttnn_layout17>) -> tensor<128256x3072xbf16, #ttnn_layout17> loc(#loc)
        "ttnn.deallocate"(%arg5) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout17>) -> () loc(#loc)
        %10 = ttcore.load_cached(@main_const_eval_10, [%arg9]) : (tensor<1024x3072xbf16, #ttnn_layout>) -> tensor<512x3072xbf16, #ttnn_layout1> loc(#loc)
        "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<1024x3072xbf16, #ttnn_layout>) -> () loc(#loc)
        %11 = ttcore.load_cached(@main_const_eval_11, [%arg6]) : (tensor<3072xbf16, #ttnn_layout14>) -> tensor<1x3072xf32, #ttnn_layout15> loc(#loc)
        "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<3072xbf16, #ttnn_layout14>) -> () loc(#loc)
        %12 = ttcore.load_cached(@main_const_eval_12, [%arg20]) : (tensor<3072xbf16, #ttnn_layout14>) -> tensor<1x3072xf32, #ttnn_layout15> loc(#loc)
        "ttnn.deallocate"(%arg20) <{force = false}> : (tensor<3072xbf16, #ttnn_layout14>) -> () loc(#loc)
        %13 = ttcore.load_cached(@main_const_eval_13, []) : () -> tensor<1x1x1xf32, #ttnn_layout18> loc(#loc)
        %14 = ttcore.load_cached(@main_const_eval_14, [%arg11]) : (tensor<128256x3072xbf16, #ttnn_layout17>) -> tensor<128256x3072xbf16, #ttnn_layout17> loc(#loc)
        "ttnn.deallocate"(%arg11) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout17>) -> () loc(#loc)
        %15:2 = ttcore.load_cached(@main_const_eval_15, [%arg15]) : (tensor<bf16, #ttnn_layout19>) -> (tensor<1x1x7x16xf32, #ttnn_layout6>, tensor<1x1x7x16xf32, #ttnn_layout6>) loc(#loc)
        "ttnn.deallocate"(%arg15) <{force = false}> : (tensor<bf16, #ttnn_layout19>) -> () loc(#loc)
        %16 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %17 = "ttnn.full"(%16) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 3.25520843E-4 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<1x7>}> : (!ttnn.device) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc)
        %18 = "ttnn.mesh_shard"(%arg0, %16) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<7xsi32, #ttnn_layout20>, !ttnn.device) -> tensor<7xsi32, #ttnn_layout20> loc(#loc)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<7xsi32, #ttnn_layout20>) -> () loc(#loc)
        %19 = "ttnn.mesh_shard"(%arg1, %16) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32, #ttnn_layout26>, !ttnn.device) -> tensor<64xf32, #ttnn_layout26> loc(#loc)
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<64xf32, #ttnn_layout26>) -> () loc(#loc)
        %20 = "ttnn.mesh_shard"(%arg4, %16) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x7xsi32, #ttnn_layout23>, !ttnn.device) -> tensor<1x7xsi32, #ttnn_layout23> loc(#loc)
        "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<1x7xsi32, #ttnn_layout23>) -> () loc(#loc)
        %21 = "ttnn.mesh_shard"(%arg8, %16) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x16x128xbf16, #ttnn_layout27>, !ttnn.device) -> tensor<1x4x16x128xbf16, #ttnn_layout31> loc(#loc)
        "ttnn.deallocate"(%arg8) <{force = false}> : (tensor<1x8x16x128xbf16, #ttnn_layout27>) -> () loc(#loc)
        %22 = "ttnn.mesh_shard"(%arg10, %16) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x16x128xbf16, #ttnn_layout27>, !ttnn.device) -> tensor<1x4x16x128xbf16, #ttnn_layout31> loc(#loc)
        "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<1x8x16x128xbf16, #ttnn_layout27>) -> () loc(#loc)
        %23 = "ttnn.typecast"(%20) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x7xsi32, #ttnn_layout23>) -> tensor<1x7xui32, #ttnn_layout32> loc(#loc43)
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<1x7xsi32, #ttnn_layout23>) -> () loc(#loc43)
        %24 = "ttnn.reshape"(%23) <{shape = [7 : i32]}> : (tensor<1x7xui32, #ttnn_layout32>) -> tensor<7xui32, #ttnn_layout33> loc(#loc43)
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<1x7xui32, #ttnn_layout32>) -> () loc(#loc43)
        %25 = "ttnn.from_device"(%24) : (tensor<7xui32, #ttnn_layout33>) -> tensor<7xui32, #ttnn_layout34> loc(#loc151)
        "ttnn.deallocate"(%24) <{force = false}> : (tensor<7xui32, #ttnn_layout33>) -> () loc(#loc151)
        %26 = "ttnn.to_layout"(%25) <{layout = #ttnn.layout<row_major>}> : (tensor<7xui32, #ttnn_layout34>) -> tensor<7xui32, #ttnn_layout35> loc(#loc151)
        "ttnn.deallocate"(%25) <{force = false}> : (tensor<7xui32, #ttnn_layout34>) -> () loc(#loc151)
        %27 = "ttnn.to_device"(%26, %16) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<7xui32, #ttnn_layout35>, !ttnn.device) -> tensor<7xui32, #ttnn_layout36> loc(#loc151)
        "ttnn.deallocate"(%26) <{force = false}> : (tensor<7xui32, #ttnn_layout35>) -> () loc(#loc151)
        %28 = "ttnn.embedding"(%27, %9) : (tensor<7xui32, #ttnn_layout36>, tensor<128256x3072xbf16, #ttnn_layout17>) -> tensor<7x3072xbf16, #ttnn_layout16> loc(#loc44)
        "ttnn.deallocate"(%27) <{force = false}> : (tensor<7xui32, #ttnn_layout36>) -> () loc(#loc44)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout17>) -> () loc(#loc44)
        %29 = "ttnn.typecast"(%28) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> tensor<7x3072xf32, #ttnn_layout15> loc(#loc45)
        %30 = "ttnn.reshape"(%29) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn_layout15>) -> tensor<1x7x3072xf32, #ttnn_layout37> loc(#loc45)
        %31 = "ttnn.pow"(%30, %13) : (tensor<1x7x3072xf32, #ttnn_layout37>, tensor<1x1x1xf32, #ttnn_layout18>) -> tensor<1x7x3072xf32, #ttnn_layout37> loc(#loc46)
        "ttnn.deallocate"(%30) <{force = false}> : (tensor<1x7x3072xf32, #ttnn_layout37>) -> () loc(#loc46)
        %32 = "ttnn.sum"(%31) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn_layout37>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc47)
        "ttnn.deallocate"(%31) <{force = false}> : (tensor<1x7x3072xf32, #ttnn_layout37>) -> () loc(#loc47)
        %33 = "ttnn.multiply"(%32, %17) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn_layout11>, tensor<1x7xf32, #ttnn_layout11>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc5)
        "ttnn.deallocate"(%32) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc5)
        %34 = "ttnn.add"(%33, %5#0) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn_layout11>, tensor<1x7xf32, #ttnn_layout11>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc48)
        "ttnn.deallocate"(%33) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc48)
        "ttnn.deallocate"(%5#0) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc48)
        %35 = "ttnn.rsqrt"(%34) : (tensor<1x7xf32, #ttnn_layout11>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc49)
        "ttnn.deallocate"(%34) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc49)
        %36 = "ttnn.reshape"(%35) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn_layout11>) -> tensor<7x1xf32, #ttnn_layout11> loc(#loc49)
        "ttnn.deallocate"(%35) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc49)
        %37 = "ttnn.multiply"(%29, %36) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn_layout15>, tensor<7x1xf32, #ttnn_layout11>) -> tensor<7x3072xf32, #ttnn_layout15> loc(#loc50)
        "ttnn.deallocate"(%36) <{force = false}> : (tensor<7x1xf32, #ttnn_layout11>) -> () loc(#loc50)
        "ttnn.deallocate"(%29) <{force = false}> : (tensor<7x3072xf32, #ttnn_layout15>) -> () loc(#loc50)
        %38 = "ttnn.multiply"(%11, %37) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn_layout15>, tensor<7x3072xf32, #ttnn_layout15>) -> tensor<7x3072xf32, #ttnn_layout15> loc(#loc51)
        "ttnn.deallocate"(%37) <{force = false}> : (tensor<7x3072xf32, #ttnn_layout15>) -> () loc(#loc51)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout15>) -> () loc(#loc51)
        %39 = "ttnn.typecast"(%38) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn_layout15>) -> tensor<7x3072xbf16, #ttnn_layout16> loc(#loc52)
        "ttnn.deallocate"(%38) <{force = false}> : (tensor<7x3072xf32, #ttnn_layout15>) -> () loc(#loc52)
        %40 = "ttnn.matmul"(%39, %0) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn_layout16>, tensor<512x3072xbf16, #ttnn_layout1>) -> tensor<7x512xbf16, #ttnn_layout38> loc(#loc53)
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<512x3072xbf16, #ttnn_layout1>) -> () loc(#loc53)
        %41 = "ttnn.reshape"(%40) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn_layout38>) -> tensor<1x7x4x128xbf16, #ttnn_layout39> loc(#loc54)
        "ttnn.deallocate"(%40) <{force = false}> : (tensor<7x512xbf16, #ttnn_layout38>) -> () loc(#loc54)
        %42 = "ttnn.permute"(%41) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn_layout39>) -> tensor<1x4x7x128xbf16, #ttnn_layout31> loc(#loc55)
        "ttnn.deallocate"(%41) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn_layout39>) -> () loc(#loc55)
        %43 = "ttnn.typecast"(%42) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn_layout31>) -> tensor<1x4x7x128xf32, #ttnn_layout40> loc(#loc56)
        %44 = "ttnn.reshape"(%19) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32, #ttnn_layout26>) -> tensor<1x64x1xf32, #ttnn_layout41> loc(#loc57)
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<64xf32, #ttnn_layout26>) -> () loc(#loc57)
        %45 = "ttnn.typecast"(%18) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7xsi32, #ttnn_layout20>) -> tensor<7xf32, #ttnn_layout42> loc(#loc58)
        %46 = "ttnn.reshape"(%45) <{shape = [1 : i32, 1 : i32, 7 : i32]}> : (tensor<7xf32, #ttnn_layout42>) -> tensor<1x1x7xf32, #ttnn_layout18> loc(#loc58)
        "ttnn.deallocate"(%45) <{force = false}> : (tensor<7xf32, #ttnn_layout42>) -> () loc(#loc58)
        %47 = "ttnn.matmul"(%44, %46) <{transpose_a = false, transpose_b = false}> : (tensor<1x64x1xf32, #ttnn_layout41>, tensor<1x1x7xf32, #ttnn_layout18>) -> tensor<1x64x7xf32, #ttnn_layout41> loc(#loc59)
        "ttnn.deallocate"(%46) <{force = false}> : (tensor<1x1x7xf32, #ttnn_layout18>) -> () loc(#loc59)
        "ttnn.deallocate"(%44) <{force = false}> : (tensor<1x64x1xf32, #ttnn_layout41>) -> () loc(#loc59)
        %48 = "ttnn.permute"(%47) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x7xf32, #ttnn_layout41>) -> tensor<1x7x64xf32, #ttnn_layout43> loc(#loc60)
        "ttnn.deallocate"(%47) <{force = false}> : (tensor<1x64x7xf32, #ttnn_layout41>) -> () loc(#loc60)
        %49 = "ttnn.reshape"(%48) <{shape = [1 : i32, 1 : i32, 7 : i32, 64 : i32]}> : (tensor<1x7x64xf32, #ttnn_layout43>) -> tensor<1x1x7x64xf32, #ttnn_layout44> loc(#loc61)
        %50 = "ttnn.reshape"(%48) <{shape = [1 : i32, 1 : i32, 7 : i32, 64 : i32]}> : (tensor<1x7x64xf32, #ttnn_layout43>) -> tensor<1x1x7x64xf32, #ttnn_layout44> loc(#loc61)
        "ttnn.deallocate"(%48) <{force = false}> : (tensor<1x7x64xf32, #ttnn_layout43>) -> () loc(#loc61)
        %51 = "ttnn.concat"(%49, %50) <{dim = 3 : si32}> : (tensor<1x1x7x64xf32, #ttnn_layout44>, tensor<1x1x7x64xf32, #ttnn_layout44>) -> tensor<1x1x7x128xf32, #ttnn_layout45> loc(#loc61)
        "ttnn.deallocate"(%50) <{force = false}> : (tensor<1x1x7x64xf32, #ttnn_layout44>) -> () loc(#loc61)
        "ttnn.deallocate"(%49) <{force = false}> : (tensor<1x1x7x64xf32, #ttnn_layout44>) -> () loc(#loc61)
        %52 = "ttnn.cos"(%51) : (tensor<1x1x7x128xf32, #ttnn_layout45>) -> tensor<1x1x7x128xf32, #ttnn_layout45> loc(#loc62)
        %53 = "ttnn.multiply"(%43, %52) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn_layout40>, tensor<1x1x7x128xf32, #ttnn_layout45>) -> tensor<1x4x7x128xf32, #ttnn_layout40> loc(#loc63)
        "ttnn.deallocate"(%43) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn_layout40>) -> () loc(#loc63)
        %54 = "ttnn.typecast"(%53) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn_layout40>) -> tensor<1x4x7x128xbf16, #ttnn_layout31> loc(#loc64)
        "ttnn.deallocate"(%53) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn_layout40>) -> () loc(#loc64)
        %55 = "ttnn.slice_static"(%42) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn_layout31>) -> tensor<1x4x7x64xbf16, #ttnn_layout46> loc(#loc65)
        %56 = "ttnn.neg"(%55) : (tensor<1x4x7x64xbf16, #ttnn_layout46>) -> tensor<1x4x7x64xbf16, #ttnn_layout46> loc(#loc66)
        "ttnn.deallocate"(%55) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn_layout46>) -> () loc(#loc66)
        %57 = "ttnn.slice_static"(%42) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x7x128xbf16, #ttnn_layout31>) -> tensor<1x4x7x64xbf16, #ttnn_layout46> loc(#loc67)
        "ttnn.deallocate"(%42) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn_layout31>) -> () loc(#loc67)
        %58 = "ttnn.concat"(%56, %57) <{dim = 3 : si32}> : (tensor<1x4x7x64xbf16, #ttnn_layout46>, tensor<1x4x7x64xbf16, #ttnn_layout46>) -> tensor<1x4x7x128xbf16, #ttnn_layout31> loc(#loc68)
        "ttnn.deallocate"(%57) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn_layout46>) -> () loc(#loc68)
        "ttnn.deallocate"(%56) <{force = false}> : (tensor<1x4x7x64xbf16, #ttnn_layout46>) -> () loc(#loc68)
        %59 = "ttnn.typecast"(%58) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xbf16, #ttnn_layout31>) -> tensor<1x4x7x128xf32, #ttnn_layout40> loc(#loc69)
        "ttnn.deallocate"(%58) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn_layout31>) -> () loc(#loc69)
        %60 = "ttnn.sin"(%51) : (tensor<1x1x7x128xf32, #ttnn_layout45>) -> tensor<1x1x7x128xf32, #ttnn_layout45> loc(#loc70)
        "ttnn.deallocate"(%51) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn_layout45>) -> () loc(#loc70)
        %61 = "ttnn.multiply"(%59, %60) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x7x128xf32, #ttnn_layout40>, tensor<1x1x7x128xf32, #ttnn_layout45>) -> tensor<1x4x7x128xf32, #ttnn_layout40> loc(#loc71)
        "ttnn.deallocate"(%59) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn_layout40>) -> () loc(#loc71)
        %62 = "ttnn.typecast"(%61) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xf32, #ttnn_layout40>) -> tensor<1x4x7x128xbf16, #ttnn_layout31> loc(#loc72)
        "ttnn.deallocate"(%61) <{force = false}> : (tensor<1x4x7x128xf32, #ttnn_layout40>) -> () loc(#loc72)
        %63 = "ttnn.add"(%54, %62) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x7x128xbf16, #ttnn_layout31>, tensor<1x4x7x128xbf16, #ttnn_layout31>) -> tensor<1x4x7x128xbf16, #ttnn_layout31> loc(#loc73)
        "ttnn.deallocate"(%62) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn_layout31>) -> () loc(#loc73)
        "ttnn.deallocate"(%54) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn_layout31>) -> () loc(#loc73)
        "ttnn.fill_cache"(%21, %63) <{batch_offset = 0 : i32}> : (tensor<1x4x16x128xbf16, #ttnn_layout31>, tensor<1x4x7x128xbf16, #ttnn_layout31>) -> () loc(#loc74)
        "ttnn.deallocate"(%63) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn_layout31>) -> () loc(#loc74)
        %64 = "ttnn.matmul"(%39, %10) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn_layout16>, tensor<512x3072xbf16, #ttnn_layout1>) -> tensor<7x512xbf16, #ttnn_layout38> loc(#loc75)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<512x3072xbf16, #ttnn_layout1>) -> () loc(#loc75)
        %65 = "ttnn.reshape"(%64) <{shape = [1 : i32, 7 : i32, 4 : i32, 128 : i32]}> : (tensor<7x512xbf16, #ttnn_layout38>) -> tensor<1x7x4x128xbf16, #ttnn_layout39> loc(#loc76)
        "ttnn.deallocate"(%64) <{force = false}> : (tensor<7x512xbf16, #ttnn_layout38>) -> () loc(#loc76)
        %66 = "ttnn.permute"(%65) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x4x128xbf16, #ttnn_layout39>) -> tensor<1x4x7x128xbf16, #ttnn_layout31> loc(#loc77)
        "ttnn.deallocate"(%65) <{force = false}> : (tensor<1x7x4x128xbf16, #ttnn_layout39>) -> () loc(#loc77)
        "ttnn.fill_cache"(%22, %66) <{batch_offset = 0 : i32}> : (tensor<1x4x16x128xbf16, #ttnn_layout31>, tensor<1x4x7x128xbf16, #ttnn_layout31>) -> () loc(#loc78)
        "ttnn.deallocate"(%66) <{force = false}> : (tensor<1x4x7x128xbf16, #ttnn_layout31>) -> () loc(#loc78)
        %67 = "ttnn.matmul"(%39, %4) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn_layout16>, tensor<1536x3072xbf16, #ttnn_layout10>) -> tensor<7x1536xbf16, #ttnn_layout47> loc(#loc79)
        "ttnn.deallocate"(%39) <{force = false}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> () loc(#loc79)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1536x3072xbf16, #ttnn_layout10>) -> () loc(#loc79)
        %68 = "ttnn.reshape"(%67) <{shape = [1 : i32, 7 : i32, 12 : i32, 128 : i32]}> : (tensor<7x1536xbf16, #ttnn_layout47>) -> tensor<1x7x12x128xbf16, #ttnn_layout39> loc(#loc80)
        "ttnn.deallocate"(%67) <{force = false}> : (tensor<7x1536xbf16, #ttnn_layout47>) -> () loc(#loc80)
        %69 = "ttnn.permute"(%68) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x12x128xbf16, #ttnn_layout39>) -> tensor<1x12x7x128xbf16, #ttnn_layout48> loc(#loc81)
        "ttnn.deallocate"(%68) <{force = false}> : (tensor<1x7x12x128xbf16, #ttnn_layout39>) -> () loc(#loc81)
        %70 = "ttnn.typecast"(%69) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x128xbf16, #ttnn_layout48>) -> tensor<1x12x7x128xf32, #ttnn_layout49> loc(#loc82)
        %71 = "ttnn.reshape"(%70) <{shape = [12 : i32, 7 : i32, 128 : i32]}> : (tensor<1x12x7x128xf32, #ttnn_layout49>) -> tensor<12x7x128xf32, #ttnn_layout50> loc(#loc82)
        "ttnn.deallocate"(%70) <{force = false}> : (tensor<1x12x7x128xf32, #ttnn_layout49>) -> () loc(#loc82)
        %72 = "ttnn.reshape"(%52) <{shape = [1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x1x7x128xf32, #ttnn_layout45>) -> tensor<1x7x128xf32, #ttnn_layout51> loc(#loc176)
        "ttnn.deallocate"(%52) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn_layout45>) -> () loc(#loc176)
        %73 = "ttnn.multiply"(%71, %72) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn_layout50>, tensor<1x7x128xf32, #ttnn_layout51>) -> tensor<12x7x128xf32, #ttnn_layout50> loc(#loc84)
        "ttnn.deallocate"(%72) <{force = false}> : (tensor<1x7x128xf32, #ttnn_layout51>) -> () loc(#loc84)
        "ttnn.deallocate"(%71) <{force = false}> : (tensor<12x7x128xf32, #ttnn_layout50>) -> () loc(#loc84)
        %74 = "ttnn.typecast"(%73) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn_layout50>) -> tensor<12x7x128xbf16, #ttnn_layout52> loc(#loc85)
        "ttnn.deallocate"(%73) <{force = false}> : (tensor<12x7x128xf32, #ttnn_layout50>) -> () loc(#loc85)
        %75 = "ttnn.slice_static"(%69) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn_layout48>) -> tensor<1x12x7x64xbf16, #ttnn_layout53> loc(#loc86)
        %76 = "ttnn.neg"(%75) : (tensor<1x12x7x64xbf16, #ttnn_layout53>) -> tensor<1x12x7x64xbf16, #ttnn_layout53> loc(#loc87)
        "ttnn.deallocate"(%75) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn_layout53>) -> () loc(#loc87)
        %77 = "ttnn.reshape"(%76) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn_layout53>) -> tensor<12x7x64xbf16, #ttnn_layout54> loc(#loc87)
        "ttnn.deallocate"(%76) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn_layout53>) -> () loc(#loc87)
        %78 = "ttnn.slice_static"(%69) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 7 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x7x128xbf16, #ttnn_layout48>) -> tensor<1x12x7x64xbf16, #ttnn_layout53> loc(#loc88)
        "ttnn.deallocate"(%69) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn_layout48>) -> () loc(#loc88)
        %79 = "ttnn.reshape"(%78) <{shape = [12 : i32, 7 : i32, 64 : i32]}> : (tensor<1x12x7x64xbf16, #ttnn_layout53>) -> tensor<12x7x64xbf16, #ttnn_layout54> loc(#loc89)
        "ttnn.deallocate"(%78) <{force = false}> : (tensor<1x12x7x64xbf16, #ttnn_layout53>) -> () loc(#loc89)
        %80 = "ttnn.concat"(%77, %79) <{dim = 2 : si32}> : (tensor<12x7x64xbf16, #ttnn_layout54>, tensor<12x7x64xbf16, #ttnn_layout54>) -> tensor<12x7x128xbf16, #ttnn_layout52> loc(#loc89)
        "ttnn.deallocate"(%79) <{force = false}> : (tensor<12x7x64xbf16, #ttnn_layout54>) -> () loc(#loc89)
        "ttnn.deallocate"(%77) <{force = false}> : (tensor<12x7x64xbf16, #ttnn_layout54>) -> () loc(#loc89)
        %81 = "ttnn.typecast"(%80) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xbf16, #ttnn_layout52>) -> tensor<12x7x128xf32, #ttnn_layout50> loc(#loc90)
        "ttnn.deallocate"(%80) <{force = false}> : (tensor<12x7x128xbf16, #ttnn_layout52>) -> () loc(#loc90)
        %82 = "ttnn.reshape"(%60) <{shape = [1 : i32, 7 : i32, 128 : i32]}> : (tensor<1x1x7x128xf32, #ttnn_layout45>) -> tensor<1x7x128xf32, #ttnn_layout51> loc(#loc177)
        "ttnn.deallocate"(%60) <{force = false}> : (tensor<1x1x7x128xf32, #ttnn_layout45>) -> () loc(#loc177)
        %83 = "ttnn.multiply"(%81, %82) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x128xf32, #ttnn_layout50>, tensor<1x7x128xf32, #ttnn_layout51>) -> tensor<12x7x128xf32, #ttnn_layout50> loc(#loc91)
        "ttnn.deallocate"(%82) <{force = false}> : (tensor<1x7x128xf32, #ttnn_layout51>) -> () loc(#loc91)
        "ttnn.deallocate"(%81) <{force = false}> : (tensor<12x7x128xf32, #ttnn_layout50>) -> () loc(#loc91)
        %84 = "ttnn.typecast"(%83) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xf32, #ttnn_layout50>) -> tensor<12x7x128xbf16, #ttnn_layout52> loc(#loc92)
        "ttnn.deallocate"(%83) <{force = false}> : (tensor<12x7x128xf32, #ttnn_layout50>) -> () loc(#loc92)
        %85 = "ttnn.add"(%74, %84) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x128xbf16, #ttnn_layout52>, tensor<12x7x128xbf16, #ttnn_layout52>) -> tensor<12x7x128xbf16, #ttnn_layout52> loc(#loc93)
        "ttnn.deallocate"(%84) <{force = false}> : (tensor<12x7x128xbf16, #ttnn_layout52>) -> () loc(#loc93)
        "ttnn.deallocate"(%74) <{force = false}> : (tensor<12x7x128xbf16, #ttnn_layout52>) -> () loc(#loc93)
        %86 = "ttnn.reshape"(%21) <{shape = [1 : i32, 4 : i32, 1 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x16x128xbf16, #ttnn_layout31>) -> tensor<1x4x1x16x128xbf16, #ttnn_layout55> loc(#loc94)
        %87 = "ttnn.repeat"(%86) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x16x128xbf16, #ttnn_layout55>) -> tensor<1x4x3x16x128xbf16, #ttnn_layout56> loc(#loc94)
        "ttnn.deallocate"(%86) <{force = false}> : (tensor<1x4x1x16x128xbf16, #ttnn_layout55>) -> () loc(#loc94)
        %88 = "ttnn.reshape"(%87) <{shape = [1 : i32, 12 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x3x16x128xbf16, #ttnn_layout56>) -> tensor<1x12x16x128xbf16, #ttnn_layout48> loc(#loc95)
        "ttnn.deallocate"(%87) <{force = false}> : (tensor<1x4x3x16x128xbf16, #ttnn_layout56>) -> () loc(#loc95)
        %89 = "ttnn.permute"(%88) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x16x128xbf16, #ttnn_layout48>) -> tensor<1x12x128x16xbf16, #ttnn_layout57> loc(#loc96)
        "ttnn.deallocate"(%88) <{force = false}> : (tensor<1x12x16x128xbf16, #ttnn_layout48>) -> () loc(#loc96)
        %90 = "ttnn.reshape"(%89) <{shape = [12 : i32, 128 : i32, 16 : i32]}> : (tensor<1x12x128x16xbf16, #ttnn_layout57>) -> tensor<12x128x16xbf16, #ttnn_layout58> loc(#loc97)
        "ttnn.deallocate"(%89) <{force = false}> : (tensor<1x12x128x16xbf16, #ttnn_layout57>) -> () loc(#loc97)
        %91 = "ttnn.matmul"(%85, %90) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x128xbf16, #ttnn_layout52>, tensor<12x128x16xbf16, #ttnn_layout58>) -> tensor<12x7x16xbf16, #ttnn_layout59> loc(#loc98)
        "ttnn.deallocate"(%90) <{force = false}> : (tensor<12x128x16xbf16, #ttnn_layout58>) -> () loc(#loc98)
        "ttnn.deallocate"(%85) <{force = false}> : (tensor<12x7x128xbf16, #ttnn_layout52>) -> () loc(#loc98)
        %92 = "ttnn.typecast"(%91) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x16xbf16, #ttnn_layout59>) -> tensor<12x7x16xf32, #ttnn_layout5> loc(#loc2)
        "ttnn.deallocate"(%91) <{force = false}> : (tensor<12x7x16xbf16, #ttnn_layout59>) -> () loc(#loc2)
        %93 = "ttnn.multiply"(%92, %2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x7x16xf32, #ttnn_layout5>, tensor<12x7x16xf32, #ttnn_layout5>) -> tensor<12x7x16xf32, #ttnn_layout5> loc(#loc99)
        "ttnn.deallocate"(%92) <{force = false}> : (tensor<12x7x16xf32, #ttnn_layout5>) -> () loc(#loc99)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<12x7x16xf32, #ttnn_layout5>) -> () loc(#loc99)
        %94 = "ttnn.typecast"(%93) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x7x16xf32, #ttnn_layout5>) -> tensor<12x7x16xbf16, #ttnn_layout59> loc(#loc100)
        "ttnn.deallocate"(%93) <{force = false}> : (tensor<12x7x16xf32, #ttnn_layout5>) -> () loc(#loc100)
        %95 = "ttnn.reshape"(%94) <{shape = [1 : i32, 12 : i32, 7 : i32, 16 : i32]}> : (tensor<12x7x16xbf16, #ttnn_layout59>) -> tensor<1x12x7x16xbf16, #ttnn_layout60> loc(#loc100)
        "ttnn.deallocate"(%94) <{force = false}> : (tensor<12x7x16xbf16, #ttnn_layout59>) -> () loc(#loc100)
        %96 = "ttnn.reshape"(%18) <{shape = [1 : i32, 1 : i32, 7 : i32, 1 : i32]}> : (tensor<7xsi32, #ttnn_layout20>) -> tensor<1x1x7x1xsi32, #ttnn_layout25> loc(#loc180)
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<7xsi32, #ttnn_layout20>) -> () loc(#loc180)
        %97 = "ttnn.typecast"(%96) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x1xsi32, #ttnn_layout25>) -> tensor<1x1x7x1xf32, #ttnn_layout6> loc(#loc150)
        "ttnn.deallocate"(%96) <{force = false}> : (tensor<1x1x7x1xsi32, #ttnn_layout25>) -> () loc(#loc150)
        %98 = "ttnn.gt"(%15#1, %97) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x16xf32, #ttnn_layout6>, tensor<1x1x7x1xf32, #ttnn_layout6>) -> tensor<1x1x7x16xf32, #ttnn_layout6> loc(#loc21)
        "ttnn.deallocate"(%97) <{force = false}> : (tensor<1x1x7x1xf32, #ttnn_layout6>) -> () loc(#loc21)
        "ttnn.deallocate"(%15#1) <{force = false}> : (tensor<1x1x7x16xf32, #ttnn_layout6>) -> () loc(#loc21)
        %99 = "ttnn.typecast"(%98) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x7x16xf32, #ttnn_layout6>) -> tensor<1x1x7x16xbf16, #ttnn_layout24> loc(#loc150)
        "ttnn.deallocate"(%98) <{force = false}> : (tensor<1x1x7x16xf32, #ttnn_layout6>) -> () loc(#loc150)
        %100 = "ttnn.typecast"(%99) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x16xbf16, #ttnn_layout24>) -> tensor<1x1x7x16xf32, #ttnn_layout6> loc(#loc101)
        "ttnn.deallocate"(%99) <{force = false}> : (tensor<1x1x7x16xbf16, #ttnn_layout24>) -> () loc(#loc101)
        %101 = "ttnn.multiply"(%15#0, %100) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x7x16xf32, #ttnn_layout6>, tensor<1x1x7x16xf32, #ttnn_layout6>) -> tensor<1x1x7x16xf32, #ttnn_layout6> loc(#loc102)
        "ttnn.deallocate"(%100) <{force = false}> : (tensor<1x1x7x16xf32, #ttnn_layout6>) -> () loc(#loc102)
        "ttnn.deallocate"(%15#0) <{force = false}> : (tensor<1x1x7x16xf32, #ttnn_layout6>) -> () loc(#loc102)
        %102 = "ttnn.typecast"(%101) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x7x16xf32, #ttnn_layout6>) -> tensor<1x1x7x16xbf16, #ttnn_layout24> loc(#loc103)
        "ttnn.deallocate"(%101) <{force = false}> : (tensor<1x1x7x16xf32, #ttnn_layout6>) -> () loc(#loc103)
        %103 = "ttnn.add"(%95, %102) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x16xbf16, #ttnn_layout60>, tensor<1x1x7x16xbf16, #ttnn_layout24>) -> tensor<1x12x7x16xbf16, #ttnn_layout60> loc(#loc104)
        "ttnn.deallocate"(%102) <{force = false}> : (tensor<1x1x7x16xbf16, #ttnn_layout24>) -> () loc(#loc104)
        "ttnn.deallocate"(%95) <{force = false}> : (tensor<1x12x7x16xbf16, #ttnn_layout60>) -> () loc(#loc104)
        %104 = "ttnn.typecast"(%103) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x7x16xbf16, #ttnn_layout60>) -> tensor<1x12x7x16xf32, #ttnn_layout7> loc(#loc105)
        "ttnn.deallocate"(%103) <{force = false}> : (tensor<1x12x7x16xbf16, #ttnn_layout60>) -> () loc(#loc105)
        %105 = "ttnn.softmax"(%104) <{dimension = 3 : si32, numericStable = true}> : (tensor<1x12x7x16xf32, #ttnn_layout7>) -> tensor<1x12x7x16xf32, #ttnn_layout7> loc(#loc106)
        "ttnn.deallocate"(%104) <{force = false}> : (tensor<1x12x7x16xf32, #ttnn_layout7>) -> () loc(#loc106)
        %106 = "ttnn.typecast"(%105) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x7x16xf32, #ttnn_layout7>) -> tensor<1x12x7x16xbf16, #ttnn_layout60> loc(#loc107)
        "ttnn.deallocate"(%105) <{force = false}> : (tensor<1x12x7x16xf32, #ttnn_layout7>) -> () loc(#loc107)
        %107 = "ttnn.reshape"(%106) <{shape = [12 : i32, 7 : i32, 16 : i32]}> : (tensor<1x12x7x16xbf16, #ttnn_layout60>) -> tensor<12x7x16xbf16, #ttnn_layout59> loc(#loc107)
        "ttnn.deallocate"(%106) <{force = false}> : (tensor<1x12x7x16xbf16, #ttnn_layout60>) -> () loc(#loc107)
        %108 = "ttnn.reshape"(%22) <{shape = [1 : i32, 4 : i32, 1 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x16x128xbf16, #ttnn_layout31>) -> tensor<1x4x1x16x128xbf16, #ttnn_layout55> loc(#loc108)
        %109 = "ttnn.repeat"(%108) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x16x128xbf16, #ttnn_layout55>) -> tensor<1x4x3x16x128xbf16, #ttnn_layout56> loc(#loc108)
        "ttnn.deallocate"(%108) <{force = false}> : (tensor<1x4x1x16x128xbf16, #ttnn_layout55>) -> () loc(#loc108)
        %110 = "ttnn.reshape"(%109) <{shape = [12 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x3x16x128xbf16, #ttnn_layout56>) -> tensor<12x16x128xbf16, #ttnn_layout52> loc(#loc109)
        "ttnn.deallocate"(%109) <{force = false}> : (tensor<1x4x3x16x128xbf16, #ttnn_layout56>) -> () loc(#loc109)
        %111 = "ttnn.matmul"(%107, %110) <{transpose_a = false, transpose_b = false}> : (tensor<12x7x16xbf16, #ttnn_layout59>, tensor<12x16x128xbf16, #ttnn_layout52>) -> tensor<12x7x128xbf16, #ttnn_layout52> loc(#loc110)
        "ttnn.deallocate"(%110) <{force = false}> : (tensor<12x16x128xbf16, #ttnn_layout52>) -> () loc(#loc110)
        "ttnn.deallocate"(%107) <{force = false}> : (tensor<12x7x16xbf16, #ttnn_layout59>) -> () loc(#loc110)
        %112 = "ttnn.reshape"(%111) <{shape = [1 : i32, 12 : i32, 7 : i32, 128 : i32]}> : (tensor<12x7x128xbf16, #ttnn_layout52>) -> tensor<1x12x7x128xbf16, #ttnn_layout48> loc(#loc111)
        "ttnn.deallocate"(%111) <{force = false}> : (tensor<12x7x128xbf16, #ttnn_layout52>) -> () loc(#loc111)
        %113 = "ttnn.concatenate_heads"(%112) : (tensor<1x12x7x128xbf16, #ttnn_layout48>) -> tensor<1x7x1536xbf16, #ttnn_layout61> loc(#loc112)
        "ttnn.deallocate"(%112) <{force = false}> : (tensor<1x12x7x128xbf16, #ttnn_layout48>) -> () loc(#loc112)
        %114 = "ttnn.reshape"(%113) <{shape = [7 : i32, 1536 : i32]}> : (tensor<1x7x1536xbf16, #ttnn_layout61>) -> tensor<7x1536xbf16, #ttnn_layout47> loc(#loc112)
        "ttnn.deallocate"(%113) <{force = false}> : (tensor<1x7x1536xbf16, #ttnn_layout61>) -> () loc(#loc112)
        %115 = "ttnn.matmul"(%114, %3) <{transpose_a = false, transpose_b = true}> : (tensor<7x1536xbf16, #ttnn_layout47>, tensor<3072x1536xbf16, #ttnn_layout9>) -> tensor<7x3072xbf16, #ttnn_layout16> loc(#loc113)
        "ttnn.deallocate"(%114) <{force = false}> : (tensor<7x1536xbf16, #ttnn_layout47>) -> () loc(#loc113)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<3072x1536xbf16, #ttnn_layout9>) -> () loc(#loc113)
        %116 = "ttnn.reshape"(%115) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> tensor<1x1x7x3072xbf16, #ttnn_layout62> loc(#loc166)
        "ttnn.deallocate"(%115) <{force = false}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> () loc(#loc166)
        %117 = "ttnn.reduce_scatter"(%116, %16) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn_layout62>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn_layout63> loc(#loc167)
        "ttnn.deallocate"(%116) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn_layout62>) -> () loc(#loc167)
        %118 = "ttnn.all_gather"(%117, %16) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x7x1536xbf16, #ttnn_layout63>, !ttnn.device) -> tensor<1x1x7x3072xbf16, #ttnn_layout62> loc(#loc155)
        "ttnn.deallocate"(%117) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn_layout63>) -> () loc(#loc155)
        %119 = "ttnn.reshape"(%118) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x1x7x3072xbf16, #ttnn_layout62>) -> tensor<7x3072xbf16, #ttnn_layout16> loc(#loc113)
        "ttnn.deallocate"(%118) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn_layout62>) -> () loc(#loc113)
        %120 = "ttnn.add"(%28, %119) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn_layout16>, tensor<7x3072xbf16, #ttnn_layout16>) -> tensor<7x3072xbf16, #ttnn_layout16> loc(#loc114)
        "ttnn.deallocate"(%119) <{force = false}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> () loc(#loc114)
        "ttnn.deallocate"(%28) <{force = false}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> () loc(#loc114)
        %121 = "ttnn.typecast"(%120) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> tensor<7x3072xf32, #ttnn_layout15> loc(#loc115)
        %122 = "ttnn.reshape"(%121) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn_layout15>) -> tensor<1x7x3072xf32, #ttnn_layout37> loc(#loc115)
        %123 = "ttnn.pow"(%122, %13) : (tensor<1x7x3072xf32, #ttnn_layout37>, tensor<1x1x1xf32, #ttnn_layout18>) -> tensor<1x7x3072xf32, #ttnn_layout37> loc(#loc116)
        "ttnn.deallocate"(%122) <{force = false}> : (tensor<1x7x3072xf32, #ttnn_layout37>) -> () loc(#loc116)
        %124 = "ttnn.sum"(%123) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn_layout37>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc117)
        "ttnn.deallocate"(%123) <{force = false}> : (tensor<1x7x3072xf32, #ttnn_layout37>) -> () loc(#loc117)
        %125 = "ttnn.multiply"(%124, %17) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn_layout11>, tensor<1x7xf32, #ttnn_layout11>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc6)
        "ttnn.deallocate"(%124) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc6)
        %126 = "ttnn.add"(%125, %5#1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn_layout11>, tensor<1x7xf32, #ttnn_layout11>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc118)
        "ttnn.deallocate"(%125) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc118)
        "ttnn.deallocate"(%5#1) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc118)
        %127 = "ttnn.rsqrt"(%126) : (tensor<1x7xf32, #ttnn_layout11>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc119)
        "ttnn.deallocate"(%126) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc119)
        %128 = "ttnn.reshape"(%127) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn_layout11>) -> tensor<7x1xf32, #ttnn_layout11> loc(#loc119)
        "ttnn.deallocate"(%127) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc119)
        %129 = "ttnn.multiply"(%121, %128) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn_layout15>, tensor<7x1xf32, #ttnn_layout11>) -> tensor<7x3072xf32, #ttnn_layout15> loc(#loc120)
        "ttnn.deallocate"(%128) <{force = false}> : (tensor<7x1xf32, #ttnn_layout11>) -> () loc(#loc120)
        "ttnn.deallocate"(%121) <{force = false}> : (tensor<7x3072xf32, #ttnn_layout15>) -> () loc(#loc120)
        %130 = "ttnn.multiply"(%7, %129) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn_layout15>, tensor<7x3072xf32, #ttnn_layout15>) -> tensor<7x3072xf32, #ttnn_layout15> loc(#loc121)
        "ttnn.deallocate"(%129) <{force = false}> : (tensor<7x3072xf32, #ttnn_layout15>) -> () loc(#loc121)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout15>) -> () loc(#loc121)
        %131 = "ttnn.typecast"(%130) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn_layout15>) -> tensor<7x3072xbf16, #ttnn_layout16> loc(#loc122)
        "ttnn.deallocate"(%130) <{force = false}> : (tensor<7x3072xf32, #ttnn_layout15>) -> () loc(#loc122)
        %132 = "ttnn.matmul"(%131, %8) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn_layout16>, tensor<4096x3072xbf16, #ttnn_layout13>) -> tensor<7x4096xbf16, #ttnn_layout64> loc(#loc123)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<4096x3072xbf16, #ttnn_layout13>) -> () loc(#loc123)
        %133 = "ttnn.typecast"(%132) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn_layout64>) -> tensor<7x4096xf32, #ttnn_layout65> loc(#loc124)
        %134 = "ttnn.sigmoid"(%132) : (tensor<7x4096xbf16, #ttnn_layout64>) -> tensor<7x4096xbf16, #ttnn_layout64> loc(#loc125)
        "ttnn.deallocate"(%132) <{force = false}> : (tensor<7x4096xbf16, #ttnn_layout64>) -> () loc(#loc125)
        %135 = "ttnn.typecast"(%134) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn_layout64>) -> tensor<7x4096xf32, #ttnn_layout65> loc(#loc126)
        "ttnn.deallocate"(%134) <{force = false}> : (tensor<7x4096xbf16, #ttnn_layout64>) -> () loc(#loc126)
        %136 = "ttnn.multiply"(%133, %135) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn_layout65>, tensor<7x4096xf32, #ttnn_layout65>) -> tensor<7x4096xf32, #ttnn_layout65> loc(#loc127)
        "ttnn.deallocate"(%135) <{force = false}> : (tensor<7x4096xf32, #ttnn_layout65>) -> () loc(#loc127)
        "ttnn.deallocate"(%133) <{force = false}> : (tensor<7x4096xf32, #ttnn_layout65>) -> () loc(#loc127)
        %137 = "ttnn.matmul"(%131, %6) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn_layout16>, tensor<4096x3072xbf16, #ttnn_layout13>) -> tensor<7x4096xbf16, #ttnn_layout64> loc(#loc128)
        "ttnn.deallocate"(%131) <{force = false}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> () loc(#loc128)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<4096x3072xbf16, #ttnn_layout13>) -> () loc(#loc128)
        %138 = "ttnn.typecast"(%137) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xbf16, #ttnn_layout64>) -> tensor<7x4096xf32, #ttnn_layout65> loc(#loc129)
        "ttnn.deallocate"(%137) <{force = false}> : (tensor<7x4096xbf16, #ttnn_layout64>) -> () loc(#loc129)
        %139 = "ttnn.multiply"(%136, %138) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x4096xf32, #ttnn_layout65>, tensor<7x4096xf32, #ttnn_layout65>) -> tensor<7x4096xf32, #ttnn_layout65> loc(#loc130)
        "ttnn.deallocate"(%138) <{force = false}> : (tensor<7x4096xf32, #ttnn_layout65>) -> () loc(#loc130)
        "ttnn.deallocate"(%136) <{force = false}> : (tensor<7x4096xf32, #ttnn_layout65>) -> () loc(#loc130)
        %140 = "ttnn.typecast"(%139) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x4096xf32, #ttnn_layout65>) -> tensor<7x4096xbf16, #ttnn_layout64> loc(#loc131)
        "ttnn.deallocate"(%139) <{force = false}> : (tensor<7x4096xf32, #ttnn_layout65>) -> () loc(#loc131)
        %141 = "ttnn.matmul"(%140, %1) <{transpose_a = false, transpose_b = true}> : (tensor<7x4096xbf16, #ttnn_layout64>, tensor<3072x4096xbf16, #ttnn_layout3>) -> tensor<7x3072xbf16, #ttnn_layout16> loc(#loc132)
        "ttnn.deallocate"(%140) <{force = false}> : (tensor<7x4096xbf16, #ttnn_layout64>) -> () loc(#loc132)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072x4096xbf16, #ttnn_layout3>) -> () loc(#loc132)
        %142 = "ttnn.reshape"(%141) <{shape = [1 : i32, 1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> tensor<1x1x7x3072xbf16, #ttnn_layout62> loc(#loc168)
        "ttnn.deallocate"(%141) <{force = false}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> () loc(#loc168)
        %143 = "ttnn.reduce_scatter"(%142, %16) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x7x3072xbf16, #ttnn_layout62>, !ttnn.device) -> tensor<1x1x7x1536xbf16, #ttnn_layout63> loc(#loc169)
        "ttnn.deallocate"(%142) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn_layout62>) -> () loc(#loc169)
        %144 = "ttnn.all_gather"(%143, %16) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x7x1536xbf16, #ttnn_layout63>, !ttnn.device) -> tensor<1x1x7x3072xbf16, #ttnn_layout62> loc(#loc157)
        "ttnn.deallocate"(%143) <{force = false}> : (tensor<1x1x7x1536xbf16, #ttnn_layout63>) -> () loc(#loc157)
        %145 = "ttnn.reshape"(%144) <{shape = [7 : i32, 3072 : i32]}> : (tensor<1x1x7x3072xbf16, #ttnn_layout62>) -> tensor<7x3072xbf16, #ttnn_layout16> loc(#loc132)
        "ttnn.deallocate"(%144) <{force = false}> : (tensor<1x1x7x3072xbf16, #ttnn_layout62>) -> () loc(#loc132)
        %146 = "ttnn.add"(%120, %145) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xbf16, #ttnn_layout16>, tensor<7x3072xbf16, #ttnn_layout16>) -> tensor<7x3072xbf16, #ttnn_layout16> loc(#loc133)
        "ttnn.deallocate"(%145) <{force = false}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> () loc(#loc133)
        "ttnn.deallocate"(%120) <{force = false}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> () loc(#loc133)
        %147 = "ttnn.typecast"(%146) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> tensor<7x3072xf32, #ttnn_layout15> loc(#loc134)
        "ttnn.deallocate"(%146) <{force = false}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> () loc(#loc134)
        %148 = "ttnn.reshape"(%147) <{shape = [1 : i32, 7 : i32, 3072 : i32]}> : (tensor<7x3072xf32, #ttnn_layout15>) -> tensor<1x7x3072xf32, #ttnn_layout37> loc(#loc134)
        %149 = "ttnn.pow"(%148, %13) : (tensor<1x7x3072xf32, #ttnn_layout37>, tensor<1x1x1xf32, #ttnn_layout18>) -> tensor<1x7x3072xf32, #ttnn_layout37> loc(#loc135)
        "ttnn.deallocate"(%148) <{force = false}> : (tensor<1x7x3072xf32, #ttnn_layout37>) -> () loc(#loc135)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout18>) -> () loc(#loc135)
        %150 = "ttnn.sum"(%149) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x7x3072xf32, #ttnn_layout37>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc136)
        "ttnn.deallocate"(%149) <{force = false}> : (tensor<1x7x3072xf32, #ttnn_layout37>) -> () loc(#loc136)
        %151 = "ttnn.multiply"(%150, %17) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn_layout11>, tensor<1x7xf32, #ttnn_layout11>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc7)
        "ttnn.deallocate"(%150) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc7)
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc7)
        %152 = "ttnn.add"(%151, %5#2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7xf32, #ttnn_layout11>, tensor<1x7xf32, #ttnn_layout11>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc137)
        "ttnn.deallocate"(%151) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc137)
        "ttnn.deallocate"(%5#2) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc137)
        %153 = "ttnn.rsqrt"(%152) : (tensor<1x7xf32, #ttnn_layout11>) -> tensor<1x7xf32, #ttnn_layout11> loc(#loc138)
        "ttnn.deallocate"(%152) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc138)
        %154 = "ttnn.reshape"(%153) <{shape = [7 : i32, 1 : i32]}> : (tensor<1x7xf32, #ttnn_layout11>) -> tensor<7x1xf32, #ttnn_layout11> loc(#loc138)
        "ttnn.deallocate"(%153) <{force = false}> : (tensor<1x7xf32, #ttnn_layout11>) -> () loc(#loc138)
        %155 = "ttnn.multiply"(%147, %154) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<7x3072xf32, #ttnn_layout15>, tensor<7x1xf32, #ttnn_layout11>) -> tensor<7x3072xf32, #ttnn_layout15> loc(#loc139)
        "ttnn.deallocate"(%154) <{force = false}> : (tensor<7x1xf32, #ttnn_layout11>) -> () loc(#loc139)
        "ttnn.deallocate"(%147) <{force = false}> : (tensor<7x3072xf32, #ttnn_layout15>) -> () loc(#loc139)
        %156 = "ttnn.multiply"(%12, %155) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn_layout15>, tensor<7x3072xf32, #ttnn_layout15>) -> tensor<7x3072xf32, #ttnn_layout15> loc(#loc140)
        "ttnn.deallocate"(%155) <{force = false}> : (tensor<7x3072xf32, #ttnn_layout15>) -> () loc(#loc140)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout15>) -> () loc(#loc140)
        %157 = "ttnn.typecast"(%156) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<7x3072xf32, #ttnn_layout15>) -> tensor<7x3072xbf16, #ttnn_layout16> loc(#loc141)
        "ttnn.deallocate"(%156) <{force = false}> : (tensor<7x3072xf32, #ttnn_layout15>) -> () loc(#loc141)
        %158 = "ttnn.matmul"(%157, %14) <{transpose_a = false, transpose_b = true}> : (tensor<7x3072xbf16, #ttnn_layout16>, tensor<128256x3072xbf16, #ttnn_layout17>) -> tensor<7x128256xbf16, #ttnn_layout66> loc(#loc142)
        "ttnn.deallocate"(%157) <{force = false}> : (tensor<7x3072xbf16, #ttnn_layout16>) -> () loc(#loc142)
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout17>) -> () loc(#loc142)
        %159 = "ttnn.reshape"(%158) <{shape = [1 : i32, 7 : i32, 128256 : i32]}> : (tensor<7x128256xbf16, #ttnn_layout66>) -> tensor<1x7x128256xbf16, #ttnn_layout67> loc(#loc143)
        %160 = "ttnn.to_layout"(%21) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x16x128xbf16, #ttnn_layout31>) -> tensor<1x4x16x128xbf16, #ttnn_layout68> loc(#loc)
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<1x4x16x128xbf16, #ttnn_layout31>) -> () loc(#loc)
        %161 = "ttnn.from_device"(%160) : (tensor<1x4x16x128xbf16, #ttnn_layout68>) -> tensor<1x4x16x128xbf16, #ttnn_layout69> loc(#loc)
        "ttnn.deallocate"(%160) <{force = false}> : (tensor<1x4x16x128xbf16, #ttnn_layout68>) -> () loc(#loc)
        %162 = "ttnn.mesh_shard"(%161, %16) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x16x128xbf16, #ttnn_layout69>, !ttnn.device) -> tensor<1x8x16x128xbf16, #ttnn_layout28> loc(#loc)
        "ttnn.deallocate"(%161) <{force = false}> : (tensor<1x4x16x128xbf16, #ttnn_layout69>) -> () loc(#loc)
        %163 = "ttnn.to_layout"(%22) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x16x128xbf16, #ttnn_layout31>) -> tensor<1x4x16x128xbf16, #ttnn_layout68> loc(#loc)
        "ttnn.deallocate"(%22) <{force = false}> : (tensor<1x4x16x128xbf16, #ttnn_layout31>) -> () loc(#loc)
        %164 = "ttnn.from_device"(%163) : (tensor<1x4x16x128xbf16, #ttnn_layout68>) -> tensor<1x4x16x128xbf16, #ttnn_layout69> loc(#loc)
        "ttnn.deallocate"(%163) <{force = false}> : (tensor<1x4x16x128xbf16, #ttnn_layout68>) -> () loc(#loc)
        %165 = "ttnn.mesh_shard"(%164, %16) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x16x128xbf16, #ttnn_layout69>, !ttnn.device) -> tensor<1x8x16x128xbf16, #ttnn_layout28> loc(#loc)
        "ttnn.deallocate"(%164) <{force = false}> : (tensor<1x4x16x128xbf16, #ttnn_layout69>) -> () loc(#loc)
        %166 = "ttnn.to_layout"(%158) <{layout = #ttnn.layout<row_major>}> : (tensor<7x128256xbf16, #ttnn_layout66>) -> tensor<7x128256xbf16, #ttnn_layout70> loc(#loc)
        "ttnn.deallocate"(%158) <{force = false}> : (tensor<7x128256xbf16, #ttnn_layout66>) -> () loc(#loc)
        %167 = "ttnn.from_device"(%166) : (tensor<7x128256xbf16, #ttnn_layout70>) -> tensor<7x128256xbf16, #ttnn_layout29> loc(#loc)
        "ttnn.deallocate"(%166) <{force = false}> : (tensor<7x128256xbf16, #ttnn_layout70>) -> () loc(#loc)
        %168 = "ttnn.mesh_shard"(%167, %16) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<7x128256xbf16, #ttnn_layout29>, !ttnn.device) -> tensor<7x128256xbf16, #ttnn_layout29> loc(#loc)
        "ttnn.deallocate"(%167) <{force = false}> : (tensor<7x128256xbf16, #ttnn_layout29>) -> () loc(#loc)
        %169 = "ttnn.to_layout"(%159) <{layout = #ttnn.layout<row_major>}> : (tensor<1x7x128256xbf16, #ttnn_layout67>) -> tensor<1x7x128256xbf16, #ttnn_layout71> loc(#loc)
        "ttnn.deallocate"(%159) <{force = false}> : (tensor<1x7x128256xbf16, #ttnn_layout67>) -> () loc(#loc)
        %170 = "ttnn.from_device"(%169) : (tensor<1x7x128256xbf16, #ttnn_layout71>) -> tensor<1x7x128256xbf16, #ttnn_layout30> loc(#loc)
        "ttnn.deallocate"(%169) <{force = false}> : (tensor<1x7x128256xbf16, #ttnn_layout71>) -> () loc(#loc)
        %171 = "ttnn.mesh_shard"(%170, %16) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x7x128256xbf16, #ttnn_layout30>, !ttnn.device) -> tensor<1x7x128256xbf16, #ttnn_layout30> loc(#loc)
        "ttnn.deallocate"(%170) <{force = false}> : (tensor<1x7x128256xbf16, #ttnn_layout30>) -> () loc(#loc)
        return %162, %165, %168, %171 : tensor<1x8x16x128xbf16, #ttnn_layout28>, tensor<1x8x16x128xbf16, #ttnn_layout28>, tensor<7x128256xbf16, #ttnn_layout29>, tensor<1x7x128256xbf16, #ttnn_layout30> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("broadcast.302")
#loc2 = loc("convert.301")
#loc3 = loc("reshape.89")
#loc4 = loc("broadcast.73")
#loc5 = loc("multiply.69")
#loc6 = loc("multiply.359")
#loc7 = loc("multiply.423")
#loc8 = loc("reshape.388")
#loc9 = loc("convert.375")
#loc10 = loc("convert.85")
#loc11 = loc("reshape.446")
#loc12 = loc("convert.439")
#loc13 = loc("broadcast.235")
#loc14 = loc("broadcast.237")
#loc15 = loc("subtract.238")
#loc16 = loc("compare.240")
#loc17 = loc("broadcast.224")
#loc18 = loc("select.242")
#loc19 = loc("broadcast.308")
#loc20 = loc("convert.243")
#loc21 = loc("compare.212")
#loc43 = loc("convert.48")
#loc44 = loc("gather.49")
#loc45 = loc("convert.51")
#loc46 = loc("power.53")
#loc47 = loc("reduce.60")
#loc48 = loc("add.74")
#loc49 = loc("rsqrt.75")
#loc50 = loc("multiply.78")
#loc51 = loc("multiply.87")
#loc52 = loc("convert.88")
#loc53 = loc("dot.90")
#loc54 = loc("reshape.92")
#loc55 = loc("transpose.93")
#loc56 = loc("convert.110")
#loc57 = loc("reshape.19")
#loc58 = loc("convert.11")
#loc59 = loc("dot.22")
#loc60 = loc("transpose.23")
#loc61 = loc("concatenate.24")
#loc62 = loc("cosine.104")
#loc63 = loc("multiply.113")
#loc64 = loc("convert.114")
#loc65 = loc("slice.95")
#loc66 = loc("negate.96")
#loc67 = loc("slice.94")
#loc68 = loc("concatenate.97")
#loc69 = loc("convert.98")
#loc70 = loc("sine.25")
#loc71 = loc("multiply.101")
#loc72 = loc("convert.102")
#loc73 = loc("add.117")
#loc74 = loc("scatter.136")
#loc75 = loc("dot.145")
#loc76 = loc("reshape.147")
#loc77 = loc("transpose.148")
#loc78 = loc("scatter.166")
#loc79 = loc("dot.275")
#loc80 = loc("reshape.277")
#loc81 = loc("transpose.278")
#loc82 = loc("convert.289")
#loc83 = loc("reshape.298")
#loc84 = loc("multiply.292")
#loc85 = loc("convert.293")
#loc86 = loc("slice.280")
#loc87 = loc("negate.281")
#loc88 = loc("slice.279")
#loc89 = loc("concatenate.282")
#loc90 = loc("convert.283")
#loc91 = loc("multiply.286")
#loc92 = loc("convert.287")
#loc93 = loc("add.296")
#loc94 = loc("broadcast.262")
#loc95 = loc("reshape.263")
#loc96 = loc("transpose.264")
#loc97 = loc("reshape.266")
#loc98 = loc("dot.299")
#loc99 = loc("multiply.303")
#loc100 = loc("convert.304")
#loc101 = loc("convert.213")
#loc102 = loc("multiply.244")
#loc103 = loc("convert.245")
#loc104 = loc("add.309")
#loc105 = loc("convert.310")
#loc106 = loc("divide.327")
#loc107 = loc("convert.328")
#loc108 = loc("broadcast.202")
#loc109 = loc("reshape.205")
#loc110 = loc("dot.331")
#loc111 = loc("reshape.332")
#loc112 = loc("reshape.335")
#loc113 = loc("dot.336")
#loc114 = loc("add.340")
#loc115 = loc("convert.341")
#loc116 = loc("power.343")
#loc117 = loc("reduce.350")
#loc118 = loc("add.364")
#loc119 = loc("rsqrt.365")
#loc120 = loc("multiply.368")
#loc121 = loc("multiply.377")
#loc122 = loc("convert.378")
#loc123 = loc("dot.389")
#loc124 = loc("convert.393")
#loc125 = loc("logistic.391")
#loc126 = loc("convert.392")
#loc127 = loc("multiply.394")
#loc128 = loc("dot.380")
#loc129 = loc("convert.382")
#loc130 = loc("multiply.397")
#loc131 = loc("convert.398")
#loc132 = loc("dot.400")
#loc133 = loc("add.404")
#loc134 = loc("convert.405")
#loc135 = loc("power.407")
#loc136 = loc("reduce.414")
#loc137 = loc("add.428")
#loc138 = loc("rsqrt.429")
#loc139 = loc("multiply.432")
#loc140 = loc("multiply.441")
#loc141 = loc("convert.442")
#loc142 = loc("dot.447")
#loc143 = loc("reshape.448")
#loc144 = loc("reshape.89_tm0"(#loc3))
#loc145 = loc("reshape.388_tm0"(#loc8))
#loc146 = loc("reshape.446_tm0"(#loc11))
#loc147 = loc("subtract.238_neg"(#loc15))
#loc148 = loc("compare.240_workaround"(#loc16))
#loc149 = loc("broadcast.308_tm0"(#loc19))
#loc150 = loc("compare.212_workaround"(#loc21))
#loc151 = loc("gather.49_workaround"(#loc44))
#loc152 = loc("reshape.298_tm0"(#loc83))
#loc153 = loc("reshape.298_tm1"(#loc83))
#loc154 = loc("dot.336_reduceScatter"(#loc113))
#loc155 = loc("dot.336_all_gather_4d"(#loc113))
#loc156 = loc("dot.400_reduceScatter"(#loc132))
#loc157 = loc("dot.400_all_gather_4d"(#loc132))
#loc158 = loc("reshape.89_tm0_tm1"(#loc144))
#loc159 = loc("reshape.388_tm0_tm0"(#loc145))
#loc160 = loc("reshape.89_tm0_tm0"(#loc144))
#loc161 = loc("reshape.446_tm0_tm0"(#loc146))
#loc162 = loc("broadcast.308_tm0_tm0"(#loc149))
#loc163 = loc("broadcast.308_tm0_tm1"(#loc149))
#loc164 = loc("reshape.298_tm0_tm0"(#loc152))
#loc165 = loc("reshape.298_tm1_tm0"(#loc153))
#loc166 = loc("dot.336_reduceScatter_reshape_to_4d"(#loc154))
#loc167 = loc("dot.336_reduceScatter_reduce_scatter_4d"(#loc154))
#loc168 = loc("dot.400_reduceScatter_reshape_to_4d"(#loc156))
#loc169 = loc("dot.400_reduceScatter_reduce_scatter_4d"(#loc156))
#loc170 = loc("reshape.89_tm0_tm1_tm1"(#loc158))
#loc171 = loc("reshape.388_tm0_tm0_tm0"(#loc159))
#loc172 = loc("reshape.89_tm0_tm0_tm0"(#loc160))
#loc173 = loc("reshape.446_tm0_tm0_tm0"(#loc161))
#loc174 = loc("broadcast.308_tm0_tm0_tm0"(#loc162))
#loc175 = loc("broadcast.308_tm0_tm1_tm0"(#loc163))
#loc176 = loc("reshape.298_tm0_tm0_tm1"(#loc164))
#loc177 = loc("reshape.298_tm1_tm0_tm1"(#loc165))
#loc178 = loc("reshape.89_tm0_tm1_tm1_tm0"(#loc170))
#loc179 = loc("broadcast.308_tm0_tm1_tm0_tm0"(#loc175))
#loc180 = loc("broadcast.308_tm0_tm1_tm0_tm1"(#loc175))
#loc181 = loc("reshape.89_tm0_tm1_tm1_tm0_tm1"(#loc178))
2025-09-22 18:07:09.900 (   9.585s) [        A88F8000]loaded_executable_insta:448      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2025-09-22 18:07:09.900 (   9.585s) [        A88F8000]loaded_executable_insta:467      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2025-09-22 18:07:09.901 (   9.586s) [        A88F8000]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2025-09-22 18:07:09.901 (   9.586s) [        A88F8000]      error_instance.cc:49       1| ErrorInstance::PJRT_Error_Message
2025-09-22 18:07:09.901 (   9.586s) [        A88F8000]      error_instance.cc:58       1| ErrorInstance::PJRT_Error_GetCode
2025-09-22 18:07:09.901 (   9.586s) [        A88F8000]      error_instance.cc:43       1| ErrorInstance::PJRT_Error_Destroy
2025-09-22 18:07:09.901 (   9.586s) [        A88F8000] executable_instance.cc:107      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-22 18:07:09.901 (   9.586s) [        A88F8000] executable_instance.cc:107      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-22 18:07:09.914 (   9.599s) [        A88F8000] executable_instance.cc:107      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-22 18:07:09.914 (   9.599s) [        A88F8000] executable_instance.cc:107      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-22 18:07:09.932 (   9.618s) [        EB7FE640]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.932 (   9.618s) [        EB7FE640]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:07:09.932 (   9.618s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        197FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        197FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        197FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        197FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.618s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.619s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.619s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.619s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.619s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:07:09.933 (   9.619s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:07:09.933 (   9.619s) [        EB7FE640] executable_instance.cc:139      1| ExecutableInstance::PJRT_Executable_NumOutputs
2025-09-22 18:07:09.933 (   9.619s) [        EB7FE640]loaded_executable_insta:504      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2025-09-22 18:07:09.933 (   9.619s) [        EB7FE640]loaded_executable_insta:81       1| LoadedExecutableInstance::Execute
2025-09-22 18:07:13.020 (  12.706s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=0 device_index=0 BufferInstance=0x70b83860 shape=[7] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:13.020 (  12.706s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=0 device_index=1 BufferInstance=0x70cb1c50 shape=[7] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:13.022 (  12.708s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=1 device_index=0 BufferInstance=0x8389c180 shape=[64] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:13.022 (  12.708s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=1 device_index=1 BufferInstance=0x56402200 shape=[64] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:13.022 (  12.708s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=2 device_index=0 BufferInstance=0x70d09dc0 shape=[512,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:13.022 (  12.708s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=2 device_index=1 BufferInstance=0x75273df0 shape=[512,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:13.673 (  13.359s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=3 device_index=0 BufferInstance=0x4cb0a0f0 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:13.673 (  13.359s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=3 device_index=1 BufferInstance=0x70d78610 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:13.673 (  13.359s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=4 device_index=0 BufferInstance=0x45847a60 shape=[1,7] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:13.673 (  13.359s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=4 device_index=1 BufferInstance=0x457dba50 shape=[1,7] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:13.674 (  13.359s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=5 device_index=0 BufferInstance=0x70be4ad0 shape=[128256,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:13.674 (  13.359s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=5 device_index=1 BufferInstance=0x56366f40 shape=[128256,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:14.406 (  14.092s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=6 device_index=0 BufferInstance=0x70bdeeb0 shape=[3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:14.406 (  14.092s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=6 device_index=1 BufferInstance=0x70bb4740 shape=[3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:15.008 (  14.694s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=7 device_index=0 BufferInstance=0x75655cf0 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:15.009 (  14.694s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=7 device_index=1 BufferInstance=0x70b99b00 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:15.009 (  14.695s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=8 device_index=0 BufferInstance=0x70ba04a0 shape=[1,4,16,128] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:15.009 (  14.695s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=8 device_index=1 BufferInstance=0x8380c550 shape=[1,4,16,128] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:15.694 (  15.380s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=9 device_index=0 BufferInstance=0x70d73bd0 shape=[512,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:15.694 (  15.380s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=9 device_index=1 BufferInstance=0x75237850 shape=[512,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:15.702 (  15.388s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=10 device_index=0 BufferInstance=0x83a26480 shape=[1,4,16,128] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:15.702 (  15.388s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=10 device_index=1 BufferInstance=0x70c99d20 shape=[1,4,16,128] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:15.710 (  15.396s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=11 device_index=0 BufferInstance=0x83a477b0 shape=[128256,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:15.710 (  15.396s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=11 device_index=1 BufferInstance=0x838479a0 shape=[128256,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:15.833 (  15.519s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=12 device_index=0 BufferInstance=0x839c8d70 shape=[3072,4096] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:15.833 (  15.519s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=12 device_index=1 BufferInstance=0x75260c70 shape=[3072,4096] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:16.518 (  16.204s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=13 device_index=0 BufferInstance=0x562879c0 shape=[4096,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:16.518 (  16.204s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=13 device_index=1 BufferInstance=0x56375710 shape=[4096,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:17.046 (  16.731s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=14 device_index=0 BufferInstance=0x83987740 shape=[3072,1536] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:17.046 (  16.731s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=14 device_index=1 BufferInstance=0x70b7a050 shape=[3072,1536] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:17.686 (  17.372s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=15 device_index=0 BufferInstance=0x563f20c0 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:17.686 (  17.372s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=15 device_index=1 BufferInstance=0x562b0440 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:18.330 (  18.016s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=16 device_index=0 BufferInstance=0x85689af0 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:18.330 (  18.016s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=16 device_index=1 BufferInstance=0x4cb02a20 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:18.331 (  18.016s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=17 device_index=0 BufferInstance=0x75566b90 shape=[1536,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:18.331 (  18.016s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=17 device_index=1 BufferInstance=0x7521bd00 shape=[1536,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:18.982 (  18.668s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=18 device_index=0 BufferInstance=0x564996d0 shape=[3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:18.982 (  18.668s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=18 device_index=1 BufferInstance=0x8377f530 shape=[3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:18.983 (  18.669s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=19 device_index=0 BufferInstance=0x70d0dda0 shape=[4096,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:18.983 (  18.669s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=19 device_index=1 BufferInstance=0x84b9e330 shape=[4096,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:18.988 (  18.674s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=20 device_index=0 BufferInstance=0x83a44590 shape=[3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:07:18.988 (  18.674s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=20 device_index=1 BufferInstance=0x839e0890 shape=[3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f5860035cc0 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=0 output_index=0 NEW BufferInstance=0x7f5860035cc0 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f5860cbfb10 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=0 output_index=1 NEW BufferInstance=0x7f5860cbfb10 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f5860cbfc40 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=0 output_index=2 NEW BufferInstance=0x7f5860cbfc40 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f5860d54010 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=0 output_index=3 NEW BufferInstance=0x7f5860d54010 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f5860d348c0 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=1 output_index=0 NEW BufferInstance=0x7f5860d348c0 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f5860d029c0 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=1 output_index=1 NEW BufferInstance=0x7f5860d029c0 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f5860d3e060 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=1 output_index=2 NEW BufferInstance=0x7f5860d3e060 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f5860d088d0 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:05.114 (  64.799s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=1 output_index=3 NEW BufferInstance=0x7f5860d088d0 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:05.186 (  64.871s) [        EB7FE640]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:05.186 (  64.872s) [        EB7FE640]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:05.187 (  64.872s) [        EB7FE640]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:05.187 (  64.872s) [        EB7FE640]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:05.187 (  64.872s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:05.187 (  64.873s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:05.187 (  64.873s) [        A88F8000]     buffer_instance.cc:446      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-22 18:08:05.187 (  64.873s) [        A88F8000]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:05.187 (  64.873s) [        A88F8000]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.187 (  64.873s) [        A88F8000]     buffer_instance.cc:468      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-22 18:08:05.188 (  64.873s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:05.188 (  64.874s) [        18955640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:05.190 (  64.876s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:05.190 (  64.876s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:05.190 (  64.876s) [        A88F8000]     buffer_instance.cc:446      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-22 18:08:05.190 (  64.876s) [        A88F8000]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:05.190 (  64.876s) [        A88F8000]     buffer_instance.cc:468      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-22 18:08:05.190 (  64.876s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:05.191 (  64.876s) [        19156640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:05.193 (  64.878s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:05.193 (  64.878s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:05.193 (  64.879s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:05.193 (  64.879s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:05.193 (  64.879s) [        A88F8000]     buffer_instance.cc:446      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-22 18:08:05.193 (  64.879s) [        A88F8000]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:05.193 (  64.879s) [        A88F8000]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.193 (  64.879s) [        A88F8000]     buffer_instance.cc:468      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-22 18:08:05.193 (  64.879s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User is requesting to copy the data from a runtime tensor with data type: Int32 into buffer with expected data type: Int64, the values will be casted, this may impact the throughput and the integrity of the data.
2025-09-22 18:08:05.193 (  64.879s) [        19156640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:05.194 (  64.879s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:05.194 (  64.879s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:05.194 (  64.879s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:05.194 (  64.879s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:05.194 (  64.879s) [        A88F8000]     buffer_instance.cc:446      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-22 18:08:05.194 (  64.879s) [        A88F8000]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:05.194 (  64.879s) [        A88F8000]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.194 (  64.879s) [        A88F8000]     buffer_instance.cc:468      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-22 18:08:05.194 (  64.880s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:05.194 (  64.880s) [        19957640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:05.194 (  64.880s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:05.194 (  64.880s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:05.194 (  64.880s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:08:05.194 (  64.880s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:08:05.194 (  64.880s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:08:05.194 (  64.880s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70b83860 copyFromHost BORROWED shape=[1,4,16,128] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:08:05.194 (  64.880s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:05.194 (  64.880s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:05.194 (  64.880s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:08:05.194 (  64.880s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:08:05.194 (  64.880s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:08:05.195 (  64.880s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x70c4afc0 copyFromHost BORROWED shape=[1,4,16,128] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:08:05.195 (  64.880s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:05.195 (  64.880s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:05.195 (  64.880s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:05.195 (  64.880s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:05.195 (  64.880s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:05.195 (  64.880s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:05.195 (  64.880s) [        A88F8000]     buffer_instance.cc:446      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-22 18:08:05.195 (  64.880s) [        A88F8000]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:05.195 (  64.880s) [        A88F8000]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:05.195 (  64.880s) [        A88F8000]     buffer_instance.cc:468      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-22 18:08:05.195 (  64.880s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:05.195 (  64.881s) [        19156640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x7f5860d348c0 copyFromHost BORROWED shape=[1,4,16,128] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x7f5860035cc0 copyFromHost BORROWED shape=[1,4,16,128] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:05.195 (  64.881s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:06.442 (  66.128s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:06.442 (  66.128s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:06.442 (  66.128s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:08:06.442 (  66.128s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:08:06.442 (  66.128s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-22 18:08:06.443 (  66.128s) [        A88F8000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x80a21be0 copyFromHost OWNED shape=[1,1] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:08:06.443 (  66.128s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:06.443 (  66.128s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:06.443 (  66.128s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x83a58d50 copyFromHost OWNED shape=[1,1] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x44887f60 copyFromHost OWNED shape=[1] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x84c968b0 copyFromHost OWNED shape=[1] - NEW tensor.data=0x7ffc8de5ff70 tensor.handle=0x7ffc8de5ffc0
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:06.443 (  66.129s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.451 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.137s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.452 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.453 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.453 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.453 (  66.138s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.453 (  66.139s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.453 (  66.139s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.453 (  66.139s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:06.483 (  66.168s) [        A88F8000]     client_instance.cc:427      1| ClientInstance::PJRT_Client_Compile
2025-09-22 18:08:06.483 (  66.168s) [        A88F8000]      module_builder.cc:99       1| ModuleBuilder::buildModule
2025-09-22 18:08:06.484 (  66.170s) [        A88F8000]      module_builder.cc:161      1| VHLO Module:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.31")
#loc4 = loc("p3.37")
#loc5 = loc("p4.39")
#loc6 = loc("p5.44")
#loc7 = loc("p6.81")
#loc8 = loc("p7.118")
#loc9 = loc("p8.128")
#loc10 = loc("p9.137")
#loc11 = loc("p10.156")
#loc12 = loc("p11.165")
#loc13 = loc("p12.173")
#loc14 = loc("p13.178")
#loc15 = loc("p14.186")
#loc16 = loc("p15.210")
#loc17 = loc("p16.226")
#loc18 = loc("p17.241")
#loc19 = loc("p18.343")
#loc20 = loc("p19.355")
#loc21 = loc("p20.407")
#loc47 = loc("reduce.60")
#loc98 = loc("scatter.134")
#loc107 = loc("scatter.162")
#loc156 = loc("reduce.288")
#loc161 = loc("reduce.297")
#loc185 = loc("reduce.322")
#loc230 = loc("reduce.386")
module @SyncTensorsGraph.422 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1x!vhlo.i64_v1> loc("p0.3"), %arg1: !vhlo.tensor_v1<64x!vhlo.f32_v1> loc("p1.13"), %arg2: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc("p2.31"), %arg3: !vhlo.tensor_v1<!vhlo.f32_v1> loc("p3.37"), %arg4: !vhlo.tensor_v1<1x1x!vhlo.i64_v1> loc("p4.39"), %arg5: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc("p5.44"), %arg6: !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc("p6.81"), %arg7: !vhlo.tensor_v1<!vhlo.i64_v1> loc("p7.118"), %arg8: !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc("p8.128"), %arg9: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc("p9.137"), %arg10: !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc("p10.156"), %arg11: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc("p11.165"), %arg12: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc("p12.173"), %arg13: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc("p13.178"), %arg14: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc("p14.186"), %arg15: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("p15.210"), %arg16: !vhlo.tensor_v1<!vhlo.f32_v1> loc("p16.226"), %arg17: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc("p17.241"), %arg18: !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc("p18.343"), %arg19: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc("p19.355"), %arg20: !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc("p20.407")) -> (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : () -> !vhlo.tensor_v1<1x!vhlo.i64_v1> loc(#loc)
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]> : tensor<1x16xi64>>}> : () -> !vhlo.tensor_v1<1x16x!vhlo.i64_v1> loc(#loc)
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<3.25520843E-4> : tensor<1x1xf32>>}> : () -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc)
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %6 = "vhlo.broadcast_in_dim_v1"(%5) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc)
    %7 = "vhlo.custom_call_v1"(%arg8) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_2">}>} : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc(#loc22)
    %8 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.i64_v1> loc(#loc23)
    %9 = "vhlo.custom_call_v1"(%8) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.i64_v1> loc(#loc24)
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1> loc(#loc25)
    %11 = "vhlo.compare_v1"(%10, %2) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.bool_v1> loc(#loc26)
    %12 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1> loc(#loc27)
    %13 = "vhlo.add_v1"(%10, %12) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1> loc(#loc28)
    %14 = "vhlo.select_v1"(%11, %13, %10) : (!vhlo.tensor_v1<1x!vhlo.bool_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1> loc(#loc29)
    %15 = "vhlo.reshape_v1"(%14) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.i64_v1> loc(#loc30)
    %16 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc31)
    %17 = "vhlo.custom_call_v1"(%16) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc32)
    %18 = "vhlo.reshape_v1"(%17) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc(#loc33)
    %19 = "vhlo.convert_v1"(%18) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1> loc(#loc34)
    %20 = "vhlo.reshape_v1"(%19) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc35)
    %21 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc36)
    %22 = "vhlo.custom_call_v1"(%21) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc37)
    %23 = "vhlo.reshape_v1"(%22) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc(#loc38)
    %24 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.i64_v1> loc(#loc39)
    %25 = "vhlo.custom_call_v1"(%24) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.i64_v1> loc(#loc40)
    %26 = "vhlo.reshape_v1"(%25) : (!vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1> loc(#loc41)
    %27 = "vhlo.convert_v1"(%26) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.ui32_v1> loc(#loc42)
    %28 = "vhlo.gather_v2"(%23, %27) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3072]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc43)
    %29 = "vhlo.reshape_v1"(%28) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc44)
    %30 = "vhlo.convert_v1"(%29) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc45)
    %31 = "vhlo.power_v1"(%30, %6) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc46)
    %32 = "vhlo.reduce_v1"(%31, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.60"), %arg22: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.60")):
      %230 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc48)
      "vhlo.return_v1"(%230) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc47)
    %33 = "vhlo.multiply_v1"(%32, %4) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc49)
    %34 = "vhlo.reshape_v1"(%33) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc50)
    %35 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc51)
    %36 = "vhlo.add_v1"(%34, %35) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc52)
    %37 = "vhlo.rsqrt_v2"(%36) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc53)
    %38 = "vhlo.reshape_v1"(%37) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc54)
    %39 = "vhlo.broadcast_in_dim_v1"(%38) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc55)
    %40 = "vhlo.multiply_v1"(%30, %39) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc56)
    %41 = "vhlo.convert_v1"(%40) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc57)
    %42 = "vhlo.convert_v1"(%41) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc58)
    %43 = "vhlo.multiply_v1"(%20, %42) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc59)
    %44 = "vhlo.convert_v1"(%43) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc60)
    %45 = "vhlo.reshape_v1"(%44) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc61)
    %46 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc62)
    %47 = "vhlo.custom_call_v1"(%46) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc63)
    %48 = "vhlo.reshape_v1"(%47) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc(#loc64)
    %49 = "vhlo.transpose_v1"(%48) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1> loc(#loc65)
    %50 = "vhlo.dot_general_v2"(%45, %49) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1> loc(#loc66)
    %51 = "vhlo.reshape_v1"(%50) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc67)
    %52 = "vhlo.convert_v1"(%51) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1> loc(#loc68)
    %53 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc69)
    %54 = "vhlo.custom_call_v1"(%53) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc70)
    %55 = "vhlo.reshape_v1"(%54) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1> loc(#loc71)
    %56 = "vhlo.convert_v1"(%9) : (!vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc72)
    %57 = "vhlo.dot_general_v2"(%55, %56) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1> loc(#loc73)
    %58 = "vhlo.reshape_v1"(%57) : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc74)
    %59 = "vhlo.concatenate_v1"(%58, %58) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1> loc(#loc75)
    %60 = "vhlo.cosine_v2"(%59) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1> loc(#loc76)
    %61 = "vhlo.convert_v1"(%60) : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1> loc(#loc77)
    %62 = "vhlo.reshape_v1"(%61) : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1> loc(#loc78)
    %63 = "vhlo.convert_v1"(%62) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1> loc(#loc79)
    %64 = "vhlo.reshape_v1"(%63) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1> loc(#loc80)
    %65 = "vhlo.broadcast_in_dim_v1"(%64) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1> loc(#loc81)
    %66 = "vhlo.multiply_v1"(%52, %65) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1> loc(#loc82)
    %67 = "vhlo.convert_v1"(%66) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc83)
    %68 = "vhlo.slice_v1"(%51) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1> loc(#loc84)
    %69 = "vhlo.negate_v1"(%68) : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1> loc(#loc85)
    %70 = "vhlo.slice_v1"(%51) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1> loc(#loc86)
    %71 = "vhlo.concatenate_v1"(%69, %70) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc87)
    %72 = "vhlo.convert_v1"(%71) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1> loc(#loc88)
    %73 = "vhlo.sine_v2"(%59) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1> loc(#loc89)
    %74 = "vhlo.convert_v1"(%73) : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1> loc(#loc90)
    %75 = "vhlo.reshape_v1"(%74) : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1> loc(#loc91)
    %76 = "vhlo.convert_v1"(%75) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1> loc(#loc92)
    %77 = "vhlo.reshape_v1"(%76) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1> loc(#loc93)
    %78 = "vhlo.broadcast_in_dim_v1"(%77) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1> loc(#loc94)
    %79 = "vhlo.multiply_v1"(%72, %78) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1> loc(#loc95)
    %80 = "vhlo.convert_v1"(%79) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc96)
    %81 = "vhlo.add_v1"(%67, %80) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc97)
    %82 = "vhlo.scatter_v2"(%7, %15, %81) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.134"), %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.134")):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc(#loc98)
    %83 = "vhlo.custom_call_v1"(%82) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc(#loc99)
    %84 = "vhlo.custom_call_v1"(%arg10) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_3">}>} : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc(#loc100)
    %85 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc101)
    %86 = "vhlo.custom_call_v1"(%85) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc102)
    %87 = "vhlo.reshape_v1"(%86) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc(#loc103)
    %88 = "vhlo.transpose_v1"(%87) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1> loc(#loc104)
    %89 = "vhlo.dot_general_v2"(%45, %88) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1> loc(#loc105)
    %90 = "vhlo.reshape_v1"(%89) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc106)
    %91 = "vhlo.scatter_v2"(%84, %15, %90) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.162"), %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.162")):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc(#loc107)
    %92 = "vhlo.custom_call_v1"(%91) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1> loc(#loc108)
    %93 = "vhlo.reshape_v1"(%arg20) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc109)
    %94 = "vhlo.custom_call_v1"(%93) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_norm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc110)
    %95 = "vhlo.reshape_v1"(%94) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc(#loc111)
    %96 = "vhlo.convert_v1"(%95) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1> loc(#loc112)
    %97 = "vhlo.reshape_v1"(%96) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc113)
    %98 = "vhlo.reshape_v1"(%arg17) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc114)
    %99 = "vhlo.custom_call_v1"(%98) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc115)
    %100 = "vhlo.reshape_v1"(%99) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc116)
    %101 = "vhlo.transpose_v1"(%100) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc117)
    %102 = "vhlo.dot_general_v2"(%45, %101) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc118)
    %103 = "vhlo.reshape_v1"(%102) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc119)
    %104 = "vhlo.convert_v1"(%103) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,1,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1> loc(#loc120)
    %105 = "vhlo.broadcast_in_dim_v1"(%64) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1> loc(#loc121)
    %106 = "vhlo.multiply_v1"(%104, %105) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1> loc(#loc122)
    %107 = "vhlo.convert_v1"(%106) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc123)
    %108 = "vhlo.slice_v1"(%103) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1> loc(#loc124)
    %109 = "vhlo.negate_v1"(%108) : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1> loc(#loc125)
    %110 = "vhlo.slice_v1"(%103) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1> loc(#loc126)
    %111 = "vhlo.concatenate_v1"(%109, %110) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc127)
    %112 = "vhlo.convert_v1"(%111) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1> loc(#loc128)
    %113 = "vhlo.broadcast_in_dim_v1"(%77) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1> loc(#loc129)
    %114 = "vhlo.multiply_v1"(%112, %113) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1> loc(#loc130)
    %115 = "vhlo.convert_v1"(%114) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc131)
    %116 = "vhlo.add_v1"(%107, %115) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc132)
    %117 = "vhlo.reshape_v1"(%116) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1> loc(#loc133)
    %118 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x16x128x!vhlo.bf16_v1> loc(#loc134)
    %119 = "vhlo.reshape_v1"(%118) : (!vhlo.tensor_v1<1x8x3x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x16x128x!vhlo.bf16_v1> loc(#loc135)
    %120 = "vhlo.transpose_v1"(%119) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,16]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x16x!vhlo.bf16_v1> loc(#loc136)
    %121 = "vhlo.reshape_v1"(%120) : (!vhlo.tensor_v1<1x24x128x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x16x!vhlo.bf16_v1> loc(#loc137)
    %122 = "vhlo.dot_general_v2"(%117, %121) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x16x!vhlo.bf16_v1> loc(#loc138)
    %123 = "vhlo.reshape_v1"(%122) : (!vhlo.tensor_v1<24x1x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.bf16_v1> loc(#loc139)
    %124 = "vhlo.convert_v1"(%123) : (!vhlo.tensor_v1<1x24x1x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1> loc(#loc140)
    %125 = "vhlo.broadcast_in_dim_v1"(%arg16) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1> loc(#loc141)
    %126 = "vhlo.multiply_v1"(%124, %125) : (!vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1> loc(#loc142)
    %127 = "vhlo.convert_v1"(%126) : (!vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.bf16_v1> loc(#loc143)
    %128 = "vhlo.reshape_v1"(%arg15) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x!vhlo.bf16_v1> loc(#loc144)
    %129 = "vhlo.broadcast_in_dim_v1"(%128) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<1x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x16x!vhlo.bf16_v1> loc(#loc145)
    %130 = "vhlo.convert_v1"(%129) : (!vhlo.tensor_v1<1x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x16x!vhlo.f32_v1> loc(#loc146)
    %131 = "vhlo.broadcast_in_dim_v1"(%10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x16x!vhlo.i64_v1> loc(#loc147)
    %132 = "vhlo.compare_v1"(%3, %131) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<1x16x!vhlo.i64_v1>, !vhlo.tensor_v1<1x16x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x16x!vhlo.bool_v1> loc(#loc148)
    %133 = "vhlo.convert_v1"(%132) : (!vhlo.tensor_v1<1x16x!vhlo.bool_v1>) -> !vhlo.tensor_v1<1x16x!vhlo.f32_v1> loc(#loc149)
    %134 = "vhlo.multiply_v1"(%130, %133) : (!vhlo.tensor_v1<1x16x!vhlo.f32_v1>, !vhlo.tensor_v1<1x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x16x!vhlo.f32_v1> loc(#loc150)
    %135 = "vhlo.convert_v1"(%134) : (!vhlo.tensor_v1<1x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x16x!vhlo.bf16_v1> loc(#loc151)
    %136 = "vhlo.reshape_v1"(%135) : (!vhlo.tensor_v1<1x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x16x!vhlo.bf16_v1> loc(#loc152)
    %137 = "vhlo.broadcast_in_dim_v1"(%136) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.bf16_v1> loc(#loc153)
    %138 = "vhlo.add_v1"(%127, %137) : (!vhlo.tensor_v1<1x24x1x16x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.bf16_v1> loc(#loc154)
    %139 = "vhlo.convert_v1"(%138) : (!vhlo.tensor_v1<1x24x1x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1> loc(#loc155)
    %140 = "vhlo.reduce_v1"(%139, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.288"), %arg22: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.288")):
      %230 = "vhlo.maximum_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc157)
      "vhlo.return_v1"(%230) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1> loc(#loc156)
    %141 = "vhlo.broadcast_in_dim_v1"(%140) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1> loc(#loc158)
    %142 = "vhlo.subtract_v1"(%139, %141) : (!vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1> loc(#loc159)
    %143 = "vhlo.exponential_v2"(%142) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1> loc(#loc160)
    %144 = "vhlo.reduce_v1"(%143, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.297"), %arg22: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.297")):
      %230 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc162)
      "vhlo.return_v1"(%230) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1> loc(#loc161)
    %145 = "vhlo.broadcast_in_dim_v1"(%144) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1> loc(#loc163)
    %146 = "vhlo.divide_v1"(%143, %145) : (!vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1> loc(#loc164)
    %147 = "vhlo.convert_v1"(%146) : (!vhlo.tensor_v1<1x24x1x16x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x16x!vhlo.bf16_v1> loc(#loc165)
    %148 = "vhlo.reshape_v1"(%147) : (!vhlo.tensor_v1<1x24x1x16x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x16x!vhlo.bf16_v1> loc(#loc166)
    %149 = "vhlo.broadcast_in_dim_v1"(%91) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x16x128x!vhlo.bf16_v1> loc(#loc167)
    %150 = "vhlo.reshape_v1"(%149) : (!vhlo.tensor_v1<1x8x3x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x16x128x!vhlo.bf16_v1> loc(#loc168)
    %151 = "vhlo.dot_general_v2"(%148, %150) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x1x16x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x16x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1> loc(#loc169)
    %152 = "vhlo.reshape_v1"(%151) : (!vhlo.tensor_v1<24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc170)
    %153 = "vhlo.reshape_v1"(%arg14) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc171)
    %154 = "vhlo.custom_call_v1"(%153) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc172)
    %155 = "vhlo.reshape_v1"(%154) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc173)
    %156 = "vhlo.transpose_v1"(%155) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc174)
    %157 = "vhlo.dot_general_v2"(%152, %156) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc175)
    %158 = "vhlo.reshape_v1"(%157) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc176)
    %159 = "vhlo.add_v1"(%29, %158) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc177)
    %160 = "vhlo.reshape_v1"(%arg18) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc178)
    %161 = "vhlo.custom_call_v1"(%160) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc179)
    %162 = "vhlo.reshape_v1"(%161) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc(#loc180)
    %163 = "vhlo.convert_v1"(%162) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1> loc(#loc181)
    %164 = "vhlo.reshape_v1"(%163) : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc182)
    %165 = "vhlo.convert_v1"(%159) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc183)
    %166 = "vhlo.power_v1"(%165, %6) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc184)
    %167 = "vhlo.reduce_v1"(%166, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.322"), %arg22: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.322")):
      %230 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc186)
      "vhlo.return_v1"(%230) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc185)
    %168 = "vhlo.multiply_v1"(%167, %4) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc187)
    %169 = "vhlo.reshape_v1"(%168) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc188)
    %170 = "vhlo.add_v1"(%169, %35) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc189)
    %171 = "vhlo.rsqrt_v2"(%170) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc190)
    %172 = "vhlo.reshape_v1"(%171) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc191)
    %173 = "vhlo.broadcast_in_dim_v1"(%172) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc192)
    %174 = "vhlo.multiply_v1"(%165, %173) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc193)
    %175 = "vhlo.convert_v1"(%174) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc194)
    %176 = "vhlo.convert_v1"(%175) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc195)
    %177 = "vhlo.multiply_v1"(%164, %176) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc196)
    %178 = "vhlo.convert_v1"(%177) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc197)
    %179 = "vhlo.reshape_v1"(%178) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc198)
    %180 = "vhlo.reshape_v1"(%arg19) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc199)
    %181 = "vhlo.custom_call_v1"(%180) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc200)
    %182 = "vhlo.reshape_v1"(%181) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc(#loc201)
    %183 = "vhlo.transpose_v1"(%182) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc(#loc202)
    %184 = "vhlo.dot_general_v2"(%179, %183) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1> loc(#loc203)
    %185 = "vhlo.reshape_v1"(%184) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc204)
    %186 = "vhlo.convert_v1"(%185) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1> loc(#loc205)
    %187 = "vhlo.logistic_v2"(%185) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc206)
    %188 = "vhlo.convert_v1"(%187) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1> loc(#loc207)
    %189 = "vhlo.multiply_v1"(%186, %188) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1> loc(#loc208)
    %190 = "vhlo.convert_v1"(%189) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc209)
    %191 = "vhlo.convert_v1"(%190) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1> loc(#loc210)
    %192 = "vhlo.reshape_v1"(%arg13) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc211)
    %193 = "vhlo.custom_call_v1"(%192) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc212)
    %194 = "vhlo.reshape_v1"(%193) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc(#loc213)
    %195 = "vhlo.transpose_v1"(%194) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc(#loc214)
    %196 = "vhlo.dot_general_v2"(%179, %195) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1> loc(#loc215)
    %197 = "vhlo.reshape_v1"(%196) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc216)
    %198 = "vhlo.convert_v1"(%197) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1> loc(#loc217)
    %199 = "vhlo.multiply_v1"(%191, %198) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1> loc(#loc218)
    %200 = "vhlo.convert_v1"(%199) : (!vhlo.tensor_v1<1x1x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc219)
    %201 = "vhlo.reshape_v1"(%200) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1> loc(#loc220)
    %202 = "vhlo.reshape_v1"(%arg12) : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1> loc(#loc221)
    %203 = "vhlo.custom_call_v1"(%202) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1> loc(#loc222)
    %204 = "vhlo.reshape_v1"(%203) : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc(#loc223)
    %205 = "vhlo.transpose_v1"(%204) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc(#loc224)
    %206 = "vhlo.dot_general_v2"(%201, %205) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc225)
    %207 = "vhlo.reshape_v1"(%206) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc226)
    %208 = "vhlo.add_v1"(%159, %207) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc227)
    %209 = "vhlo.convert_v1"(%208) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc228)
    %210 = "vhlo.power_v1"(%209, %6) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc229)
    %211 = "vhlo.reduce_v1"(%210, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.386"), %arg22: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.386")):
      %230 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc231)
      "vhlo.return_v1"(%230) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc230)
    %212 = "vhlo.multiply_v1"(%211, %4) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc232)
    %213 = "vhlo.reshape_v1"(%212) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc233)
    %214 = "vhlo.add_v1"(%213, %35) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc234)
    %215 = "vhlo.rsqrt_v2"(%214) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc235)
    %216 = "vhlo.reshape_v1"(%215) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc236)
    %217 = "vhlo.broadcast_in_dim_v1"(%216) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc237)
    %218 = "vhlo.multiply_v1"(%209, %217) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc238)
    %219 = "vhlo.convert_v1"(%218) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc239)
    %220 = "vhlo.convert_v1"(%219) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc240)
    %221 = "vhlo.multiply_v1"(%97, %220) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc241)
    %222 = "vhlo.convert_v1"(%221) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc242)
    %223 = "vhlo.reshape_v1"(%222) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc243)
    %224 = "vhlo.reshape_v1"(%arg11) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc244)
    %225 = "vhlo.custom_call_v1"(%224) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___lm_head_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc245)
    %226 = "vhlo.reshape_v1"(%225) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc(#loc246)
    %227 = "vhlo.transpose_v1"(%226) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,128256]{0,1}">} : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1> loc(#loc247)
    %228 = "vhlo.dot_general_v2"(%223, %227) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1> loc(#loc248)
    %229 = "vhlo.reshape_v1"(%228) : (!vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1> loc(#loc249)
    "vhlo.return_v1"(%83, %92, %228, %229) : (!vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x16x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc22 = loc("custom-call.129")
#loc23 = loc("reshape.4")
#loc24 = loc("custom-call.5")
#loc25 = loc("reshape.6")
#loc26 = loc("compare.124")
#loc27 = loc("reshape.119")
#loc28 = loc("add.121")
#loc29 = loc("select.125")
#loc30 = loc("reshape.126")
#loc31 = loc("reshape.82")
#loc32 = loc("custom-call.83")
#loc33 = loc("reshape.84")
#loc34 = loc("convert.85")
#loc35 = loc("broadcast.86")
#loc36 = loc("reshape.45")
#loc37 = loc("custom-call.46")
#loc38 = loc("reshape.47")
#loc39 = loc("reshape.40")
#loc40 = loc("custom-call.41")
#loc41 = loc("reshape.43")
#loc42 = loc("convert.48")
#loc43 = loc("gather.49")
#loc44 = loc("reshape.50")
#loc45 = loc("convert.51")
#loc46 = loc("power.53")
#loc48 = loc("add.59")
#loc49 = loc("multiply.69")
#loc50 = loc("reshape.70")
#loc51 = loc("broadcast.73")
#loc52 = loc("add.74")
#loc53 = loc("rsqrt.75")
#loc54 = loc("reshape.76")
#loc55 = loc("broadcast.77")
#loc56 = loc("multiply.78")
#loc57 = loc("convert.79")
#loc58 = loc("convert.80")
#loc59 = loc("multiply.87")
#loc60 = loc("convert.88")
#loc61 = loc("reshape.89")
#loc62 = loc("reshape.32")
#loc63 = loc("custom-call.33")
#loc64 = loc("reshape.34")
#loc65 = loc("transpose.35")
#loc66 = loc("dot.90")
#loc67 = loc("transpose.93")
#loc68 = loc("convert.110")
#loc69 = loc("reshape.14")
#loc70 = loc("custom-call.15")
#loc71 = loc("reshape.19")
#loc72 = loc("convert.11")
#loc73 = loc("dot.22")
#loc74 = loc("transpose.23")
#loc75 = loc("concatenate.24")
#loc76 = loc("cosine.104")
#loc77 = loc("convert.107")
#loc78 = loc("reshape.108")
#loc79 = loc("convert.109")
#loc80 = loc("reshape.111")
#loc81 = loc("broadcast.112")
#loc82 = loc("multiply.113")
#loc83 = loc("convert.114")
#loc84 = loc("slice.95")
#loc85 = loc("negate.96")
#loc86 = loc("slice.94")
#loc87 = loc("concatenate.97")
#loc88 = loc("convert.98")
#loc89 = loc("sine.25")
#loc90 = loc("convert.28")
#loc91 = loc("reshape.29")
#loc92 = loc("convert.30")
#loc93 = loc("reshape.99")
#loc94 = loc("broadcast.100")
#loc95 = loc("multiply.101")
#loc96 = loc("convert.102")
#loc97 = loc("add.117")
#loc99 = loc("custom-call.136")
#loc100 = loc("custom-call.157")
#loc101 = loc("reshape.138")
#loc102 = loc("custom-call.139")
#loc103 = loc("reshape.140")
#loc104 = loc("transpose.141")
#loc105 = loc("dot.143")
#loc106 = loc("transpose.146")
#loc108 = loc("custom-call.164")
#loc109 = loc("reshape.408")
#loc110 = loc("custom-call.409")
#loc111 = loc("reshape.410")
#loc112 = loc("convert.411")
#loc113 = loc("broadcast.412")
#loc114 = loc("reshape.242")
#loc115 = loc("custom-call.243")
#loc116 = loc("reshape.244")
#loc117 = loc("transpose.245")
#loc118 = loc("dot.247")
#loc119 = loc("transpose.250")
#loc120 = loc("convert.261")
#loc121 = loc("broadcast.263")
#loc122 = loc("multiply.264")
#loc123 = loc("convert.265")
#loc124 = loc("slice.252")
#loc125 = loc("negate.253")
#loc126 = loc("slice.251")
#loc127 = loc("concatenate.254")
#loc128 = loc("convert.255")
#loc129 = loc("broadcast.257")
#loc130 = loc("multiply.258")
#loc131 = loc("convert.259")
#loc132 = loc("add.268")
#loc133 = loc("reshape.270")
#loc134 = loc("broadcast.234")
#loc135 = loc("reshape.235")
#loc136 = loc("transpose.236")
#loc137 = loc("reshape.238")
#loc138 = loc("dot.271")
#loc139 = loc("reshape.272")
#loc140 = loc("convert.273")
#loc141 = loc("broadcast.274")
#loc142 = loc("multiply.275")
#loc143 = loc("convert.276")
#loc144 = loc("reshape.213")
#loc145 = loc("broadcast.214")
#loc146 = loc("convert.215")
#loc147 = loc("broadcast.207")
#loc148 = loc("compare.208")
#loc149 = loc("convert.209")
#loc150 = loc("multiply.216")
#loc151 = loc("convert.217")
#loc152 = loc("reshape.218")
#loc153 = loc("broadcast.280")
#loc154 = loc("add.281")
#loc155 = loc("convert.282")
#loc157 = loc("maximum.287")
#loc158 = loc("broadcast.289")
#loc159 = loc("subtract.290")
#loc160 = loc("exponential.291")
#loc162 = loc("add.296")
#loc163 = loc("broadcast.298")
#loc164 = loc("divide.299")
#loc165 = loc("convert.300")
#loc166 = loc("reshape.302")
#loc167 = loc("broadcast.198")
#loc168 = loc("reshape.201")
#loc169 = loc("dot.303")
#loc170 = loc("reshape.307")
#loc171 = loc("reshape.187")
#loc172 = loc("custom-call.188")
#loc173 = loc("reshape.189")
#loc174 = loc("transpose.190")
#loc175 = loc("dot.308")
#loc176 = loc("reshape.309")
#loc177 = loc("add.312")
#loc178 = loc("reshape.344")
#loc179 = loc("custom-call.345")
#loc180 = loc("reshape.346")
#loc181 = loc("convert.347")
#loc182 = loc("broadcast.348")
#loc183 = loc("convert.313")
#loc184 = loc("power.315")
#loc186 = loc("add.321")
#loc187 = loc("multiply.331")
#loc188 = loc("reshape.332")
#loc189 = loc("add.336")
#loc190 = loc("rsqrt.337")
#loc191 = loc("reshape.338")
#loc192 = loc("broadcast.339")
#loc193 = loc("multiply.340")
#loc194 = loc("convert.341")
#loc195 = loc("convert.342")
#loc196 = loc("multiply.349")
#loc197 = loc("convert.350")
#loc198 = loc("reshape.360")
#loc199 = loc("reshape.356")
#loc200 = loc("custom-call.357")
#loc201 = loc("reshape.358")
#loc202 = loc("transpose.359")
#loc203 = loc("dot.361")
#loc204 = loc("reshape.362")
#loc205 = loc("convert.365")
#loc206 = loc("logistic.363")
#loc207 = loc("convert.364")
#loc208 = loc("multiply.366")
#loc209 = loc("convert.367")
#loc210 = loc("convert.368")
#loc211 = loc("reshape.179")
#loc212 = loc("custom-call.180")
#loc213 = loc("reshape.181")
#loc214 = loc("transpose.182")
#loc215 = loc("dot.352")
#loc216 = loc("reshape.353")
#loc217 = loc("convert.354")
#loc218 = loc("multiply.369")
#loc219 = loc("convert.370")
#loc220 = loc("reshape.371")
#loc221 = loc("reshape.174")
#loc222 = loc("custom-call.175")
#loc223 = loc("reshape.176")
#loc224 = loc("transpose.177")
#loc225 = loc("dot.372")
#loc226 = loc("reshape.373")
#loc227 = loc("add.376")
#loc228 = loc("convert.377")
#loc229 = loc("power.379")
#loc231 = loc("add.385")
#loc232 = loc("multiply.395")
#loc233 = loc("reshape.396")
#loc234 = loc("add.400")
#loc235 = loc("rsqrt.401")
#loc236 = loc("reshape.402")
#loc237 = loc("broadcast.403")
#loc238 = loc("multiply.404")
#loc239 = loc("convert.405")
#loc240 = loc("convert.406")
#loc241 = loc("multiply.413")
#loc242 = loc("convert.414")
#loc243 = loc("reshape.418")
#loc244 = loc("reshape.166")
#loc245 = loc("custom-call.167")
#loc246 = loc("reshape.168")
#loc247 = loc("transpose.169")
#loc248 = loc("dot.419")
#loc249 = loc("reshape.420")
2025-09-22 18:08:06.496 (  66.182s) [        A88F8000]      module_builder.cc:181      1| SHLO Module:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.31")
#loc4 = loc("p3.37")
#loc5 = loc("p4.39")
#loc6 = loc("p5.44")
#loc7 = loc("p6.81")
#loc8 = loc("p7.118")
#loc9 = loc("p8.128")
#loc10 = loc("p9.137")
#loc11 = loc("p10.156")
#loc12 = loc("p11.165")
#loc13 = loc("p12.173")
#loc14 = loc("p13.178")
#loc15 = loc("p14.186")
#loc16 = loc("p15.210")
#loc17 = loc("p16.226")
#loc18 = loc("p17.241")
#loc19 = loc("p18.343")
#loc20 = loc("p19.355")
#loc21 = loc("p20.407")
#loc97 = loc("scatter.134")
#loc106 = loc("scatter.162")
module @SyncTensorsGraph.422 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p0.3"), %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p2.31"), %arg3: tensor<f32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"} loc("p3.37"), %arg4: tensor<1x1xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p4.39"), %arg5: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p5.44"), %arg6: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p6.81"), %arg7: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"} loc("p7.118"), %arg8: tensor<1x8x16x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} loc("p8.128"), %arg9: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p9.137"), %arg10: tensor<1x8x16x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} loc("p10.156"), %arg11: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p11.165"), %arg12: tensor<3072x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p12.173"), %arg13: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p13.178"), %arg14: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p14.186"), %arg15: tensor<bf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"} loc("p15.210"), %arg16: tensor<f32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"} loc("p16.226"), %arg17: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p17.241"), %arg18: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p18.343"), %arg19: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p19.355"), %arg20: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p20.407")) -> (tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %c = stablehlo.constant dense<0> : tensor<1xi64> loc(#loc)
    %c_1 = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]> : tensor<1x16xi64> loc(#loc)
    %cst_2 = stablehlo.constant dense<3.25520843E-4> : tensor<1x1xf32> loc(#loc)
    %cst_3 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32> loc(#loc)
    %1 = stablehlo.custom_call @tt.mark_argument(%arg8) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_2"}} : (tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc22)
    %2 = stablehlo.reshape %arg0 : (tensor<1xi64>) -> tensor<1x1x1xi64> loc(#loc23)
    %3 = stablehlo.custom_call @tt.mark_argument(%2) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<1x1x1xi64>) -> tensor<1x1x1xi64> loc(#loc24)
    %4 = stablehlo.reshape %3 : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc25)
    %5 = stablehlo.compare  LT, %4, %c : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1> loc(#loc26)
    %6 = stablehlo.reshape %arg7 : (tensor<i64>) -> tensor<1xi64> loc(#loc27)
    %7 = stablehlo.add %4, %6 : tensor<1xi64> loc(#loc28)
    %8 = stablehlo.select %5, %7, %4 : tensor<1xi1>, tensor<1xi64> loc(#loc29)
    %9 = stablehlo.reshape %8 : (tensor<1xi64>) -> tensor<1x1xi64> loc(#loc30)
    %10 = stablehlo.reshape %arg6 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc31)
    %11 = stablehlo.custom_call @tt.mark_argument(%10) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc32)
    %12 = stablehlo.reshape %11 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc33)
    %13 = stablehlo.convert %12 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc34)
    %14 = stablehlo.reshape %13 : (tensor<3072xf32>) -> tensor<1x1x3072xf32> loc(#loc35)
    %15 = stablehlo.reshape %arg5 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc36)
    %16 = stablehlo.custom_call @tt.mark_argument(%15) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_embed_tokens_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc37)
    %17 = stablehlo.reshape %16 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc38)
    %18 = stablehlo.reshape %arg4 : (tensor<1x1xi64>) -> tensor<1x1x1xi64> loc(#loc39)
    %19 = stablehlo.custom_call @tt.mark_argument(%18) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x1x1xi64>) -> tensor<1x1x1xi64> loc(#loc40)
    %20 = stablehlo.reshape %19 : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc41)
    %21 = stablehlo.convert %20 : (tensor<1xi64>) -> tensor<1xui32> loc(#loc42)
    %22 = "stablehlo.gather"(%17, %21) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16> loc(#loc43)
    %23 = stablehlo.reshape %22 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc44)
    %24 = stablehlo.convert %23 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc45)
    %25 = stablehlo.power %24, %0 : tensor<1x1x3072xf32> loc(#loc46)
    %26 = stablehlo.reduce(%25 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc47)
    %27 = stablehlo.multiply %26, %cst_2 : tensor<1x1xf32> loc(#loc48)
    %28 = stablehlo.reshape %27 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc49)
    %29 = stablehlo.reshape %arg3 : (tensor<f32>) -> tensor<1x1x1xf32> loc(#loc50)
    %30 = stablehlo.add %28, %29 : tensor<1x1x1xf32> loc(#loc51)
    %31 = stablehlo.rsqrt %30 : tensor<1x1x1xf32> loc(#loc52)
    %32 = stablehlo.reshape %31 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc53)
    %33 = stablehlo.broadcast_in_dim %32, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc54)
    %34 = stablehlo.multiply %24, %33 : tensor<1x1x3072xf32> loc(#loc55)
    %35 = stablehlo.convert %34 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc56)
    %36 = stablehlo.convert %35 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc57)
    %37 = stablehlo.multiply %14, %36 : tensor<1x1x3072xf32> loc(#loc58)
    %38 = stablehlo.convert %37 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc59)
    %39 = stablehlo.reshape %38 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc60)
    %40 = stablehlo.reshape %arg2 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc61)
    %41 = stablehlo.custom_call @tt.mark_argument(%40) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc62)
    %42 = stablehlo.reshape %41 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc63)
    %43 = stablehlo.transpose %42, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc64)
    %44 = stablehlo.dot_general %39, %43, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16> loc(#loc65)
    %45 = stablehlo.reshape %44 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc66)
    %46 = stablehlo.convert %45 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32> loc(#loc67)
    %47 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc68)
    %48 = stablehlo.custom_call @tt.mark_argument(%47) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "l__self___model_rotary_emb_inv_freq"}} : (tensor<1x1x64xf32>) -> tensor<1x1x64xf32> loc(#loc69)
    %49 = stablehlo.reshape %48 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc70)
    %50 = stablehlo.convert %3 : (tensor<1x1x1xi64>) -> tensor<1x1x1xf32> loc(#loc71)
    %51 = stablehlo.dot_general %49, %50, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32> loc(#loc72)
    %52 = stablehlo.reshape %51 : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32> loc(#loc73)
    %53 = stablehlo.concatenate %52, %52, dim = 2 : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32> loc(#loc74)
    %54 = stablehlo.cosine %53 : tensor<1x1x128xf32> loc(#loc75)
    %55 = stablehlo.convert %54 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc76)
    %56 = stablehlo.reshape %55 : (tensor<1x1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc77)
    %57 = stablehlo.convert %56 : (tensor<1x1x1x128xbf16>) -> tensor<1x1x1x128xf32> loc(#loc78)
    %58 = stablehlo.reshape %57 : (tensor<1x1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc79)
    %59 = stablehlo.broadcast_in_dim %58, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32> loc(#loc80)
    %60 = stablehlo.multiply %46, %59 : tensor<1x8x1x128xf32> loc(#loc81)
    %61 = stablehlo.convert %60 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16> loc(#loc82)
    %62 = stablehlo.slice %45 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16> loc(#loc83)
    %63 = stablehlo.negate %62 : tensor<1x8x1x64xbf16> loc(#loc84)
    %64 = stablehlo.slice %45 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16> loc(#loc85)
    %65 = stablehlo.concatenate %63, %64, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc86)
    %66 = stablehlo.convert %65 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32> loc(#loc87)
    %67 = stablehlo.sine %53 : tensor<1x1x128xf32> loc(#loc88)
    %68 = stablehlo.convert %67 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc89)
    %69 = stablehlo.reshape %68 : (tensor<1x1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc90)
    %70 = stablehlo.convert %69 : (tensor<1x1x1x128xbf16>) -> tensor<1x1x1x128xf32> loc(#loc91)
    %71 = stablehlo.reshape %70 : (tensor<1x1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc92)
    %72 = stablehlo.broadcast_in_dim %71, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32> loc(#loc93)
    %73 = stablehlo.multiply %66, %72 : tensor<1x8x1x128xf32> loc(#loc94)
    %74 = stablehlo.convert %73 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16> loc(#loc95)
    %75 = stablehlo.add %61, %74 : tensor<1x8x1x128xbf16> loc(#loc96)
    %76 = "stablehlo.scatter"(%1, %9, %75) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16> loc("scatter.134"), %arg22: tensor<bf16> loc("scatter.134")):
      stablehlo.return %arg22 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x16x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc97)
    %77 = stablehlo.custom_call @Sharding(%76) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc98)
    %78 = stablehlo.custom_call @tt.mark_argument(%arg10) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_3"}} : (tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc99)
    %79 = stablehlo.reshape %arg9 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc100)
    %80 = stablehlo.custom_call @tt.mark_argument(%79) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc101)
    %81 = stablehlo.reshape %80 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc102)
    %82 = stablehlo.transpose %81, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc103)
    %83 = stablehlo.dot_general %39, %82, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16> loc(#loc104)
    %84 = stablehlo.reshape %83 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc105)
    %85 = "stablehlo.scatter"(%78, %9, %84) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16> loc("scatter.162"), %arg22: tensor<bf16> loc("scatter.162")):
      stablehlo.return %arg22 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x16x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc106)
    %86 = stablehlo.custom_call @Sharding(%85) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc107)
    %87 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc108)
    %88 = stablehlo.custom_call @tt.mark_argument(%87) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_norm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc109)
    %89 = stablehlo.reshape %88 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc110)
    %90 = stablehlo.convert %89 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc111)
    %91 = stablehlo.reshape %90 : (tensor<3072xf32>) -> tensor<1x1x3072xf32> loc(#loc112)
    %92 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc113)
    %93 = stablehlo.custom_call @tt.mark_argument(%92) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc114)
    %94 = stablehlo.reshape %93 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc115)
    %95 = stablehlo.transpose %94, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc116)
    %96 = stablehlo.dot_general %39, %95, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc117)
    %97 = stablehlo.reshape %96 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc118)
    %98 = stablehlo.convert %97 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32> loc(#loc119)
    %99 = stablehlo.broadcast_in_dim %58, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32> loc(#loc120)
    %100 = stablehlo.multiply %98, %99 : tensor<1x24x1x128xf32> loc(#loc121)
    %101 = stablehlo.convert %100 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16> loc(#loc122)
    %102 = stablehlo.slice %97 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16> loc(#loc123)
    %103 = stablehlo.negate %102 : tensor<1x24x1x64xbf16> loc(#loc124)
    %104 = stablehlo.slice %97 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16> loc(#loc125)
    %105 = stablehlo.concatenate %103, %104, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc126)
    %106 = stablehlo.convert %105 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32> loc(#loc127)
    %107 = stablehlo.broadcast_in_dim %71, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32> loc(#loc128)
    %108 = stablehlo.multiply %106, %107 : tensor<1x24x1x128xf32> loc(#loc129)
    %109 = stablehlo.convert %108 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16> loc(#loc130)
    %110 = stablehlo.add %101, %109 : tensor<1x24x1x128xbf16> loc(#loc131)
    %111 = stablehlo.reshape %110 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16> loc(#loc132)
    %112 = stablehlo.broadcast_in_dim %76, dims = [0, 1, 3, 4] : (tensor<1x8x16x128xbf16>) -> tensor<1x8x3x16x128xbf16> loc(#loc133)
    %113 = stablehlo.reshape %112 : (tensor<1x8x3x16x128xbf16>) -> tensor<1x24x16x128xbf16> loc(#loc134)
    %114 = stablehlo.transpose %113, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,16]{2,3,1,0}"} : (tensor<1x24x16x128xbf16>) -> tensor<1x24x128x16xbf16> loc(#loc135)
    %115 = stablehlo.reshape %114 : (tensor<1x24x128x16xbf16>) -> tensor<24x128x16xbf16> loc(#loc136)
    %116 = stablehlo.dot_general %111, %115, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x16xbf16>) -> tensor<24x1x16xbf16> loc(#loc137)
    %117 = stablehlo.reshape %116 : (tensor<24x1x16xbf16>) -> tensor<1x24x1x16xbf16> loc(#loc138)
    %118 = stablehlo.convert %117 : (tensor<1x24x1x16xbf16>) -> tensor<1x24x1x16xf32> loc(#loc139)
    %119 = stablehlo.broadcast_in_dim %arg16, dims = [] : (tensor<f32>) -> tensor<1x24x1x16xf32> loc(#loc140)
    %120 = stablehlo.multiply %118, %119 : tensor<1x24x1x16xf32> loc(#loc141)
    %121 = stablehlo.convert %120 : (tensor<1x24x1x16xf32>) -> tensor<1x24x1x16xbf16> loc(#loc142)
    %122 = stablehlo.reshape %arg15 : (tensor<bf16>) -> tensor<1xbf16> loc(#loc143)
    %123 = stablehlo.broadcast_in_dim %122, dims = [0] : (tensor<1xbf16>) -> tensor<1x16xbf16> loc(#loc144)
    %124 = stablehlo.convert %123 : (tensor<1x16xbf16>) -> tensor<1x16xf32> loc(#loc145)
    %125 = stablehlo.broadcast_in_dim %4, dims = [0] : (tensor<1xi64>) -> tensor<1x16xi64> loc(#loc146)
    %126 = stablehlo.compare  GT, %c_1, %125 : (tensor<1x16xi64>, tensor<1x16xi64>) -> tensor<1x16xi1> loc(#loc147)
    %127 = stablehlo.convert %126 : (tensor<1x16xi1>) -> tensor<1x16xf32> loc(#loc148)
    %128 = stablehlo.multiply %124, %127 : tensor<1x16xf32> loc(#loc149)
    %129 = stablehlo.convert %128 : (tensor<1x16xf32>) -> tensor<1x16xbf16> loc(#loc150)
    %130 = stablehlo.reshape %129 : (tensor<1x16xbf16>) -> tensor<1x1x16xbf16> loc(#loc151)
    %131 = stablehlo.broadcast_in_dim %130, dims = [0, 2, 3] : (tensor<1x1x16xbf16>) -> tensor<1x24x1x16xbf16> loc(#loc152)
    %132 = stablehlo.add %121, %131 : tensor<1x24x1x16xbf16> loc(#loc153)
    %133 = stablehlo.convert %132 : (tensor<1x24x1x16xbf16>) -> tensor<1x24x1x16xf32> loc(#loc154)
    %134 = stablehlo.reduce(%133 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x16xf32>, tensor<f32>) -> tensor<1x24x1xf32> loc(#loc155)
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x16xf32> loc(#loc156)
    %136 = stablehlo.subtract %133, %135 : tensor<1x24x1x16xf32> loc(#loc157)
    %137 = stablehlo.exponential %136 : tensor<1x24x1x16xf32> loc(#loc158)
    %138 = stablehlo.reduce(%137 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x16xf32>, tensor<f32>) -> tensor<1x24x1xf32> loc(#loc159)
    %139 = stablehlo.broadcast_in_dim %138, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x16xf32> loc(#loc160)
    %140 = stablehlo.divide %137, %139 : tensor<1x24x1x16xf32> loc(#loc161)
    %141 = stablehlo.convert %140 : (tensor<1x24x1x16xf32>) -> tensor<1x24x1x16xbf16> loc(#loc162)
    %142 = stablehlo.reshape %141 : (tensor<1x24x1x16xbf16>) -> tensor<24x1x16xbf16> loc(#loc163)
    %143 = stablehlo.broadcast_in_dim %85, dims = [0, 1, 3, 4] : (tensor<1x8x16x128xbf16>) -> tensor<1x8x3x16x128xbf16> loc(#loc164)
    %144 = stablehlo.reshape %143 : (tensor<1x8x3x16x128xbf16>) -> tensor<24x16x128xbf16> loc(#loc165)
    %145 = stablehlo.dot_general %142, %144, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x16xbf16>, tensor<24x16x128xbf16>) -> tensor<24x1x128xbf16> loc(#loc166)
    %146 = stablehlo.reshape %145 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16> loc(#loc167)
    %147 = stablehlo.reshape %arg14 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc168)
    %148 = stablehlo.custom_call @tt.mark_argument(%147) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc169)
    %149 = stablehlo.reshape %148 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc170)
    %150 = stablehlo.transpose %149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc171)
    %151 = stablehlo.dot_general %146, %150, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc172)
    %152 = stablehlo.reshape %151 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc173)
    %153 = stablehlo.add %23, %152 : tensor<1x1x3072xbf16> loc(#loc174)
    %154 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc175)
    %155 = stablehlo.custom_call @tt.mark_argument(%154) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc176)
    %156 = stablehlo.reshape %155 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc177)
    %157 = stablehlo.convert %156 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc178)
    %158 = stablehlo.reshape %157 : (tensor<3072xf32>) -> tensor<1x1x3072xf32> loc(#loc179)
    %159 = stablehlo.convert %153 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc180)
    %160 = stablehlo.power %159, %0 : tensor<1x1x3072xf32> loc(#loc181)
    %161 = stablehlo.reduce(%160 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc182)
    %162 = stablehlo.multiply %161, %cst_2 : tensor<1x1xf32> loc(#loc183)
    %163 = stablehlo.reshape %162 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc184)
    %164 = stablehlo.add %163, %29 : tensor<1x1x1xf32> loc(#loc185)
    %165 = stablehlo.rsqrt %164 : tensor<1x1x1xf32> loc(#loc186)
    %166 = stablehlo.reshape %165 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc187)
    %167 = stablehlo.broadcast_in_dim %166, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc188)
    %168 = stablehlo.multiply %159, %167 : tensor<1x1x3072xf32> loc(#loc189)
    %169 = stablehlo.convert %168 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc190)
    %170 = stablehlo.convert %169 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc191)
    %171 = stablehlo.multiply %158, %170 : tensor<1x1x3072xf32> loc(#loc192)
    %172 = stablehlo.convert %171 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc193)
    %173 = stablehlo.reshape %172 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc194)
    %174 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc195)
    %175 = stablehlo.custom_call @tt.mark_argument(%174) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc196)
    %176 = stablehlo.reshape %175 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc197)
    %177 = stablehlo.transpose %176, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc198)
    %178 = stablehlo.dot_general %173, %177, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16> loc(#loc199)
    %179 = stablehlo.reshape %178 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc200)
    %180 = stablehlo.convert %179 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32> loc(#loc201)
    %181 = stablehlo.logistic %179 : tensor<1x1x8192xbf16> loc(#loc202)
    %182 = stablehlo.convert %181 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32> loc(#loc203)
    %183 = stablehlo.multiply %180, %182 : tensor<1x1x8192xf32> loc(#loc204)
    %184 = stablehlo.convert %183 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16> loc(#loc205)
    %185 = stablehlo.convert %184 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32> loc(#loc206)
    %186 = stablehlo.reshape %arg13 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc207)
    %187 = stablehlo.custom_call @tt.mark_argument(%186) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc208)
    %188 = stablehlo.reshape %187 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc209)
    %189 = stablehlo.transpose %188, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc210)
    %190 = stablehlo.dot_general %173, %189, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16> loc(#loc211)
    %191 = stablehlo.reshape %190 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc212)
    %192 = stablehlo.convert %191 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32> loc(#loc213)
    %193 = stablehlo.multiply %185, %192 : tensor<1x1x8192xf32> loc(#loc214)
    %194 = stablehlo.convert %193 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16> loc(#loc215)
    %195 = stablehlo.reshape %194 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16> loc(#loc216)
    %196 = stablehlo.reshape %arg12 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16> loc(#loc217)
    %197 = stablehlo.custom_call @tt.mark_argument(%196) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}} : (tensor<1x3072x8192xbf16>) -> tensor<1x3072x8192xbf16> loc(#loc218)
    %198 = stablehlo.reshape %197 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16> loc(#loc219)
    %199 = stablehlo.transpose %198, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16> loc(#loc220)
    %200 = stablehlo.dot_general %195, %199, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc221)
    %201 = stablehlo.reshape %200 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc222)
    %202 = stablehlo.add %153, %201 : tensor<1x1x3072xbf16> loc(#loc223)
    %203 = stablehlo.convert %202 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc224)
    %204 = stablehlo.power %203, %0 : tensor<1x1x3072xf32> loc(#loc225)
    %205 = stablehlo.reduce(%204 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc226)
    %206 = stablehlo.multiply %205, %cst_2 : tensor<1x1xf32> loc(#loc227)
    %207 = stablehlo.reshape %206 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc228)
    %208 = stablehlo.add %207, %29 : tensor<1x1x1xf32> loc(#loc229)
    %209 = stablehlo.rsqrt %208 : tensor<1x1x1xf32> loc(#loc230)
    %210 = stablehlo.reshape %209 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc231)
    %211 = stablehlo.broadcast_in_dim %210, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc232)
    %212 = stablehlo.multiply %203, %211 : tensor<1x1x3072xf32> loc(#loc233)
    %213 = stablehlo.convert %212 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc234)
    %214 = stablehlo.convert %213 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc235)
    %215 = stablehlo.multiply %91, %214 : tensor<1x1x3072xf32> loc(#loc236)
    %216 = stablehlo.convert %215 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc237)
    %217 = stablehlo.reshape %216 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc238)
    %218 = stablehlo.reshape %arg11 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc239)
    %219 = stablehlo.custom_call @tt.mark_argument(%218) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___lm_head_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc240)
    %220 = stablehlo.reshape %219 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc241)
    %221 = stablehlo.transpose %220, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc242)
    %222 = stablehlo.dot_general %217, %221, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<1x128256xbf16> loc(#loc243)
    %223 = stablehlo.reshape %222 : (tensor<1x128256xbf16>) -> tensor<1x1x128256xbf16> loc(#loc244)
    return %77, %86, %222, %223 : tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc22 = loc("custom-call.129")
#loc23 = loc("reshape.4")
#loc24 = loc("custom-call.5")
#loc25 = loc("reshape.6")
#loc26 = loc("compare.124")
#loc27 = loc("reshape.119")
#loc28 = loc("add.121")
#loc29 = loc("select.125")
#loc30 = loc("reshape.126")
#loc31 = loc("reshape.82")
#loc32 = loc("custom-call.83")
#loc33 = loc("reshape.84")
#loc34 = loc("convert.85")
#loc35 = loc("broadcast.86")
#loc36 = loc("reshape.45")
#loc37 = loc("custom-call.46")
#loc38 = loc("reshape.47")
#loc39 = loc("reshape.40")
#loc40 = loc("custom-call.41")
#loc41 = loc("reshape.43")
#loc42 = loc("convert.48")
#loc43 = loc("gather.49")
#loc44 = loc("reshape.50")
#loc45 = loc("convert.51")
#loc46 = loc("power.53")
#loc47 = loc("reduce.60")
#loc48 = loc("multiply.69")
#loc49 = loc("reshape.70")
#loc50 = loc("broadcast.73")
#loc51 = loc("add.74")
#loc52 = loc("rsqrt.75")
#loc53 = loc("reshape.76")
#loc54 = loc("broadcast.77")
#loc55 = loc("multiply.78")
#loc56 = loc("convert.79")
#loc57 = loc("convert.80")
#loc58 = loc("multiply.87")
#loc59 = loc("convert.88")
#loc60 = loc("reshape.89")
#loc61 = loc("reshape.32")
#loc62 = loc("custom-call.33")
#loc63 = loc("reshape.34")
#loc64 = loc("transpose.35")
#loc65 = loc("dot.90")
#loc66 = loc("transpose.93")
#loc67 = loc("convert.110")
#loc68 = loc("reshape.14")
#loc69 = loc("custom-call.15")
#loc70 = loc("reshape.19")
#loc71 = loc("convert.11")
#loc72 = loc("dot.22")
#loc73 = loc("transpose.23")
#loc74 = loc("concatenate.24")
#loc75 = loc("cosine.104")
#loc76 = loc("convert.107")
#loc77 = loc("reshape.108")
#loc78 = loc("convert.109")
#loc79 = loc("reshape.111")
#loc80 = loc("broadcast.112")
#loc81 = loc("multiply.113")
#loc82 = loc("convert.114")
#loc83 = loc("slice.95")
#loc84 = loc("negate.96")
#loc85 = loc("slice.94")
#loc86 = loc("concatenate.97")
#loc87 = loc("convert.98")
#loc88 = loc("sine.25")
#loc89 = loc("convert.28")
#loc90 = loc("reshape.29")
#loc91 = loc("convert.30")
#loc92 = loc("reshape.99")
#loc93 = loc("broadcast.100")
#loc94 = loc("multiply.101")
#loc95 = loc("convert.102")
#loc96 = loc("add.117")
#loc98 = loc("custom-call.136")
#loc99 = loc("custom-call.157")
#loc100 = loc("reshape.138")
#loc101 = loc("custom-call.139")
#loc102 = loc("reshape.140")
#loc103 = loc("transpose.141")
#loc104 = loc("dot.143")
#loc105 = loc("transpose.146")
#loc107 = loc("custom-call.164")
#loc108 = loc("reshape.408")
#loc109 = loc("custom-call.409")
#loc110 = loc("reshape.410")
#loc111 = loc("convert.411")
#loc112 = loc("broadcast.412")
#loc113 = loc("reshape.242")
#loc114 = loc("custom-call.243")
#loc115 = loc("reshape.244")
#loc116 = loc("transpose.245")
#loc117 = loc("dot.247")
#loc118 = loc("transpose.250")
#loc119 = loc("convert.261")
#loc120 = loc("broadcast.263")
#loc121 = loc("multiply.264")
#loc122 = loc("convert.265")
#loc123 = loc("slice.252")
#loc124 = loc("negate.253")
#loc125 = loc("slice.251")
#loc126 = loc("concatenate.254")
#loc127 = loc("convert.255")
#loc128 = loc("broadcast.257")
#loc129 = loc("multiply.258")
#loc130 = loc("convert.259")
#loc131 = loc("add.268")
#loc132 = loc("reshape.270")
#loc133 = loc("broadcast.234")
#loc134 = loc("reshape.235")
#loc135 = loc("transpose.236")
#loc136 = loc("reshape.238")
#loc137 = loc("dot.271")
#loc138 = loc("reshape.272")
#loc139 = loc("convert.273")
#loc140 = loc("broadcast.274")
#loc141 = loc("multiply.275")
#loc142 = loc("convert.276")
#loc143 = loc("reshape.213")
#loc144 = loc("broadcast.214")
#loc145 = loc("convert.215")
#loc146 = loc("broadcast.207")
#loc147 = loc("compare.208")
#loc148 = loc("convert.209")
#loc149 = loc("multiply.216")
#loc150 = loc("convert.217")
#loc151 = loc("reshape.218")
#loc152 = loc("broadcast.280")
#loc153 = loc("add.281")
#loc154 = loc("convert.282")
#loc155 = loc("reduce.288")
#loc156 = loc("broadcast.289")
#loc157 = loc("subtract.290")
#loc158 = loc("exponential.291")
#loc159 = loc("reduce.297")
#loc160 = loc("broadcast.298")
#loc161 = loc("divide.299")
#loc162 = loc("convert.300")
#loc163 = loc("reshape.302")
#loc164 = loc("broadcast.198")
#loc165 = loc("reshape.201")
#loc166 = loc("dot.303")
#loc167 = loc("reshape.307")
#loc168 = loc("reshape.187")
#loc169 = loc("custom-call.188")
#loc170 = loc("reshape.189")
#loc171 = loc("transpose.190")
#loc172 = loc("dot.308")
#loc173 = loc("reshape.309")
#loc174 = loc("add.312")
#loc175 = loc("reshape.344")
#loc176 = loc("custom-call.345")
#loc177 = loc("reshape.346")
#loc178 = loc("convert.347")
#loc179 = loc("broadcast.348")
#loc180 = loc("convert.313")
#loc181 = loc("power.315")
#loc182 = loc("reduce.322")
#loc183 = loc("multiply.331")
#loc184 = loc("reshape.332")
#loc185 = loc("add.336")
#loc186 = loc("rsqrt.337")
#loc187 = loc("reshape.338")
#loc188 = loc("broadcast.339")
#loc189 = loc("multiply.340")
#loc190 = loc("convert.341")
#loc191 = loc("convert.342")
#loc192 = loc("multiply.349")
#loc193 = loc("convert.350")
#loc194 = loc("reshape.360")
#loc195 = loc("reshape.356")
#loc196 = loc("custom-call.357")
#loc197 = loc("reshape.358")
#loc198 = loc("transpose.359")
#loc199 = loc("dot.361")
#loc200 = loc("reshape.362")
#loc201 = loc("convert.365")
#loc202 = loc("logistic.363")
#loc203 = loc("convert.364")
#loc204 = loc("multiply.366")
#loc205 = loc("convert.367")
#loc206 = loc("convert.368")
#loc207 = loc("reshape.179")
#loc208 = loc("custom-call.180")
#loc209 = loc("reshape.181")
#loc210 = loc("transpose.182")
#loc211 = loc("dot.352")
#loc212 = loc("reshape.353")
#loc213 = loc("convert.354")
#loc214 = loc("multiply.369")
#loc215 = loc("convert.370")
#loc216 = loc("reshape.371")
#loc217 = loc("reshape.174")
#loc218 = loc("custom-call.175")
#loc219 = loc("reshape.176")
#loc220 = loc("transpose.177")
#loc221 = loc("dot.372")
#loc222 = loc("reshape.373")
#loc223 = loc("add.376")
#loc224 = loc("convert.377")
#loc225 = loc("power.379")
#loc226 = loc("reduce.386")
#loc227 = loc("multiply.395")
#loc228 = loc("reshape.396")
#loc229 = loc("add.400")
#loc230 = loc("rsqrt.401")
#loc231 = loc("reshape.402")
#loc232 = loc("broadcast.403")
#loc233 = loc("multiply.404")
#loc234 = loc("convert.405")
#loc235 = loc("convert.406")
#loc236 = loc("multiply.413")
#loc237 = loc("convert.414")
#loc238 = loc("reshape.418")
#loc239 = loc("reshape.166")
#loc240 = loc("custom-call.167")
#loc241 = loc("reshape.168")
#loc242 = loc("transpose.169")
#loc243 = loc("dot.419")
#loc244 = loc("reshape.420")
2025-09-22 18:08:06.505 (  66.190s) [        A88F8000]      module_builder.cc:190      1| SHLO Module after frontend StableHLO pipeline:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.31")
#loc4 = loc("p3.37")
#loc5 = loc("p4.39")
#loc6 = loc("p5.44")
#loc7 = loc("p6.81")
#loc8 = loc("p7.118")
#loc9 = loc("p8.128")
#loc10 = loc("p9.137")
#loc11 = loc("p10.156")
#loc12 = loc("p11.165")
#loc13 = loc("p12.173")
#loc14 = loc("p13.178")
#loc15 = loc("p14.186")
#loc16 = loc("p15.210")
#loc17 = loc("p16.226")
#loc18 = loc("p17.241")
#loc19 = loc("p18.343")
#loc20 = loc("p19.355")
#loc21 = loc("p20.407")
#loc90 = loc("scatter.134")
#loc97 = loc("scatter.162")
module @SyncTensorsGraph.422 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.31"), %arg3: tensor<f32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_0"} loc("p3.37"), %arg4: tensor<1x1xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("p4.39"), %arg5: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p5.44"), %arg6: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p6.81"), %arg7: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_1"} loc("p7.118"), %arg8: tensor<1x8x16x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"} loc("p8.128"), %arg9: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p9.137"), %arg10: tensor<1x8x16x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_3"} loc("p10.156"), %arg11: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"} loc("p11.165"), %arg12: tensor<3072x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p12.173"), %arg13: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p13.178"), %arg14: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p14.186"), %arg15: tensor<bf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_2"} loc("p15.210"), %arg16: tensor<f32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_3"} loc("p16.226"), %arg17: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p17.241"), %arg18: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p18.343"), %arg19: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p19.355"), %arg20: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"} loc("p20.407")) -> (tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %c = stablehlo.constant dense<0> : tensor<1xi64> loc(#loc)
    %c_1 = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]> : tensor<1x16xi64> loc(#loc)
    %cst_2 = stablehlo.constant dense<3.25520843E-4> : tensor<1x1xf32> loc(#loc)
    %cst_3 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32> loc(#loc)
    %1 = stablehlo.reshape %arg0 : (tensor<1xi64>) -> tensor<1x1x1xi64> loc(#loc22)
    %2 = stablehlo.reshape %1 : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc23)
    %3 = stablehlo.compare  LT, %2, %c : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1> loc(#loc24)
    %4 = stablehlo.reshape %arg7 : (tensor<i64>) -> tensor<1xi64> loc(#loc25)
    %5 = stablehlo.add %2, %4 : tensor<1xi64> loc(#loc26)
    %6 = stablehlo.select %3, %5, %2 : tensor<1xi1>, tensor<1xi64> loc(#loc27)
    %7 = stablehlo.reshape %6 : (tensor<1xi64>) -> tensor<1x1xi64> loc(#loc28)
    %8 = stablehlo.reshape %arg6 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc29)
    %9 = stablehlo.reshape %8 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc30)
    %10 = stablehlo.convert %9 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc31)
    %11 = stablehlo.reshape %10 : (tensor<3072xf32>) -> tensor<1x1x3072xf32> loc(#loc32)
    %12 = stablehlo.reshape %arg5 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc33)
    %13 = stablehlo.reshape %12 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc34)
    %14 = stablehlo.reshape %arg4 : (tensor<1x1xi64>) -> tensor<1x1x1xi64> loc(#loc35)
    %15 = stablehlo.reshape %14 : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc36)
    %16 = stablehlo.convert %15 : (tensor<1xi64>) -> tensor<1xui32> loc(#loc37)
    %17 = "stablehlo.gather"(%13, %16) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16> loc(#loc38)
    %18 = stablehlo.reshape %17 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc39)
    %19 = stablehlo.convert %18 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc40)
    %20 = stablehlo.power %19, %0 : tensor<1x1x3072xf32> loc(#loc41)
    %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc42)
    %22 = stablehlo.multiply %21, %cst_2 : tensor<1x1xf32> loc(#loc43)
    %23 = stablehlo.reshape %22 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc44)
    %24 = stablehlo.reshape %arg3 : (tensor<f32>) -> tensor<1x1x1xf32> loc(#loc45)
    %25 = stablehlo.add %23, %24 : tensor<1x1x1xf32> loc(#loc46)
    %26 = stablehlo.rsqrt %25 : tensor<1x1x1xf32> loc(#loc47)
    %27 = stablehlo.reshape %26 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc48)
    %28 = stablehlo.broadcast_in_dim %27, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc49)
    %29 = stablehlo.multiply %19, %28 : tensor<1x1x3072xf32> loc(#loc50)
    %30 = stablehlo.convert %29 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc51)
    %31 = stablehlo.convert %30 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc52)
    %32 = stablehlo.multiply %11, %31 : tensor<1x1x3072xf32> loc(#loc53)
    %33 = stablehlo.convert %32 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc54)
    %34 = stablehlo.reshape %33 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc55)
    %35 = stablehlo.reshape %arg2 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc56)
    %36 = stablehlo.reshape %35 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc57)
    %37 = stablehlo.transpose %36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc58)
    %38 = stablehlo.dot_general %34, %37, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16> loc(#loc59)
    %39 = stablehlo.reshape %38 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc60)
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32> loc(#loc61)
    %41 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc62)
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc63)
    %43 = stablehlo.convert %1 : (tensor<1x1x1xi64>) -> tensor<1x1x1xf32> loc(#loc64)
    %44 = stablehlo.dot_general %42, %43, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32> loc(#loc65)
    %45 = stablehlo.reshape %44 : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32> loc(#loc66)
    %46 = stablehlo.concatenate %45, %45, dim = 2 : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32> loc(#loc67)
    %47 = stablehlo.cosine %46 : tensor<1x1x128xf32> loc(#loc68)
    %48 = stablehlo.convert %47 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc69)
    %49 = stablehlo.reshape %48 : (tensor<1x1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc70)
    %50 = stablehlo.convert %49 : (tensor<1x1x1x128xbf16>) -> tensor<1x1x1x128xf32> loc(#loc71)
    %51 = stablehlo.reshape %50 : (tensor<1x1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc72)
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32> loc(#loc73)
    %53 = stablehlo.multiply %40, %52 : tensor<1x8x1x128xf32> loc(#loc74)
    %54 = stablehlo.convert %53 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16> loc(#loc75)
    %55 = stablehlo.slice %39 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16> loc(#loc76)
    %56 = stablehlo.negate %55 : tensor<1x8x1x64xbf16> loc(#loc77)
    %57 = stablehlo.slice %39 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16> loc(#loc78)
    %58 = stablehlo.concatenate %56, %57, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc79)
    %59 = stablehlo.convert %58 : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x128xf32> loc(#loc80)
    %60 = stablehlo.sine %46 : tensor<1x1x128xf32> loc(#loc81)
    %61 = stablehlo.convert %60 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc82)
    %62 = stablehlo.reshape %61 : (tensor<1x1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc83)
    %63 = stablehlo.convert %62 : (tensor<1x1x1x128xbf16>) -> tensor<1x1x1x128xf32> loc(#loc84)
    %64 = stablehlo.reshape %63 : (tensor<1x1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc85)
    %65 = stablehlo.broadcast_in_dim %64, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x8x1x128xf32> loc(#loc86)
    %66 = stablehlo.multiply %59, %65 : tensor<1x8x1x128xf32> loc(#loc87)
    %67 = stablehlo.convert %66 : (tensor<1x8x1x128xf32>) -> tensor<1x8x1x128xbf16> loc(#loc88)
    %68 = stablehlo.add %54, %67 : tensor<1x8x1x128xbf16> loc(#loc89)
    %69 = "stablehlo.scatter"(%arg8, %7, %68) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16> loc("scatter.134"), %arg22: tensor<bf16> loc("scatter.134")):
      stablehlo.return %arg22 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x16x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc90)
    %70 = stablehlo.custom_call @Sharding(%69) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc91)
    %71 = stablehlo.reshape %arg9 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc92)
    %72 = stablehlo.reshape %71 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc93)
    %73 = stablehlo.transpose %72, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc94)
    %74 = stablehlo.dot_general %34, %73, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16> loc(#loc95)
    %75 = stablehlo.reshape %74 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc96)
    %76 = "stablehlo.scatter"(%arg10, %7, %75) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16> loc("scatter.162"), %arg22: tensor<bf16> loc("scatter.162")):
      stablehlo.return %arg22 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x16x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc97)
    %77 = stablehlo.custom_call @Sharding(%76) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc98)
    %78 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc99)
    %79 = stablehlo.reshape %78 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc100)
    %80 = stablehlo.convert %79 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc101)
    %81 = stablehlo.reshape %80 : (tensor<3072xf32>) -> tensor<1x1x3072xf32> loc(#loc102)
    %82 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc103)
    %83 = stablehlo.reshape %82 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc104)
    %84 = stablehlo.transpose %83, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc105)
    %85 = stablehlo.dot_general %34, %84, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc106)
    %86 = stablehlo.reshape %85 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc107)
    %87 = stablehlo.convert %86 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32> loc(#loc108)
    %88 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32> loc(#loc109)
    %89 = stablehlo.multiply %87, %88 : tensor<1x24x1x128xf32> loc(#loc110)
    %90 = stablehlo.convert %89 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16> loc(#loc111)
    %91 = stablehlo.slice %86 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16> loc(#loc112)
    %92 = stablehlo.negate %91 : tensor<1x24x1x64xbf16> loc(#loc113)
    %93 = stablehlo.slice %86 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16> loc(#loc114)
    %94 = stablehlo.concatenate %92, %93, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc115)
    %95 = stablehlo.convert %94 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32> loc(#loc116)
    %96 = stablehlo.broadcast_in_dim %64, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x24x1x128xf32> loc(#loc117)
    %97 = stablehlo.multiply %95, %96 : tensor<1x24x1x128xf32> loc(#loc118)
    %98 = stablehlo.convert %97 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16> loc(#loc119)
    %99 = stablehlo.add %90, %98 : tensor<1x24x1x128xbf16> loc(#loc120)
    %100 = stablehlo.reshape %99 : (tensor<1x24x1x128xbf16>) -> tensor<24x1x128xbf16> loc(#loc121)
    %101 = stablehlo.broadcast_in_dim %69, dims = [0, 1, 3, 4] : (tensor<1x8x16x128xbf16>) -> tensor<1x8x3x16x128xbf16> loc(#loc122)
    %102 = stablehlo.reshape %101 : (tensor<1x8x3x16x128xbf16>) -> tensor<1x24x16x128xbf16> loc(#loc123)
    %103 = stablehlo.transpose %102, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,16]{2,3,1,0}"} : (tensor<1x24x16x128xbf16>) -> tensor<1x24x128x16xbf16> loc(#loc124)
    %104 = stablehlo.reshape %103 : (tensor<1x24x128x16xbf16>) -> tensor<24x128x16xbf16> loc(#loc125)
    %105 = stablehlo.dot_general %100, %104, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x128xbf16>, tensor<24x128x16xbf16>) -> tensor<24x1x16xbf16> loc(#loc126)
    %106 = stablehlo.reshape %105 : (tensor<24x1x16xbf16>) -> tensor<1x24x1x16xbf16> loc(#loc127)
    %107 = stablehlo.convert %106 : (tensor<1x24x1x16xbf16>) -> tensor<1x24x1x16xf32> loc(#loc128)
    %108 = stablehlo.broadcast_in_dim %arg16, dims = [] : (tensor<f32>) -> tensor<1x24x1x16xf32> loc(#loc129)
    %109 = stablehlo.multiply %107, %108 : tensor<1x24x1x16xf32> loc(#loc130)
    %110 = stablehlo.convert %109 : (tensor<1x24x1x16xf32>) -> tensor<1x24x1x16xbf16> loc(#loc131)
    %111 = stablehlo.reshape %arg15 : (tensor<bf16>) -> tensor<1xbf16> loc(#loc132)
    %112 = stablehlo.broadcast_in_dim %111, dims = [0] : (tensor<1xbf16>) -> tensor<1x16xbf16> loc(#loc133)
    %113 = stablehlo.convert %112 : (tensor<1x16xbf16>) -> tensor<1x16xf32> loc(#loc134)
    %114 = stablehlo.broadcast_in_dim %2, dims = [0] : (tensor<1xi64>) -> tensor<1x16xi64> loc(#loc135)
    %115 = stablehlo.compare  GT, %c_1, %114 : (tensor<1x16xi64>, tensor<1x16xi64>) -> tensor<1x16xi1> loc(#loc136)
    %116 = stablehlo.convert %115 : (tensor<1x16xi1>) -> tensor<1x16xf32> loc(#loc137)
    %117 = stablehlo.multiply %113, %116 : tensor<1x16xf32> loc(#loc138)
    %118 = stablehlo.convert %117 : (tensor<1x16xf32>) -> tensor<1x16xbf16> loc(#loc139)
    %119 = stablehlo.reshape %118 : (tensor<1x16xbf16>) -> tensor<1x1x16xbf16> loc(#loc140)
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 2, 3] : (tensor<1x1x16xbf16>) -> tensor<1x24x1x16xbf16> loc(#loc141)
    %121 = stablehlo.add %110, %120 : tensor<1x24x1x16xbf16> loc(#loc142)
    %122 = stablehlo.convert %121 : (tensor<1x24x1x16xbf16>) -> tensor<1x24x1x16xf32> loc(#loc143)
    %123 = stablehlo.reduce(%122 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x16xf32>, tensor<f32>) -> tensor<1x24x1xf32> loc(#loc144)
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x16xf32> loc(#loc145)
    %125 = stablehlo.subtract %122, %124 : tensor<1x24x1x16xf32> loc(#loc146)
    %126 = stablehlo.exponential %125 : tensor<1x24x1x16xf32> loc(#loc147)
    %127 = stablehlo.reduce(%126 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x16xf32>, tensor<f32>) -> tensor<1x24x1xf32> loc(#loc148)
    %128 = stablehlo.broadcast_in_dim %127, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x16xf32> loc(#loc149)
    %129 = stablehlo.divide %126, %128 : tensor<1x24x1x16xf32> loc(#loc150)
    %130 = stablehlo.convert %129 : (tensor<1x24x1x16xf32>) -> tensor<1x24x1x16xbf16> loc(#loc151)
    %131 = stablehlo.reshape %130 : (tensor<1x24x1x16xbf16>) -> tensor<24x1x16xbf16> loc(#loc152)
    %132 = stablehlo.broadcast_in_dim %76, dims = [0, 1, 3, 4] : (tensor<1x8x16x128xbf16>) -> tensor<1x8x3x16x128xbf16> loc(#loc153)
    %133 = stablehlo.reshape %132 : (tensor<1x8x3x16x128xbf16>) -> tensor<24x16x128xbf16> loc(#loc154)
    %134 = stablehlo.dot_general %131, %133, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x1x16xbf16>, tensor<24x16x128xbf16>) -> tensor<24x1x128xbf16> loc(#loc155)
    %135 = stablehlo.reshape %134 : (tensor<24x1x128xbf16>) -> tensor<1x3072xbf16> loc(#loc156)
    %136 = stablehlo.reshape %arg14 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc157)
    %137 = stablehlo.reshape %136 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc158)
    %138 = stablehlo.transpose %137, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc159)
    %139 = stablehlo.dot_general %135, %138, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc160)
    %140 = stablehlo.reshape %139 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc161)
    %141 = stablehlo.add %18, %140 : tensor<1x1x3072xbf16> loc(#loc162)
    %142 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc163)
    %143 = stablehlo.reshape %142 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc164)
    %144 = stablehlo.convert %143 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc165)
    %145 = stablehlo.reshape %144 : (tensor<3072xf32>) -> tensor<1x1x3072xf32> loc(#loc166)
    %146 = stablehlo.convert %141 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc167)
    %147 = stablehlo.power %146, %0 : tensor<1x1x3072xf32> loc(#loc168)
    %148 = stablehlo.reduce(%147 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc169)
    %149 = stablehlo.multiply %148, %cst_2 : tensor<1x1xf32> loc(#loc170)
    %150 = stablehlo.reshape %149 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc171)
    %151 = stablehlo.add %150, %24 : tensor<1x1x1xf32> loc(#loc172)
    %152 = stablehlo.rsqrt %151 : tensor<1x1x1xf32> loc(#loc173)
    %153 = stablehlo.reshape %152 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc174)
    %154 = stablehlo.broadcast_in_dim %153, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc175)
    %155 = stablehlo.multiply %146, %154 : tensor<1x1x3072xf32> loc(#loc176)
    %156 = stablehlo.convert %155 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc177)
    %157 = stablehlo.convert %156 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc178)
    %158 = stablehlo.multiply %145, %157 : tensor<1x1x3072xf32> loc(#loc179)
    %159 = stablehlo.convert %158 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc180)
    %160 = stablehlo.reshape %159 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc181)
    %161 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc182)
    %162 = stablehlo.reshape %161 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc183)
    %163 = stablehlo.transpose %162, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc184)
    %164 = stablehlo.dot_general %160, %163, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16> loc(#loc185)
    %165 = stablehlo.reshape %164 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc186)
    %166 = stablehlo.convert %165 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32> loc(#loc187)
    %167 = stablehlo.logistic %165 : tensor<1x1x8192xbf16> loc(#loc188)
    %168 = stablehlo.convert %167 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32> loc(#loc189)
    %169 = stablehlo.multiply %166, %168 : tensor<1x1x8192xf32> loc(#loc190)
    %170 = stablehlo.convert %169 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16> loc(#loc191)
    %171 = stablehlo.convert %170 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32> loc(#loc192)
    %172 = stablehlo.reshape %arg13 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc193)
    %173 = stablehlo.reshape %172 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc194)
    %174 = stablehlo.transpose %173, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc195)
    %175 = stablehlo.dot_general %160, %174, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16> loc(#loc196)
    %176 = stablehlo.reshape %175 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc197)
    %177 = stablehlo.convert %176 : (tensor<1x1x8192xbf16>) -> tensor<1x1x8192xf32> loc(#loc198)
    %178 = stablehlo.multiply %171, %177 : tensor<1x1x8192xf32> loc(#loc199)
    %179 = stablehlo.convert %178 : (tensor<1x1x8192xf32>) -> tensor<1x1x8192xbf16> loc(#loc200)
    %180 = stablehlo.reshape %179 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16> loc(#loc201)
    %181 = stablehlo.reshape %arg12 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16> loc(#loc202)
    %182 = stablehlo.reshape %181 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16> loc(#loc203)
    %183 = stablehlo.transpose %182, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16> loc(#loc204)
    %184 = stablehlo.dot_general %180, %183, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc205)
    %185 = stablehlo.reshape %184 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc206)
    %186 = stablehlo.add %141, %185 : tensor<1x1x3072xbf16> loc(#loc207)
    %187 = stablehlo.convert %186 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc208)
    %188 = stablehlo.power %187, %0 : tensor<1x1x3072xf32> loc(#loc209)
    %189 = stablehlo.reduce(%188 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc210)
    %190 = stablehlo.multiply %189, %cst_2 : tensor<1x1xf32> loc(#loc211)
    %191 = stablehlo.reshape %190 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc212)
    %192 = stablehlo.add %191, %24 : tensor<1x1x1xf32> loc(#loc213)
    %193 = stablehlo.rsqrt %192 : tensor<1x1x1xf32> loc(#loc214)
    %194 = stablehlo.reshape %193 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc215)
    %195 = stablehlo.broadcast_in_dim %194, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc216)
    %196 = stablehlo.multiply %187, %195 : tensor<1x1x3072xf32> loc(#loc217)
    %197 = stablehlo.convert %196 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc218)
    %198 = stablehlo.convert %197 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc219)
    %199 = stablehlo.multiply %81, %198 : tensor<1x1x3072xf32> loc(#loc220)
    %200 = stablehlo.convert %199 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc221)
    %201 = stablehlo.reshape %200 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc222)
    %202 = stablehlo.reshape %arg11 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc223)
    %203 = stablehlo.reshape %202 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc224)
    %204 = stablehlo.transpose %203, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc225)
    %205 = stablehlo.dot_general %201, %204, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<1x128256xbf16> loc(#loc226)
    %206 = stablehlo.reshape %205 : (tensor<1x128256xbf16>) -> tensor<1x1x128256xbf16> loc(#loc227)
    return %70, %77, %205, %206 : tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc22 = loc("reshape.4")
#loc23 = loc("reshape.6")
#loc24 = loc("compare.124")
#loc25 = loc("reshape.119")
#loc26 = loc("add.121")
#loc27 = loc("select.125")
#loc28 = loc("reshape.126")
#loc29 = loc("reshape.82")
#loc30 = loc("reshape.84")
#loc31 = loc("convert.85")
#loc32 = loc("broadcast.86")
#loc33 = loc("reshape.45")
#loc34 = loc("reshape.47")
#loc35 = loc("reshape.40")
#loc36 = loc("reshape.43")
#loc37 = loc("convert.48")
#loc38 = loc("gather.49")
#loc39 = loc("reshape.50")
#loc40 = loc("convert.51")
#loc41 = loc("power.53")
#loc42 = loc("reduce.60")
#loc43 = loc("multiply.69")
#loc44 = loc("reshape.70")
#loc45 = loc("broadcast.73")
#loc46 = loc("add.74")
#loc47 = loc("rsqrt.75")
#loc48 = loc("reshape.76")
#loc49 = loc("broadcast.77")
#loc50 = loc("multiply.78")
#loc51 = loc("convert.79")
#loc52 = loc("convert.80")
#loc53 = loc("multiply.87")
#loc54 = loc("convert.88")
#loc55 = loc("reshape.89")
#loc56 = loc("reshape.32")
#loc57 = loc("reshape.34")
#loc58 = loc("transpose.35")
#loc59 = loc("dot.90")
#loc60 = loc("transpose.93")
#loc61 = loc("convert.110")
#loc62 = loc("reshape.14")
#loc63 = loc("reshape.19")
#loc64 = loc("convert.11")
#loc65 = loc("dot.22")
#loc66 = loc("transpose.23")
#loc67 = loc("concatenate.24")
#loc68 = loc("cosine.104")
#loc69 = loc("convert.107")
#loc70 = loc("reshape.108")
#loc71 = loc("convert.109")
#loc72 = loc("reshape.111")
#loc73 = loc("broadcast.112")
#loc74 = loc("multiply.113")
#loc75 = loc("convert.114")
#loc76 = loc("slice.95")
#loc77 = loc("negate.96")
#loc78 = loc("slice.94")
#loc79 = loc("concatenate.97")
#loc80 = loc("convert.98")
#loc81 = loc("sine.25")
#loc82 = loc("convert.28")
#loc83 = loc("reshape.29")
#loc84 = loc("convert.30")
#loc85 = loc("reshape.99")
#loc86 = loc("broadcast.100")
#loc87 = loc("multiply.101")
#loc88 = loc("convert.102")
#loc89 = loc("add.117")
#loc91 = loc("custom-call.136")
#loc92 = loc("reshape.138")
#loc93 = loc("reshape.140")
#loc94 = loc("transpose.141")
#loc95 = loc("dot.143")
#loc96 = loc("transpose.146")
#loc98 = loc("custom-call.164")
#loc99 = loc("reshape.408")
#loc100 = loc("reshape.410")
#loc101 = loc("convert.411")
#loc102 = loc("broadcast.412")
#loc103 = loc("reshape.242")
#loc104 = loc("reshape.244")
#loc105 = loc("transpose.245")
#loc106 = loc("dot.247")
#loc107 = loc("transpose.250")
#loc108 = loc("convert.261")
#loc109 = loc("broadcast.263")
#loc110 = loc("multiply.264")
#loc111 = loc("convert.265")
#loc112 = loc("slice.252")
#loc113 = loc("negate.253")
#loc114 = loc("slice.251")
#loc115 = loc("concatenate.254")
#loc116 = loc("convert.255")
#loc117 = loc("broadcast.257")
#loc118 = loc("multiply.258")
#loc119 = loc("convert.259")
#loc120 = loc("add.268")
#loc121 = loc("reshape.270")
#loc122 = loc("broadcast.234")
#loc123 = loc("reshape.235")
#loc124 = loc("transpose.236")
#loc125 = loc("reshape.238")
#loc126 = loc("dot.271")
#loc127 = loc("reshape.272")
#loc128 = loc("convert.273")
#loc129 = loc("broadcast.274")
#loc130 = loc("multiply.275")
#loc131 = loc("convert.276")
#loc132 = loc("reshape.213")
#loc133 = loc("broadcast.214")
#loc134 = loc("convert.215")
#loc135 = loc("broadcast.207")
#loc136 = loc("compare.208")
#loc137 = loc("convert.209")
#loc138 = loc("multiply.216")
#loc139 = loc("convert.217")
#loc140 = loc("reshape.218")
#loc141 = loc("broadcast.280")
#loc142 = loc("add.281")
#loc143 = loc("convert.282")
#loc144 = loc("reduce.288")
#loc145 = loc("broadcast.289")
#loc146 = loc("subtract.290")
#loc147 = loc("exponential.291")
#loc148 = loc("reduce.297")
#loc149 = loc("broadcast.298")
#loc150 = loc("divide.299")
#loc151 = loc("convert.300")
#loc152 = loc("reshape.302")
#loc153 = loc("broadcast.198")
#loc154 = loc("reshape.201")
#loc155 = loc("dot.303")
#loc156 = loc("reshape.307")
#loc157 = loc("reshape.187")
#loc158 = loc("reshape.189")
#loc159 = loc("transpose.190")
#loc160 = loc("dot.308")
#loc161 = loc("reshape.309")
#loc162 = loc("add.312")
#loc163 = loc("reshape.344")
#loc164 = loc("reshape.346")
#loc165 = loc("convert.347")
#loc166 = loc("broadcast.348")
#loc167 = loc("convert.313")
#loc168 = loc("power.315")
#loc169 = loc("reduce.322")
#loc170 = loc("multiply.331")
#loc171 = loc("reshape.332")
#loc172 = loc("add.336")
#loc173 = loc("rsqrt.337")
#loc174 = loc("reshape.338")
#loc175 = loc("broadcast.339")
#loc176 = loc("multiply.340")
#loc177 = loc("convert.341")
#loc178 = loc("convert.342")
#loc179 = loc("multiply.349")
#loc180 = loc("convert.350")
#loc181 = loc("reshape.360")
#loc182 = loc("reshape.356")
#loc183 = loc("reshape.358")
#loc184 = loc("transpose.359")
#loc185 = loc("dot.361")
#loc186 = loc("reshape.362")
#loc187 = loc("convert.365")
#loc188 = loc("logistic.363")
#loc189 = loc("convert.364")
#loc190 = loc("multiply.366")
#loc191 = loc("convert.367")
#loc192 = loc("convert.368")
#loc193 = loc("reshape.179")
#loc194 = loc("reshape.181")
#loc195 = loc("transpose.182")
#loc196 = loc("dot.352")
#loc197 = loc("reshape.353")
#loc198 = loc("convert.354")
#loc199 = loc("multiply.369")
#loc200 = loc("convert.370")
#loc201 = loc("reshape.371")
#loc202 = loc("reshape.174")
#loc203 = loc("reshape.176")
#loc204 = loc("transpose.177")
#loc205 = loc("dot.372")
#loc206 = loc("reshape.373")
#loc207 = loc("add.376")
#loc208 = loc("convert.377")
#loc209 = loc("power.379")
#loc210 = loc("reduce.386")
#loc211 = loc("multiply.395")
#loc212 = loc("reshape.396")
#loc213 = loc("add.400")
#loc214 = loc("rsqrt.401")
#loc215 = loc("reshape.402")
#loc216 = loc("broadcast.403")
#loc217 = loc("multiply.404")
#loc218 = loc("convert.405")
#loc219 = loc("convert.406")
#loc220 = loc("multiply.413")
#loc221 = loc("convert.414")
#loc222 = loc("reshape.418")
#loc223 = loc("reshape.166")
#loc224 = loc("reshape.168")
#loc225 = loc("transpose.169")
#loc226 = loc("dot.419")
#loc227 = loc("reshape.420")
2025-09-22 18:08:06.537 (  66.222s) [        A88F8000]      module_builder.cc:473      1| SHLO Module after compiler StableHLO pipeline:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.31")
#loc4 = loc("p3.37")
#loc5 = loc("p4.39")
#loc6 = loc("p5.44")
#loc7 = loc("p6.81")
#loc8 = loc("p7.118")
#loc9 = loc("p8.128")
#loc10 = loc("p9.137")
#loc11 = loc("p10.156")
#loc12 = loc("p11.165")
#loc13 = loc("p12.173")
#loc14 = loc("p13.178")
#loc15 = loc("p14.186")
#loc16 = loc("p15.210")
#loc17 = loc("p16.226")
#loc18 = loc("p17.241")
#loc19 = loc("p18.343")
#loc20 = loc("p19.355")
#loc21 = loc("p20.407")
#loc90 = loc("scatter.134")
#loc96 = loc("scatter.162")
#loc158 = loc("dot.308")
#loc203 = loc("dot.372")
module @SyncTensorsGraph.422 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]> loc(#loc)
  func.func @main(%arg0: tensor<1xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.31"), %arg3: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"} loc("p3.37"), %arg4: tensor<1x1xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p4.39"), %arg5: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p5.44"), %arg6: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p6.81"), %arg7: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"} loc("p7.118"), %arg8: tensor<1x8x16x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p8.128"), %arg9: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p9.137"), %arg10: tensor<1x8x16x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p10.156"), %arg11: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"} loc("p11.165"), %arg12: tensor<3072x8192xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p12.173"), %arg13: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p13.178"), %arg14: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p14.186"), %arg15: tensor<bf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"} loc("p15.210"), %arg16: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"} loc("p16.226"), %arg17: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p17.241"), %arg18: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p18.343"), %arg19: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p19.355"), %arg20: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"} loc("p20.407")) -> (tensor<1x8x16x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x16x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:4 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18, %arg19, %arg20) in_shardings=[<@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, []>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, []>, <@mesh, []>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg21: tensor<1xi64> loc("p0.3"), %arg22: tensor<64xf32> loc("p1.13"), %arg23: tensor<512x3072xbf16> loc("p2.31"), %arg24: tensor<f32> loc("p3.37"), %arg25: tensor<1x1xi64> loc("p4.39"), %arg26: tensor<128256x3072xbf16> loc("p5.44"), %arg27: tensor<3072xbf16> loc("p6.81"), %arg28: tensor<i64> loc("p7.118"), %arg29: tensor<1x4x16x128xbf16> loc("p8.128"), %arg30: tensor<512x3072xbf16> loc("p9.137"), %arg31: tensor<1x4x16x128xbf16> loc("p10.156"), %arg32: tensor<128256x3072xbf16> loc("p11.165"), %arg33: tensor<3072x4096xbf16> loc("p12.173"), %arg34: tensor<4096x3072xbf16> loc("p13.178"), %arg35: tensor<3072x1536xbf16> loc("p14.186"), %arg36: tensor<bf16> loc("p15.210"), %arg37: tensor<f32> loc("p16.226"), %arg38: tensor<1536x3072xbf16> loc("p17.241"), %arg39: tensor<3072xbf16> loc("p18.343"), %arg40: tensor<4096x3072xbf16> loc("p19.355"), %arg41: tensor<3072xbf16> loc("p20.407")) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
      %c = stablehlo.constant dense<0> : tensor<1xi64> loc(#loc)
      %c_1 = stablehlo.constant dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]> : tensor<1x16xi64> loc(#loc)
      %cst_2 = stablehlo.constant dense<3.25520843E-4> : tensor<1x1xf32> loc(#loc)
      %cst_3 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
      %1 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32> loc(#loc)
      %2 = stablehlo.reshape %arg21 : (tensor<1xi64>) -> tensor<1x1x1xi64> loc(#loc22)
      %3 = stablehlo.reshape %2 : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc23)
      %4 = stablehlo.compare  LT, %3, %c : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1> loc(#loc24)
      %5 = stablehlo.reshape %arg28 : (tensor<i64>) -> tensor<1xi64> loc(#loc25)
      %6 = stablehlo.add %3, %5 : tensor<1xi64> loc(#loc26)
      %7 = stablehlo.select %4, %6, %3 : tensor<1xi1>, tensor<1xi64> loc(#loc27)
      %8 = stablehlo.reshape %7 : (tensor<1xi64>) -> tensor<1x1xi64> loc(#loc28)
      %9 = stablehlo.reshape %arg27 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc29)
      %10 = stablehlo.reshape %9 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc30)
      %11 = stablehlo.convert %10 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc31)
      %12 = stablehlo.reshape %11 : (tensor<3072xf32>) -> tensor<1x1x3072xf32> loc(#loc32)
      %13 = stablehlo.reshape %arg26 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc33)
      %14 = stablehlo.reshape %13 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc34)
      %15 = stablehlo.reshape %arg25 : (tensor<1x1xi64>) -> tensor<1x1x1xi64> loc(#loc35)
      %16 = stablehlo.reshape %15 : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc36)
      %17 = stablehlo.convert %16 : (tensor<1xi64>) -> tensor<1xui32> loc(#loc37)
      %18 = "stablehlo.gather"(%14, %17) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16> loc(#loc38)
      %19 = stablehlo.reshape %18 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc39)
      %20 = stablehlo.convert %19 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc40)
      %21 = stablehlo.power %20, %1 : tensor<1x1x3072xf32> loc(#loc41)
      %22 = stablehlo.reduce(%21 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc42)
      %23 = stablehlo.multiply %22, %cst_2 : tensor<1x1xf32> loc(#loc43)
      %24 = stablehlo.reshape %23 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc44)
      %25 = stablehlo.reshape %arg24 : (tensor<f32>) -> tensor<1x1x1xf32> loc(#loc45)
      %26 = stablehlo.add %24, %25 : tensor<1x1x1xf32> loc(#loc46)
      %27 = stablehlo.rsqrt %26 : tensor<1x1x1xf32> loc(#loc47)
      %28 = stablehlo.reshape %27 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc48)
      %29 = stablehlo.broadcast_in_dim %28, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc49)
      %30 = stablehlo.multiply %20, %29 : tensor<1x1x3072xf32> loc(#loc50)
      %31 = stablehlo.convert %30 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc51)
      %32 = stablehlo.convert %31 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc52)
      %33 = stablehlo.multiply %12, %32 : tensor<1x1x3072xf32> loc(#loc53)
      %34 = stablehlo.convert %33 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc54)
      %35 = stablehlo.reshape %34 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc55)
      %36 = stablehlo.reshape %arg23 : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc56)
      %37 = stablehlo.reshape %36 : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc57)
      %38 = stablehlo.transpose %37, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16> loc(#loc58)
      %39 = stablehlo.dot_general %35, %38, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16> loc(#loc59)
      %40 = stablehlo.reshape %39 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc60)
      %41 = stablehlo.convert %40 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,1,128]{3,1,2,0}"} : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32> loc(#loc61)
      %42 = stablehlo.reshape %arg22 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc62)
      %43 = stablehlo.reshape %42 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc63)
      %44 = stablehlo.convert %2 : (tensor<1x1x1xi64>) -> tensor<1x1x1xf32> loc(#loc64)
      %45 = stablehlo.dot_general %43, %44, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32> loc(#loc65)
      %46 = stablehlo.reshape %45 : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32> loc(#loc66)
      %47 = stablehlo.concatenate %46, %46, dim = 2 : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32> loc(#loc67)
      %48 = stablehlo.cosine %47 : tensor<1x1x128xf32> loc(#loc68)
      %49 = stablehlo.convert %48 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc69)
      %50 = stablehlo.reshape %49 : (tensor<1x1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc70)
      %51 = stablehlo.convert %50 : (tensor<1x1x1x128xbf16>) -> tensor<1x1x1x128xf32> loc(#loc71)
      %52 = stablehlo.reshape %51 : (tensor<1x1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc72)
      %53 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x4x1x128xf32> loc(#loc73)
      %54 = stablehlo.multiply %41, %53 : tensor<1x4x1x128xf32> loc(#loc74)
      %55 = stablehlo.convert %54 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16> loc(#loc75)
      %56 = stablehlo.slice %40 [0:1, 0:4, 0:1, 64:128] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16> loc(#loc76)
      %57 = stablehlo.negate %56 : tensor<1x4x1x64xbf16> loc(#loc77)
      %58 = stablehlo.slice %40 [0:1, 0:4, 0:1, 0:64] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16> loc(#loc78)
      %59 = stablehlo.concatenate %57, %58, dim = 3 : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc79)
      %60 = stablehlo.convert %59 : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xf32> loc(#loc80)
      %61 = stablehlo.sine %47 : tensor<1x1x128xf32> loc(#loc81)
      %62 = stablehlo.convert %61 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc82)
      %63 = stablehlo.reshape %62 : (tensor<1x1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc83)
      %64 = stablehlo.convert %63 : (tensor<1x1x1x128xbf16>) -> tensor<1x1x1x128xf32> loc(#loc84)
      %65 = stablehlo.reshape %64 : (tensor<1x1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc85)
      %66 = stablehlo.broadcast_in_dim %65, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x4x1x128xf32> loc(#loc86)
      %67 = stablehlo.multiply %60, %66 : tensor<1x4x1x128xf32> loc(#loc87)
      %68 = stablehlo.convert %67 : (tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xbf16> loc(#loc88)
      %69 = stablehlo.add %55, %68 : tensor<1x4x1x128xbf16> loc(#loc89)
      %70 = "stablehlo.scatter"(%arg29, %8, %69) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg42: tensor<bf16> loc("scatter.134"), %arg43: tensor<bf16> loc("scatter.134")):
        stablehlo.return %arg43 : tensor<bf16> loc(#loc)
      }) : (tensor<1x4x16x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x16x128xbf16> loc(#loc90)
      %71 = stablehlo.reshape %arg30 : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc91)
      %72 = stablehlo.reshape %71 : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc92)
      %73 = stablehlo.transpose %72, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16> loc(#loc93)
      %74 = stablehlo.dot_general %35, %73, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16> loc(#loc94)
      %75 = stablehlo.reshape %74 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc95)
      %76 = "stablehlo.scatter"(%arg31, %8, %75) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg42: tensor<bf16> loc("scatter.162"), %arg43: tensor<bf16> loc("scatter.162")):
        stablehlo.return %arg43 : tensor<bf16> loc(#loc)
      }) : (tensor<1x4x16x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x16x128xbf16> loc(#loc96)
      %77 = stablehlo.reshape %arg41 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc97)
      %78 = stablehlo.reshape %77 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc98)
      %79 = stablehlo.convert %78 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc99)
      %80 = stablehlo.reshape %79 : (tensor<3072xf32>) -> tensor<1x1x3072xf32> loc(#loc100)
      %81 = stablehlo.reshape %arg38 : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16> loc(#loc101)
      %82 = stablehlo.reshape %81 : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc102)
      %83 = stablehlo.transpose %82, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16> loc(#loc103)
      %84 = stablehlo.dot_general %35, %83, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16> loc(#loc104)
      %85 = stablehlo.reshape %84 : (tensor<1x1536xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc105)
      %86 = stablehlo.convert %85 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,1,128]{3,1,2,0}"} : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32> loc(#loc106)
      %87 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x12x1x128xf32> loc(#loc107)
      %88 = stablehlo.multiply %86, %87 : tensor<1x12x1x128xf32> loc(#loc108)
      %89 = stablehlo.convert %88 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16> loc(#loc109)
      %90 = stablehlo.slice %85 [0:1, 0:12, 0:1, 64:128] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16> loc(#loc110)
      %91 = stablehlo.negate %90 : tensor<1x12x1x64xbf16> loc(#loc111)
      %92 = stablehlo.slice %85 [0:1, 0:12, 0:1, 0:64] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16> loc(#loc112)
      %93 = stablehlo.concatenate %91, %92, dim = 3 : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc113)
      %94 = stablehlo.convert %93 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32> loc(#loc114)
      %95 = stablehlo.broadcast_in_dim %65, dims = [0, 2, 3] : (tensor<1x1x128xf32>) -> tensor<1x12x1x128xf32> loc(#loc115)
      %96 = stablehlo.multiply %94, %95 : tensor<1x12x1x128xf32> loc(#loc116)
      %97 = stablehlo.convert %96 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16> loc(#loc117)
      %98 = stablehlo.add %89, %97 : tensor<1x12x1x128xbf16> loc(#loc118)
      %99 = stablehlo.reshape %98 : (tensor<1x12x1x128xbf16>) -> tensor<12x1x128xbf16> loc(#loc119)
      %100 = stablehlo.broadcast_in_dim %70, dims = [0, 1, 3, 4] : (tensor<1x4x16x128xbf16>) -> tensor<1x4x3x16x128xbf16> loc(#loc120)
      %101 = stablehlo.reshape %100 : (tensor<1x4x3x16x128xbf16>) -> tensor<1x12x16x128xbf16> loc(#loc121)
      %102 = stablehlo.transpose %101, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,16]{2,3,1,0}"} : (tensor<1x12x16x128xbf16>) -> tensor<1x12x128x16xbf16> loc(#loc122)
      %103 = stablehlo.reshape %102 : (tensor<1x12x128x16xbf16>) -> tensor<12x128x16xbf16> loc(#loc123)
      %104 = stablehlo.dot_general %99, %103, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x128xbf16>, tensor<12x128x16xbf16>) -> tensor<12x1x16xbf16> loc(#loc124)
      %105 = stablehlo.reshape %104 : (tensor<12x1x16xbf16>) -> tensor<1x12x1x16xbf16> loc(#loc125)
      %106 = stablehlo.convert %105 : (tensor<1x12x1x16xbf16>) -> tensor<1x12x1x16xf32> loc(#loc126)
      %107 = stablehlo.broadcast_in_dim %arg37, dims = [] : (tensor<f32>) -> tensor<1x12x1x16xf32> loc(#loc127)
      %108 = stablehlo.multiply %106, %107 : tensor<1x12x1x16xf32> loc(#loc128)
      %109 = stablehlo.convert %108 : (tensor<1x12x1x16xf32>) -> tensor<1x12x1x16xbf16> loc(#loc129)
      %110 = stablehlo.reshape %arg36 : (tensor<bf16>) -> tensor<1xbf16> loc(#loc130)
      %111 = stablehlo.broadcast_in_dim %110, dims = [0] : (tensor<1xbf16>) -> tensor<1x16xbf16> loc(#loc131)
      %112 = stablehlo.convert %111 : (tensor<1x16xbf16>) -> tensor<1x16xf32> loc(#loc132)
      %113 = stablehlo.broadcast_in_dim %3, dims = [0] : (tensor<1xi64>) -> tensor<1x16xi64> loc(#loc133)
      %114 = stablehlo.compare  GT, %c_1, %113 : (tensor<1x16xi64>, tensor<1x16xi64>) -> tensor<1x16xi1> loc(#loc134)
      %115 = stablehlo.convert %114 : (tensor<1x16xi1>) -> tensor<1x16xf32> loc(#loc135)
      %116 = stablehlo.multiply %112, %115 : tensor<1x16xf32> loc(#loc136)
      %117 = stablehlo.convert %116 : (tensor<1x16xf32>) -> tensor<1x16xbf16> loc(#loc137)
      %118 = stablehlo.reshape %117 : (tensor<1x16xbf16>) -> tensor<1x1x16xbf16> loc(#loc138)
      %119 = stablehlo.broadcast_in_dim %118, dims = [0, 2, 3] : (tensor<1x1x16xbf16>) -> tensor<1x12x1x16xbf16> loc(#loc139)
      %120 = stablehlo.add %109, %119 : tensor<1x12x1x16xbf16> loc(#loc140)
      %121 = stablehlo.convert %120 : (tensor<1x12x1x16xbf16>) -> tensor<1x12x1x16xf32> loc(#loc141)
      %122 = stablehlo.reduce(%121 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x1x16xf32>, tensor<f32>) -> tensor<1x12x1xf32> loc(#loc142)
      %123 = stablehlo.broadcast_in_dim %122, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x16xf32> loc(#loc143)
      %124 = stablehlo.subtract %121, %123 : tensor<1x12x1x16xf32> loc(#loc144)
      %125 = stablehlo.exponential %124 : tensor<1x12x1x16xf32> loc(#loc145)
      %126 = stablehlo.reduce(%125 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x1x16xf32>, tensor<f32>) -> tensor<1x12x1xf32> loc(#loc146)
      %127 = stablehlo.broadcast_in_dim %126, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x16xf32> loc(#loc147)
      %128 = stablehlo.divide %125, %127 : tensor<1x12x1x16xf32> loc(#loc148)
      %129 = stablehlo.convert %128 : (tensor<1x12x1x16xf32>) -> tensor<1x12x1x16xbf16> loc(#loc149)
      %130 = stablehlo.reshape %129 : (tensor<1x12x1x16xbf16>) -> tensor<12x1x16xbf16> loc(#loc150)
      %131 = stablehlo.broadcast_in_dim %76, dims = [0, 1, 3, 4] : (tensor<1x4x16x128xbf16>) -> tensor<1x4x3x16x128xbf16> loc(#loc151)
      %132 = stablehlo.reshape %131 : (tensor<1x4x3x16x128xbf16>) -> tensor<12x16x128xbf16> loc(#loc152)
      %133 = stablehlo.dot_general %130, %132, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<12x1x16xbf16>, tensor<12x16x128xbf16>) -> tensor<12x1x128xbf16> loc(#loc153)
      %134 = stablehlo.reshape %133 : (tensor<12x1x128xbf16>) -> tensor<1x1536xbf16> loc(#loc154)
      %135 = stablehlo.reshape %arg35 : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16> loc(#loc155)
      %136 = stablehlo.reshape %135 : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16> loc(#loc156)
      %137 = stablehlo.transpose %136, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16> loc(#loc157)
      %138 = stablehlo.dot_general %134, %137, contracting_dims = [1] x [0] : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc158)
      %139 = "stablehlo.all_reduce"(%138) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg42: tensor<bf16> loc("dot.308"), %arg43: tensor<bf16> loc("dot.308")):
        %208 = stablehlo.add %arg42, %arg43 : tensor<bf16> loc(#loc158)
        stablehlo.return %208 : tensor<bf16> loc(#loc158)
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc158)
      %140 = stablehlo.reshape %139 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc159)
      %141 = stablehlo.add %19, %140 : tensor<1x1x3072xbf16> loc(#loc160)
      %142 = stablehlo.reshape %arg39 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc161)
      %143 = stablehlo.reshape %142 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc162)
      %144 = stablehlo.convert %143 : (tensor<3072xbf16>) -> tensor<3072xf32> loc(#loc163)
      %145 = stablehlo.reshape %144 : (tensor<3072xf32>) -> tensor<1x1x3072xf32> loc(#loc164)
      %146 = stablehlo.convert %141 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc165)
      %147 = stablehlo.power %146, %1 : tensor<1x1x3072xf32> loc(#loc166)
      %148 = stablehlo.reduce(%147 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc167)
      %149 = stablehlo.multiply %148, %cst_2 : tensor<1x1xf32> loc(#loc168)
      %150 = stablehlo.reshape %149 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc169)
      %151 = stablehlo.add %150, %25 : tensor<1x1x1xf32> loc(#loc170)
      %152 = stablehlo.rsqrt %151 : tensor<1x1x1xf32> loc(#loc171)
      %153 = stablehlo.reshape %152 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc172)
      %154 = stablehlo.broadcast_in_dim %153, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc173)
      %155 = stablehlo.multiply %146, %154 : tensor<1x1x3072xf32> loc(#loc174)
      %156 = stablehlo.convert %155 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc175)
      %157 = stablehlo.convert %156 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc176)
      %158 = stablehlo.multiply %145, %157 : tensor<1x1x3072xf32> loc(#loc177)
      %159 = stablehlo.convert %158 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc178)
      %160 = stablehlo.reshape %159 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc179)
      %161 = stablehlo.reshape %arg40 : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc180)
      %162 = stablehlo.reshape %161 : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc181)
      %163 = stablehlo.transpose %162, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16> loc(#loc182)
      %164 = stablehlo.dot_general %160, %163, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16> loc(#loc183)
      %165 = stablehlo.reshape %164 : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc184)
      %166 = stablehlo.convert %165 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32> loc(#loc185)
      %167 = stablehlo.logistic %165 : tensor<1x1x4096xbf16> loc(#loc186)
      %168 = stablehlo.convert %167 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32> loc(#loc187)
      %169 = stablehlo.multiply %166, %168 : tensor<1x1x4096xf32> loc(#loc188)
      %170 = stablehlo.convert %169 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16> loc(#loc189)
      %171 = stablehlo.convert %170 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32> loc(#loc190)
      %172 = stablehlo.reshape %arg34 : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc191)
      %173 = stablehlo.reshape %172 : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc192)
      %174 = stablehlo.transpose %173, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16> loc(#loc193)
      %175 = stablehlo.dot_general %160, %174, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16> loc(#loc194)
      %176 = stablehlo.reshape %175 : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc195)
      %177 = stablehlo.convert %176 : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xf32> loc(#loc196)
      %178 = stablehlo.multiply %171, %177 : tensor<1x1x4096xf32> loc(#loc197)
      %179 = stablehlo.convert %178 : (tensor<1x1x4096xf32>) -> tensor<1x1x4096xbf16> loc(#loc198)
      %180 = stablehlo.reshape %179 : (tensor<1x1x4096xbf16>) -> tensor<1x4096xbf16> loc(#loc199)
      %181 = stablehlo.reshape %arg33 : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16> loc(#loc200)
      %182 = stablehlo.reshape %181 : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc201)
      %183 = stablehlo.transpose %182, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16> loc(#loc202)
      %184 = stablehlo.dot_general %180, %183, contracting_dims = [1] x [0] : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc203)
      %185 = "stablehlo.all_reduce"(%184) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg42: tensor<bf16> loc("dot.372"), %arg43: tensor<bf16> loc("dot.372")):
        %208 = stablehlo.add %arg42, %arg43 : tensor<bf16> loc(#loc203)
        stablehlo.return %208 : tensor<bf16> loc(#loc203)
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc203)
      %186 = stablehlo.reshape %185 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc204)
      %187 = stablehlo.add %141, %186 : tensor<1x1x3072xbf16> loc(#loc205)
      %188 = stablehlo.convert %187 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc206)
      %189 = stablehlo.power %188, %1 : tensor<1x1x3072xf32> loc(#loc207)
      %190 = stablehlo.reduce(%189 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc208)
      %191 = stablehlo.multiply %190, %cst_2 : tensor<1x1xf32> loc(#loc209)
      %192 = stablehlo.reshape %191 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc210)
      %193 = stablehlo.add %192, %25 : tensor<1x1x1xf32> loc(#loc211)
      %194 = stablehlo.rsqrt %193 : tensor<1x1x1xf32> loc(#loc212)
      %195 = stablehlo.reshape %194 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc213)
      %196 = stablehlo.broadcast_in_dim %195, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc214)
      %197 = stablehlo.multiply %188, %196 : tensor<1x1x3072xf32> loc(#loc215)
      %198 = stablehlo.convert %197 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc216)
      %199 = stablehlo.convert %198 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc217)
      %200 = stablehlo.multiply %80, %199 : tensor<1x1x3072xf32> loc(#loc218)
      %201 = stablehlo.convert %200 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc219)
      %202 = stablehlo.reshape %201 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc220)
      %203 = stablehlo.reshape %arg32 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc221)
      %204 = stablehlo.reshape %203 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc222)
      %205 = stablehlo.transpose %204, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc223)
      %206 = stablehlo.dot_general %202, %205, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<1x128256xbf16> loc(#loc224)
      %207 = stablehlo.reshape %206 : (tensor<1x128256xbf16>) -> tensor<1x1x128256xbf16> loc(#loc225)
      sdy.return %70, %76, %206, %207 : tensor<1x4x16x128xbf16>, tensor<1x4x16x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16> loc(#loc)
    } : (tensor<1xi64>, tensor<64xf32>, tensor<1024x3072xbf16>, tensor<f32>, tensor<1x1xi64>, tensor<128256x3072xbf16>, tensor<3072xbf16>, tensor<i64>, tensor<1x8x16x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x16x128xbf16>, tensor<128256x3072xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<bf16>, tensor<f32>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>) -> (tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) loc(#loc)
    return %0#0, %0#1, %0#2, %0#3 : tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc22 = loc("reshape.4")
#loc23 = loc("reshape.6")
#loc24 = loc("compare.124")
#loc25 = loc("reshape.119")
#loc26 = loc("add.121")
#loc27 = loc("select.125")
#loc28 = loc("reshape.126")
#loc29 = loc("reshape.82")
#loc30 = loc("reshape.84")
#loc31 = loc("convert.85")
#loc32 = loc("broadcast.86")
#loc33 = loc("reshape.45")
#loc34 = loc("reshape.47")
#loc35 = loc("reshape.40")
#loc36 = loc("reshape.43")
#loc37 = loc("convert.48")
#loc38 = loc("gather.49")
#loc39 = loc("reshape.50")
#loc40 = loc("convert.51")
#loc41 = loc("power.53")
#loc42 = loc("reduce.60")
#loc43 = loc("multiply.69")
#loc44 = loc("reshape.70")
#loc45 = loc("broadcast.73")
#loc46 = loc("add.74")
#loc47 = loc("rsqrt.75")
#loc48 = loc("reshape.76")
#loc49 = loc("broadcast.77")
#loc50 = loc("multiply.78")
#loc51 = loc("convert.79")
#loc52 = loc("convert.80")
#loc53 = loc("multiply.87")
#loc54 = loc("convert.88")
#loc55 = loc("reshape.89")
#loc56 = loc("reshape.32")
#loc57 = loc("reshape.34")
#loc58 = loc("transpose.35")
#loc59 = loc("dot.90")
#loc60 = loc("transpose.93")
#loc61 = loc("convert.110")
#loc62 = loc("reshape.14")
#loc63 = loc("reshape.19")
#loc64 = loc("convert.11")
#loc65 = loc("dot.22")
#loc66 = loc("transpose.23")
#loc67 = loc("concatenate.24")
#loc68 = loc("cosine.104")
#loc69 = loc("convert.107")
#loc70 = loc("reshape.108")
#loc71 = loc("convert.109")
#loc72 = loc("reshape.111")
#loc73 = loc("broadcast.112")
#loc74 = loc("multiply.113")
#loc75 = loc("convert.114")
#loc76 = loc("slice.95")
#loc77 = loc("negate.96")
#loc78 = loc("slice.94")
#loc79 = loc("concatenate.97")
#loc80 = loc("convert.98")
#loc81 = loc("sine.25")
#loc82 = loc("convert.28")
#loc83 = loc("reshape.29")
#loc84 = loc("convert.30")
#loc85 = loc("reshape.99")
#loc86 = loc("broadcast.100")
#loc87 = loc("multiply.101")
#loc88 = loc("convert.102")
#loc89 = loc("add.117")
#loc91 = loc("reshape.138")
#loc92 = loc("reshape.140")
#loc93 = loc("transpose.141")
#loc94 = loc("dot.143")
#loc95 = loc("transpose.146")
#loc97 = loc("reshape.408")
#loc98 = loc("reshape.410")
#loc99 = loc("convert.411")
#loc100 = loc("broadcast.412")
#loc101 = loc("reshape.242")
#loc102 = loc("reshape.244")
#loc103 = loc("transpose.245")
#loc104 = loc("dot.247")
#loc105 = loc("transpose.250")
#loc106 = loc("convert.261")
#loc107 = loc("broadcast.263")
#loc108 = loc("multiply.264")
#loc109 = loc("convert.265")
#loc110 = loc("slice.252")
#loc111 = loc("negate.253")
#loc112 = loc("slice.251")
#loc113 = loc("concatenate.254")
#loc114 = loc("convert.255")
#loc115 = loc("broadcast.257")
#loc116 = loc("multiply.258")
#loc117 = loc("convert.259")
#loc118 = loc("add.268")
#loc119 = loc("reshape.270")
#loc120 = loc("broadcast.234")
#loc121 = loc("reshape.235")
#loc122 = loc("transpose.236")
#loc123 = loc("reshape.238")
#loc124 = loc("dot.271")
#loc125 = loc("reshape.272")
#loc126 = loc("convert.273")
#loc127 = loc("broadcast.274")
#loc128 = loc("multiply.275")
#loc129 = loc("convert.276")
#loc130 = loc("reshape.213")
#loc131 = loc("broadcast.214")
#loc132 = loc("convert.215")
#loc133 = loc("broadcast.207")
#loc134 = loc("compare.208")
#loc135 = loc("convert.209")
#loc136 = loc("multiply.216")
#loc137 = loc("convert.217")
#loc138 = loc("reshape.218")
#loc139 = loc("broadcast.280")
#loc140 = loc("add.281")
#loc141 = loc("convert.282")
#loc142 = loc("reduce.288")
#loc143 = loc("broadcast.289")
#loc144 = loc("subtract.290")
#loc145 = loc("exponential.291")
#loc146 = loc("reduce.297")
#loc147 = loc("broadcast.298")
#loc148 = loc("divide.299")
#loc149 = loc("convert.300")
#loc150 = loc("reshape.302")
#loc151 = loc("broadcast.198")
#loc152 = loc("reshape.201")
#loc153 = loc("dot.303")
#loc154 = loc("reshape.307")
#loc155 = loc("reshape.187")
#loc156 = loc("reshape.189")
#loc157 = loc("transpose.190")
#loc159 = loc("reshape.309")
#loc160 = loc("add.312")
#loc161 = loc("reshape.344")
#loc162 = loc("reshape.346")
#loc163 = loc("convert.347")
#loc164 = loc("broadcast.348")
#loc165 = loc("convert.313")
#loc166 = loc("power.315")
#loc167 = loc("reduce.322")
#loc168 = loc("multiply.331")
#loc169 = loc("reshape.332")
#loc170 = loc("add.336")
#loc171 = loc("rsqrt.337")
#loc172 = loc("reshape.338")
#loc173 = loc("broadcast.339")
#loc174 = loc("multiply.340")
#loc175 = loc("convert.341")
#loc176 = loc("convert.342")
#loc177 = loc("multiply.349")
#loc178 = loc("convert.350")
#loc179 = loc("reshape.360")
#loc180 = loc("reshape.356")
#loc181 = loc("reshape.358")
#loc182 = loc("transpose.359")
#loc183 = loc("dot.361")
#loc184 = loc("reshape.362")
#loc185 = loc("convert.365")
#loc186 = loc("logistic.363")
#loc187 = loc("convert.364")
#loc188 = loc("multiply.366")
#loc189 = loc("convert.367")
#loc190 = loc("convert.368")
#loc191 = loc("reshape.179")
#loc192 = loc("reshape.181")
#loc193 = loc("transpose.182")
#loc194 = loc("dot.352")
#loc195 = loc("reshape.353")
#loc196 = loc("convert.354")
#loc197 = loc("multiply.369")
#loc198 = loc("convert.370")
#loc199 = loc("reshape.371")
#loc200 = loc("reshape.174")
#loc201 = loc("reshape.176")
#loc202 = loc("transpose.177")
#loc204 = loc("reshape.373")
#loc205 = loc("add.376")
#loc206 = loc("convert.377")
#loc207 = loc("power.379")
#loc208 = loc("reduce.386")
#loc209 = loc("multiply.395")
#loc210 = loc("reshape.396")
#loc211 = loc("add.400")
#loc212 = loc("rsqrt.401")
#loc213 = loc("reshape.402")
#loc214 = loc("broadcast.403")
#loc215 = loc("multiply.404")
#loc216 = loc("convert.405")
#loc217 = loc("convert.406")
#loc218 = loc("multiply.413")
#loc219 = loc("convert.414")
#loc220 = loc("reshape.418")
#loc221 = loc("reshape.166")
#loc222 = loc("reshape.168")
#loc223 = loc("transpose.169")
#loc224 = loc("dot.419")
#loc225 = loc("reshape.420")
2025-09-22 18:08:06.551 (  66.237s) [        A88F8000]      module_builder.cc:499      1| TTIR Module:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.31")
#loc4 = loc("p3.37")
#loc5 = loc("p4.39")
#loc6 = loc("p5.44")
#loc7 = loc("p6.81")
#loc8 = loc("p7.118")
#loc9 = loc("p8.128")
#loc10 = loc("p9.137")
#loc11 = loc("p10.156")
#loc12 = loc("p11.165")
#loc13 = loc("p12.173")
#loc14 = loc("p13.178")
#loc15 = loc("p14.186")
#loc16 = loc("p15.210")
#loc17 = loc("p16.226")
#loc18 = loc("p17.241")
#loc19 = loc("p18.343")
#loc20 = loc("p19.355")
#loc21 = loc("p20.407")
module @SyncTensorsGraph.422 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<1xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.31"), %arg3: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"} loc("p3.37"), %arg4: tensor<1x1xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p4.39"), %arg5: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p5.44"), %arg6: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p6.81"), %arg7: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"} loc("p7.118"), %arg8: tensor<1x8x16x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p8.128"), %arg9: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p9.137"), %arg10: tensor<1x8x16x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p10.156"), %arg11: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"} loc("p11.165"), %arg12: tensor<3072x8192xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p12.173"), %arg13: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p13.178"), %arg14: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p14.186"), %arg15: tensor<bf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"} loc("p15.210"), %arg16: tensor<f32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"} loc("p16.226"), %arg17: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p17.241"), %arg18: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p18.343"), %arg19: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p19.355"), %arg20: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"} loc("p20.407")) -> (tensor<1x8x16x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x16x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = ttir.empty() : tensor<1xi64> loc(#loc)
    %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi64> loc(#loc)
    %2 = ttir.empty() : tensor<64xf32> loc(#loc)
    %3 = "ttir.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32>, tensor<64xf32>) -> tensor<64xf32> loc(#loc)
    %4 = ttir.empty() : tensor<512x3072xbf16> loc(#loc)
    %5 = "ttir.mesh_shard"(%arg2, %4) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc)
    %6 = ttir.empty() : tensor<f32> loc(#loc)
    %7 = "ttir.mesh_shard"(%arg3, %6) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32>, tensor<f32>) -> tensor<f32> loc(#loc)
    %8 = ttir.empty() : tensor<1x1xi64> loc(#loc)
    %9 = "ttir.mesh_shard"(%arg4, %8) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x1xi64>, tensor<1x1xi64>) -> tensor<1x1xi64> loc(#loc)
    %10 = ttir.empty() : tensor<128256x3072xbf16> loc(#loc)
    %11 = "ttir.mesh_shard"(%arg5, %10) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16>, tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc)
    %12 = ttir.empty() : tensor<3072xbf16> loc(#loc)
    %13 = "ttir.mesh_shard"(%arg6, %12) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc)
    %14 = ttir.empty() : tensor<i64> loc(#loc)
    %15 = "ttir.mesh_shard"(%arg7, %14) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<i64>, tensor<i64>) -> tensor<i64> loc(#loc)
    %16 = ttir.empty() : tensor<1x4x16x128xbf16> loc(#loc)
    %17 = "ttir.mesh_shard"(%arg8, %16) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x16x128xbf16>, tensor<1x4x16x128xbf16>) -> tensor<1x4x16x128xbf16> loc(#loc)
    %18 = ttir.empty() : tensor<512x3072xbf16> loc(#loc)
    %19 = "ttir.mesh_shard"(%arg9, %18) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc)
    %20 = ttir.empty() : tensor<1x4x16x128xbf16> loc(#loc)
    %21 = "ttir.mesh_shard"(%arg10, %20) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x16x128xbf16>, tensor<1x4x16x128xbf16>) -> tensor<1x4x16x128xbf16> loc(#loc)
    %22 = ttir.empty() : tensor<128256x3072xbf16> loc(#loc)
    %23 = "ttir.mesh_shard"(%arg11, %22) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16>, tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc)
    %24 = ttir.empty() : tensor<3072x4096xbf16> loc(#loc)
    %25 = "ttir.mesh_shard"(%arg12, %24) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc)
    %26 = ttir.empty() : tensor<4096x3072xbf16> loc(#loc)
    %27 = "ttir.mesh_shard"(%arg13, %26) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc)
    %28 = ttir.empty() : tensor<3072x1536xbf16> loc(#loc)
    %29 = "ttir.mesh_shard"(%arg14, %28) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16> loc(#loc)
    %30 = ttir.empty() : tensor<bf16> loc(#loc)
    %31 = "ttir.mesh_shard"(%arg15, %30) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<bf16>, tensor<bf16>) -> tensor<bf16> loc(#loc)
    %32 = ttir.empty() : tensor<f32> loc(#loc)
    %33 = "ttir.mesh_shard"(%arg16, %32) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32>, tensor<f32>) -> tensor<f32> loc(#loc)
    %34 = ttir.empty() : tensor<1536x3072xbf16> loc(#loc)
    %35 = "ttir.mesh_shard"(%arg17, %34) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc)
    %36 = ttir.empty() : tensor<3072xbf16> loc(#loc)
    %37 = "ttir.mesh_shard"(%arg18, %36) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc)
    %38 = ttir.empty() : tensor<4096x3072xbf16> loc(#loc)
    %39 = "ttir.mesh_shard"(%arg19, %38) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc)
    %40 = ttir.empty() : tensor<3072xbf16> loc(#loc)
    %41 = "ttir.mesh_shard"(%arg20, %40) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc)
    %42 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
    %43 = "ttir.constant"() <{value = dense<0xFF800000> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
    %44 = "ttir.constant"() <{value = dense<0> : tensor<1xi64>}> : () -> tensor<1xi64> loc(#loc)
    %45 = "ttir.constant"() <{value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]> : tensor<1x16xi64>}> : () -> tensor<1x16xi64> loc(#loc)
    %46 = "ttir.constant"() <{value = dense<3.25520843E-4> : tensor<1x1xf32>}> : () -> tensor<1x1xf32> loc(#loc)
    %47 = "ttir.constant"() <{value = dense<2.000000e+00> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
    %48 = ttir.empty() : tensor<1x1x1xf32> loc(#loc)
    %49 = "ttir.reshape"(%47, %48) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc)
    %50 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc)
    %51 = "ttir.broadcast"(%49, %50) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc)
    %52 = ttir.empty() : tensor<1x1x1xi64> loc(#loc22)
    %53 = "ttir.reshape"(%1, %52) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1xi64>, tensor<1x1x1xi64>) -> tensor<1x1x1xi64> loc(#loc22)
    %54 = ttir.empty() : tensor<1xi64> loc(#loc23)
    %55 = "ttir.reshape"(%53, %54) <{shape = [1 : i32]}> : (tensor<1x1x1xi64>, tensor<1xi64>) -> tensor<1xi64> loc(#loc23)
    %56 = ttir.empty() : tensor<1xi1> loc(#loc24)
    %57 = "ttir.lt"(%55, %44, %56) : (tensor<1xi64>, tensor<1xi64>, tensor<1xi1>) -> tensor<1xi1> loc(#loc24)
    %58 = ttir.empty() : tensor<1xi64> loc(#loc25)
    %59 = "ttir.reshape"(%15, %58) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64> loc(#loc25)
    %60 = ttir.empty() : tensor<1xi64> loc(#loc26)
    %61 = "ttir.add"(%55, %59, %60) : (tensor<1xi64>, tensor<1xi64>, tensor<1xi64>) -> tensor<1xi64> loc(#loc26)
    %62 = ttir.empty() : tensor<1xi64> loc(#loc27)
    %63 = "ttir.where"(%57, %61, %55, %62) : (tensor<1xi1>, tensor<1xi64>, tensor<1xi64>, tensor<1xi64>) -> tensor<1xi64> loc(#loc27)
    %64 = ttir.empty() : tensor<1x1xi64> loc(#loc28)
    %65 = "ttir.reshape"(%63, %64) <{shape = [1 : i32, 1 : i32]}> : (tensor<1xi64>, tensor<1x1xi64>) -> tensor<1x1xi64> loc(#loc28)
    %66 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc29)
    %67 = "ttir.reshape"(%13, %66) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc29)
    %68 = ttir.empty() : tensor<3072xbf16> loc(#loc30)
    %69 = "ttir.reshape"(%67, %68) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc30)
    %70 = ttir.empty() : tensor<3072xf32> loc(#loc31)
    %71 = "ttir.typecast"(%69, %70) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32> loc(#loc31)
    %72 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc32)
    %73 = "ttir.reshape"(%71, %72) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc32)
    %74 = ttir.empty() : tensor<1x128256x3072xbf16> loc(#loc33)
    %75 = "ttir.reshape"(%11, %74) <{shape = [1 : i32, 128256 : i32, 3072 : i32]}> : (tensor<128256x3072xbf16>, tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc33)
    %76 = ttir.empty() : tensor<128256x3072xbf16> loc(#loc34)
    %77 = "ttir.reshape"(%75, %76) <{shape = [128256 : i32, 3072 : i32]}> : (tensor<1x128256x3072xbf16>, tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc34)
    %78 = ttir.empty() : tensor<1x1x1xi64> loc(#loc35)
    %79 = "ttir.reshape"(%9, %78) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xi64>, tensor<1x1x1xi64>) -> tensor<1x1x1xi64> loc(#loc35)
    %80 = ttir.empty() : tensor<1xi64> loc(#loc36)
    %81 = "ttir.reshape"(%79, %80) <{shape = [1 : i32]}> : (tensor<1x1x1xi64>, tensor<1xi64>) -> tensor<1xi64> loc(#loc36)
    %82 = ttir.empty() : tensor<1xui32> loc(#loc37)
    %83 = "ttir.typecast"(%81, %82) <{conservative_folding = false}> : (tensor<1xi64>, tensor<1xui32>) -> tensor<1xui32> loc(#loc37)
    %84 = ttir.empty() : tensor<1x3072xbf16> loc(#loc38)
    %85 = "ttir.gather"(%77, %83, %84) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3072>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<128256x3072xbf16>, tensor<1xui32>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc38)
    %86 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc39)
    %87 = "ttir.reshape"(%85, %86) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc39)
    %88 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc40)
    %89 = "ttir.typecast"(%87, %88) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc40)
    %90 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc41)
    %91 = "ttir.pow"(%89, %51, %90) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc41)
    %92 = ttir.empty() : tensor<1x1xf32> loc(#loc42)
    %93 = "ttir.sum"(%91, %92) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32> loc(#loc42)
    %94 = ttir.empty() : tensor<1x1xf32> loc(#loc43)
    %95 = "ttir.multiply"(%93, %46, %94) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32> loc(#loc43)
    %96 = ttir.empty() : tensor<1x1x1xf32> loc(#loc44)
    %97 = "ttir.reshape"(%95, %96) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc44)
    %98 = ttir.empty() : tensor<1x1x1xf32> loc(#loc45)
    %99 = "ttir.reshape"(%7, %98) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc45)
    %100 = ttir.empty() : tensor<1x1x1xf32> loc(#loc46)
    %101 = "ttir.add"(%97, %99, %100) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc46)
    %102 = ttir.empty() : tensor<1x1x1xf32> loc(#loc47)
    %103 = "ttir.rsqrt"(%101, %102) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc47)
    %104 = ttir.empty() : tensor<1x1xf32> loc(#loc48)
    %105 = "ttir.reshape"(%103, %104) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32> loc(#loc48)
    %106 = ttir.empty() : tensor<1x1x1xf32> loc(#loc49)
    %107 = "ttir.reshape"(%105, %106) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc49)
    %108 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc49)
    %109 = "ttir.broadcast"(%107, %108) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc49)
    %110 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc50)
    %111 = "ttir.multiply"(%89, %109, %110) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc50)
    %112 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc51)
    %113 = "ttir.typecast"(%111, %112) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc51)
    %114 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc52)
    %115 = "ttir.typecast"(%113, %114) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc52)
    %116 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc53)
    %117 = "ttir.multiply"(%73, %115, %116) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc53)
    %118 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc54)
    %119 = "ttir.typecast"(%117, %118) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc54)
    %120 = ttir.empty() : tensor<1x3072xbf16> loc(#loc55)
    %121 = "ttir.reshape"(%119, %120) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc55)
    %122 = ttir.empty() : tensor<1x512x3072xbf16> loc(#loc56)
    %123 = "ttir.reshape"(%5, %122) <{shape = [1 : i32, 512 : i32, 3072 : i32]}> : (tensor<512x3072xbf16>, tensor<1x512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc56)
    %124 = ttir.empty() : tensor<512x3072xbf16> loc(#loc57)
    %125 = "ttir.reshape"(%123, %124) <{shape = [512 : i32, 3072 : i32]}> : (tensor<1x512x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc57)
    %126 = ttir.empty() : tensor<3072x512xbf16> loc(#loc58)
    %127 = "ttir.permute"(%125, %126) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16> loc(#loc58)
    %128 = "ttir.dot_general"(%121, %127) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16> loc(#loc59)
    %129 = ttir.empty() : tensor<1x4x1x128xbf16> loc(#loc60)
    %130 = "ttir.reshape"(%128, %129) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc60)
    %131 = ttir.empty() : tensor<1x4x1x128xf32> loc(#loc61)
    %132 = "ttir.typecast"(%130, %131) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32> loc(#loc61)
    %133 = ttir.empty() : tensor<1x1x64xf32> loc(#loc62)
    %134 = "ttir.reshape"(%3, %133) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x64xf32> loc(#loc62)
    %135 = ttir.empty() : tensor<1x64x1xf32> loc(#loc63)
    %136 = "ttir.reshape"(%134, %135) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<1x1x64xf32>, tensor<1x64x1xf32>) -> tensor<1x64x1xf32> loc(#loc63)
    %137 = ttir.empty() : tensor<1x1x1xf32> loc(#loc64)
    %138 = "ttir.typecast"(%53, %137) <{conservative_folding = false}> : (tensor<1x1x1xi64>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc64)
    %139 = "ttir.dot_general"(%136, %138) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32> loc(#loc65)
    %140 = ttir.empty() : tensor<1x1x64xf32> loc(#loc66)
    %141 = "ttir.reshape"(%139, %140) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<1x64x1xf32>, tensor<1x1x64xf32>) -> tensor<1x1x64xf32> loc(#loc66)
    %142 = ttir.empty() : tensor<1x1x128xf32> loc(#loc67)
    %143 = "ttir.concat"(%141, %141, %142) <{dim = 2 : si32}> : (tensor<1x1x64xf32>, tensor<1x1x64xf32>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc67)
    %144 = ttir.empty() : tensor<1x1x128xf32> loc(#loc68)
    %145 = "ttir.cos"(%143, %144) : (tensor<1x1x128xf32>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc68)
    %146 = ttir.empty() : tensor<1x1x128xbf16> loc(#loc69)
    %147 = "ttir.typecast"(%145, %146) <{conservative_folding = false}> : (tensor<1x1x128xf32>, tensor<1x1x128xbf16>) -> tensor<1x1x128xbf16> loc(#loc69)
    %148 = ttir.empty() : tensor<1x1x1x128xbf16> loc(#loc70)
    %149 = "ttir.reshape"(%147, %148) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xbf16>, tensor<1x1x1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc70)
    %150 = ttir.empty() : tensor<1x1x1x128xf32> loc(#loc71)
    %151 = "ttir.typecast"(%149, %150) <{conservative_folding = false}> : (tensor<1x1x1x128xbf16>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32> loc(#loc71)
    %152 = ttir.empty() : tensor<1x1x128xf32> loc(#loc72)
    %153 = "ttir.reshape"(%151, %152) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x1x128xf32>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc72)
    %154 = ttir.empty() : tensor<1x1x1x128xf32> loc(#loc73)
    %155 = "ttir.reshape"(%153, %154) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32> loc(#loc73)
    %156 = ttir.empty() : tensor<1x4x1x128xf32> loc(#loc73)
    %157 = "ttir.broadcast"(%155, %156) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32> loc(#loc73)
    %158 = ttir.empty() : tensor<1x4x1x128xf32> loc(#loc74)
    %159 = "ttir.multiply"(%132, %157, %158) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32> loc(#loc74)
    %160 = ttir.empty() : tensor<1x4x1x128xbf16> loc(#loc75)
    %161 = "ttir.typecast"(%159, %160) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc75)
    %162 = ttir.empty() : tensor<1x4x1x64xbf16> loc(#loc76)
    %163 = "ttir.slice_static"(%130, %162) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16> loc(#loc76)
    %164 = ttir.empty() : tensor<1x4x1x64xbf16> loc(#loc77)
    %165 = "ttir.neg"(%163, %164) : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16> loc(#loc77)
    %166 = ttir.empty() : tensor<1x4x1x64xbf16> loc(#loc78)
    %167 = "ttir.slice_static"(%130, %166) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16> loc(#loc78)
    %168 = ttir.empty() : tensor<1x4x1x128xbf16> loc(#loc79)
    %169 = "ttir.concat"(%165, %167, %168) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc79)
    %170 = ttir.empty() : tensor<1x4x1x128xf32> loc(#loc80)
    %171 = "ttir.typecast"(%169, %170) <{conservative_folding = false}> : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32> loc(#loc80)
    %172 = ttir.empty() : tensor<1x1x128xf32> loc(#loc81)
    %173 = "ttir.sin"(%143, %172) : (tensor<1x1x128xf32>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc81)
    %174 = ttir.empty() : tensor<1x1x128xbf16> loc(#loc82)
    %175 = "ttir.typecast"(%173, %174) <{conservative_folding = false}> : (tensor<1x1x128xf32>, tensor<1x1x128xbf16>) -> tensor<1x1x128xbf16> loc(#loc82)
    %176 = ttir.empty() : tensor<1x1x1x128xbf16> loc(#loc83)
    %177 = "ttir.reshape"(%175, %176) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xbf16>, tensor<1x1x1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc83)
    %178 = ttir.empty() : tensor<1x1x1x128xf32> loc(#loc84)
    %179 = "ttir.typecast"(%177, %178) <{conservative_folding = false}> : (tensor<1x1x1x128xbf16>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32> loc(#loc84)
    %180 = ttir.empty() : tensor<1x1x128xf32> loc(#loc85)
    %181 = "ttir.reshape"(%179, %180) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x1x128xf32>, tensor<1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc85)
    %182 = ttir.empty() : tensor<1x1x1x128xf32> loc(#loc86)
    %183 = "ttir.reshape"(%181, %182) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32> loc(#loc86)
    %184 = ttir.empty() : tensor<1x4x1x128xf32> loc(#loc86)
    %185 = "ttir.broadcast"(%183, %184) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32> loc(#loc86)
    %186 = ttir.empty() : tensor<1x4x1x128xf32> loc(#loc87)
    %187 = "ttir.multiply"(%171, %185, %186) : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>, tensor<1x4x1x128xf32>) -> tensor<1x4x1x128xf32> loc(#loc87)
    %188 = ttir.empty() : tensor<1x4x1x128xbf16> loc(#loc88)
    %189 = "ttir.typecast"(%187, %188) <{conservative_folding = false}> : (tensor<1x4x1x128xf32>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc88)
    %190 = ttir.empty() : tensor<1x4x1x128xbf16> loc(#loc89)
    %191 = "ttir.add"(%161, %189, %190) : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc89)
    %192 = ttir.empty() : tensor<1x4x16x128xbf16> loc(#loc90)
    %193 = "ttir.scatter"(%17, %65, %191, %192) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x16x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x16x128xbf16>) -> tensor<1x4x16x128xbf16> loc(#loc90)
    %194 = ttir.empty() : tensor<1x512x3072xbf16> loc(#loc91)
    %195 = "ttir.reshape"(%19, %194) <{shape = [1 : i32, 512 : i32, 3072 : i32]}> : (tensor<512x3072xbf16>, tensor<1x512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc91)
    %196 = ttir.empty() : tensor<512x3072xbf16> loc(#loc92)
    %197 = "ttir.reshape"(%195, %196) <{shape = [512 : i32, 3072 : i32]}> : (tensor<1x512x3072xbf16>, tensor<512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc92)
    %198 = ttir.empty() : tensor<3072x512xbf16> loc(#loc93)
    %199 = "ttir.permute"(%197, %198) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>, tensor<3072x512xbf16>) -> tensor<3072x512xbf16> loc(#loc93)
    %200 = "ttir.dot_general"(%121, %199) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16> loc(#loc94)
    %201 = ttir.empty() : tensor<1x4x1x128xbf16> loc(#loc95)
    %202 = "ttir.reshape"(%200, %201) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc95)
    %203 = ttir.empty() : tensor<1x4x16x128xbf16> loc(#loc96)
    %204 = "ttir.scatter"(%21, %65, %202, %203) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x16x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>, tensor<1x4x16x128xbf16>) -> tensor<1x4x16x128xbf16> loc(#loc96)
    %205 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc97)
    %206 = "ttir.reshape"(%41, %205) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc97)
    %207 = ttir.empty() : tensor<3072xbf16> loc(#loc98)
    %208 = "ttir.reshape"(%206, %207) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc98)
    %209 = ttir.empty() : tensor<3072xf32> loc(#loc99)
    %210 = "ttir.typecast"(%208, %209) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32> loc(#loc99)
    %211 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc100)
    %212 = "ttir.reshape"(%210, %211) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc100)
    %213 = ttir.empty() : tensor<1x1536x3072xbf16> loc(#loc101)
    %214 = "ttir.reshape"(%35, %213) <{shape = [1 : i32, 1536 : i32, 3072 : i32]}> : (tensor<1536x3072xbf16>, tensor<1x1536x3072xbf16>) -> tensor<1x1536x3072xbf16> loc(#loc101)
    %215 = ttir.empty() : tensor<1536x3072xbf16> loc(#loc102)
    %216 = "ttir.reshape"(%214, %215) <{shape = [1536 : i32, 3072 : i32]}> : (tensor<1x1536x3072xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc102)
    %217 = ttir.empty() : tensor<3072x1536xbf16> loc(#loc103)
    %218 = "ttir.permute"(%216, %217) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16> loc(#loc103)
    %219 = "ttir.dot_general"(%121, %218) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16> loc(#loc104)
    %220 = ttir.empty() : tensor<1x12x1x128xbf16> loc(#loc105)
    %221 = "ttir.reshape"(%219, %220) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc105)
    %222 = ttir.empty() : tensor<1x12x1x128xf32> loc(#loc106)
    %223 = "ttir.typecast"(%221, %222) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32> loc(#loc106)
    %224 = ttir.empty() : tensor<1x1x1x128xf32> loc(#loc107)
    %225 = "ttir.reshape"(%153, %224) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32> loc(#loc107)
    %226 = ttir.empty() : tensor<1x12x1x128xf32> loc(#loc107)
    %227 = "ttir.broadcast"(%225, %226) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32> loc(#loc107)
    %228 = ttir.empty() : tensor<1x12x1x128xf32> loc(#loc108)
    %229 = "ttir.multiply"(%223, %227, %228) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32> loc(#loc108)
    %230 = ttir.empty() : tensor<1x12x1x128xbf16> loc(#loc109)
    %231 = "ttir.typecast"(%229, %230) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc109)
    %232 = ttir.empty() : tensor<1x12x1x64xbf16> loc(#loc110)
    %233 = "ttir.slice_static"(%221, %232) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16> loc(#loc110)
    %234 = ttir.empty() : tensor<1x12x1x64xbf16> loc(#loc111)
    %235 = "ttir.neg"(%233, %234) : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16> loc(#loc111)
    %236 = ttir.empty() : tensor<1x12x1x64xbf16> loc(#loc112)
    %237 = "ttir.slice_static"(%221, %236) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16> loc(#loc112)
    %238 = ttir.empty() : tensor<1x12x1x128xbf16> loc(#loc113)
    %239 = "ttir.concat"(%235, %237, %238) <{dim = 3 : si32}> : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc113)
    %240 = ttir.empty() : tensor<1x12x1x128xf32> loc(#loc114)
    %241 = "ttir.typecast"(%239, %240) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32> loc(#loc114)
    %242 = ttir.empty() : tensor<1x1x1x128xf32> loc(#loc115)
    %243 = "ttir.reshape"(%181, %242) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xf32>, tensor<1x1x1x128xf32>) -> tensor<1x1x1x128xf32> loc(#loc115)
    %244 = ttir.empty() : tensor<1x12x1x128xf32> loc(#loc115)
    %245 = "ttir.broadcast"(%243, %244) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32> loc(#loc115)
    %246 = ttir.empty() : tensor<1x12x1x128xf32> loc(#loc116)
    %247 = "ttir.multiply"(%241, %245, %246) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32> loc(#loc116)
    %248 = ttir.empty() : tensor<1x12x1x128xbf16> loc(#loc117)
    %249 = "ttir.typecast"(%247, %248) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc117)
    %250 = ttir.empty() : tensor<1x12x1x128xbf16> loc(#loc118)
    %251 = "ttir.add"(%231, %249, %250) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc118)
    %252 = ttir.empty() : tensor<12x1x128xbf16> loc(#loc119)
    %253 = "ttir.reshape"(%251, %252) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x12x1x128xbf16>, tensor<12x1x128xbf16>) -> tensor<12x1x128xbf16> loc(#loc119)
    %254 = ttir.empty() : tensor<1x4x1x16x128xbf16> loc(#loc120)
    %255 = "ttir.reshape"(%193, %254) <{shape = [1 : i32, 4 : i32, 1 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x16x128xbf16>, tensor<1x4x1x16x128xbf16>) -> tensor<1x4x1x16x128xbf16> loc(#loc120)
    %256 = ttir.empty() : tensor<1x4x3x16x128xbf16> loc(#loc120)
    %257 = "ttir.broadcast"(%255, %256) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x16x128xbf16>, tensor<1x4x3x16x128xbf16>) -> tensor<1x4x3x16x128xbf16> loc(#loc120)
    %258 = ttir.empty() : tensor<1x12x16x128xbf16> loc(#loc121)
    %259 = "ttir.reshape"(%257, %258) <{shape = [1 : i32, 12 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x3x16x128xbf16>, tensor<1x12x16x128xbf16>) -> tensor<1x12x16x128xbf16> loc(#loc121)
    %260 = ttir.empty() : tensor<1x12x128x16xbf16> loc(#loc122)
    %261 = "ttir.permute"(%259, %260) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x16x128xbf16>, tensor<1x12x128x16xbf16>) -> tensor<1x12x128x16xbf16> loc(#loc122)
    %262 = ttir.empty() : tensor<12x128x16xbf16> loc(#loc123)
    %263 = "ttir.reshape"(%261, %262) <{shape = [12 : i32, 128 : i32, 16 : i32]}> : (tensor<1x12x128x16xbf16>, tensor<12x128x16xbf16>) -> tensor<12x128x16xbf16> loc(#loc123)
    %264 = "ttir.dot_general"(%253, %263) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x128xbf16>, tensor<12x128x16xbf16>) -> tensor<12x1x16xbf16> loc(#loc124)
    %265 = ttir.empty() : tensor<1x12x1x16xbf16> loc(#loc125)
    %266 = "ttir.reshape"(%264, %265) <{shape = [1 : i32, 12 : i32, 1 : i32, 16 : i32]}> : (tensor<12x1x16xbf16>, tensor<1x12x1x16xbf16>) -> tensor<1x12x1x16xbf16> loc(#loc125)
    %267 = ttir.empty() : tensor<1x12x1x16xf32> loc(#loc126)
    %268 = "ttir.typecast"(%266, %267) <{conservative_folding = false}> : (tensor<1x12x1x16xbf16>, tensor<1x12x1x16xf32>) -> tensor<1x12x1x16xf32> loc(#loc126)
    %269 = ttir.empty() : tensor<1x1x1x1xf32> loc(#loc127)
    %270 = "ttir.reshape"(%33, %269) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>, tensor<1x1x1x1xf32>) -> tensor<1x1x1x1xf32> loc(#loc127)
    %271 = ttir.empty() : tensor<1x12x1x16xf32> loc(#loc127)
    %272 = "ttir.broadcast"(%270, %271) <{broadcast_dimensions = array<i64: 1, 12, 1, 16>}> : (tensor<1x1x1x1xf32>, tensor<1x12x1x16xf32>) -> tensor<1x12x1x16xf32> loc(#loc127)
    %273 = ttir.empty() : tensor<1x12x1x16xf32> loc(#loc128)
    %274 = "ttir.multiply"(%268, %272, %273) : (tensor<1x12x1x16xf32>, tensor<1x12x1x16xf32>, tensor<1x12x1x16xf32>) -> tensor<1x12x1x16xf32> loc(#loc128)
    %275 = ttir.empty() : tensor<1x12x1x16xbf16> loc(#loc129)
    %276 = "ttir.typecast"(%274, %275) <{conservative_folding = false}> : (tensor<1x12x1x16xf32>, tensor<1x12x1x16xbf16>) -> tensor<1x12x1x16xbf16> loc(#loc129)
    %277 = ttir.empty() : tensor<1xbf16> loc(#loc130)
    %278 = "ttir.reshape"(%31, %277) <{shape = [1 : i32]}> : (tensor<bf16>, tensor<1xbf16>) -> tensor<1xbf16> loc(#loc130)
    %279 = ttir.empty() : tensor<1x1xbf16> loc(#loc131)
    %280 = "ttir.reshape"(%278, %279) <{shape = [1 : i32, 1 : i32]}> : (tensor<1xbf16>, tensor<1x1xbf16>) -> tensor<1x1xbf16> loc(#loc131)
    %281 = ttir.empty() : tensor<1x16xbf16> loc(#loc131)
    %282 = "ttir.broadcast"(%280, %281) <{broadcast_dimensions = array<i64: 1, 16>}> : (tensor<1x1xbf16>, tensor<1x16xbf16>) -> tensor<1x16xbf16> loc(#loc131)
    %283 = ttir.empty() : tensor<1x16xf32> loc(#loc132)
    %284 = "ttir.typecast"(%282, %283) <{conservative_folding = false}> : (tensor<1x16xbf16>, tensor<1x16xf32>) -> tensor<1x16xf32> loc(#loc132)
    %285 = ttir.empty() : tensor<1x1xi64> loc(#loc133)
    %286 = "ttir.reshape"(%55, %285) <{shape = [1 : i32, 1 : i32]}> : (tensor<1xi64>, tensor<1x1xi64>) -> tensor<1x1xi64> loc(#loc133)
    %287 = ttir.empty() : tensor<1x16xi64> loc(#loc133)
    %288 = "ttir.broadcast"(%286, %287) <{broadcast_dimensions = array<i64: 1, 16>}> : (tensor<1x1xi64>, tensor<1x16xi64>) -> tensor<1x16xi64> loc(#loc133)
    %289 = ttir.empty() : tensor<1x16xi1> loc(#loc134)
    %290 = "ttir.gt"(%45, %288, %289) : (tensor<1x16xi64>, tensor<1x16xi64>, tensor<1x16xi1>) -> tensor<1x16xi1> loc(#loc134)
    %291 = ttir.empty() : tensor<1x16xf32> loc(#loc135)
    %292 = "ttir.typecast"(%290, %291) <{conservative_folding = false}> : (tensor<1x16xi1>, tensor<1x16xf32>) -> tensor<1x16xf32> loc(#loc135)
    %293 = ttir.empty() : tensor<1x16xf32> loc(#loc136)
    %294 = "ttir.multiply"(%284, %292, %293) : (tensor<1x16xf32>, tensor<1x16xf32>, tensor<1x16xf32>) -> tensor<1x16xf32> loc(#loc136)
    %295 = ttir.empty() : tensor<1x16xbf16> loc(#loc137)
    %296 = "ttir.typecast"(%294, %295) <{conservative_folding = false}> : (tensor<1x16xf32>, tensor<1x16xbf16>) -> tensor<1x16xbf16> loc(#loc137)
    %297 = ttir.empty() : tensor<1x1x16xbf16> loc(#loc138)
    %298 = "ttir.reshape"(%296, %297) <{shape = [1 : i32, 1 : i32, 16 : i32]}> : (tensor<1x16xbf16>, tensor<1x1x16xbf16>) -> tensor<1x1x16xbf16> loc(#loc138)
    %299 = ttir.empty() : tensor<1x1x1x16xbf16> loc(#loc139)
    %300 = "ttir.reshape"(%298, %299) <{shape = [1 : i32, 1 : i32, 1 : i32, 16 : i32]}> : (tensor<1x1x16xbf16>, tensor<1x1x1x16xbf16>) -> tensor<1x1x1x16xbf16> loc(#loc139)
    %301 = ttir.empty() : tensor<1x12x1x16xbf16> loc(#loc139)
    %302 = "ttir.broadcast"(%300, %301) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x1x16xbf16>, tensor<1x12x1x16xbf16>) -> tensor<1x12x1x16xbf16> loc(#loc139)
    %303 = ttir.empty() : tensor<1x12x1x16xbf16> loc(#loc140)
    %304 = "ttir.add"(%276, %302, %303) : (tensor<1x12x1x16xbf16>, tensor<1x12x1x16xbf16>, tensor<1x12x1x16xbf16>) -> tensor<1x12x1x16xbf16> loc(#loc140)
    %305 = ttir.empty() : tensor<1x12x1x16xf32> loc(#loc141)
    %306 = "ttir.typecast"(%304, %305) <{conservative_folding = false}> : (tensor<1x12x1x16xbf16>, tensor<1x12x1x16xf32>) -> tensor<1x12x1x16xf32> loc(#loc141)
    %307 = ttir.empty() : tensor<1x12x1xf32> loc(#loc142)
    %308 = "ttir.max"(%306, %307) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x16xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32> loc(#loc142)
    %309 = ttir.empty() : tensor<1x12x1x1xf32> loc(#loc143)
    %310 = "ttir.reshape"(%308, %309) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32> loc(#loc143)
    %311 = ttir.empty() : tensor<1x12x1x16xf32> loc(#loc143)
    %312 = "ttir.broadcast"(%310, %311) <{broadcast_dimensions = array<i64: 1, 1, 1, 16>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x16xf32>) -> tensor<1x12x1x16xf32> loc(#loc143)
    %313 = ttir.empty() : tensor<1x12x1x16xf32> loc(#loc144)
    %314 = "ttir.subtract"(%306, %312, %313) : (tensor<1x12x1x16xf32>, tensor<1x12x1x16xf32>, tensor<1x12x1x16xf32>) -> tensor<1x12x1x16xf32> loc(#loc144)
    %315 = ttir.empty() : tensor<1x12x1x16xf32> loc(#loc145)
    %316 = "ttir.exp"(%314, %315) : (tensor<1x12x1x16xf32>, tensor<1x12x1x16xf32>) -> tensor<1x12x1x16xf32> loc(#loc145)
    %317 = ttir.empty() : tensor<1x12x1xf32> loc(#loc146)
    %318 = "ttir.sum"(%316, %317) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x16xf32>, tensor<1x12x1xf32>) -> tensor<1x12x1xf32> loc(#loc146)
    %319 = ttir.empty() : tensor<1x12x1x1xf32> loc(#loc147)
    %320 = "ttir.reshape"(%318, %319) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>, tensor<1x12x1x1xf32>) -> tensor<1x12x1x1xf32> loc(#loc147)
    %321 = ttir.empty() : tensor<1x12x1x16xf32> loc(#loc147)
    %322 = "ttir.broadcast"(%320, %321) <{broadcast_dimensions = array<i64: 1, 1, 1, 16>}> : (tensor<1x12x1x1xf32>, tensor<1x12x1x16xf32>) -> tensor<1x12x1x16xf32> loc(#loc147)
    %323 = ttir.empty() : tensor<1x12x1x16xf32> loc(#loc148)
    %324 = "ttir.div"(%316, %322, %323) : (tensor<1x12x1x16xf32>, tensor<1x12x1x16xf32>, tensor<1x12x1x16xf32>) -> tensor<1x12x1x16xf32> loc(#loc148)
    %325 = ttir.empty() : tensor<1x12x1x16xbf16> loc(#loc149)
    %326 = "ttir.typecast"(%324, %325) <{conservative_folding = false}> : (tensor<1x12x1x16xf32>, tensor<1x12x1x16xbf16>) -> tensor<1x12x1x16xbf16> loc(#loc149)
    %327 = ttir.empty() : tensor<12x1x16xbf16> loc(#loc150)
    %328 = "ttir.reshape"(%326, %327) <{shape = [12 : i32, 1 : i32, 16 : i32]}> : (tensor<1x12x1x16xbf16>, tensor<12x1x16xbf16>) -> tensor<12x1x16xbf16> loc(#loc150)
    %329 = ttir.empty() : tensor<1x4x1x16x128xbf16> loc(#loc151)
    %330 = "ttir.reshape"(%204, %329) <{shape = [1 : i32, 4 : i32, 1 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x16x128xbf16>, tensor<1x4x1x16x128xbf16>) -> tensor<1x4x1x16x128xbf16> loc(#loc151)
    %331 = ttir.empty() : tensor<1x4x3x16x128xbf16> loc(#loc151)
    %332 = "ttir.broadcast"(%330, %331) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x16x128xbf16>, tensor<1x4x3x16x128xbf16>) -> tensor<1x4x3x16x128xbf16> loc(#loc151)
    %333 = ttir.empty() : tensor<12x16x128xbf16> loc(#loc152)
    %334 = "ttir.reshape"(%332, %333) <{shape = [12 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x3x16x128xbf16>, tensor<12x16x128xbf16>) -> tensor<12x16x128xbf16> loc(#loc152)
    %335 = "ttir.dot_general"(%328, %334) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<12x1x16xbf16>, tensor<12x16x128xbf16>) -> tensor<12x1x128xbf16> loc(#loc153)
    %336 = ttir.empty() : tensor<1x1536xbf16> loc(#loc154)
    %337 = "ttir.reshape"(%335, %336) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16>, tensor<1x1536xbf16>) -> tensor<1x1536xbf16> loc(#loc154)
    %338 = ttir.empty() : tensor<1x3072x1536xbf16> loc(#loc155)
    %339 = "ttir.reshape"(%29, %338) <{shape = [1 : i32, 3072 : i32, 1536 : i32]}> : (tensor<3072x1536xbf16>, tensor<1x3072x1536xbf16>) -> tensor<1x3072x1536xbf16> loc(#loc155)
    %340 = ttir.empty() : tensor<3072x1536xbf16> loc(#loc156)
    %341 = "ttir.reshape"(%339, %340) <{shape = [3072 : i32, 1536 : i32]}> : (tensor<1x3072x1536xbf16>, tensor<3072x1536xbf16>) -> tensor<3072x1536xbf16> loc(#loc156)
    %342 = ttir.empty() : tensor<1536x3072xbf16> loc(#loc157)
    %343 = "ttir.permute"(%341, %342) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc157)
    %344 = "ttir.dot_general"(%337, %343) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc158)
    %345 = ttir.empty() : tensor<1x3072xbf16> loc(#loc158)
    %346 = "ttir.all_reduce"(%344, %345) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc158)
    %347 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc159)
    %348 = "ttir.reshape"(%346, %347) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc159)
    %349 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc160)
    %350 = "ttir.add"(%87, %348, %349) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc160)
    %351 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc161)
    %352 = "ttir.reshape"(%37, %351) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc161)
    %353 = ttir.empty() : tensor<3072xbf16> loc(#loc162)
    %354 = "ttir.reshape"(%352, %353) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc162)
    %355 = ttir.empty() : tensor<3072xf32> loc(#loc163)
    %356 = "ttir.typecast"(%354, %355) <{conservative_folding = false}> : (tensor<3072xbf16>, tensor<3072xf32>) -> tensor<3072xf32> loc(#loc163)
    %357 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc164)
    %358 = "ttir.reshape"(%356, %357) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc164)
    %359 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc165)
    %360 = "ttir.typecast"(%350, %359) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc165)
    %361 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc166)
    %362 = "ttir.pow"(%360, %51, %361) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc166)
    %363 = ttir.empty() : tensor<1x1xf32> loc(#loc167)
    %364 = "ttir.sum"(%362, %363) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32> loc(#loc167)
    %365 = ttir.empty() : tensor<1x1xf32> loc(#loc168)
    %366 = "ttir.multiply"(%364, %46, %365) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32> loc(#loc168)
    %367 = ttir.empty() : tensor<1x1x1xf32> loc(#loc169)
    %368 = "ttir.reshape"(%366, %367) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc169)
    %369 = ttir.empty() : tensor<1x1x1xf32> loc(#loc170)
    %370 = "ttir.add"(%368, %99, %369) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc170)
    %371 = ttir.empty() : tensor<1x1x1xf32> loc(#loc171)
    %372 = "ttir.rsqrt"(%370, %371) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc171)
    %373 = ttir.empty() : tensor<1x1xf32> loc(#loc172)
    %374 = "ttir.reshape"(%372, %373) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32> loc(#loc172)
    %375 = ttir.empty() : tensor<1x1x1xf32> loc(#loc173)
    %376 = "ttir.reshape"(%374, %375) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc173)
    %377 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc173)
    %378 = "ttir.broadcast"(%376, %377) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc173)
    %379 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc174)
    %380 = "ttir.multiply"(%360, %378, %379) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc174)
    %381 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc175)
    %382 = "ttir.typecast"(%380, %381) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc175)
    %383 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc176)
    %384 = "ttir.typecast"(%382, %383) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc176)
    %385 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc177)
    %386 = "ttir.multiply"(%358, %384, %385) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc177)
    %387 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc178)
    %388 = "ttir.typecast"(%386, %387) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc178)
    %389 = ttir.empty() : tensor<1x3072xbf16> loc(#loc179)
    %390 = "ttir.reshape"(%388, %389) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc179)
    %391 = ttir.empty() : tensor<1x4096x3072xbf16> loc(#loc180)
    %392 = "ttir.reshape"(%39, %391) <{shape = [1 : i32, 4096 : i32, 3072 : i32]}> : (tensor<4096x3072xbf16>, tensor<1x4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc180)
    %393 = ttir.empty() : tensor<4096x3072xbf16> loc(#loc181)
    %394 = "ttir.reshape"(%392, %393) <{shape = [4096 : i32, 3072 : i32]}> : (tensor<1x4096x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc181)
    %395 = ttir.empty() : tensor<3072x4096xbf16> loc(#loc182)
    %396 = "ttir.permute"(%394, %395) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc182)
    %397 = "ttir.dot_general"(%390, %396) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16> loc(#loc183)
    %398 = ttir.empty() : tensor<1x1x4096xbf16> loc(#loc184)
    %399 = "ttir.reshape"(%397, %398) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc184)
    %400 = ttir.empty() : tensor<1x1x4096xf32> loc(#loc185)
    %401 = "ttir.typecast"(%399, %400) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32> loc(#loc185)
    %402 = ttir.empty() : tensor<1x1x4096xbf16> loc(#loc186)
    %403 = "ttir.sigmoid"(%399, %402) : (tensor<1x1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc186)
    %404 = ttir.empty() : tensor<1x1x4096xf32> loc(#loc187)
    %405 = "ttir.typecast"(%403, %404) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32> loc(#loc187)
    %406 = ttir.empty() : tensor<1x1x4096xf32> loc(#loc188)
    %407 = "ttir.multiply"(%401, %405, %406) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32> loc(#loc188)
    %408 = ttir.empty() : tensor<1x1x4096xbf16> loc(#loc189)
    %409 = "ttir.typecast"(%407, %408) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc189)
    %410 = ttir.empty() : tensor<1x1x4096xf32> loc(#loc190)
    %411 = "ttir.typecast"(%409, %410) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32> loc(#loc190)
    %412 = ttir.empty() : tensor<1x4096x3072xbf16> loc(#loc191)
    %413 = "ttir.reshape"(%27, %412) <{shape = [1 : i32, 4096 : i32, 3072 : i32]}> : (tensor<4096x3072xbf16>, tensor<1x4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc191)
    %414 = ttir.empty() : tensor<4096x3072xbf16> loc(#loc192)
    %415 = "ttir.reshape"(%413, %414) <{shape = [4096 : i32, 3072 : i32]}> : (tensor<1x4096x3072xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc192)
    %416 = ttir.empty() : tensor<3072x4096xbf16> loc(#loc193)
    %417 = "ttir.permute"(%415, %416) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc193)
    %418 = "ttir.dot_general"(%390, %417) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16> loc(#loc194)
    %419 = ttir.empty() : tensor<1x1x4096xbf16> loc(#loc195)
    %420 = "ttir.reshape"(%418, %419) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc195)
    %421 = ttir.empty() : tensor<1x1x4096xf32> loc(#loc196)
    %422 = "ttir.typecast"(%420, %421) <{conservative_folding = false}> : (tensor<1x1x4096xbf16>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32> loc(#loc196)
    %423 = ttir.empty() : tensor<1x1x4096xf32> loc(#loc197)
    %424 = "ttir.multiply"(%411, %422, %423) : (tensor<1x1x4096xf32>, tensor<1x1x4096xf32>, tensor<1x1x4096xf32>) -> tensor<1x1x4096xf32> loc(#loc197)
    %425 = ttir.empty() : tensor<1x1x4096xbf16> loc(#loc198)
    %426 = "ttir.typecast"(%424, %425) <{conservative_folding = false}> : (tensor<1x1x4096xf32>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc198)
    %427 = ttir.empty() : tensor<1x4096xbf16> loc(#loc199)
    %428 = "ttir.reshape"(%426, %427) <{shape = [1 : i32, 4096 : i32]}> : (tensor<1x1x4096xbf16>, tensor<1x4096xbf16>) -> tensor<1x4096xbf16> loc(#loc199)
    %429 = ttir.empty() : tensor<1x3072x4096xbf16> loc(#loc200)
    %430 = "ttir.reshape"(%25, %429) <{shape = [1 : i32, 3072 : i32, 4096 : i32]}> : (tensor<3072x4096xbf16>, tensor<1x3072x4096xbf16>) -> tensor<1x3072x4096xbf16> loc(#loc200)
    %431 = ttir.empty() : tensor<3072x4096xbf16> loc(#loc201)
    %432 = "ttir.reshape"(%430, %431) <{shape = [3072 : i32, 4096 : i32]}> : (tensor<1x3072x4096xbf16>, tensor<3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc201)
    %433 = ttir.empty() : tensor<4096x3072xbf16> loc(#loc202)
    %434 = "ttir.permute"(%432, %433) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc202)
    %435 = "ttir.dot_general"(%428, %434) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc203)
    %436 = ttir.empty() : tensor<1x3072xbf16> loc(#loc203)
    %437 = "ttir.all_reduce"(%435, %436) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc203)
    %438 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc204)
    %439 = "ttir.reshape"(%437, %438) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc204)
    %440 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc205)
    %441 = "ttir.add"(%350, %439, %440) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc205)
    %442 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc206)
    %443 = "ttir.typecast"(%441, %442) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc206)
    %444 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc207)
    %445 = "ttir.pow"(%443, %51, %444) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc207)
    %446 = ttir.empty() : tensor<1x1xf32> loc(#loc208)
    %447 = "ttir.sum"(%445, %446) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>, tensor<1x1xf32>) -> tensor<1x1xf32> loc(#loc208)
    %448 = ttir.empty() : tensor<1x1xf32> loc(#loc209)
    %449 = "ttir.multiply"(%447, %46, %448) : (tensor<1x1xf32>, tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32> loc(#loc209)
    %450 = ttir.empty() : tensor<1x1x1xf32> loc(#loc210)
    %451 = "ttir.reshape"(%449, %450) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc210)
    %452 = ttir.empty() : tensor<1x1x1xf32> loc(#loc211)
    %453 = "ttir.add"(%451, %99, %452) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc211)
    %454 = ttir.empty() : tensor<1x1x1xf32> loc(#loc212)
    %455 = "ttir.rsqrt"(%453, %454) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc212)
    %456 = ttir.empty() : tensor<1x1xf32> loc(#loc213)
    %457 = "ttir.reshape"(%455, %456) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32> loc(#loc213)
    %458 = ttir.empty() : tensor<1x1x1xf32> loc(#loc214)
    %459 = "ttir.reshape"(%457, %458) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc214)
    %460 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc214)
    %461 = "ttir.broadcast"(%459, %460) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc214)
    %462 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc215)
    %463 = "ttir.multiply"(%443, %461, %462) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc215)
    %464 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc216)
    %465 = "ttir.typecast"(%463, %464) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc216)
    %466 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc217)
    %467 = "ttir.typecast"(%465, %466) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc217)
    %468 = ttir.empty() : tensor<1x1x3072xf32> loc(#loc218)
    %469 = "ttir.multiply"(%212, %467, %468) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc218)
    %470 = ttir.empty() : tensor<1x1x3072xbf16> loc(#loc219)
    %471 = "ttir.typecast"(%469, %470) <{conservative_folding = false}> : (tensor<1x1x3072xf32>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc219)
    %472 = ttir.empty() : tensor<1x3072xbf16> loc(#loc220)
    %473 = "ttir.reshape"(%471, %472) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>, tensor<1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc220)
    %474 = ttir.empty() : tensor<1x128256x3072xbf16> loc(#loc221)
    %475 = "ttir.reshape"(%23, %474) <{shape = [1 : i32, 128256 : i32, 3072 : i32]}> : (tensor<128256x3072xbf16>, tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc221)
    %476 = ttir.empty() : tensor<128256x3072xbf16> loc(#loc222)
    %477 = "ttir.reshape"(%475, %476) <{shape = [128256 : i32, 3072 : i32]}> : (tensor<1x128256x3072xbf16>, tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc222)
    %478 = ttir.empty() : tensor<3072x128256xbf16> loc(#loc223)
    %479 = "ttir.permute"(%477, %478) <{permutation = array<i64: 1, 0>}> : (tensor<128256x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<3072x128256xbf16> loc(#loc223)
    %480 = "ttir.dot_general"(%473, %479) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<1x128256xbf16> loc(#loc224)
    %481 = ttir.empty() : tensor<1x1x128256xbf16> loc(#loc225)
    %482 = "ttir.reshape"(%480, %481) <{shape = [1 : i32, 1 : i32, 128256 : i32]}> : (tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) -> tensor<1x1x128256xbf16> loc(#loc225)
    %483 = ttir.empty() : tensor<1x8x16x128xbf16> loc(#loc)
    %484 = "ttir.mesh_shard"(%193, %483) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x16x128xbf16>, tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc)
    %485 = ttir.empty() : tensor<1x8x16x128xbf16> loc(#loc)
    %486 = "ttir.mesh_shard"(%204, %485) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x16x128xbf16>, tensor<1x8x16x128xbf16>) -> tensor<1x8x16x128xbf16> loc(#loc)
    %487 = ttir.empty() : tensor<1x128256xbf16> loc(#loc)
    %488 = "ttir.mesh_shard"(%480, %487) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x128256xbf16>, tensor<1x128256xbf16>) -> tensor<1x128256xbf16> loc(#loc)
    %489 = ttir.empty() : tensor<1x1x128256xbf16> loc(#loc)
    %490 = "ttir.mesh_shard"(%482, %489) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x1x128256xbf16>, tensor<1x1x128256xbf16>) -> tensor<1x1x128256xbf16> loc(#loc)
    return %484, %486, %488, %490 : tensor<1x8x16x128xbf16>, tensor<1x8x16x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc22 = loc("reshape.4")
#loc23 = loc("reshape.6")
#loc24 = loc("compare.124")
#loc25 = loc("reshape.119")
#loc26 = loc("add.121")
#loc27 = loc("select.125")
#loc28 = loc("reshape.126")
#loc29 = loc("reshape.82")
#loc30 = loc("reshape.84")
#loc31 = loc("convert.85")
#loc32 = loc("broadcast.86")
#loc33 = loc("reshape.45")
#loc34 = loc("reshape.47")
#loc35 = loc("reshape.40")
#loc36 = loc("reshape.43")
#loc37 = loc("convert.48")
#loc38 = loc("gather.49")
#loc39 = loc("reshape.50")
#loc40 = loc("convert.51")
#loc41 = loc("power.53")
#loc42 = loc("reduce.60")
#loc43 = loc("multiply.69")
#loc44 = loc("reshape.70")
#loc45 = loc("broadcast.73")
#loc46 = loc("add.74")
#loc47 = loc("rsqrt.75")
#loc48 = loc("reshape.76")
#loc49 = loc("broadcast.77")
#loc50 = loc("multiply.78")
#loc51 = loc("convert.79")
#loc52 = loc("convert.80")
#loc53 = loc("multiply.87")
#loc54 = loc("convert.88")
#loc55 = loc("reshape.89")
#loc56 = loc("reshape.32")
#loc57 = loc("reshape.34")
#loc58 = loc("transpose.35")
#loc59 = loc("dot.90")
#loc60 = loc("transpose.93")
#loc61 = loc("convert.110")
#loc62 = loc("reshape.14")
#loc63 = loc("reshape.19")
#loc64 = loc("convert.11")
#loc65 = loc("dot.22")
#loc66 = loc("transpose.23")
#loc67 = loc("concatenate.24")
#loc68 = loc("cosine.104")
#loc69 = loc("convert.107")
#loc70 = loc("reshape.108")
#loc71 = loc("convert.109")
#loc72 = loc("reshape.111")
#loc73 = loc("broadcast.112")
#loc74 = loc("multiply.113")
#loc75 = loc("convert.114")
#loc76 = loc("slice.95")
#loc77 = loc("negate.96")
#loc78 = loc("slice.94")
#loc79 = loc("concatenate.97")
#loc80 = loc("convert.98")
#loc81 = loc("sine.25")
#loc82 = loc("convert.28")
#loc83 = loc("reshape.29")
#loc84 = loc("convert.30")
#loc85 = loc("reshape.99")
#loc86 = loc("broadcast.100")
#loc87 = loc("multiply.101")
#loc88 = loc("convert.102")
#loc89 = loc("add.117")
#loc90 = loc("scatter.134")
#loc91 = loc("reshape.138")
#loc92 = loc("reshape.140")
#loc93 = loc("transpose.141")
#loc94 = loc("dot.143")
#loc95 = loc("transpose.146")
#loc96 = loc("scatter.162")
#loc97 = loc("reshape.408")
#loc98 = loc("reshape.410")
#loc99 = loc("convert.411")
#loc100 = loc("broadcast.412")
#loc101 = loc("reshape.242")
#loc102 = loc("reshape.244")
#loc103 = loc("transpose.245")
#loc104 = loc("dot.247")
#loc105 = loc("transpose.250")
#loc106 = loc("convert.261")
#loc107 = loc("broadcast.263")
#loc108 = loc("multiply.264")
#loc109 = loc("convert.265")
#loc110 = loc("slice.252")
#loc111 = loc("negate.253")
#loc112 = loc("slice.251")
#loc113 = loc("concatenate.254")
#loc114 = loc("convert.255")
#loc115 = loc("broadcast.257")
#loc116 = loc("multiply.258")
#loc117 = loc("convert.259")
#loc118 = loc("add.268")
#loc119 = loc("reshape.270")
#loc120 = loc("broadcast.234")
#loc121 = loc("reshape.235")
#loc122 = loc("transpose.236")
#loc123 = loc("reshape.238")
#loc124 = loc("dot.271")
#loc125 = loc("reshape.272")
#loc126 = loc("convert.273")
#loc127 = loc("broadcast.274")
#loc128 = loc("multiply.275")
#loc129 = loc("convert.276")
#loc130 = loc("reshape.213")
#loc131 = loc("broadcast.214")
#loc132 = loc("convert.215")
#loc133 = loc("broadcast.207")
#loc134 = loc("compare.208")
#loc135 = loc("convert.209")
#loc136 = loc("multiply.216")
#loc137 = loc("convert.217")
#loc138 = loc("reshape.218")
#loc139 = loc("broadcast.280")
#loc140 = loc("add.281")
#loc141 = loc("convert.282")
#loc142 = loc("reduce.288")
#loc143 = loc("broadcast.289")
#loc144 = loc("subtract.290")
#loc145 = loc("exponential.291")
#loc146 = loc("reduce.297")
#loc147 = loc("broadcast.298")
#loc148 = loc("divide.299")
#loc149 = loc("convert.300")
#loc150 = loc("reshape.302")
#loc151 = loc("broadcast.198")
#loc152 = loc("reshape.201")
#loc153 = loc("dot.303")
#loc154 = loc("reshape.307")
#loc155 = loc("reshape.187")
#loc156 = loc("reshape.189")
#loc157 = loc("transpose.190")
#loc158 = loc("dot.308")
#loc159 = loc("reshape.309")
#loc160 = loc("add.312")
#loc161 = loc("reshape.344")
#loc162 = loc("reshape.346")
#loc163 = loc("convert.347")
#loc164 = loc("broadcast.348")
#loc165 = loc("convert.313")
#loc166 = loc("power.315")
#loc167 = loc("reduce.322")
#loc168 = loc("multiply.331")
#loc169 = loc("reshape.332")
#loc170 = loc("add.336")
#loc171 = loc("rsqrt.337")
#loc172 = loc("reshape.338")
#loc173 = loc("broadcast.339")
#loc174 = loc("multiply.340")
#loc175 = loc("convert.341")
#loc176 = loc("convert.342")
#loc177 = loc("multiply.349")
#loc178 = loc("convert.350")
#loc179 = loc("reshape.360")
#loc180 = loc("reshape.356")
#loc181 = loc("reshape.358")
#loc182 = loc("transpose.359")
#loc183 = loc("dot.361")
#loc184 = loc("reshape.362")
#loc185 = loc("convert.365")
#loc186 = loc("logistic.363")
#loc187 = loc("convert.364")
#loc188 = loc("multiply.366")
#loc189 = loc("convert.367")
#loc190 = loc("convert.368")
#loc191 = loc("reshape.179")
#loc192 = loc("reshape.181")
#loc193 = loc("transpose.182")
#loc194 = loc("dot.352")
#loc195 = loc("reshape.353")
#loc196 = loc("convert.354")
#loc197 = loc("multiply.369")
#loc198 = loc("convert.370")
#loc199 = loc("reshape.371")
#loc200 = loc("reshape.174")
#loc201 = loc("reshape.176")
#loc202 = loc("transpose.177")
#loc203 = loc("dot.372")
#loc204 = loc("reshape.373")
#loc205 = loc("add.376")
#loc206 = loc("convert.377")
#loc207 = loc("power.379")
#loc208 = loc("reduce.386")
#loc209 = loc("multiply.395")
#loc210 = loc("reshape.396")
#loc211 = loc("add.400")
#loc212 = loc("rsqrt.401")
#loc213 = loc("reshape.402")
#loc214 = loc("broadcast.403")
#loc215 = loc("multiply.404")
#loc216 = loc("convert.405")
#loc217 = loc("convert.406")
#loc218 = loc("multiply.413")
#loc219 = loc("convert.414")
#loc220 = loc("reshape.418")
#loc221 = loc("reshape.166")
#loc222 = loc("reshape.168")
#loc223 = loc("transpose.169")
#loc224 = loc("dot.419")
#loc225 = loc("reshape.420")
2025-09-22 18:08:06.563 (  66.249s) [        A88F8000]      module_builder.cc:550   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2025-09-22 18:08:06.563 (  66.249s) [        A88F8000]      module_builder.cc:564   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2025-09-22 18:08:06.563 (  66.249s) [        A88F8000]      module_builder.cc:574   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2025-09-22 18:08:06.642 (  66.327s) [        A88F8000]      module_builder.cc:621      1| TTNN Module:
#dram = #ttnn.buffer_type<dram>
#loc = loc(unknown)
#loc12 = loc("p0.3")
#loc13 = loc("p1.13")
#loc14 = loc("p2.31")
#loc15 = loc("p3.37")
#loc16 = loc("p4.39")
#loc17 = loc("p5.44")
#loc18 = loc("p6.81")
#loc19 = loc("p7.118")
#loc20 = loc("p8.128")
#loc21 = loc("p9.137")
#loc22 = loc("p10.156")
#loc23 = loc("p11.165")
#loc24 = loc("p12.173")
#loc25 = loc("p13.178")
#loc26 = loc("p14.186")
#loc27 = loc("p15.210")
#loc28 = loc("p16.226")
#loc29 = loc("p17.241")
#loc30 = loc("p18.343")
#loc31 = loc("p19.355")
#loc32 = loc("p20.407")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout11 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout12 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout13 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout14 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout15 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout16 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout17 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout18 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout19 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout20 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout21 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout22 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout23 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout24 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout25 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout26 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 32 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout27 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 16 + d2, d3), <1x1>, memref<128x128xbf16, #system_memory>>
#ttnn_layout28 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128256xbf16, #system_memory>>
#ttnn_layout29 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x128256xbf16, #system_memory>>
#ttnn_layout30 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout31 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout32 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout33 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #system_memory>>
#ttnn_layout34 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #system_memory>>
#ttnn_layout35 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xui32, #dram>, <interleaved>>
#ttnn_layout36 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout37 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout38 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout39 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout40 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout41 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout42 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout43 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout44 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout45 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout46 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout47 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout48 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout49 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout50 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout51 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout52 = #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 128 + d1 * 32 + d2 * 32 + d3, d4), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout53 = #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 384 + d1 * 96 + d2 * 32 + d3, d4), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout54 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout55 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 128 + d1, d2), <1x1>, memref<48x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout56 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<12x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout57 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout58 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout59 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout60 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout61 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout62 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout63 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout64 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 16 + d2, d3), <1x1>, memref<64x128xbf16, #dram>, <interleaved>>
#ttnn_layout65 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 64 + d1 * 16 + d2, d3), <1x1>, memref<64x128xbf16, #system_memory>>
#ttnn_layout66 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128256xbf16, #dram>, <interleaved>>
#ttnn_layout67 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x128256xbf16, #dram>, <interleaved>>
module @SyncTensorsGraph.422 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.422 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]> loc(#loc)
      func.func @main_const_eval_0(%arg0: tensor<1024x3072xbf16, #ttnn_layout> loc(unknown)) -> tensor<512x3072xbf16, #ttnn_layout1> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn_layout>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn_layout1> loc(#loc)
        return %1 : tensor<512x3072xbf16, #ttnn_layout1> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_1(%arg0: tensor<3072x8192xbf16, #ttnn_layout2> loc(unknown)) -> tensor<3072x4096xbf16, #ttnn_layout3> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn_layout2>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn_layout3> loc(#loc)
        return %1 : tensor<3072x4096xbf16, #ttnn_layout3> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_2(%arg0: tensor<3072x3072xbf16, #ttnn_layout4> loc(unknown)) -> tensor<3072x1536xbf16, #ttnn_layout5> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn_layout5> loc(#loc)
        return %1 : tensor<3072x1536xbf16, #ttnn_layout5> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_3(%arg0: tensor<3072x3072xbf16, #ttnn_layout4> loc(unknown)) -> tensor<1536x3072xbf16, #ttnn_layout6> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn_layout4>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn_layout6> loc(#loc)
        return %1 : tensor<1536x3072xbf16, #ttnn_layout6> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_4(%arg0: tensor<bf16, #ttnn_layout7> loc(unknown)) -> tensor<1x1x1x1xf32, #ttnn_layout8> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<bf16, #ttnn_layout7>, !ttnn.device) -> tensor<bf16, #ttnn_layout7> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout7>) -> tensor<1x1x1x1xbf16, #ttnn_layout9> loc(#loc160)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<bf16, #ttnn_layout7>) -> () loc(#loc160)
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x1xbf16, #ttnn_layout9>) -> tensor<1x1x1x1xf32, #ttnn_layout8> loc(#loc2)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout9>) -> () loc(#loc2)
        return %3 : tensor<1x1x1x1xf32, #ttnn_layout8> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_5(%arg0: tensor<8192x3072xbf16, #ttnn_layout10> loc(unknown)) -> tensor<4096x3072xbf16, #ttnn_layout11> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn_layout10>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn_layout11> loc(#loc)
        return %1 : tensor<4096x3072xbf16, #ttnn_layout11> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_6(%arg0: tensor<128256x3072xbf16, #ttnn_layout12> loc(unknown)) -> tensor<128256x3072xbf16, #ttnn_layout12> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16, #ttnn_layout12>, !ttnn.device) -> tensor<128256x3072xbf16, #ttnn_layout12> loc(#loc)
        return %1 : tensor<128256x3072xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_7(%arg0: tensor<3072xbf16, #ttnn_layout13> loc(unknown)) -> tensor<1x3072xf32, #ttnn_layout14> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn_layout13>, !ttnn.device) -> tensor<3072xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn_layout13>) -> tensor<1x3072xbf16, #ttnn_layout15> loc(#loc161)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072xbf16, #ttnn_layout13>) -> () loc(#loc161)
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc4)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> () loc(#loc4)
        return %3 : tensor<1x3072xf32, #ttnn_layout14> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_8(%arg0: tensor<8192x3072xbf16, #ttnn_layout10> loc(unknown)) -> tensor<4096x3072xbf16, #ttnn_layout11> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn_layout10>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn_layout11> loc(#loc)
        return %1 : tensor<4096x3072xbf16, #ttnn_layout11> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_9(%arg0: tensor<128256x3072xbf16, #ttnn_layout12> loc(unknown)) -> tensor<128256x3072xbf16, #ttnn_layout12> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16, #ttnn_layout12>, !ttnn.device) -> tensor<128256x3072xbf16, #ttnn_layout12> loc(#loc)
        return %1 : tensor<128256x3072xbf16, #ttnn_layout12> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_10(%arg0: tensor<1024x3072xbf16, #ttnn_layout> loc(unknown)) -> tensor<512x3072xbf16, #ttnn_layout1> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn_layout>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn_layout1> loc(#loc)
        return %1 : tensor<512x3072xbf16, #ttnn_layout1> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_11(%arg0: tensor<f32, #ttnn_layout16> loc(unknown)) -> (tensor<1x1xf32, #ttnn_layout17>, tensor<1x1xf32, #ttnn_layout17>, tensor<1x1xf32, #ttnn_layout17>) attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn_layout16>, !ttnn.device) -> tensor<f32, #ttnn_layout16> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout16>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc175)
        %3 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout16>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc176)
        %4 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout16>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc177)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn_layout16>) -> () loc(#loc177)
        return %2, %3, %4 : tensor<1x1xf32, #ttnn_layout17>, tensor<1x1xf32, #ttnn_layout17>, tensor<1x1xf32, #ttnn_layout17> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_12(%arg0: tensor<3072xbf16, #ttnn_layout13> loc(unknown)) -> tensor<1x3072xf32, #ttnn_layout14> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn_layout13>, !ttnn.device) -> tensor<3072xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn_layout13>) -> tensor<1x3072xbf16, #ttnn_layout15> loc(#loc165)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072xbf16, #ttnn_layout13>) -> () loc(#loc165)
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc7)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> () loc(#loc7)
        return %3 : tensor<1x3072xf32, #ttnn_layout14> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_13() -> tensor<1x1x1x16xf32, #ttnn_layout8> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]> : tensor<1x16xsi32>}> : (!ttnn.device) -> tensor<1x16xsi32, #ttnn_layout18> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 16 : i32]}> : (tensor<1x16xsi32, #ttnn_layout18>) -> tensor<1x1x1x16xsi32, #ttnn_layout19> loc(#loc173)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x16xsi32, #ttnn_layout18>) -> () loc(#loc173)
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x16xsi32, #ttnn_layout19>) -> tensor<1x1x1x16xf32, #ttnn_layout8> loc(#loc136)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x1x16xsi32, #ttnn_layout19>) -> () loc(#loc136)
        return %3 : tensor<1x1x1x16xf32, #ttnn_layout8> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_14(%arg0: tensor<f32, #ttnn_layout16> loc(unknown)) -> tensor<12x1x16xf32, #ttnn_layout20> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<f32, #ttnn_layout16>, !ttnn.device) -> tensor<f32, #ttnn_layout16> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout16>) -> tensor<1x1x1x1xf32, #ttnn_layout8> loc(#loc9)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn_layout16>) -> () loc(#loc9)
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<1x12x1x16>}> : (tensor<1x1x1x1xf32, #ttnn_layout8>) -> tensor<1x12x1x16xf32, #ttnn_layout21> loc(#loc9)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn_layout8>) -> () loc(#loc9)
        %4 = "ttnn.reshape"(%3) <{shape = [12 : i32, 1 : i32, 16 : i32]}> : (tensor<1x12x1x16xf32, #ttnn_layout21>) -> tensor<12x1x16xf32, #ttnn_layout20> loc(#loc10)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x12x1x16xf32, #ttnn_layout21>) -> () loc(#loc10)
        return %4 : tensor<12x1x16xf32, #ttnn_layout20> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_15() -> tensor<1x1x1xf32, #ttnn_layout22> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 2.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn_layout16> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout16>) -> tensor<1x1x1xf32, #ttnn_layout22> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn_layout16>) -> () loc(#loc)
        return %2 : tensor<1x1x1xf32, #ttnn_layout22> loc(#loc)
      } loc(#loc)
      func.func @main_const_eval_16(%arg0: tensor<3072xbf16, #ttnn_layout13> loc(unknown)) -> tensor<1x3072xf32, #ttnn_layout14> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16, #ttnn_layout13>, !ttnn.device) -> tensor<3072xbf16, #ttnn_layout13> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn_layout13>) -> tensor<1x3072xbf16, #ttnn_layout15> loc(#loc167)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072xbf16, #ttnn_layout13>) -> () loc(#loc167)
        %3 = "ttnn.typecast"(%2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc11)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> () loc(#loc11)
        return %3 : tensor<1x3072xf32, #ttnn_layout14> loc(#loc)
      } loc(#loc)
      func.func @main(%arg0: tensor<1xsi32, #ttnn_layout23> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32, #ttnn_layout24> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.31"), %arg3: tensor<f32, #ttnn_layout16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"} loc("p3.37"), %arg4: tensor<1x1xsi32, #ttnn_layout18> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p4.39"), %arg5: tensor<128256x3072xbf16, #ttnn_layout12> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p5.44"), %arg6: tensor<3072xbf16, #ttnn_layout13> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p6.81"), %arg7: tensor<si32, #ttnn_layout25> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"} loc("p7.118"), %arg8: tensor<1x8x16x128xbf16, #ttnn_layout26> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p8.128"), %arg9: tensor<1024x3072xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p9.137"), %arg10: tensor<1x8x16x128xbf16, #ttnn_layout26> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p10.156"), %arg11: tensor<128256x3072xbf16, #ttnn_layout12> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"} loc("p11.165"), %arg12: tensor<3072x8192xbf16, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p12.173"), %arg13: tensor<8192x3072xbf16, #ttnn_layout10> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p13.178"), %arg14: tensor<3072x3072xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p14.186"), %arg15: tensor<bf16, #ttnn_layout7> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"} loc("p15.210"), %arg16: tensor<f32, #ttnn_layout16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"} loc("p16.226"), %arg17: tensor<3072x3072xbf16, #ttnn_layout4> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p17.241"), %arg18: tensor<3072xbf16, #ttnn_layout13> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p18.343"), %arg19: tensor<8192x3072xbf16, #ttnn_layout10> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p19.355"), %arg20: tensor<3072xbf16, #ttnn_layout13> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"} loc("p20.407")) -> (tensor<1x8x16x128xbf16, #ttnn_layout27> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x16x128xbf16, #ttnn_layout27> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x128256xbf16, #ttnn_layout28> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x1x128256xbf16, #ttnn_layout29> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, [%arg2]) : (tensor<1024x3072xbf16, #ttnn_layout>) -> tensor<512x3072xbf16, #ttnn_layout1> loc(#loc)
        "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<si32, #ttnn_layout25>) -> () loc(#loc)
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<1024x3072xbf16, #ttnn_layout>) -> () loc(#loc)
        %1 = ttcore.load_cached(@main_const_eval_1, [%arg12]) : (tensor<3072x8192xbf16, #ttnn_layout2>) -> tensor<3072x4096xbf16, #ttnn_layout3> loc(#loc)
        "ttnn.deallocate"(%arg12) <{force = false}> : (tensor<3072x8192xbf16, #ttnn_layout2>) -> () loc(#loc)
        %2 = ttcore.load_cached(@main_const_eval_2, [%arg14]) : (tensor<3072x3072xbf16, #ttnn_layout4>) -> tensor<3072x1536xbf16, #ttnn_layout5> loc(#loc)
        "ttnn.deallocate"(%arg14) <{force = false}> : (tensor<3072x3072xbf16, #ttnn_layout4>) -> () loc(#loc)
        %3 = ttcore.load_cached(@main_const_eval_3, [%arg17]) : (tensor<3072x3072xbf16, #ttnn_layout4>) -> tensor<1536x3072xbf16, #ttnn_layout6> loc(#loc)
        "ttnn.deallocate"(%arg17) <{force = false}> : (tensor<3072x3072xbf16, #ttnn_layout4>) -> () loc(#loc)
        %4 = ttcore.load_cached(@main_const_eval_4, [%arg15]) : (tensor<bf16, #ttnn_layout7>) -> tensor<1x1x1x1xf32, #ttnn_layout8> loc(#loc)
        "ttnn.deallocate"(%arg15) <{force = false}> : (tensor<bf16, #ttnn_layout7>) -> () loc(#loc)
        %5 = ttcore.load_cached(@main_const_eval_5, [%arg19]) : (tensor<8192x3072xbf16, #ttnn_layout10>) -> tensor<4096x3072xbf16, #ttnn_layout11> loc(#loc)
        "ttnn.deallocate"(%arg19) <{force = false}> : (tensor<8192x3072xbf16, #ttnn_layout10>) -> () loc(#loc)
        %6 = ttcore.load_cached(@main_const_eval_6, [%arg11]) : (tensor<128256x3072xbf16, #ttnn_layout12>) -> tensor<128256x3072xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg11) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout12>) -> () loc(#loc)
        %7 = ttcore.load_cached(@main_const_eval_7, [%arg18]) : (tensor<3072xbf16, #ttnn_layout13>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%arg18) <{force = false}> : (tensor<3072xbf16, #ttnn_layout13>) -> () loc(#loc)
        %8 = ttcore.load_cached(@main_const_eval_8, [%arg13]) : (tensor<8192x3072xbf16, #ttnn_layout10>) -> tensor<4096x3072xbf16, #ttnn_layout11> loc(#loc)
        "ttnn.deallocate"(%arg13) <{force = false}> : (tensor<8192x3072xbf16, #ttnn_layout10>) -> () loc(#loc)
        %9 = ttcore.load_cached(@main_const_eval_9, [%arg5]) : (tensor<128256x3072xbf16, #ttnn_layout12>) -> tensor<128256x3072xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%arg5) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout12>) -> () loc(#loc)
        %10 = ttcore.load_cached(@main_const_eval_10, [%arg9]) : (tensor<1024x3072xbf16, #ttnn_layout>) -> tensor<512x3072xbf16, #ttnn_layout1> loc(#loc)
        "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<1024x3072xbf16, #ttnn_layout>) -> () loc(#loc)
        %11:3 = ttcore.load_cached(@main_const_eval_11, [%arg3]) : (tensor<f32, #ttnn_layout16>) -> (tensor<1x1xf32, #ttnn_layout17>, tensor<1x1xf32, #ttnn_layout17>, tensor<1x1xf32, #ttnn_layout17>) loc(#loc)
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<f32, #ttnn_layout16>) -> () loc(#loc)
        %12 = ttcore.load_cached(@main_const_eval_12, [%arg20]) : (tensor<3072xbf16, #ttnn_layout13>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%arg20) <{force = false}> : (tensor<3072xbf16, #ttnn_layout13>) -> () loc(#loc)
        %13 = ttcore.load_cached(@main_const_eval_13, []) : () -> tensor<1x1x1x16xf32, #ttnn_layout8> loc(#loc)
        %14 = ttcore.load_cached(@main_const_eval_14, [%arg16]) : (tensor<f32, #ttnn_layout16>) -> tensor<12x1x16xf32, #ttnn_layout20> loc(#loc)
        "ttnn.deallocate"(%arg16) <{force = false}> : (tensor<f32, #ttnn_layout16>) -> () loc(#loc)
        %15 = ttcore.load_cached(@main_const_eval_15, []) : () -> tensor<1x1x1xf32, #ttnn_layout22> loc(#loc)
        %16 = ttcore.load_cached(@main_const_eval_16, [%arg6]) : (tensor<3072xbf16, #ttnn_layout13>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<3072xbf16, #ttnn_layout13>) -> () loc(#loc)
        %17 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %18 = "ttnn.full"(%17) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 3.25520843E-4 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<1x1>}> : (!ttnn.device) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc)
        %19 = "ttnn.mesh_shard"(%arg0, %17) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1xsi32, #ttnn_layout23>, !ttnn.device) -> tensor<1xsi32, #ttnn_layout23> loc(#loc)
        %20 = "ttnn.mesh_shard"(%arg1, %17) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32, #ttnn_layout24>, !ttnn.device) -> tensor<64xf32, #ttnn_layout24> loc(#loc)
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<64xf32, #ttnn_layout24>) -> () loc(#loc)
        %21 = "ttnn.mesh_shard"(%arg4, %17) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x1xsi32, #ttnn_layout18>, !ttnn.device) -> tensor<1x1xsi32, #ttnn_layout18> loc(#loc)
        "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<1x1xsi32, #ttnn_layout18>) -> () loc(#loc)
        %22 = "ttnn.mesh_shard"(%arg8, %17) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x16x128xbf16, #ttnn_layout26>, !ttnn.device) -> tensor<1x4x16x128xbf16, #ttnn_layout30> loc(#loc)
        "ttnn.deallocate"(%arg8) <{force = false}> : (tensor<1x8x16x128xbf16, #ttnn_layout26>) -> () loc(#loc)
        %23 = "ttnn.mesh_shard"(%arg10, %17) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x16x128xbf16, #ttnn_layout26>, !ttnn.device) -> tensor<1x4x16x128xbf16, #ttnn_layout30> loc(#loc)
        "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<1x8x16x128xbf16, #ttnn_layout26>) -> () loc(#loc)
        %24 = "ttnn.typecast"(%21) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x1xsi32, #ttnn_layout18>) -> tensor<1x1xui32, #ttnn_layout31> loc(#loc33)
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<1x1xsi32, #ttnn_layout18>) -> () loc(#loc33)
        %25 = "ttnn.reshape"(%24) <{shape = [1 : i32]}> : (tensor<1x1xui32, #ttnn_layout31>) -> tensor<1xui32, #ttnn_layout32> loc(#loc33)
        "ttnn.deallocate"(%24) <{force = false}> : (tensor<1x1xui32, #ttnn_layout31>) -> () loc(#loc33)
        %26 = "ttnn.from_device"(%25) : (tensor<1xui32, #ttnn_layout32>) -> tensor<1xui32, #ttnn_layout33> loc(#loc137)
        "ttnn.deallocate"(%25) <{force = false}> : (tensor<1xui32, #ttnn_layout32>) -> () loc(#loc137)
        %27 = "ttnn.to_layout"(%26) <{layout = #ttnn.layout<row_major>}> : (tensor<1xui32, #ttnn_layout33>) -> tensor<1xui32, #ttnn_layout34> loc(#loc137)
        "ttnn.deallocate"(%26) <{force = false}> : (tensor<1xui32, #ttnn_layout33>) -> () loc(#loc137)
        %28 = "ttnn.to_device"(%27, %17) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1xui32, #ttnn_layout34>, !ttnn.device) -> tensor<1xui32, #ttnn_layout35> loc(#loc137)
        "ttnn.deallocate"(%27) <{force = false}> : (tensor<1xui32, #ttnn_layout34>) -> () loc(#loc137)
        %29 = "ttnn.embedding"(%28, %9) : (tensor<1xui32, #ttnn_layout35>, tensor<128256x3072xbf16, #ttnn_layout12>) -> tensor<1x3072xbf16, #ttnn_layout15> loc(#loc34)
        "ttnn.deallocate"(%28) <{force = false}> : (tensor<1xui32, #ttnn_layout35>) -> () loc(#loc34)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout12>) -> () loc(#loc34)
        %30 = "ttnn.typecast"(%29) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc35)
        %31 = "ttnn.reshape"(%30) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn_layout14>) -> tensor<1x1x3072xf32, #ttnn_layout36> loc(#loc35)
        %32 = "ttnn.pow"(%31, %15) : (tensor<1x1x3072xf32, #ttnn_layout36>, tensor<1x1x1xf32, #ttnn_layout22>) -> tensor<1x1x3072xf32, #ttnn_layout36> loc(#loc36)
        "ttnn.deallocate"(%31) <{force = false}> : (tensor<1x1x3072xf32, #ttnn_layout36>) -> () loc(#loc36)
        %33 = "ttnn.sum"(%32) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn_layout36>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc37)
        "ttnn.deallocate"(%32) <{force = false}> : (tensor<1x1x3072xf32, #ttnn_layout36>) -> () loc(#loc37)
        %34 = "ttnn.multiply"(%33, %18) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn_layout17>, tensor<1x1xf32, #ttnn_layout17>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc38)
        "ttnn.deallocate"(%33) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc38)
        %35 = "ttnn.add"(%34, %11#0) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn_layout17>, tensor<1x1xf32, #ttnn_layout17>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc39)
        "ttnn.deallocate"(%34) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc39)
        "ttnn.deallocate"(%11#0) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc39)
        %36 = "ttnn.rsqrt"(%35) : (tensor<1x1xf32, #ttnn_layout17>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc40)
        "ttnn.deallocate"(%35) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc40)
        %37 = "ttnn.multiply"(%30, %36) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn_layout14>, tensor<1x1xf32, #ttnn_layout17>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc41)
        "ttnn.deallocate"(%36) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc41)
        "ttnn.deallocate"(%30) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout14>) -> () loc(#loc41)
        %38 = "ttnn.multiply"(%16, %37) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn_layout14>, tensor<1x3072xf32, #ttnn_layout14>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc42)
        "ttnn.deallocate"(%37) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout14>) -> () loc(#loc42)
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout14>) -> () loc(#loc42)
        %39 = "ttnn.typecast"(%38) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn_layout14>) -> tensor<1x3072xbf16, #ttnn_layout15> loc(#loc43)
        "ttnn.deallocate"(%38) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout14>) -> () loc(#loc43)
        %40 = "ttnn.matmul"(%39, %0) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn_layout15>, tensor<512x3072xbf16, #ttnn_layout1>) -> tensor<1x512xbf16, #ttnn_layout37> loc(#loc44)
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<512x3072xbf16, #ttnn_layout1>) -> () loc(#loc44)
        %41 = "ttnn.reshape"(%40) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn_layout37>) -> tensor<1x4x1x128xbf16, #ttnn_layout30> loc(#loc45)
        "ttnn.deallocate"(%40) <{force = false}> : (tensor<1x512xbf16, #ttnn_layout37>) -> () loc(#loc45)
        %42 = "ttnn.typecast"(%41) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn_layout30>) -> tensor<1x4x1x128xf32, #ttnn_layout38> loc(#loc46)
        %43 = "ttnn.reshape"(%20) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32, #ttnn_layout24>) -> tensor<1x64x1xf32, #ttnn_layout39> loc(#loc47)
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<64xf32, #ttnn_layout24>) -> () loc(#loc47)
        %44 = "ttnn.typecast"(%19) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1xsi32, #ttnn_layout23>) -> tensor<1xf32, #ttnn_layout40> loc(#loc48)
        %45 = "ttnn.reshape"(%44) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1xf32, #ttnn_layout40>) -> tensor<1x1x1xf32, #ttnn_layout22> loc(#loc48)
        "ttnn.deallocate"(%44) <{force = false}> : (tensor<1xf32, #ttnn_layout40>) -> () loc(#loc48)
        %46 = "ttnn.matmul"(%43, %45) <{transpose_a = false, transpose_b = false}> : (tensor<1x64x1xf32, #ttnn_layout39>, tensor<1x1x1xf32, #ttnn_layout22>) -> tensor<1x64x1xf32, #ttnn_layout39> loc(#loc49)
        "ttnn.deallocate"(%45) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout22>) -> () loc(#loc49)
        "ttnn.deallocate"(%43) <{force = false}> : (tensor<1x64x1xf32, #ttnn_layout39>) -> () loc(#loc49)
        %47 = "ttnn.reshape"(%46) <{shape = [1 : i32, 1 : i32, 1 : i32, 64 : i32]}> : (tensor<1x64x1xf32, #ttnn_layout39>) -> tensor<1x1x1x64xf32, #ttnn_layout41> loc(#loc50)
        %48 = "ttnn.reshape"(%46) <{shape = [1 : i32, 1 : i32, 1 : i32, 64 : i32]}> : (tensor<1x64x1xf32, #ttnn_layout39>) -> tensor<1x1x1x64xf32, #ttnn_layout41> loc(#loc50)
        "ttnn.deallocate"(%46) <{force = false}> : (tensor<1x64x1xf32, #ttnn_layout39>) -> () loc(#loc50)
        %49 = "ttnn.concat"(%47, %48) <{dim = 3 : si32}> : (tensor<1x1x1x64xf32, #ttnn_layout41>, tensor<1x1x1x64xf32, #ttnn_layout41>) -> tensor<1x1x1x128xf32, #ttnn_layout42> loc(#loc50)
        "ttnn.deallocate"(%48) <{force = false}> : (tensor<1x1x1x64xf32, #ttnn_layout41>) -> () loc(#loc50)
        "ttnn.deallocate"(%47) <{force = false}> : (tensor<1x1x1x64xf32, #ttnn_layout41>) -> () loc(#loc50)
        %50 = "ttnn.cos"(%49) : (tensor<1x1x1x128xf32, #ttnn_layout42>) -> tensor<1x1x1x128xf32, #ttnn_layout42> loc(#loc51)
        %51 = "ttnn.multiply"(%42, %50) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn_layout38>, tensor<1x1x1x128xf32, #ttnn_layout42>) -> tensor<1x4x1x128xf32, #ttnn_layout38> loc(#loc52)
        "ttnn.deallocate"(%42) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn_layout38>) -> () loc(#loc52)
        %52 = "ttnn.typecast"(%51) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn_layout38>) -> tensor<1x4x1x128xbf16, #ttnn_layout30> loc(#loc53)
        "ttnn.deallocate"(%51) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn_layout38>) -> () loc(#loc53)
        %53 = "ttnn.slice_static"(%41) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn_layout30>) -> tensor<1x4x1x64xbf16, #ttnn_layout43> loc(#loc54)
        %54 = "ttnn.neg"(%53) : (tensor<1x4x1x64xbf16, #ttnn_layout43>) -> tensor<1x4x1x64xbf16, #ttnn_layout43> loc(#loc55)
        "ttnn.deallocate"(%53) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn_layout43>) -> () loc(#loc55)
        %55 = "ttnn.slice_static"(%41) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn_layout30>) -> tensor<1x4x1x64xbf16, #ttnn_layout43> loc(#loc56)
        "ttnn.deallocate"(%41) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn_layout30>) -> () loc(#loc56)
        %56 = "ttnn.concat"(%54, %55) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16, #ttnn_layout43>, tensor<1x4x1x64xbf16, #ttnn_layout43>) -> tensor<1x4x1x128xbf16, #ttnn_layout30> loc(#loc57)
        "ttnn.deallocate"(%55) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn_layout43>) -> () loc(#loc57)
        "ttnn.deallocate"(%54) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn_layout43>) -> () loc(#loc57)
        %57 = "ttnn.typecast"(%56) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xbf16, #ttnn_layout30>) -> tensor<1x4x1x128xf32, #ttnn_layout38> loc(#loc58)
        "ttnn.deallocate"(%56) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn_layout30>) -> () loc(#loc58)
        %58 = "ttnn.sin"(%49) : (tensor<1x1x1x128xf32, #ttnn_layout42>) -> tensor<1x1x1x128xf32, #ttnn_layout42> loc(#loc59)
        "ttnn.deallocate"(%49) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn_layout42>) -> () loc(#loc59)
        %59 = "ttnn.multiply"(%57, %58) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4x1x128xf32, #ttnn_layout38>, tensor<1x1x1x128xf32, #ttnn_layout42>) -> tensor<1x4x1x128xf32, #ttnn_layout38> loc(#loc60)
        "ttnn.deallocate"(%57) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn_layout38>) -> () loc(#loc60)
        %60 = "ttnn.typecast"(%59) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xf32, #ttnn_layout38>) -> tensor<1x4x1x128xbf16, #ttnn_layout30> loc(#loc61)
        "ttnn.deallocate"(%59) <{force = false}> : (tensor<1x4x1x128xf32, #ttnn_layout38>) -> () loc(#loc61)
        %61 = "ttnn.add"(%52, %60) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x1x128xbf16, #ttnn_layout30>, tensor<1x4x1x128xbf16, #ttnn_layout30>) -> tensor<1x4x1x128xbf16, #ttnn_layout30> loc(#loc62)
        "ttnn.deallocate"(%60) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn_layout30>) -> () loc(#loc62)
        "ttnn.deallocate"(%52) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn_layout30>) -> () loc(#loc62)
        %62 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn_layout23>) -> tensor<1xui32, #ttnn_layout32> loc(#loc138)
        "ttnn.update_cache"(%22, %61, %62) <{batch_offset = 0 : i32}> : (tensor<1x4x16x128xbf16, #ttnn_layout30>, tensor<1x4x1x128xbf16, #ttnn_layout30>, tensor<1xui32, #ttnn_layout32>) -> () loc(#loc63)
        "ttnn.deallocate"(%62) <{force = false}> : (tensor<1xui32, #ttnn_layout32>) -> () loc(#loc63)
        "ttnn.deallocate"(%61) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn_layout30>) -> () loc(#loc63)
        %63 = "ttnn.matmul"(%39, %10) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn_layout15>, tensor<512x3072xbf16, #ttnn_layout1>) -> tensor<1x512xbf16, #ttnn_layout37> loc(#loc64)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<512x3072xbf16, #ttnn_layout1>) -> () loc(#loc64)
        %64 = "ttnn.reshape"(%63) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn_layout37>) -> tensor<1x4x1x128xbf16, #ttnn_layout30> loc(#loc65)
        "ttnn.deallocate"(%63) <{force = false}> : (tensor<1x512xbf16, #ttnn_layout37>) -> () loc(#loc65)
        %65 = "ttnn.typecast"(%arg0) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1xsi32, #ttnn_layout23>) -> tensor<1xui32, #ttnn_layout32> loc(#loc139)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<1xsi32, #ttnn_layout23>) -> () loc(#loc139)
        "ttnn.update_cache"(%23, %64, %65) <{batch_offset = 0 : i32}> : (tensor<1x4x16x128xbf16, #ttnn_layout30>, tensor<1x4x1x128xbf16, #ttnn_layout30>, tensor<1xui32, #ttnn_layout32>) -> () loc(#loc66)
        "ttnn.deallocate"(%65) <{force = false}> : (tensor<1xui32, #ttnn_layout32>) -> () loc(#loc66)
        "ttnn.deallocate"(%64) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn_layout30>) -> () loc(#loc66)
        %66 = "ttnn.matmul"(%39, %3) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn_layout15>, tensor<1536x3072xbf16, #ttnn_layout6>) -> tensor<1x1536xbf16, #ttnn_layout44> loc(#loc67)
        "ttnn.deallocate"(%39) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> () loc(#loc67)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1536x3072xbf16, #ttnn_layout6>) -> () loc(#loc67)
        %67 = "ttnn.reshape"(%66) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16, #ttnn_layout44>) -> tensor<1x12x1x128xbf16, #ttnn_layout45> loc(#loc68)
        %68 = "ttnn.typecast"(%66) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1536xbf16, #ttnn_layout44>) -> tensor<1x1536xf32, #ttnn_layout46> loc(#loc69)
        "ttnn.deallocate"(%66) <{force = false}> : (tensor<1x1536xbf16, #ttnn_layout44>) -> () loc(#loc69)
        %69 = "ttnn.reshape"(%68) <{shape = [12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xf32, #ttnn_layout46>) -> tensor<12x1x128xf32, #ttnn_layout47> loc(#loc69)
        "ttnn.deallocate"(%68) <{force = false}> : (tensor<1x1536xf32, #ttnn_layout46>) -> () loc(#loc69)
        %70 = "ttnn.reshape"(%50) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x1x128xf32, #ttnn_layout42>) -> tensor<1x1x128xf32, #ttnn_layout48> loc(#loc168)
        "ttnn.deallocate"(%50) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn_layout42>) -> () loc(#loc168)
        %71 = "ttnn.multiply"(%69, %70) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn_layout47>, tensor<1x1x128xf32, #ttnn_layout48>) -> tensor<12x1x128xf32, #ttnn_layout47> loc(#loc71)
        "ttnn.deallocate"(%70) <{force = false}> : (tensor<1x1x128xf32, #ttnn_layout48>) -> () loc(#loc71)
        "ttnn.deallocate"(%69) <{force = false}> : (tensor<12x1x128xf32, #ttnn_layout47>) -> () loc(#loc71)
        %72 = "ttnn.typecast"(%71) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn_layout47>) -> tensor<12x1x128xbf16, #ttnn_layout49> loc(#loc72)
        "ttnn.deallocate"(%71) <{force = false}> : (tensor<12x1x128xf32, #ttnn_layout47>) -> () loc(#loc72)
        %73 = "ttnn.slice_static"(%67) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn_layout45>) -> tensor<1x12x1x64xbf16, #ttnn_layout50> loc(#loc73)
        %74 = "ttnn.neg"(%73) : (tensor<1x12x1x64xbf16, #ttnn_layout50>) -> tensor<1x12x1x64xbf16, #ttnn_layout50> loc(#loc74)
        "ttnn.deallocate"(%73) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn_layout50>) -> () loc(#loc74)
        %75 = "ttnn.reshape"(%74) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn_layout50>) -> tensor<12x1x64xbf16, #ttnn_layout51> loc(#loc74)
        "ttnn.deallocate"(%74) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn_layout50>) -> () loc(#loc74)
        %76 = "ttnn.slice_static"(%67) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn_layout45>) -> tensor<1x12x1x64xbf16, #ttnn_layout50> loc(#loc75)
        "ttnn.deallocate"(%67) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn_layout45>) -> () loc(#loc75)
        %77 = "ttnn.reshape"(%76) <{shape = [12 : i32, 1 : i32, 64 : i32]}> : (tensor<1x12x1x64xbf16, #ttnn_layout50>) -> tensor<12x1x64xbf16, #ttnn_layout51> loc(#loc76)
        "ttnn.deallocate"(%76) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn_layout50>) -> () loc(#loc76)
        %78 = "ttnn.concat"(%75, %77) <{dim = 2 : si32}> : (tensor<12x1x64xbf16, #ttnn_layout51>, tensor<12x1x64xbf16, #ttnn_layout51>) -> tensor<12x1x128xbf16, #ttnn_layout49> loc(#loc76)
        "ttnn.deallocate"(%77) <{force = false}> : (tensor<12x1x64xbf16, #ttnn_layout51>) -> () loc(#loc76)
        "ttnn.deallocate"(%75) <{force = false}> : (tensor<12x1x64xbf16, #ttnn_layout51>) -> () loc(#loc76)
        %79 = "ttnn.typecast"(%78) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xbf16, #ttnn_layout49>) -> tensor<12x1x128xf32, #ttnn_layout47> loc(#loc77)
        "ttnn.deallocate"(%78) <{force = false}> : (tensor<12x1x128xbf16, #ttnn_layout49>) -> () loc(#loc77)
        %80 = "ttnn.reshape"(%58) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x1x128xf32, #ttnn_layout42>) -> tensor<1x1x128xf32, #ttnn_layout48> loc(#loc169)
        "ttnn.deallocate"(%58) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn_layout42>) -> () loc(#loc169)
        %81 = "ttnn.multiply"(%79, %80) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x128xf32, #ttnn_layout47>, tensor<1x1x128xf32, #ttnn_layout48>) -> tensor<12x1x128xf32, #ttnn_layout47> loc(#loc78)
        "ttnn.deallocate"(%80) <{force = false}> : (tensor<1x1x128xf32, #ttnn_layout48>) -> () loc(#loc78)
        "ttnn.deallocate"(%79) <{force = false}> : (tensor<12x1x128xf32, #ttnn_layout47>) -> () loc(#loc78)
        %82 = "ttnn.typecast"(%81) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xf32, #ttnn_layout47>) -> tensor<12x1x128xbf16, #ttnn_layout49> loc(#loc79)
        "ttnn.deallocate"(%81) <{force = false}> : (tensor<12x1x128xf32, #ttnn_layout47>) -> () loc(#loc79)
        %83 = "ttnn.add"(%72, %82) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x128xbf16, #ttnn_layout49>, tensor<12x1x128xbf16, #ttnn_layout49>) -> tensor<12x1x128xbf16, #ttnn_layout49> loc(#loc80)
        "ttnn.deallocate"(%82) <{force = false}> : (tensor<12x1x128xbf16, #ttnn_layout49>) -> () loc(#loc80)
        "ttnn.deallocate"(%72) <{force = false}> : (tensor<12x1x128xbf16, #ttnn_layout49>) -> () loc(#loc80)
        %84 = "ttnn.reshape"(%22) <{shape = [1 : i32, 4 : i32, 1 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x16x128xbf16, #ttnn_layout30>) -> tensor<1x4x1x16x128xbf16, #ttnn_layout52> loc(#loc81)
        %85 = "ttnn.repeat"(%84) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x16x128xbf16, #ttnn_layout52>) -> tensor<1x4x3x16x128xbf16, #ttnn_layout53> loc(#loc81)
        "ttnn.deallocate"(%84) <{force = false}> : (tensor<1x4x1x16x128xbf16, #ttnn_layout52>) -> () loc(#loc81)
        %86 = "ttnn.reshape"(%85) <{shape = [1 : i32, 12 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x3x16x128xbf16, #ttnn_layout53>) -> tensor<1x12x16x128xbf16, #ttnn_layout45> loc(#loc82)
        "ttnn.deallocate"(%85) <{force = false}> : (tensor<1x4x3x16x128xbf16, #ttnn_layout53>) -> () loc(#loc82)
        %87 = "ttnn.permute"(%86) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x16x128xbf16, #ttnn_layout45>) -> tensor<1x12x128x16xbf16, #ttnn_layout54> loc(#loc83)
        "ttnn.deallocate"(%86) <{force = false}> : (tensor<1x12x16x128xbf16, #ttnn_layout45>) -> () loc(#loc83)
        %88 = "ttnn.reshape"(%87) <{shape = [12 : i32, 128 : i32, 16 : i32]}> : (tensor<1x12x128x16xbf16, #ttnn_layout54>) -> tensor<12x128x16xbf16, #ttnn_layout55> loc(#loc84)
        "ttnn.deallocate"(%87) <{force = false}> : (tensor<1x12x128x16xbf16, #ttnn_layout54>) -> () loc(#loc84)
        %89 = "ttnn.matmul"(%83, %88) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x128xbf16, #ttnn_layout49>, tensor<12x128x16xbf16, #ttnn_layout55>) -> tensor<12x1x16xbf16, #ttnn_layout56> loc(#loc85)
        "ttnn.deallocate"(%88) <{force = false}> : (tensor<12x128x16xbf16, #ttnn_layout55>) -> () loc(#loc85)
        "ttnn.deallocate"(%83) <{force = false}> : (tensor<12x1x128xbf16, #ttnn_layout49>) -> () loc(#loc85)
        %90 = "ttnn.typecast"(%89) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x16xbf16, #ttnn_layout56>) -> tensor<12x1x16xf32, #ttnn_layout20> loc(#loc10)
        "ttnn.deallocate"(%89) <{force = false}> : (tensor<12x1x16xbf16, #ttnn_layout56>) -> () loc(#loc10)
        %91 = "ttnn.multiply"(%90, %14) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<12x1x16xf32, #ttnn_layout20>, tensor<12x1x16xf32, #ttnn_layout20>) -> tensor<12x1x16xf32, #ttnn_layout20> loc(#loc86)
        "ttnn.deallocate"(%90) <{force = false}> : (tensor<12x1x16xf32, #ttnn_layout20>) -> () loc(#loc86)
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<12x1x16xf32, #ttnn_layout20>) -> () loc(#loc86)
        %92 = "ttnn.typecast"(%91) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<12x1x16xf32, #ttnn_layout20>) -> tensor<12x1x16xbf16, #ttnn_layout56> loc(#loc87)
        "ttnn.deallocate"(%91) <{force = false}> : (tensor<12x1x16xf32, #ttnn_layout20>) -> () loc(#loc87)
        %93 = "ttnn.reshape"(%92) <{shape = [1 : i32, 12 : i32, 1 : i32, 16 : i32]}> : (tensor<12x1x16xbf16, #ttnn_layout56>) -> tensor<1x12x1x16xbf16, #ttnn_layout57> loc(#loc87)
        "ttnn.deallocate"(%92) <{force = false}> : (tensor<12x1x16xbf16, #ttnn_layout56>) -> () loc(#loc87)
        %94 = "ttnn.reshape"(%19) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1xsi32, #ttnn_layout23>) -> tensor<1x1x1x1xsi32, #ttnn_layout19> loc(#loc174)
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<1xsi32, #ttnn_layout23>) -> () loc(#loc174)
        %95 = "ttnn.typecast"(%94) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x1xsi32, #ttnn_layout19>) -> tensor<1x1x1x1xf32, #ttnn_layout8> loc(#loc136)
        "ttnn.deallocate"(%94) <{force = false}> : (tensor<1x1x1x1xsi32, #ttnn_layout19>) -> () loc(#loc136)
        %96 = "ttnn.gt"(%13, %95) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x16xf32, #ttnn_layout8>, tensor<1x1x1x1xf32, #ttnn_layout8>) -> tensor<1x1x1x16xf32, #ttnn_layout8> loc(#loc8)
        "ttnn.deallocate"(%95) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn_layout8>) -> () loc(#loc8)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<1x1x1x16xf32, #ttnn_layout8>) -> () loc(#loc8)
        %97 = "ttnn.typecast"(%96) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x16xf32, #ttnn_layout8>) -> tensor<1x1x1x16xbf16, #ttnn_layout9> loc(#loc136)
        "ttnn.deallocate"(%96) <{force = false}> : (tensor<1x1x1x16xf32, #ttnn_layout8>) -> () loc(#loc136)
        %98 = "ttnn.typecast"(%97) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x16xbf16, #ttnn_layout9>) -> tensor<1x1x1x16xf32, #ttnn_layout8> loc(#loc88)
        "ttnn.deallocate"(%97) <{force = false}> : (tensor<1x1x1x16xbf16, #ttnn_layout9>) -> () loc(#loc88)
        %99 = "ttnn.multiply"(%4, %98) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1x1xf32, #ttnn_layout8>, tensor<1x1x1x16xf32, #ttnn_layout8>) -> tensor<1x1x1x16xf32, #ttnn_layout8> loc(#loc89)
        "ttnn.deallocate"(%98) <{force = false}> : (tensor<1x1x1x16xf32, #ttnn_layout8>) -> () loc(#loc89)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1x1x1x1xf32, #ttnn_layout8>) -> () loc(#loc89)
        %100 = "ttnn.typecast"(%99) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x16xf32, #ttnn_layout8>) -> tensor<1x1x1x16xbf16, #ttnn_layout9> loc(#loc90)
        "ttnn.deallocate"(%99) <{force = false}> : (tensor<1x1x1x16xf32, #ttnn_layout8>) -> () loc(#loc90)
        %101 = "ttnn.add"(%93, %100) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x16xbf16, #ttnn_layout57>, tensor<1x1x1x16xbf16, #ttnn_layout9>) -> tensor<1x12x1x16xbf16, #ttnn_layout57> loc(#loc91)
        "ttnn.deallocate"(%100) <{force = false}> : (tensor<1x1x1x16xbf16, #ttnn_layout9>) -> () loc(#loc91)
        "ttnn.deallocate"(%93) <{force = false}> : (tensor<1x12x1x16xbf16, #ttnn_layout57>) -> () loc(#loc91)
        %102 = "ttnn.typecast"(%101) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x16xbf16, #ttnn_layout57>) -> tensor<1x12x1x16xf32, #ttnn_layout21> loc(#loc92)
        "ttnn.deallocate"(%101) <{force = false}> : (tensor<1x12x1x16xbf16, #ttnn_layout57>) -> () loc(#loc92)
        %103 = "ttnn.softmax"(%102) <{dimension = 3 : si32, numericStable = true}> : (tensor<1x12x1x16xf32, #ttnn_layout21>) -> tensor<1x12x1x16xf32, #ttnn_layout21> loc(#loc93)
        "ttnn.deallocate"(%102) <{force = false}> : (tensor<1x12x1x16xf32, #ttnn_layout21>) -> () loc(#loc93)
        %104 = "ttnn.typecast"(%103) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x16xf32, #ttnn_layout21>) -> tensor<1x12x1x16xbf16, #ttnn_layout57> loc(#loc94)
        "ttnn.deallocate"(%103) <{force = false}> : (tensor<1x12x1x16xf32, #ttnn_layout21>) -> () loc(#loc94)
        %105 = "ttnn.reshape"(%104) <{shape = [12 : i32, 1 : i32, 16 : i32]}> : (tensor<1x12x1x16xbf16, #ttnn_layout57>) -> tensor<12x1x16xbf16, #ttnn_layout56> loc(#loc94)
        "ttnn.deallocate"(%104) <{force = false}> : (tensor<1x12x1x16xbf16, #ttnn_layout57>) -> () loc(#loc94)
        %106 = "ttnn.reshape"(%23) <{shape = [1 : i32, 4 : i32, 1 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x16x128xbf16, #ttnn_layout30>) -> tensor<1x4x1x16x128xbf16, #ttnn_layout52> loc(#loc95)
        %107 = "ttnn.repeat"(%106) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x16x128xbf16, #ttnn_layout52>) -> tensor<1x4x3x16x128xbf16, #ttnn_layout53> loc(#loc95)
        "ttnn.deallocate"(%106) <{force = false}> : (tensor<1x4x1x16x128xbf16, #ttnn_layout52>) -> () loc(#loc95)
        %108 = "ttnn.reshape"(%107) <{shape = [12 : i32, 16 : i32, 128 : i32]}> : (tensor<1x4x3x16x128xbf16, #ttnn_layout53>) -> tensor<12x16x128xbf16, #ttnn_layout49> loc(#loc96)
        "ttnn.deallocate"(%107) <{force = false}> : (tensor<1x4x3x16x128xbf16, #ttnn_layout53>) -> () loc(#loc96)
        %109 = "ttnn.matmul"(%105, %108) <{transpose_a = false, transpose_b = false}> : (tensor<12x1x16xbf16, #ttnn_layout56>, tensor<12x16x128xbf16, #ttnn_layout49>) -> tensor<12x1x128xbf16, #ttnn_layout49> loc(#loc97)
        "ttnn.deallocate"(%108) <{force = false}> : (tensor<12x16x128xbf16, #ttnn_layout49>) -> () loc(#loc97)
        "ttnn.deallocate"(%105) <{force = false}> : (tensor<12x1x16xbf16, #ttnn_layout56>) -> () loc(#loc97)
        %110 = "ttnn.reshape"(%109) <{shape = [1 : i32, 1536 : i32]}> : (tensor<12x1x128xbf16, #ttnn_layout49>) -> tensor<1x1536xbf16, #ttnn_layout44> loc(#loc98)
        "ttnn.deallocate"(%109) <{force = false}> : (tensor<12x1x128xbf16, #ttnn_layout49>) -> () loc(#loc98)
        %111 = "ttnn.matmul"(%110, %2) <{transpose_a = false, transpose_b = true}> : (tensor<1x1536xbf16, #ttnn_layout44>, tensor<3072x1536xbf16, #ttnn_layout5>) -> tensor<1x3072xbf16, #ttnn_layout15> loc(#loc99)
        "ttnn.deallocate"(%110) <{force = false}> : (tensor<1x1536xbf16, #ttnn_layout44>) -> () loc(#loc99)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<3072x1536xbf16, #ttnn_layout5>) -> () loc(#loc99)
        %112 = "ttnn.reshape"(%111) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> tensor<1x1x1x3072xbf16, #ttnn_layout58> loc(#loc156)
        "ttnn.deallocate"(%111) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> () loc(#loc156)
        %113 = "ttnn.reduce_scatter"(%112, %17) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn_layout58>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn_layout59> loc(#loc157)
        "ttnn.deallocate"(%112) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn_layout58>) -> () loc(#loc157)
        %114 = "ttnn.all_gather"(%113, %17) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn_layout59>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn_layout58> loc(#loc143)
        "ttnn.deallocate"(%113) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn_layout59>) -> () loc(#loc143)
        %115 = "ttnn.reshape"(%114) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn_layout58>) -> tensor<1x3072xbf16, #ttnn_layout15> loc(#loc99)
        "ttnn.deallocate"(%114) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn_layout58>) -> () loc(#loc99)
        %116 = "ttnn.add"(%29, %115) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn_layout15>, tensor<1x3072xbf16, #ttnn_layout15>) -> tensor<1x3072xbf16, #ttnn_layout15> loc(#loc100)
        "ttnn.deallocate"(%115) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> () loc(#loc100)
        "ttnn.deallocate"(%29) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> () loc(#loc100)
        %117 = "ttnn.typecast"(%116) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc101)
        %118 = "ttnn.reshape"(%117) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn_layout14>) -> tensor<1x1x3072xf32, #ttnn_layout36> loc(#loc101)
        %119 = "ttnn.pow"(%118, %15) : (tensor<1x1x3072xf32, #ttnn_layout36>, tensor<1x1x1xf32, #ttnn_layout22>) -> tensor<1x1x3072xf32, #ttnn_layout36> loc(#loc102)
        "ttnn.deallocate"(%118) <{force = false}> : (tensor<1x1x3072xf32, #ttnn_layout36>) -> () loc(#loc102)
        %120 = "ttnn.sum"(%119) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn_layout36>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc103)
        "ttnn.deallocate"(%119) <{force = false}> : (tensor<1x1x3072xf32, #ttnn_layout36>) -> () loc(#loc103)
        %121 = "ttnn.multiply"(%120, %18) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn_layout17>, tensor<1x1xf32, #ttnn_layout17>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc104)
        "ttnn.deallocate"(%120) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc104)
        %122 = "ttnn.add"(%121, %11#1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn_layout17>, tensor<1x1xf32, #ttnn_layout17>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc105)
        "ttnn.deallocate"(%121) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc105)
        "ttnn.deallocate"(%11#1) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc105)
        %123 = "ttnn.rsqrt"(%122) : (tensor<1x1xf32, #ttnn_layout17>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc106)
        "ttnn.deallocate"(%122) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc106)
        %124 = "ttnn.multiply"(%117, %123) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn_layout14>, tensor<1x1xf32, #ttnn_layout17>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc107)
        "ttnn.deallocate"(%123) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc107)
        "ttnn.deallocate"(%117) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout14>) -> () loc(#loc107)
        %125 = "ttnn.multiply"(%7, %124) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn_layout14>, tensor<1x3072xf32, #ttnn_layout14>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc108)
        "ttnn.deallocate"(%124) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout14>) -> () loc(#loc108)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout14>) -> () loc(#loc108)
        %126 = "ttnn.typecast"(%125) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn_layout14>) -> tensor<1x3072xbf16, #ttnn_layout15> loc(#loc109)
        "ttnn.deallocate"(%125) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout14>) -> () loc(#loc109)
        %127 = "ttnn.matmul"(%126, %5) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn_layout15>, tensor<4096x3072xbf16, #ttnn_layout11>) -> tensor<1x4096xbf16, #ttnn_layout60> loc(#loc110)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<4096x3072xbf16, #ttnn_layout11>) -> () loc(#loc110)
        %128 = "ttnn.typecast"(%127) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn_layout60>) -> tensor<1x4096xf32, #ttnn_layout61> loc(#loc111)
        %129 = "ttnn.sigmoid"(%127) : (tensor<1x4096xbf16, #ttnn_layout60>) -> tensor<1x4096xbf16, #ttnn_layout60> loc(#loc112)
        "ttnn.deallocate"(%127) <{force = false}> : (tensor<1x4096xbf16, #ttnn_layout60>) -> () loc(#loc112)
        %130 = "ttnn.typecast"(%129) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn_layout60>) -> tensor<1x4096xf32, #ttnn_layout61> loc(#loc113)
        "ttnn.deallocate"(%129) <{force = false}> : (tensor<1x4096xbf16, #ttnn_layout60>) -> () loc(#loc113)
        %131 = "ttnn.multiply"(%128, %130) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn_layout61>, tensor<1x4096xf32, #ttnn_layout61>) -> tensor<1x4096xf32, #ttnn_layout61> loc(#loc114)
        "ttnn.deallocate"(%130) <{force = false}> : (tensor<1x4096xf32, #ttnn_layout61>) -> () loc(#loc114)
        "ttnn.deallocate"(%128) <{force = false}> : (tensor<1x4096xf32, #ttnn_layout61>) -> () loc(#loc114)
        %132 = "ttnn.matmul"(%126, %8) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn_layout15>, tensor<4096x3072xbf16, #ttnn_layout11>) -> tensor<1x4096xbf16, #ttnn_layout60> loc(#loc115)
        "ttnn.deallocate"(%126) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> () loc(#loc115)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<4096x3072xbf16, #ttnn_layout11>) -> () loc(#loc115)
        %133 = "ttnn.typecast"(%132) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xbf16, #ttnn_layout60>) -> tensor<1x4096xf32, #ttnn_layout61> loc(#loc116)
        "ttnn.deallocate"(%132) <{force = false}> : (tensor<1x4096xbf16, #ttnn_layout60>) -> () loc(#loc116)
        %134 = "ttnn.multiply"(%131, %133) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x4096xf32, #ttnn_layout61>, tensor<1x4096xf32, #ttnn_layout61>) -> tensor<1x4096xf32, #ttnn_layout61> loc(#loc117)
        "ttnn.deallocate"(%133) <{force = false}> : (tensor<1x4096xf32, #ttnn_layout61>) -> () loc(#loc117)
        "ttnn.deallocate"(%131) <{force = false}> : (tensor<1x4096xf32, #ttnn_layout61>) -> () loc(#loc117)
        %135 = "ttnn.typecast"(%134) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4096xf32, #ttnn_layout61>) -> tensor<1x4096xbf16, #ttnn_layout60> loc(#loc118)
        "ttnn.deallocate"(%134) <{force = false}> : (tensor<1x4096xf32, #ttnn_layout61>) -> () loc(#loc118)
        %136 = "ttnn.matmul"(%135, %1) <{transpose_a = false, transpose_b = true}> : (tensor<1x4096xbf16, #ttnn_layout60>, tensor<3072x4096xbf16, #ttnn_layout3>) -> tensor<1x3072xbf16, #ttnn_layout15> loc(#loc119)
        "ttnn.deallocate"(%135) <{force = false}> : (tensor<1x4096xbf16, #ttnn_layout60>) -> () loc(#loc119)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072x4096xbf16, #ttnn_layout3>) -> () loc(#loc119)
        %137 = "ttnn.reshape"(%136) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> tensor<1x1x1x3072xbf16, #ttnn_layout58> loc(#loc158)
        "ttnn.deallocate"(%136) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> () loc(#loc158)
        %138 = "ttnn.reduce_scatter"(%137, %17) <{cluster_axis = 1 : ui32, num_links = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn_layout58>, !ttnn.device) -> tensor<1x1x1x1536xbf16, #ttnn_layout59> loc(#loc159)
        "ttnn.deallocate"(%137) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn_layout58>) -> () loc(#loc159)
        %139 = "ttnn.all_gather"(%138, %17) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32, num_links = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn_layout59>, !ttnn.device) -> tensor<1x1x1x3072xbf16, #ttnn_layout58> loc(#loc145)
        "ttnn.deallocate"(%138) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn_layout59>) -> () loc(#loc145)
        %140 = "ttnn.reshape"(%139) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn_layout58>) -> tensor<1x3072xbf16, #ttnn_layout15> loc(#loc119)
        "ttnn.deallocate"(%139) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn_layout58>) -> () loc(#loc119)
        %141 = "ttnn.add"(%116, %140) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn_layout15>, tensor<1x3072xbf16, #ttnn_layout15>) -> tensor<1x3072xbf16, #ttnn_layout15> loc(#loc120)
        "ttnn.deallocate"(%140) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> () loc(#loc120)
        "ttnn.deallocate"(%116) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> () loc(#loc120)
        %142 = "ttnn.typecast"(%141) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc121)
        "ttnn.deallocate"(%141) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> () loc(#loc121)
        %143 = "ttnn.reshape"(%142) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xf32, #ttnn_layout14>) -> tensor<1x1x3072xf32, #ttnn_layout36> loc(#loc121)
        %144 = "ttnn.pow"(%143, %15) : (tensor<1x1x3072xf32, #ttnn_layout36>, tensor<1x1x1xf32, #ttnn_layout22>) -> tensor<1x1x3072xf32, #ttnn_layout36> loc(#loc122)
        "ttnn.deallocate"(%143) <{force = false}> : (tensor<1x1x3072xf32, #ttnn_layout36>) -> () loc(#loc122)
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout22>) -> () loc(#loc122)
        %145 = "ttnn.sum"(%144) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32, #ttnn_layout36>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc123)
        "ttnn.deallocate"(%144) <{force = false}> : (tensor<1x1x3072xf32, #ttnn_layout36>) -> () loc(#loc123)
        %146 = "ttnn.multiply"(%145, %18) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn_layout17>, tensor<1x1xf32, #ttnn_layout17>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc124)
        "ttnn.deallocate"(%145) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc124)
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc124)
        %147 = "ttnn.add"(%146, %11#2) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1xf32, #ttnn_layout17>, tensor<1x1xf32, #ttnn_layout17>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc125)
        "ttnn.deallocate"(%146) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc125)
        "ttnn.deallocate"(%11#2) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc125)
        %148 = "ttnn.rsqrt"(%147) : (tensor<1x1xf32, #ttnn_layout17>) -> tensor<1x1xf32, #ttnn_layout17> loc(#loc126)
        "ttnn.deallocate"(%147) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc126)
        %149 = "ttnn.multiply"(%142, %148) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn_layout14>, tensor<1x1xf32, #ttnn_layout17>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc127)
        "ttnn.deallocate"(%148) <{force = false}> : (tensor<1x1xf32, #ttnn_layout17>) -> () loc(#loc127)
        "ttnn.deallocate"(%142) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout14>) -> () loc(#loc127)
        %150 = "ttnn.multiply"(%12, %149) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn_layout14>, tensor<1x3072xf32, #ttnn_layout14>) -> tensor<1x3072xf32, #ttnn_layout14> loc(#loc128)
        "ttnn.deallocate"(%149) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout14>) -> () loc(#loc128)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout14>) -> () loc(#loc128)
        %151 = "ttnn.typecast"(%150) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn_layout14>) -> tensor<1x3072xbf16, #ttnn_layout15> loc(#loc129)
        "ttnn.deallocate"(%150) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout14>) -> () loc(#loc129)
        %152 = "ttnn.matmul"(%151, %6) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn_layout15>, tensor<128256x3072xbf16, #ttnn_layout12>) -> tensor<1x128256xbf16, #ttnn_layout62> loc(#loc130)
        "ttnn.deallocate"(%151) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout15>) -> () loc(#loc130)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout12>) -> () loc(#loc130)
        %153 = "ttnn.reshape"(%152) <{shape = [1 : i32, 1 : i32, 128256 : i32]}> : (tensor<1x128256xbf16, #ttnn_layout62>) -> tensor<1x1x128256xbf16, #ttnn_layout63> loc(#loc131)
        %154 = "ttnn.to_layout"(%22) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x16x128xbf16, #ttnn_layout30>) -> tensor<1x4x16x128xbf16, #ttnn_layout64> loc(#loc)
        "ttnn.deallocate"(%22) <{force = false}> : (tensor<1x4x16x128xbf16, #ttnn_layout30>) -> () loc(#loc)
        %155 = "ttnn.from_device"(%154) : (tensor<1x4x16x128xbf16, #ttnn_layout64>) -> tensor<1x4x16x128xbf16, #ttnn_layout65> loc(#loc)
        "ttnn.deallocate"(%154) <{force = false}> : (tensor<1x4x16x128xbf16, #ttnn_layout64>) -> () loc(#loc)
        %156 = "ttnn.mesh_shard"(%155, %17) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x16x128xbf16, #ttnn_layout65>, !ttnn.device) -> tensor<1x8x16x128xbf16, #ttnn_layout27> loc(#loc)
        "ttnn.deallocate"(%155) <{force = false}> : (tensor<1x4x16x128xbf16, #ttnn_layout65>) -> () loc(#loc)
        %157 = "ttnn.to_layout"(%23) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x16x128xbf16, #ttnn_layout30>) -> tensor<1x4x16x128xbf16, #ttnn_layout64> loc(#loc)
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<1x4x16x128xbf16, #ttnn_layout30>) -> () loc(#loc)
        %158 = "ttnn.from_device"(%157) : (tensor<1x4x16x128xbf16, #ttnn_layout64>) -> tensor<1x4x16x128xbf16, #ttnn_layout65> loc(#loc)
        "ttnn.deallocate"(%157) <{force = false}> : (tensor<1x4x16x128xbf16, #ttnn_layout64>) -> () loc(#loc)
        %159 = "ttnn.mesh_shard"(%158, %17) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x16x128xbf16, #ttnn_layout65>, !ttnn.device) -> tensor<1x8x16x128xbf16, #ttnn_layout27> loc(#loc)
        "ttnn.deallocate"(%158) <{force = false}> : (tensor<1x4x16x128xbf16, #ttnn_layout65>) -> () loc(#loc)
        %160 = "ttnn.to_layout"(%152) <{layout = #ttnn.layout<row_major>}> : (tensor<1x128256xbf16, #ttnn_layout62>) -> tensor<1x128256xbf16, #ttnn_layout66> loc(#loc)
        "ttnn.deallocate"(%152) <{force = false}> : (tensor<1x128256xbf16, #ttnn_layout62>) -> () loc(#loc)
        %161 = "ttnn.from_device"(%160) : (tensor<1x128256xbf16, #ttnn_layout66>) -> tensor<1x128256xbf16, #ttnn_layout28> loc(#loc)
        "ttnn.deallocate"(%160) <{force = false}> : (tensor<1x128256xbf16, #ttnn_layout66>) -> () loc(#loc)
        %162 = "ttnn.mesh_shard"(%161, %17) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x128256xbf16, #ttnn_layout28>, !ttnn.device) -> tensor<1x128256xbf16, #ttnn_layout28> loc(#loc)
        "ttnn.deallocate"(%161) <{force = false}> : (tensor<1x128256xbf16, #ttnn_layout28>) -> () loc(#loc)
        %163 = "ttnn.to_layout"(%153) <{layout = #ttnn.layout<row_major>}> : (tensor<1x1x128256xbf16, #ttnn_layout63>) -> tensor<1x1x128256xbf16, #ttnn_layout67> loc(#loc)
        "ttnn.deallocate"(%153) <{force = false}> : (tensor<1x1x128256xbf16, #ttnn_layout63>) -> () loc(#loc)
        %164 = "ttnn.from_device"(%163) : (tensor<1x1x128256xbf16, #ttnn_layout67>) -> tensor<1x1x128256xbf16, #ttnn_layout29> loc(#loc)
        "ttnn.deallocate"(%163) <{force = false}> : (tensor<1x1x128256xbf16, #ttnn_layout67>) -> () loc(#loc)
        %165 = "ttnn.mesh_shard"(%164, %17) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x1x128256xbf16, #ttnn_layout29>, !ttnn.device) -> tensor<1x1x128256xbf16, #ttnn_layout29> loc(#loc)
        "ttnn.deallocate"(%164) <{force = false}> : (tensor<1x1x128256xbf16, #ttnn_layout29>) -> () loc(#loc)
        return %156, %159, %162, %165 : tensor<1x8x16x128xbf16, #ttnn_layout27>, tensor<1x8x16x128xbf16, #ttnn_layout27>, tensor<1x128256xbf16, #ttnn_layout28>, tensor<1x1x128256xbf16, #ttnn_layout29> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("broadcast.280")
#loc2 = loc("convert.215")
#loc3 = loc("reshape.360")
#loc4 = loc("convert.347")
#loc5 = loc("reshape.89")
#loc6 = loc("reshape.418")
#loc7 = loc("convert.411")
#loc8 = loc("compare.208")
#loc9 = loc("broadcast.274")
#loc10 = loc("convert.273")
#loc11 = loc("convert.85")
#loc33 = loc("convert.48")
#loc34 = loc("gather.49")
#loc35 = loc("convert.51")
#loc36 = loc("power.53")
#loc37 = loc("reduce.60")
#loc38 = loc("multiply.69")
#loc39 = loc("add.74")
#loc40 = loc("rsqrt.75")
#loc41 = loc("multiply.78")
#loc42 = loc("multiply.87")
#loc43 = loc("convert.88")
#loc44 = loc("dot.90")
#loc45 = loc("transpose.93")
#loc46 = loc("convert.110")
#loc47 = loc("reshape.19")
#loc48 = loc("convert.11")
#loc49 = loc("dot.22")
#loc50 = loc("concatenate.24")
#loc51 = loc("cosine.104")
#loc52 = loc("multiply.113")
#loc53 = loc("convert.114")
#loc54 = loc("slice.95")
#loc55 = loc("negate.96")
#loc56 = loc("slice.94")
#loc57 = loc("concatenate.97")
#loc58 = loc("convert.98")
#loc59 = loc("sine.25")
#loc60 = loc("multiply.101")
#loc61 = loc("convert.102")
#loc62 = loc("add.117")
#loc63 = loc("scatter.134")
#loc64 = loc("dot.143")
#loc65 = loc("transpose.146")
#loc66 = loc("scatter.162")
#loc67 = loc("dot.247")
#loc68 = loc("transpose.250")
#loc69 = loc("convert.261")
#loc70 = loc("reshape.270")
#loc71 = loc("multiply.264")
#loc72 = loc("convert.265")
#loc73 = loc("slice.252")
#loc74 = loc("negate.253")
#loc75 = loc("slice.251")
#loc76 = loc("concatenate.254")
#loc77 = loc("convert.255")
#loc78 = loc("multiply.258")
#loc79 = loc("convert.259")
#loc80 = loc("add.268")
#loc81 = loc("broadcast.234")
#loc82 = loc("reshape.235")
#loc83 = loc("transpose.236")
#loc84 = loc("reshape.238")
#loc85 = loc("dot.271")
#loc86 = loc("multiply.275")
#loc87 = loc("convert.276")
#loc88 = loc("convert.209")
#loc89 = loc("multiply.216")
#loc90 = loc("convert.217")
#loc91 = loc("add.281")
#loc92 = loc("convert.282")
#loc93 = loc("divide.299")
#loc94 = loc("convert.300")
#loc95 = loc("broadcast.198")
#loc96 = loc("reshape.201")
#loc97 = loc("dot.303")
#loc98 = loc("reshape.307")
#loc99 = loc("dot.308")
#loc100 = loc("add.312")
#loc101 = loc("convert.313")
#loc102 = loc("power.315")
#loc103 = loc("reduce.322")
#loc104 = loc("multiply.331")
#loc105 = loc("add.336")
#loc106 = loc("rsqrt.337")
#loc107 = loc("multiply.340")
#loc108 = loc("multiply.349")
#loc109 = loc("convert.350")
#loc110 = loc("dot.361")
#loc111 = loc("convert.365")
#loc112 = loc("logistic.363")
#loc113 = loc("convert.364")
#loc114 = loc("multiply.366")
#loc115 = loc("dot.352")
#loc116 = loc("convert.354")
#loc117 = loc("multiply.369")
#loc118 = loc("convert.370")
#loc119 = loc("dot.372")
#loc120 = loc("add.376")
#loc121 = loc("convert.377")
#loc122 = loc("power.379")
#loc123 = loc("reduce.386")
#loc124 = loc("multiply.395")
#loc125 = loc("add.400")
#loc126 = loc("rsqrt.401")
#loc127 = loc("multiply.404")
#loc128 = loc("multiply.413")
#loc129 = loc("convert.414")
#loc130 = loc("dot.419")
#loc131 = loc("reshape.420")
#loc132 = loc("broadcast.280_tm0"(#loc1))
#loc133 = loc("reshape.360_tm0"(#loc3))
#loc134 = loc("reshape.89_tm0"(#loc5))
#loc135 = loc("reshape.418_tm0"(#loc6))
#loc136 = loc("compare.208_workaround"(#loc8))
#loc137 = loc("gather.49_workaround"(#loc34))
#loc138 = loc("scatter.134_workaround"(#loc63))
#loc139 = loc("scatter.162_workaround"(#loc66))
#loc140 = loc("reshape.270_tm0"(#loc70))
#loc141 = loc("reshape.270_tm1"(#loc70))
#loc142 = loc("dot.308_reduceScatter"(#loc99))
#loc143 = loc("dot.308_all_gather_4d"(#loc99))
#loc144 = loc("dot.372_reduceScatter"(#loc119))
#loc145 = loc("dot.372_all_gather_4d"(#loc119))
#loc146 = loc("broadcast.280_tm0_tm0"(#loc132))
#loc147 = loc("reshape.360_tm0_tm0"(#loc133))
#loc148 = loc("reshape.89_tm0_tm1"(#loc134))
#loc149 = loc("reshape.360_tm0_tm1"(#loc133))
#loc150 = loc("reshape.418_tm0_tm1"(#loc135))
#loc151 = loc("reshape.418_tm0_tm0"(#loc135))
#loc152 = loc("broadcast.280_tm0_tm1"(#loc132))
#loc153 = loc("reshape.89_tm0_tm0"(#loc134))
#loc154 = loc("reshape.270_tm0_tm0"(#loc140))
#loc155 = loc("reshape.270_tm1_tm0"(#loc141))
#loc156 = loc("dot.308_reduceScatter_reshape_to_4d"(#loc142))
#loc157 = loc("dot.308_reduceScatter_reduce_scatter_4d"(#loc142))
#loc158 = loc("dot.372_reduceScatter_reshape_to_4d"(#loc144))
#loc159 = loc("dot.372_reduceScatter_reduce_scatter_4d"(#loc144))
#loc160 = loc("broadcast.280_tm0_tm0_tm0"(#loc146))
#loc161 = loc("reshape.360_tm0_tm0_tm0"(#loc147))
#loc162 = loc("reshape.89_tm0_tm1_tm1"(#loc148))
#loc163 = loc("reshape.360_tm0_tm1_tm1"(#loc149))
#loc164 = loc("reshape.418_tm0_tm1_tm1"(#loc150))
#loc165 = loc("reshape.418_tm0_tm0_tm0"(#loc151))
#loc166 = loc("broadcast.280_tm0_tm1_tm0"(#loc152))
#loc167 = loc("reshape.89_tm0_tm0_tm0"(#loc153))
#loc168 = loc("reshape.270_tm0_tm0_tm1"(#loc154))
#loc169 = loc("reshape.270_tm1_tm0_tm1"(#loc155))
#loc170 = loc("reshape.89_tm0_tm1_tm1_tm0"(#loc162))
#loc171 = loc("reshape.360_tm0_tm1_tm1_tm0"(#loc163))
#loc172 = loc("reshape.418_tm0_tm1_tm1_tm0"(#loc164))
#loc173 = loc("broadcast.280_tm0_tm1_tm0_tm0"(#loc166))
#loc174 = loc("broadcast.280_tm0_tm1_tm0_tm1"(#loc166))
#loc175 = loc("reshape.89_tm0_tm1_tm1_tm0_tm1"(#loc170))
#loc176 = loc("reshape.360_tm0_tm1_tm1_tm0_tm1"(#loc171))
#loc177 = loc("reshape.418_tm0_tm1_tm1_tm0_tm1"(#loc172))
2025-09-22 18:08:06.676 (  66.362s) [        A88F8000]loaded_executable_insta:448      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2025-09-22 18:08:06.676 (  66.362s) [        A88F8000]loaded_executable_insta:467      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2025-09-22 18:08:06.677 (  66.362s) [        A88F8000]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2025-09-22 18:08:06.677 (  66.362s) [        A88F8000]      error_instance.cc:49       1| ErrorInstance::PJRT_Error_Message
2025-09-22 18:08:06.677 (  66.362s) [        A88F8000]      error_instance.cc:58       1| ErrorInstance::PJRT_Error_GetCode
2025-09-22 18:08:06.677 (  66.362s) [        A88F8000]      error_instance.cc:43       1| ErrorInstance::PJRT_Error_Destroy
2025-09-22 18:08:06.677 (  66.363s) [        A88F8000] executable_instance.cc:107      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-22 18:08:06.677 (  66.363s) [        A88F8000] executable_instance.cc:107      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-22 18:08:06.689 (  66.374s) [        A88F8000] executable_instance.cc:107      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-22 18:08:06.689 (  66.374s) [        A88F8000] executable_instance.cc:107      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-22 18:08:06.699 (  66.384s) [        EB7FE640]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:06.699 (  66.384s) [        EB7FE640]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:06.699 (  66.384s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.384s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        197FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        197FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        197FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        197FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:06.699 (  66.385s) [        20FF9640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-22 18:08:06.699 (  66.385s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:06.699 (  66.385s) [        1B7FE640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        217FA640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-22 18:08:06.699 (  66.385s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:06.699 (  66.385s) [        EB7FE640] executable_instance.cc:139      1| ExecutableInstance::PJRT_Executable_NumOutputs
2025-09-22 18:08:06.700 (  66.385s) [        EB7FE640]loaded_executable_insta:504      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2025-09-22 18:08:06.700 (  66.385s) [        EB7FE640]loaded_executable_insta:81       1| LoadedExecutableInstance::Execute
2025-09-22 18:08:06.808 (  66.493s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=0 device_index=0 BufferInstance=0x44887f60 shape=[1] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.808 (  66.493s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=0 device_index=1 BufferInstance=0x84c968b0 shape=[1] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.809 (  66.494s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=1 device_index=0 BufferInstance=0x8389c180 shape=[64] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.809 (  66.494s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=1 device_index=1 BufferInstance=0x56402200 shape=[64] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.809 (  66.495s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=2 device_index=0 BufferInstance=0x70d09dc0 shape=[512,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.809 (  66.495s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=2 device_index=1 BufferInstance=0x75273df0 shape=[512,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.811 (  66.496s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=3 device_index=0 BufferInstance=0x4cb0a0f0 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.811 (  66.496s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=3 device_index=1 BufferInstance=0x70d78610 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.811 (  66.497s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=4 device_index=0 BufferInstance=0x80a21be0 shape=[1,1] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.811 (  66.497s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=4 device_index=1 BufferInstance=0x83a58d50 shape=[1,1] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.811 (  66.497s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=5 device_index=0 BufferInstance=0x70be4ad0 shape=[128256,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.811 (  66.497s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=5 device_index=1 BufferInstance=0x56366f40 shape=[128256,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.932 (  66.617s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=6 device_index=0 BufferInstance=0x70bdeeb0 shape=[3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.932 (  66.617s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=6 device_index=1 BufferInstance=0x70bb4740 shape=[3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.933 (  66.618s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=7 device_index=0 BufferInstance=0x75655cf0 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.933 (  66.618s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=7 device_index=1 BufferInstance=0x70b99b00 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.933 (  66.618s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=8 device_index=0 BufferInstance=0x70b83860 shape=[1,4,16,128] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.933 (  66.618s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=8 device_index=1 BufferInstance=0x70c4afc0 shape=[1,4,16,128] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.933 (  66.619s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=9 device_index=0 BufferInstance=0x70d73bd0 shape=[512,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.933 (  66.619s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=9 device_index=1 BufferInstance=0x75237850 shape=[512,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.935 (  66.620s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=10 device_index=0 BufferInstance=0x7f5860d348c0 shape=[1,4,16,128] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.935 (  66.620s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=10 device_index=1 BufferInstance=0x7f5860035cc0 shape=[1,4,16,128] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.935 (  66.621s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=11 device_index=0 BufferInstance=0x83a477b0 shape=[128256,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:06.935 (  66.621s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=11 device_index=1 BufferInstance=0x838479a0 shape=[128256,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.062 (  66.748s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=12 device_index=0 BufferInstance=0x839c8d70 shape=[3072,4096] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.062 (  66.748s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=12 device_index=1 BufferInstance=0x75260c70 shape=[3072,4096] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.076 (  66.762s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=13 device_index=0 BufferInstance=0x562879c0 shape=[4096,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.077 (  66.762s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=13 device_index=1 BufferInstance=0x56375710 shape=[4096,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.081 (  66.767s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=14 device_index=0 BufferInstance=0x83987740 shape=[3072,1536] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.081 (  66.767s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=14 device_index=1 BufferInstance=0x70b7a050 shape=[3072,1536] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.084 (  66.769s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=15 device_index=0 BufferInstance=0x563f20c0 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.084 (  66.769s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=15 device_index=1 BufferInstance=0x562b0440 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.084 (  66.770s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=16 device_index=0 BufferInstance=0x85689af0 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.084 (  66.770s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=16 device_index=1 BufferInstance=0x4cb02a20 shape=[] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.084 (  66.770s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=17 device_index=0 BufferInstance=0x75566b90 shape=[1536,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.084 (  66.770s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=17 device_index=1 BufferInstance=0x7521bd00 shape=[1536,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.087 (  66.772s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=18 device_index=0 BufferInstance=0x564996d0 shape=[3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.087 (  66.772s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=18 device_index=1 BufferInstance=0x8377f530 shape=[3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.088 (  66.773s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=19 device_index=0 BufferInstance=0x70d0dda0 shape=[4096,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.088 (  66.773s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=19 device_index=1 BufferInstance=0x84b9e330 shape=[4096,3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.092 (  66.777s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=20 device_index=0 BufferInstance=0x83a44590 shape=[3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:07.092 (  66.777s) [        EB7FE640]loaded_executable_insta:251   INFO| EXEC_TRACE: Input arg_index=20 device_index=1 BufferInstance=0x839e0890 shape=[3072] m_runtime_tensor.data=0x7f5beb7fcd90 tensor.handle=0x7f5beb7fcde0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f5860d03c20 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=0 output_index=0 NEW BufferInstance=0x7f5860d03c20 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x8380c550 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=0 output_index=1 NEW BufferInstance=0x8380c550 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x70ba04a0 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=0 output_index=2 NEW BufferInstance=0x70ba04a0 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f5860c9bb60 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=0 output_index=3 NEW BufferInstance=0x7f5860c9bb60 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f5860cc5c90 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=1 output_index=0 NEW BufferInstance=0x7f5860cc5c90 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x44841fd0 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=1 output_index=1 NEW BufferInstance=0x44841fd0 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f5860ac6dd0 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=1 output_index=2 NEW BufferInstance=0x7f5860ac6dd0 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f586016a550 constructor with tensor.data=0x7f5beb7fcbe0 tensor.handle=0x7f5beb7fcbf0
2025-09-22 18:08:11.568 (  71.254s) [        EB7FE640]loaded_executable_insta:397   INFO| EXEC_TRACE: Output device_index=1 output_index=3 NEW BufferInstance=0x7f586016a550 m_runtime_tensor.data=0x7f5beb7fcde0 tensor.handle=0x7f5beb7fcdf0
2025-09-22 18:08:11.571 (  71.257s) [        EB7FE640]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:11.572 (  71.257s) [        EB7FE640]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.572 (  71.258s) [        EB7FE640]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.572 (  71.258s) [        EB7FE640]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.572 (  71.258s) [        EB7FE640]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.573 (  71.258s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:11.573 (  71.258s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:11.573 (  71.258s) [        A88F8000]     buffer_instance.cc:446      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-22 18:08:11.573 (  71.258s) [        A88F8000]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:11.573 (  71.258s) [        A88F8000]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.574 (  71.259s) [        A88F8000]     buffer_instance.cc:468      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-22 18:08:11.574 (  71.260s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:11.574 (  71.260s) [        DBFFF640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:11.575 (  71.261s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:11.575 (  71.261s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:11.575 (  71.261s) [        A88F8000]     buffer_instance.cc:446      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-22 18:08:11.575 (  71.261s) [        A88F8000]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:11.576 (  71.261s) [        A88F8000]     buffer_instance.cc:468      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-22 18:08:11.576 (  71.261s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:11.578 (  71.264s) [        19156640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:11.580 (  71.265s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.580 (  71.265s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.580 (  71.265s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:11.580 (  71.265s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:11.580 (  71.265s) [        A88F8000]     buffer_instance.cc:446      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-22 18:08:11.580 (  71.265s) [        A88F8000]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:11.580 (  71.265s) [        A88F8000]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.580 (  71.265s) [        A88F8000]     buffer_instance.cc:468      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-22 18:08:11.580 (  71.265s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User is requesting to copy the data from a runtime tensor with data type: Int32 into buffer with expected data type: Int64, the values will be casted, this may impact the throughput and the integrity of the data.
2025-09-22 18:08:11.580 (  71.266s) [        19156640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:11.580 (  71.266s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.580 (  71.266s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.580 (  71.266s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:11.580 (  71.266s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:11.580 (  71.266s) [        A88F8000]     buffer_instance.cc:446      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-22 18:08:11.580 (  71.266s) [        A88F8000]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:11.580 (  71.266s) [        A88F8000]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.580 (  71.266s) [        A88F8000]     buffer_instance.cc:468      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-22 18:08:11.580 (  71.266s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:11.581 (  71.266s) [        1A158640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:11.581 (  71.266s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:11.581 (  71.266s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:11.581 (  71.266s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:08:11.581 (  71.266s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:08:11.581 (  71.266s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:08:11.581 (  71.266s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x44887f60 copyFromHost BORROWED shape=[1,4,16,128] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x560e8e70 copyFromHost BORROWED shape=[1,4,16,128] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]     buffer_instance.cc:446      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]     buffer_instance.cc:468      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-22 18:08:11.581 (  71.267s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:11.582 (  71.267s) [        19156640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:11.582 (  71.267s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:11.582 (  71.267s) [        A88F8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-22 18:08:11.582 (  71.267s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:08:11.582 (  71.267s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:08:11.582 (  71.267s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:08:11.582 (  71.267s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x7f5860cc5c90 copyFromHost BORROWED shape=[1,4,16,128] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:08:11.582 (  71.267s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:11.582 (  71.267s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:11.582 (  71.267s) [        A88F8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-22 18:08:11.582 (  71.267s) [        A88F8000]     client_instance.cc:465      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-22 18:08:11.582 (  71.267s) [        A88F8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-22 18:08:11.582 (  71.268s) [        A88F8000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x7f5860d03c20 copyFromHost BORROWED shape=[1,4,16,128] - NEW tensor.data=0x7ffc8de65170 tensor.handle=0x7ffc8de651c0
2025-09-22 18:08:11.582 (  71.268s) [        A88F8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-22 18:08:11.582 (  71.268s) [        A88F8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-22 18:08:11.582 (  71.268s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.582 (  71.268s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.610 (  71.296s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.610 (  71.296s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.610 (  71.296s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.610 (  71.296s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.610 (  71.296s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.610 (  71.296s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.611 (  71.296s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.611 (  71.296s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
[james] override use torch.export.export
program.graph_signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___input_layernorm_weight'), target='L__self___model_layers__modules__0___input_layernorm_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___post_attention_layernorm_weight'), target='L__self___model_layers__modules__0___post_attention_layernorm_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_norm_weight'), target='L__self___model_norm_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_embed_tokens_weight'), target='L__self___model_embed_tokens.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___self_attn_q_proj_weight'), target='L__self___model_layers__modules__0___self_attn_q_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___self_attn_k_proj_weight'), target='L__self___model_layers__modules__0___self_attn_k_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___self_attn_v_proj_weight'), target='L__self___model_layers__modules__0___self_attn_v_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___self_attn_o_proj_weight'), target='L__self___model_layers__modules__0___self_attn_o_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___mlp_gate_proj_weight'), target='L__self___model_layers__modules__0___mlp_gate_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___mlp_up_proj_weight'), target='L__self___model_layers__modules__0___mlp_up_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___mlp_down_proj_weight'), target='L__self___model_layers__modules__0___mlp_down_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_lm_head_weight'), target='L__self___lm_head.weight', persistent=None), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_model_rotary_emb_inv_freq'), target='L__self___model_rotary_emb_inv_freq', persistent=True), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='args_0'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='args_1'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='args_2'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='args_3'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_INPUT_MUTATION: 6>, arg=TensorArgument(name='index_put'), target='args_2'), OutputSpec(kind=<OutputKind.USER_INPUT_MUTATION: 6>, arg=TensorArgument(name='index_put_1'), target='args_3'), OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='view_31'), target=None)])
CausalLMOutputWithPast(loss=None, logits=tensor([[[-0.8555, -2.3438, -0.5352,  ...,  0.8320,  0.8320,  0.8320],
         [-0.1807,  0.2158,  0.8086,  ..., -0.8438, -0.8438, -0.8477],
         [ 1.7734, -1.3672, -0.8672,  ..., -1.4297, -1.4219, -1.4297],
         ...,
         [ 0.0540, -0.8672, -1.4609,  ..., -0.6914, -0.6914, -0.6914],
         [-0.0591, -1.1406, -1.2031,  ..., -2.3594, -2.3594, -2.3594],
         [-1.1016, -0.0152, -0.7656,  ..., -1.4688, -1.4688, -1.4688]]],
       device='xla:0', dtype=torch.bfloat16), past_key_values=<transformers.cache_utils.StaticCache object at 0x7f64d4f90990>, hidden_states=None, attentions=None)
Generated token:  the
[james] override use torch.export.export
program.graph_signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___input_layernorm_weight'), target='L__self___model_layers__modules__0___input_layernorm_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___post_attention_layernorm_weight'), target='L__self___model_layers__modules__0___post_attention_layernorm_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_norm_weight'), target='L__self___model_norm_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_embed_tokens_weight'), target='L__self___model_embed_tokens.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___self_attn_q_proj_weight'), target='L__self___model_layers__modules__0___self_attn_q_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___self_attn_k_proj_weight'), target='L__self___model_layers__modules__0___self_attn_k_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___self_attn_v_proj_weight'), target='L__self___model_layers__modules__0___self_attn_v_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___self_attn_o_proj_weight'), target='L__self___model_layers__modules__0___self_attn_o_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___mlp_gate_proj_weight'), target='L__self___model_layers__modules__0___mlp_gate_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___mlp_up_proj_weight'), target='L__self___model_layers__modules__0___mlp_up_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_model_layers__modules__0___mlp_down_proj_weight'), target='L__self___model_layers__modules__0___mlp_down_proj.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_lm_head_weight'), target='L__self___lm_head.weight', persistent=None), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_model_rotary_emb_inv_freq'), target='L__self___model_rotary_emb_inv_freq', persistent=True), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='args_0'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='args_1'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='args_2'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='args_3'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_INPUT_MUTATION: 6>, arg=TensorArgument(name='index_put'), target='args_2'), OutputSpec(kind=<OutputKind.USER_INPUT_MUTATION: 6>, arg=TensorArgument(name='index_put_1'), target='args_3'), OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='view_31'), target=None)])
CausalLMOutputWithPast(loss=None, logits=tensor([[[ 1.1797,  0.1738, -1.3750,  ..., -3.3906, -3.3906, -3.3906]]],
       device='xla:0', dtype=torch.bfloat16), past_key_values=<transformers.cache_utils.StaticCache object at 0x7f64d4f90990>, hidden_states=None, attentions=None)
Generated token:  the
output tokens: [' the', ' the']
2025-09-22 18:08:11.980 (  71.665s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.980 (  71.665s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.980 (  71.666s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.980 (  71.666s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.980 (  71.666s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.981 (  71.666s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.981 (  71.666s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.981 (  71.667s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.981 (  71.667s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.981 (  71.667s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.982 (  71.667s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.982 (  71.667s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.982 (  71.667s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.982 (  71.668s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.982 (  71.668s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.982 (  71.668s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.982 (  71.668s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.983 (  71.668s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.983 (  71.668s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.983 (  71.668s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.983 (  71.669s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.983 (  71.669s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.983 (  71.669s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.983 (  71.669s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.983 (  71.669s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.984 (  71.669s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.984 (  71.669s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.984 (  71.669s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.984 (  71.670s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.984 (  71.670s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.984 (  71.670s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.984 (  71.670s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.984 (  71.670s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.985 (  71.670s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.985 (  71.670s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.985 (  71.670s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.985 (  71.670s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.985 (  71.671s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.985 (  71.671s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.985 (  71.671s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.985 (  71.671s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.985 (  71.671s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.986 (  71.671s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.986 (  71.671s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.986 (  71.672s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.986 (  71.672s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.986 (  71.672s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.986 (  71.672s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.986 (  71.672s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.986 (  71.672s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.987 (  71.672s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.987 (  71.672s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.987 (  71.672s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.987 (  71.672s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.987 (  71.672s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.987 (  71.673s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.987 (  71.673s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.987 (  71.673s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.987 (  71.673s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.987 (  71.673s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.988 (  71.673s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.988 (  71.673s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.988 (  71.673s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.988 (  71.673s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.988 (  71.674s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.988 (  71.674s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.988 (  71.674s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.988 (  71.674s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.988 (  71.674s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.988 (  71.674s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.989 (  71.674s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.989 (  71.674s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.989 (  71.674s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.989 (  71.675s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.989 (  71.675s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.989 (  71.675s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.989 (  71.675s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.989 (  71.675s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.989 (  71.675s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.990 (  71.675s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.990 (  71.675s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.990 (  71.675s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.990 (  71.675s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.990 (  71.675s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.990 (  71.676s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.990 (  71.676s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.990 (  71.676s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.990 (  71.676s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.990 (  71.676s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.991 (  71.676s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.991 (  71.676s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.991 (  71.676s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.991 (  71.676s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.991 (  71.677s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.991 (  71.677s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.991 (  71.677s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.991 (  71.677s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.991 (  71.677s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.991 (  71.677s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.992 (  71.677s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.992 (  71.677s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.992 (  71.677s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.992 (  71.677s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.992 (  71.678s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.992 (  71.678s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.992 (  71.678s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.992 (  71.678s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.992 (  71.678s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.992 (  71.678s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.993 (  71.678s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.993 (  71.678s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.993 (  71.678s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.993 (  71.679s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.993 (  71.679s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.993 (  71.679s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.993 (  71.679s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.993 (  71.679s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.993 (  71.679s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.994 (  71.679s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.994 (  71.679s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.994 (  71.679s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.994 (  71.679s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.994 (  71.680s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.994 (  71.680s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.994 (  71.680s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.994 (  71.680s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.994 (  71.680s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.994 (  71.680s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.994 (  71.680s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.994 (  71.680s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.995 (  71.680s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.995 (  71.680s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.995 (  71.680s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.995 (  71.680s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.995 (  71.681s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.995 (  71.681s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.995 (  71.681s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.995 (  71.681s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.995 (  71.681s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.995 (  71.681s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.996 (  71.681s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.996 (  71.681s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.996 (  71.681s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.996 (  71.681s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.996 (  71.681s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.996 (  71.682s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.996 (  71.682s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.996 (  71.682s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.996 (  71.682s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.996 (  71.682s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.996 (  71.682s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.997 (  71.682s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.997 (  71.682s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.997 (  71.682s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.997 (  71.682s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.997 (  71.683s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.997 (  71.683s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.997 (  71.683s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.997 (  71.683s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.997 (  71.683s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.997 (  71.683s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.998 (  71.683s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.998 (  71.683s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.998 (  71.684s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.998 (  71.684s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.998 (  71.684s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.998 (  71.684s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.998 (  71.684s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.998 (  71.684s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.999 (  71.684s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.999 (  71.684s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.999 (  71.684s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.999 (  71.684s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.999 (  71.685s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.999 (  71.685s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.999 (  71.685s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.999 (  71.685s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:11.999 (  71.685s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.000 (  71.685s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.000 (  71.685s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.000 (  71.685s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.000 (  71.685s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.000 (  71.686s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.000 (  71.686s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.000 (  71.686s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.000 (  71.686s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.000 (  71.686s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.001 (  71.686s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.001 (  71.686s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.001 (  71.686s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.001 (  71.687s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.001 (  71.687s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.001 (  71.687s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.001 (  71.687s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.001 (  71.687s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.002 (  71.687s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.002 (  71.687s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.002 (  71.687s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.002 (  71.688s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.002 (  71.688s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.002 (  71.688s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.002 (  71.688s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.002 (  71.688s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.003 (  71.688s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.003 (  71.688s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.003 (  71.688s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.003 (  71.688s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.003 (  71.688s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.003 (  71.689s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.003 (  71.689s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.003 (  71.689s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.003 (  71.689s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.003 (  71.689s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.003 (  71.689s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.004 (  71.689s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.004 (  71.689s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.004 (  71.689s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.004 (  71.689s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.004 (  71.690s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.004 (  71.690s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.004 (  71.690s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.004 (  71.690s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.004 (  71.690s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.005 (  71.690s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.005 (  71.690s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.005 (  71.690s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.005 (  71.690s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.005 (  71.691s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.005 (  71.691s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.005 (  71.691s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.005 (  71.691s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.005 (  71.691s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.006 (  71.691s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.006 (  71.691s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.006 (  71.691s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.006 (  71.691s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.006 (  71.692s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.006 (  71.692s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.006 (  71.692s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.006 (  71.692s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.006 (  71.692s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.006 (  71.692s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.007 (  71.692s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.007 (  71.692s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.007 (  71.692s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.007 (  71.692s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.007 (  71.693s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.007 (  71.693s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.007 (  71.693s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.007 (  71.693s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.007 (  71.693s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.007 (  71.693s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.007 (  71.693s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.008 (  71.693s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.008 (  71.693s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.008 (  71.693s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.008 (  71.693s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.008 (  71.694s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.008 (  71.694s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.008 (  71.694s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.008 (  71.694s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.008 (  71.694s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.009 (  71.694s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.009 (  71.694s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.009 (  71.694s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.009 (  71.694s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.009 (  71.695s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.009 (  71.695s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.009 (  71.695s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.009 (  71.695s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.009 (  71.695s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.009 (  71.695s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.010 (  71.695s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.010 (  71.695s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.010 (  71.695s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.010 (  71.696s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.010 (  71.696s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.010 (  71.696s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.010 (  71.696s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.010 (  71.696s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.010 (  71.696s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.011 (  71.696s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.011 (  71.696s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.011 (  71.696s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.011 (  71.696s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.011 (  71.697s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.011 (  71.697s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.011 (  71.697s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.011 (  71.697s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.011 (  71.697s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.011 (  71.697s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.011 (  71.697s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.012 (  71.697s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.012 (  71.697s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.012 (  71.697s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.012 (  71.698s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.012 (  71.698s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.012 (  71.698s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.012 (  71.698s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.012 (  71.698s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.012 (  71.698s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.012 (  71.698s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.013 (  71.698s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.013 (  71.698s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.013 (  71.698s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.013 (  71.698s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.013 (  71.699s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.013 (  71.699s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.013 (  71.699s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.013 (  71.699s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.013 (  71.699s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.014 (  71.699s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.014 (  71.699s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.014 (  71.699s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.014 (  71.699s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.014 (  71.700s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.014 (  71.700s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.014 (  71.700s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.014 (  71.700s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.014 (  71.700s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.015 (  71.700s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.015 (  71.700s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.015 (  71.700s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.015 (  71.700s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.015 (  71.701s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.015 (  71.701s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.015 (  71.701s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.015 (  71.701s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.015 (  71.701s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.015 (  71.701s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.016 (  71.701s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.016 (  71.701s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.016 (  71.701s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.016 (  71.701s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.016 (  71.702s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.016 (  71.702s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.016 (  71.702s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.016 (  71.702s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.016 (  71.702s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.017 (  71.702s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.017 (  71.702s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.017 (  71.702s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.017 (  71.702s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.017 (  71.702s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.017 (  71.703s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.017 (  71.703s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.017 (  71.703s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.017 (  71.703s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.017 (  71.703s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.018 (  71.703s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.018 (  71.703s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.018 (  71.703s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.018 (  71.703s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.018 (  71.704s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.018 (  71.704s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.018 (  71.704s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.018 (  71.704s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.018 (  71.704s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.019 (  71.704s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.019 (  71.704s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.019 (  71.704s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.019 (  71.704s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.019 (  71.705s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.019 (  71.705s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.019 (  71.705s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.019 (  71.705s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.019 (  71.705s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.019 (  71.705s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.020 (  71.705s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.020 (  71.705s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.020 (  71.705s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.020 (  71.706s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.020 (  71.706s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.020 (  71.706s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.020 (  71.706s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.020 (  71.706s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.020 (  71.706s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.021 (  71.706s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.021 (  71.706s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.021 (  71.706s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.021 (  71.706s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.021 (  71.707s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.021 (  71.707s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.021 (  71.707s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.021 (  71.707s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.021 (  71.707s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.022 (  71.707s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.022 (  71.707s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.022 (  71.707s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.022 (  71.707s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.022 (  71.708s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.022 (  71.708s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.022 (  71.708s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.022 (  71.708s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.022 (  71.708s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.022 (  71.708s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.023 (  71.708s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.023 (  71.708s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.023 (  71.708s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.023 (  71.708s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.023 (  71.708s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.023 (  71.709s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.023 (  71.709s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.023 (  71.709s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.023 (  71.709s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.023 (  71.709s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.024 (  71.709s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.024 (  71.709s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.024 (  71.709s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.024 (  71.709s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.024 (  71.710s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.024 (  71.710s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.024 (  71.710s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.024 (  71.710s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.024 (  71.710s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.024 (  71.710s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.025 (  71.710s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.025 (  71.710s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.025 (  71.710s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.025 (  71.711s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.025 (  71.711s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.025 (  71.711s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.025 (  71.711s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.025 (  71.711s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.026 (  71.711s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.026 (  71.711s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.026 (  71.711s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.026 (  71.711s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.026 (  71.712s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.026 (  71.712s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.026 (  71.712s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.026 (  71.712s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.026 (  71.712s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.027 (  71.712s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.027 (  71.712s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.027 (  71.712s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.027 (  71.712s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.027 (  71.713s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.027 (  71.713s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.027 (  71.713s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.027 (  71.713s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.027 (  71.713s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.027 (  71.713s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.028 (  71.713s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.028 (  71.713s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.028 (  71.713s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.028 (  71.714s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.028 (  71.714s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.028 (  71.714s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.028 (  71.714s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.028 (  71.714s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.028 (  71.714s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.029 (  71.714s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.029 (  71.714s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.029 (  71.714s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.029 (  71.715s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.029 (  71.715s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.029 (  71.715s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.029 (  71.715s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.029 (  71.715s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.030 (  71.715s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.030 (  71.715s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.030 (  71.715s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.030 (  71.715s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.030 (  71.716s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.030 (  71.716s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.030 (  71.716s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.030 (  71.716s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.030 (  71.716s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.030 (  71.716s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.030 (  71.716s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.031 (  71.716s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.031 (  71.716s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.031 (  71.716s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.031 (  71.717s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.031 (  71.717s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.031 (  71.717s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.031 (  71.717s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.031 (  71.717s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.031 (  71.717s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.032 (  71.717s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.032 (  71.717s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.032 (  71.717s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.034 (  71.719s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.034 (  71.719s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.034 (  71.720s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.034 (  71.720s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.062 (  71.748s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.090 (  71.776s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.090 (  71.776s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.090 (  71.776s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.091 (  71.776s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.091 (  71.776s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.091 (  71.776s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.091 (  71.776s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.091 (  71.776s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.091 (  71.777s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.124 (  71.809s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.150 (  71.836s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.150 (  71.836s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.150 (  71.836s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.150 (  71.836s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.151 (  71.836s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.151 (  71.836s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.151 (  71.836s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.151 (  71.836s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.151 (  71.837s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.151 (  71.837s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.151 (  71.837s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.153 (  71.838s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.155 (  71.840s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-22 18:08:12.155 (  71.840s) [        A88F8000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
