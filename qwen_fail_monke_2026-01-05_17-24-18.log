Using PJRT plugin directory: /localdev/jameszianxu/tt-xla/python_package/pjrt_plugin_tt
Using TT-Metal from the source tree: /localdev/jameszianxu/tt-xla/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
WARNING: TT plugin is setting XLA_STABLEHLO_COMPILE to 1. This is required for TT PJRT plugin to work correctly.
============================= test session starts ==============================
platform linux -- Python 3.11.14, pytest-8.4.2, pluggy-1.6.0 -- /localdev/jameszianxu/tt-xla/venv/bin/python
cachedir: .pytest_cache
metadata: {'Python': '3.11.14', 'Platform': 'Linux-5.15.0-142-generic-x86_64-with-glibc2.35', 'Packages': {'pytest': '8.4.2', 'pluggy': '1.6.0'}, 'Plugins': {'metadata': '3.1.1', 'split': '0.10.0', 'jaxtyping': '0.3.4', 'forked': '1.6.0', 'anyio': '4.12.0', 'json-report': '1.5.0'}}
rootdir: /localdev/jameszianxu/tt-xla
configfile: pytest.ini
plugins: metadata-3.1.1, split-0.10.0, jaxtyping-0.3.4, forked-1.6.0, anyio-4.12.0, json-report-1.5.0
collecting ... collected 1 item

tests/torch/graphs/test_attention.py::test_qwen2_5_attention_prefill_push[7b_instruct-1024-llmbox] 2026-01-05 17:22:57.939 (   0.000s) [        7BAA3480]   plugin_attributes.cc:60       1| PluginAttributes::PJRT_Plugin_Initialize
2026-01-05 17:22:57.939 (   0.000s) [        7BAA3480]     client_instance.cc:553      1| ClientInstance::PJRT_Client_Create
2026-01-05 17:22:57.941 (   0.002s) [        7BAA3480]     client_instance.cc:177      1| ClientInstance::ClientInstance
2026-01-05 17:22:57.941 (   0.002s) [        7BAA3480]     client_instance.cc:198      1| ClientInstance::Initialize
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]              stubs.inc:103   WARN| STUB: PJRT_Client_TopologyDescription
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]     client_instance.cc:607      1| ClientInstance::PJRT_Client_PlatformVersion
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]     client_instance.cc:588      1| ClientInstance::PJRT_Client_PlatformName
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]     client_instance.cc:618      1| ClientInstance::PJRT_Client_Devices
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-01-05 17:23:09.689 (  11.750s) [        7BAA3480]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     client_instance.cc:631      1| ClientInstance::PJRT_Client_AddressableDevices
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     client_instance.cc:681      1| ClientInstance::PJRT_Client_AddressableMemories
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-05 17:23:09.690 (  11.750s) [        7BAA3480]   plugin_attributes.cc:66       1| PluginAttributes::PJRT_Plugin_Attributes
2026-01-05 17:23:09.690204: W torch_xla/csrc/runtime/profiler.cpp:88] Profiler API not found for PJRT plugin
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:09.690 (  11.751s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.611 (  20.672s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.611 (  20.672s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.611 (  20.672s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.611 (  20.672s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.611 (  20.672s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.611 (  20.672s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.611 (  20.672s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.611 (  20.672s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.623 (  20.684s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.623 (  20.684s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.623 (  20.684s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.623 (  20.684s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.623 (  20.684s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.623 (  20.684s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.623 (  20.684s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.623 (  20.684s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.630 (  20.691s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.630 (  20.691s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.630 (  20.691s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.631 (  20.692s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.632 (  20.692s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.632 (  20.692s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.632 (  20.692s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.632 (  20.692s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.632 (  20.692s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.632 (  20.692s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.632 (  20.692s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.632 (  20.692s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.632 (  20.693s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.632 (  20.693s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.632 (  20.693s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.632 (  20.693s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.632 (  20.693s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.632 (  20.693s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.632 (  20.693s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.632 (  20.693s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.632 (  20.693s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.632 (  20.693s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.632 (  20.693s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.632 (  20.693s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.633 (  20.693s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.633 (  20.693s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.633 (  20.693s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.633 (  20.694s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.634 (  20.694s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.634 (  20.694s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.634 (  20.694s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.634 (  20.694s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.634 (  20.694s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.634 (  20.694s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.634 (  20.694s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.634 (  20.694s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.634 (  20.695s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.635 (  20.695s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.635 (  20.695s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.635 (  20.695s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.635 (  20.695s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.635 (  20.695s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.635 (  20.695s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.635 (  20.696s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.636 (  20.697s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.637 (  20.697s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.637 (  20.697s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.637 (  20.697s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.637 (  20.697s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.637 (  20.697s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.637 (  20.697s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.637 (  20.697s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.637 (  20.697s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.637 (  20.697s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.637 (  20.697s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.637 (  20.698s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.643 (  20.704s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.644 (  20.704s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.644 (  20.704s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.644 (  20.704s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.644 (  20.704s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.644 (  20.704s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.644 (  20.704s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.644 (  20.705s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.645 (  20.706s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.646 (  20.706s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.646 (  20.706s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.646 (  20.707s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.647 (  20.707s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.647 (  20.707s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.647 (  20.707s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.647 (  20.707s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.647 (  20.707s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.647 (  20.708s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.648 (  20.708s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.648 (  20.708s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.648 (  20.708s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.648 (  20.708s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.648 (  20.708s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.648 (  20.708s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:18.656 (  20.717s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.656 (  20.717s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.656 (  20.717s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:18.657 (  20.718s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:18.658 (  20.718s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:18.658 (  20.718s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.428 (  21.489s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.429 (  21.489s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.429 (  21.489s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.429 (  21.489s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.429 (  21.489s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.429 (  21.489s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.429 (  21.490s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.430 (  21.490s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.430 (  21.490s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.430 (  21.490s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.430 (  21.490s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.430 (  21.490s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.430 (  21.491s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.431 (  21.491s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.431 (  21.491s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.431 (  21.491s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.431 (  21.491s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.431 (  21.491s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     client_instance.cc:742      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:19.431 (  21.492s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.434 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.435 (  21.495s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.435 (  21.496s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.435 (  21.496s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.435 (  21.496s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.435 (  21.496s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.435 (  21.496s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.435 (  21.496s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.435 (  21.496s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.435 (  21.496s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.435 (  21.496s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.435 (  21.496s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.447 (  21.508s) [        7BAA3480]     client_instance.cc:694      1| ClientInstance::PJRT_Client_Compile
2026-01-05 17:23:19.447 (  21.508s) [        7BAA3480]     client_instance.cc:327      1| MLIR code size: 6060 bytes
=== MLIR Code (size=6060) ===
MLRStableHLO_v1.11.0
=== End MLIR Code ===
2026-01-05 17:23:19.447 (  21.508s) [        7BAA3480]      module_builder.cc:213      1| ModuleBuilder::buildModule
2026-01-05 17:23:19.451 (  21.512s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module vhlo:
#loc1 = loc("p0.1")
#loc2 = loc("p1.7")
#loc3 = loc("p2.11")
#loc4 = loc("p3.16")
#loc5 = loc("p4.37")
#loc6 = loc("p5.44")
#loc7 = loc("p6.48")
#loc8 = loc("p7.52")
#loc9 = loc("p8.73")
#loc10 = loc("p9.94")
#loc11 = loc("p10.98")
#loc70 = loc("reduce.140")
#loc75 = loc("reduce.149")
module @SyncTensorsGraph.161 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1> loc("p0.1"), %arg1: !vhlo.tensor_v1<512x!vhlo.bf16_v1> loc("p1.7"), %arg2: !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1> loc("p2.11"), %arg3: !vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1> loc("p3.16"), %arg4: !vhlo.tensor_v1<2x1x1024x1024x!vhlo.bf16_v1> loc("p4.37"), %arg5: !vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1> loc("p5.44"), %arg6: !vhlo.tensor_v1<512x!vhlo.bf16_v1> loc("p6.48"), %arg7: !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1> loc("p7.52"), %arg8: !vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1> loc("p8.73"), %arg9: !vhlo.tensor_v1<3584x!vhlo.bf16_v1> loc("p9.94"), %arg10: !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1> loc("p10.98")) -> (!vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<8.837890e-02> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %3 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1> loc(#loc)
    %4 = "vhlo.custom_call_v1"(%arg3) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1> loc(#loc12)
    %5 = "vhlo.reshape_v1"(%4) : (!vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2048x3584x!vhlo.bf16_v1> loc(#loc13)
    %6 = "vhlo.reshape_v1"(%arg10) : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1> loc(#loc14)
    %7 = "vhlo.custom_call_v1"(%6) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___q_proj_weight">}>} : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1> loc(#loc15)
    %8 = "vhlo.reshape_v1"(%7) : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1> loc(#loc16)
    %9 = "vhlo.transpose_v1"(%8) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,3584]{0,1}">} : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1> loc(#loc17)
    %10 = "vhlo.dot_general_v2"(%5, %9) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<2048x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2048x3584x!vhlo.bf16_v1> loc(#loc18)
    %11 = "vhlo.reshape_v1"(%10) : (!vhlo.tensor_v1<2048x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1> loc(#loc19)
    %12 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1> loc(#loc20)
    %13 = "vhlo.custom_call_v1"(%12) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___q_proj_bias">}>} : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1> loc(#loc21)
    %14 = "vhlo.reshape_v1"(%13) : (!vhlo.tensor_v1<1x1x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x!vhlo.bf16_v1> loc(#loc22)
    %15 = "vhlo.broadcast_in_dim_v1"(%14) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1> loc(#loc23)
    %16 = "vhlo.add_v1"(%11, %15) : (!vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1> loc(#loc24)
    %17 = "vhlo.reshape_v1"(%16) : (!vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x28x128x!vhlo.bf16_v1> loc(#loc25)
    %18 = "vhlo.transpose_v1"(%17) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,28,1024,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x1024x28x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1> loc(#loc26)
    %19 = "vhlo.custom_call_v1"(%arg8) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1> loc(#loc27)
    %20 = "vhlo.broadcast_in_dim_v1"(%19) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1> loc(#loc28)
    %21 = "vhlo.multiply_v1"(%18, %20) : (!vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1> loc(#loc29)
    %22 = "vhlo.slice_v1"(%18) <{limit_indices = #vhlo.tensor_v1<dense<[2, 28, 1024, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x64x!vhlo.bf16_v1> loc(#loc30)
    %23 = "vhlo.negate_v1"(%22) : (!vhlo.tensor_v1<2x28x1024x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x64x!vhlo.bf16_v1> loc(#loc31)
    %24 = "vhlo.slice_v1"(%18) <{limit_indices = #vhlo.tensor_v1<dense<[2, 28, 1024, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x64x!vhlo.bf16_v1> loc(#loc32)
    %25 = "vhlo.concatenate_v1"(%23, %24) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<2x28x1024x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x1024x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1> loc(#loc33)
    %26 = "vhlo.custom_call_v1"(%arg5) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_2">}>} : (!vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1> loc(#loc34)
    %27 = "vhlo.broadcast_in_dim_v1"(%26) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1> loc(#loc35)
    %28 = "vhlo.multiply_v1"(%25, %27) : (!vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1> loc(#loc36)
    %29 = "vhlo.add_v1"(%21, %28) : (!vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1> loc(#loc37)
    %30 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1> loc(#loc38)
    %31 = "vhlo.custom_call_v1"(%30) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___k_proj_weight">}>} : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1> loc(#loc39)
    %32 = "vhlo.reshape_v1"(%31) : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1> loc(#loc40)
    %33 = "vhlo.transpose_v1"(%32) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,512]{0,1}">} : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1> loc(#loc41)
    %34 = "vhlo.dot_general_v2"(%5, %33) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<2048x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2048x512x!vhlo.bf16_v1> loc(#loc42)
    %35 = "vhlo.reshape_v1"(%34) : (!vhlo.tensor_v1<2048x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x512x!vhlo.bf16_v1> loc(#loc43)
    %36 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1> loc(#loc44)
    %37 = "vhlo.custom_call_v1"(%36) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___k_proj_bias">}>} : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1> loc(#loc45)
    %38 = "vhlo.reshape_v1"(%37) : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x!vhlo.bf16_v1> loc(#loc46)
    %39 = "vhlo.broadcast_in_dim_v1"(%38) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x512x!vhlo.bf16_v1> loc(#loc47)
    %40 = "vhlo.add_v1"(%35, %39) : (!vhlo.tensor_v1<2x1024x512x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1024x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x512x!vhlo.bf16_v1> loc(#loc48)
    %41 = "vhlo.reshape_v1"(%40) : (!vhlo.tensor_v1<2x1024x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x4x128x!vhlo.bf16_v1> loc(#loc49)
    %42 = "vhlo.transpose_v1"(%41) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,4,1024,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x1024x4x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1> loc(#loc50)
    %43 = "vhlo.broadcast_in_dim_v1"(%19) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1> loc(#loc51)
    %44 = "vhlo.multiply_v1"(%42, %43) : (!vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1> loc(#loc52)
    %45 = "vhlo.slice_v1"(%42) <{limit_indices = #vhlo.tensor_v1<dense<[2, 4, 1024, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x1024x64x!vhlo.bf16_v1> loc(#loc53)
    %46 = "vhlo.negate_v1"(%45) : (!vhlo.tensor_v1<2x4x1024x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x1024x64x!vhlo.bf16_v1> loc(#loc54)
    %47 = "vhlo.slice_v1"(%42) <{limit_indices = #vhlo.tensor_v1<dense<[2, 4, 1024, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x1024x64x!vhlo.bf16_v1> loc(#loc55)
    %48 = "vhlo.concatenate_v1"(%46, %47) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<2x4x1024x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x1024x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1> loc(#loc56)
    %49 = "vhlo.broadcast_in_dim_v1"(%26) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1> loc(#loc57)
    %50 = "vhlo.multiply_v1"(%48, %49) : (!vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1> loc(#loc58)
    %51 = "vhlo.add_v1"(%44, %50) : (!vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1> loc(#loc59)
    %52 = "vhlo.broadcast_in_dim_v1"(%51) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x7x1024x128x!vhlo.bf16_v1> loc(#loc60)
    %53 = "vhlo.reshape_v1"(%52) : (!vhlo.tensor_v1<2x4x7x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1> loc(#loc61)
    %54 = "vhlo.transpose_v1"(%53) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,28,128,1024]{2,3,1,0}">} : (!vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x128x1024x!vhlo.bf16_v1> loc(#loc62)
    %55 = "vhlo.dot_general_v2"(%29, %54) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"grad_x"> = #vhlo.string_v1<"false">, #vhlo.string_v1<"grad_y"> = #vhlo.string_v1<"false">}>} : (!vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x128x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1> loc(#loc63)
    %56 = "vhlo.multiply_v1"(%55, %3) : (!vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1> loc(#loc64)
    %57 = "vhlo.custom_call_v1"(%arg4) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_3">}>} : (!vhlo.tensor_v1<2x1x1024x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x1024x1024x!vhlo.bf16_v1> loc(#loc65)
    %58 = "vhlo.reshape_v1"(%57) : (!vhlo.tensor_v1<2x1x1024x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x1024x!vhlo.bf16_v1> loc(#loc66)
    %59 = "vhlo.broadcast_in_dim_v1"(%58) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x1024x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1> loc(#loc67)
    %60 = "vhlo.add_v1"(%56, %59) : (!vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1> loc(#loc68)
    %61 = "vhlo.convert_v1"(%60) : (!vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1> loc(#loc69)
    %62 = "vhlo.reduce_v1"(%61, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg11: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.140"), %arg12: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.140")):
      %94 = "vhlo.maximum_v1"(%arg11, %arg12) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc71)
      "vhlo.return_v1"(%94) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x1024x!vhlo.f32_v1> loc(#loc70)
    %63 = "vhlo.broadcast_in_dim_v1"(%62) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x28x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1> loc(#loc72)
    %64 = "vhlo.subtract_v1"(%61, %63) : (!vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1> loc(#loc73)
    %65 = "vhlo.exponential_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1> loc(#loc74)
    %66 = "vhlo.reduce_v1"(%65, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg11: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.149"), %arg12: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.149")):
      %94 = "vhlo.add_v1"(%arg11, %arg12) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc76)
      "vhlo.return_v1"(%94) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x1024x!vhlo.f32_v1> loc(#loc75)
    %67 = "vhlo.broadcast_in_dim_v1"(%66) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<2x28x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1> loc(#loc77)
    %68 = "vhlo.divide_v1"(%65, %67) : (!vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1> loc(#loc78)
    %69 = "vhlo.convert_v1"(%68) : (!vhlo.tensor_v1<2x28x1024x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1> loc(#loc79)
    %70 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1> loc(#loc80)
    %71 = "vhlo.custom_call_v1"(%70) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___v_proj_weight">}>} : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1> loc(#loc81)
    %72 = "vhlo.reshape_v1"(%71) : (!vhlo.tensor_v1<1x512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x3584x!vhlo.bf16_v1> loc(#loc82)
    %73 = "vhlo.transpose_v1"(%72) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,512]{0,1}">} : (!vhlo.tensor_v1<512x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1> loc(#loc83)
    %74 = "vhlo.dot_general_v2"(%5, %73) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<2048x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2048x512x!vhlo.bf16_v1> loc(#loc84)
    %75 = "vhlo.reshape_v1"(%74) : (!vhlo.tensor_v1<2048x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x512x!vhlo.bf16_v1> loc(#loc85)
    %76 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1> loc(#loc86)
    %77 = "vhlo.custom_call_v1"(%76) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___v_proj_bias">}>} : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1> loc(#loc87)
    %78 = "vhlo.reshape_v1"(%77) : (!vhlo.tensor_v1<1x1x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<512x!vhlo.bf16_v1> loc(#loc88)
    %79 = "vhlo.broadcast_in_dim_v1"(%78) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x512x!vhlo.bf16_v1> loc(#loc89)
    %80 = "vhlo.add_v1"(%75, %79) : (!vhlo.tensor_v1<2x1024x512x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x1024x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x512x!vhlo.bf16_v1> loc(#loc90)
    %81 = "vhlo.reshape_v1"(%80) : (!vhlo.tensor_v1<2x1024x512x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x4x128x!vhlo.bf16_v1> loc(#loc91)
    %82 = "vhlo.transpose_v1"(%81) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,4,1024,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x1024x4x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1> loc(#loc92)
    %83 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<2x4x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x4x7x1024x128x!vhlo.bf16_v1> loc(#loc93)
    %84 = "vhlo.reshape_v1"(%83) : (!vhlo.tensor_v1<2x4x7x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1> loc(#loc94)
    %85 = "vhlo.dot_general_v2"(%69, %84) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"grad_x"> = #vhlo.string_v1<"false">, #vhlo.string_v1<"grad_y"> = #vhlo.string_v1<"false">}>} : (!vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1> loc(#loc95)
    %86 = "vhlo.transpose_v1"(%85) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[2,1024,28,128]{3,1,2,0}">} : (!vhlo.tensor_v1<2x28x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x28x128x!vhlo.bf16_v1> loc(#loc96)
    %87 = "vhlo.reshape_v1"(%86) : (!vhlo.tensor_v1<2x1024x28x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2048x3584x!vhlo.bf16_v1> loc(#loc97)
    %88 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1> loc(#loc98)
    %89 = "vhlo.custom_call_v1"(%88) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___o_proj_weight">}>} : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1> loc(#loc99)
    %90 = "vhlo.reshape_v1"(%89) : (!vhlo.tensor_v1<1x3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1> loc(#loc100)
    %91 = "vhlo.transpose_v1"(%90) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3584,3584]{0,1}">} : (!vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1> loc(#loc101)
    %92 = "vhlo.dot_general_v2"(%87, %91) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<2048x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<3584x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2048x3584x!vhlo.bf16_v1> loc(#loc102)
    %93 = "vhlo.reshape_v1"(%92) : (!vhlo.tensor_v1<2048x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1> loc(#loc103)
    "vhlo.return_v1"(%93, %69) : (!vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1>, !vhlo.tensor_v1<2x28x1024x1024x!vhlo.bf16_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_1\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,4,2]<=[2,4]T(1,0) last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,2]<=[2,4]T(1,0) last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,1,1,4]<=[8] last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,2]<=[2,4]T(1,0) last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[4,1,2]<=[2,4]T(1,0) last_tile_dim_replicate}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc12 = loc("custom-call.17")
#loc13 = loc("reshape.103")
#loc14 = loc("reshape.99")
#loc15 = loc("custom-call.100")
#loc16 = loc("reshape.101")
#loc17 = loc("transpose.102")
#loc18 = loc("dot.104")
#loc19 = loc("reshape.105")
#loc20 = loc("reshape.95")
#loc21 = loc("custom-call.96")
#loc22 = loc("reshape.97")
#loc23 = loc("broadcast.108")
#loc24 = loc("add.109")
#loc25 = loc("reshape.110")
#loc26 = loc("transpose.111")
#loc27 = loc("custom-call.74")
#loc28 = loc("broadcast.120")
#loc29 = loc("multiply.121")
#loc30 = loc("slice.113")
#loc31 = loc("negate.114")
#loc32 = loc("slice.112")
#loc33 = loc("concatenate.115")
#loc34 = loc("custom-call.45")
#loc35 = loc("broadcast.117")
#loc36 = loc("multiply.118")
#loc37 = loc("add.124")
#loc38 = loc("reshape.53")
#loc39 = loc("custom-call.54")
#loc40 = loc("reshape.55")
#loc41 = loc("transpose.56")
#loc42 = loc("dot.58")
#loc43 = loc("reshape.59")
#loc44 = loc("reshape.49")
#loc45 = loc("custom-call.50")
#loc46 = loc("reshape.51")
#loc47 = loc("broadcast.62")
#loc48 = loc("add.63")
#loc49 = loc("reshape.64")
#loc50 = loc("transpose.65")
#loc51 = loc("broadcast.77")
#loc52 = loc("multiply.78")
#loc53 = loc("slice.67")
#loc54 = loc("negate.68")
#loc55 = loc("slice.66")
#loc56 = loc("concatenate.69")
#loc57 = loc("broadcast.71")
#loc58 = loc("multiply.72")
#loc59 = loc("add.81")
#loc60 = loc("broadcast.89")
#loc61 = loc("reshape.90")
#loc62 = loc("transpose.91")
#loc63 = loc("dot.125")
#loc64 = loc("multiply.128")
#loc65 = loc("custom-call.38")
#loc66 = loc("reshape.131")
#loc67 = loc("broadcast.132")
#loc68 = loc("add.133")
#loc69 = loc("convert.134")
#loc71 = loc("maximum.139")
#loc72 = loc("broadcast.141")
#loc73 = loc("subtract.142")
#loc74 = loc("exponential.143")
#loc76 = loc("add.148")
#loc77 = loc("broadcast.150")
#loc78 = loc("divide.151")
#loc79 = loc("convert.152")
#loc80 = loc("reshape.12")
#loc81 = loc("custom-call.13")
#loc82 = loc("reshape.14")
#loc83 = loc("transpose.15")
#loc84 = loc("dot.19")
#loc85 = loc("reshape.20")
#loc86 = loc("reshape.8")
#loc87 = loc("custom-call.9")
#loc88 = loc("reshape.10")
#loc89 = loc("broadcast.23")
#loc90 = loc("add.24")
#loc91 = loc("reshape.25")
#loc92 = loc("transpose.26")
#loc93 = loc("broadcast.34")
#loc94 = loc("reshape.35")
#loc95 = loc("dot.153")
#loc96 = loc("transpose.155")
#loc97 = loc("reshape.157")
#loc98 = loc("reshape.2")
#loc99 = loc("custom-call.3")
#loc100 = loc("reshape.4")
#loc101 = loc("transpose.5")
#loc102 = loc("dot.158")
#loc103 = loc("reshape.159")
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.470 (  21.531s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo:
#loc1 = loc("p0.1")
#loc2 = loc("p1.7")
#loc3 = loc("p2.11")
#loc4 = loc("p3.16")
#loc5 = loc("p4.37")
#loc6 = loc("p5.44")
#loc7 = loc("p6.48")
#loc8 = loc("p7.52")
#loc9 = loc("p8.73")
#loc10 = loc("p9.94")
#loc11 = loc("p10.98")
module @SyncTensorsGraph.161 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[1,4,2]<=[2,4]T(1,0) last_tile_dim_replicate}"} loc("p0.1"), %arg1: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p1.7"), %arg2: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,2]<=[2,4]T(1,0) last_tile_dim_replicate}"} loc("p2.11"), %arg3: tensor<2x1024x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}"} loc("p3.16"), %arg4: tensor<2x1x1024x1024xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,1,4]<=[8] last_tile_dim_replicate}"} loc("p4.37"), %arg5: tensor<2x1024x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}"} loc("p5.44"), %arg6: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p6.48"), %arg7: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,2]<=[2,4]T(1,0) last_tile_dim_replicate}"} loc("p7.52"), %arg8: tensor<2x1024x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}"} loc("p8.73"), %arg9: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p9.94"), %arg10: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,2]<=[2,4]T(1,0) last_tile_dim_replicate}"} loc("p10.98")) -> (tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16>) {
    %cst = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<8.837890e-02> : tensor<bf16> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<bf16>) -> tensor<2x28x1024x1024xbf16> loc(#loc)
    %1 = stablehlo.custom_call @tt.mark_argument(%arg3) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<2x1024x3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc12)
    %2 = stablehlo.reshape %1 : (tensor<2x1024x3584xbf16>) -> tensor<2048x3584xbf16> loc(#loc13)
    %3 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16> loc(#loc14)
    %4 = stablehlo.custom_call @tt.mark_argument(%3) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___q_proj_weight"}} : (tensor<1x3584x3584xbf16>) -> tensor<1x3584x3584xbf16> loc(#loc15)
    %5 = stablehlo.reshape %4 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc16)
    %6 = stablehlo.transpose %5, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc17)
    %7 = stablehlo.dot_general %2, %6, contracting_dims = [1] x [0] : (tensor<2048x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<2048x3584xbf16> loc(#loc18)
    %8 = stablehlo.reshape %7 : (tensor<2048x3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc19)
    %9 = stablehlo.reshape %arg9 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc20)
    %10 = stablehlo.custom_call @tt.mark_argument(%9) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___q_proj_bias"}} : (tensor<1x1x3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc21)
    %11 = stablehlo.reshape %10 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16> loc(#loc22)
    %12 = stablehlo.broadcast_in_dim %11, dims = [2] : (tensor<3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc23)
    %13 = stablehlo.add %8, %12 : tensor<2x1024x3584xbf16> loc(#loc24)
    %14 = stablehlo.reshape %13 : (tensor<2x1024x3584xbf16>) -> tensor<2x1024x28x128xbf16> loc(#loc25)
    %15 = stablehlo.transpose %14, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,1024,128]{3,1,2,0}"} : (tensor<2x1024x28x128xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc26)
    %16 = stablehlo.custom_call @tt.mark_argument(%arg8) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<2x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc27)
    %17 = stablehlo.broadcast_in_dim %16, dims = [0, 2, 3] : (tensor<2x1024x128xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc28)
    %18 = stablehlo.multiply %15, %17 : tensor<2x28x1024x128xbf16> loc(#loc29)
    %19 = stablehlo.slice %15 [0:2, 0:28, 0:1024, 64:128] : (tensor<2x28x1024x128xbf16>) -> tensor<2x28x1024x64xbf16> loc(#loc30)
    %20 = stablehlo.negate %19 : tensor<2x28x1024x64xbf16> loc(#loc31)
    %21 = stablehlo.slice %15 [0:2, 0:28, 0:1024, 0:64] : (tensor<2x28x1024x128xbf16>) -> tensor<2x28x1024x64xbf16> loc(#loc32)
    %22 = stablehlo.concatenate %20, %21, dim = 3 : (tensor<2x28x1024x64xbf16>, tensor<2x28x1024x64xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc33)
    %23 = stablehlo.custom_call @tt.mark_argument(%arg5) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_2"}} : (tensor<2x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc34)
    %24 = stablehlo.broadcast_in_dim %23, dims = [0, 2, 3] : (tensor<2x1024x128xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc35)
    %25 = stablehlo.multiply %22, %24 : tensor<2x28x1024x128xbf16> loc(#loc36)
    %26 = stablehlo.add %18, %25 : tensor<2x28x1024x128xbf16> loc(#loc37)
    %27 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16> loc(#loc38)
    %28 = stablehlo.custom_call @tt.mark_argument(%27) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___k_proj_weight"}} : (tensor<1x512x3584xbf16>) -> tensor<1x512x3584xbf16> loc(#loc39)
    %29 = stablehlo.reshape %28 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16> loc(#loc40)
    %30 = stablehlo.transpose %29, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16> loc(#loc41)
    %31 = stablehlo.dot_general %2, %30, contracting_dims = [1] x [0] : (tensor<2048x3584xbf16>, tensor<3584x512xbf16>) -> tensor<2048x512xbf16> loc(#loc42)
    %32 = stablehlo.reshape %31 : (tensor<2048x512xbf16>) -> tensor<2x1024x512xbf16> loc(#loc43)
    %33 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16> loc(#loc44)
    %34 = stablehlo.custom_call @tt.mark_argument(%33) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___k_proj_bias"}} : (tensor<1x1x512xbf16>) -> tensor<1x1x512xbf16> loc(#loc45)
    %35 = stablehlo.reshape %34 : (tensor<1x1x512xbf16>) -> tensor<512xbf16> loc(#loc46)
    %36 = stablehlo.broadcast_in_dim %35, dims = [2] : (tensor<512xbf16>) -> tensor<2x1024x512xbf16> loc(#loc47)
    %37 = stablehlo.add %32, %36 : tensor<2x1024x512xbf16> loc(#loc48)
    %38 = stablehlo.reshape %37 : (tensor<2x1024x512xbf16>) -> tensor<2x1024x4x128xbf16> loc(#loc49)
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,1024,128]{3,1,2,0}"} : (tensor<2x1024x4x128xbf16>) -> tensor<2x4x1024x128xbf16> loc(#loc50)
    %40 = stablehlo.broadcast_in_dim %16, dims = [0, 2, 3] : (tensor<2x1024x128xbf16>) -> tensor<2x4x1024x128xbf16> loc(#loc51)
    %41 = stablehlo.multiply %39, %40 : tensor<2x4x1024x128xbf16> loc(#loc52)
    %42 = stablehlo.slice %39 [0:2, 0:4, 0:1024, 64:128] : (tensor<2x4x1024x128xbf16>) -> tensor<2x4x1024x64xbf16> loc(#loc53)
    %43 = stablehlo.negate %42 : tensor<2x4x1024x64xbf16> loc(#loc54)
    %44 = stablehlo.slice %39 [0:2, 0:4, 0:1024, 0:64] : (tensor<2x4x1024x128xbf16>) -> tensor<2x4x1024x64xbf16> loc(#loc55)
    %45 = stablehlo.concatenate %43, %44, dim = 3 : (tensor<2x4x1024x64xbf16>, tensor<2x4x1024x64xbf16>) -> tensor<2x4x1024x128xbf16> loc(#loc56)
    %46 = stablehlo.broadcast_in_dim %23, dims = [0, 2, 3] : (tensor<2x1024x128xbf16>) -> tensor<2x4x1024x128xbf16> loc(#loc57)
    %47 = stablehlo.multiply %45, %46 : tensor<2x4x1024x128xbf16> loc(#loc58)
    %48 = stablehlo.add %41, %47 : tensor<2x4x1024x128xbf16> loc(#loc59)
    %49 = stablehlo.broadcast_in_dim %48, dims = [0, 1, 3, 4] : (tensor<2x4x1024x128xbf16>) -> tensor<2x4x7x1024x128xbf16> loc(#loc60)
    %50 = stablehlo.reshape %49 : (tensor<2x4x7x1024x128xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc61)
    %51 = stablehlo.transpose %50, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,1024]{2,3,1,0}"} : (tensor<2x28x1024x128xbf16>) -> tensor<2x28x128x1024xbf16> loc(#loc62)
    %52 = stablehlo.dot_general %26, %51, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<2x28x1024x128xbf16>, tensor<2x28x128x1024xbf16>) -> tensor<2x28x1024x1024xbf16> loc(#loc63)
    %53 = stablehlo.multiply %52, %0 : tensor<2x28x1024x1024xbf16> loc(#loc64)
    %54 = stablehlo.custom_call @tt.mark_argument(%arg4) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_3"}} : (tensor<2x1x1024x1024xbf16>) -> tensor<2x1x1024x1024xbf16> loc(#loc65)
    %55 = stablehlo.reshape %54 : (tensor<2x1x1024x1024xbf16>) -> tensor<2x1024x1024xbf16> loc(#loc66)
    %56 = stablehlo.broadcast_in_dim %55, dims = [0, 2, 3] : (tensor<2x1024x1024xbf16>) -> tensor<2x28x1024x1024xbf16> loc(#loc67)
    %57 = stablehlo.add %53, %56 : tensor<2x28x1024x1024xbf16> loc(#loc68)
    %58 = stablehlo.convert %57 : (tensor<2x28x1024x1024xbf16>) -> tensor<2x28x1024x1024xf32> loc(#loc69)
    %59 = stablehlo.reduce(%58 init: %cst) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x1024x1024xf32>, tensor<f32>) -> tensor<2x28x1024xf32> loc(#loc70)
    %60 = stablehlo.broadcast_in_dim %59, dims = [0, 1, 2] : (tensor<2x28x1024xf32>) -> tensor<2x28x1024x1024xf32> loc(#loc71)
    %61 = stablehlo.subtract %58, %60 : tensor<2x28x1024x1024xf32> loc(#loc72)
    %62 = stablehlo.exponential %61 : tensor<2x28x1024x1024xf32> loc(#loc73)
    %63 = stablehlo.reduce(%62 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<2x28x1024x1024xf32>, tensor<f32>) -> tensor<2x28x1024xf32> loc(#loc74)
    %64 = stablehlo.broadcast_in_dim %63, dims = [0, 1, 2] : (tensor<2x28x1024xf32>) -> tensor<2x28x1024x1024xf32> loc(#loc75)
    %65 = stablehlo.divide %62, %64 : tensor<2x28x1024x1024xf32> loc(#loc76)
    %66 = stablehlo.convert %65 : (tensor<2x28x1024x1024xf32>) -> tensor<2x28x1024x1024xbf16> loc(#loc77)
    %67 = stablehlo.reshape %arg2 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16> loc(#loc78)
    %68 = stablehlo.custom_call @tt.mark_argument(%67) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___v_proj_weight"}} : (tensor<1x512x3584xbf16>) -> tensor<1x512x3584xbf16> loc(#loc79)
    %69 = stablehlo.reshape %68 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16> loc(#loc80)
    %70 = stablehlo.transpose %69, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16> loc(#loc81)
    %71 = stablehlo.dot_general %2, %70, contracting_dims = [1] x [0] : (tensor<2048x3584xbf16>, tensor<3584x512xbf16>) -> tensor<2048x512xbf16> loc(#loc82)
    %72 = stablehlo.reshape %71 : (tensor<2048x512xbf16>) -> tensor<2x1024x512xbf16> loc(#loc83)
    %73 = stablehlo.reshape %arg1 : (tensor<512xbf16>) -> tensor<1x1x512xbf16> loc(#loc84)
    %74 = stablehlo.custom_call @tt.mark_argument(%73) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___v_proj_bias"}} : (tensor<1x1x512xbf16>) -> tensor<1x1x512xbf16> loc(#loc85)
    %75 = stablehlo.reshape %74 : (tensor<1x1x512xbf16>) -> tensor<512xbf16> loc(#loc86)
    %76 = stablehlo.broadcast_in_dim %75, dims = [2] : (tensor<512xbf16>) -> tensor<2x1024x512xbf16> loc(#loc87)
    %77 = stablehlo.add %72, %76 : tensor<2x1024x512xbf16> loc(#loc88)
    %78 = stablehlo.reshape %77 : (tensor<2x1024x512xbf16>) -> tensor<2x1024x4x128xbf16> loc(#loc89)
    %79 = stablehlo.transpose %78, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,1024,128]{3,1,2,0}"} : (tensor<2x1024x4x128xbf16>) -> tensor<2x4x1024x128xbf16> loc(#loc90)
    %80 = stablehlo.broadcast_in_dim %79, dims = [0, 1, 3, 4] : (tensor<2x4x1024x128xbf16>) -> tensor<2x4x7x1024x128xbf16> loc(#loc91)
    %81 = stablehlo.reshape %80 : (tensor<2x4x7x1024x128xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc92)
    %82 = stablehlo.dot_general %66, %81, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<2x28x1024x1024xbf16>, tensor<2x28x1024x128xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc93)
    %83 = stablehlo.transpose %82, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,1024,28,128]{3,1,2,0}"} : (tensor<2x28x1024x128xbf16>) -> tensor<2x1024x28x128xbf16> loc(#loc94)
    %84 = stablehlo.reshape %83 : (tensor<2x1024x28x128xbf16>) -> tensor<2048x3584xbf16> loc(#loc95)
    %85 = stablehlo.reshape %arg0 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16> loc(#loc96)
    %86 = stablehlo.custom_call @tt.mark_argument(%85) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___o_proj_weight"}} : (tensor<1x3584x3584xbf16>) -> tensor<1x3584x3584xbf16> loc(#loc97)
    %87 = stablehlo.reshape %86 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc98)
    %88 = stablehlo.transpose %87, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc99)
    %89 = stablehlo.dot_general %84, %88, contracting_dims = [1] x [0] : (tensor<2048x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<2048x3584xbf16> loc(#loc100)
    %90 = stablehlo.reshape %89 : (tensor<2048x3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc101)
    return %90, %66 : tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc12 = loc("custom-call.17")
#loc13 = loc("reshape.103")
#loc14 = loc("reshape.99")
#loc15 = loc("custom-call.100")
#loc16 = loc("reshape.101")
#loc17 = loc("transpose.102")
#loc18 = loc("dot.104")
#loc19 = loc("reshape.105")
#loc20 = loc("reshape.95")
#loc21 = loc("custom-call.96")
#loc22 = loc("reshape.97")
#loc23 = loc("broadcast.108")
#loc24 = loc("add.109")
#loc25 = loc("reshape.110")
#loc26 = loc("transpose.111")
#loc27 = loc("custom-call.74")
#loc28 = loc("broadcast.120")
#loc29 = loc("multiply.121")
#loc30 = loc("slice.113")
#loc31 = loc("negate.114")
#loc32 = loc("slice.112")
#loc33 = loc("concatenate.115")
#loc34 = loc("custom-call.45")
#loc35 = loc("broadcast.117")
#loc36 = loc("multiply.118")
#loc37 = loc("add.124")
#loc38 = loc("reshape.53")
#loc39 = loc("custom-call.54")
#loc40 = loc("reshape.55")
#loc41 = loc("transpose.56")
#loc42 = loc("dot.58")
#loc43 = loc("reshape.59")
#loc44 = loc("reshape.49")
#loc45 = loc("custom-call.50")
#loc46 = loc("reshape.51")
#loc47 = loc("broadcast.62")
#loc48 = loc("add.63")
#loc49 = loc("reshape.64")
#loc50 = loc("transpose.65")
#loc51 = loc("broadcast.77")
#loc52 = loc("multiply.78")
#loc53 = loc("slice.67")
#loc54 = loc("negate.68")
#loc55 = loc("slice.66")
#loc56 = loc("concatenate.69")
#loc57 = loc("broadcast.71")
#loc58 = loc("multiply.72")
#loc59 = loc("add.81")
#loc60 = loc("broadcast.89")
#loc61 = loc("reshape.90")
#loc62 = loc("transpose.91")
#loc63 = loc("dot.125")
#loc64 = loc("multiply.128")
#loc65 = loc("custom-call.38")
#loc66 = loc("reshape.131")
#loc67 = loc("broadcast.132")
#loc68 = loc("add.133")
#loc69 = loc("convert.134")
#loc70 = loc("reduce.140")
#loc71 = loc("broadcast.141")
#loc72 = loc("subtract.142")
#loc73 = loc("exponential.143")
#loc74 = loc("reduce.149")
#loc75 = loc("broadcast.150")
#loc76 = loc("divide.151")
#loc77 = loc("convert.152")
#loc78 = loc("reshape.12")
#loc79 = loc("custom-call.13")
#loc80 = loc("reshape.14")
#loc81 = loc("transpose.15")
#loc82 = loc("dot.19")
#loc83 = loc("reshape.20")
#loc84 = loc("reshape.8")
#loc85 = loc("custom-call.9")
#loc86 = loc("reshape.10")
#loc87 = loc("broadcast.23")
#loc88 = loc("add.24")
#loc89 = loc("reshape.25")
#loc90 = loc("transpose.26")
#loc91 = loc("broadcast.34")
#loc92 = loc("reshape.35")
#loc93 = loc("dot.153")
#loc94 = loc("transpose.155")
#loc95 = loc("reshape.157")
#loc96 = loc("reshape.2")
#loc97 = loc("custom-call.3")
#loc98 = loc("reshape.4")
#loc99 = loc("transpose.5")
#loc100 = loc("dot.158")
#loc101 = loc("reshape.159")
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.477 (  21.537s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_frontend:
#loc1 = loc("p0.1")
#loc2 = loc("p1.7")
#loc3 = loc("p2.11")
#loc4 = loc("p3.16")
#loc5 = loc("p4.37")
#loc6 = loc("p5.44")
#loc7 = loc("p6.48")
#loc8 = loc("p7.52")
#loc9 = loc("p8.73")
#loc10 = loc("p9.94")
#loc11 = loc("p10.98")
module @SyncTensorsGraph.161 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_1\22}]>"}, mhlo.sharding = "{devices=[1,4,2]<=[2,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___o_proj_weight"} loc("p0.1"), %arg1: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___v_proj_bias"} loc("p1.7"), %arg2: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,2]<=[2,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___v_proj_weight"} loc("p2.11"), %arg3: tensor<2x1024x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("p3.16"), %arg4: tensor<2x1x1024x1024xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_3"} loc("p4.37"), %arg5: tensor<2x1024x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"} loc("p5.44"), %arg6: tensor<512xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___k_proj_bias"} loc("p6.48"), %arg7: tensor<512x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,2]<=[2,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___k_proj_weight"} loc("p7.52"), %arg8: tensor<2x1024x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"} loc("p8.73"), %arg9: tensor<3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___q_proj_bias"} loc("p9.94"), %arg10: tensor<3584x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_1\22}, {}]>"}, mhlo.sharding = "{devices=[4,1,2]<=[2,4]T(1,0) last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___q_proj_weight"} loc("p10.98")) -> (tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16>) {
    %cst = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_1 = stablehlo.constant dense<8.837890e-02> : tensor<bf16> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<bf16>) -> tensor<2x28x1024x1024xbf16> loc(#loc)
    %1 = stablehlo.reshape %arg3 : (tensor<2x1024x3584xbf16>) -> tensor<2048x3584xbf16> loc(#loc12)
    %2 = stablehlo.reshape %arg10 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16> loc(#loc13)
    %3 = stablehlo.reshape %2 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc14)
    %4 = stablehlo.transpose %3, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc15)
    %5 = stablehlo.dot_general %1, %4, contracting_dims = [1] x [0] : (tensor<2048x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<2048x3584xbf16> loc(#loc16)
    %6 = stablehlo.reshape %5 : (tensor<2048x3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc17)
    %7 = stablehlo.reshape %arg9 : (tensor<3584xbf16>) -> tensor<1x1x3584xbf16> loc(#loc18)
    %8 = stablehlo.reshape %7 : (tensor<1x1x3584xbf16>) -> tensor<3584xbf16> loc(#loc19)
    %9 = stablehlo.broadcast_in_dim %8, dims = [2] : (tensor<3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc20)
    %10 = stablehlo.add %6, %9 : tensor<2x1024x3584xbf16> loc(#loc21)
    %11 = stablehlo.reshape %10 : (tensor<2x1024x3584xbf16>) -> tensor<2x1024x28x128xbf16> loc(#loc22)
    %12 = stablehlo.transpose %11, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,1024,128]{3,1,2,0}"} : (tensor<2x1024x28x128xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc23)
    %13 = stablehlo.broadcast_in_dim %arg8, dims = [0, 2, 3] : (tensor<2x1024x128xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc24)
    %14 = stablehlo.multiply %12, %13 : tensor<2x28x1024x128xbf16> loc(#loc25)
    %15 = stablehlo.slice %12 [0:2, 0:28, 0:1024, 64:128] : (tensor<2x28x1024x128xbf16>) -> tensor<2x28x1024x64xbf16> loc(#loc26)
    %16 = stablehlo.negate %15 : tensor<2x28x1024x64xbf16> loc(#loc27)
    %17 = stablehlo.slice %12 [0:2, 0:28, 0:1024, 0:64] : (tensor<2x28x1024x128xbf16>) -> tensor<2x28x1024x64xbf16> loc(#loc28)
    %18 = stablehlo.concatenate %16, %17, dim = 3 : (tensor<2x28x1024x64xbf16>, tensor<2x28x1024x64xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc29)
    %19 = stablehlo.broadcast_in_dim %arg5, dims = [0, 2, 3] : (tensor<2x1024x128xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc30)
    %20 = stablehlo.multiply %18, %19 : tensor<2x28x1024x128xbf16> loc(#loc31)
    %21 = stablehlo.add %14, %20 : tensor<2x28x1024x128xbf16> loc(#loc32)
    %22 = stablehlo.reshape %arg7 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16> loc(#loc33)
    %23 = stablehlo.reshape %22 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16> loc(#loc34)
    %24 = stablehlo.transpose %23, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16> loc(#loc35)
    %25 = stablehlo.dot_general %1, %24, contracting_dims = [1] x [0] : (tensor<2048x3584xbf16>, tensor<3584x512xbf16>) -> tensor<2048x512xbf16> loc(#loc36)
    %26 = stablehlo.reshape %25 : (tensor<2048x512xbf16>) -> tensor<2x1024x512xbf16> loc(#loc37)
    %27 = stablehlo.reshape %arg6 : (tensor<512xbf16>) -> tensor<1x1x512xbf16> loc(#loc38)
    %28 = stablehlo.reshape %27 : (tensor<1x1x512xbf16>) -> tensor<512xbf16> loc(#loc39)
    %29 = stablehlo.broadcast_in_dim %28, dims = [2] : (tensor<512xbf16>) -> tensor<2x1024x512xbf16> loc(#loc40)
    %30 = stablehlo.add %26, %29 : tensor<2x1024x512xbf16> loc(#loc41)
    %31 = stablehlo.reshape %30 : (tensor<2x1024x512xbf16>) -> tensor<2x1024x4x128xbf16> loc(#loc42)
    %32 = stablehlo.transpose %31, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,1024,128]{3,1,2,0}"} : (tensor<2x1024x4x128xbf16>) -> tensor<2x4x1024x128xbf16> loc(#loc43)
    %33 = stablehlo.broadcast_in_dim %arg8, dims = [0, 2, 3] : (tensor<2x1024x128xbf16>) -> tensor<2x4x1024x128xbf16> loc(#loc44)
    %34 = stablehlo.multiply %32, %33 : tensor<2x4x1024x128xbf16> loc(#loc45)
    %35 = stablehlo.slice %32 [0:2, 0:4, 0:1024, 64:128] : (tensor<2x4x1024x128xbf16>) -> tensor<2x4x1024x64xbf16> loc(#loc46)
    %36 = stablehlo.negate %35 : tensor<2x4x1024x64xbf16> loc(#loc47)
    %37 = stablehlo.slice %32 [0:2, 0:4, 0:1024, 0:64] : (tensor<2x4x1024x128xbf16>) -> tensor<2x4x1024x64xbf16> loc(#loc48)
    %38 = stablehlo.concatenate %36, %37, dim = 3 : (tensor<2x4x1024x64xbf16>, tensor<2x4x1024x64xbf16>) -> tensor<2x4x1024x128xbf16> loc(#loc49)
    %39 = stablehlo.broadcast_in_dim %arg5, dims = [0, 2, 3] : (tensor<2x1024x128xbf16>) -> tensor<2x4x1024x128xbf16> loc(#loc50)
    %40 = stablehlo.multiply %38, %39 : tensor<2x4x1024x128xbf16> loc(#loc51)
    %41 = stablehlo.add %34, %40 : tensor<2x4x1024x128xbf16> loc(#loc52)
    %42 = stablehlo.broadcast_in_dim %41, dims = [0, 1, 3, 4] : (tensor<2x4x1024x128xbf16>) -> tensor<2x4x7x1024x128xbf16> loc(#loc53)
    %43 = stablehlo.reshape %42 : (tensor<2x4x7x1024x128xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc54)
    %44 = stablehlo.transpose %43, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,1024]{2,3,1,0}"} : (tensor<2x28x1024x128xbf16>) -> tensor<2x28x128x1024xbf16> loc(#loc55)
    %45 = stablehlo.dot_general %21, %44, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<2x28x1024x128xbf16>, tensor<2x28x128x1024xbf16>) -> tensor<2x28x1024x1024xbf16> loc(#loc56)
    %46 = stablehlo.multiply %45, %0 : tensor<2x28x1024x1024xbf16> loc(#loc57)
    %47 = stablehlo.reshape %arg4 : (tensor<2x1x1024x1024xbf16>) -> tensor<2x1024x1024xbf16> loc(#loc58)
    %48 = stablehlo.broadcast_in_dim %47, dims = [0, 2, 3] : (tensor<2x1024x1024xbf16>) -> tensor<2x28x1024x1024xbf16> loc(#loc59)
    %49 = stablehlo.add %46, %48 : tensor<2x28x1024x1024xbf16> loc(#loc60)
    %50 = stablehlo.convert %49 : (tensor<2x28x1024x1024xbf16>) -> tensor<2x28x1024x1024xf32> loc(#loc61)
    %51 = stablehlo.reduce(%50 init: %cst) applies stablehlo.maximum across dimensions = [3] : (tensor<2x28x1024x1024xf32>, tensor<f32>) -> tensor<2x28x1024xf32> loc(#loc62)
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 1, 2] : (tensor<2x28x1024xf32>) -> tensor<2x28x1024x1024xf32> loc(#loc63)
    %53 = stablehlo.subtract %50, %52 : tensor<2x28x1024x1024xf32> loc(#loc64)
    %54 = stablehlo.exponential %53 : tensor<2x28x1024x1024xf32> loc(#loc65)
    %55 = stablehlo.reduce(%54 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<2x28x1024x1024xf32>, tensor<f32>) -> tensor<2x28x1024xf32> loc(#loc66)
    %56 = stablehlo.broadcast_in_dim %55, dims = [0, 1, 2] : (tensor<2x28x1024xf32>) -> tensor<2x28x1024x1024xf32> loc(#loc67)
    %57 = stablehlo.divide %54, %56 : tensor<2x28x1024x1024xf32> loc(#loc68)
    %58 = stablehlo.convert %57 : (tensor<2x28x1024x1024xf32>) -> tensor<2x28x1024x1024xbf16> loc(#loc69)
    %59 = stablehlo.reshape %arg2 : (tensor<512x3584xbf16>) -> tensor<1x512x3584xbf16> loc(#loc70)
    %60 = stablehlo.reshape %59 : (tensor<1x512x3584xbf16>) -> tensor<512x3584xbf16> loc(#loc71)
    %61 = stablehlo.transpose %60, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<512x3584xbf16>) -> tensor<3584x512xbf16> loc(#loc72)
    %62 = stablehlo.dot_general %1, %61, contracting_dims = [1] x [0] : (tensor<2048x3584xbf16>, tensor<3584x512xbf16>) -> tensor<2048x512xbf16> loc(#loc73)
    %63 = stablehlo.reshape %62 : (tensor<2048x512xbf16>) -> tensor<2x1024x512xbf16> loc(#loc74)
    %64 = stablehlo.reshape %arg1 : (tensor<512xbf16>) -> tensor<1x1x512xbf16> loc(#loc75)
    %65 = stablehlo.reshape %64 : (tensor<1x1x512xbf16>) -> tensor<512xbf16> loc(#loc76)
    %66 = stablehlo.broadcast_in_dim %65, dims = [2] : (tensor<512xbf16>) -> tensor<2x1024x512xbf16> loc(#loc77)
    %67 = stablehlo.add %63, %66 : tensor<2x1024x512xbf16> loc(#loc78)
    %68 = stablehlo.reshape %67 : (tensor<2x1024x512xbf16>) -> tensor<2x1024x4x128xbf16> loc(#loc79)
    %69 = stablehlo.transpose %68, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,1024,128]{3,1,2,0}"} : (tensor<2x1024x4x128xbf16>) -> tensor<2x4x1024x128xbf16> loc(#loc80)
    %70 = stablehlo.broadcast_in_dim %69, dims = [0, 1, 3, 4] : (tensor<2x4x1024x128xbf16>) -> tensor<2x4x7x1024x128xbf16> loc(#loc81)
    %71 = stablehlo.reshape %70 : (tensor<2x4x7x1024x128xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc82)
    %72 = stablehlo.dot_general %58, %71, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<2x28x1024x1024xbf16>, tensor<2x28x1024x128xbf16>) -> tensor<2x28x1024x128xbf16> loc(#loc83)
    %73 = stablehlo.transpose %72, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,1024,28,128]{3,1,2,0}"} : (tensor<2x28x1024x128xbf16>) -> tensor<2x1024x28x128xbf16> loc(#loc84)
    %74 = stablehlo.reshape %73 : (tensor<2x1024x28x128xbf16>) -> tensor<2048x3584xbf16> loc(#loc85)
    %75 = stablehlo.reshape %arg0 : (tensor<3584x3584xbf16>) -> tensor<1x3584x3584xbf16> loc(#loc86)
    %76 = stablehlo.reshape %75 : (tensor<1x3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc87)
    %77 = stablehlo.transpose %76, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x3584xbf16>) -> tensor<3584x3584xbf16> loc(#loc88)
    %78 = stablehlo.dot_general %74, %77, contracting_dims = [1] x [0] : (tensor<2048x3584xbf16>, tensor<3584x3584xbf16>) -> tensor<2048x3584xbf16> loc(#loc89)
    %79 = stablehlo.reshape %78 : (tensor<2048x3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc90)
    return %79, %58 : tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc12 = loc("reshape.103")
#loc13 = loc("reshape.99")
#loc14 = loc("reshape.101")
#loc15 = loc("transpose.102")
#loc16 = loc("dot.104")
#loc17 = loc("reshape.105")
#loc18 = loc("reshape.95")
#loc19 = loc("reshape.97")
#loc20 = loc("broadcast.108")
#loc21 = loc("add.109")
#loc22 = loc("reshape.110")
#loc23 = loc("transpose.111")
#loc24 = loc("broadcast.120")
#loc25 = loc("multiply.121")
#loc26 = loc("slice.113")
#loc27 = loc("negate.114")
#loc28 = loc("slice.112")
#loc29 = loc("concatenate.115")
#loc30 = loc("broadcast.117")
#loc31 = loc("multiply.118")
#loc32 = loc("add.124")
#loc33 = loc("reshape.53")
#loc34 = loc("reshape.55")
#loc35 = loc("transpose.56")
#loc36 = loc("dot.58")
#loc37 = loc("reshape.59")
#loc38 = loc("reshape.49")
#loc39 = loc("reshape.51")
#loc40 = loc("broadcast.62")
#loc41 = loc("add.63")
#loc42 = loc("reshape.64")
#loc43 = loc("transpose.65")
#loc44 = loc("broadcast.77")
#loc45 = loc("multiply.78")
#loc46 = loc("slice.67")
#loc47 = loc("negate.68")
#loc48 = loc("slice.66")
#loc49 = loc("concatenate.69")
#loc50 = loc("broadcast.71")
#loc51 = loc("multiply.72")
#loc52 = loc("add.81")
#loc53 = loc("broadcast.89")
#loc54 = loc("reshape.90")
#loc55 = loc("transpose.91")
#loc56 = loc("dot.125")
#loc57 = loc("multiply.128")
#loc58 = loc("reshape.131")
#loc59 = loc("broadcast.132")
#loc60 = loc("add.133")
#loc61 = loc("convert.134")
#loc62 = loc("reduce.140")
#loc63 = loc("broadcast.141")
#loc64 = loc("subtract.142")
#loc65 = loc("exponential.143")
#loc66 = loc("reduce.149")
#loc67 = loc("broadcast.150")
#loc68 = loc("divide.151")
#loc69 = loc("convert.152")
#loc70 = loc("reshape.12")
#loc71 = loc("reshape.14")
#loc72 = loc("transpose.15")
#loc73 = loc("dot.19")
#loc74 = loc("reshape.20")
#loc75 = loc("reshape.8")
#loc76 = loc("reshape.10")
#loc77 = loc("broadcast.23")
#loc78 = loc("add.24")
#loc79 = loc("reshape.25")
#loc80 = loc("transpose.26")
#loc81 = loc("broadcast.34")
#loc82 = loc("reshape.35")
#loc83 = loc("dot.153")
#loc84 = loc("transpose.155")
#loc85 = loc("reshape.157")
#loc86 = loc("reshape.2")
#loc87 = loc("reshape.4")
#loc88 = loc("transpose.5")
#loc89 = loc("dot.158")
#loc90 = loc("reshape.159")
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.560 (  21.621s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_compiler:
#loc1 = loc("p0.1")
#loc2 = loc("p1.7")
#loc3 = loc("p2.11")
#loc4 = loc("p3.16")
#loc5 = loc("p4.37")
#loc6 = loc("p5.44")
#loc7 = loc("p6.48")
#loc8 = loc("p7.52")
#loc9 = loc("p8.73")
#loc10 = loc("p9.94")
#loc11 = loc("p10.98")
#loc89 = loc("dot.158")
module @SyncTensorsGraph.161 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]> loc(#loc)
  func.func @main(%arg0: tensor<3584x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___o_proj_weight"} loc("p0.1"), %arg1: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___v_proj_bias"} loc("p1.7"), %arg2: tensor<512x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___v_proj_weight"} loc("p2.11"), %arg3: tensor<2x1024x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p3.16"), %arg4: tensor<2x1x1024x1024xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p4.37"), %arg5: tensor<2x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p5.44"), %arg6: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___k_proj_bias"} loc("p6.48"), %arg7: tensor<512x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___k_proj_weight"} loc("p7.52"), %arg8: tensor<2x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p8.73"), %arg9: tensor<3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___q_proj_bias"} loc("p9.94"), %arg10: tensor<3584x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___q_proj_weight"} loc("p10.98")) -> (tensor<2x1024x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x28x1024x1024xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:2 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10) in_shardings=[<@mesh, [{}, {"_axis_1"}]>, <@mesh, [{}]>, <@mesh, [{"_axis_1"}, {}]>, <@mesh, [{"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}, {}, {}]>, <@mesh, [{"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_1"}, {}]>, <@mesh, [{"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_1"}, {}]>] out_shardings=[<@mesh, [{"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {"_axis_1"}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg11: tensor<3584x896xbf16> loc("p0.1"), %arg12: tensor<512xbf16> loc("p1.7"), %arg13: tensor<128x3584xbf16> loc("p2.11"), %arg14: tensor<1x1024x3584xbf16> loc("p3.16"), %arg15: tensor<1x1x1024x1024xbf16> loc("p4.37"), %arg16: tensor<1x1024x128xbf16> loc("p5.44"), %arg17: tensor<512xbf16> loc("p6.48"), %arg18: tensor<128x3584xbf16> loc("p7.52"), %arg19: tensor<1x1024x128xbf16> loc("p8.73"), %arg20: tensor<3584xbf16> loc("p9.94"), %arg21: tensor<896x3584xbf16> loc("p10.98")) {
      %cst = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
      %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
      %cst_1 = stablehlo.constant dense<8.837890e-02> : tensor<bf16> loc(#loc)
      %1 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<bf16>) -> tensor<1x7x1024x1024xbf16> loc(#loc)
      %2 = stablehlo.reshape %arg14 : (tensor<1x1024x3584xbf16>) -> tensor<1024x3584xbf16> loc(#loc12)
      %3 = stablehlo.reshape %arg21 : (tensor<896x3584xbf16>) -> tensor<1x896x3584xbf16> loc(#loc13)
      %4 = stablehlo.reshape %3 : (tensor<1x896x3584xbf16>) -> tensor<896x3584xbf16> loc(#loc14)
      %5 = stablehlo.transpose %4, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<896x3584xbf16>) -> tensor<3584x896xbf16> loc(#loc15)
      %6 = stablehlo.dot_general %2, %5, contracting_dims = [1] x [0] : (tensor<1024x3584xbf16>, tensor<3584x896xbf16>) -> tensor<1024x896xbf16> loc(#loc16)
      %7 = stablehlo.reshape %6 : (tensor<1024x896xbf16>) -> tensor<1x1024x896xbf16> loc(#loc17)
      %8 = stablehlo.reshape %arg20 : (tensor<3584xbf16>) -> tensor<4x896xbf16> loc(#loc10)
      %9 = "stablehlo.all_to_all"(%8) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7]]> : tensor<2x4xi64>, split_count = 4 : i64, split_dimension = 0 : i64}> : (tensor<4x896xbf16>) -> tensor<4x896xbf16> loc(#loc10)
      %10 = stablehlo.slice %9 [0:1, 0:896] : (tensor<4x896xbf16>) -> tensor<1x896xbf16> loc(#loc10)
      %11 = stablehlo.reshape %10 : (tensor<1x896xbf16>) -> tensor<896xbf16> loc(#loc10)
      %12 = stablehlo.reshape %11 : (tensor<896xbf16>) -> tensor<1x1x896xbf16> loc(#loc18)
      %13 = stablehlo.reshape %12 : (tensor<1x1x896xbf16>) -> tensor<896xbf16> loc(#loc19)
      %14 = stablehlo.broadcast_in_dim %13, dims = [2] : (tensor<896xbf16>) -> tensor<1x1024x896xbf16> loc(#loc20)
      %15 = stablehlo.add %7, %14 : tensor<1x1024x896xbf16> loc(#loc21)
      %16 = stablehlo.reshape %15 : (tensor<1x1024x896xbf16>) -> tensor<1x1024x7x128xbf16> loc(#loc22)
      %17 = stablehlo.transpose %16, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,1024,128]{3,1,2,0}"} : (tensor<1x1024x7x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc23)
      %18 = stablehlo.broadcast_in_dim %arg19, dims = [0, 2, 3] : (tensor<1x1024x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc24)
      %19 = stablehlo.multiply %17, %18 : tensor<1x7x1024x128xbf16> loc(#loc25)
      %20 = stablehlo.slice %17 [0:1, 0:7, 0:1024, 64:128] : (tensor<1x7x1024x128xbf16>) -> tensor<1x7x1024x64xbf16> loc(#loc26)
      %21 = stablehlo.negate %20 : tensor<1x7x1024x64xbf16> loc(#loc27)
      %22 = stablehlo.slice %17 [0:1, 0:7, 0:1024, 0:64] : (tensor<1x7x1024x128xbf16>) -> tensor<1x7x1024x64xbf16> loc(#loc28)
      %23 = stablehlo.concatenate %21, %22, dim = 3 : (tensor<1x7x1024x64xbf16>, tensor<1x7x1024x64xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc29)
      %24 = stablehlo.broadcast_in_dim %arg16, dims = [0, 2, 3] : (tensor<1x1024x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc30)
      %25 = stablehlo.multiply %23, %24 : tensor<1x7x1024x128xbf16> loc(#loc31)
      %26 = stablehlo.add %19, %25 : tensor<1x7x1024x128xbf16> loc(#loc32)
      %27 = stablehlo.reshape %arg18 : (tensor<128x3584xbf16>) -> tensor<1x128x3584xbf16> loc(#loc33)
      %28 = stablehlo.reshape %27 : (tensor<1x128x3584xbf16>) -> tensor<128x3584xbf16> loc(#loc34)
      %29 = stablehlo.transpose %28, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<128x3584xbf16>) -> tensor<3584x128xbf16> loc(#loc35)
      %30 = stablehlo.dot_general %2, %29, contracting_dims = [1] x [0] : (tensor<1024x3584xbf16>, tensor<3584x128xbf16>) -> tensor<1024x128xbf16> loc(#loc36)
      %31 = stablehlo.reshape %30 : (tensor<1024x128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc37)
      %32 = stablehlo.reshape %arg17 : (tensor<512xbf16>) -> tensor<4x128xbf16> loc(#loc7)
      %33 = "stablehlo.all_to_all"(%32) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7]]> : tensor<2x4xi64>, split_count = 4 : i64, split_dimension = 0 : i64}> : (tensor<4x128xbf16>) -> tensor<4x128xbf16> loc(#loc7)
      %34 = stablehlo.slice %33 [0:1, 0:128] : (tensor<4x128xbf16>) -> tensor<1x128xbf16> loc(#loc7)
      %35 = stablehlo.reshape %34 : (tensor<1x128xbf16>) -> tensor<128xbf16> loc(#loc7)
      %36 = stablehlo.reshape %35 : (tensor<128xbf16>) -> tensor<1x1x128xbf16> loc(#loc38)
      %37 = stablehlo.reshape %36 : (tensor<1x1x128xbf16>) -> tensor<128xbf16> loc(#loc39)
      %38 = stablehlo.broadcast_in_dim %37, dims = [2] : (tensor<128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc40)
      %39 = stablehlo.add %31, %38 : tensor<1x1024x128xbf16> loc(#loc41)
      %40 = stablehlo.reshape %39 : (tensor<1x1024x128xbf16>) -> tensor<1x1024x1x128xbf16> loc(#loc42)
      %41 = stablehlo.transpose %40, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,1024,128]{3,1,2,0}"} : (tensor<1x1024x1x128xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc43)
      %42 = stablehlo.broadcast_in_dim %arg19, dims = [0, 2, 3] : (tensor<1x1024x128xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc44)
      %43 = stablehlo.multiply %41, %42 : tensor<1x1x1024x128xbf16> loc(#loc45)
      %44 = stablehlo.slice %41 [0:1, 0:1, 0:1024, 64:128] : (tensor<1x1x1024x128xbf16>) -> tensor<1x1x1024x64xbf16> loc(#loc46)
      %45 = stablehlo.negate %44 : tensor<1x1x1024x64xbf16> loc(#loc47)
      %46 = stablehlo.slice %41 [0:1, 0:1, 0:1024, 0:64] : (tensor<1x1x1024x128xbf16>) -> tensor<1x1x1024x64xbf16> loc(#loc48)
      %47 = stablehlo.concatenate %45, %46, dim = 3 : (tensor<1x1x1024x64xbf16>, tensor<1x1x1024x64xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc49)
      %48 = stablehlo.broadcast_in_dim %arg16, dims = [0, 2, 3] : (tensor<1x1024x128xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc50)
      %49 = stablehlo.multiply %47, %48 : tensor<1x1x1024x128xbf16> loc(#loc51)
      %50 = stablehlo.add %43, %49 : tensor<1x1x1024x128xbf16> loc(#loc52)
      %51 = stablehlo.broadcast_in_dim %50, dims = [0, 1, 3, 4] : (tensor<1x1x1024x128xbf16>) -> tensor<1x1x7x1024x128xbf16> loc(#loc53)
      %52 = stablehlo.reshape %51 : (tensor<1x1x7x1024x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc54)
      %53 = stablehlo.transpose %52, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[2,28,128,1024]{2,3,1,0}"} : (tensor<1x7x1024x128xbf16>) -> tensor<1x7x128x1024xbf16> loc(#loc55)
      %54 = stablehlo.dot_general %26, %53, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x7x1024x128xbf16>, tensor<1x7x128x1024xbf16>) -> tensor<1x7x1024x1024xbf16> loc(#loc56)
      %55 = stablehlo.multiply %54, %1 : tensor<1x7x1024x1024xbf16> loc(#loc57)
      %56 = stablehlo.reshape %arg15 : (tensor<1x1x1024x1024xbf16>) -> tensor<1x1024x1024xbf16> loc(#loc58)
      %57 = stablehlo.broadcast_in_dim %56, dims = [0, 2, 3] : (tensor<1x1024x1024xbf16>) -> tensor<1x7x1024x1024xbf16> loc(#loc59)
      %58 = stablehlo.add %55, %57 : tensor<1x7x1024x1024xbf16> loc(#loc60)
      %59 = stablehlo.convert %58 : (tensor<1x7x1024x1024xbf16>) -> tensor<1x7x1024x1024xf32> loc(#loc61)
      %60 = stablehlo.reduce(%59 init: %cst) applies stablehlo.maximum across dimensions = [3] : (tensor<1x7x1024x1024xf32>, tensor<f32>) -> tensor<1x7x1024xf32> loc(#loc62)
      %61 = stablehlo.broadcast_in_dim %60, dims = [0, 1, 2] : (tensor<1x7x1024xf32>) -> tensor<1x7x1024x1024xf32> loc(#loc63)
      %62 = stablehlo.subtract %59, %61 : tensor<1x7x1024x1024xf32> loc(#loc64)
      %63 = stablehlo.exponential %62 : tensor<1x7x1024x1024xf32> loc(#loc65)
      %64 = stablehlo.reduce(%63 init: %cst_0) applies stablehlo.add across dimensions = [3] : (tensor<1x7x1024x1024xf32>, tensor<f32>) -> tensor<1x7x1024xf32> loc(#loc66)
      %65 = stablehlo.broadcast_in_dim %64, dims = [0, 1, 2] : (tensor<1x7x1024xf32>) -> tensor<1x7x1024x1024xf32> loc(#loc67)
      %66 = stablehlo.divide %63, %65 : tensor<1x7x1024x1024xf32> loc(#loc68)
      %67 = stablehlo.convert %66 : (tensor<1x7x1024x1024xf32>) -> tensor<1x7x1024x1024xbf16> loc(#loc69)
      %68 = stablehlo.reshape %arg13 : (tensor<128x3584xbf16>) -> tensor<1x128x3584xbf16> loc(#loc70)
      %69 = stablehlo.reshape %68 : (tensor<1x128x3584xbf16>) -> tensor<128x3584xbf16> loc(#loc71)
      %70 = stablehlo.transpose %69, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,512]{0,1}"} : (tensor<128x3584xbf16>) -> tensor<3584x128xbf16> loc(#loc72)
      %71 = stablehlo.dot_general %2, %70, contracting_dims = [1] x [0] : (tensor<1024x3584xbf16>, tensor<3584x128xbf16>) -> tensor<1024x128xbf16> loc(#loc73)
      %72 = stablehlo.reshape %71 : (tensor<1024x128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc74)
      %73 = stablehlo.reshape %arg12 : (tensor<512xbf16>) -> tensor<4x128xbf16> loc(#loc2)
      %74 = "stablehlo.all_to_all"(%73) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, concat_dimension = 0 : i64, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7]]> : tensor<2x4xi64>, split_count = 4 : i64, split_dimension = 0 : i64}> : (tensor<4x128xbf16>) -> tensor<4x128xbf16> loc(#loc2)
      %75 = stablehlo.slice %74 [0:1, 0:128] : (tensor<4x128xbf16>) -> tensor<1x128xbf16> loc(#loc2)
      %76 = stablehlo.reshape %75 : (tensor<1x128xbf16>) -> tensor<128xbf16> loc(#loc2)
      %77 = stablehlo.reshape %76 : (tensor<128xbf16>) -> tensor<1x1x128xbf16> loc(#loc75)
      %78 = stablehlo.reshape %77 : (tensor<1x1x128xbf16>) -> tensor<128xbf16> loc(#loc76)
      %79 = stablehlo.broadcast_in_dim %78, dims = [2] : (tensor<128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc77)
      %80 = stablehlo.add %72, %79 : tensor<1x1024x128xbf16> loc(#loc78)
      %81 = stablehlo.reshape %80 : (tensor<1x1024x128xbf16>) -> tensor<1x1024x1x128xbf16> loc(#loc79)
      %82 = stablehlo.transpose %81, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,4,1024,128]{3,1,2,0}"} : (tensor<1x1024x1x128xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc80)
      %83 = stablehlo.broadcast_in_dim %82, dims = [0, 1, 3, 4] : (tensor<1x1x1024x128xbf16>) -> tensor<1x1x7x1024x128xbf16> loc(#loc81)
      %84 = stablehlo.reshape %83 : (tensor<1x1x7x1024x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc82)
      %85 = stablehlo.dot_general %67, %84, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x7x1024x1024xbf16>, tensor<1x7x1024x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc83)
      %86 = stablehlo.transpose %85, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[2,1024,28,128]{3,1,2,0}"} : (tensor<1x7x1024x128xbf16>) -> tensor<1x1024x7x128xbf16> loc(#loc84)
      %87 = stablehlo.reshape %86 : (tensor<1x1024x7x128xbf16>) -> tensor<1024x896xbf16> loc(#loc85)
      %88 = stablehlo.reshape %arg11 : (tensor<3584x896xbf16>) -> tensor<1x3584x896xbf16> loc(#loc86)
      %89 = stablehlo.reshape %88 : (tensor<1x3584x896xbf16>) -> tensor<3584x896xbf16> loc(#loc87)
      %90 = stablehlo.transpose %89, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3584,3584]{0,1}"} : (tensor<3584x896xbf16>) -> tensor<896x3584xbf16> loc(#loc88)
      %91 = stablehlo.dot_general %87, %90, contracting_dims = [1] x [0] : (tensor<1024x896xbf16>, tensor<896x3584xbf16>) -> tensor<1024x3584xbf16> loc(#loc89)
      %92 = "stablehlo.all_reduce"(%91) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7]]> : tensor<2x4xi64>}> ({
      ^bb0(%arg22: tensor<bf16> loc("dot.158"), %arg23: tensor<bf16> loc("dot.158")):
        %94 = stablehlo.add %arg22, %arg23 : tensor<bf16> loc(#loc89)
        stablehlo.return %94 : tensor<bf16> loc(#loc89)
      }) : (tensor<1024x3584xbf16>) -> tensor<1024x3584xbf16> loc(#loc89)
      %93 = stablehlo.reshape %92 : (tensor<1024x3584xbf16>) -> tensor<1x1024x3584xbf16> loc(#loc90)
      sdy.return %93, %67 : tensor<1x1024x3584xbf16>, tensor<1x7x1024x1024xbf16> loc(#loc)
    } : (tensor<3584x3584xbf16>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<2x1024x3584xbf16>, tensor<2x1x1024x1024xbf16>, tensor<2x1024x128xbf16>, tensor<512xbf16>, tensor<512x3584xbf16>, tensor<2x1024x128xbf16>, tensor<3584xbf16>, tensor<3584x3584xbf16>) -> (tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16>) loc(#loc)
    return %0#0, %0#1 : tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc12 = loc("reshape.103")
#loc13 = loc("reshape.99")
#loc14 = loc("reshape.101")
#loc15 = loc("transpose.102")
#loc16 = loc("dot.104")
#loc17 = loc("reshape.105")
#loc18 = loc("reshape.95")
#loc19 = loc("reshape.97")
#loc20 = loc("broadcast.108")
#loc21 = loc("add.109")
#loc22 = loc("reshape.110")
#loc23 = loc("transpose.111")
#loc24 = loc("broadcast.120")
#loc25 = loc("multiply.121")
#loc26 = loc("slice.113")
#loc27 = loc("negate.114")
#loc28 = loc("slice.112")
#loc29 = loc("concatenate.115")
#loc30 = loc("broadcast.117")
#loc31 = loc("multiply.118")
#loc32 = loc("add.124")
#loc33 = loc("reshape.53")
#loc34 = loc("reshape.55")
#loc35 = loc("transpose.56")
#loc36 = loc("dot.58")
#loc37 = loc("reshape.59")
#loc38 = loc("reshape.49")
#loc39 = loc("reshape.51")
#loc40 = loc("broadcast.62")
#loc41 = loc("add.63")
#loc42 = loc("reshape.64")
#loc43 = loc("transpose.65")
#loc44 = loc("broadcast.77")
#loc45 = loc("multiply.78")
#loc46 = loc("slice.67")
#loc47 = loc("negate.68")
#loc48 = loc("slice.66")
#loc49 = loc("concatenate.69")
#loc50 = loc("broadcast.71")
#loc51 = loc("multiply.72")
#loc52 = loc("add.81")
#loc53 = loc("broadcast.89")
#loc54 = loc("reshape.90")
#loc55 = loc("transpose.91")
#loc56 = loc("dot.125")
#loc57 = loc("multiply.128")
#loc58 = loc("reshape.131")
#loc59 = loc("broadcast.132")
#loc60 = loc("add.133")
#loc61 = loc("convert.134")
#loc62 = loc("reduce.140")
#loc63 = loc("broadcast.141")
#loc64 = loc("subtract.142")
#loc65 = loc("exponential.143")
#loc66 = loc("reduce.149")
#loc67 = loc("broadcast.150")
#loc68 = loc("divide.151")
#loc69 = loc("convert.152")
#loc70 = loc("reshape.12")
#loc71 = loc("reshape.14")
#loc72 = loc("transpose.15")
#loc73 = loc("dot.19")
#loc74 = loc("reshape.20")
#loc75 = loc("reshape.8")
#loc76 = loc("reshape.10")
#loc77 = loc("broadcast.23")
#loc78 = loc("add.24")
#loc79 = loc("reshape.25")
#loc80 = loc("transpose.26")
#loc81 = loc("broadcast.34")
#loc82 = loc("reshape.35")
#loc83 = loc("dot.153")
#loc84 = loc("transpose.155")
#loc85 = loc("reshape.157")
#loc86 = loc("reshape.2")
#loc87 = loc("reshape.4")
#loc88 = loc("transpose.5")
#loc90 = loc("reshape.159")
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.566 (  21.627s) [        7BAA3480]      module_builder.cc:273      1| Cleaning for XLA ingestion
Out sharding: #sdy.sharding<@mesh, [{"_axis_0"}, {}, {}]>
Out sharding: #sdy.sharding<@mesh, [{"_axis_0"}, {"_axis_1"}, {}, {}]>
  Out sharding #0, dim #0, axisName.size()=1
  Out sharding #0, dim #1, axisName.size()=0
  Out sharding #0, dim #2, axisName.size()=0
Out sharding str for out sharding #0 is: {devices=[2,1,1]<=[8]}
  Out sharding #1, dim #0, axisName.size()=1
  Out sharding #1, dim #1, axisName.size()=1
  Out sharding #1, dim #2, axisName.size()=0
  Out sharding #1, dim #3, axisName.size()=0
Out sharding str for out sharding #1 is: {devices=[2,4,1,1]<=[8]}
Module after injecting out sharding result and simplifying main function:
module @SyncTensorsGraph.161 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{devices=[2,1,1]<=[8]},{devices=[2,4,1,1]<=[8]}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<3584x3584xbf16>, %arg1: tensor<512xbf16>, %arg2: tensor<512x3584xbf16>, %arg3: tensor<2x1024x3584xbf16>, %arg4: tensor<2x1x1024x1024xbf16>, %arg5: tensor<2x1024x128xbf16>, %arg6: tensor<512xbf16>, %arg7: tensor<512x3584xbf16>, %arg8: tensor<2x1024x128xbf16>, %arg9: tensor<3584xbf16>, %arg10: tensor<3584x3584xbf16>) -> (tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x3584xbf16>
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<2x28x1024x1024xbf16>
    return %cst, %cst_0 : tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16>
  }
}
2026-01-05 17:23:19.568 (  21.629s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_compiler_cleaned:
#loc = loc(unknown)
module @SyncTensorsGraph.161 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{devices=[2,1,1]<=[8]},{devices=[2,4,1,1]<=[8]}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<3584x3584xbf16> loc(unknown), %arg1: tensor<512xbf16> loc(unknown), %arg2: tensor<512x3584xbf16> loc(unknown), %arg3: tensor<2x1024x3584xbf16> loc(unknown), %arg4: tensor<2x1x1024x1024xbf16> loc(unknown), %arg5: tensor<2x1024x128xbf16> loc(unknown), %arg6: tensor<512xbf16> loc(unknown), %arg7: tensor<512x3584xbf16> loc(unknown), %arg8: tensor<2x1024x128xbf16> loc(unknown), %arg9: tensor<3584xbf16> loc(unknown), %arg10: tensor<3584x3584xbf16> loc(unknown)) -> (tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x3584xbf16> loc(#loc)
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<2x28x1024x1024xbf16> loc(#loc)
    return %cst, %cst_0 : tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.584 (  21.645s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module ttir:
#loc1 = loc("p0.1")
#loc2 = loc("p1.7")
#loc3 = loc("p2.11")
#loc4 = loc("p3.16")
#loc5 = loc("p4.37")
#loc6 = loc("p5.44")
#loc7 = loc("p6.48")
#loc8 = loc("p7.52")
#loc9 = loc("p8.73")
#loc10 = loc("p9.94")
#loc11 = loc("p10.98")
module @SyncTensorsGraph.161 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.161 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
      func.func @main(%arg0: tensor<3584x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___o_proj_weight"} loc("p0.1"), %arg1: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___v_proj_bias"} loc("p1.7"), %arg2: tensor<512x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___v_proj_weight"} loc("p2.11"), %arg3: tensor<2x1024x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p3.16"), %arg4: tensor<2x1x1024x1024xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p4.37"), %arg5: tensor<2x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p5.44"), %arg6: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___k_proj_bias"} loc("p6.48"), %arg7: tensor<512x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___k_proj_weight"} loc("p7.52"), %arg8: tensor<2x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p8.73"), %arg9: tensor<3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___q_proj_bias"} loc("p9.94"), %arg10: tensor<3584x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___q_proj_weight"} loc("p10.98")) -> (tensor<2x1024x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x28x1024x1024xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 4>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3584x3584xbf16>) -> tensor<3584x896xbf16> loc(#loc)
        %1 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<512xbf16>) -> tensor<512xbf16> loc(#loc)
        %2 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 4, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<512x3584xbf16>) -> tensor<128x3584xbf16> loc(#loc)
        %3 = "ttir.mesh_shard"(%arg3) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x3584xbf16>) -> tensor<1x1024x3584xbf16> loc(#loc)
        %4 = "ttir.mesh_shard"(%arg4) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1x1024x1024xbf16>) -> tensor<1x1x1024x1024xbf16> loc(#loc)
        %5 = "ttir.mesh_shard"(%arg5) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc)
        %6 = "ttir.mesh_shard"(%arg6) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<512xbf16>) -> tensor<512xbf16> loc(#loc)
        %7 = "ttir.mesh_shard"(%arg7) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 4, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<512x3584xbf16>) -> tensor<128x3584xbf16> loc(#loc)
        %8 = "ttir.mesh_shard"(%arg8) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc)
        %9 = "ttir.mesh_shard"(%arg9) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3584xbf16>) -> tensor<3584xbf16> loc(#loc)
        %10 = "ttir.mesh_shard"(%arg10) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 4, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3584x3584xbf16>) -> tensor<896x3584xbf16> loc(#loc)
        %11 = "ttir.constant"() <{value = dense<8.837890e-02> : tensor<bf16>}> : () -> tensor<bf16> loc(#loc)
        %12 = "ttir.reshape"(%11) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>) -> tensor<1x1x1x1xbf16> loc(#loc)
        %13 = "ttir.broadcast"(%12) <{broadcast_dimensions = array<i64: 1, 7, 1024, 1024>}> : (tensor<1x1x1x1xbf16>) -> tensor<1x7x1024x1024xbf16> loc(#loc)
        %14 = "ttir.reshape"(%3) <{shape = [1024 : i32, 3584 : i32]}> : (tensor<1x1024x3584xbf16>) -> tensor<1024x3584xbf16> loc(#loc12)
        %15 = "ttir.reshape"(%10) <{shape = [1 : i32, 896 : i32, 3584 : i32]}> : (tensor<896x3584xbf16>) -> tensor<1x896x3584xbf16> loc(#loc13)
        %16 = "ttir.reshape"(%15) <{shape = [896 : i32, 3584 : i32]}> : (tensor<1x896x3584xbf16>) -> tensor<896x3584xbf16> loc(#loc14)
        %17 = "ttir.permute"(%16) <{permutation = array<i64: 1, 0>}> : (tensor<896x3584xbf16>) -> tensor<3584x896xbf16> loc(#loc15)
        %18 = "ttir.dot_general"(%14, %17) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1024x3584xbf16>, tensor<3584x896xbf16>) -> tensor<1024x896xbf16> loc(#loc16)
        %19 = "ttir.reshape"(%18) <{shape = [1 : i32, 1024 : i32, 896 : i32]}> : (tensor<1024x896xbf16>) -> tensor<1x1024x896xbf16> loc(#loc17)
        %20 = "ttir.reshape"(%9) <{shape = [4 : i32, 896 : i32]}> : (tensor<3584xbf16>) -> tensor<4x896xbf16> loc(#loc10)
        %21 = "ttir.all_to_all"(%20) <{concat_dim = 0 : si32, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7]]> : tensor<2x4xi64>, split_count = 4 : si32, split_dim = 0 : si32}> : (tensor<4x896xbf16>) -> tensor<4x896xbf16> loc(#loc10)
        %22 = "ttir.slice_static"(%21) <{begins = [0 : i32, 0 : i32], ends = [1 : i32, 896 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x896xbf16>) -> tensor<1x896xbf16> loc(#loc10)
        %23 = "ttir.reshape"(%22) <{shape = [896 : i32]}> : (tensor<1x896xbf16>) -> tensor<896xbf16> loc(#loc10)
        %24 = "ttir.reshape"(%23) <{shape = [1 : i32, 1 : i32, 896 : i32]}> : (tensor<896xbf16>) -> tensor<1x1x896xbf16> loc(#loc18)
        %25 = "ttir.reshape"(%24) <{shape = [896 : i32]}> : (tensor<1x1x896xbf16>) -> tensor<896xbf16> loc(#loc19)
        %26 = "ttir.reshape"(%25) <{shape = [1 : i32, 1 : i32, 896 : i32]}> : (tensor<896xbf16>) -> tensor<1x1x896xbf16> loc(#loc20)
        %27 = "ttir.broadcast"(%26) <{broadcast_dimensions = array<i64: 1, 1024, 1>}> : (tensor<1x1x896xbf16>) -> tensor<1x1024x896xbf16> loc(#loc20)
        %28 = "ttir.add"(%19, %27) : (tensor<1x1024x896xbf16>, tensor<1x1024x896xbf16>) -> tensor<1x1024x896xbf16> loc(#loc21)
        %29 = "ttir.reshape"(%28) <{shape = [1 : i32, 1024 : i32, 7 : i32, 128 : i32]}> : (tensor<1x1024x896xbf16>) -> tensor<1x1024x7x128xbf16> loc(#loc22)
        %30 = "ttir.permute"(%29) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x1024x7x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc23)
        %31 = "ttir.reshape"(%8) <{shape = [1 : i32, 1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x1024x128xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc24)
        %32 = "ttir.broadcast"(%31) <{broadcast_dimensions = array<i64: 1, 7, 1, 1>}> : (tensor<1x1x1024x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc24)
        %33 = "ttir.multiply"(%30, %32) : (tensor<1x7x1024x128xbf16>, tensor<1x7x1024x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc25)
        %34 = "ttir.slice_static"(%30) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 7 : i32, 1024 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x7x1024x128xbf16>) -> tensor<1x7x1024x64xbf16> loc(#loc26)
        %35 = "ttir.neg"(%34) : (tensor<1x7x1024x64xbf16>) -> tensor<1x7x1024x64xbf16> loc(#loc27)
        %36 = "ttir.slice_static"(%30) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 7 : i32, 1024 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x7x1024x128xbf16>) -> tensor<1x7x1024x64xbf16> loc(#loc28)
        %37 = "ttir.concat"(%35, %36) <{dim = 3 : si32}> : (tensor<1x7x1024x64xbf16>, tensor<1x7x1024x64xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc29)
        %38 = "ttir.reshape"(%5) <{shape = [1 : i32, 1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x1024x128xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc30)
        %39 = "ttir.broadcast"(%38) <{broadcast_dimensions = array<i64: 1, 7, 1, 1>}> : (tensor<1x1x1024x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc30)
        %40 = "ttir.multiply"(%37, %39) : (tensor<1x7x1024x128xbf16>, tensor<1x7x1024x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc31)
        %41 = "ttir.add"(%33, %40) : (tensor<1x7x1024x128xbf16>, tensor<1x7x1024x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc32)
        %42 = "ttir.reshape"(%7) <{shape = [1 : i32, 128 : i32, 3584 : i32]}> : (tensor<128x3584xbf16>) -> tensor<1x128x3584xbf16> loc(#loc33)
        %43 = "ttir.reshape"(%42) <{shape = [128 : i32, 3584 : i32]}> : (tensor<1x128x3584xbf16>) -> tensor<128x3584xbf16> loc(#loc34)
        %44 = "ttir.permute"(%43) <{permutation = array<i64: 1, 0>}> : (tensor<128x3584xbf16>) -> tensor<3584x128xbf16> loc(#loc35)
        %45 = "ttir.dot_general"(%14, %44) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1024x3584xbf16>, tensor<3584x128xbf16>) -> tensor<1024x128xbf16> loc(#loc36)
        %46 = "ttir.reshape"(%45) <{shape = [1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1024x128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc37)
        %47 = "ttir.reshape"(%6) <{shape = [4 : i32, 128 : i32]}> : (tensor<512xbf16>) -> tensor<4x128xbf16> loc(#loc7)
        %48 = "ttir.all_to_all"(%47) <{concat_dim = 0 : si32, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7]]> : tensor<2x4xi64>, split_count = 4 : si32, split_dim = 0 : si32}> : (tensor<4x128xbf16>) -> tensor<4x128xbf16> loc(#loc7)
        %49 = "ttir.slice_static"(%48) <{begins = [0 : i32, 0 : i32], ends = [1 : i32, 128 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x128xbf16>) -> tensor<1x128xbf16> loc(#loc7)
        %50 = "ttir.reshape"(%49) <{shape = [128 : i32]}> : (tensor<1x128xbf16>) -> tensor<128xbf16> loc(#loc7)
        %51 = "ttir.reshape"(%50) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16> loc(#loc38)
        %52 = "ttir.reshape"(%51) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16> loc(#loc39)
        %53 = "ttir.reshape"(%52) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16> loc(#loc40)
        %54 = "ttir.broadcast"(%53) <{broadcast_dimensions = array<i64: 1, 1024, 1>}> : (tensor<1x1x128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc40)
        %55 = "ttir.add"(%46, %54) : (tensor<1x1024x128xbf16>, tensor<1x1024x128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc41)
        %56 = "ttir.reshape"(%55) <{shape = [1 : i32, 1024 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1024x128xbf16>) -> tensor<1x1024x1x128xbf16> loc(#loc42)
        %57 = "ttir.permute"(%56) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x1024x1x128xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc43)
        %58 = "ttir.broadcast"(%31) <{broadcast_dimensions = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x1024x128xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc44)
        %59 = "ttir.multiply"(%57, %58) : (tensor<1x1x1024x128xbf16>, tensor<1x1x1024x128xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc45)
        %60 = "ttir.slice_static"(%57) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 1 : i32, 1024 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1x1024x128xbf16>) -> tensor<1x1x1024x64xbf16> loc(#loc46)
        %61 = "ttir.neg"(%60) : (tensor<1x1x1024x64xbf16>) -> tensor<1x1x1024x64xbf16> loc(#loc47)
        %62 = "ttir.slice_static"(%57) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 1 : i32, 1024 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1x1024x128xbf16>) -> tensor<1x1x1024x64xbf16> loc(#loc48)
        %63 = "ttir.concat"(%61, %62) <{dim = 3 : si32}> : (tensor<1x1x1024x64xbf16>, tensor<1x1x1024x64xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc49)
        %64 = "ttir.broadcast"(%38) <{broadcast_dimensions = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x1024x128xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc50)
        %65 = "ttir.multiply"(%63, %64) : (tensor<1x1x1024x128xbf16>, tensor<1x1x1024x128xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc51)
        %66 = "ttir.add"(%59, %65) : (tensor<1x1x1024x128xbf16>, tensor<1x1x1024x128xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc52)
        %67 = "ttir.reshape"(%66) <{shape = [1 : i32, 1 : i32, 1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x1x1024x128xbf16>) -> tensor<1x1x1x1024x128xbf16> loc(#loc53)
        %68 = "ttir.broadcast"(%67) <{broadcast_dimensions = array<i64: 1, 1, 7, 1, 1>}> : (tensor<1x1x1x1024x128xbf16>) -> tensor<1x1x7x1024x128xbf16> loc(#loc53)
        %69 = "ttir.reshape"(%68) <{shape = [1 : i32, 7 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x1x7x1024x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc54)
        %70 = "ttir.permute"(%69) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x7x1024x128xbf16>) -> tensor<1x7x128x1024xbf16> loc(#loc55)
        %71 = "ttir.dot_general"(%41, %70) <{batch_dims_lhs = array<i64: 0, 1>, batch_dims_rhs = array<i64: 0, 1>, contract_dims_lhs = array<i64: 3>, contract_dims_rhs = array<i64: 2>}> : (tensor<1x7x1024x128xbf16>, tensor<1x7x128x1024xbf16>) -> tensor<1x7x1024x1024xbf16> loc(#loc56)
        %72 = "ttir.multiply"(%71, %13) : (tensor<1x7x1024x1024xbf16>, tensor<1x7x1024x1024xbf16>) -> tensor<1x7x1024x1024xbf16> loc(#loc57)
        %73 = "ttir.reshape"(%4) <{shape = [1 : i32, 1024 : i32, 1024 : i32]}> : (tensor<1x1x1024x1024xbf16>) -> tensor<1x1024x1024xbf16> loc(#loc58)
        %74 = "ttir.reshape"(%73) <{shape = [1 : i32, 1 : i32, 1024 : i32, 1024 : i32]}> : (tensor<1x1024x1024xbf16>) -> tensor<1x1x1024x1024xbf16> loc(#loc59)
        %75 = "ttir.broadcast"(%74) <{broadcast_dimensions = array<i64: 1, 7, 1, 1>}> : (tensor<1x1x1024x1024xbf16>) -> tensor<1x7x1024x1024xbf16> loc(#loc59)
        %76 = "ttir.add"(%72, %75) : (tensor<1x7x1024x1024xbf16>, tensor<1x7x1024x1024xbf16>) -> tensor<1x7x1024x1024xbf16> loc(#loc60)
        %77 = "ttir.typecast"(%76) <{conservative_folding = false}> : (tensor<1x7x1024x1024xbf16>) -> tensor<1x7x1024x1024xf32> loc(#loc61)
        %78 = "ttir.max"(%77) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x7x1024x1024xf32>) -> tensor<1x7x1024xf32> loc(#loc62)
        %79 = "ttir.reshape"(%78) <{shape = [1 : i32, 7 : i32, 1024 : i32, 1 : i32]}> : (tensor<1x7x1024xf32>) -> tensor<1x7x1024x1xf32> loc(#loc63)
        %80 = "ttir.broadcast"(%79) <{broadcast_dimensions = array<i64: 1, 1, 1, 1024>}> : (tensor<1x7x1024x1xf32>) -> tensor<1x7x1024x1024xf32> loc(#loc63)
        %81 = "ttir.subtract"(%77, %80) : (tensor<1x7x1024x1024xf32>, tensor<1x7x1024x1024xf32>) -> tensor<1x7x1024x1024xf32> loc(#loc64)
        %82 = "ttir.exp"(%81) : (tensor<1x7x1024x1024xf32>) -> tensor<1x7x1024x1024xf32> loc(#loc65)
        %83 = "ttir.sum"(%82) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x7x1024x1024xf32>) -> tensor<1x7x1024xf32> loc(#loc66)
        %84 = "ttir.reshape"(%83) <{shape = [1 : i32, 7 : i32, 1024 : i32, 1 : i32]}> : (tensor<1x7x1024xf32>) -> tensor<1x7x1024x1xf32> loc(#loc67)
        %85 = "ttir.broadcast"(%84) <{broadcast_dimensions = array<i64: 1, 1, 1, 1024>}> : (tensor<1x7x1024x1xf32>) -> tensor<1x7x1024x1024xf32> loc(#loc67)
        %86 = "ttir.div"(%82, %85) : (tensor<1x7x1024x1024xf32>, tensor<1x7x1024x1024xf32>) -> tensor<1x7x1024x1024xf32> loc(#loc68)
        %87 = "ttir.typecast"(%86) <{conservative_folding = false}> : (tensor<1x7x1024x1024xf32>) -> tensor<1x7x1024x1024xbf16> loc(#loc69)
        %88 = "ttir.reshape"(%2) <{shape = [1 : i32, 128 : i32, 3584 : i32]}> : (tensor<128x3584xbf16>) -> tensor<1x128x3584xbf16> loc(#loc70)
        %89 = "ttir.reshape"(%88) <{shape = [128 : i32, 3584 : i32]}> : (tensor<1x128x3584xbf16>) -> tensor<128x3584xbf16> loc(#loc71)
        %90 = "ttir.permute"(%89) <{permutation = array<i64: 1, 0>}> : (tensor<128x3584xbf16>) -> tensor<3584x128xbf16> loc(#loc72)
        %91 = "ttir.dot_general"(%14, %90) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1024x3584xbf16>, tensor<3584x128xbf16>) -> tensor<1024x128xbf16> loc(#loc73)
        %92 = "ttir.reshape"(%91) <{shape = [1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1024x128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc74)
        %93 = "ttir.reshape"(%1) <{shape = [4 : i32, 128 : i32]}> : (tensor<512xbf16>) -> tensor<4x128xbf16> loc(#loc2)
        %94 = "ttir.all_to_all"(%93) <{concat_dim = 0 : si32, replica_groups = dense<[[0, 1, 2, 3], [4, 5, 6, 7]]> : tensor<2x4xi64>, split_count = 4 : si32, split_dim = 0 : si32}> : (tensor<4x128xbf16>) -> tensor<4x128xbf16> loc(#loc2)
        %95 = "ttir.slice_static"(%94) <{begins = [0 : i32, 0 : i32], ends = [1 : i32, 128 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x128xbf16>) -> tensor<1x128xbf16> loc(#loc2)
        %96 = "ttir.reshape"(%95) <{shape = [128 : i32]}> : (tensor<1x128xbf16>) -> tensor<128xbf16> loc(#loc2)
        %97 = "ttir.reshape"(%96) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16> loc(#loc75)
        %98 = "ttir.reshape"(%97) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16> loc(#loc76)
        %99 = "ttir.reshape"(%98) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16> loc(#loc77)
        %100 = "ttir.broadcast"(%99) <{broadcast_dimensions = array<i64: 1, 1024, 1>}> : (tensor<1x1x128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc77)
        %101 = "ttir.add"(%92, %100) : (tensor<1x1024x128xbf16>, tensor<1x1024x128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc78)
        %102 = "ttir.reshape"(%101) <{shape = [1 : i32, 1024 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1024x128xbf16>) -> tensor<1x1024x1x128xbf16> loc(#loc79)
        %103 = "ttir.permute"(%102) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x1024x1x128xbf16>) -> tensor<1x1x1024x128xbf16> loc(#loc80)
        %104 = "ttir.reshape"(%103) <{shape = [1 : i32, 1 : i32, 1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x1x1024x128xbf16>) -> tensor<1x1x1x1024x128xbf16> loc(#loc81)
        %105 = "ttir.broadcast"(%104) <{broadcast_dimensions = array<i64: 1, 1, 7, 1, 1>}> : (tensor<1x1x1x1024x128xbf16>) -> tensor<1x1x7x1024x128xbf16> loc(#loc81)
        %106 = "ttir.reshape"(%105) <{shape = [1 : i32, 7 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x1x7x1024x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc82)
        %107 = "ttir.dot_general"(%87, %106) <{batch_dims_lhs = array<i64: 0, 1>, batch_dims_rhs = array<i64: 0, 1>, contract_dims_lhs = array<i64: 3>, contract_dims_rhs = array<i64: 2>}> : (tensor<1x7x1024x1024xbf16>, tensor<1x7x1024x128xbf16>) -> tensor<1x7x1024x128xbf16> loc(#loc83)
        %108 = "ttir.permute"(%107) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x7x1024x128xbf16>) -> tensor<1x1024x7x128xbf16> loc(#loc84)
        %109 = "ttir.reshape"(%108) <{shape = [1024 : i32, 896 : i32]}> : (tensor<1x1024x7x128xbf16>) -> tensor<1024x896xbf16> loc(#loc85)
        %110 = "ttir.reshape"(%0) <{shape = [1 : i32, 3584 : i32, 896 : i32]}> : (tensor<3584x896xbf16>) -> tensor<1x3584x896xbf16> loc(#loc86)
        %111 = "ttir.reshape"(%110) <{shape = [3584 : i32, 896 : i32]}> : (tensor<1x3584x896xbf16>) -> tensor<3584x896xbf16> loc(#loc87)
        %112 = "ttir.permute"(%111) <{permutation = array<i64: 1, 0>}> : (tensor<3584x896xbf16>) -> tensor<896x3584xbf16> loc(#loc88)
        %113 = "ttir.dot_general"(%109, %112) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1024x896xbf16>, tensor<896x3584xbf16>) -> tensor<1024x3584xbf16> loc(#loc89)
        %114 = "ttir.all_reduce"(%113) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1024x3584xbf16>) -> tensor<1024x3584xbf16> loc(#loc89)
        %115 = "ttir.reshape"(%114) <{shape = [1 : i32, 1024 : i32, 3584 : i32]}> : (tensor<1024x3584xbf16>) -> tensor<1x1024x3584xbf16> loc(#loc90)
        %116 = "ttir.mesh_shard"(%115) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x1024x3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc)
        %117 = "ttir.mesh_shard"(%87) <{shard_dims = array<i64: 0, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 4, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x7x1024x1024xbf16>) -> tensor<2x28x1024x1024xbf16> loc(#loc)
        return %116, %117 : tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc12 = loc("reshape.103")
#loc13 = loc("reshape.99")
#loc14 = loc("reshape.101")
#loc15 = loc("transpose.102")
#loc16 = loc("dot.104")
#loc17 = loc("reshape.105")
#loc18 = loc("reshape.95")
#loc19 = loc("reshape.97")
#loc20 = loc("broadcast.108")
#loc21 = loc("add.109")
#loc22 = loc("reshape.110")
#loc23 = loc("transpose.111")
#loc24 = loc("broadcast.120")
#loc25 = loc("multiply.121")
#loc26 = loc("slice.113")
#loc27 = loc("negate.114")
#loc28 = loc("slice.112")
#loc29 = loc("concatenate.115")
#loc30 = loc("broadcast.117")
#loc31 = loc("multiply.118")
#loc32 = loc("add.124")
#loc33 = loc("reshape.53")
#loc34 = loc("reshape.55")
#loc35 = loc("transpose.56")
#loc36 = loc("dot.58")
#loc37 = loc("reshape.59")
#loc38 = loc("reshape.49")
#loc39 = loc("reshape.51")
#loc40 = loc("broadcast.62")
#loc41 = loc("add.63")
#loc42 = loc("reshape.64")
#loc43 = loc("transpose.65")
#loc44 = loc("broadcast.77")
#loc45 = loc("multiply.78")
#loc46 = loc("slice.67")
#loc47 = loc("negate.68")
#loc48 = loc("slice.66")
#loc49 = loc("concatenate.69")
#loc50 = loc("broadcast.71")
#loc51 = loc("multiply.72")
#loc52 = loc("add.81")
#loc53 = loc("broadcast.89")
#loc54 = loc("reshape.90")
#loc55 = loc("transpose.91")
#loc56 = loc("dot.125")
#loc57 = loc("multiply.128")
#loc58 = loc("reshape.131")
#loc59 = loc("broadcast.132")
#loc60 = loc("add.133")
#loc61 = loc("convert.134")
#loc62 = loc("reduce.140")
#loc63 = loc("broadcast.141")
#loc64 = loc("subtract.142")
#loc65 = loc("exponential.143")
#loc66 = loc("reduce.149")
#loc67 = loc("broadcast.150")
#loc68 = loc("divide.151")
#loc69 = loc("convert.152")
#loc70 = loc("reshape.12")
#loc71 = loc("reshape.14")
#loc72 = loc("transpose.15")
#loc73 = loc("dot.19")
#loc74 = loc("reshape.20")
#loc75 = loc("reshape.8")
#loc76 = loc("reshape.10")
#loc77 = loc("broadcast.23")
#loc78 = loc("add.24")
#loc79 = loc("reshape.25")
#loc80 = loc("transpose.26")
#loc81 = loc("broadcast.34")
#loc82 = loc("reshape.35")
#loc83 = loc("dot.153")
#loc84 = loc("transpose.155")
#loc85 = loc("reshape.157")
#loc86 = loc("reshape.2")
#loc87 = loc("reshape.4")
#loc88 = loc("transpose.5")
#loc89 = loc("dot.158")
#loc90 = loc("reshape.159")
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.589 (  21.650s) [        7BAA3480]      module_builder.cc:823   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2026-01-05 17:23:19.589 (  21.650s) [        7BAA3480]      module_builder.cc:837   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2026-01-05 17:23:19.589 (  21.650s) [        7BAA3480]      module_builder.cc:847   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2026-01-05 17:23:19.656 (  21.717s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module ttnn:
#dram = #ttnn.buffer_type<dram>
#loc = loc(unknown)
#loc1 = loc("p6.48")
#loc2 = loc("p9.94")
#loc3 = loc("p1.7")
#loc4 = loc("p0.1")
#loc5 = loc("p2.11")
#loc6 = loc("p3.16")
#loc7 = loc("p4.37")
#loc8 = loc("p5.44")
#loc9 = loc("p7.52")
#loc10 = loc("p8.73")
#loc11 = loc("p10.98")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x512xbf16, #system_memory>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x512xbf16, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3584xbf16, #system_memory>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x28x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3584xbf16, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<112x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout11 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout12 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<64x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout13 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 1024 + d2, d3), <1x1>, memref<64x32x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout14 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<64x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout15 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 28672 + d1 * 1024 + d2, d3), <1x1>, memref<1792x32x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout16 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout17 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<8x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout18 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x28x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout19 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<32x28x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout20 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout21 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout22 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<32x8x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout23 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<112x28x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout24 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<28x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout25 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<32x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout26 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 1024 + d2, d3), <1x1>, memref<32x32x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout27 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout28 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x28x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout29 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x8x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout30 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 7168 + d1 * 1024 + d2, d3), <1x1>, memref<224x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout31 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 1024 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout32 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 7168 + d1 * 1024 + d2, d3), <1x1>, memref<224x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout33 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 1024 + d2, d3), <1x1>, memref<32x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout34 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 7168 + d1 * 1024 + d2, d3), <1x1>, memref<224x32x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout35 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 7168 + d1 * 1024 + d2, d3), <1x1>, memref<224x32x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout36 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 1024 + d2, d3), <1x1>, memref<32x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout37 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 256 + d2, d3), <1x1>, memref<8x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
module @SyncTensorsGraph.161 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.161 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]> loc(#loc)
      func.func private @main_const_eval_0() -> tensor<1x1x1x1xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.0883789062 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout1> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout1>) -> tensor<1x1x1x1xbf16, #ttnn_layout> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<bf16, #ttnn_layout1>) -> () loc(#loc)
        return %2 : tensor<1x1x1x1xbf16, #ttnn_layout> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_1(%arg0: tensor<512xbf16, #ttnn_layout2> loc(unknown)) -> (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<512xbf16, #ttnn_layout2>, !ttnn.device) -> tensor<512xbf16, #ttnn_layout4> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<512xbf16, #ttnn_layout4>) -> tensor<512xbf16, #ttnn_layout5> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<512xbf16, #ttnn_layout4>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [4 : i32, 128 : i32]}> : (tensor<512xbf16, #ttnn_layout5>) -> tensor<4x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<512xbf16, #ttnn_layout5>) -> () loc(#loc1)
        %4 = "ttnn.slice_static"(%3) <{begins = [0 : i32, 0 : i32], ends = [1 : i32, 128 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        %5 = "ttnn.slice_static"(%3) <{begins = [1 : i32, 0 : i32], ends = [2 : i32, 128 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        %6 = "ttnn.slice_static"(%3) <{begins = [2 : i32, 0 : i32], ends = [3 : i32, 128 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        %7 = "ttnn.slice_static"(%3) <{begins = [3 : i32, 0 : i32], ends = [4 : i32, 128 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<4x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        return %4, %5, %6, %7 : tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_2(%arg0: tensor<3584xbf16, #ttnn_layout6> loc(unknown)) -> (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<3584xbf16, #ttnn_layout6>, !ttnn.device) -> tensor<3584xbf16, #ttnn_layout8> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<3584xbf16, #ttnn_layout8>) -> tensor<3584xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3584xbf16, #ttnn_layout8>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [4 : i32, 896 : i32]}> : (tensor<3584xbf16, #ttnn_layout9>) -> tensor<4x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<3584xbf16, #ttnn_layout9>) -> () loc(#loc2)
        %4 = "ttnn.slice_static"(%3) <{begins = [0 : i32, 0 : i32], ends = [1 : i32, 896 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        %5 = "ttnn.slice_static"(%3) <{begins = [1 : i32, 0 : i32], ends = [2 : i32, 896 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        %6 = "ttnn.slice_static"(%3) <{begins = [2 : i32, 0 : i32], ends = [3 : i32, 896 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        %7 = "ttnn.slice_static"(%3) <{begins = [3 : i32, 0 : i32], ends = [4 : i32, 896 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<4x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        return %4, %5, %6, %7 : tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_3(%arg0: tensor<512xbf16, #ttnn_layout2> loc(unknown)) -> (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<512xbf16, #ttnn_layout2>, !ttnn.device) -> tensor<512xbf16, #ttnn_layout4> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<512xbf16, #ttnn_layout4>) -> tensor<512xbf16, #ttnn_layout5> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<512xbf16, #ttnn_layout4>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [4 : i32, 128 : i32]}> : (tensor<512xbf16, #ttnn_layout5>) -> tensor<4x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<512xbf16, #ttnn_layout5>) -> () loc(#loc3)
        %4 = "ttnn.slice_static"(%3) <{begins = [0 : i32, 0 : i32], ends = [1 : i32, 128 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        %5 = "ttnn.slice_static"(%3) <{begins = [1 : i32, 0 : i32], ends = [2 : i32, 128 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        %6 = "ttnn.slice_static"(%3) <{begins = [2 : i32, 0 : i32], ends = [3 : i32, 128 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        %7 = "ttnn.slice_static"(%3) <{begins = [3 : i32, 0 : i32], ends = [4 : i32, 128 : i32], step = [1 : i32, 1 : i32]}> : (tensor<4x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<4x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        return %4, %5, %6, %7 : tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3> loc(#loc)
      } loc(#loc)
      func.func @main(%arg0: tensor<3584x3584xbf16, #ttnn_layout10> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___o_proj_weight"} loc("p0.1"), %arg1: tensor<512xbf16, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___v_proj_bias"} loc("p1.7"), %arg2: tensor<512x3584xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___v_proj_weight"} loc("p2.11"), %arg3: tensor<2x1024x3584xbf16, #ttnn_layout12> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p3.16"), %arg4: tensor<2x1x1024x1024xbf16, #ttnn_layout13> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p4.37"), %arg5: tensor<2x1024x128xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p5.44"), %arg6: tensor<512xbf16, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___k_proj_bias"} loc("p6.48"), %arg7: tensor<512x3584xbf16, #ttnn_layout11> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___k_proj_weight"} loc("p7.52"), %arg8: tensor<2x1024x128xbf16, #ttnn_layout14> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p8.73"), %arg9: tensor<3584xbf16, #ttnn_layout6> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___q_proj_bias"} loc("p9.94"), %arg10: tensor<3584x3584xbf16, #ttnn_layout10> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___q_proj_weight"} loc("p10.98")) -> (tensor<2x1024x3584xbf16, #ttnn_layout12> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<2x28x1024x1024xbf16, #ttnn_layout15> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x1x1xbf16, #ttnn_layout> loc(#loc)
        %1:4 = ttcore.load_cached(@main_const_eval_1, [%arg6]) : (tensor<512xbf16, #ttnn_layout2>) -> (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) loc(#loc)
        "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<512xbf16, #ttnn_layout2>) -> () loc(#loc)
        %2:4 = ttcore.load_cached(@main_const_eval_2, [%arg9]) : (tensor<3584xbf16, #ttnn_layout6>) -> (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) loc(#loc)
        "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<3584xbf16, #ttnn_layout6>) -> () loc(#loc)
        %3:4 = ttcore.load_cached(@main_const_eval_3, [%arg1]) : (tensor<512xbf16, #ttnn_layout2>) -> (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) loc(#loc)
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<512xbf16, #ttnn_layout2>) -> () loc(#loc)
        %4 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %5 = "ttnn.mesh_shard"(%arg2, %4) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 4, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<512x3584xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<128x3584xbf16, #ttnn_layout16> loc(#loc)
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<512x3584xbf16, #ttnn_layout11>) -> () loc(#loc)
        %6 = "ttnn.mesh_shard"(%arg7, %4) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 4, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<512x3584xbf16, #ttnn_layout11>, !ttnn.device) -> tensor<128x3584xbf16, #ttnn_layout16> loc(#loc)
        "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<512x3584xbf16, #ttnn_layout11>) -> () loc(#loc)
        %7 = "ttnn.concat"(%6, %5) <{dim = 0 : si32}> : (tensor<128x3584xbf16, #ttnn_layout16>, tensor<128x3584xbf16, #ttnn_layout16>) -> tensor<256x3584xbf16, #ttnn_layout17> loc(#loc)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<128x3584xbf16, #ttnn_layout16>) -> () loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<128x3584xbf16, #ttnn_layout16>) -> () loc(#loc)
        %8 = "ttnn.assign"(%2#0) <{dtype = #ttcore.supportedDataTypes<bf16>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        %9 = "ttnn.assign"(%2#1) <{dtype = #ttcore.supportedDataTypes<bf16>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        %10 = "ttnn.assign"(%2#2) <{dtype = #ttcore.supportedDataTypes<bf16>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        %11 = "ttnn.assign"(%2#3) <{dtype = #ttcore.supportedDataTypes<bf16>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        %12 = "ttnn.point_to_point"(%2#1, %8) <{receiver_coord = array<i64: 0, 1>, sender_coord = array<i64: 0, 0>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %13 = "ttnn.point_to_point"(%2#2, %12) <{receiver_coord = array<i64: 0, 2>, sender_coord = array<i64: 0, 0>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %14 = "ttnn.point_to_point"(%2#3, %13) <{receiver_coord = array<i64: 0, 3>, sender_coord = array<i64: 0, 0>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %15 = "ttnn.point_to_point"(%2#0, %9) <{receiver_coord = array<i64: 0, 0>, sender_coord = array<i64: 0, 1>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %16 = "ttnn.point_to_point"(%2#2, %15) <{receiver_coord = array<i64: 0, 2>, sender_coord = array<i64: 0, 1>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %17 = "ttnn.point_to_point"(%2#3, %16) <{receiver_coord = array<i64: 0, 3>, sender_coord = array<i64: 0, 1>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %18 = "ttnn.point_to_point"(%2#0, %10) <{receiver_coord = array<i64: 0, 0>, sender_coord = array<i64: 0, 2>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %19 = "ttnn.point_to_point"(%2#1, %18) <{receiver_coord = array<i64: 0, 1>, sender_coord = array<i64: 0, 2>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %20 = "ttnn.point_to_point"(%2#3, %19) <{receiver_coord = array<i64: 0, 3>, sender_coord = array<i64: 0, 2>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %21 = "ttnn.point_to_point"(%2#0, %11) <{receiver_coord = array<i64: 0, 0>, sender_coord = array<i64: 0, 3>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %22 = "ttnn.point_to_point"(%2#1, %21) <{receiver_coord = array<i64: 0, 1>, sender_coord = array<i64: 0, 3>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %23 = "ttnn.point_to_point"(%2#2, %22) <{receiver_coord = array<i64: 0, 2>, sender_coord = array<i64: 0, 3>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%22) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %24 = "ttnn.point_to_point"(%2#1, %14) <{receiver_coord = array<i64: 1, 1>, sender_coord = array<i64: 1, 0>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %25 = "ttnn.point_to_point"(%2#2, %24) <{receiver_coord = array<i64: 1, 2>, sender_coord = array<i64: 1, 0>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%24) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %26 = "ttnn.point_to_point"(%2#3, %25) <{receiver_coord = array<i64: 1, 3>, sender_coord = array<i64: 1, 0>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%25) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %27 = "ttnn.point_to_point"(%2#0, %17) <{receiver_coord = array<i64: 1, 0>, sender_coord = array<i64: 1, 1>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %28 = "ttnn.point_to_point"(%2#2, %27) <{receiver_coord = array<i64: 1, 2>, sender_coord = array<i64: 1, 1>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%27) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %29 = "ttnn.point_to_point"(%2#3, %28) <{receiver_coord = array<i64: 1, 3>, sender_coord = array<i64: 1, 1>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%28) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %30 = "ttnn.point_to_point"(%2#0, %20) <{receiver_coord = array<i64: 1, 0>, sender_coord = array<i64: 1, 2>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %31 = "ttnn.point_to_point"(%2#1, %30) <{receiver_coord = array<i64: 1, 1>, sender_coord = array<i64: 1, 2>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%30) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %32 = "ttnn.point_to_point"(%2#3, %31) <{receiver_coord = array<i64: 1, 3>, sender_coord = array<i64: 1, 2>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%31) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        "ttnn.deallocate"(%2#3) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %33 = "ttnn.point_to_point"(%2#0, %23) <{receiver_coord = array<i64: 1, 0>, sender_coord = array<i64: 1, 3>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        "ttnn.deallocate"(%2#0) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %34 = "ttnn.point_to_point"(%2#1, %33) <{receiver_coord = array<i64: 1, 1>, sender_coord = array<i64: 1, 3>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%33) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        "ttnn.deallocate"(%2#1) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %35 = "ttnn.point_to_point"(%2#2, %34) <{receiver_coord = array<i64: 1, 2>, sender_coord = array<i64: 1, 3>}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<1x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%34) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        "ttnn.deallocate"(%2#2) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %36 = "ttnn.concat"(%26, %29, %32, %35) <{dim = 0 : si32}> : (tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>, tensor<1x896xbf16, #ttnn_layout7>) -> tensor<4x896xbf16, #ttnn_layout7> loc(#loc2)
        "ttnn.deallocate"(%35) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        "ttnn.deallocate"(%32) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        "ttnn.deallocate"(%29) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        "ttnn.deallocate"(%26) <{force = false}> : (tensor<1x896xbf16, #ttnn_layout7>) -> () loc(#loc2)
        %37 = "ttnn.reshape"(%36) <{shape = [1 : i32, 4 : i32, 896 : i32]}> : (tensor<4x896xbf16, #ttnn_layout7>) -> tensor<1x4x896xbf16, #ttnn_layout18> loc(#loc12)
        "ttnn.deallocate"(%36) <{force = false}> : (tensor<4x896xbf16, #ttnn_layout7>) -> () loc(#loc12)
        %38 = "ttnn.slice_static"(%37) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 1 : i32, 896 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x896xbf16, #ttnn_layout18>) -> tensor<1x1x896xbf16, #ttnn_layout18> loc(#loc2)
        "ttnn.deallocate"(%37) <{force = false}> : (tensor<1x4x896xbf16, #ttnn_layout18>) -> () loc(#loc2)
        %39 = "ttnn.repeat"(%38) <{repeat_dims = #ttnn.shape<1x1024x1>}> : (tensor<1x1x896xbf16, #ttnn_layout18>) -> tensor<1x1024x896xbf16, #ttnn_layout19> loc(#loc12)
        "ttnn.deallocate"(%38) <{force = false}> : (tensor<1x1x896xbf16, #ttnn_layout18>) -> () loc(#loc12)
        %40 = "ttnn.assign"(%1#0) <{dtype = #ttcore.supportedDataTypes<bf16>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        %41 = "ttnn.assign"(%1#1) <{dtype = #ttcore.supportedDataTypes<bf16>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        %42 = "ttnn.assign"(%1#2) <{dtype = #ttcore.supportedDataTypes<bf16>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        %43 = "ttnn.assign"(%1#3) <{dtype = #ttcore.supportedDataTypes<bf16>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        %44 = "ttnn.point_to_point"(%1#1, %40) <{receiver_coord = array<i64: 0, 1>, sender_coord = array<i64: 0, 0>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%40) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %45 = "ttnn.point_to_point"(%1#2, %44) <{receiver_coord = array<i64: 0, 2>, sender_coord = array<i64: 0, 0>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%44) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %46 = "ttnn.point_to_point"(%1#3, %45) <{receiver_coord = array<i64: 0, 3>, sender_coord = array<i64: 0, 0>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%45) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %47 = "ttnn.point_to_point"(%1#0, %41) <{receiver_coord = array<i64: 0, 0>, sender_coord = array<i64: 0, 1>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%41) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %48 = "ttnn.point_to_point"(%1#2, %47) <{receiver_coord = array<i64: 0, 2>, sender_coord = array<i64: 0, 1>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%47) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %49 = "ttnn.point_to_point"(%1#3, %48) <{receiver_coord = array<i64: 0, 3>, sender_coord = array<i64: 0, 1>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%48) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %50 = "ttnn.point_to_point"(%1#0, %42) <{receiver_coord = array<i64: 0, 0>, sender_coord = array<i64: 0, 2>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%42) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %51 = "ttnn.point_to_point"(%1#1, %50) <{receiver_coord = array<i64: 0, 1>, sender_coord = array<i64: 0, 2>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%50) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %52 = "ttnn.point_to_point"(%1#3, %51) <{receiver_coord = array<i64: 0, 3>, sender_coord = array<i64: 0, 2>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%51) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %53 = "ttnn.point_to_point"(%1#0, %43) <{receiver_coord = array<i64: 0, 0>, sender_coord = array<i64: 0, 3>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%43) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %54 = "ttnn.point_to_point"(%1#1, %53) <{receiver_coord = array<i64: 0, 1>, sender_coord = array<i64: 0, 3>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%53) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %55 = "ttnn.point_to_point"(%1#2, %54) <{receiver_coord = array<i64: 0, 2>, sender_coord = array<i64: 0, 3>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%54) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %56 = "ttnn.point_to_point"(%1#1, %46) <{receiver_coord = array<i64: 1, 1>, sender_coord = array<i64: 1, 0>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%46) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %57 = "ttnn.point_to_point"(%1#2, %56) <{receiver_coord = array<i64: 1, 2>, sender_coord = array<i64: 1, 0>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%56) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %58 = "ttnn.point_to_point"(%1#3, %57) <{receiver_coord = array<i64: 1, 3>, sender_coord = array<i64: 1, 0>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%57) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %59 = "ttnn.point_to_point"(%1#0, %49) <{receiver_coord = array<i64: 1, 0>, sender_coord = array<i64: 1, 1>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%49) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %60 = "ttnn.point_to_point"(%1#2, %59) <{receiver_coord = array<i64: 1, 2>, sender_coord = array<i64: 1, 1>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%59) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %61 = "ttnn.point_to_point"(%1#3, %60) <{receiver_coord = array<i64: 1, 3>, sender_coord = array<i64: 1, 1>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%60) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %62 = "ttnn.point_to_point"(%1#0, %52) <{receiver_coord = array<i64: 1, 0>, sender_coord = array<i64: 1, 2>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%52) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %63 = "ttnn.point_to_point"(%1#1, %62) <{receiver_coord = array<i64: 1, 1>, sender_coord = array<i64: 1, 2>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%62) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %64 = "ttnn.point_to_point"(%1#3, %63) <{receiver_coord = array<i64: 1, 3>, sender_coord = array<i64: 1, 2>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%63) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        "ttnn.deallocate"(%1#3) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %65 = "ttnn.point_to_point"(%1#0, %55) <{receiver_coord = array<i64: 1, 0>, sender_coord = array<i64: 1, 3>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%55) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        "ttnn.deallocate"(%1#0) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %66 = "ttnn.point_to_point"(%1#1, %65) <{receiver_coord = array<i64: 1, 1>, sender_coord = array<i64: 1, 3>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%65) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        "ttnn.deallocate"(%1#1) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %67 = "ttnn.point_to_point"(%1#2, %66) <{receiver_coord = array<i64: 1, 2>, sender_coord = array<i64: 1, 3>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%66) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        "ttnn.deallocate"(%1#2) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %68 = "ttnn.concat"(%58, %61, %64, %67) <{dim = 0 : si32}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<4x128xbf16, #ttnn_layout3> loc(#loc1)
        "ttnn.deallocate"(%67) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        "ttnn.deallocate"(%64) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        "ttnn.deallocate"(%61) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        "ttnn.deallocate"(%58) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        %69 = "ttnn.reshape"(%68) <{shape = [1 : i32, 4 : i32, 128 : i32]}> : (tensor<4x128xbf16, #ttnn_layout3>) -> tensor<1x4x128xbf16, #ttnn_layout20> loc(#loc13)
        "ttnn.deallocate"(%68) <{force = false}> : (tensor<4x128xbf16, #ttnn_layout3>) -> () loc(#loc13)
        %70 = "ttnn.slice_static"(%69) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x128xbf16, #ttnn_layout20>) -> tensor<1x1x128xbf16, #ttnn_layout20> loc(#loc1)
        "ttnn.deallocate"(%69) <{force = false}> : (tensor<1x4x128xbf16, #ttnn_layout20>) -> () loc(#loc1)
        %71 = "ttnn.repeat"(%70) <{repeat_dims = #ttnn.shape<1x1024x1>}> : (tensor<1x1x128xbf16, #ttnn_layout20>) -> tensor<1x1024x128xbf16, #ttnn_layout21> loc(#loc13)
        "ttnn.deallocate"(%70) <{force = false}> : (tensor<1x1x128xbf16, #ttnn_layout20>) -> () loc(#loc13)
        %72 = "ttnn.assign"(%3#0) <{dtype = #ttcore.supportedDataTypes<bf16>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        %73 = "ttnn.assign"(%3#1) <{dtype = #ttcore.supportedDataTypes<bf16>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        %74 = "ttnn.assign"(%3#2) <{dtype = #ttcore.supportedDataTypes<bf16>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        %75 = "ttnn.assign"(%3#3) <{dtype = #ttcore.supportedDataTypes<bf16>, memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        %76 = "ttnn.point_to_point"(%3#1, %72) <{receiver_coord = array<i64: 0, 1>, sender_coord = array<i64: 0, 0>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%72) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %77 = "ttnn.point_to_point"(%3#2, %76) <{receiver_coord = array<i64: 0, 2>, sender_coord = array<i64: 0, 0>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%76) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %78 = "ttnn.point_to_point"(%3#3, %77) <{receiver_coord = array<i64: 0, 3>, sender_coord = array<i64: 0, 0>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%77) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %79 = "ttnn.point_to_point"(%3#0, %73) <{receiver_coord = array<i64: 0, 0>, sender_coord = array<i64: 0, 1>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%73) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %80 = "ttnn.point_to_point"(%3#2, %79) <{receiver_coord = array<i64: 0, 2>, sender_coord = array<i64: 0, 1>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%79) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %81 = "ttnn.point_to_point"(%3#3, %80) <{receiver_coord = array<i64: 0, 3>, sender_coord = array<i64: 0, 1>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%80) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %82 = "ttnn.point_to_point"(%3#0, %74) <{receiver_coord = array<i64: 0, 0>, sender_coord = array<i64: 0, 2>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%74) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %83 = "ttnn.point_to_point"(%3#1, %82) <{receiver_coord = array<i64: 0, 1>, sender_coord = array<i64: 0, 2>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%82) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %84 = "ttnn.point_to_point"(%3#3, %83) <{receiver_coord = array<i64: 0, 3>, sender_coord = array<i64: 0, 2>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%83) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %85 = "ttnn.point_to_point"(%3#0, %75) <{receiver_coord = array<i64: 0, 0>, sender_coord = array<i64: 0, 3>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%75) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %86 = "ttnn.point_to_point"(%3#1, %85) <{receiver_coord = array<i64: 0, 1>, sender_coord = array<i64: 0, 3>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%85) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %87 = "ttnn.point_to_point"(%3#2, %86) <{receiver_coord = array<i64: 0, 2>, sender_coord = array<i64: 0, 3>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%86) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %88 = "ttnn.point_to_point"(%3#1, %78) <{receiver_coord = array<i64: 1, 1>, sender_coord = array<i64: 1, 0>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%78) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %89 = "ttnn.point_to_point"(%3#2, %88) <{receiver_coord = array<i64: 1, 2>, sender_coord = array<i64: 1, 0>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%88) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %90 = "ttnn.point_to_point"(%3#3, %89) <{receiver_coord = array<i64: 1, 3>, sender_coord = array<i64: 1, 0>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%89) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %91 = "ttnn.point_to_point"(%3#0, %81) <{receiver_coord = array<i64: 1, 0>, sender_coord = array<i64: 1, 1>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%81) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %92 = "ttnn.point_to_point"(%3#2, %91) <{receiver_coord = array<i64: 1, 2>, sender_coord = array<i64: 1, 1>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%91) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %93 = "ttnn.point_to_point"(%3#3, %92) <{receiver_coord = array<i64: 1, 3>, sender_coord = array<i64: 1, 1>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%92) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %94 = "ttnn.point_to_point"(%3#0, %84) <{receiver_coord = array<i64: 1, 0>, sender_coord = array<i64: 1, 2>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%84) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %95 = "ttnn.point_to_point"(%3#1, %94) <{receiver_coord = array<i64: 1, 1>, sender_coord = array<i64: 1, 2>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%94) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %96 = "ttnn.point_to_point"(%3#3, %95) <{receiver_coord = array<i64: 1, 3>, sender_coord = array<i64: 1, 2>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%95) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        "ttnn.deallocate"(%3#3) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %97 = "ttnn.point_to_point"(%3#0, %87) <{receiver_coord = array<i64: 1, 0>, sender_coord = array<i64: 1, 3>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%87) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        "ttnn.deallocate"(%3#0) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %98 = "ttnn.point_to_point"(%3#1, %97) <{receiver_coord = array<i64: 1, 1>, sender_coord = array<i64: 1, 3>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%97) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        "ttnn.deallocate"(%3#1) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %99 = "ttnn.point_to_point"(%3#2, %98) <{receiver_coord = array<i64: 1, 2>, sender_coord = array<i64: 1, 3>}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<1x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%98) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        "ttnn.deallocate"(%3#2) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %100 = "ttnn.concat"(%90, %93, %96, %99) <{dim = 0 : si32}> : (tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>, tensor<1x128xbf16, #ttnn_layout3>) -> tensor<4x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%99) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        "ttnn.deallocate"(%96) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        "ttnn.deallocate"(%93) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        "ttnn.deallocate"(%90) <{force = false}> : (tensor<1x128xbf16, #ttnn_layout3>) -> () loc(#loc3)
        %101 = "ttnn.reshape"(%100) <{shape = [1 : i32, 4 : i32, 128 : i32]}> : (tensor<4x128xbf16, #ttnn_layout3>) -> tensor<1x4x128xbf16, #ttnn_layout20> loc(#loc14)
        "ttnn.deallocate"(%100) <{force = false}> : (tensor<4x128xbf16, #ttnn_layout3>) -> () loc(#loc14)
        %102 = "ttnn.slice_static"(%101) <{begins = [0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x128xbf16, #ttnn_layout20>) -> tensor<1x1x128xbf16, #ttnn_layout20> loc(#loc3)
        "ttnn.deallocate"(%101) <{force = false}> : (tensor<1x4x128xbf16, #ttnn_layout20>) -> () loc(#loc3)
        %103 = "ttnn.repeat"(%102) <{repeat_dims = #ttnn.shape<1x1024x1>}> : (tensor<1x1x128xbf16, #ttnn_layout20>) -> tensor<1x1024x128xbf16, #ttnn_layout21> loc(#loc14)
        "ttnn.deallocate"(%102) <{force = false}> : (tensor<1x1x128xbf16, #ttnn_layout20>) -> () loc(#loc14)
        %104 = "ttnn.concat"(%71, %103) <{dim = 2 : si32}> : (tensor<1x1024x128xbf16, #ttnn_layout21>, tensor<1x1024x128xbf16, #ttnn_layout21>) -> tensor<1x1024x256xbf16, #ttnn_layout22> loc(#loc14)
        "ttnn.deallocate"(%103) <{force = false}> : (tensor<1x1024x128xbf16, #ttnn_layout21>) -> () loc(#loc14)
        "ttnn.deallocate"(%71) <{force = false}> : (tensor<1x1024x128xbf16, #ttnn_layout21>) -> () loc(#loc14)
        %105 = "ttnn.mesh_shard"(%arg0, %4) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 4>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3584x3584xbf16, #ttnn_layout10>, !ttnn.device) -> tensor<3584x896xbf16, #ttnn_layout23> loc(#loc)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<3584x3584xbf16, #ttnn_layout10>) -> () loc(#loc)
        %106 = "ttnn.mesh_shard"(%arg10, %4) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 4, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3584x3584xbf16, #ttnn_layout10>, !ttnn.device) -> tensor<896x3584xbf16, #ttnn_layout24> loc(#loc)
        "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<3584x3584xbf16, #ttnn_layout10>) -> () loc(#loc)
        %107 = "ttnn.mesh_shard"(%arg3, %4) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x3584xbf16, #ttnn_layout12>, !ttnn.device) -> tensor<1x1024x3584xbf16, #ttnn_layout25> loc(#loc)
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<2x1024x3584xbf16, #ttnn_layout12>) -> () loc(#loc)
        %108 = "ttnn.mesh_shard"(%arg4, %4) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1x1024x1024xbf16, #ttnn_layout13>, !ttnn.device) -> tensor<1x1x1024x1024xbf16, #ttnn_layout26> loc(#loc)
        "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<2x1x1024x1024xbf16, #ttnn_layout13>) -> () loc(#loc)
        %109 = "ttnn.mesh_shard"(%arg5, %4) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x128xbf16, #ttnn_layout14>, !ttnn.device) -> tensor<1x1024x128xbf16, #ttnn_layout21> loc(#loc)
        "ttnn.deallocate"(%arg5) <{force = false}> : (tensor<2x1024x128xbf16, #ttnn_layout14>) -> () loc(#loc)
        %110 = "ttnn.mesh_shard"(%arg8, %4) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x128xbf16, #ttnn_layout14>, !ttnn.device) -> tensor<1x1024x128xbf16, #ttnn_layout21> loc(#loc)
        "ttnn.deallocate"(%arg8) <{force = false}> : (tensor<2x1024x128xbf16, #ttnn_layout14>) -> () loc(#loc)
        %111 = "ttnn.reshape"(%107) <{shape = [1024 : i32, 3584 : i32]}> : (tensor<1x1024x3584xbf16, #ttnn_layout25>) -> tensor<1024x3584xbf16, #ttnn_layout27> loc(#loc15)
        "ttnn.deallocate"(%107) <{force = false}> : (tensor<1x1024x3584xbf16, #ttnn_layout25>) -> () loc(#loc15)
        %112 = "ttnn.matmul"(%111, %106) <{transpose_a = false, transpose_b = true}> : (tensor<1024x3584xbf16, #ttnn_layout27>, tensor<896x3584xbf16, #ttnn_layout24>) -> tensor<1024x896xbf16, #ttnn_layout28> loc(#loc46)
        "ttnn.deallocate"(%106) <{force = false}> : (tensor<896x3584xbf16, #ttnn_layout24>) -> () loc(#loc46)
        %113 = "ttnn.add"(%112, %39) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1024x896xbf16, #ttnn_layout28>, tensor<1x1024x896xbf16, #ttnn_layout19>) -> tensor<1x1024x896xbf16, #ttnn_layout19> loc(#loc47)
        "ttnn.deallocate"(%112) <{force = false}> : (tensor<1024x896xbf16, #ttnn_layout28>) -> () loc(#loc47)
        "ttnn.deallocate"(%39) <{force = false}> : (tensor<1x1024x896xbf16, #ttnn_layout19>) -> () loc(#loc47)
        %114 = "ttnn.matmul"(%111, %7) <{transpose_a = false, transpose_b = true}> : (tensor<1024x3584xbf16, #ttnn_layout27>, tensor<256x3584xbf16, #ttnn_layout17>) -> tensor<1024x256xbf16, #ttnn_layout29> loc(#loc48)
        "ttnn.deallocate"(%111) <{force = false}> : (tensor<1024x3584xbf16, #ttnn_layout27>) -> () loc(#loc48)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<256x3584xbf16, #ttnn_layout17>) -> () loc(#loc48)
        %115 = "ttnn.add"(%114, %104) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1024x256xbf16, #ttnn_layout29>, tensor<1x1024x256xbf16, #ttnn_layout22>) -> tensor<1x1024x256xbf16, #ttnn_layout22> loc(#loc49)
        "ttnn.deallocate"(%114) <{force = false}> : (tensor<1024x256xbf16, #ttnn_layout29>) -> () loc(#loc49)
        "ttnn.deallocate"(%104) <{force = false}> : (tensor<1x1024x256xbf16, #ttnn_layout22>) -> () loc(#loc49)
        %query, %key, %value = "ttnn.split_query_key_value_and_split_heads"(%113, %115) <{num_heads = 7 : ui32, num_kv_heads = 1 : ui32, transpose_key = false}> : (tensor<1x1024x896xbf16, #ttnn_layout19>, tensor<1x1024x256xbf16, #ttnn_layout22>) -> (tensor<1x7x1024x128xbf16, #ttnn_layout30>, tensor<1x1x1024x128xbf16, #ttnn_layout31>, tensor<1x1x1024x128xbf16, #ttnn_layout31>) loc(#loc17)
        "ttnn.deallocate"(%115) <{force = false}> : (tensor<1x1024x256xbf16, #ttnn_layout22>) -> () loc(#loc17)
        "ttnn.deallocate"(%113) <{force = false}> : (tensor<1x1024x896xbf16, #ttnn_layout19>) -> () loc(#loc17)
        %116 = "ttnn.reshape"(%110) <{shape = [1 : i32, 1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x1024x128xbf16, #ttnn_layout21>) -> tensor<1x1x1024x128xbf16, #ttnn_layout31> loc(#loc18)
        "ttnn.deallocate"(%110) <{force = false}> : (tensor<1x1024x128xbf16, #ttnn_layout21>) -> () loc(#loc18)
        %117 = "ttnn.multiply"(%query, %116) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>, tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> tensor<1x7x1024x128xbf16, #ttnn_layout30> loc(#loc19)
        %118 = "ttnn.slice_static"(%query) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 7 : i32, 1024 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> tensor<1x7x1024x64xbf16, #ttnn_layout32> loc(#loc20)
        %119 = "ttnn.neg"(%118) : (tensor<1x7x1024x64xbf16, #ttnn_layout32>) -> tensor<1x7x1024x64xbf16, #ttnn_layout32> loc(#loc21)
        "ttnn.deallocate"(%118) <{force = false}> : (tensor<1x7x1024x64xbf16, #ttnn_layout32>) -> () loc(#loc21)
        %120 = "ttnn.slice_static"(%query) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 7 : i32, 1024 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> tensor<1x7x1024x64xbf16, #ttnn_layout32> loc(#loc22)
        "ttnn.deallocate"(%query) <{force = false}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> () loc(#loc22)
        %121 = "ttnn.concat"(%119, %120) <{dim = 3 : si32}> : (tensor<1x7x1024x64xbf16, #ttnn_layout32>, tensor<1x7x1024x64xbf16, #ttnn_layout32>) -> tensor<1x7x1024x128xbf16, #ttnn_layout30> loc(#loc23)
        "ttnn.deallocate"(%120) <{force = false}> : (tensor<1x7x1024x64xbf16, #ttnn_layout32>) -> () loc(#loc23)
        "ttnn.deallocate"(%119) <{force = false}> : (tensor<1x7x1024x64xbf16, #ttnn_layout32>) -> () loc(#loc23)
        %122 = "ttnn.reshape"(%109) <{shape = [1 : i32, 1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x1024x128xbf16, #ttnn_layout21>) -> tensor<1x1x1024x128xbf16, #ttnn_layout31> loc(#loc24)
        "ttnn.deallocate"(%109) <{force = false}> : (tensor<1x1024x128xbf16, #ttnn_layout21>) -> () loc(#loc24)
        %123 = "ttnn.multiply"(%121, %122) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>, tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> tensor<1x7x1024x128xbf16, #ttnn_layout30> loc(#loc25)
        "ttnn.deallocate"(%121) <{force = false}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> () loc(#loc25)
        %124 = "ttnn.add"(%117, %123) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>, tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> tensor<1x7x1024x128xbf16, #ttnn_layout30> loc(#loc26)
        "ttnn.deallocate"(%123) <{force = false}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> () loc(#loc26)
        "ttnn.deallocate"(%117) <{force = false}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> () loc(#loc26)
        %125 = "ttnn.multiply"(%key, %116) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>, tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> tensor<1x1x1024x128xbf16, #ttnn_layout31> loc(#loc27)
        "ttnn.deallocate"(%116) <{force = false}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> () loc(#loc27)
        %126 = "ttnn.slice_static"(%key) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 1 : i32, 1024 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> tensor<1x1x1024x64xbf16, #ttnn_layout33> loc(#loc28)
        %127 = "ttnn.neg"(%126) : (tensor<1x1x1024x64xbf16, #ttnn_layout33>) -> tensor<1x1x1024x64xbf16, #ttnn_layout33> loc(#loc29)
        "ttnn.deallocate"(%126) <{force = false}> : (tensor<1x1x1024x64xbf16, #ttnn_layout33>) -> () loc(#loc29)
        %128 = "ttnn.slice_static"(%key) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 1 : i32, 1024 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> tensor<1x1x1024x64xbf16, #ttnn_layout33> loc(#loc30)
        "ttnn.deallocate"(%key) <{force = false}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> () loc(#loc30)
        %129 = "ttnn.concat"(%127, %128) <{dim = 3 : si32}> : (tensor<1x1x1024x64xbf16, #ttnn_layout33>, tensor<1x1x1024x64xbf16, #ttnn_layout33>) -> tensor<1x1x1024x128xbf16, #ttnn_layout31> loc(#loc31)
        "ttnn.deallocate"(%128) <{force = false}> : (tensor<1x1x1024x64xbf16, #ttnn_layout33>) -> () loc(#loc31)
        "ttnn.deallocate"(%127) <{force = false}> : (tensor<1x1x1024x64xbf16, #ttnn_layout33>) -> () loc(#loc31)
        %130 = "ttnn.multiply"(%129, %122) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>, tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> tensor<1x1x1024x128xbf16, #ttnn_layout31> loc(#loc32)
        "ttnn.deallocate"(%129) <{force = false}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> () loc(#loc32)
        "ttnn.deallocate"(%122) <{force = false}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> () loc(#loc32)
        %131 = "ttnn.add"(%125, %130) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>, tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> tensor<1x1x1024x128xbf16, #ttnn_layout31> loc(#loc33)
        "ttnn.deallocate"(%130) <{force = false}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> () loc(#loc33)
        "ttnn.deallocate"(%125) <{force = false}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> () loc(#loc33)
        %132 = "ttnn.repeat"(%131) <{repeat_dims = #ttnn.shape<1x7x1x1>}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> tensor<1x7x1024x128xbf16, #ttnn_layout30> loc(#loc34)
        "ttnn.deallocate"(%131) <{force = false}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> () loc(#loc34)
        %133 = "ttnn.matmul"(%124, %132) <{transpose_a = false, transpose_b = true}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>, tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> tensor<1x7x1024x1024xbf16, #ttnn_layout34> loc(#loc35)
        "ttnn.deallocate"(%132) <{force = false}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> () loc(#loc35)
        "ttnn.deallocate"(%124) <{force = false}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> () loc(#loc35)
        %134 = "ttnn.multiply"(%133, %0) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x7x1024x1024xbf16, #ttnn_layout34>, tensor<1x1x1x1xbf16, #ttnn_layout>) -> tensor<1x7x1024x1024xbf16, #ttnn_layout34> loc(#loc36)
        "ttnn.deallocate"(%133) <{force = false}> : (tensor<1x7x1024x1024xbf16, #ttnn_layout34>) -> () loc(#loc36)
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout>) -> () loc(#loc36)
        %135 = "ttnn.add"(%134, %108) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x7x1024x1024xbf16, #ttnn_layout34>, tensor<1x1x1024x1024xbf16, #ttnn_layout26>) -> tensor<1x7x1024x1024xbf16, #ttnn_layout34> loc(#loc37)
        "ttnn.deallocate"(%134) <{force = false}> : (tensor<1x7x1024x1024xbf16, #ttnn_layout34>) -> () loc(#loc37)
        "ttnn.deallocate"(%108) <{force = false}> : (tensor<1x1x1024x1024xbf16, #ttnn_layout26>) -> () loc(#loc37)
        %136 = "ttnn.typecast"(%135) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x7x1024x1024xbf16, #ttnn_layout34>) -> tensor<1x7x1024x1024xf32, #ttnn_layout35> loc(#loc38)
        "ttnn.deallocate"(%135) <{force = false}> : (tensor<1x7x1024x1024xbf16, #ttnn_layout34>) -> () loc(#loc38)
        %137 = "ttnn.softmax"(%136) <{dimension = 3 : si32, numericStable = true}> : (tensor<1x7x1024x1024xf32, #ttnn_layout35>) -> tensor<1x7x1024x1024xf32, #ttnn_layout35> loc(#loc39)
        "ttnn.deallocate"(%136) <{force = false}> : (tensor<1x7x1024x1024xf32, #ttnn_layout35>) -> () loc(#loc39)
        %138 = "ttnn.typecast"(%137) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x7x1024x1024xf32, #ttnn_layout35>) -> tensor<1x7x1024x1024xbf16, #ttnn_layout34> loc(#loc40)
        "ttnn.deallocate"(%137) <{force = false}> : (tensor<1x7x1024x1024xf32, #ttnn_layout35>) -> () loc(#loc40)
        %139 = "ttnn.repeat"(%value) <{repeat_dims = #ttnn.shape<1x7x1x1>}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> tensor<1x7x1024x128xbf16, #ttnn_layout30> loc(#loc41)
        "ttnn.deallocate"(%value) <{force = false}> : (tensor<1x1x1024x128xbf16, #ttnn_layout31>) -> () loc(#loc41)
        %140 = "ttnn.matmul"(%138, %139) <{transpose_a = false, transpose_b = false}> : (tensor<1x7x1024x1024xbf16, #ttnn_layout34>, tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> tensor<1x7x1024x128xbf16, #ttnn_layout30> loc(#loc42)
        "ttnn.deallocate"(%139) <{force = false}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> () loc(#loc42)
        %141 = "ttnn.concatenate_heads"(%140) : (tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> tensor<1x1024x896xbf16, #ttnn_layout19> loc(#loc43)
        "ttnn.deallocate"(%140) <{force = false}> : (tensor<1x7x1024x128xbf16, #ttnn_layout30>) -> () loc(#loc43)
        %142 = "ttnn.reshape"(%141) <{shape = [1024 : i32, 896 : i32]}> : (tensor<1x1024x896xbf16, #ttnn_layout19>) -> tensor<1024x896xbf16, #ttnn_layout28> loc(#loc43)
        "ttnn.deallocate"(%141) <{force = false}> : (tensor<1x1024x896xbf16, #ttnn_layout19>) -> () loc(#loc43)
        %143 = "ttnn.matmul"(%142, %105) <{transpose_a = false, transpose_b = true}> : (tensor<1024x896xbf16, #ttnn_layout28>, tensor<3584x896xbf16, #ttnn_layout23>) -> tensor<1024x3584xbf16, #ttnn_layout27> loc(#loc44)
        "ttnn.deallocate"(%142) <{force = false}> : (tensor<1024x896xbf16, #ttnn_layout28>) -> () loc(#loc44)
        "ttnn.deallocate"(%105) <{force = false}> : (tensor<3584x896xbf16, #ttnn_layout23>) -> () loc(#loc44)
        %144 = "ttnn.reshape"(%143) <{shape = [1 : i32, 1 : i32, 1024 : i32, 3584 : i32]}> : (tensor<1024x3584xbf16, #ttnn_layout27>) -> tensor<1x1x1024x3584xbf16, #ttnn_layout36> loc(#loc52)
        "ttnn.deallocate"(%143) <{force = false}> : (tensor<1024x3584xbf16, #ttnn_layout27>) -> () loc(#loc52)
        %145 = "ttnn.reduce_scatter"(%144) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 2 : si32}> : (tensor<1x1x1024x3584xbf16, #ttnn_layout36>) -> tensor<1x1x256x3584xbf16, #ttnn_layout37> loc(#loc53)
        "ttnn.deallocate"(%144) <{force = false}> : (tensor<1x1x1024x3584xbf16, #ttnn_layout36>) -> () loc(#loc53)
        %146 = "ttnn.all_gather"(%145) <{all_gather_dim = 2 : si32, cluster_axis = 1 : ui32}> : (tensor<1x1x256x3584xbf16, #ttnn_layout37>) -> tensor<1x1x1024x3584xbf16, #ttnn_layout36> loc(#loc51)
        "ttnn.deallocate"(%145) <{force = false}> : (tensor<1x1x256x3584xbf16, #ttnn_layout37>) -> () loc(#loc51)
        %147 = "ttnn.reshape"(%146) <{shape = [1 : i32, 1024 : i32, 3584 : i32]}> : (tensor<1x1x1024x3584xbf16, #ttnn_layout36>) -> tensor<1x1024x3584xbf16, #ttnn_layout25> loc(#loc45)
        "ttnn.deallocate"(%146) <{force = false}> : (tensor<1x1x1024x3584xbf16, #ttnn_layout36>) -> () loc(#loc45)
        %148 = "ttnn.mesh_shard"(%147, %4) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x1024x3584xbf16, #ttnn_layout25>, !ttnn.device) -> tensor<2x1024x3584xbf16, #ttnn_layout12> loc(#loc)
        "ttnn.deallocate"(%147) <{force = false}> : (tensor<1x1024x3584xbf16, #ttnn_layout25>) -> () loc(#loc)
        %149 = "ttnn.mesh_shard"(%138, %4) <{shard_dims = array<i64: 0, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 2, 4, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x7x1024x1024xbf16, #ttnn_layout34>, !ttnn.device) -> tensor<2x28x1024x1024xbf16, #ttnn_layout15> loc(#loc)
        "ttnn.deallocate"(%138) <{force = false}> : (tensor<1x7x1024x1024xbf16, #ttnn_layout34>) -> () loc(#loc)
        return %148, %149 : tensor<2x1024x3584xbf16, #ttnn_layout12>, tensor<2x28x1024x1024xbf16, #ttnn_layout15> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc12 = loc("broadcast.108")
#loc13 = loc("broadcast.62")
#loc14 = loc("broadcast.23")
#loc15 = loc("reshape.103")
#loc16 = loc("add.109")
#loc17 = loc("add.63")
#loc18 = loc("broadcast.120")
#loc19 = loc("multiply.121")
#loc20 = loc("slice.113")
#loc21 = loc("negate.114")
#loc22 = loc("slice.112")
#loc23 = loc("concatenate.115")
#loc24 = loc("broadcast.117")
#loc25 = loc("multiply.118")
#loc26 = loc("add.124")
#loc27 = loc("multiply.78")
#loc28 = loc("slice.67")
#loc29 = loc("negate.68")
#loc30 = loc("slice.66")
#loc31 = loc("concatenate.69")
#loc32 = loc("multiply.72")
#loc33 = loc("add.81")
#loc34 = loc("broadcast.89")
#loc35 = loc("dot.125")
#loc36 = loc("multiply.128")
#loc37 = loc("add.133")
#loc38 = loc("convert.134")
#loc39 = loc("divide.151")
#loc40 = loc("convert.152")
#loc41 = loc("broadcast.34")
#loc42 = loc("dot.153")
#loc43 = loc("reshape.157")
#loc44 = loc("dot.158")
#loc45 = loc("reshape.159")
#loc46 = loc("add.109_decomp_matmul"(#loc16))
#loc47 = loc("add.109_decomp_add"(#loc16))
#loc48 = loc("add.63_decomp_matmul"(#loc17))
#loc49 = loc("add.63_decomp_add"(#loc17))
#loc50 = loc("dot.158_reduceScatter"(#loc44))
#loc51 = loc("dot.158_all_gather_4d"(#loc44))
#loc52 = loc("dot.158_reduceScatter_reshape_to_4d"(#loc50))
#loc53 = loc("dot.158_reduceScatter_reduce_scatter_4d"(#loc50))
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.704 (  21.765s) [        7BAA3480]loaded_executable_insta:290      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2026-01-05 17:23:19.704 (  21.765s) [        7BAA3480]loaded_executable_insta:309      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2026-01-05 17:23:19.705 (  21.766s) [        7BAA3480]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2026-01-05 17:23:19.705 (  21.766s) [        7BAA3480]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-01-05 17:23:19.705 (  21.766s) [        7BAA3480]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-01-05 17:23:19.705 (  21.766s) [        7BAA3480]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-01-05 17:23:19.705 (  21.766s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:19.705 (  21.766s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:19.705 (  21.766s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=1124):
#loc = loc(unknown)
module @SyncTensorsGraph.161 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{devices=[2,1,1]<=[8]},{devices=[2,4,1,1]<=[8]}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<3584x3584xbf16> loc(unknown), %arg1: tensor<512xbf16> loc(unknown), %arg2: tensor<512x3584xbf16> loc(unknown), %arg3: tensor<2x1024x3584xbf16> loc(unknown), %arg4: tensor<2x1x1024x1024xbf16> loc(unknown), %arg5: tensor<2x1024x128xbf16> loc(unknown), %arg6: tensor<512xbf16> loc(unknown), %arg7: tensor<512x3584xbf16> loc(unknown), %arg8: tensor<2x1024x128xbf16> loc(unknown), %arg9: tensor<3584xbf16> loc(unknown), %arg10: tensor<3584x3584xbf16> loc(unknown)) -> (tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x3584xbf16> loc(#loc)
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<2x28x1024x1024xbf16> loc(#loc)
    return %cst, %cst_0 : tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:19.705 (  21.766s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:19.705 (  21.766s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:19.705 (  21.766s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=1124):
#loc = loc(unknown)
module @SyncTensorsGraph.161 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{devices=[2,1,1]<=[8]},{devices=[2,4,1,1]<=[8]}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<3584x3584xbf16> loc(unknown), %arg1: tensor<512xbf16> loc(unknown), %arg2: tensor<512x3584xbf16> loc(unknown), %arg3: tensor<2x1024x3584xbf16> loc(unknown), %arg4: tensor<2x1x1024x1024xbf16> loc(unknown), %arg5: tensor<2x1024x128xbf16> loc(unknown), %arg6: tensor<512xbf16> loc(unknown), %arg7: tensor<512x3584xbf16> loc(unknown), %arg8: tensor<2x1024x128xbf16> loc(unknown), %arg9: tensor<3584xbf16> loc(unknown), %arg10: tensor<3584x3584xbf16> loc(unknown)) -> (tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x3584xbf16> loc(#loc)
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<2x28x1024x1024xbf16> loc(#loc)
    return %cst, %cst_0 : tensor<2x1024x3584xbf16>, tensor<2x28x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

E0105 17:23:19.772973   32204 status_macros.cc:57] INTERNAL: RET_CHECK failure (external/xla/xla/hlo/ir/hlo_sharding.cc:943) product_of_dimensions == product_of_iota_dimensions 
*** Begin stack trace ***
	tsl::CurrentStackTrace[abi:cxx11]()
	
	
	xla::status_macros::MakeErrorStream::Impl::GetStatus()
	xla::HloSharding::FromProto(xla::OpSharding const&)
	xla::HloSharding::FromProto(xla::OpSharding const&)
	xla::HloModule::CreateFromProto(xla::HloModuleProto const&, xla::HloModuleConfig const&, bool, std::unique_ptr<xla::CompilationEnvironments, std::default_delete<xla::CompilationEnvironments> >)
	mlir::ConvertMlirHloToHloModule(mlir::ModuleOp, mlir::MlirToHloConversionOptions)
	xla::PjRtCApiExecutable::GetHloModules() const
	xla::PjRtCApiLoadedExecutable::GetHloModules() const
	torch_xla::runtime::PjRtComputationClient::Compile(std::vector<torch_xla::runtime::ComputationClient::CompileInstance, std::allocator<torch_xla::runtime::ComputationClient::CompileInstance> >)
	torch_xla::XLAGraphExecutor::Compile(std::vector<c10::intrusive_ptr<torch_xla::XLATensor, c10::detail::intrusive_target_default_null_type<torch_xla::XLATensor> >, std::allocator<c10::intrusive_ptr<torch_xla::XLATensor, c10::detail::intrusive_target_default_null_type<torch_xla::XLATensor> > > >&, absl::lts_20230802::Span<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, torch::lazy::LazyGraphExecutor::SyncTensorCollection const&, torch::lazy::LazyGraphExecutor::PostOrderData*, std::vector<torch::lazy::Value, std::allocator<torch::lazy::Value> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&)
	torch_xla::XLAGraphExecutor::SyncTensorsGraphInternal(std::vector<c10::intrusive_ptr<torch_xla::XLATensor, c10::detail::intrusive_target_default_null_type<torch_xla::XLATensor> >, std::allocator<c10::intrusive_ptr<torch_xla::XLATensor, c10::detail::intrusive_target_default_null_type<torch_xla::XLATensor> > > >*, absl::lts_20230802::Span<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, torch::lazy::LazyGraphExecutor::SyncTensorsConfig const&, bool)
	torch_xla::XLAGraphExecutor::SyncTensorsGraph(std::vector<c10::intrusive_ptr<torch_xla::XLATensor, c10::detail::intrusive_target_default_null_type<torch_xla::XLATensor> >, std::allocator<c10::intrusive_ptr<torch_xla::XLATensor, c10::detail::intrusive_target_default_null_type<torch_xla::XLATensor> > > >*, absl::lts_20230802::Span<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, bool, bool, bool)
	
	
	
	
	_PyObject_MakeTpCall
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	PyObject_Call
	_PyEval_EvalFrameDefault
	
	
	PyObject_Vectorcall
	_PyEval_EvalFrameDefault
	dynamo_eval_custom_code
	
	
	_PyEval_EvalFrameDefault
	
	
	_PyEval_EvalFrameDefault
	
	
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	_PyEval_EvalFrameDefault
	
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	PyObject_Call
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	PyObject_Call
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	PyObject_Call
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	_PyEval_EvalFrameDefault
	
	PyEval_EvalCode
	
	
	PyObject_Vectorcall
	_PyEval_EvalFrameDefault
	_PyFunction_Vectorcall
	
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

2026-01-05 17:23:19.773 (  21.834s) [        7BAA3480] executable_instance.cc:62       1| ExecutableInstance::PJRT_Executable_Destroy
2026-01-05 17:23:19.773 (  21.834s) [        7BAA3480]loaded_executable_insta:280      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Destroy
2026-01-05 17:23:19.773 (  21.834s) [        7BAA3480]loaded_executable_insta:46       1| Clearing program cache.
2026-01-05 17:23:19.899 (  21.960s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.899 (  21.960s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.899 (  21.960s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.899 (  21.960s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.899 (  21.960s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.899 (  21.960s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.899 (  21.960s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.899 (  21.960s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:19.899 (  21.960s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.902 (  21.963s) [        7BAA3480]     client_instance.cc:694      1| ClientInstance::PJRT_Client_Compile
2026-01-05 17:23:19.902 (  21.963s) [        7BAA3480]     client_instance.cc:327      1| MLIR code size: 791 bytes
=== MLIR Code (size=791) ===
MLRStableHLO_v1.11.0
=== End MLIR Code ===
2026-01-05 17:23:19.902 (  21.963s) [        7BAA3480]      module_builder.cc:213      1| ModuleBuilder::buildModule
2026-01-05 17:23:19.903 (  21.964s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module vhlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1> loc("p0.1")) -> (!vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1>) {
    %0 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"xla.sdy.FuncResultSharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<true>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}, {}]>]>">}>} : (!vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1> loc(#loc1)
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<2x1024x3584x!vhlo.bf16_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}">}>]>, res_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.904 (  21.965s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}"} loc("p0.1")) -> (tensor<2x1024x3584xbf16> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}, {}]>]>"}} : (tensor<2x1024x3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc1)
    return %0 : tensor<2x1024x3584xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.904 (  21.965s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_frontend:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x3584xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>} loc("p0.1")) -> (tensor<2x1024x3584xbf16> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}, {}]>]>"}} : (tensor<2x1024x3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc1)
    return %0 : tensor<2x1024x3584xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.910 (  21.971s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_compiler:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]> loc(#loc)
  func.func @main(%arg0: tensor<2x1024x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<2x1024x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = sdy.manual_computation(%arg0) in_shardings=[<@mesh, [{"_axis_0"}, {}, {}]>] out_shardings=[<@mesh, [{}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg1: tensor<1x1024x3584xbf16> loc("p0.1")) {
      %1 = "stablehlo.all_gather"(%arg1) <{all_gather_dim = 0 : i64, channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>}> : (tensor<1x1024x3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc1)
      sdy.return %1 : tensor<2x1024x3584xbf16> loc(#loc)
    } : (tensor<2x1024x3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc)
    return %0 : tensor<2x1024x3584xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.910 (  21.971s) [        7BAA3480]      module_builder.cc:273      1| Cleaning for XLA ingestion
Out sharding: #sdy.sharding<@mesh, [{}, {}, {}]>
  Out sharding #0, dim #0, axisName.size()=0
  Out sharding #0, dim #1, axisName.size()=0
  Out sharding #0, dim #2, axisName.size()=0
Out sharding str for out sharding #0 is: {replicated}
Module after injecting out sharding result and simplifying main function:
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x3584xbf16>) -> tensor<2x1024x3584xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x3584xbf16>
    return %cst : tensor<2x1024x3584xbf16>
  }
}
2026-01-05 17:23:19.911 (  21.972s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_compiler_cleaned:
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x3584xbf16> loc(unknown)) -> tensor<2x1024x3584xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x3584xbf16> loc(#loc)
    return %cst : tensor<2x1024x3584xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.913 (  21.974s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module ttir:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
      func.func @main(%arg0: tensor<2x1024x3584xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<2x1024x3584xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) {
        %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x3584xbf16>) -> tensor<1x1024x3584xbf16> loc(#loc)
        %1 = "ttir.all_gather"(%0) <{all_gather_dim = 0 : si32, cluster_axis = 0 : ui32}> : (tensor<1x1024x3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc1)
        %2 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x3584xbf16>) -> tensor<2x1024x3584xbf16> loc(#loc)
        return %2 : tensor<2x1024x3584xbf16> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.914 (  21.974s) [        7BAA3480]      module_builder.cc:823   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2026-01-05 17:23:19.914 (  21.974s) [        7BAA3480]      module_builder.cc:837   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2026-01-05 17:23:19.914 (  21.974s) [        7BAA3480]      module_builder.cc:847   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2026-01-05 17:23:19.926 (  21.987s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module ttnn:
#dram = #ttnn.buffer_type<dram>
#loc1 = loc("p0.1")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<64x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<32x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 1024 + d2, d3), <1x1>, memref<32x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 2048 + d1 * 1024 + d2, d3), <1x1>, memref<64x112x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]> loc(#loc)
      func.func @main(%arg0: tensor<2x1024x3584xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<2x1024x3584xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<presharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x3584xbf16, #ttnn_layout>, !ttnn.device) -> tensor<1x1024x3584xbf16, #ttnn_layout1> loc(#loc)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<2x1024x3584xbf16, #ttnn_layout>) -> () loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1024 : i32, 3584 : i32]}> : (tensor<1x1024x3584xbf16, #ttnn_layout1>) -> tensor<1x1x1024x3584xbf16, #ttnn_layout2> loc(#loc2)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x1024x3584xbf16, #ttnn_layout1>) -> () loc(#loc2)
        %3 = "ttnn.all_gather"(%2) <{all_gather_dim = 1 : si32, cluster_axis = 0 : ui32}> : (tensor<1x1x1024x3584xbf16, #ttnn_layout2>) -> tensor<1x2x1024x3584xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x1024x3584xbf16, #ttnn_layout2>) -> () loc(#loc3)
        %4 = "ttnn.reshape"(%3) <{shape = [2 : i32, 1024 : i32, 3584 : i32]}> : (tensor<1x2x1024x3584xbf16, #ttnn_layout3>) -> tensor<2x1024x3584xbf16, #ttnn_layout> loc(#loc1)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x2x1024x3584xbf16, #ttnn_layout3>) -> () loc(#loc1)
        return %4 : tensor<2x1024x3584xbf16, #ttnn_layout> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("p0.1_reshape_to_4d"(#loc1))
#loc3 = loc("p0.1_all_gather_4d"(#loc1))
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:19.930 (  21.991s) [        7BAA3480]loaded_executable_insta:290      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2026-01-05 17:23:19.930 (  21.991s) [        7BAA3480]loaded_executable_insta:309      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2026-01-05 17:23:19.930 (  21.991s) [        7BAA3480]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2026-01-05 17:23:19.930 (  21.991s) [        7BAA3480]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-01-05 17:23:19.930 (  21.991s) [        7BAA3480]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-01-05 17:23:19.930 (  21.991s) [        7BAA3480]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-01-05 17:23:19.930 (  21.991s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:19.930 (  21.991s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:19.930 (  21.991s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=503):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x3584xbf16> loc(unknown)) -> tensor<2x1024x3584xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x3584xbf16> loc(#loc)
    return %cst : tensor<2x1024x3584xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:19.930 (  21.991s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:19.930 (  21.991s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:19.930 (  21.991s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=503):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x3584xbf16> loc(unknown)) -> tensor<2x1024x3584xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x3584xbf16> loc(#loc)
    return %cst : tensor<2x1024x3584xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:19.933 (  21.993s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:19.933 (  21.993s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:19.933 (  21.993s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=503):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x3584xbf16> loc(unknown)) -> tensor<2x1024x3584xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x3584xbf16> loc(#loc)
    return %cst : tensor<2x1024x3584xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:19.933 (  21.993s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:19.933 (  21.994s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:19.933 (  21.994s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=503):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x3584xbf16> loc(unknown)) -> tensor<2x1024x3584xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x3584xbf16> loc(#loc)
    return %cst : tensor<2x1024x3584xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480] executable_instance.cc:219      1| ExecutableInstance::PJRT_Executable_NumOutputs
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]loaded_executable_insta:345      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2026-01-05 17:23:19.934 (  21.995s) [        7BAA3480]flatbuffer_loaded_execu:260      1| FlatbufferLoadedExecutableInstance::Execute
2026-01-05 17:23:19.935 (  21.995s) [        7BAA3480]     client_instance.cc:431      1| ClientInstance::getOrCreateMeshDevice - reshaping mesh device - [1, 8] -> [2, 4]
2026-01-05 17:23:19.935 (  21.995s) [        7BAA3480]     client_instance.cc:506      1| Closing parent mesh.
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 0 with shape [2, 1024, 3584] and UID 88
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 1 with shape [2, 1024, 3584] and UID 89
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 2 with shape [2, 1024, 3584] and UID 90
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 3 with shape [2, 1024, 3584] and UID 91
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 4 with shape [2, 1024, 3584] and UID 92
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 5 with shape [2, 1024, 3584] and UID 93
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 6 with shape [2, 1024, 3584] and UID 94
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 7 with shape [2, 1024, 3584] and UID 95
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480] executable_instance.cc:62       1| ExecutableInstance::PJRT_Executable_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]loaded_executable_insta:280      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Destroy
2026-01-05 17:23:22.871 (  24.932s) [        7BAA3480]loaded_executable_insta:46       1| Clearing program cache.
2026-01-05 17:23:22.873 (  24.934s) [        7BAA3480]     buffer_instance.cc:564      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2026-01-05 17:23:22.873 (  24.934s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:22.873 (  24.934s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:22.873 (  24.934s) [        7BAA3480]     buffer_instance.cc:586      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2026-01-05 17:23:22.873 (  24.934s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:22.873 (  24.934s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:23.569 (  25.630s) [        4E7E1640]     buffer_instance.cc:425      1| Returning tensor to host with host_runtime_tensors ct = 8 from device 0 with buffer UID 88 and shape [2, 1024, 3584]
2026-01-05 17:23:23.571 (  25.632s) [        4DFE0640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:23.582 (  25.643s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:23.582 (  25.643s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:23.582 (  25.643s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:23.582 (  25.643s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:23.582 (  25.643s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:23.582 (  25.643s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:23.582 (  25.643s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:23.582 (  25.643s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:23.582 (  25.643s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:23.586 (  25.647s) [        7BAA3480]     client_instance.cc:694      1| ClientInstance::PJRT_Client_Compile
2026-01-05 17:23:23.587 (  25.647s) [        7BAA3480]     client_instance.cc:327      1| MLIR code size: 791 bytes
=== MLIR Code (size=791) ===
MLRStableHLO_v1.11.0
=== End MLIR Code ===
2026-01-05 17:23:23.587 (  25.647s) [        7BAA3480]      module_builder.cc:213      1| ModuleBuilder::buildModule
2026-01-05 17:23:23.587 (  25.648s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module vhlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1> loc("p0.1")) -> (!vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1>) {
    %0 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"xla.sdy.FuncResultSharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<true>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}, {}]>]>">}>} : (!vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1> loc(#loc1)
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}">}>]>, res_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:23.588 (  25.649s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}"} loc("p0.1")) -> (tensor<2x1024x128xbf16> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}, {}]>]>"}} : (tensor<2x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc1)
    return %0 : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:23.589 (  25.650s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_frontend:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>} loc("p0.1")) -> (tensor<2x1024x128xbf16> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}, {}]>]>"}} : (tensor<2x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc1)
    return %0 : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:23.594 (  25.655s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_compiler:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]> loc(#loc)
  func.func @main(%arg0: tensor<2x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<2x1024x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = sdy.manual_computation(%arg0) in_shardings=[<@mesh, [{"_axis_0"}, {}, {}]>] out_shardings=[<@mesh, [{}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg1: tensor<1x1024x128xbf16> loc("p0.1")) {
      %1 = "stablehlo.all_gather"(%arg1) <{all_gather_dim = 0 : i64, channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>}> : (tensor<1x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc1)
      sdy.return %1 : tensor<2x1024x128xbf16> loc(#loc)
    } : (tensor<2x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc)
    return %0 : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:23.595 (  25.656s) [        7BAA3480]      module_builder.cc:273      1| Cleaning for XLA ingestion
Out sharding: #sdy.sharding<@mesh, [{}, {}, {}]>
  Out sharding #0, dim #0, axisName.size()=0
  Out sharding #0, dim #1, axisName.size()=0
  Out sharding #0, dim #2, axisName.size()=0
Out sharding str for out sharding #0 is: {replicated}
Module after injecting out sharding result and simplifying main function:
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16>) -> tensor<2x1024x128xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x128xbf16>
    return %cst : tensor<2x1024x128xbf16>
  }
}
2026-01-05 17:23:23.595 (  25.656s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_compiler_cleaned:
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> loc(unknown)) -> tensor<2x1024x128xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x128xbf16> loc(#loc)
    return %cst : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:23.598 (  25.659s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module ttir:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
      func.func @main(%arg0: tensor<2x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<2x1024x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) {
        %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc)
        %1 = "ttir.all_gather"(%0) <{all_gather_dim = 0 : si32, cluster_axis = 0 : ui32}> : (tensor<1x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc1)
        %2 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc)
        return %2 : tensor<2x1024x128xbf16> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:23.598 (  25.659s) [        7BAA3480]      module_builder.cc:823   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2026-01-05 17:23:23.598 (  25.659s) [        7BAA3480]      module_builder.cc:837   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2026-01-05 17:23:23.598 (  25.659s) [        7BAA3480]      module_builder.cc:847   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2026-01-05 17:23:23.612 (  25.673s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module ttnn:
#dram = #ttnn.buffer_type<dram>
#loc1 = loc("p0.1")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<64x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 1024 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 2048 + d1 * 1024 + d2, d3), <1x1>, memref<64x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]> loc(#loc)
      func.func @main(%arg0: tensor<2x1024x128xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<2x1024x128xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<presharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x128xbf16, #ttnn_layout>, !ttnn.device) -> tensor<1x1024x128xbf16, #ttnn_layout1> loc(#loc)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<2x1024x128xbf16, #ttnn_layout>) -> () loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x1024x128xbf16, #ttnn_layout1>) -> tensor<1x1x1024x128xbf16, #ttnn_layout2> loc(#loc2)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x1024x128xbf16, #ttnn_layout1>) -> () loc(#loc2)
        %3 = "ttnn.all_gather"(%2) <{all_gather_dim = 1 : si32, cluster_axis = 0 : ui32}> : (tensor<1x1x1024x128xbf16, #ttnn_layout2>) -> tensor<1x2x1024x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x1024x128xbf16, #ttnn_layout2>) -> () loc(#loc3)
        %4 = "ttnn.reshape"(%3) <{shape = [2 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x2x1024x128xbf16, #ttnn_layout3>) -> tensor<2x1024x128xbf16, #ttnn_layout> loc(#loc1)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x2x1024x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        return %4 : tensor<2x1024x128xbf16, #ttnn_layout> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("p0.1_reshape_to_4d"(#loc1))
#loc3 = loc("p0.1_all_gather_4d"(#loc1))
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:23.617 (  25.678s) [        7BAA3480]loaded_executable_insta:290      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2026-01-05 17:23:23.617 (  25.678s) [        7BAA3480]loaded_executable_insta:309      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2026-01-05 17:23:23.617 (  25.678s) [        7BAA3480]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2026-01-05 17:23:23.617 (  25.678s) [        7BAA3480]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-01-05 17:23:23.617 (  25.678s) [        7BAA3480]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-01-05 17:23:23.617 (  25.678s) [        7BAA3480]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-01-05 17:23:23.617 (  25.678s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:23.617 (  25.678s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:23.617 (  25.678s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=499):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> loc(unknown)) -> tensor<2x1024x128xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x128xbf16> loc(#loc)
    return %cst : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:23.617 (  25.678s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:23.617 (  25.678s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:23.617 (  25.678s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=499):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> loc(unknown)) -> tensor<2x1024x128xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x128xbf16> loc(#loc)
    return %cst : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:23.620 (  25.681s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:23.620 (  25.681s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:23.620 (  25.681s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=499):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> loc(unknown)) -> tensor<2x1024x128xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x128xbf16> loc(#loc)
    return %cst : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:23.620 (  25.681s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:23.620 (  25.681s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:23.620 (  25.681s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=499):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> loc(unknown)) -> tensor<2x1024x128xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x128xbf16> loc(#loc)
    return %cst : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480] executable_instance.cc:219      1| ExecutableInstance::PJRT_Executable_NumOutputs
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]loaded_executable_insta:345      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]flatbuffer_loaded_execu:260      1| FlatbufferLoadedExecutableInstance::Execute
2026-01-05 17:23:23.622 (  25.683s) [        7BAA3480]     client_instance.cc:423      1| ClientInstance::getOrCreateMeshDevice - reusing already opened mesh device [2, 4]
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 0 with shape [2, 1024, 128] and UID 96
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 1 with shape [2, 1024, 128] and UID 97
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 2 with shape [2, 1024, 128] and UID 98
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 3 with shape [2, 1024, 128] and UID 99
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 4 with shape [2, 1024, 128] and UID 100
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 5 with shape [2, 1024, 128] and UID 101
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 6 with shape [2, 1024, 128] and UID 102
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 7 with shape [2, 1024, 128] and UID 103
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.548 (  27.609s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480] executable_instance.cc:62       1| ExecutableInstance::PJRT_Executable_Destroy
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]loaded_executable_insta:280      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Destroy
2026-01-05 17:23:25.549 (  27.609s) [        7BAA3480]loaded_executable_insta:46       1| Clearing program cache.
2026-01-05 17:23:25.550 (  27.611s) [        7BAA3480]     buffer_instance.cc:564      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2026-01-05 17:23:25.550 (  27.611s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:25.550 (  27.611s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:25.550 (  27.611s) [        7BAA3480]     buffer_instance.cc:586      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2026-01-05 17:23:25.550 (  27.611s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:25.550 (  27.611s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:26.200 (  28.261s) [        73FFF640]     buffer_instance.cc:425      1| Returning tensor to host with host_runtime_tensors ct = 8 from device 0 with buffer UID 96 and shape [2, 1024, 128]
2026-01-05 17:23:26.200 (  28.261s) [        737FE640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:26.202 (  28.263s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.202 (  28.263s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.202 (  28.263s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.202 (  28.263s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.202 (  28.263s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.202 (  28.263s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.202 (  28.263s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.202 (  28.263s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.203 (  28.264s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.207 (  28.268s) [        7BAA3480]     client_instance.cc:694      1| ClientInstance::PJRT_Client_Compile
2026-01-05 17:23:26.207 (  28.268s) [        7BAA3480]     client_instance.cc:327      1| MLIR code size: 791 bytes
=== MLIR Code (size=791) ===
MLRStableHLO_v1.11.0
=== End MLIR Code ===
2026-01-05 17:23:26.207 (  28.268s) [        7BAA3480]      module_builder.cc:213      1| ModuleBuilder::buildModule
2026-01-05 17:23:26.207 (  28.268s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module vhlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1> loc("p0.1")) -> (!vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1>) {
    %0 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"xla.sdy.FuncResultSharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<true>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}, {}]>]>">}>} : (!vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1> loc(#loc1)
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<2x1024x128x!vhlo.bf16_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}">}>]>, res_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.209 (  28.270s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}"} loc("p0.1")) -> (tensor<2x1024x128xbf16> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}, {}]>]>"}} : (tensor<2x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc1)
    return %0 : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.209 (  28.270s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_frontend:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>} loc("p0.1")) -> (tensor<2x1024x128xbf16> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}, {}]>]>"}} : (tensor<2x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc1)
    return %0 : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.214 (  28.275s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_compiler:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]> loc(#loc)
  func.func @main(%arg0: tensor<2x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<2x1024x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = sdy.manual_computation(%arg0) in_shardings=[<@mesh, [{"_axis_0"}, {}, {}]>] out_shardings=[<@mesh, [{}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg1: tensor<1x1024x128xbf16> loc("p0.1")) {
      %1 = "stablehlo.all_gather"(%arg1) <{all_gather_dim = 0 : i64, channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>}> : (tensor<1x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc1)
      sdy.return %1 : tensor<2x1024x128xbf16> loc(#loc)
    } : (tensor<2x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc)
    return %0 : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.215 (  28.276s) [        7BAA3480]      module_builder.cc:273      1| Cleaning for XLA ingestion
Out sharding: #sdy.sharding<@mesh, [{}, {}, {}]>
  Out sharding #0, dim #0, axisName.size()=0
  Out sharding #0, dim #1, axisName.size()=0
  Out sharding #0, dim #2, axisName.size()=0
Out sharding str for out sharding #0 is: {replicated}
Module after injecting out sharding result and simplifying main function:
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16>) -> tensor<2x1024x128xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x128xbf16>
    return %cst : tensor<2x1024x128xbf16>
  }
}
2026-01-05 17:23:26.215 (  28.276s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_compiler_cleaned:
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> loc(unknown)) -> tensor<2x1024x128xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x128xbf16> loc(#loc)
    return %cst : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.218 (  28.279s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module ttir:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
      func.func @main(%arg0: tensor<2x1024x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<2x1024x128xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) {
        %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x128xbf16>) -> tensor<1x1024x128xbf16> loc(#loc)
        %1 = "ttir.all_gather"(%0) <{all_gather_dim = 0 : si32, cluster_axis = 0 : ui32}> : (tensor<1x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc1)
        %2 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x128xbf16>) -> tensor<2x1024x128xbf16> loc(#loc)
        return %2 : tensor<2x1024x128xbf16> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.218 (  28.279s) [        7BAA3480]      module_builder.cc:823   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2026-01-05 17:23:26.218 (  28.279s) [        7BAA3480]      module_builder.cc:837   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2026-01-05 17:23:26.218 (  28.279s) [        7BAA3480]      module_builder.cc:847   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2026-01-05 17:23:26.231 (  28.292s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module ttnn:
#dram = #ttnn.buffer_type<dram>
#loc1 = loc("p0.1")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<64x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 1024 + d1, d2), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 1024 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 2048 + d1 * 1024 + d2, d3), <1x1>, memref<64x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]> loc(#loc)
      func.func @main(%arg0: tensor<2x1024x128xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<2x1024x128xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<presharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1024x128xbf16, #ttnn_layout>, !ttnn.device) -> tensor<1x1024x128xbf16, #ttnn_layout1> loc(#loc)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<2x1024x128xbf16, #ttnn_layout>) -> () loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x1024x128xbf16, #ttnn_layout1>) -> tensor<1x1x1024x128xbf16, #ttnn_layout2> loc(#loc2)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x1024x128xbf16, #ttnn_layout1>) -> () loc(#loc2)
        %3 = "ttnn.all_gather"(%2) <{all_gather_dim = 1 : si32, cluster_axis = 0 : ui32}> : (tensor<1x1x1024x128xbf16, #ttnn_layout2>) -> tensor<1x2x1024x128xbf16, #ttnn_layout3> loc(#loc3)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x1024x128xbf16, #ttnn_layout2>) -> () loc(#loc3)
        %4 = "ttnn.reshape"(%3) <{shape = [2 : i32, 1024 : i32, 128 : i32]}> : (tensor<1x2x1024x128xbf16, #ttnn_layout3>) -> tensor<2x1024x128xbf16, #ttnn_layout> loc(#loc1)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x2x1024x128xbf16, #ttnn_layout3>) -> () loc(#loc1)
        return %4 : tensor<2x1024x128xbf16, #ttnn_layout> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("p0.1_reshape_to_4d"(#loc1))
#loc3 = loc("p0.1_all_gather_4d"(#loc1))
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.236 (  28.297s) [        7BAA3480]loaded_executable_insta:290      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2026-01-05 17:23:26.236 (  28.297s) [        7BAA3480]loaded_executable_insta:309      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2026-01-05 17:23:26.236 (  28.297s) [        7BAA3480]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2026-01-05 17:23:26.236 (  28.297s) [        7BAA3480]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-01-05 17:23:26.236 (  28.297s) [        7BAA3480]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-01-05 17:23:26.236 (  28.297s) [        7BAA3480]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-01-05 17:23:26.236 (  28.297s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:26.236 (  28.297s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:26.236 (  28.297s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=499):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> loc(unknown)) -> tensor<2x1024x128xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x128xbf16> loc(#loc)
    return %cst : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:26.236 (  28.297s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:26.236 (  28.297s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:26.236 (  28.297s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=499):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> loc(unknown)) -> tensor<2x1024x128xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x128xbf16> loc(#loc)
    return %cst : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:26.239 (  28.300s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:26.239 (  28.300s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:26.239 (  28.300s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=499):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> loc(unknown)) -> tensor<2x1024x128xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x128xbf16> loc(#loc)
    return %cst : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:26.239 (  28.300s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:26.239 (  28.300s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:26.239 (  28.300s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=499):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1024x128xbf16> loc(unknown)) -> tensor<2x1024x128xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1024x128xbf16> loc(#loc)
    return %cst : tensor<2x1024x128xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:26.241 (  28.301s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480] executable_instance.cc:219      1| ExecutableInstance::PJRT_Executable_NumOutputs
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]loaded_executable_insta:345      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]flatbuffer_loaded_execu:260      1| FlatbufferLoadedExecutableInstance::Execute
2026-01-05 17:23:26.241 (  28.302s) [        7BAA3480]     client_instance.cc:423      1| ClientInstance::getOrCreateMeshDevice - reusing already opened mesh device [2, 4]
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 0 with shape [2, 1024, 128] and UID 104
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 1 with shape [2, 1024, 128] and UID 105
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 2 with shape [2, 1024, 128] and UID 106
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 3 with shape [2, 1024, 128] and UID 107
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 4 with shape [2, 1024, 128] and UID 108
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 5 with shape [2, 1024, 128] and UID 109
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 6 with shape [2, 1024, 128] and UID 110
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 7 with shape [2, 1024, 128] and UID 111
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:26.263 (  28.324s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.264 (  28.324s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:26.264 (  28.324s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:26.264 (  28.324s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:26.264 (  28.324s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:26.264 (  28.324s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:26.264 (  28.324s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:26.264 (  28.324s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:26.264 (  28.324s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:26.264 (  28.324s) [        7BAA3480] executable_instance.cc:62       1| ExecutableInstance::PJRT_Executable_Destroy
2026-01-05 17:23:26.264 (  28.324s) [        7BAA3480]loaded_executable_insta:280      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Destroy
2026-01-05 17:23:26.264 (  28.324s) [        7BAA3480]loaded_executable_insta:46       1| Clearing program cache.
2026-01-05 17:23:26.265 (  28.325s) [        7BAA3480]     buffer_instance.cc:564      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2026-01-05 17:23:26.265 (  28.325s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:26.265 (  28.325s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:26.265 (  28.325s) [        7BAA3480]     buffer_instance.cc:586      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2026-01-05 17:23:26.265 (  28.326s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:26.265 (  28.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:26.271 (  28.332s) [        88FF9640]     buffer_instance.cc:425      1| Returning tensor to host with host_runtime_tensors ct = 8 from device 0 with buffer UID 104 and shape [2, 1024, 128]
2026-01-05 17:23:26.271 (  28.332s) [        72FFD640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:26.273 (  28.334s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.273 (  28.334s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.273 (  28.334s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.273 (  28.334s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.273 (  28.334s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.273 (  28.334s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.273 (  28.334s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.273 (  28.334s) [        7BAA3480]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-05 17:23:26.273 (  28.334s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.277 (  28.338s) [        7BAA3480]     client_instance.cc:694      1| ClientInstance::PJRT_Client_Compile
2026-01-05 17:23:26.277 (  28.338s) [        7BAA3480]     client_instance.cc:327      1| MLIR code size: 802 bytes
=== MLIR Code (size=802) ===
MLRStableHLO_v1.11.0
=== End MLIR Code ===
2026-01-05 17:23:26.277 (  28.338s) [        7BAA3480]      module_builder.cc:213      1| ModuleBuilder::buildModule
2026-01-05 17:23:26.277 (  28.338s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module vhlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<2x1x1024x1024x!vhlo.bf16_v1> loc("p0.1")) -> (!vhlo.tensor_v1<2x1x1024x1024x!vhlo.bf16_v1>) {
    %0 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"xla.sdy.FuncResultSharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<true>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}, {}, {}]>]>">}>} : (!vhlo.tensor_v1<2x1x1024x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<2x1x1024x1024x!vhlo.bf16_v1> loc(#loc1)
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<2x1x1024x1024x!vhlo.bf16_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1,1,1,4]<=[8] last_tile_dim_replicate}">}>]>, res_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.279 (  28.340s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1x1024x1024xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,1,4]<=[8] last_tile_dim_replicate}"} loc("p0.1")) -> (tensor<2x1x1024x1024xbf16> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}, {}, {}]>]>"}} : (tensor<2x1x1024x1024xbf16>) -> tensor<2x1x1024x1024xbf16> loc(#loc1)
    return %0 : tensor<2x1x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.279 (  28.340s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_frontend:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2, \22_axis_1\22=4]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1x1024x1024xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}, {}, {}]>"}, mhlo.sharding = "{devices=[2,1,1,1,4]<=[8] last_tile_dim_replicate}", ttcore.argument_type = #ttcore.argument_type<input>} loc("p0.1")) -> (tensor<2x1x1024x1024xbf16> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}, {}, {}]>]>"}} : (tensor<2x1x1024x1024xbf16>) -> tensor<2x1x1024x1024xbf16> loc(#loc1)
    return %0 : tensor<2x1x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.284 (  28.345s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_compiler:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2, "_axis_1"=4]> loc(#loc)
  func.func @main(%arg0: tensor<2x1x1024x1024xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<2x1x1024x1024xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) {
    %0 = sdy.manual_computation(%arg0) in_shardings=[<@mesh, [{"_axis_0"}, {}, {}, {}]>] out_shardings=[<@mesh, [{}, {}, {}, {}]>] manual_axes={"_axis_0", "_axis_1"} (%arg1: tensor<1x1x1024x1024xbf16> loc("p0.1")) {
      %1 = "stablehlo.all_gather"(%arg1) <{all_gather_dim = 0 : i64, channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 4], [1, 5], [2, 6], [3, 7]]> : tensor<4x2xi64>}> : (tensor<1x1x1024x1024xbf16>) -> tensor<2x1x1024x1024xbf16> loc(#loc1)
      sdy.return %1 : tensor<2x1x1024x1024xbf16> loc(#loc)
    } : (tensor<2x1x1024x1024xbf16>) -> tensor<2x1x1024x1024xbf16> loc(#loc)
    return %0 : tensor<2x1x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.285 (  28.346s) [        7BAA3480]      module_builder.cc:273      1| Cleaning for XLA ingestion
Out sharding: #sdy.sharding<@mesh, [{}, {}, {}, {}]>
  Out sharding #0, dim #0, axisName.size()=0
  Out sharding #0, dim #1, axisName.size()=0
  Out sharding #0, dim #2, axisName.size()=0
  Out sharding #0, dim #3, axisName.size()=0
Out sharding str for out sharding #0 is: {replicated}
Module after injecting out sharding result and simplifying main function:
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1x1024x1024xbf16>) -> tensor<2x1x1024x1024xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1x1024x1024xbf16>
    return %cst : tensor<2x1x1024x1024xbf16>
  }
}
2026-01-05 17:23:26.286 (  28.347s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module shlo_compiler_cleaned:
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1x1024x1024xbf16> loc(unknown)) -> tensor<2x1x1024x1024xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1x1024x1024xbf16> loc(#loc)
    return %cst : tensor<2x1x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.288 (  28.349s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module ttir:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
      func.func @main(%arg0: tensor<2x1x1024x1024xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<2x1x1024x1024xbf16> {ttcore.shard_status = #ttcore.shard_status<presharded>}) {
        %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1x1024x1024xbf16>) -> tensor<1x1x1024x1024xbf16> loc(#loc)
        %1 = "ttir.all_gather"(%0) <{all_gather_dim = 0 : si32, cluster_axis = 0 : ui32}> : (tensor<1x1x1024x1024xbf16>) -> tensor<2x1x1024x1024xbf16> loc(#loc1)
        %2 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1x1024x1024xbf16>) -> tensor<2x1x1024x1024xbf16> loc(#loc)
        return %2 : tensor<2x1x1024x1024xbf16> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.289 (  28.349s) [        7BAA3480]      module_builder.cc:823   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2026-01-05 17:23:26.289 (  28.349s) [        7BAA3480]      module_builder.cc:837   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2026-01-05 17:23:26.289 (  28.349s) [        7BAA3480]      module_builder.cc:847   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2026-01-05 17:23:26.301 (  28.362s) [        7BAA3480]      module_builder.cc:1063     1| MLIR Module ttnn:
#dram = #ttnn.buffer_type<dram>
#loc1 = loc("p0.1")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073142976, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073160096, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1, 2, 3, 4, 5, 6, 7], [1 : i32, 1 : i32, 1 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 1024 + d2, d3), <1x1>, memref<64x32x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 1024 + d2, d3), <1x1>, memref<32x32x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>} {
  ttcore.device_module {
    builtin.module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 2x4>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 2x4, chipIds = [0, 1, 2, 3, 4, 5, 6, 7]> loc(#loc)
      func.func @main(%arg0: tensor<2x1x1024x1024xbf16, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p0.1")) -> (tensor<2x1x1024x1024xbf16, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<presharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 2x4>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: 0, -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<2x1x1024x1024xbf16, #ttnn_layout>, !ttnn.device) -> tensor<1x1x1024x1024xbf16, #ttnn_layout1> loc(#loc)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<2x1x1024x1024xbf16, #ttnn_layout>) -> () loc(#loc)
        %2 = "ttnn.all_gather"(%1) <{all_gather_dim = 0 : si32, cluster_axis = 0 : ui32}> : (tensor<1x1x1024x1024xbf16, #ttnn_layout1>) -> tensor<2x1x1024x1024xbf16, #ttnn_layout> loc(#loc1)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x1x1024x1024xbf16, #ttnn_layout1>) -> () loc(#loc1)
        return %2 : tensor<2x1x1024x1024xbf16, #ttnn_layout> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-01-05 17:23:26.305 (  28.366s) [        7BAA3480]loaded_executable_insta:290      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2026-01-05 17:23:26.305 (  28.366s) [        7BAA3480]loaded_executable_insta:309      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2026-01-05 17:23:26.306 (  28.367s) [        7BAA3480]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2026-01-05 17:23:26.306 (  28.367s) [        7BAA3480]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-01-05 17:23:26.306 (  28.367s) [        7BAA3480]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-01-05 17:23:26.306 (  28.367s) [        7BAA3480]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-01-05 17:23:26.306 (  28.367s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:26.306 (  28.367s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:26.306 (  28.367s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=511):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1x1024x1024xbf16> loc(unknown)) -> tensor<2x1x1024x1024xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1x1024x1024xbf16> loc(#loc)
    return %cst : tensor<2x1x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:26.306 (  28.367s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:26.306 (  28.367s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:26.306 (  28.367s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=511):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1x1024x1024xbf16> loc(unknown)) -> tensor<2x1x1024x1024xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1x1024x1024xbf16> loc(#loc)
    return %cst : tensor<2x1x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:26.308 (  28.369s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:26.308 (  28.369s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:26.308 (  28.369s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=511):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1x1024x1024xbf16> loc(unknown)) -> tensor<2x1x1024x1024xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1x1024x1024xbf16> loc(#loc)
    return %cst : tensor<2x1x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:26.308 (  28.369s) [        7BAA3480] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-05 17:23:26.308 (  28.369s) [        7BAA3480] executable_instance.cc:147      1| USE_SANITIZED_EMITHLO_IR=1, using sanitized MLIR code
2026-01-05 17:23:26.308 (  28.369s) [        7BAA3480] executable_instance.cc:196      1| Literal MLIR code (size=511):
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<2x1x1024x1024xbf16> loc(unknown)) -> tensor<2x1x1024x1024xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<2x1x1024x1024xbf16> loc(#loc)
    return %cst : tensor<2x1x1024x1024xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)

2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480] executable_instance.cc:219      1| ExecutableInstance::PJRT_Executable_NumOutputs
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]loaded_executable_insta:345      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]flatbuffer_loaded_execu:260      1| FlatbufferLoadedExecutableInstance::Execute
2026-01-05 17:23:26.310 (  28.371s) [        7BAA3480]     client_instance.cc:423      1| ClientInstance::getOrCreateMeshDevice - reusing already opened mesh device [2, 4]
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 0 with shape [2, 1, 1024, 1024] and UID 112
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 1 with shape [2, 1, 1024, 1024] and UID 113
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 2 with shape [2, 1, 1024, 1024] and UID 114
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 3 with shape [2, 1, 1024, 1024] and UID 115
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 4 with shape [2, 1, 1024, 1024] and UID 116
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 5 with shape [2, 1, 1024, 1024] and UID 117
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 6 with shape [2, 1, 1024, 1024] and UID 118
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 7 with shape [2, 1, 1024, 1024] and UID 119
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:28.215 (  30.276s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:28.216 (  30.276s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:28.216 (  30.276s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:28.216 (  30.276s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:28.216 (  30.276s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:28.216 (  30.276s) [        7BAA3480] executable_instance.cc:62       1| ExecutableInstance::PJRT_Executable_Destroy
2026-01-05 17:23:28.216 (  30.276s) [        7BAA3480]loaded_executable_insta:280      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Destroy
2026-01-05 17:23:28.216 (  30.276s) [        7BAA3480]loaded_executable_insta:46       1| Clearing program cache.
2026-01-05 17:23:28.217 (  30.277s) [        7BAA3480]     buffer_instance.cc:564      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2026-01-05 17:23:28.217 (  30.278s) [        7BAA3480]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-05 17:23:28.217 (  30.278s) [        7BAA3480]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-05 17:23:28.217 (  30.278s) [        7BAA3480]     buffer_instance.cc:586      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2026-01-05 17:23:28.217 (  30.278s) [        7BAA3480]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-05 17:23:28.217 (  30.278s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:28.880 (  30.941s) [        73FFF640]     buffer_instance.cc:425      1| Returning tensor to host with host_runtime_tensors ct = 8 from device 0 with buffer UID 112 and shape [2, 1, 1024, 1024]
2026-01-05 17:23:28.881 (  30.941s) [        72FFD640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
FAILED

=================================== FAILURES ===================================
_________ test_qwen2_5_attention_prefill_push[7b_instruct-1024-llmbox] _________

seq_len = 1024, variant = <ModelVariant.QWEN_2_5_7B_INSTRUCT: '7b_instruct'>
arch = 'llmbox'

    @pytest.mark.push
    @parametrize_arch(["single_device", "llmbox"])
    @pytest.mark.parametrize("seq_len", [1024])
    @pytest.mark.parametrize("variant", [Qwen2_5ModelVariant.QWEN_2_5_7B_INSTRUCT])
    def test_qwen2_5_attention_prefill_push(seq_len, variant, arch):
        xr.set_device_type("TT")
    
        loader = Qwen2_5ModelLoader(variant=variant)
        config = loader.load_config()
        attention = Qwen2Attention(config, layer_idx=0).to(torch.bfloat16)
    
        # Determine batch size and mesh configuration based on attention heads
        if arch == "llmbox":
            num_devices = xr.global_runtime_device_count()
            num_heads = config.num_attention_heads
            num_key_value_heads = getattr(config, "num_key_value_heads", num_heads)
    
            if num_heads % 8 == 0 and num_key_value_heads % 8 == 0:
                # Use 1x8 mesh for full model parallelism
                batch_size = 1
                mesh_shape = (1, num_devices)
                device_ids = np.array(range(num_devices))
                mesh = Mesh(device_ids, mesh_shape, ("batch", "model"))
    
                def get_shard_spec(attention, args, kwargs):
                    shard_specs = {}
                    # Don't shard args - no batch dimension splitting
                    # Only shard the model weights
                    shard_specs[attention.q_proj.weight] = ("model", None)
                    shard_specs[attention.k_proj.weight] = ("model", None)
                    shard_specs[attention.v_proj.weight] = ("model", None)
                    shard_specs[attention.o_proj.weight] = (None, "model")
                    return shard_specs
    
            elif num_heads % 4 == 0 and num_key_value_heads % 4 == 0:
                # Use 2x4 mesh when divisible by 4
                batch_size = 2
                mesh_shape = (2, num_devices // 2)
                device_ids = np.array(range(num_devices))
                mesh = Mesh(device_ids, mesh_shape, ("batch", "model"))
    
                def get_shard_spec(attention, args, kwargs):
                    shard_specs = {}
                    # Shard args on batch dimension
                    shard_specs[args[0]] = ("batch", None, None)
                    shard_specs[args[1][0]] = ("batch", None, None)
                    shard_specs[args[1][1]] = ("batch", None, None)
                    shard_specs[args[2]] = ("batch", None, None, None)
                    # Shard weights on model dimension
                    shard_specs[attention.q_proj.weight] = ("model", None)
                    shard_specs[attention.k_proj.weight] = ("model", None)
                    shard_specs[attention.v_proj.weight] = ("model", None)
                    shard_specs[attention.o_proj.weight] = (None, "model")
                    return shard_specs
    
            else:
                pytest.skip("1x8 and 2x4 mesh not supported for this variant")
    
        else:
            batch_size = 1
            mesh = None
            get_shard_spec = None
    
        hidden_states = torch.randn(
            (batch_size, seq_len, config.hidden_size), dtype=torch.bfloat16
        )
        head_dim = config.hidden_size // config.num_attention_heads
        cos_sin = torch.rand(batch_size, seq_len, head_dim, dtype=torch.bfloat16)
        position_embeddings = (cos_sin, cos_sin)
        attention_mask = torch.rand(batch_size, 1, seq_len, seq_len, dtype=torch.bfloat16)
    
        past_key_states = None
    
        comparison_config = ComparisonConfig(pcc=PccConfig(required_pcc=0.98))
    
>       run_graph_test(
            attention,
            [hidden_states, position_embeddings, attention_mask, past_key_states],
            comparison_config=comparison_config,
            framework=Framework.TORCH,
            mesh=mesh,
            shard_spec_fn=get_shard_spec,
        )

tests/torch/graphs/test_attention.py:1248: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/infra/testers/single_chip/graph/graph_tester.py:63: in run_graph_test
    tester.test(workload)
tests/infra/testers/single_chip/op/op_tester.py:51: in test
    tt_res = self._device_runner.run_on_tt_device(tt_workload)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tests/infra/runners/device_runner.py:30: in run_on_tt_device
    return self.run_on_device(workload, DeviceType.TT, device_num)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tests/infra/runners/device_runner.py:40: in run_on_device
    return self._run_on_device(device_workload, device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tests/infra/runners/torch_device_runner.py:82: in _run_on_device
    return workload.execute()
           ^^^^^^^^^^^^^^^^^^
tests/infra/workloads/workload.py:71: in execute
    return self.compiled_executable(*self.args, **self.kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:655: in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/modeling_qwen2.py:147: in forward
    def forward(
/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:838: in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tt_torch.backend.backend.XLAExecutor object at 0x7fc8e638fe90>
args = (tensor([[[-6.9531e-01, -1.0391e+00, -6.6016e-01,  ..., -1.1094e+00,
           4.7070e-01, -1.7285e-01],
         [ 1...42],
          [0.0117, 0.1289, 0.9922,  ..., 0.7656, 0.4180, 0.6719]]]],
       device='xla:0', dtype=torch.bfloat16))
output = (<[RuntimeError('Check failed: data()->tensor_data: ') raised in repr()] Tensor object at 0x7fc7d05a0650>, <[RuntimeError('Check failed: data()->tensor_data: ') raised in repr()] Tensor object at 0x7fc7f06bbe30>)
gm_has_functional_output_kind = True
el = OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='clone_2'), target=None)

    def __call__(self, *args):
        if self.experimental_compile_enabled:
            return self._call_experimental_compile(*args)
    
        if self.inject_metadata:
            # MetadataDispatchMode intercepts tensor operations via TorchDispatchMode and
            # attaches FX metadata (module hierarchy, file, line) to XLA tensors.
            with MetadataDispatchMode(self.node_info):
                output = self.module(*args)
        else:
            output = self.module(*args)
        gm_has_functional_output_kind: bool = True
    
        for el in self.signature.output_specs:
            if el.kind is not OutputKind.USER_OUTPUT:
                gm_has_functional_output_kind = False
                break
    
        if gm_has_functional_output_kind:
            # This tells torch-xla to cut the graph at only what is required to
            # compute all tensors in the `output` list.
>           torch_xla._XLAC._xla_sync_multi(list(output), self.devices, wait=False)
E           RuntimeError: RET_CHECK failure (external/xla/xla/hlo/ir/hlo_sharding.cc:943) product_of_dimensions == product_of_iota_dimensions

python_package/tt_torch/backend/backend.py:174: RuntimeError
=========================== short test summary info ============================
FAILED tests/torch/graphs/test_attention.py::test_qwen2_5_attention_prefill_push[7b_instruct-1024-llmbox] - RuntimeError: RET_CHECK failure (external/xla/xla/hlo/ir/hlo_sharding.cc:943) product_of_dimensions == product_of_iota_dimensions
============================== 1 failed in 32.22s ==============================
2026-01-05 17:23:30.776 (  32.837s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.776 (  32.837s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.776 (  32.837s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.776 (  32.837s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.776 (  32.837s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.776 (  32.837s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.776 (  32.837s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.776 (  32.837s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.837s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.837s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.777 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.778 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:30.778 (  32.838s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.265 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.265 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.265 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.265 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.265 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.265 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.265 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.265 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.265 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.265 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.265 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.265 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.265 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.326s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.266 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.327s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.267 (  33.328s) [        7BAA3480]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-05 17:23:31.390 (  33.451s) [        7BAA3480]     client_instance.cc:192      1| ClientInstance::~ClientInstance
2026-01-05 17:23:31.390 (  33.451s) [        7BAA3480]     client_instance.cc:506      1| Closing parent mesh.
