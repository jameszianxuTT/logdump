2026-02-11 16:18:45.696 | INFO     | pjrt_plugin_tt:setup_tt_pjrt_plugin_dir:42 - Using PJRT plugin directory: /localdev/jameszianxu/tt-xla/python_package/pjrt_plugin_tt
2026-02-11 16:18:45.697 | INFO     | pjrt_plugin_tt:setup_tt_metal_home:103 - Using TT-Metal from the source tree: /localdev/jameszianxu/tt-xla/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
2026-02-11 16:18:45.697 | WARNING  | torch_plugin_tt:__init__:38 - TT plugin is setting XLA_STABLEHLO_COMPILE to 1. This is required for TT PJRT plugin to work correctly.
============================= test session starts ==============================
platform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0 -- /localdev/jameszianxu/tt-xla/venv/bin/python
cachedir: .pytest_cache
metadata: {'Python': '3.11.14', 'Platform': 'Linux-5.4.0-216-generic-x86_64-with-glibc2.35', 'Packages': {'pytest': '9.0.2', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.12.1', 'json-report': '1.5.0', 'metadata': '3.1.1', 'split': '0.11.0', 'forked': '1.6.0', 'jaxtyping': '0.3.7'}}
rootdir: /localdev/jameszianxu/tt-xla
configfile: pytest.ini
plugins: anyio-4.12.1, json-report-1.5.0, metadata-3.1.1, split-0.11.0, forked-1.6.0, jaxtyping-0.3.7
collecting ... collected 1 item

tests/torch/graphs/test_tensor_persistence.py::test_simple_distributed_addition 2026-02-11 16:18:49.363 (   0.000s) [        EA108000]   plugin_attributes.cc:60       1| PluginAttributes::PJRT_Plugin_Initialize
2026-02-11 16:18:49.364 (   0.000s) [        EA108000]     client_instance.cc:513      1| ClientInstance::PJRT_Client_Create
2026-02-11 16:18:49.366 (   0.002s) [        EA108000]     client_instance.cc:177      1| ClientInstance::ClientInstance
2026-02-11 16:18:49.366 (   0.002s) [        EA108000]     client_instance.cc:198      1| ClientInstance::Initialize
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]              stubs.inc:103   WARN| STUB: PJRT_Client_TopologyDescription
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]     client_instance.cc:567      1| ClientInstance::PJRT_Client_PlatformVersion
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]     client_instance.cc:548      1| ClientInstance::PJRT_Client_PlatformName
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]     client_instance.cc:578      1| ClientInstance::PJRT_Client_Devices
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]  device_description.cc:82       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]  device_description.cc:82       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]     client_instance.cc:591      1| ClientInstance::PJRT_Client_AddressableDevices
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]     client_instance.cc:641      1| ClientInstance::PJRT_Client_AddressableMemories
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]   plugin_attributes.cc:66       1| PluginAttributes::PJRT_Plugin_Attributes
2026-02-11 16:18:49.899744: W torch_xla/csrc/runtime/profiler.cpp:88] Profiler API not found for PJRT plugin
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]  device_description.cc:120      1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-02-11 16:18:49.899 (   0.535s) [        EA108000]  device_description.cc:120      1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-02-11 16:18:49.899 (   0.536s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.899 (   0.536s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.899 (   0.536s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.899 (   0.536s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.914 (   0.550s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.914 (   0.550s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.914 (   0.551s) [        EA108000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-02-11 16:18:49.914 (   0.551s) [        EA108000]     client_instance.cc:703      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-02-11 16:18:49.914 (   0.551s) [        EA108000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-02-11 16:18:49.915 (   0.552s) [        EA108000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]     client_instance.cc:703      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]     client_instance.cc:703      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]     client_instance.cc:703      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:18:49.916 (   0.552s) [        EA108000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212 (   0.848s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.212894: W torch_xla/csrc/runtime/pjrt_computation_client.cpp:703] Failed to deserialize executable: UNIMPLEMENTED: Deserializing serialized executable not supported.
2026-02-11 16:18:50.213 (   0.849s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.213 (   0.849s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.222 (   0.858s) [        EA108000]     client_instance.cc:654      1| ClientInstance::PJRT_Client_Compile
2026-02-11 16:18:50.222 (   0.858s) [        EA108000]      module_builder.cc:223      1| ModuleBuilder::buildModule
2026-02-11 16:18:50.224 (   0.860s) [        EA108000]      module_builder.cc:1121     1| MLIR Module vhlo:
#loc1 = loc("p0.2")
#loc2 = loc("p1.6")
module @SyncTensorsGraph.14 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<32x32x!vhlo.f32_v1> loc("p0.2"), %arg1: !vhlo.tensor_v1<32x32x!vhlo.f32_v1> loc("p1.6")) -> (!vhlo.tensor_v1<32x32x!vhlo.f32_v1>) {
    %0 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<32x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x32x!vhlo.f32_v1> loc(#loc3)
    %1 = "vhlo.custom_call_v1"(%0) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x32x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x32x!vhlo.f32_v1> loc(#loc4)
    %2 = "vhlo.reshape_v1"(%1) : (!vhlo.tensor_v1<1x32x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<32x32x!vhlo.f32_v1> loc(#loc5)
    %3 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<32x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x32x!vhlo.f32_v1> loc(#loc6)
    %4 = "vhlo.custom_call_v1"(%3) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x32x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x32x!vhlo.f32_v1> loc(#loc7)
    %5 = "vhlo.reshape_v1"(%4) : (!vhlo.tensor_v1<1x32x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<32x32x!vhlo.f32_v1> loc(#loc8)
    %6 = "vhlo.add_v1"(%2, %5) : (!vhlo.tensor_v1<32x32x!vhlo.f32_v1>, !vhlo.tensor_v1<32x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<32x32x!vhlo.f32_v1> loc(#loc9)
    "vhlo.return_v1"(%6) : (!vhlo.tensor_v1<32x32x!vhlo.f32_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc3 = loc("reshape.7")
#loc4 = loc("custom-call.8")
#loc5 = loc("reshape.9")
#loc6 = loc("reshape.3")
#loc7 = loc("custom-call.4")
#loc8 = loc("reshape.5")
#loc9 = loc("add.12")
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.230 (   0.866s) [        EA108000]      module_builder.cc:1121     1| MLIR Module shlo:
#loc1 = loc("p0.2")
#loc2 = loc("p1.6")
module @SyncTensorsGraph.14 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p0.2"), %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p1.6")) -> tensor<32x32xf32> {
    %0 = stablehlo.reshape %arg1 : (tensor<32x32xf32>) -> tensor<1x32x32xf32> loc(#loc3)
    %1 = stablehlo.custom_call @tt.mark_argument(%0) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x32x32xf32>) -> tensor<1x32x32xf32> loc(#loc4)
    %2 = stablehlo.reshape %1 : (tensor<1x32x32xf32>) -> tensor<32x32xf32> loc(#loc5)
    %3 = stablehlo.reshape %arg0 : (tensor<32x32xf32>) -> tensor<1x32x32xf32> loc(#loc6)
    %4 = stablehlo.custom_call @tt.mark_argument(%3) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<1x32x32xf32>) -> tensor<1x32x32xf32> loc(#loc7)
    %5 = stablehlo.reshape %4 : (tensor<1x32x32xf32>) -> tensor<32x32xf32> loc(#loc8)
    %6 = stablehlo.add %2, %5 : tensor<32x32xf32> loc(#loc9)
    return %6 : tensor<32x32xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc3 = loc("reshape.7")
#loc4 = loc("custom-call.8")
#loc5 = loc("reshape.9")
#loc6 = loc("reshape.3")
#loc7 = loc("custom-call.4")
#loc8 = loc("reshape.5")
#loc9 = loc("add.12")
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.231 (   0.868s) [        EA108000]      module_builder.cc:1121     1| MLIR Module shlo_frontend:
#loc1 = loc("p0.2")
#loc2 = loc("p1.6")
module @SyncTensorsGraph.14 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"} loc("p0.2"), %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("p1.6")) -> tensor<32x32xf32> {
    %0 = stablehlo.reshape %arg1 : (tensor<32x32xf32>) -> tensor<1x32x32xf32> loc(#loc3)
    %1 = stablehlo.reshape %0 : (tensor<1x32x32xf32>) -> tensor<32x32xf32> loc(#loc4)
    %2 = stablehlo.reshape %arg0 : (tensor<32x32xf32>) -> tensor<1x32x32xf32> loc(#loc5)
    %3 = stablehlo.reshape %2 : (tensor<1x32x32xf32>) -> tensor<32x32xf32> loc(#loc6)
    %4 = stablehlo.add %1, %3 : tensor<32x32xf32> loc(#loc7)
    return %4 : tensor<32x32xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc3 = loc("reshape.7")
#loc4 = loc("reshape.9")
#loc5 = loc("reshape.3")
#loc6 = loc("reshape.5")
#loc7 = loc("add.12")
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.238 (   0.875s) [        EA108000]      module_builder.cc:1121     1| MLIR Module shlo_compiler:
#loc1 = loc("p0.2")
#loc2 = loc("p1.6")
module @SyncTensorsGraph.14 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]> loc(#loc)
  func.func @main(%arg0: tensor<32x32xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<32x16xf32>>, ttir.name = "args_1"} loc("p0.2"), %arg1: tensor<32x32xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<32x16xf32>>, ttir.name = "args_0"} loc("p1.6")) -> (tensor<32x32xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<32x32xf32>>}) {
    %0 = sdy.manual_computation(%arg0, %arg1) in_shardings=[<@mesh, [{}, {"_axis_0"}]>, <@mesh, [{}, {"_axis_0"}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg2: tensor<32x16xf32> loc("p0.2"), %arg3: tensor<32x16xf32> loc("p1.6")) {
      %1 = stablehlo.reshape %arg3 : (tensor<32x16xf32>) -> tensor<1x32x16xf32> loc(#loc3)
      %2 = stablehlo.reshape %1 : (tensor<1x32x16xf32>) -> tensor<32x16xf32> loc(#loc4)
      %3 = stablehlo.reshape %arg2 : (tensor<32x16xf32>) -> tensor<1x32x16xf32> loc(#loc5)
      %4 = stablehlo.reshape %3 : (tensor<1x32x16xf32>) -> tensor<32x16xf32> loc(#loc6)
      %5 = stablehlo.add %2, %4 : tensor<32x16xf32> loc(#loc7)
      sdy.return %5 : tensor<32x16xf32> loc(#loc)
    } : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32> loc(#loc)
    return %0 : tensor<32x32xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc3 = loc("reshape.7")
#loc4 = loc("reshape.9")
#loc5 = loc("reshape.3")
#loc6 = loc("reshape.5")
#loc7 = loc("add.12")
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.239 (   0.876s) [        EA108000]      module_builder.cc:303      1| SHLO compiler pipeline run completed - is using shardy output shardings: 1
2026-02-11 16:18:50.241 (   0.877s) [        EA108000]      module_builder.cc:1121     1| MLIR Module shlo_compiler_cleaned:
#loc = loc(unknown)
module @SyncTensorsGraph.14 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{devices=[1,2]<=[2]}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x32xf32> loc(unknown), %arg1: tensor<32x32xf32> loc(unknown)) -> tensor<32x32xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc)
    return %cst : tensor<32x32xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.243 (   0.880s) [        EA108000]      module_builder.cc:1121     1| MLIR Module ttir:
#loc1 = loc("p0.2")
#loc2 = loc("p1.6")
module @SyncTensorsGraph.14 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.14 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
      func.func @main(%arg0: tensor<32x32xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<32x16xf32>>, ttir.name = "args_1"} loc("p0.2"), %arg1: tensor<32x32xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<32x16xf32>>, ttir.name = "args_0"} loc("p1.6")) -> (tensor<32x32xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<32x32xf32>>}) {
        %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<32x32xf32>) -> tensor<32x16xf32> loc(#loc)
        %1 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<32x32xf32>) -> tensor<32x16xf32> loc(#loc)
        %2 = "ttir.reshape"(%1) <{shape = [1 : i32, 32 : i32, 16 : i32]}> : (tensor<32x16xf32>) -> tensor<1x32x16xf32> loc(#loc3)
        %3 = "ttir.reshape"(%2) <{shape = [32 : i32, 16 : i32]}> : (tensor<1x32x16xf32>) -> tensor<32x16xf32> loc(#loc4)
        %4 = "ttir.reshape"(%0) <{shape = [1 : i32, 32 : i32, 16 : i32]}> : (tensor<32x16xf32>) -> tensor<1x32x16xf32> loc(#loc5)
        %5 = "ttir.reshape"(%4) <{shape = [32 : i32, 16 : i32]}> : (tensor<1x32x16xf32>) -> tensor<32x16xf32> loc(#loc6)
        %6 = "ttir.add"(%3, %5) : (tensor<32x16xf32>, tensor<32x16xf32>) -> tensor<32x16xf32> loc(#loc7)
        %7 = "ttir.mesh_shard"(%6) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<32x16xf32>) -> tensor<32x32xf32> loc(#loc)
        return %7 : tensor<32x32xf32> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc3 = loc("reshape.7")
#loc4 = loc("reshape.9")
#loc5 = loc("reshape.3")
#loc6 = loc("reshape.5")
#loc7 = loc("add.12")
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.244 (   0.880s) [        EA108000]      module_builder.cc:862   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2026-02-11 16:18:50.244 (   0.881s) [        EA108000]      module_builder.cc:876   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2026-02-11 16:18:50.244 (   0.881s) [        EA108000]      module_builder.cc:886   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2026-02-11 16:18:50.272 (   0.908s) [        EA108000]      module_builder.cc:1121     1| MLIR Module ttnn:
#dram = #ttnn.buffer_type<dram>
#loc1 = loc("p0.2")
#loc2 = loc("p1.6")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 103712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073162752, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 64, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 103712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073171392, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 64, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.14 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.14 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]> loc(#loc)
      func.func @main(%arg0: tensor<32x32xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<32x16xf32>>, ttir.name = "args_1"} loc("p0.2"), %arg1: tensor<32x32xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<32x16xf32>>, ttir.name = "args_0"} loc("p1.6")) -> (tensor<32x32xf32, #ttnn_layout> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<32x32xf32>>}) attributes {tt.function_type = "forward_device"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<32x32xf32, #ttnn_layout>, !ttnn.device) -> tensor<32x16xf32, #ttnn_layout> loc(#loc)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<32x32xf32, #ttnn_layout>) -> () loc(#loc)
        %2 = "ttnn.mesh_shard"(%arg1, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<32x32xf32, #ttnn_layout>, !ttnn.device) -> tensor<32x16xf32, #ttnn_layout> loc(#loc)
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<32x32xf32, #ttnn_layout>) -> () loc(#loc)
        %3 = "ttnn.add"(%2, %1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<32x16xf32, #ttnn_layout>, tensor<32x16xf32, #ttnn_layout>) -> tensor<32x16xf32, #ttnn_layout> loc(#loc3)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<32x16xf32, #ttnn_layout>) -> () loc(#loc3)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<32x16xf32, #ttnn_layout>) -> () loc(#loc3)
        %4 = "ttnn.mesh_shard"(%3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<32x16xf32, #ttnn_layout>, !ttnn.device) -> tensor<32x32xf32, #ttnn_layout> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<32x16xf32, #ttnn_layout>) -> () loc(#loc)
        return %4 : tensor<32x32xf32, #ttnn_layout> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc3 = loc("add.12")
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.281 (   0.917s) [        EA108000]loaded_executable_insta:256      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2026-02-11 16:18:50.281 (   0.917s) [        EA108000]loaded_executable_insta:275      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2026-02-11 16:18:50.282 (   0.918s) [        EA108000]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2026-02-11 16:18:50.282 (   0.918s) [        EA108000]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-02-11 16:18:50.282 (   0.918s) [        EA108000]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-02-11 16:18:50.282 (   0.918s) [        EA108000]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-02-11 16:18:50.282 (   0.918s) [        EA108000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-02-11 16:18:50.282 (   0.918s) [        EA108000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-02-11 16:18:50.286 (   0.922s) [        EA108000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-02-11 16:18:50.286 (   0.922s) [        EA108000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-02-11 16:18:50.289 (   0.925s) [        EA108000] executable_instance.cc:239      1| ExecutableInstance::PJRT_Executable_Serialize
2026-02-11 16:18:50.291 (   0.927s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.291 (   0.927s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.291 (   0.927s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.291 (   0.927s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]     buffer_instance.cc:547      1| BufferInstance::PJRT_Buffer_Device
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]     buffer_instance.cc:547      1| BufferInstance::PJRT_Buffer_Device
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]     buffer_instance.cc:547      1| BufferInstance::PJRT_Buffer_Device
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]     buffer_instance.cc:547      1| BufferInstance::PJRT_Buffer_Device
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640] executable_instance.cc:145      1| ExecutableInstance::PJRT_Executable_NumOutputs
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]loaded_executable_insta:311      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]flatbuffer_loaded_execu:203      1| FlatbufferLoadedExecutableInstance::Execute
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]     client_instance.cc:383      1| ClientInstance::getOrCreateMeshDevice - reusing already opened mesh device [1, 2]
2026-02-11 16:18:50.297 (   0.933s) [        DE7FC640]              tensor.cc:180      1| rt_tensor_from_strategy: first_shard_UID=2 num_shards=2 strategy=shard_2d shape=[32, 16]
2026-02-11 16:18:50.309 (   0.945s) [        DE7FC640]              tensor.cc:180      1| rt_tensor_from_strategy: first_shard_UID=0 num_shards=2 strategy=shard_2d shape=[32, 16]
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]flatbuffer_loaded_execu:108      1| fillPJRTOutputLists: output_index=0 is_sharded=1 num_host_tensors=2 shape=[32,32]
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]flatbuffer_loaded_execu:134      1| Filled output at output_index 0 device_index 0 with shape [32, 16] and UID 4
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]flatbuffer_loaded_execu:134      1| Filled output at output_index 0 device_index 1 with shape [32, 16] and UID 5
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]     buffer_instance.cc:445      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_ElementType
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]     buffer_instance.cc:445      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:18:50.322 (   0.958s) [        DE7FC640]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_ElementType
2026-02-11 16:18:50.322 (   0.958s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.322 (   0.958s) [        EA108000]     buffer_instance.cc:493      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-02-11 16:18:50.322 (   0.958s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:50.327 (   0.964s) [        EA108000]     client_instance.cc:654      1| ClientInstance::PJRT_Client_Compile
2026-02-11 16:18:50.328 (   0.964s) [        EA108000]      module_builder.cc:223      1| ModuleBuilder::buildModule
2026-02-11 16:18:50.328 (   0.964s) [        EA108000]      module_builder.cc:1121     1| MLIR Module vhlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<32x32x!vhlo.f32_v1> loc("p0.1")) -> (!vhlo.tensor_v1<32x32x!vhlo.f32_v1>) {
    %0 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"xla.sdy.FuncResultSharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<true>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>">}>} : (!vhlo.tensor_v1<32x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<32x32x!vhlo.f32_v1> loc(#loc1)
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<32x32x!vhlo.f32_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>]>, res_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.329 (   0.965s) [        EA108000]      module_builder.cc:1121     1| MLIR Module shlo:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p0.1")) -> (tensor<32x32xf32> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<32x32xf32>) -> tensor<32x32xf32> loc(#loc1)
    return %0 : tensor<32x32xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.329 (   0.965s) [        EA108000]      module_builder.cc:1121     1| MLIR Module shlo_frontend:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>} loc("p0.1")) -> (tensor<32x32xf32> {mhlo.sharding = "{replicated}"}) {
    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {}]>]>"}} : (tensor<32x32xf32>) -> tensor<32x32xf32> loc(#loc1)
    return %0 : tensor<32x32xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.332 (   0.969s) [        EA108000]      module_builder.cc:1121     1| MLIR Module shlo_compiler:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]> loc(#loc)
  func.func @main(%arg0: tensor<32x32xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<32x16xf32>>} loc("p0.1")) -> (tensor<32x32xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<32x32xf32>>}) {
    %0 = sdy.manual_computation(%arg0) in_shardings=[<@mesh, [{}, {"_axis_0"}]>] out_shardings=[<@mesh, [{}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg1: tensor<32x16xf32> loc("p0.1")) {
      %1 = "stablehlo.all_gather"(%arg1) <{all_gather_dim = 1 : i64, channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> : (tensor<32x16xf32>) -> tensor<32x32xf32> loc(#loc1)
      sdy.return %1 : tensor<32x32xf32> loc(#loc)
    } : (tensor<32x32xf32>) -> tensor<32x32xf32> loc(#loc)
    return %0 : tensor<32x32xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.333 (   0.969s) [        EA108000]      module_builder.cc:303      1| SHLO compiler pipeline run completed - is using shardy output shardings: 1
2026-02-11 16:18:50.333 (   0.969s) [        EA108000]      module_builder.cc:1121     1| MLIR Module shlo_compiler_cleaned:
#loc = loc(unknown)
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_sharding = "{{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x32xf32> loc(unknown)) -> tensor<32x32xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc)
    return %cst : tensor<32x32xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.335 (   0.971s) [        EA108000]      module_builder.cc:1121     1| MLIR Module ttir:
#loc1 = loc("p0.1")
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
      func.func @main(%arg0: tensor<32x32xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<32x16xf32>>} loc("p0.1")) -> (tensor<32x32xf32> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<32x32xf32>>}) {
        %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<32x32xf32>) -> tensor<32x16xf32> loc(#loc)
        %1 = "ttir.all_gather"(%0) <{all_gather_dim = 1 : si32, cluster_axis = 1 : ui32}> : (tensor<32x16xf32>) -> tensor<32x32xf32> loc(#loc1)
        %2 = "ttir.mesh_shard"(%1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<32x32xf32>) -> tensor<32x32xf32> loc(#loc)
        return %2 : tensor<32x32xf32> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.335 (   0.971s) [        EA108000]      module_builder.cc:862   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2026-02-11 16:18:50.335 (   0.971s) [        EA108000]      module_builder.cc:876   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2026-02-11 16:18:50.335 (   0.971s) [        EA108000]      module_builder.cc:886   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2026-02-11 16:18:50.356 (   0.992s) [        EA108000]      module_builder.cc:1121     1| MLIR Module ttnn:
#dram = #ttnn.buffer_type<dram>
#loc1 = loc("p0.1")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 103712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073162752, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 64, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 103712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073171392, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 64, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @ReplicateShardedData.6 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]> loc(#loc)
      func.func @main(%arg0: tensor<32x32xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <presharded>, local_shape = tensor<32x16xf32>>} loc("p0.1")) -> (tensor<32x32xf32, #ttnn_layout> {ttcore.runtime_tensor_sharding = #ttcore<runtime_tensor_sharding shard_status = <unsharded>, local_shape = tensor<32x32xf32>>}) attributes {tt.function_type = "forward_device"} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<32x32xf32, #ttnn_layout>, !ttnn.device) -> tensor<32x16xf32, #ttnn_layout> loc(#loc)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<32x32xf32, #ttnn_layout>) -> () loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 32 : i32, 16 : i32]}> : (tensor<32x16xf32, #ttnn_layout>) -> tensor<1x1x32x16xf32, #ttnn_layout1> loc(#loc2)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<32x16xf32, #ttnn_layout>) -> () loc(#loc2)
        %3 = "ttnn.all_gather"(%2) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32}> : (tensor<1x1x32x16xf32, #ttnn_layout1>) -> tensor<1x1x32x32xf32, #ttnn_layout1> loc(#loc3)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x32x16xf32, #ttnn_layout1>) -> () loc(#loc3)
        %4 = "ttnn.reshape"(%3) <{shape = [32 : i32, 32 : i32]}> : (tensor<1x1x32x32xf32, #ttnn_layout1>) -> tensor<32x32xf32, #ttnn_layout> loc(#loc1)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x1x32x32xf32, #ttnn_layout1>) -> () loc(#loc1)
        return %4 : tensor<32x32xf32, #ttnn_layout> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc2 = loc("p0.1_reshape_to_4d"(#loc1))
#loc3 = loc("p0.1_all_gather_4d"(#loc1))
------------------ END OF MLIR MODULE ------------------
2026-02-11 16:18:50.362 (   0.998s) [        EA108000]loaded_executable_insta:256      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2026-02-11 16:18:50.362 (   0.998s) [        EA108000]loaded_executable_insta:275      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2026-02-11 16:18:50.362 (   0.998s) [        EA108000]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2026-02-11 16:18:50.362 (   0.998s) [        EA108000]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-02-11 16:18:50.362 (   0.998s) [        EA108000]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-02-11 16:18:50.362 (   0.998s) [        EA108000]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-02-11 16:18:50.362 (   0.998s) [        EA108000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-02-11 16:18:50.362 (   0.998s) [        EA108000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-02-11 16:18:50.365 (   1.001s) [        EA108000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-02-11 16:18:50.365 (   1.001s) [        EA108000] executable_instance.cc:108      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-02-11 16:18:50.366 (   1.003s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:50.366 (   1.003s) [        EA108000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-02-11 16:18:50.366 (   1.003s) [        EA108000]     buffer_instance.cc:547      1| BufferInstance::PJRT_Buffer_Device
2026-02-11 16:18:50.366 (   1.003s) [        EA108000]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-02-11 16:18:50.366 (   1.003s) [        EA108000]     buffer_instance.cc:547      1| BufferInstance::PJRT_Buffer_Device
2026-02-11 16:18:50.366 (   1.003s) [        EA108000]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-02-11 16:18:50.367 (   1.003s) [        EA108000] executable_instance.cc:145      1| ExecutableInstance::PJRT_Executable_NumOutputs
2026-02-11 16:18:50.367 (   1.003s) [        EA108000]loaded_executable_insta:311      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2026-02-11 16:18:50.367 (   1.003s) [        EA108000]flatbuffer_loaded_execu:203      1| FlatbufferLoadedExecutableInstance::Execute
2026-02-11 16:18:50.367 (   1.003s) [        EA108000]     client_instance.cc:383      1| ClientInstance::getOrCreateMeshDevice - reusing already opened mesh device [1, 2]
2026-02-11 16:18:50.397 (   1.033s) [        EA108000]flatbuffer_loaded_execu:108      1| fillPJRTOutputLists: output_index=0 is_sharded=1 num_host_tensors=2 shape=[32,32]
2026-02-11 16:18:50.397 (   1.033s) [        EA108000]flatbuffer_loaded_execu:134      1| Filled output at output_index 0 device_index 0 with shape [32, 32] and UID 6
2026-02-11 16:18:50.397 (   1.033s) [        EA108000]flatbuffer_loaded_execu:134      1| Filled output at output_index 0 device_index 1 with shape [32, 32] and UID 7
2026-02-11 16:18:50.397 (   1.034s) [        EA108000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:18:50.397 (   1.034s) [        EA108000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:18:50.397 (   1.034s) [        EA108000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:18:50.397 (   1.034s) [        EA108000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]     buffer_instance.cc:445      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_ElementType
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]     buffer_instance.cc:445      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_ElementType
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_Destroy
2026-02-11 16:18:50.398 (   1.034s) [        EA108000] executable_instance.cc:60       1| ExecutableInstance::PJRT_Executable_Destroy
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]loaded_executable_insta:246      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Destroy
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]loaded_executable_insta:46       1| Clearing program cache.
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]     buffer_instance.cc:433      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]     buffer_instance.cc:414      1| BufferInstance::PJRT_Buffer_ElementType
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]     buffer_instance.cc:422      1| BufferInstance::PJRT_Buffer_Dimensions
2026-02-11 16:18:50.398 (   1.034s) [        EA108000]     buffer_instance.cc:455      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2026-02-11 16:18:50.398 (   1.035s) [        EA108000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-02-11 16:18:50.398 (   1.035s) [        EA108000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_Destroy
2026-02-11 16:18:50.408 (   1.044s) [        B77FE640]              tensor.cc:120      1| Deleted tensor shard. Skipping PjrtTensor creation.
2026-02-11 16:18:50.408 (   1.045s) [        DCFF9640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-02-11 16:18:50.410 (   1.046s) [        EA108000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_Destroy
2026-02-11 16:18:50.410 (   1.046s) [        EA108000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_Destroy
PASSED

============================== 1 passed in 1.37s ===============================
2026-02-11 16:18:52.916 (   3.553s) [        EA108000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_Destroy
2026-02-11 16:18:52.917 (   3.553s) [        EA108000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_Destroy
2026-02-11 16:18:52.917 (   3.553s) [        EA108000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_Destroy
2026-02-11 16:18:52.917 (   3.553s) [        EA108000]     buffer_instance.cc:406      1| BufferInstance::PJRT_Buffer_Destroy
2026-02-11 16:18:53.056 (   3.692s) [        EA108000]     client_instance.cc:192      1| ClientInstance::~ClientInstance
2026-02-11 16:18:53.056 (   3.692s) [        EA108000]     client_instance.cc:466      1| Closing parent mesh.
