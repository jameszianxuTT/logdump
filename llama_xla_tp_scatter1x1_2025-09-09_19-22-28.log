WARNING:root:Defaulting to PJRT_DEVICE=CPU
2025-09-09 19:22:11.284 (   0.000s) [        56CD8000]      dylib_platform.cc:47       1| DylibPlatform::SubclassInitialize
2025-09-09 19:22:11.286 (   0.002s) [        56CD8000]     client_instance.cc:38       1| ClientInstance::ClientInstance
2025-09-09 19:22:11.286 (   0.002s) [        56CD8000]              client.cc:18       1| TTClientInstance::TTClientInstance
2025-09-09 19:22:11.286 (   0.002s) [        56CD8000]     client_instance.cc:59       1| ClientInstance::Initialize
2025-09-09 19:22:15.251 (   3.966s) [        56CD8000]              stubs.inc:112   WARN| STUB: PJRT_Client_TopologyDescription
2025-09-09 19:22:15.251 (   3.966s) [        56CD8000]      error_instance.cc:49       1| ErrorInstance::PJRT_Error_Message
2025-09-09 19:22:15.251 (   3.966s) [        56CD8000]      error_instance.cc:58       1| ErrorInstance::PJRT_Error_GetCode
2025-09-09 19:22:15.251 (   3.966s) [        56CD8000]      error_instance.cc:43       1| ErrorInstance::PJRT_Error_Destroy
2025-09-09 19:22:15.251 (   3.966s) [        56CD8000]     client_instance.cc:340      1| ClientInstance::PJRT_Client_PlatformVersion
2025-09-09 19:22:15.251 (   3.966s) [        56CD8000]     client_instance.cc:320      1| ClientInstance::PJRT_Client_PlatformName
2025-09-09 19:22:15.251 (   3.966s) [        56CD8000]     client_instance.cc:352      1| ClientInstance::PJRT_Client_Devices
2025-09-09 19:22:15.251 (   3.966s) [        56CD8000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]     client_instance.cc:365      1| ClientInstance::PJRT_Client_AddressableDevices
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]     client_instance.cc:415      1| ClientInstance::PJRT_Client_AddressableMemories
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]        api_bindings.cc:76       1| PJRT_Plugin_Attributes
2025-09-09 19:22:15.251350: W torch_xla/csrc/runtime/profiler.cpp:88] Profiler API not found for PJRT plugin
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:15.251 (   3.967s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
/localdev/jameszianxu/tt-xla/examples/pytorch/llama.py:68: DeprecationWarning: Use torch_xla.device instead
  device = xm.xla_device()
Using TT-Metal from the source tree: /localdev/jameszianxu/tt-xla/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
WARNING: TT plugin is setting XLA_STABLEHLO_COMPILE to 1. This is required for TT PJRT plugin to work correctly.
Setting up XLA environment...
XLA environment configured.
Created device mesh: (1, 2) with 2 devices
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 52.54it/s]
2025-09-09 19:22:16.846 (   5.562s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:16.846 (   5.562s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:16.846 (   5.562s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:16.846 (   5.562s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:16.846 (   5.562s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-09 19:22:16.847 (   5.563s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:16.847 (   5.563s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:16.847 (   5.563s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:16.847 (   5.563s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:16.847 (   5.563s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-09 19:22:16.847 (   5.563s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:16.847 (   5.563s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:16.848 (   5.563s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:16.848 (   5.563s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:16.848 (   5.564s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:16.848 (   5.564s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:16.848 (   5.564s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-09 19:22:16.848 (   5.564s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:16.848 (   5.564s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:16.848 (   5.564s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:16.848 (   5.564s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:16.848 (   5.564s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-09 19:22:16.848 (   5.564s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:16.848 (   5.564s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:16.848 (   5.564s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:16.848 (   5.564s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:16.854 (   5.570s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:16.854 (   5.570s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:16.854 (   5.570s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:16.854 (   5.570s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:16.854 (   5.570s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:16.854 (   5.570s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:16.854 (   5.570s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:16.854 (   5.570s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:16.855 (   5.570s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:16.855 (   5.570s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:16.855 (   5.571s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:16.855 (   5.571s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:16.855 (   5.571s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:16.855 (   5.571s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:16.855 (   5.571s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:16.855 (   5.571s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:16.855 (   5.571s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:16.855 (   5.571s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:16.855 (   5.571s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:16.855 (   5.571s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:16.855 (   5.571s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:16.855 (   5.571s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.424 (   6.140s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.424 (   6.140s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.430 (   6.146s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.430 (   6.146s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.430 (   6.146s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.431 (   6.146s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.431 (   6.146s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.431 (   6.146s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.431 (   6.147s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.431 (   6.147s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.431 (   6.147s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.431 (   6.147s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.434 (   6.150s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.434 (   6.150s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.440 (   6.156s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.440 (   6.156s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.440 (   6.156s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.440 (   6.156s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.440 (   6.156s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.440 (   6.156s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.440 (   6.156s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.440 (   6.156s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.440 (   6.156s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.440 (   6.156s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.443 (   6.159s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.443 (   6.159s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.452 (   6.168s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.452 (   6.168s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.452 (   6.168s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.452 (   6.168s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.452 (   6.168s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.452 (   6.168s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.452 (   6.168s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.452 (   6.168s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.453 (   6.168s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.453 (   6.168s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.456 (   6.171s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.456 (   6.171s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.457 (   6.173s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.457 (   6.173s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.457 (   6.173s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.457 (   6.173s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.457 (   6.173s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.457 (   6.173s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.457 (   6.173s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.457 (   6.173s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.458 (   6.173s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.458 (   6.173s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.458 (   6.174s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.458 (   6.174s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.458 (   6.174s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.458 (   6.174s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.458 (   6.174s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.459 (   6.174s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.459 (   6.174s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.459 (   6.174s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.459 (   6.174s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.459 (   6.174s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.459 (   6.175s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.459 (   6.175s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.459 (   6.175s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.459 (   6.175s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.459 (   6.175s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.459 (   6.175s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.459 (   6.175s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.460 (   6.175s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.460 (   6.176s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.460 (   6.176s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.460 (   6.176s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.460 (   6.176s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.460 (   6.176s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.460 (   6.176s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.460 (   6.176s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.460 (   6.176s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.461 (   6.177s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.461 (   6.177s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.461 (   6.177s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.462 (   6.177s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.462 (   6.177s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.462 (   6.177s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.462 (   6.177s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.462 (   6.177s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.462 (   6.178s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.462 (   6.178s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.462 (   6.178s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.462 (   6.178s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.467 (   6.183s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.468 (   6.183s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.468 (   6.183s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.468 (   6.184s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.468 (   6.184s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.468 (   6.184s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.468 (   6.184s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.468 (   6.184s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.468 (   6.184s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.468 (   6.184s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.471 (   6.187s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.471 (   6.187s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.477 (   6.193s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.477 (   6.193s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.477 (   6.193s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.477 (   6.193s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.477 (   6.193s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.477 (   6.193s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.477 (   6.193s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.477 (   6.193s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.477 (   6.193s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.478 (   6.193s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.480 (   6.196s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.480 (   6.196s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.489 (   6.205s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.489 (   6.205s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.489 (   6.205s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.490 (   6.206s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.490 (   6.206s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.490 (   6.206s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.490 (   6.206s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.490 (   6.206s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.490 (   6.206s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.490 (   6.206s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.493 (   6.209s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.493 (   6.209s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.494 (   6.210s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.494 (   6.210s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.494 (   6.210s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.495 (   6.210s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.495 (   6.210s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.495 (   6.210s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.495 (   6.210s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.495 (   6.210s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.495 (   6.211s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.495 (   6.211s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.495 (   6.211s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.495 (   6.211s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.495 (   6.211s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.495 (   6.211s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.495 (   6.211s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.496 (   6.211s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.496 (   6.211s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.496 (   6.211s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.496 (   6.212s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.496 (   6.212s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.496 (   6.212s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.496 (   6.212s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.496 (   6.212s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.496 (   6.212s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.496 (   6.212s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.496 (   6.212s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.496 (   6.212s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.497 (   6.212s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.497 (   6.212s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.497 (   6.212s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.497 (   6.212s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.497 (   6.212s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.497 (   6.213s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.497 (   6.213s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.497 (   6.213s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.497 (   6.213s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.498 (   6.214s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.498 (   6.214s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.498 (   6.214s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.498 (   6.214s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.499 (   6.214s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.499 (   6.214s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.499 (   6.214s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.499 (   6.214s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.499 (   6.215s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.499 (   6.215s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.499 (   6.215s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.499 (   6.215s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.504 (   6.220s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.504 (   6.220s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.505 (   6.220s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.505 (   6.220s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.505 (   6.221s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.505 (   6.221s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.505 (   6.221s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.505 (   6.221s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.505 (   6.221s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.505 (   6.221s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.508 (   6.224s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.508 (   6.224s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.514 (   6.230s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.514 (   6.230s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.514 (   6.230s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.514 (   6.230s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.514 (   6.230s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.514 (   6.230s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.514 (   6.230s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.514 (   6.230s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.515 (   6.230s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.515 (   6.230s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.517 (   6.233s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.517 (   6.233s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.526 (   6.242s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.526 (   6.242s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.526 (   6.242s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.526 (   6.242s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.526 (   6.242s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.526 (   6.242s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.526 (   6.242s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.526 (   6.242s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.526 (   6.242s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.526 (   6.242s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.529 (   6.245s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.529 (   6.245s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.531 (   6.247s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.531 (   6.247s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.531 (   6.247s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.531 (   6.247s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.531 (   6.247s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.531 (   6.247s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.531 (   6.247s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.531 (   6.247s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.531 (   6.247s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.531 (   6.247s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.531 (   6.247s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.531 (   6.247s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.532 (   6.248s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.532 (   6.248s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.532 (   6.248s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.532 (   6.248s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.532 (   6.248s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.532 (   6.248s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.532 (   6.248s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.532 (   6.248s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.532 (   6.248s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.532 (   6.248s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.532 (   6.248s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.533 (   6.248s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.533 (   6.249s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.533 (   6.249s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.533 (   6.249s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.533 (   6.249s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.533 (   6.249s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.533 (   6.249s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.533 (   6.249s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.533 (   6.249s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.533 (   6.249s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.533 (   6.249s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.533 (   6.249s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.533 (   6.249s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.535 (   6.251s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.535 (   6.251s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.535 (   6.251s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.535 (   6.251s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.535 (   6.251s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.535 (   6.251s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.535 (   6.251s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.535 (   6.251s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.535 (   6.251s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.536 (   6.251s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.536 (   6.251s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.536 (   6.251s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.541 (   6.257s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.541 (   6.257s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.541 (   6.257s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.541 (   6.257s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.542 (   6.257s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.542 (   6.257s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.542 (   6.257s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.542 (   6.257s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.542 (   6.258s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.542 (   6.258s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.545 (   6.261s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.545 (   6.261s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.550 (   6.266s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.550 (   6.266s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.550 (   6.266s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.551 (   6.266s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.551 (   6.267s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.551 (   6.267s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.551 (   6.267s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.551 (   6.267s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.551 (   6.267s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.551 (   6.267s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.554 (   6.270s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.554 (   6.270s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.566 (   6.282s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.566 (   6.282s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.566 (   6.282s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.566 (   6.282s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.566 (   6.282s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.566 (   6.282s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.566 (   6.282s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.566 (   6.282s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.567 (   6.282s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.567 (   6.282s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.569 (   6.285s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.569 (   6.285s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.571 (   6.287s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.571 (   6.287s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.571 (   6.287s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.571 (   6.287s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.571 (   6.287s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.571 (   6.287s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.571 (   6.287s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.571 (   6.287s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.571 (   6.287s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.571 (   6.287s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.572 (   6.287s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.572 (   6.287s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.572 (   6.288s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.572 (   6.288s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.572 (   6.288s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.572 (   6.288s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.572 (   6.288s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.572 (   6.288s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.572 (   6.288s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.572 (   6.288s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.572 (   6.288s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.572 (   6.288s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.572 (   6.288s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.573 (   6.288s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.573 (   6.289s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.573 (   6.289s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.573 (   6.289s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.573 (   6.289s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.573 (   6.289s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.573 (   6.289s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.573 (   6.289s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.573 (   6.289s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.573 (   6.289s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.573 (   6.289s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.573 (   6.289s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.574 (   6.289s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.575 (   6.291s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.575 (   6.291s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.575 (   6.291s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.575 (   6.291s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.575 (   6.291s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.575 (   6.291s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.575 (   6.291s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.575 (   6.291s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.575 (   6.291s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.575 (   6.291s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.575 (   6.291s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.575 (   6.291s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.581 (   6.297s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.581 (   6.297s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.581 (   6.297s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.581 (   6.297s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.581 (   6.297s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.581 (   6.297s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.581 (   6.297s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.581 (   6.297s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.581 (   6.297s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.582 (   6.297s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.585 (   6.300s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.585 (   6.300s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.591 (   6.307s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.591 (   6.307s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.591 (   6.307s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.591 (   6.307s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.591 (   6.307s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.591 (   6.307s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.591 (   6.307s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.591 (   6.307s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.591 (   6.307s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.591 (   6.307s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.594 (   6.310s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.594 (   6.310s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.603 (   6.318s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.603 (   6.319s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.603 (   6.319s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.603 (   6.319s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.603 (   6.319s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.603 (   6.319s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.603 (   6.319s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.603 (   6.319s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.603 (   6.319s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.603 (   6.319s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.606 (   6.322s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.606 (   6.322s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.608 (   6.324s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.608 (   6.324s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.608 (   6.324s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.608 (   6.324s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.608 (   6.324s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.608 (   6.324s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.608 (   6.324s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.608 (   6.324s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.608 (   6.324s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.608 (   6.324s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.608 (   6.324s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.608 (   6.324s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.609 (   6.325s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.609 (   6.325s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.609 (   6.325s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.609 (   6.325s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.609 (   6.325s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.609 (   6.325s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.609 (   6.325s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.609 (   6.325s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.609 (   6.325s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.609 (   6.325s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.609 (   6.325s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.609 (   6.325s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.610 (   6.326s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.610 (   6.326s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.610 (   6.326s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.610 (   6.326s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.610 (   6.326s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.610 (   6.326s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.610 (   6.326s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.610 (   6.326s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.610 (   6.326s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.610 (   6.326s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.610 (   6.326s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.610 (   6.326s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.612 (   6.328s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.612 (   6.328s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.612 (   6.328s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.612 (   6.328s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.612 (   6.328s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.612 (   6.328s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.612 (   6.328s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.612 (   6.328s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.612 (   6.328s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.612 (   6.328s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.612 (   6.328s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.612 (   6.328s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.618 (   6.334s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.618 (   6.334s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.618 (   6.334s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.618 (   6.334s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.618 (   6.334s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.618 (   6.334s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.618 (   6.334s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.618 (   6.334s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.619 (   6.334s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.619 (   6.334s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.622 (   6.337s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.622 (   6.337s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.627 (   6.343s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.627 (   6.343s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.627 (   6.343s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.628 (   6.343s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.628 (   6.343s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.628 (   6.344s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.628 (   6.344s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.628 (   6.344s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.628 (   6.344s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.628 (   6.344s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.631 (   6.347s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.631 (   6.347s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.640 (   6.355s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.640 (   6.355s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.640 (   6.355s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.640 (   6.356s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.640 (   6.356s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.640 (   6.356s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.640 (   6.356s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.640 (   6.356s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.640 (   6.356s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.640 (   6.356s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.643 (   6.359s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.643 (   6.359s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.645 (   6.361s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.645 (   6.361s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.645 (   6.361s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.645 (   6.361s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.645 (   6.361s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.645 (   6.361s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.645 (   6.361s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.645 (   6.361s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.645 (   6.361s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.645 (   6.361s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.645 (   6.361s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.645 (   6.361s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.646 (   6.362s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.646 (   6.362s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.646 (   6.362s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.646 (   6.362s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.646 (   6.362s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.646 (   6.362s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.646 (   6.362s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.646 (   6.362s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.646 (   6.362s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.646 (   6.362s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.646 (   6.362s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.646 (   6.362s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.647 (   6.363s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.647 (   6.363s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.647 (   6.363s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.647 (   6.363s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.647 (   6.363s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.647 (   6.363s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.647 (   6.363s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.647 (   6.363s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.647 (   6.363s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.647 (   6.363s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.647 (   6.363s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.647 (   6.363s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.649 (   6.365s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.649 (   6.365s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.649 (   6.365s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.649 (   6.365s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.649 (   6.365s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.649 (   6.365s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.649 (   6.365s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.649 (   6.365s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.649 (   6.365s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.649 (   6.365s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.649 (   6.365s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.649 (   6.365s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.655 (   6.371s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.655 (   6.371s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.655 (   6.371s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.655 (   6.371s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.655 (   6.371s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.655 (   6.371s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.655 (   6.371s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.655 (   6.371s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.655 (   6.371s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.655 (   6.371s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.658 (   6.374s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.658 (   6.374s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.664 (   6.380s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.664 (   6.380s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.664 (   6.380s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.664 (   6.380s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.664 (   6.380s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.664 (   6.380s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.664 (   6.380s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.664 (   6.380s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.665 (   6.380s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.665 (   6.380s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.668 (   6.383s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.668 (   6.383s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.676 (   6.392s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.676 (   6.392s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.676 (   6.392s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.676 (   6.392s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.676 (   6.392s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.676 (   6.392s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.676 (   6.392s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.676 (   6.392s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.677 (   6.392s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.677 (   6.392s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.680 (   6.395s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.680 (   6.395s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.681 (   6.397s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.681 (   6.397s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.681 (   6.397s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.681 (   6.397s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.681 (   6.397s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.681 (   6.397s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.682 (   6.397s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.682 (   6.397s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.682 (   6.397s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.682 (   6.397s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.682 (   6.398s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.682 (   6.398s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.682 (   6.398s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.682 (   6.398s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.682 (   6.398s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.682 (   6.398s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.682 (   6.398s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.682 (   6.398s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.682 (   6.398s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.683 (   6.398s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.683 (   6.398s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.683 (   6.398s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.683 (   6.399s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.683 (   6.399s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.683 (   6.399s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.683 (   6.399s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.683 (   6.399s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.683 (   6.399s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.683 (   6.399s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.683 (   6.399s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.683 (   6.399s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.683 (   6.399s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.683 (   6.399s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.684 (   6.399s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.684 (   6.399s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.684 (   6.400s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.685 (   6.401s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.685 (   6.401s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.685 (   6.401s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.686 (   6.401s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.686 (   6.401s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.686 (   6.401s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.686 (   6.401s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.686 (   6.401s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.686 (   6.402s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.686 (   6.402s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.686 (   6.402s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.686 (   6.402s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.692 (   6.408s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.692 (   6.408s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.692 (   6.408s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.692 (   6.408s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.692 (   6.408s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.692 (   6.408s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.692 (   6.408s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.692 (   6.408s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.692 (   6.408s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.692 (   6.408s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.695 (   6.411s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.695 (   6.411s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.701 (   6.417s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.701 (   6.417s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.701 (   6.417s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.702 (   6.417s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.702 (   6.417s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.702 (   6.417s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.702 (   6.417s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.702 (   6.418s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.702 (   6.418s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.702 (   6.418s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.705 (   6.421s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.705 (   6.421s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.713 (   6.429s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.713 (   6.429s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.713 (   6.429s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.713 (   6.429s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.713 (   6.429s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.714 (   6.429s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.714 (   6.429s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.714 (   6.429s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.714 (   6.430s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.714 (   6.430s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.717 (   6.433s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.717 (   6.433s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.718 (   6.434s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.718 (   6.434s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.718 (   6.434s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.719 (   6.434s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.719 (   6.434s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.719 (   6.435s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.719 (   6.435s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.719 (   6.435s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.719 (   6.435s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.719 (   6.435s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.719 (   6.435s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.719 (   6.435s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.719 (   6.435s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.719 (   6.435s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.720 (   6.435s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.720 (   6.435s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.720 (   6.435s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.720 (   6.436s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.720 (   6.436s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.720 (   6.436s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.720 (   6.436s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.720 (   6.436s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.720 (   6.436s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.720 (   6.436s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.721 (   6.437s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.721 (   6.437s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.721 (   6.437s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.721 (   6.437s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.721 (   6.437s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.721 (   6.437s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.721 (   6.437s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.721 (   6.437s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.721 (   6.437s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.721 (   6.437s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.721 (   6.437s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.721 (   6.437s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.723 (   6.439s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.723 (   6.439s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.723 (   6.439s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.723 (   6.439s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.723 (   6.439s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.723 (   6.439s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.723 (   6.439s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.723 (   6.439s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.723 (   6.439s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.724 (   6.439s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.724 (   6.439s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.724 (   6.440s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.729 (   6.445s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.729 (   6.445s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.729 (   6.445s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.729 (   6.445s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.730 (   6.445s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.730 (   6.445s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.730 (   6.445s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.730 (   6.445s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.730 (   6.446s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.730 (   6.446s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.733 (   6.449s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.733 (   6.449s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.741 (   6.457s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.741 (   6.457s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.741 (   6.457s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.741 (   6.457s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.741 (   6.457s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.741 (   6.457s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.741 (   6.457s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.741 (   6.457s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.741 (   6.457s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.742 (   6.457s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.744 (   6.460s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.745 (   6.460s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.753 (   6.469s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.753 (   6.469s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.753 (   6.469s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.753 (   6.469s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.753 (   6.469s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.753 (   6.469s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.754 (   6.469s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.754 (   6.469s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.754 (   6.470s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.754 (   6.470s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.757 (   6.473s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.757 (   6.473s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.758 (   6.474s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.758 (   6.474s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.758 (   6.474s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.759 (   6.474s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.759 (   6.475s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.759 (   6.475s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.759 (   6.475s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.759 (   6.475s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.759 (   6.475s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.759 (   6.475s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.759 (   6.475s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.759 (   6.475s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.760 (   6.476s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.760 (   6.476s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.760 (   6.476s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.760 (   6.476s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.760 (   6.476s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.760 (   6.476s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.760 (   6.476s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.760 (   6.476s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.760 (   6.476s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.760 (   6.476s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.760 (   6.476s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.760 (   6.476s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.761 (   6.477s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.761 (   6.477s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.761 (   6.477s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.761 (   6.477s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.761 (   6.477s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.761 (   6.477s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.761 (   6.477s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.761 (   6.477s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.762 (   6.477s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.762 (   6.477s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.762 (   6.478s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.762 (   6.478s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.763 (   6.479s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.763 (   6.479s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.764 (   6.479s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.764 (   6.479s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.764 (   6.480s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.764 (   6.480s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.764 (   6.480s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.764 (   6.480s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.764 (   6.480s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.764 (   6.480s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.764 (   6.480s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.764 (   6.480s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.770 (   6.486s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.770 (   6.486s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.770 (   6.486s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.770 (   6.486s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.770 (   6.486s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.770 (   6.486s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.770 (   6.486s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.770 (   6.486s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.770 (   6.486s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.771 (   6.486s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.773 (   6.489s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.773 (   6.489s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.779 (   6.495s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.779 (   6.495s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.779 (   6.495s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.779 (   6.495s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.779 (   6.495s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.779 (   6.495s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.780 (   6.495s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.780 (   6.495s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.780 (   6.496s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.780 (   6.496s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.783 (   6.499s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.783 (   6.499s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.792 (   6.508s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.792 (   6.508s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.792 (   6.508s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.792 (   6.508s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.793 (   6.508s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.793 (   6.508s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.793 (   6.508s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.793 (   6.509s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.793 (   6.509s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.793 (   6.509s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.796 (   6.512s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.796 (   6.512s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.798 (   6.513s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.798 (   6.513s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.798 (   6.513s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.798 (   6.514s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.798 (   6.514s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.798 (   6.514s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.798 (   6.514s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.798 (   6.514s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.798 (   6.514s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.798 (   6.514s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.799 (   6.514s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.799 (   6.514s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.799 (   6.515s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.799 (   6.515s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.799 (   6.515s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.799 (   6.515s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.799 (   6.515s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.799 (   6.515s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.799 (   6.515s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.799 (   6.515s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.800 (   6.515s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.800 (   6.515s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.800 (   6.516s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.800 (   6.516s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.800 (   6.516s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.800 (   6.516s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.800 (   6.516s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.800 (   6.516s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.801 (   6.516s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.801 (   6.516s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.801 (   6.516s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.801 (   6.516s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.801 (   6.517s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.801 (   6.517s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.801 (   6.517s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.801 (   6.517s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.803 (   6.518s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.803 (   6.519s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.803 (   6.519s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.803 (   6.519s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.803 (   6.519s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.803 (   6.519s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.803 (   6.519s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.803 (   6.519s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.803 (   6.519s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.803 (   6.519s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.803 (   6.519s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.803 (   6.519s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.809 (   6.525s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.809 (   6.525s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.809 (   6.525s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.810 (   6.525s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.810 (   6.525s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.810 (   6.526s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.810 (   6.526s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.810 (   6.526s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.810 (   6.526s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.810 (   6.526s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.813 (   6.529s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.813 (   6.529s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.819 (   6.534s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.819 (   6.534s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.819 (   6.535s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.819 (   6.535s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.819 (   6.535s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.819 (   6.535s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.819 (   6.535s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.819 (   6.535s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.819 (   6.535s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.819 (   6.535s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.822 (   6.538s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.822 (   6.538s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.831 (   6.546s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.831 (   6.546s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.831 (   6.547s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.831 (   6.547s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.831 (   6.547s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.831 (   6.547s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.831 (   6.547s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.831 (   6.547s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.831 (   6.547s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.831 (   6.547s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.834 (   6.550s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.834 (   6.550s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.836 (   6.552s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.836 (   6.552s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.836 (   6.552s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.836 (   6.552s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.836 (   6.552s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.836 (   6.552s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.836 (   6.552s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.836 (   6.552s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.836 (   6.552s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.837 (   6.552s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.837 (   6.553s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.837 (   6.553s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.837 (   6.553s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.837 (   6.553s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.837 (   6.553s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.837 (   6.553s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.838 (   6.553s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.838 (   6.553s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.838 (   6.553s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.838 (   6.553s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.838 (   6.554s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.838 (   6.554s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.838 (   6.554s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.838 (   6.554s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.838 (   6.554s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.838 (   6.554s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.839 (   6.554s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.839 (   6.554s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.839 (   6.555s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.839 (   6.555s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.839 (   6.555s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.839 (   6.555s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.839 (   6.555s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.839 (   6.555s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.839 (   6.555s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.839 (   6.555s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.842 (   6.558s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.842 (   6.558s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.842 (   6.558s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.842 (   6.558s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.842 (   6.558s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.842 (   6.558s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.843 (   6.558s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.843 (   6.558s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.843 (   6.559s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.843 (   6.559s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.843 (   6.559s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.843 (   6.559s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.849 (   6.565s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.849 (   6.565s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.849 (   6.565s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.849 (   6.565s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.849 (   6.565s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.849 (   6.565s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.849 (   6.565s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.849 (   6.565s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.849 (   6.565s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.849 (   6.565s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.852 (   6.568s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.852 (   6.568s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.858 (   6.574s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.858 (   6.574s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.858 (   6.574s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.858 (   6.574s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.858 (   6.574s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.858 (   6.574s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.859 (   6.574s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.859 (   6.574s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.859 (   6.575s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.859 (   6.575s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.862 (   6.577s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.862 (   6.577s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.870 (   6.586s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.870 (   6.586s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.870 (   6.586s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.870 (   6.586s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.871 (   6.586s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.871 (   6.586s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.871 (   6.586s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.871 (   6.587s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.871 (   6.587s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.871 (   6.587s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.874 (   6.590s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.874 (   6.590s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.875 (   6.591s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.875 (   6.591s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.875 (   6.591s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.875 (   6.591s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.876 (   6.591s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.876 (   6.591s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.876 (   6.591s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.876 (   6.591s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.876 (   6.592s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.876 (   6.592s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.876 (   6.592s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.876 (   6.592s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.876 (   6.592s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.877 (   6.592s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.877 (   6.592s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.877 (   6.593s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.877 (   6.593s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.877 (   6.593s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.877 (   6.593s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.877 (   6.593s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.877 (   6.593s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.877 (   6.593s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.877 (   6.593s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.877 (   6.593s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.878 (   6.594s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.878 (   6.594s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.878 (   6.594s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.878 (   6.594s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.878 (   6.594s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.878 (   6.594s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.878 (   6.594s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.878 (   6.594s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.878 (   6.594s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.878 (   6.594s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.878 (   6.594s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.878 (   6.594s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.880 (   6.596s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.880 (   6.596s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.880 (   6.596s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.880 (   6.596s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.881 (   6.596s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.881 (   6.596s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.881 (   6.596s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.881 (   6.596s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.881 (   6.597s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.881 (   6.597s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.881 (   6.597s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.881 (   6.597s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.887 (   6.603s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.887 (   6.603s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.887 (   6.603s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.887 (   6.603s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.887 (   6.603s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.887 (   6.603s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.887 (   6.603s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.887 (   6.603s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.887 (   6.603s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.887 (   6.603s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.890 (   6.606s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.890 (   6.606s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.896 (   6.612s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.896 (   6.612s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.896 (   6.612s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.896 (   6.612s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.896 (   6.612s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.896 (   6.612s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.897 (   6.612s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.897 (   6.612s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.897 (   6.613s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.897 (   6.613s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.900 (   6.615s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.900 (   6.616s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.908 (   6.624s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.909 (   6.624s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.909 (   6.624s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.909 (   6.625s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.909 (   6.625s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.909 (   6.625s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.909 (   6.625s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.909 (   6.625s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.909 (   6.625s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.909 (   6.625s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.912 (   6.628s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.912 (   6.628s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.914 (   6.630s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.914 (   6.630s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.914 (   6.630s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.914 (   6.630s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.914 (   6.630s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.914 (   6.630s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.914 (   6.630s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.914 (   6.630s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.914 (   6.630s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.914 (   6.630s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.915 (   6.630s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.915 (   6.630s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.915 (   6.631s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.915 (   6.631s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.915 (   6.631s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.915 (   6.631s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.915 (   6.631s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.915 (   6.631s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.915 (   6.631s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.915 (   6.631s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.916 (   6.631s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.916 (   6.631s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.916 (   6.632s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.916 (   6.632s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.916 (   6.632s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.916 (   6.632s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.916 (   6.632s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.916 (   6.632s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.917 (   6.632s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.917 (   6.632s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.917 (   6.632s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.917 (   6.632s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.917 (   6.633s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.917 (   6.633s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.917 (   6.633s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.917 (   6.633s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.919 (   6.635s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.919 (   6.635s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.919 (   6.635s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.919 (   6.635s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.919 (   6.635s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.919 (   6.635s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.919 (   6.635s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.920 (   6.635s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.920 (   6.635s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.920 (   6.636s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.920 (   6.636s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.920 (   6.636s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.926 (   6.641s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.926 (   6.642s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.926 (   6.642s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.926 (   6.642s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.926 (   6.642s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.926 (   6.642s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.926 (   6.642s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.926 (   6.642s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.926 (   6.642s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.926 (   6.642s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.929 (   6.645s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.929 (   6.645s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.935 (   6.651s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.935 (   6.651s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.935 (   6.651s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.935 (   6.651s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.935 (   6.651s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.935 (   6.651s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.935 (   6.651s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.935 (   6.651s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.936 (   6.651s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.936 (   6.651s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.938 (   6.654s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.938 (   6.654s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.947 (   6.663s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.947 (   6.663s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.947 (   6.663s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.947 (   6.663s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.947 (   6.663s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.947 (   6.663s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.947 (   6.663s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.947 (   6.663s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.948 (   6.663s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.948 (   6.663s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.950 (   6.666s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.950 (   6.666s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.952 (   6.668s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.952 (   6.668s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.952 (   6.668s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.952 (   6.668s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.952 (   6.668s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.952 (   6.668s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.952 (   6.668s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.952 (   6.668s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.952 (   6.668s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.953 (   6.668s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.953 (   6.669s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.953 (   6.669s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.953 (   6.669s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.953 (   6.669s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.953 (   6.669s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.953 (   6.669s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.953 (   6.669s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.954 (   6.669s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.954 (   6.669s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.954 (   6.669s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.954 (   6.670s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.954 (   6.670s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.954 (   6.670s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.954 (   6.670s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.954 (   6.670s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.954 (   6.670s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.954 (   6.670s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.955 (   6.670s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.955 (   6.670s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.955 (   6.671s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.955 (   6.671s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.955 (   6.671s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.955 (   6.671s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.955 (   6.671s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.955 (   6.671s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.955 (   6.671s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.957 (   6.673s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.957 (   6.673s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.957 (   6.673s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.957 (   6.673s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.957 (   6.673s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.957 (   6.673s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.957 (   6.673s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.957 (   6.673s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.958 (   6.673s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.958 (   6.673s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.958 (   6.674s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.958 (   6.674s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.963 (   6.679s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.963 (   6.679s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.964 (   6.679s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.964 (   6.680s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.964 (   6.680s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.964 (   6.680s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.964 (   6.680s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.964 (   6.680s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.964 (   6.680s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.964 (   6.680s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.967 (   6.683s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.967 (   6.683s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.973 (   6.688s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.973 (   6.688s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.973 (   6.689s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.973 (   6.689s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.973 (   6.689s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.973 (   6.689s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.973 (   6.689s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.973 (   6.689s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.973 (   6.689s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.973 (   6.689s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.976 (   6.692s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.976 (   6.692s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.986 (   6.702s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.986 (   6.702s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.986 (   6.702s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.986 (   6.702s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.986 (   6.702s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.986 (   6.702s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.986 (   6.702s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.986 (   6.702s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.986 (   6.702s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.987 (   6.702s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.989 (   6.705s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.989 (   6.705s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.991 (   6.707s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.991 (   6.707s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.991 (   6.707s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.991 (   6.707s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.991 (   6.707s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.991 (   6.707s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.991 (   6.707s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.991 (   6.707s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.991 (   6.707s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.991 (   6.707s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.992 (   6.707s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.992 (   6.707s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.992 (   6.708s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.992 (   6.708s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.992 (   6.708s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.992 (   6.708s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.992 (   6.708s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.992 (   6.708s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.992 (   6.708s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.992 (   6.708s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.993 (   6.708s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.993 (   6.708s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.993 (   6.709s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.993 (   6.709s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.993 (   6.709s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.993 (   6.709s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.993 (   6.709s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.994 (   6.709s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.994 (   6.709s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.994 (   6.709s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.994 (   6.709s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.994 (   6.710s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.994 (   6.710s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.994 (   6.710s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.994 (   6.710s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.994 (   6.710s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.996 (   6.712s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.996 (   6.712s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.996 (   6.712s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.996 (   6.712s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.996 (   6.712s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.996 (   6.712s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:17.996 (   6.712s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:17.996 (   6.712s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:17.996 (   6.712s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:17.996 (   6.712s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:17.997 (   6.712s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:17.997 (   6.712s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.003 (   6.719s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.003 (   6.719s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.003 (   6.719s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.003 (   6.719s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.003 (   6.719s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.003 (   6.719s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.004 (   6.719s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.004 (   6.719s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.004 (   6.720s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.004 (   6.720s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.006 (   6.722s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.006 (   6.722s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.012 (   6.728s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.012 (   6.728s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.012 (   6.728s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.013 (   6.728s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.013 (   6.729s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.013 (   6.729s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.013 (   6.729s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.013 (   6.729s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.013 (   6.729s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.013 (   6.729s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.016 (   6.731s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.016 (   6.731s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.024 (   6.740s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.024 (   6.740s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.025 (   6.740s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.025 (   6.741s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.025 (   6.741s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.025 (   6.741s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.025 (   6.741s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.025 (   6.741s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.025 (   6.741s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.025 (   6.741s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.028 (   6.744s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.028 (   6.744s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.030 (   6.746s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.030 (   6.746s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.030 (   6.746s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.030 (   6.746s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.030 (   6.746s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.030 (   6.746s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.031 (   6.746s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.031 (   6.746s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.031 (   6.747s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.031 (   6.747s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.031 (   6.747s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.031 (   6.747s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.032 (   6.747s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.032 (   6.747s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.032 (   6.748s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.032 (   6.748s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.032 (   6.748s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.032 (   6.748s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.032 (   6.748s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.032 (   6.748s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.032 (   6.748s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.032 (   6.748s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.032 (   6.748s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.032 (   6.748s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.033 (   6.749s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.033 (   6.749s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.033 (   6.749s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.033 (   6.749s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.033 (   6.749s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.033 (   6.749s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.033 (   6.749s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.033 (   6.749s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.033 (   6.749s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.033 (   6.749s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.033 (   6.749s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.033 (   6.749s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.036 (   6.751s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.036 (   6.752s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.036 (   6.752s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.036 (   6.752s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.036 (   6.752s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.036 (   6.752s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.036 (   6.752s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.036 (   6.752s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.036 (   6.752s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.036 (   6.752s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.036 (   6.752s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.036 (   6.752s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.042 (   6.758s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.042 (   6.758s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.042 (   6.758s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.042 (   6.758s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.042 (   6.758s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.043 (   6.758s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.043 (   6.758s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.043 (   6.758s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.043 (   6.759s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.043 (   6.759s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.045 (   6.761s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.045 (   6.761s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.051 (   6.767s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.051 (   6.767s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.051 (   6.767s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.052 (   6.767s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.052 (   6.767s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.052 (   6.767s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.052 (   6.767s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.052 (   6.768s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.052 (   6.768s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.052 (   6.768s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.054 (   6.770s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.054 (   6.770s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.063 (   6.779s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.063 (   6.779s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.063 (   6.779s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.064 (   6.779s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.064 (   6.779s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.064 (   6.779s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.064 (   6.779s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.064 (   6.780s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.064 (   6.780s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.064 (   6.780s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.066 (   6.782s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.067 (   6.782s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.069 (   6.785s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.069 (   6.785s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.069 (   6.785s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.069 (   6.785s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.069 (   6.785s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.069 (   6.785s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.069 (   6.785s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.069 (   6.785s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.069 (   6.785s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.069 (   6.785s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.070 (   6.785s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.070 (   6.785s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.070 (   6.786s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.070 (   6.786s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.070 (   6.786s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.070 (   6.786s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.070 (   6.786s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.071 (   6.786s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.071 (   6.786s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.071 (   6.786s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.071 (   6.787s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.071 (   6.787s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.071 (   6.787s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.071 (   6.787s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.071 (   6.787s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.071 (   6.787s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.071 (   6.787s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.072 (   6.787s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.072 (   6.787s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.072 (   6.787s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.072 (   6.787s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.072 (   6.788s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.072 (   6.788s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.072 (   6.788s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.072 (   6.788s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.072 (   6.788s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.074 (   6.790s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.075 (   6.790s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.075 (   6.790s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.075 (   6.791s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.075 (   6.791s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.075 (   6.791s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.075 (   6.791s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.075 (   6.791s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.075 (   6.791s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.075 (   6.791s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.075 (   6.791s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.075 (   6.791s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.081 (   6.797s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.081 (   6.797s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.081 (   6.797s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.081 (   6.797s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.081 (   6.797s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.081 (   6.797s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.081 (   6.797s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.081 (   6.797s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.082 (   6.797s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.082 (   6.797s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.084 (   6.800s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.084 (   6.800s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.090 (   6.806s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.090 (   6.806s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.090 (   6.806s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.090 (   6.806s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.090 (   6.806s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.090 (   6.806s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.090 (   6.806s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.090 (   6.806s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.091 (   6.806s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.091 (   6.806s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.093 (   6.809s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.093 (   6.809s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.102 (   6.818s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.103 (   6.818s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.103 (   6.818s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.103 (   6.819s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.103 (   6.819s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.103 (   6.819s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.103 (   6.819s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.103 (   6.819s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.103 (   6.819s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.103 (   6.819s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.106 (   6.822s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.106 (   6.822s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.108 (   6.824s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.108 (   6.824s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.108 (   6.824s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.108 (   6.824s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.108 (   6.824s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.108 (   6.824s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.108 (   6.824s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.109 (   6.824s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.109 (   6.824s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.109 (   6.825s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.109 (   6.825s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.109 (   6.825s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.110 (   6.825s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.110 (   6.825s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.110 (   6.825s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.110 (   6.826s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.110 (   6.826s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.110 (   6.826s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.110 (   6.826s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.110 (   6.826s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.110 (   6.826s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.110 (   6.826s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.110 (   6.826s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.110 (   6.826s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.111 (   6.826s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.111 (   6.826s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.111 (   6.827s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.111 (   6.827s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.111 (   6.827s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.111 (   6.827s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.111 (   6.827s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.111 (   6.827s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.111 (   6.827s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.111 (   6.827s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.111 (   6.827s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.111 (   6.827s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.114 (   6.830s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.114 (   6.830s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.114 (   6.830s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.114 (   6.830s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.114 (   6.830s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.114 (   6.830s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.114 (   6.830s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.114 (   6.830s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.114 (   6.830s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.114 (   6.830s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.114 (   6.830s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.114 (   6.830s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.120 (   6.836s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.120 (   6.836s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.120 (   6.836s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.120 (   6.836s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.121 (   6.836s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.121 (   6.836s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.121 (   6.836s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.121 (   6.836s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.121 (   6.837s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.121 (   6.837s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.123 (   6.839s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.123 (   6.839s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.129 (   6.845s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.129 (   6.845s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.129 (   6.845s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.129 (   6.845s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.129 (   6.845s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.129 (   6.845s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.129 (   6.845s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.130 (   6.845s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.130 (   6.845s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.130 (   6.846s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.132 (   6.848s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.132 (   6.848s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.141 (   6.857s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.141 (   6.857s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.141 (   6.857s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.141 (   6.857s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.141 (   6.857s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.141 (   6.857s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.141 (   6.857s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.141 (   6.857s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.141 (   6.857s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.142 (   6.857s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.144 (   6.860s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.144 (   6.860s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.146 (   6.862s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.146 (   6.862s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.147 (   6.862s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.147 (   6.862s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.147 (   6.863s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.147 (   6.863s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.147 (   6.863s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.147 (   6.863s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.147 (   6.863s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.147 (   6.863s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.147 (   6.863s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.147 (   6.863s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.148 (   6.864s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.148 (   6.864s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.148 (   6.864s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.148 (   6.864s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.148 (   6.864s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.148 (   6.864s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.148 (   6.864s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.148 (   6.864s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.148 (   6.864s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.149 (   6.864s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.149 (   6.864s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.149 (   6.865s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.149 (   6.865s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.149 (   6.865s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.149 (   6.865s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.149 (   6.865s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.149 (   6.865s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.149 (   6.865s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.149 (   6.865s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.149 (   6.865s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.150 (   6.865s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.150 (   6.865s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.150 (   6.866s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.150 (   6.866s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.152 (   6.868s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.152 (   6.868s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.152 (   6.868s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.152 (   6.868s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.152 (   6.868s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.152 (   6.868s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.152 (   6.868s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.152 (   6.868s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.153 (   6.868s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.153 (   6.869s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.153 (   6.869s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.153 (   6.869s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.158 (   6.874s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.159 (   6.874s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.159 (   6.874s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.159 (   6.875s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.159 (   6.875s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.159 (   6.875s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.159 (   6.875s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.159 (   6.875s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.159 (   6.875s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.159 (   6.875s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.162 (   6.878s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.162 (   6.878s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.167 (   6.883s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.167 (   6.883s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.168 (   6.883s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.168 (   6.884s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.168 (   6.884s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.168 (   6.884s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.168 (   6.884s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.168 (   6.884s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.168 (   6.884s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.168 (   6.884s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.171 (   6.886s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.171 (   6.886s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.179 (   6.895s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.179 (   6.895s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.179 (   6.895s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.180 (   6.895s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.180 (   6.896s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.180 (   6.896s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.180 (   6.896s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.180 (   6.896s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.180 (   6.896s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.180 (   6.896s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.183 (   6.898s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.183 (   6.899s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.185 (   6.901s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.185 (   6.901s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.185 (   6.901s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.185 (   6.901s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.185 (   6.901s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.185 (   6.901s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.185 (   6.901s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.185 (   6.901s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.185 (   6.901s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.186 (   6.901s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.186 (   6.901s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.186 (   6.902s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.186 (   6.902s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.186 (   6.902s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.186 (   6.902s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.187 (   6.902s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.187 (   6.902s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.187 (   6.902s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.187 (   6.903s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.187 (   6.903s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.187 (   6.903s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.187 (   6.903s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.187 (   6.903s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.187 (   6.903s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.187 (   6.903s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.187 (   6.903s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.188 (   6.903s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.188 (   6.903s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.188 (   6.904s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.188 (   6.904s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.188 (   6.904s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.188 (   6.904s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.188 (   6.904s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.188 (   6.904s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.188 (   6.904s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.188 (   6.904s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.190 (   6.906s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.190 (   6.906s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.190 (   6.906s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.191 (   6.906s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.191 (   6.906s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.191 (   6.907s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.191 (   6.907s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.191 (   6.907s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.191 (   6.907s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.191 (   6.907s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.191 (   6.907s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.191 (   6.907s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.197 (   6.913s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.197 (   6.913s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.197 (   6.913s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.197 (   6.913s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.197 (   6.913s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.197 (   6.913s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.197 (   6.913s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.197 (   6.913s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.197 (   6.913s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.197 (   6.913s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.200 (   6.916s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.200 (   6.916s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.206 (   6.921s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.206 (   6.921s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.206 (   6.921s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.206 (   6.922s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.206 (   6.922s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.206 (   6.922s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.206 (   6.922s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.206 (   6.922s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.206 (   6.922s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.206 (   6.922s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.209 (   6.925s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.209 (   6.925s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.217 (   6.933s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.217 (   6.933s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.217 (   6.933s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.218 (   6.934s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.218 (   6.934s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.218 (   6.934s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.218 (   6.934s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.218 (   6.934s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.218 (   6.934s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.218 (   6.934s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.221 (   6.936s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.221 (   6.937s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.223 (   6.939s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.223 (   6.939s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.223 (   6.939s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.223 (   6.939s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.223 (   6.939s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.223 (   6.939s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.223 (   6.939s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.223 (   6.939s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.224 (   6.939s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.224 (   6.939s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.224 (   6.940s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.224 (   6.940s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.224 (   6.940s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.224 (   6.940s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.225 (   6.940s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.225 (   6.940s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.225 (   6.941s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.225 (   6.941s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.225 (   6.941s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.225 (   6.941s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.225 (   6.941s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.225 (   6.941s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.225 (   6.941s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.225 (   6.941s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.226 (   6.941s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.226 (   6.941s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.226 (   6.941s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.226 (   6.942s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.226 (   6.942s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.226 (   6.942s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.226 (   6.942s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.226 (   6.942s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.226 (   6.942s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.226 (   6.942s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.226 (   6.942s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.226 (   6.942s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.228 (   6.943s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.228 (   6.944s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.228 (   6.944s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.228 (   6.944s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.228 (   6.944s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.228 (   6.944s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.228 (   6.944s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.228 (   6.944s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.228 (   6.944s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.228 (   6.944s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.228 (   6.944s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.228 (   6.944s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.234 (   6.950s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.234 (   6.950s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.234 (   6.950s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.234 (   6.950s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.234 (   6.950s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.234 (   6.950s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.234 (   6.950s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.234 (   6.950s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.235 (   6.950s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.235 (   6.950s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.237 (   6.953s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.237 (   6.953s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.243 (   6.959s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.243 (   6.959s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.243 (   6.959s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.243 (   6.959s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.243 (   6.959s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.243 (   6.959s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.243 (   6.959s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.243 (   6.959s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.244 (   6.959s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.244 (   6.959s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.246 (   6.962s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.246 (   6.962s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.255 (   6.970s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.255 (   6.971s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.255 (   6.971s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.255 (   6.971s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.255 (   6.971s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.255 (   6.971s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.255 (   6.971s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.255 (   6.971s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.255 (   6.971s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.255 (   6.971s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.258 (   6.974s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.258 (   6.974s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.260 (   6.976s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.260 (   6.976s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.260 (   6.976s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.260 (   6.976s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.261 (   6.976s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.261 (   6.976s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.261 (   6.976s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.261 (   6.977s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.261 (   6.977s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.261 (   6.977s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.261 (   6.977s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.261 (   6.977s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.262 (   6.978s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.262 (   6.978s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.262 (   6.978s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.262 (   6.978s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.262 (   6.978s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.262 (   6.978s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.262 (   6.978s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.262 (   6.978s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.262 (   6.978s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.262 (   6.978s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.262 (   6.978s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.262 (   6.978s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.263 (   6.979s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.263 (   6.979s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.263 (   6.979s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.263 (   6.979s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.263 (   6.979s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.263 (   6.979s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.263 (   6.979s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.263 (   6.979s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.263 (   6.979s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.263 (   6.979s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.263 (   6.979s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.264 (   6.979s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.266 (   6.982s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.266 (   6.982s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.266 (   6.982s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.266 (   6.982s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.266 (   6.982s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.266 (   6.982s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.266 (   6.982s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.266 (   6.982s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.266 (   6.982s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.266 (   6.982s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.267 (   6.982s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.267 (   6.983s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.272 (   6.988s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.272 (   6.988s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.272 (   6.988s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.273 (   6.988s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.273 (   6.988s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.273 (   6.988s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.273 (   6.989s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.273 (   6.989s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.273 (   6.989s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.273 (   6.989s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.275 (   6.991s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.276 (   6.991s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.281 (   6.997s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.281 (   6.997s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.281 (   6.997s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.281 (   6.997s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.282 (   6.997s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.282 (   6.997s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.282 (   6.997s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.282 (   6.997s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.282 (   6.998s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.282 (   6.998s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.284 (   7.000s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.284 (   7.000s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.293 (   7.009s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.293 (   7.009s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.293 (   7.009s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.293 (   7.009s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.293 (   7.009s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.293 (   7.009s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.293 (   7.009s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.293 (   7.009s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.294 (   7.009s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.294 (   7.009s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.296 (   7.012s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.296 (   7.012s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.299 (   7.014s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.299 (   7.014s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.299 (   7.014s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.299 (   7.015s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.299 (   7.015s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.299 (   7.015s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.299 (   7.015s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.299 (   7.015s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.299 (   7.015s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.299 (   7.015s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.299 (   7.015s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.299 (   7.015s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.300 (   7.016s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.300 (   7.016s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.300 (   7.016s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.300 (   7.016s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.300 (   7.016s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.300 (   7.016s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.300 (   7.016s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.300 (   7.016s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.300 (   7.016s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.300 (   7.016s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.301 (   7.016s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.301 (   7.016s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.301 (   7.017s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.301 (   7.017s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.301 (   7.017s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.301 (   7.017s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.301 (   7.017s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.301 (   7.017s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.301 (   7.017s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.302 (   7.017s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.302 (   7.017s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.302 (   7.018s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.302 (   7.018s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.302 (   7.018s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.304 (   7.020s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.304 (   7.020s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.304 (   7.020s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.305 (   7.020s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.305 (   7.020s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.305 (   7.020s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.305 (   7.021s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.305 (   7.021s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.305 (   7.021s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.305 (   7.021s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.305 (   7.021s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.305 (   7.021s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.311 (   7.026s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.311 (   7.027s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.311 (   7.027s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.311 (   7.027s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.311 (   7.027s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.311 (   7.027s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.311 (   7.027s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.311 (   7.027s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.311 (   7.027s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.311 (   7.027s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.314 (   7.030s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.314 (   7.030s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.319 (   7.035s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.320 (   7.035s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.320 (   7.035s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.320 (   7.036s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.320 (   7.036s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.320 (   7.036s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.320 (   7.036s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.320 (   7.036s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.320 (   7.036s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.320 (   7.036s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.323 (   7.039s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.323 (   7.039s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.331 (   7.047s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.331 (   7.047s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.331 (   7.047s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.332 (   7.047s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.332 (   7.048s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.332 (   7.048s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.332 (   7.048s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.332 (   7.048s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.332 (   7.048s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.332 (   7.048s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.335 (   7.050s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.335 (   7.050s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.337 (   7.053s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.337 (   7.053s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.337 (   7.053s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.337 (   7.053s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.337 (   7.053s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.337 (   7.053s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.337 (   7.053s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.337 (   7.053s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.337 (   7.053s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.338 (   7.053s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.338 (   7.054s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.338 (   7.054s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.338 (   7.054s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.338 (   7.054s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.338 (   7.054s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.339 (   7.054s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.339 (   7.054s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.339 (   7.055s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.339 (   7.055s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.339 (   7.055s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.339 (   7.055s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.339 (   7.055s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.339 (   7.055s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.339 (   7.055s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.340 (   7.055s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.340 (   7.055s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.340 (   7.055s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.340 (   7.056s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.340 (   7.056s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.340 (   7.056s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.340 (   7.056s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.340 (   7.056s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.340 (   7.056s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.340 (   7.056s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.340 (   7.056s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.340 (   7.056s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.343 (   7.058s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.343 (   7.059s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.343 (   7.059s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.343 (   7.059s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.343 (   7.059s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.343 (   7.059s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.343 (   7.059s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.343 (   7.059s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.343 (   7.059s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.343 (   7.059s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.343 (   7.059s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.343 (   7.059s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.349 (   7.065s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.349 (   7.065s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.349 (   7.065s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.349 (   7.065s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.349 (   7.065s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.350 (   7.065s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.350 (   7.065s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.350 (   7.065s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.350 (   7.066s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.350 (   7.066s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.352 (   7.068s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.352 (   7.068s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.358 (   7.074s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.358 (   7.074s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.358 (   7.074s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.358 (   7.074s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.358 (   7.074s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.358 (   7.074s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.358 (   7.074s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.358 (   7.074s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.359 (   7.074s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.359 (   7.074s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.361 (   7.077s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.361 (   7.077s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.370 (   7.085s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.370 (   7.086s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.370 (   7.086s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.370 (   7.086s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.370 (   7.086s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.370 (   7.086s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.370 (   7.086s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.370 (   7.086s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.370 (   7.086s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.370 (   7.086s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.373 (   7.089s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.373 (   7.089s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.377 (   7.092s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.377 (   7.093s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.377 (   7.093s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.377 (   7.093s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.377 (   7.093s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.377 (   7.093s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.377 (   7.093s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.377 (   7.093s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.377 (   7.093s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.377 (   7.093s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.377 (   7.093s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.378 (   7.093s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.378 (   7.094s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.378 (   7.094s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.378 (   7.094s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.378 (   7.094s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.378 (   7.094s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.378 (   7.094s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.378 (   7.094s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.379 (   7.094s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.379 (   7.094s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.379 (   7.095s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.379 (   7.095s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.379 (   7.095s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.379 (   7.095s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.379 (   7.095s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.379 (   7.095s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.379 (   7.095s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.380 (   7.095s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.380 (   7.095s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.380 (   7.095s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.380 (   7.095s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.380 (   7.096s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.380 (   7.096s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.380 (   7.096s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.380 (   7.096s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.382 (   7.098s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.382 (   7.098s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.383 (   7.098s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.383 (   7.098s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.383 (   7.099s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.383 (   7.099s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.383 (   7.099s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.383 (   7.099s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.383 (   7.099s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.383 (   7.099s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.383 (   7.099s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.383 (   7.099s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.389 (   7.105s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.389 (   7.105s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.389 (   7.105s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.389 (   7.105s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.389 (   7.105s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.389 (   7.105s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.389 (   7.105s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.389 (   7.105s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.389 (   7.105s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.389 (   7.105s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.392 (   7.108s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.392 (   7.108s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.398 (   7.113s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.398 (   7.114s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.398 (   7.114s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.398 (   7.114s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.398 (   7.114s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.398 (   7.114s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.398 (   7.114s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.398 (   7.114s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.398 (   7.114s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.398 (   7.114s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.401 (   7.117s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.401 (   7.117s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.409 (   7.125s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.409 (   7.125s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.410 (   7.125s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.410 (   7.126s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.410 (   7.126s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.410 (   7.126s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.410 (   7.126s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.410 (   7.126s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.410 (   7.126s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.410 (   7.126s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.413 (   7.129s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.413 (   7.129s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.415 (   7.131s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.415 (   7.131s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.415 (   7.131s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.415 (   7.131s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.415 (   7.131s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.415 (   7.131s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.415 (   7.131s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.416 (   7.131s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.416 (   7.131s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.416 (   7.132s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.416 (   7.132s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.416 (   7.132s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.417 (   7.132s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.417 (   7.132s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.417 (   7.132s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.417 (   7.133s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.417 (   7.133s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.417 (   7.133s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.417 (   7.133s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.417 (   7.133s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.417 (   7.133s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.417 (   7.133s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.417 (   7.133s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.417 (   7.133s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.418 (   7.133s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.418 (   7.134s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.418 (   7.134s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.418 (   7.134s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.418 (   7.134s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.418 (   7.134s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.418 (   7.134s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.418 (   7.134s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.418 (   7.134s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.418 (   7.134s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.418 (   7.134s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.418 (   7.134s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.421 (   7.137s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.421 (   7.137s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.421 (   7.137s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.421 (   7.137s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.421 (   7.137s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.421 (   7.137s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.421 (   7.137s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.421 (   7.137s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.421 (   7.137s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.422 (   7.137s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.422 (   7.138s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.422 (   7.138s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.427 (   7.143s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.427 (   7.143s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.427 (   7.143s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.428 (   7.143s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.428 (   7.144s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.428 (   7.144s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.428 (   7.144s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.428 (   7.144s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.428 (   7.144s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.428 (   7.144s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.430 (   7.146s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.430 (   7.146s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.436 (   7.152s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.436 (   7.152s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.436 (   7.152s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.436 (   7.152s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.436 (   7.152s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.436 (   7.152s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.436 (   7.152s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.436 (   7.152s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.437 (   7.152s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.437 (   7.153s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.439 (   7.155s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.439 (   7.155s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.447 (   7.163s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.447 (   7.163s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.447 (   7.163s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.448 (   7.164s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.448 (   7.164s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.448 (   7.164s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.448 (   7.164s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.448 (   7.164s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.448 (   7.164s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.448 (   7.164s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.450 (   7.166s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.451 (   7.166s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.453 (   7.169s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.453 (   7.169s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.453 (   7.169s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.453 (   7.169s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.453 (   7.169s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.453 (   7.169s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.453 (   7.169s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.453 (   7.169s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.453 (   7.169s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.453 (   7.169s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.454 (   7.169s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.454 (   7.169s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.454 (   7.170s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.454 (   7.170s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.454 (   7.170s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.454 (   7.170s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.454 (   7.170s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.454 (   7.170s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.455 (   7.170s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.455 (   7.170s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.455 (   7.171s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.455 (   7.171s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.455 (   7.171s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.455 (   7.171s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.455 (   7.171s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.455 (   7.171s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.455 (   7.171s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.456 (   7.171s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.456 (   7.171s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.456 (   7.171s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.456 (   7.171s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.456 (   7.172s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.456 (   7.172s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.456 (   7.172s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.456 (   7.172s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.456 (   7.172s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.459 (   7.174s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.459 (   7.174s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.459 (   7.174s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.459 (   7.175s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.459 (   7.175s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.459 (   7.175s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.459 (   7.175s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.459 (   7.175s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.459 (   7.175s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.459 (   7.175s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.459 (   7.175s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.459 (   7.175s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.465 (   7.181s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.465 (   7.181s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.465 (   7.181s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.465 (   7.181s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.465 (   7.181s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.465 (   7.181s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.465 (   7.181s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.465 (   7.181s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.466 (   7.181s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.466 (   7.181s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.468 (   7.184s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.468 (   7.184s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.474 (   7.189s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.474 (   7.189s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.474 (   7.190s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.474 (   7.190s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.474 (   7.190s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.474 (   7.190s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.474 (   7.190s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.474 (   7.190s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.474 (   7.190s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.474 (   7.190s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.477 (   7.192s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.477 (   7.192s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.485 (   7.201s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.485 (   7.201s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.485 (   7.201s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.486 (   7.201s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.486 (   7.201s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.486 (   7.202s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.486 (   7.202s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.486 (   7.202s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.486 (   7.202s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.486 (   7.202s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.488 (   7.204s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.488 (   7.204s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.491 (   7.206s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.491 (   7.206s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.491 (   7.206s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.491 (   7.207s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.491 (   7.207s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.491 (   7.207s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.491 (   7.207s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.491 (   7.207s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.491 (   7.207s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.491 (   7.207s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.491 (   7.207s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.491 (   7.207s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.492 (   7.208s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.492 (   7.208s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.492 (   7.208s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.492 (   7.208s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.492 (   7.208s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.492 (   7.208s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.492 (   7.208s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.492 (   7.208s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.492 (   7.208s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.493 (   7.208s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.493 (   7.208s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.493 (   7.209s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.493 (   7.209s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.493 (   7.209s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.493 (   7.209s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.493 (   7.209s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.493 (   7.209s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.493 (   7.209s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.493 (   7.209s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.493 (   7.209s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.494 (   7.209s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.494 (   7.209s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.494 (   7.210s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.494 (   7.210s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:18.496 (   7.212s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.496 (   7.212s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.496 (   7.212s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.497 (   7.212s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.497 (   7.212s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:18.497 (   7.212s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:18.497 (   7.213s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:18.497 (   7.213s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:18.497 (   7.213s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:18.497 (   7.213s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.717 (   8.433s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.717 (   8.433s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.717 (   8.433s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.717 (   8.433s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.717 (   8.433s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.718 (   8.433s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.718 (   8.433s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.718 (   8.434s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.719 (   8.434s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.719 (   8.434s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.719 (   8.434s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.719 (   8.434s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.719 (   8.434s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.719 (   8.434s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.719 (   8.434s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.719 (   8.435s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.719 (   8.435s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.719 (   8.435s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.719 (   8.435s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.801 (   8.517s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.801 (   8.517s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.801 (   8.517s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.801 (   8.517s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.801 (   8.517s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.801 (   8.517s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.801 (   8.517s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.801 (   8.517s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.801 (   8.517s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.801 (   8.517s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.834 (   8.550s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.834 (   8.550s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.915 (   8.631s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.915 (   8.631s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.915 (   8.631s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.916 (   8.631s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.916 (   8.631s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.916 (   8.631s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.916 (   8.631s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.916 (   8.631s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.916 (   8.632s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.916 (   8.632s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.942 (   8.657s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.942 (   8.657s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.942 (   8.658s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.942 (   8.658s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.942 (   8.658s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.942 (   8.658s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.942 (   8.658s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.942 (   8.658s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.942 (   8.658s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.942 (   8.658s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.942 (   8.658s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.942 (   8.658s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.943 (   8.659s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.943 (   8.659s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.943 (   8.659s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.943 (   8.659s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.943 (   8.659s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.943 (   8.659s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.943 (   8.659s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.943 (   8.659s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.943 (   8.659s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.943 (   8.659s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.943 (   8.659s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.943 (   8.659s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.946 (   8.662s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.946 (   8.662s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.946 (   8.662s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.946 (   8.662s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.946 (   8.662s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.947 (   8.662s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.947 (   8.662s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.947 (   8.662s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.947 (   8.662s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.947 (   8.662s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.947 (   8.663s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.947 (   8.663s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.948 (   8.664s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.948 (   8.664s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.948 (   8.664s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.948 (   8.664s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.948 (   8.664s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-09 19:22:19.948 (   8.664s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.948 (   8.664s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.949 (   8.664s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.949 (   8.664s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.949 (   8.664s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-09 19:22:19.949 (   8.664s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.949 (   8.664s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.949 (   8.665s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.950 (   8.665s) [        56CD8000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-09 19:22:19.950 (   8.665s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.950 (   8.665s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.950 (   8.665s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.950 (   8.665s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.950 (   8.665s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.950 (   8.665s) [        56CD8000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-09 19:22:19.950 (   8.665s) [        56CD8000]     client_instance.cc:466      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-09 19:22:19.950 (   8.665s) [        56CD8000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-09 19:22:19.950 (   8.666s) [        56CD8000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-09 19:22:19.950 (   8.666s) [        56CD8000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.953 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.954 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.954 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.954 (   8.669s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.954 (   8.670s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.954 (   8.670s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.954 (   8.670s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.954 (   8.670s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.954 (   8.670s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.954 (   8.670s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.954 (   8.670s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.954 (   8.670s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.954 (   8.670s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.955 (   8.670s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.955 (   8.670s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.955 (   8.671s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.955 (   8.671s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.955 (   8.671s) [        56CD8000]     buffer_instance.cc:480      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-09 19:22:19.985 (   8.701s) [        56CD8000]     client_instance.cc:428      1| ClientInstance::PJRT_Client_Compile
2025-09-09 19:22:19.986 (   8.701s) [        56CD8000]      module_builder.cc:103      1| ModuleBuilder::buildModule
2025-09-09 19:22:19.988 (   8.704s) [        56CD8000]      module_builder.cc:165      1| VHLO Module:
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, %arg1: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg2: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg3: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg4: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg5: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg6: !vhlo.tensor_v1<1x7x!vhlo.i64_v1>, %arg7: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, %arg8: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg9: !vhlo.tensor_v1<7x!vhlo.i64_v1>, %arg10: !vhlo.tensor_v1<!vhlo.i64_v1>, %arg11: !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, %arg12: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg13: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg14: !vhlo.tensor_v1<64x!vhlo.f32_v1>, %arg15: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg16: !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, %arg17: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg18: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg19: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg20: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"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tensor<1024xi64>>}> : () -> !vhlo.tensor_v1<1024x!vhlo.i64_v1>
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>>}> : () -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<3.25520843E-4> : tensor<1x7xf32>>}> : () -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<7xi64>>}> : () -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<1> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1>
    %8 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %9 = "vhlo.broadcast_in_dim_v1"(%8) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %10 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %11 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %12 = "vhlo.reshape_v1"(%arg20) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %13 = "vhlo.custom_call_v1"(%12) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_norm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %14 = "vhlo.reshape_v1"(%13) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1>
    %15 = "vhlo.convert_v1"(%14) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %16 = "vhlo.broadcast_in_dim_v1"(%15) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %17 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %18 = "vhlo.custom_call_v1"(%17) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %19 = "vhlo.reshape_v1"(%18) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>
    %20 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %21 = "vhlo.custom_call_v1"(%20) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %22 = "vhlo.reshape_v1"(%21) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %23 = "vhlo.convert_v1"(%22) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.ui32_v1>
    %24 = "vhlo.gather_v2"(%19, %23) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3072]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %25 = "vhlo.reshape_v1"(%24) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %26 = "vhlo.reshape_v1"(%arg8) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %27 = "vhlo.custom_call_v1"(%26) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %28 = "vhlo.reshape_v1"(%27) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1>
    %29 = "vhlo.convert_v1"(%28) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %30 = "vhlo.broadcast_in_dim_v1"(%29) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %31 = "vhlo.convert_v1"(%25) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %32 = "vhlo.power_v1"(%31, %11) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %33 = "vhlo.reduce_v1"(%32, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %34 = "vhlo.multiply_v1"(%33, %5) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %35 = "vhlo.reshape_v1"(%34) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %36 = "vhlo.broadcast_in_dim_v1"(%arg1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %37 = "vhlo.add_v1"(%35, %36) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %38 = "vhlo.rsqrt_v2"(%37) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %39 = "vhlo.reshape_v1"(%38) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %40 = "vhlo.broadcast_in_dim_v1"(%39) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %41 = "vhlo.multiply_v1"(%31, %40) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %42 = "vhlo.convert_v1"(%41) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %43 = "vhlo.convert_v1"(%42) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %44 = "vhlo.multiply_v1"(%30, %43) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %45 = "vhlo.convert_v1"(%44) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %46 = "vhlo.reshape_v1"(%45) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %47 = "vhlo.reshape_v1"(%arg17) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %48 = "vhlo.custom_call_v1"(%47) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %49 = "vhlo.reshape_v1"(%48) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %50 = "vhlo.transpose_v1"(%49) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %51 = "vhlo.dot_general_v2"(%46, %50) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %52 = "vhlo.reshape_v1"(%51) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %53 = "vhlo.transpose_v1"(%52) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %54 = "vhlo.convert_v1"(%53) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %55 = "vhlo.reshape_v1"(%arg14) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %56 = "vhlo.custom_call_v1"(%55) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %57 = "vhlo.reshape_v1"(%56) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %58 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %59 = "vhlo.custom_call_v1"(%58) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %60 = "vhlo.reshape_v1"(%59) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %61 = "vhlo.convert_v1"(%59) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1>
    %62 = "vhlo.dot_general_v2"(%57, %61) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x7x!vhlo.f32_v1>
    %63 = "vhlo.transpose_v1"(%62) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,7,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>
    %64 = "vhlo.concatenate_v1"(%63, %63) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %65 = "vhlo.cosine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %66 = "vhlo.convert_v1"(%65) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %67 = "vhlo.reshape_v1"(%66) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>
    %68 = "vhlo.convert_v1"(%67) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>
    %69 = "vhlo.reshape_v1"(%68) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %70 = "vhlo.broadcast_in_dim_v1"(%69) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %71 = "vhlo.multiply_v1"(%54, %70) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %72 = "vhlo.convert_v1"(%71) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %73 = "vhlo.slice_v1"(%53) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %74 = "vhlo.negate_v1"(%73) : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %75 = "vhlo.slice_v1"(%53) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %76 = "vhlo.concatenate_v1"(%74, %75) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %77 = "vhlo.convert_v1"(%76) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %78 = "vhlo.sine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %79 = "vhlo.convert_v1"(%78) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %80 = "vhlo.reshape_v1"(%79) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>
    %81 = "vhlo.convert_v1"(%80) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>
    %82 = "vhlo.reshape_v1"(%81) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %83 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %84 = "vhlo.multiply_v1"(%77, %83) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %85 = "vhlo.convert_v1"(%84) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %86 = "vhlo.add_v1"(%72, %85) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %87 = "vhlo.reshape_v1"(%86) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %88 = "vhlo.custom_call_v1"(%arg16) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_2">}>} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %89 = "vhlo.compare_v1"(%60, %6) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.bool_v1>
    %90 = "vhlo.broadcast_in_dim_v1"(%arg10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %91 = "vhlo.add_v1"(%60, %90) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %92 = "vhlo.select_v1"(%89, %91, %60) : (!vhlo.tensor_v1<7x!vhlo.bool_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %93 = "vhlo.reshape_v1"(%92) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1x!vhlo.i64_v1>
    %94 = "vhlo.reshape_v1"(%arg15) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %95 = "vhlo.custom_call_v1"(%94) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %96 = "vhlo.reshape_v1"(%95) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>
    %97 = "vhlo.transpose_v1"(%96) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %98 = "vhlo.dot_general_v2"(%46, %97) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %99 = "vhlo.reshape_v1"(%98) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %100 = "vhlo.transpose_v1"(%99) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %101 = "vhlo.convert_v1"(%100) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %102 = "vhlo.broadcast_in_dim_v1"(%69) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %103 = "vhlo.multiply_v1"(%101, %102) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %104 = "vhlo.convert_v1"(%103) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %105 = "vhlo.slice_v1"(%100) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %106 = "vhlo.negate_v1"(%105) : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %107 = "vhlo.slice_v1"(%100) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %108 = "vhlo.concatenate_v1"(%106, %107) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %109 = "vhlo.convert_v1"(%108) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %110 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %111 = "vhlo.multiply_v1"(%109, %110) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %112 = "vhlo.convert_v1"(%111) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %113 = "vhlo.add_v1"(%104, %112) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %114 = "vhlo.scatter_v2"(%88, %93, %113) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %115 = "vhlo.broadcast_in_dim_v1"(%114) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>
    %116 = "vhlo.reshape_v1"(%115) : (!vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1024x128x!vhlo.bf16_v1>
    %117 = "vhlo.transpose_v1"(%116) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,1024]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x1024x!vhlo.bf16_v1>
    %118 = "vhlo.reshape_v1"(%117) : (!vhlo.tensor_v1<1x24x128x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x1024x!vhlo.bf16_v1>
    %119 = "vhlo.dot_general_v2"(%87, %118) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>
    %120 = "vhlo.reshape_v1"(%119) : (!vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %121 = "vhlo.convert_v1"(%120) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %122 = "vhlo.broadcast_in_dim_v1"(%arg13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %123 = "vhlo.multiply_v1"(%121, %122) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %124 = "vhlo.convert_v1"(%123) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %125 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %126 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %127 = "vhlo.subtract_v1"(%125, %126) : (!vhlo.tensor_v1<7x1024x!vhlo.i64_v1>, !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %128 = "vhlo.compare_v1"(%127, %10) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GE>}> : (!vhlo.tensor_v1<7x1024x!vhlo.i64_v1>, !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bool_v1>
    %129 = "vhlo.broadcast_in_dim_v1"(%arg12) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %130 = "vhlo.select_v1"(%128, %129, %9) : (!vhlo.tensor_v1<7x1024x!vhlo.bool_v1>, !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %131 = "vhlo.convert_v1"(%130) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>
    %132 = "vhlo.broadcast_in_dim_v1"(%60) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %133 = "vhlo.compare_v1"(%125, %132) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<7x1024x!vhlo.i64_v1>, !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bool_v1>
    %134 = "vhlo.convert_v1"(%133) : (!vhlo.tensor_v1<7x1024x!vhlo.bool_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>
    %135 = "vhlo.multiply_v1"(%131, %134) : (!vhlo.tensor_v1<7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>
    %136 = "vhlo.convert_v1"(%135) : (!vhlo.tensor_v1<7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %137 = "vhlo.reshape_v1"(%136) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x1024x!vhlo.bf16_v1>
    %138 = "vhlo.broadcast_in_dim_v1"(%137) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %139 = "vhlo.add_v1"(%124, %138) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %140 = "vhlo.convert_v1"(%139) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %141 = "vhlo.reduce_v1"(%140, %3) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.maximum_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %142 = "vhlo.broadcast_in_dim_v1"(%141) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %143 = "vhlo.subtract_v1"(%140, %142) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %144 = "vhlo.exponential_v2"(%143) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %145 = "vhlo.reduce_v1"(%144, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %146 = "vhlo.broadcast_in_dim_v1"(%145) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %147 = "vhlo.divide_v1"(%144, %146) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %148 = "vhlo.convert_v1"(%147) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %149 = "vhlo.reshape_v1"(%148) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>
    %150 = "vhlo.custom_call_v1"(%arg11) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_3">}>} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %151 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %152 = "vhlo.custom_call_v1"(%151) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %153 = "vhlo.reshape_v1"(%152) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>
    %154 = "vhlo.transpose_v1"(%153) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %155 = "vhlo.dot_general_v2"(%46, %154) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %156 = "vhlo.reshape_v1"(%155) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %157 = "vhlo.transpose_v1"(%156) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %158 = "vhlo.scatter_v2"(%150, %93, %157) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %159 = "vhlo.broadcast_in_dim_v1"(%158) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>
    %160 = "vhlo.reshape_v1"(%159) : (!vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1024x128x!vhlo.bf16_v1>
    %161 = "vhlo.dot_general_v2"(%149, %160) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %162 = "vhlo.reshape_v1"(%161) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %163 = "vhlo.transpose_v1"(%162) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,7,24,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %164 = "vhlo.reshape_v1"(%163) : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %165 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %166 = "vhlo.custom_call_v1"(%165) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %167 = "vhlo.reshape_v1"(%166) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %168 = "vhlo.transpose_v1"(%167) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %169 = "vhlo.dot_general_v2"(%164, %168) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %170 = "vhlo.reshape_v1"(%169) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %171 = "vhlo.add_v1"(%25, %170) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %172 = "vhlo.reshape_v1"(%arg18) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %173 = "vhlo.custom_call_v1"(%172) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %174 = "vhlo.reshape_v1"(%173) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1>
    %175 = "vhlo.convert_v1"(%174) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %176 = "vhlo.broadcast_in_dim_v1"(%175) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %177 = "vhlo.convert_v1"(%171) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %178 = "vhlo.power_v1"(%177, %11) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %179 = "vhlo.reduce_v1"(%178, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %180 = "vhlo.multiply_v1"(%179, %5) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %181 = "vhlo.reshape_v1"(%180) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %182 = "vhlo.add_v1"(%181, %36) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %183 = "vhlo.rsqrt_v2"(%182) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %184 = "vhlo.reshape_v1"(%183) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %185 = "vhlo.broadcast_in_dim_v1"(%184) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %186 = "vhlo.multiply_v1"(%177, %185) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %187 = "vhlo.convert_v1"(%186) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %188 = "vhlo.convert_v1"(%187) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %189 = "vhlo.multiply_v1"(%176, %188) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %190 = "vhlo.convert_v1"(%189) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %191 = "vhlo.reshape_v1"(%190) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %192 = "vhlo.reshape_v1"(%arg19) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %193 = "vhlo.custom_call_v1"(%192) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %194 = "vhlo.reshape_v1"(%193) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %195 = "vhlo.transpose_v1"(%194) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %196 = "vhlo.dot_general_v2"(%191, %195) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %197 = "vhlo.reshape_v1"(%196) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %198 = "vhlo.convert_v1"(%197) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %199 = "vhlo.logistic_v2"(%197) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %200 = "vhlo.convert_v1"(%199) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %201 = "vhlo.multiply_v1"(%198, %200) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %202 = "vhlo.convert_v1"(%201) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %203 = "vhlo.convert_v1"(%202) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %204 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %205 = "vhlo.custom_call_v1"(%204) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %206 = "vhlo.reshape_v1"(%205) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %207 = "vhlo.transpose_v1"(%206) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %208 = "vhlo.dot_general_v2"(%191, %207) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %209 = "vhlo.reshape_v1"(%208) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %210 = "vhlo.convert_v1"(%209) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %211 = "vhlo.multiply_v1"(%203, %210) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %212 = "vhlo.convert_v1"(%211) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %213 = "vhlo.reshape_v1"(%212) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %214 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>
    %215 = "vhlo.custom_call_v1"(%214) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>
    %216 = "vhlo.reshape_v1"(%215) : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %217 = "vhlo.transpose_v1"(%216) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %218 = "vhlo.dot_general_v2"(%213, %217) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %219 = "vhlo.reshape_v1"(%218) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %220 = "vhlo.add_v1"(%171, %219) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %221 = "vhlo.convert_v1"(%220) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %222 = "vhlo.power_v1"(%221, %11) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %223 = "vhlo.reduce_v1"(%222, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %224 = "vhlo.multiply_v1"(%223, %5) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %225 = "vhlo.reshape_v1"(%224) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %226 = "vhlo.add_v1"(%225, %36) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %227 = "vhlo.rsqrt_v2"(%226) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %228 = "vhlo.reshape_v1"(%227) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %229 = "vhlo.broadcast_in_dim_v1"(%228) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %230 = "vhlo.multiply_v1"(%221, %229) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %231 = "vhlo.convert_v1"(%230) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %232 = "vhlo.convert_v1"(%231) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %233 = "vhlo.multiply_v1"(%16, %232) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %234 = "vhlo.convert_v1"(%233) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %235 = "vhlo.reshape_v1"(%234) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %236 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %237 = "vhlo.custom_call_v1"(%236) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___lm_head_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %238 = "vhlo.reshape_v1"(%237) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>
    %239 = "vhlo.transpose_v1"(%238) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,128256]{0,1}">} : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>
    %240 = "vhlo.dot_general_v2"(%235, %239) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>
    %241 = "vhlo.reshape_v1"(%240) : (!vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>
    "vhlo.return_v1"(%241) : (!vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}
// -----// IR Dump Before VhloToVersionPass (vhlo-to-version) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, %arg1: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg2: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg3: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg4: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg5: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg6: !vhlo.tensor_v1<1x7x!vhlo.i64_v1>, %arg7: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, %arg8: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg9: !vhlo.tensor_v1<7x!vhlo.i64_v1>, %arg10: !vhlo.tensor_v1<!vhlo.i64_v1>, %arg11: !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, %arg12: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg13: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg14: !vhlo.tensor_v1<64x!vhlo.f32_v1>, %arg15: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg16: !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, %arg17: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg18: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg19: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg20: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"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tensor<1024xi64>>}> : () -> !vhlo.tensor_v1<1024x!vhlo.i64_v1>
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>>}> : () -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<3.25520843E-4> : tensor<1x7xf32>>}> : () -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<7xi64>>}> : () -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<1> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1>
    %8 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %9 = "vhlo.broadcast_in_dim_v1"(%8) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %10 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %11 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %12 = "vhlo.reshape_v1"(%arg20) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %13 = "vhlo.custom_call_v1"(%12) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_norm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %14 = "vhlo.reshape_v1"(%13) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1>
    %15 = "vhlo.convert_v1"(%14) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %16 = "vhlo.broadcast_in_dim_v1"(%15) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %17 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %18 = "vhlo.custom_call_v1"(%17) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %19 = "vhlo.reshape_v1"(%18) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>
    %20 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %21 = "vhlo.custom_call_v1"(%20) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %22 = "vhlo.reshape_v1"(%21) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %23 = "vhlo.convert_v1"(%22) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.ui32_v1>
    %24 = "vhlo.gather_v2"(%19, %23) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3072]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %25 = "vhlo.reshape_v1"(%24) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %26 = "vhlo.reshape_v1"(%arg8) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %27 = "vhlo.custom_call_v1"(%26) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %28 = "vhlo.reshape_v1"(%27) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1>
    %29 = "vhlo.convert_v1"(%28) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %30 = "vhlo.broadcast_in_dim_v1"(%29) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %31 = "vhlo.convert_v1"(%25) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %32 = "vhlo.power_v1"(%31, %11) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %33 = "vhlo.reduce_v1"(%32, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %34 = "vhlo.multiply_v1"(%33, %5) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %35 = "vhlo.reshape_v1"(%34) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %36 = "vhlo.broadcast_in_dim_v1"(%arg1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %37 = "vhlo.add_v1"(%35, %36) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %38 = "vhlo.rsqrt_v2"(%37) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %39 = "vhlo.reshape_v1"(%38) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %40 = "vhlo.broadcast_in_dim_v1"(%39) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %41 = "vhlo.multiply_v1"(%31, %40) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %42 = "vhlo.convert_v1"(%41) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %43 = "vhlo.convert_v1"(%42) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %44 = "vhlo.multiply_v1"(%30, %43) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %45 = "vhlo.convert_v1"(%44) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %46 = "vhlo.reshape_v1"(%45) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %47 = "vhlo.reshape_v1"(%arg17) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %48 = "vhlo.custom_call_v1"(%47) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %49 = "vhlo.reshape_v1"(%48) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %50 = "vhlo.transpose_v1"(%49) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %51 = "vhlo.dot_general_v2"(%46, %50) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %52 = "vhlo.reshape_v1"(%51) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %53 = "vhlo.transpose_v1"(%52) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %54 = "vhlo.convert_v1"(%53) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %55 = "vhlo.reshape_v1"(%arg14) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %56 = "vhlo.custom_call_v1"(%55) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %57 = "vhlo.reshape_v1"(%56) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %58 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %59 = "vhlo.custom_call_v1"(%58) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %60 = "vhlo.reshape_v1"(%59) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %61 = "vhlo.convert_v1"(%59) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1>
    %62 = "vhlo.dot_general_v2"(%57, %61) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x7x!vhlo.f32_v1>
    %63 = "vhlo.transpose_v1"(%62) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,7,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>
    %64 = "vhlo.concatenate_v1"(%63, %63) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %65 = "vhlo.cosine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %66 = "vhlo.convert_v1"(%65) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %67 = "vhlo.reshape_v1"(%66) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>
    %68 = "vhlo.convert_v1"(%67) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>
    %69 = "vhlo.reshape_v1"(%68) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %70 = "vhlo.broadcast_in_dim_v1"(%69) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %71 = "vhlo.multiply_v1"(%54, %70) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %72 = "vhlo.convert_v1"(%71) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %73 = "vhlo.slice_v1"(%53) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %74 = "vhlo.negate_v1"(%73) : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %75 = "vhlo.slice_v1"(%53) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %76 = "vhlo.concatenate_v1"(%74, %75) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %77 = "vhlo.convert_v1"(%76) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %78 = "vhlo.sine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %79 = "vhlo.convert_v1"(%78) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %80 = "vhlo.reshape_v1"(%79) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>
    %81 = "vhlo.convert_v1"(%80) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>
    %82 = "vhlo.reshape_v1"(%81) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %83 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %84 = "vhlo.multiply_v1"(%77, %83) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %85 = "vhlo.convert_v1"(%84) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %86 = "vhlo.add_v1"(%72, %85) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %87 = "vhlo.reshape_v1"(%86) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %88 = "vhlo.custom_call_v1"(%arg16) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_2">}>} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %89 = "vhlo.compare_v1"(%60, %6) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.bool_v1>
    %90 = "vhlo.broadcast_in_dim_v1"(%arg10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %91 = "vhlo.add_v1"(%60, %90) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %92 = "vhlo.select_v1"(%89, %91, %60) : (!vhlo.tensor_v1<7x!vhlo.bool_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %93 = "vhlo.reshape_v1"(%92) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1x!vhlo.i64_v1>
    %94 = "vhlo.reshape_v1"(%arg15) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %95 = "vhlo.custom_call_v1"(%94) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %96 = "vhlo.reshape_v1"(%95) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>
    %97 = "vhlo.transpose_v1"(%96) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %98 = "vhlo.dot_general_v2"(%46, %97) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %99 = "vhlo.reshape_v1"(%98) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %100 = "vhlo.transpose_v1"(%99) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %101 = "vhlo.convert_v1"(%100) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %102 = "vhlo.broadcast_in_dim_v1"(%69) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %103 = "vhlo.multiply_v1"(%101, %102) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %104 = "vhlo.convert_v1"(%103) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %105 = "vhlo.slice_v1"(%100) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %106 = "vhlo.negate_v1"(%105) : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %107 = "vhlo.slice_v1"(%100) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %108 = "vhlo.concatenate_v1"(%106, %107) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %109 = "vhlo.convert_v1"(%108) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %110 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %111 = "vhlo.multiply_v1"(%109, %110) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %112 = "vhlo.convert_v1"(%111) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %113 = "vhlo.add_v1"(%104, %112) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %114 = "vhlo.scatter_v2"(%88, %93, %113) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %115 = "vhlo.broadcast_in_dim_v1"(%114) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>
    %116 = "vhlo.reshape_v1"(%115) : (!vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1024x128x!vhlo.bf16_v1>
    %117 = "vhlo.transpose_v1"(%116) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,1024]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x1024x!vhlo.bf16_v1>
    %118 = "vhlo.reshape_v1"(%117) : (!vhlo.tensor_v1<1x24x128x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x1024x!vhlo.bf16_v1>
    %119 = "vhlo.dot_general_v2"(%87, %118) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>
    %120 = "vhlo.reshape_v1"(%119) : (!vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %121 = "vhlo.convert_v1"(%120) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %122 = "vhlo.broadcast_in_dim_v1"(%arg13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %123 = "vhlo.multiply_v1"(%121, %122) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %124 = "vhlo.convert_v1"(%123) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %125 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %126 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %127 = "vhlo.subtract_v1"(%125, %126) : (!vhlo.tensor_v1<7x1024x!vhlo.i64_v1>, !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %128 = "vhlo.compare_v1"(%127, %10) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GE>}> : (!vhlo.tensor_v1<7x1024x!vhlo.i64_v1>, !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bool_v1>
    %129 = "vhlo.broadcast_in_dim_v1"(%arg12) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %130 = "vhlo.select_v1"(%128, %129, %9) : (!vhlo.tensor_v1<7x1024x!vhlo.bool_v1>, !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %131 = "vhlo.convert_v1"(%130) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>
    %132 = "vhlo.broadcast_in_dim_v1"(%60) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %133 = "vhlo.compare_v1"(%125, %132) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<7x1024x!vhlo.i64_v1>, !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bool_v1>
    %134 = "vhlo.convert_v1"(%133) : (!vhlo.tensor_v1<7x1024x!vhlo.bool_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>
    %135 = "vhlo.multiply_v1"(%131, %134) : (!vhlo.tensor_v1<7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>
    %136 = "vhlo.convert_v1"(%135) : (!vhlo.tensor_v1<7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %137 = "vhlo.reshape_v1"(%136) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x1024x!vhlo.bf16_v1>
    %138 = "vhlo.broadcast_in_dim_v1"(%137) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %139 = "vhlo.add_v1"(%124, %138) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %140 = "vhlo.convert_v1"(%139) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %141 = "vhlo.reduce_v1"(%140, %3) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.maximum_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %142 = "vhlo.broadcast_in_dim_v1"(%141) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %143 = "vhlo.subtract_v1"(%140, %142) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %144 = "vhlo.exponential_v2"(%143) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %145 = "vhlo.reduce_v1"(%144, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %146 = "vhlo.broadcast_in_dim_v1"(%145) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %147 = "vhlo.divide_v1"(%144, %146) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %148 = "vhlo.convert_v1"(%147) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %149 = "vhlo.reshape_v1"(%148) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>
    %150 = "vhlo.custom_call_v1"(%arg11) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_3">}>} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %151 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %152 = "vhlo.custom_call_v1"(%151) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %153 = "vhlo.reshape_v1"(%152) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>
    %154 = "vhlo.transpose_v1"(%153) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %155 = "vhlo.dot_general_v2"(%46, %154) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %156 = "vhlo.reshape_v1"(%155) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %157 = "vhlo.transpose_v1"(%156) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %158 = "vhlo.scatter_v2"(%150, %93, %157) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %159 = "vhlo.broadcast_in_dim_v1"(%158) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>
    %160 = "vhlo.reshape_v1"(%159) : (!vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1024x128x!vhlo.bf16_v1>
    %161 = "vhlo.dot_general_v2"(%149, %160) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %162 = "vhlo.reshape_v1"(%161) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %163 = "vhlo.transpose_v1"(%162) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,7,24,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %164 = "vhlo.reshape_v1"(%163) : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %165 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %166 = "vhlo.custom_call_v1"(%165) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %167 = "vhlo.reshape_v1"(%166) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %168 = "vhlo.transpose_v1"(%167) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %169 = "vhlo.dot_general_v2"(%164, %168) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %170 = "vhlo.reshape_v1"(%169) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %171 = "vhlo.add_v1"(%25, %170) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %172 = "vhlo.reshape_v1"(%arg18) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %173 = "vhlo.custom_call_v1"(%172) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %174 = "vhlo.reshape_v1"(%173) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1>
    %175 = "vhlo.convert_v1"(%174) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %176 = "vhlo.broadcast_in_dim_v1"(%175) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %177 = "vhlo.convert_v1"(%171) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %178 = "vhlo.power_v1"(%177, %11) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %179 = "vhlo.reduce_v1"(%178, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %180 = "vhlo.multiply_v1"(%179, %5) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %181 = "vhlo.reshape_v1"(%180) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %182 = "vhlo.add_v1"(%181, %36) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %183 = "vhlo.rsqrt_v2"(%182) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %184 = "vhlo.reshape_v1"(%183) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %185 = "vhlo.broadcast_in_dim_v1"(%184) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %186 = "vhlo.multiply_v1"(%177, %185) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %187 = "vhlo.convert_v1"(%186) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %188 = "vhlo.convert_v1"(%187) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %189 = "vhlo.multiply_v1"(%176, %188) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %190 = "vhlo.convert_v1"(%189) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %191 = "vhlo.reshape_v1"(%190) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %192 = "vhlo.reshape_v1"(%arg19) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %193 = "vhlo.custom_call_v1"(%192) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %194 = "vhlo.reshape_v1"(%193) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %195 = "vhlo.transpose_v1"(%194) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %196 = "vhlo.dot_general_v2"(%191, %195) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %197 = "vhlo.reshape_v1"(%196) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %198 = "vhlo.convert_v1"(%197) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %199 = "vhlo.logistic_v2"(%197) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %200 = "vhlo.convert_v1"(%199) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %201 = "vhlo.multiply_v1"(%198, %200) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %202 = "vhlo.convert_v1"(%201) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %203 = "vhlo.convert_v1"(%202) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %204 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %205 = "vhlo.custom_call_v1"(%204) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %206 = "vhlo.reshape_v1"(%205) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %207 = "vhlo.transpose_v1"(%206) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %208 = "vhlo.dot_general_v2"(%191, %207) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %209 = "vhlo.reshape_v1"(%208) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %210 = "vhlo.convert_v1"(%209) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %211 = "vhlo.multiply_v1"(%203, %210) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %212 = "vhlo.convert_v1"(%211) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %213 = "vhlo.reshape_v1"(%212) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %214 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>
    %215 = "vhlo.custom_call_v1"(%214) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>
    %216 = "vhlo.reshape_v1"(%215) : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %217 = "vhlo.transpose_v1"(%216) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %218 = "vhlo.dot_general_v2"(%213, %217) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %219 = "vhlo.reshape_v1"(%218) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %220 = "vhlo.add_v1"(%171, %219) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %221 = "vhlo.convert_v1"(%220) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %222 = "vhlo.power_v1"(%221, %11) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %223 = "vhlo.reduce_v1"(%222, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %224 = "vhlo.multiply_v1"(%223, %5) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %225 = "vhlo.reshape_v1"(%224) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %226 = "vhlo.add_v1"(%225, %36) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %227 = "vhlo.rsqrt_v2"(%226) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %228 = "vhlo.reshape_v1"(%227) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %229 = "vhlo.broadcast_in_dim_v1"(%228) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %230 = "vhlo.multiply_v1"(%221, %229) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %231 = "vhlo.convert_v1"(%230) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %232 = "vhlo.convert_v1"(%231) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %233 = "vhlo.multiply_v1"(%16, %232) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %234 = "vhlo.convert_v1"(%233) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %235 = "vhlo.reshape_v1"(%234) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %236 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %237 = "vhlo.custom_call_v1"(%236) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___lm_head_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %238 = "vhlo.reshape_v1"(%237) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>
    %239 = "vhlo.transpose_v1"(%238) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,128256]{0,1}">} : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>
    %240 = "vhlo.dot_general_v2"(%235, %239) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>
    %241 = "vhlo.reshape_v1"(%240) : (!vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>
    "vhlo.return_v1"(%241) : (!vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump Before VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, %arg1: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg2: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>, %arg3: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg4: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg5: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg6: !vhlo.tensor_v1<1x7x!vhlo.i64_v1>, %arg7: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, %arg8: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg9: !vhlo.tensor_v1<7x!vhlo.i64_v1>, %arg10: !vhlo.tensor_v1<!vhlo.i64_v1>, %arg11: !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, %arg12: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg13: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg14: !vhlo.tensor_v1<64x!vhlo.f32_v1>, %arg15: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>, %arg16: !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, %arg17: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>, %arg18: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>, %arg19: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>, %arg20: !vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> (!vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"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tensor<1024xi64>>}> : () -> !vhlo.tensor_v1<1024x!vhlo.i64_v1>
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>>}> : () -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<3.25520843E-4> : tensor<1x7xf32>>}> : () -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<7xi64>>}> : () -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<1> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1>
    %8 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1>
    %9 = "vhlo.broadcast_in_dim_v1"(%8) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %10 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %11 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %12 = "vhlo.reshape_v1"(%arg20) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %13 = "vhlo.custom_call_v1"(%12) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_norm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %14 = "vhlo.reshape_v1"(%13) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1>
    %15 = "vhlo.convert_v1"(%14) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %16 = "vhlo.broadcast_in_dim_v1"(%15) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %17 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %18 = "vhlo.custom_call_v1"(%17) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %19 = "vhlo.reshape_v1"(%18) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>
    %20 = "vhlo.reshape_v1"(%arg6) : (!vhlo.tensor_v1<1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %21 = "vhlo.custom_call_v1"(%20) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %22 = "vhlo.reshape_v1"(%21) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %23 = "vhlo.convert_v1"(%22) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.ui32_v1>
    %24 = "vhlo.gather_v2"(%19, %23) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3072]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %25 = "vhlo.reshape_v1"(%24) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %26 = "vhlo.reshape_v1"(%arg8) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %27 = "vhlo.custom_call_v1"(%26) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %28 = "vhlo.reshape_v1"(%27) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1>
    %29 = "vhlo.convert_v1"(%28) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %30 = "vhlo.broadcast_in_dim_v1"(%29) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %31 = "vhlo.convert_v1"(%25) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %32 = "vhlo.power_v1"(%31, %11) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %33 = "vhlo.reduce_v1"(%32, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %34 = "vhlo.multiply_v1"(%33, %5) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %35 = "vhlo.reshape_v1"(%34) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %36 = "vhlo.broadcast_in_dim_v1"(%arg1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %37 = "vhlo.add_v1"(%35, %36) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %38 = "vhlo.rsqrt_v2"(%37) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %39 = "vhlo.reshape_v1"(%38) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %40 = "vhlo.broadcast_in_dim_v1"(%39) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %41 = "vhlo.multiply_v1"(%31, %40) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %42 = "vhlo.convert_v1"(%41) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %43 = "vhlo.convert_v1"(%42) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %44 = "vhlo.multiply_v1"(%30, %43) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %45 = "vhlo.convert_v1"(%44) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %46 = "vhlo.reshape_v1"(%45) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %47 = "vhlo.reshape_v1"(%arg17) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %48 = "vhlo.custom_call_v1"(%47) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %49 = "vhlo.reshape_v1"(%48) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %50 = "vhlo.transpose_v1"(%49) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %51 = "vhlo.dot_general_v2"(%46, %50) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %52 = "vhlo.reshape_v1"(%51) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %53 = "vhlo.transpose_v1"(%52) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %54 = "vhlo.convert_v1"(%53) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,24,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %55 = "vhlo.reshape_v1"(%arg14) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %56 = "vhlo.custom_call_v1"(%55) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>
    %57 = "vhlo.reshape_v1"(%56) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>
    %58 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %59 = "vhlo.custom_call_v1"(%58) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>
    %60 = "vhlo.reshape_v1"(%59) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %61 = "vhlo.convert_v1"(%59) : (!vhlo.tensor_v1<1x1x7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1>
    %62 = "vhlo.dot_general_v2"(%57, %61) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x7x!vhlo.f32_v1>
    %63 = "vhlo.transpose_v1"(%62) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,7,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>
    %64 = "vhlo.concatenate_v1"(%63, %63) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %65 = "vhlo.cosine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %66 = "vhlo.convert_v1"(%65) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %67 = "vhlo.reshape_v1"(%66) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>
    %68 = "vhlo.convert_v1"(%67) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>
    %69 = "vhlo.reshape_v1"(%68) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %70 = "vhlo.broadcast_in_dim_v1"(%69) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %71 = "vhlo.multiply_v1"(%54, %70) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %72 = "vhlo.convert_v1"(%71) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %73 = "vhlo.slice_v1"(%53) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %74 = "vhlo.negate_v1"(%73) : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %75 = "vhlo.slice_v1"(%53) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>
    %76 = "vhlo.concatenate_v1"(%74, %75) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %77 = "vhlo.convert_v1"(%76) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %78 = "vhlo.sine_v2"(%64) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %79 = "vhlo.convert_v1"(%78) : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>
    %80 = "vhlo.reshape_v1"(%79) : (!vhlo.tensor_v1<1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>
    %81 = "vhlo.convert_v1"(%80) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>
    %82 = "vhlo.reshape_v1"(%81) : (!vhlo.tensor_v1<1x1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>
    %83 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %84 = "vhlo.multiply_v1"(%77, %83) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>
    %85 = "vhlo.convert_v1"(%84) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %86 = "vhlo.add_v1"(%72, %85) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %87 = "vhlo.reshape_v1"(%86) : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %88 = "vhlo.custom_call_v1"(%arg16) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_2">}>} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %89 = "vhlo.compare_v1"(%60, %6) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.bool_v1>
    %90 = "vhlo.broadcast_in_dim_v1"(%arg10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %91 = "vhlo.add_v1"(%60, %90) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %92 = "vhlo.select_v1"(%89, %91, %60) : (!vhlo.tensor_v1<7x!vhlo.bool_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>, !vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x!vhlo.i64_v1>
    %93 = "vhlo.reshape_v1"(%92) : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1x!vhlo.i64_v1>
    %94 = "vhlo.reshape_v1"(%arg15) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %95 = "vhlo.custom_call_v1"(%94) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %96 = "vhlo.reshape_v1"(%95) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>
    %97 = "vhlo.transpose_v1"(%96) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %98 = "vhlo.dot_general_v2"(%46, %97) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %99 = "vhlo.reshape_v1"(%98) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %100 = "vhlo.transpose_v1"(%99) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %101 = "vhlo.convert_v1"(%100) {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"f32[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %102 = "vhlo.broadcast_in_dim_v1"(%69) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %103 = "vhlo.multiply_v1"(%101, %102) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %104 = "vhlo.convert_v1"(%103) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %105 = "vhlo.slice_v1"(%100) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %106 = "vhlo.negate_v1"(%105) : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %107 = "vhlo.slice_v1"(%100) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 7, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>
    %108 = "vhlo.concatenate_v1"(%106, %107) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %109 = "vhlo.convert_v1"(%108) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %110 = "vhlo.broadcast_in_dim_v1"(%82) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %111 = "vhlo.multiply_v1"(%109, %110) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>
    %112 = "vhlo.convert_v1"(%111) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %113 = "vhlo.add_v1"(%104, %112) : (!vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %114 = "vhlo.scatter_v2"(%88, %93, %113) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %115 = "vhlo.broadcast_in_dim_v1"(%114) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>
    %116 = "vhlo.reshape_v1"(%115) : (!vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1024x128x!vhlo.bf16_v1>
    %117 = "vhlo.transpose_v1"(%116) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,1024]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x1024x!vhlo.bf16_v1>
    %118 = "vhlo.reshape_v1"(%117) : (!vhlo.tensor_v1<1x24x128x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x128x1024x!vhlo.bf16_v1>
    %119 = "vhlo.dot_general_v2"(%87, %118) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x128x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>
    %120 = "vhlo.reshape_v1"(%119) : (!vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %121 = "vhlo.convert_v1"(%120) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %122 = "vhlo.broadcast_in_dim_v1"(%arg13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %123 = "vhlo.multiply_v1"(%121, %122) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %124 = "vhlo.convert_v1"(%123) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %125 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %126 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %127 = "vhlo.subtract_v1"(%125, %126) : (!vhlo.tensor_v1<7x1024x!vhlo.i64_v1>, !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %128 = "vhlo.compare_v1"(%127, %10) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GE>}> : (!vhlo.tensor_v1<7x1024x!vhlo.i64_v1>, !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bool_v1>
    %129 = "vhlo.broadcast_in_dim_v1"(%arg12) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %130 = "vhlo.select_v1"(%128, %129, %9) : (!vhlo.tensor_v1<7x1024x!vhlo.bool_v1>, !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %131 = "vhlo.convert_v1"(%130) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>
    %132 = "vhlo.broadcast_in_dim_v1"(%60) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<7x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>
    %133 = "vhlo.compare_v1"(%125, %132) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<7x1024x!vhlo.i64_v1>, !vhlo.tensor_v1<7x1024x!vhlo.i64_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bool_v1>
    %134 = "vhlo.convert_v1"(%133) : (!vhlo.tensor_v1<7x1024x!vhlo.bool_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>
    %135 = "vhlo.multiply_v1"(%131, %134) : (!vhlo.tensor_v1<7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.f32_v1>
    %136 = "vhlo.convert_v1"(%135) : (!vhlo.tensor_v1<7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %137 = "vhlo.reshape_v1"(%136) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x1024x!vhlo.bf16_v1>
    %138 = "vhlo.broadcast_in_dim_v1"(%137) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %139 = "vhlo.add_v1"(%124, %138) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %140 = "vhlo.convert_v1"(%139) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %141 = "vhlo.reduce_v1"(%140, %3) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.maximum_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %142 = "vhlo.broadcast_in_dim_v1"(%141) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %143 = "vhlo.subtract_v1"(%140, %142) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %144 = "vhlo.exponential_v2"(%143) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %145 = "vhlo.reduce_v1"(%144, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>
    %146 = "vhlo.broadcast_in_dim_v1"(%145) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %147 = "vhlo.divide_v1"(%144, %146) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>
    %148 = "vhlo.convert_v1"(%147) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>
    %149 = "vhlo.reshape_v1"(%148) : (!vhlo.tensor_v1<1x24x7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>
    %150 = "vhlo.custom_call_v1"(%arg11) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_3">}>} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %151 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %152 = "vhlo.custom_call_v1"(%151) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>
    %153 = "vhlo.reshape_v1"(%152) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>
    %154 = "vhlo.transpose_v1"(%153) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>
    %155 = "vhlo.dot_general_v2"(%46, %154) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>
    %156 = "vhlo.reshape_v1"(%155) : (!vhlo.tensor_v1<7x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>
    %157 = "vhlo.transpose_v1"(%156) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,7,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x7x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>
    %158 = "vhlo.scatter_v2"(%150, %93, %157) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.bf16_v1>, %arg22: !vhlo.tensor_v1<!vhlo.bf16_v1>):
      "vhlo.return_v1"(%arg22) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<7x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>
    %159 = "vhlo.broadcast_in_dim_v1"(%158) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>
    %160 = "vhlo.reshape_v1"(%159) : (!vhlo.tensor_v1<1x8x3x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x1024x128x!vhlo.bf16_v1>
    %161 = "vhlo.dot_general_v2"(%149, %160) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<24x7x1024x!vhlo.bf16_v1>, !vhlo.tensor_v1<24x1024x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>
    %162 = "vhlo.reshape_v1"(%161) : (!vhlo.tensor_v1<24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>
    %163 = "vhlo.transpose_v1"(%162) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,7,24,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x7x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>
    %164 = "vhlo.reshape_v1"(%163) : (!vhlo.tensor_v1<1x7x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %165 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %166 = "vhlo.custom_call_v1"(%165) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>
    %167 = "vhlo.reshape_v1"(%166) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %168 = "vhlo.transpose_v1"(%167) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>
    %169 = "vhlo.dot_general_v2"(%164, %168) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %170 = "vhlo.reshape_v1"(%169) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %171 = "vhlo.add_v1"(%25, %170) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %172 = "vhlo.reshape_v1"(%arg18) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %173 = "vhlo.custom_call_v1"(%172) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>
    %174 = "vhlo.reshape_v1"(%173) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1>
    %175 = "vhlo.convert_v1"(%174) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.f32_v1>
    %176 = "vhlo.broadcast_in_dim_v1"(%175) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %177 = "vhlo.convert_v1"(%171) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %178 = "vhlo.power_v1"(%177, %11) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %179 = "vhlo.reduce_v1"(%178, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %180 = "vhlo.multiply_v1"(%179, %5) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %181 = "vhlo.reshape_v1"(%180) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %182 = "vhlo.add_v1"(%181, %36) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %183 = "vhlo.rsqrt_v2"(%182) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %184 = "vhlo.reshape_v1"(%183) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %185 = "vhlo.broadcast_in_dim_v1"(%184) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %186 = "vhlo.multiply_v1"(%177, %185) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %187 = "vhlo.convert_v1"(%186) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %188 = "vhlo.convert_v1"(%187) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %189 = "vhlo.multiply_v1"(%176, %188) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %190 = "vhlo.convert_v1"(%189) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %191 = "vhlo.reshape_v1"(%190) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %192 = "vhlo.reshape_v1"(%arg19) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %193 = "vhlo.custom_call_v1"(%192) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %194 = "vhlo.reshape_v1"(%193) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %195 = "vhlo.transpose_v1"(%194) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %196 = "vhlo.dot_general_v2"(%191, %195) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %197 = "vhlo.reshape_v1"(%196) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %198 = "vhlo.convert_v1"(%197) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %199 = "vhlo.logistic_v2"(%197) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %200 = "vhlo.convert_v1"(%199) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %201 = "vhlo.multiply_v1"(%198, %200) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %202 = "vhlo.convert_v1"(%201) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %203 = "vhlo.convert_v1"(%202) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %204 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %205 = "vhlo.custom_call_v1"(%204) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>
    %206 = "vhlo.reshape_v1"(%205) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %207 = "vhlo.transpose_v1"(%206) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %208 = "vhlo.dot_general_v2"(%191, %207) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %209 = "vhlo.reshape_v1"(%208) : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %210 = "vhlo.convert_v1"(%209) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %211 = "vhlo.multiply_v1"(%203, %210) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>
    %212 = "vhlo.convert_v1"(%211) : (!vhlo.tensor_v1<1x7x8192x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>
    %213 = "vhlo.reshape_v1"(%212) : (!vhlo.tensor_v1<1x7x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>
    %214 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>
    %215 = "vhlo.custom_call_v1"(%214) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>
    %216 = "vhlo.reshape_v1"(%215) : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>
    %217 = "vhlo.transpose_v1"(%216) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>
    %218 = "vhlo.dot_general_v2"(%213, %217) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %219 = "vhlo.reshape_v1"(%218) : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %220 = "vhlo.add_v1"(%171, %219) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %221 = "vhlo.convert_v1"(%220) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %222 = "vhlo.power_v1"(%221, %11) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %223 = "vhlo.reduce_v1"(%222, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg21: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg22: !vhlo.tensor_v1<!vhlo.f32_v1>):
      %242 = "vhlo.add_v1"(%arg21, %arg22) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1>
      "vhlo.return_v1"(%242) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %224 = "vhlo.multiply_v1"(%223, %5) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %225 = "vhlo.reshape_v1"(%224) : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %226 = "vhlo.add_v1"(%225, %36) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %227 = "vhlo.rsqrt_v2"(%226) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>
    %228 = "vhlo.reshape_v1"(%227) : (!vhlo.tensor_v1<1x7x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x!vhlo.f32_v1>
    %229 = "vhlo.broadcast_in_dim_v1"(%228) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x7x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %230 = "vhlo.multiply_v1"(%221, %229) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %231 = "vhlo.convert_v1"(%230) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %232 = "vhlo.convert_v1"(%231) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %233 = "vhlo.multiply_v1"(%16, %232) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>
    %234 = "vhlo.convert_v1"(%233) : (!vhlo.tensor_v1<1x7x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>
    %235 = "vhlo.reshape_v1"(%234) : (!vhlo.tensor_v1<1x7x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>
    %236 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %237 = "vhlo.custom_call_v1"(%236) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___lm_head_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>
    %238 = "vhlo.reshape_v1"(%237) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>
    %239 = "vhlo.transpose_v1"(%238) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,128256]{0,1}">} : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>
    %240 = "vhlo.dot_general_v2"(%235, %239) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<7x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>
    %241 = "vhlo.reshape_v1"(%240) : (!vhlo.tensor_v1<7x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>
    "vhlo.return_v1"(%241) : (!vhlo.tensor_v1<1x7x128256x!vhlo.bf16_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump After VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}, %arg1: tensor<f32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"}, %arg2: tensor<3072x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"}, %arg3: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"}, %arg4: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"}, %arg5: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"}, %arg6: tensor<1x7xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}, %arg7: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}, %arg8: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg9: tensor<7xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg10: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"}, %arg11: tensor<1x8x1024x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"}, %arg12: tensor<bf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"}, %arg13: tensor<f32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"}, %arg14: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg15: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"}, %arg16: tensor<1x8x1024x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"}, %arg17: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"}, %arg18: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg19: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"}, %arg20: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}) -> tensor<1x7x128256xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.custom_call @tt.mark_argument(%3) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_norm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %6 = stablehlo.convert %5 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %7 = stablehlo.broadcast_in_dim %6, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %8 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %9 = stablehlo.custom_call @tt.mark_argument(%8) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_embed_tokens_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %11 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %12 = stablehlo.custom_call @tt.mark_argument(%11) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x1x7xi64>) -> tensor<1x1x7xi64>
    %13 = stablehlo.reshape %12 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %14 = stablehlo.convert %13 : (tensor<7xi64>) -> tensor<7xui32>
    %15 = "stablehlo.gather"(%10, %14) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %16 = stablehlo.reshape %15 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %17 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %18 = stablehlo.custom_call @tt.mark_argument(%17) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %19 = stablehlo.reshape %18 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %20 = stablehlo.convert %19 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %21 = stablehlo.broadcast_in_dim %20, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %22 = stablehlo.convert %16 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %23 = stablehlo.power %22, %2 : tensor<1x7x3072xf32>
    %24 = stablehlo.reduce(%23 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %25 = stablehlo.multiply %24, %cst_3 : tensor<1x7xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %27 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %28 = stablehlo.add %26, %27 : tensor<1x7x1xf32>
    %29 = stablehlo.rsqrt %28 : tensor<1x7x1xf32>
    %30 = stablehlo.reshape %29 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %31 = stablehlo.broadcast_in_dim %30, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %32 = stablehlo.multiply %22, %31 : tensor<1x7x3072xf32>
    %33 = stablehlo.convert %32 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %34 = stablehlo.convert %33 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %35 = stablehlo.multiply %21, %34 : tensor<1x7x3072xf32>
    %36 = stablehlo.convert %35 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %37 = stablehlo.reshape %36 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %39 = stablehlo.custom_call @tt.mark_argument(%38) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %40 = stablehlo.reshape %39 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %41 = stablehlo.transpose %40, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %42 = stablehlo.dot_general %37, %41, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %43 = stablehlo.reshape %42 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %44 = stablehlo.transpose %43, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %45 = stablehlo.convert %44 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %46 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %47 = stablehlo.custom_call @tt.mark_argument(%46) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "l__self___model_rotary_emb_inv_freq"}} : (tensor<1x1x64xf32>) -> tensor<1x1x64xf32>
    %48 = stablehlo.reshape %47 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %49 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %50 = stablehlo.custom_call @tt.mark_argument(%49) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<1x1x7xi64>) -> tensor<1x1x7xi64>
    %51 = stablehlo.reshape %50 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %52 = stablehlo.convert %50 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %53 = stablehlo.dot_general %48, %52, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %54 = stablehlo.transpose %53, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %55 = stablehlo.concatenate %54, %54, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %56 = stablehlo.cosine %55 : tensor<1x7x128xf32>
    %57 = stablehlo.convert %56 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %58 = stablehlo.reshape %57 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16>
    %59 = stablehlo.convert %58 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32>
    %60 = stablehlo.reshape %59 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32>
    %61 = stablehlo.broadcast_in_dim %60, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %62 = stablehlo.multiply %45, %61 : tensor<1x24x7x128xf32>
    %63 = stablehlo.convert %62 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %64 = stablehlo.slice %44 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %65 = stablehlo.negate %64 : tensor<1x24x7x64xbf16>
    %66 = stablehlo.slice %44 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %67 = stablehlo.concatenate %65, %66, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %68 = stablehlo.convert %67 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %69 = stablehlo.sine %55 : tensor<1x7x128xf32>
    %70 = stablehlo.convert %69 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %71 = stablehlo.reshape %70 : (tensor<1x7x128xbf16>) -> tensor<1x1x7x128xbf16>
    %72 = stablehlo.convert %71 : (tensor<1x1x7x128xbf16>) -> tensor<1x1x7x128xf32>
    %73 = stablehlo.reshape %72 : (tensor<1x1x7x128xf32>) -> tensor<1x7x128xf32>
    %74 = stablehlo.broadcast_in_dim %73, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %75 = stablehlo.multiply %68, %74 : tensor<1x24x7x128xf32>
    %76 = stablehlo.convert %75 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %77 = stablehlo.add %63, %76 : tensor<1x24x7x128xbf16>
    %78 = stablehlo.reshape %77 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %79 = stablehlo.custom_call @tt.mark_argument(%arg16) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_2"}} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %80 = stablehlo.compare  LT, %51, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %81 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %82 = stablehlo.add %51, %81 : tensor<7xi64>
    %83 = stablehlo.select %80, %82, %51 : tensor<7xi1>, tensor<7xi64>
    %84 = stablehlo.reshape %83 : (tensor<7xi64>) -> tensor<7x1xi64>
    %85 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %86 = stablehlo.custom_call @tt.mark_argument(%85) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %87 = stablehlo.reshape %86 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %88 = stablehlo.transpose %87, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %89 = stablehlo.dot_general %37, %88, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %90 = stablehlo.reshape %89 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %91 = stablehlo.transpose %90, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %92 = stablehlo.convert %91 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %93 = stablehlo.broadcast_in_dim %60, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %94 = stablehlo.multiply %92, %93 : tensor<1x8x7x128xf32>
    %95 = stablehlo.convert %94 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %96 = stablehlo.slice %91 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %97 = stablehlo.negate %96 : tensor<1x8x7x64xbf16>
    %98 = stablehlo.slice %91 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %99 = stablehlo.concatenate %97, %98, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %100 = stablehlo.convert %99 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %101 = stablehlo.broadcast_in_dim %73, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %102 = stablehlo.multiply %100, %101 : tensor<1x8x7x128xf32>
    %103 = stablehlo.convert %102 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %104 = stablehlo.add %95, %103 : tensor<1x8x7x128xbf16>
    %105 = "stablehlo.scatter"(%79, %84, %104) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %106 = stablehlo.broadcast_in_dim %105, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %107 = stablehlo.reshape %106 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %108 = stablehlo.transpose %107, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %109 = stablehlo.reshape %108 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %110 = stablehlo.dot_general %78, %109, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %111 = stablehlo.reshape %110 : (tensor<24x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %112 = stablehlo.convert %111 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %113 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %114 = stablehlo.multiply %112, %113 : tensor<1x24x7x1024xf32>
    %115 = stablehlo.convert %114 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %117 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %118 = stablehlo.subtract %116, %117 : tensor<7x1024xi64>
    %119 = stablehlo.compare  GE, %118, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %120 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %121 = stablehlo.select %119, %120, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %122 = stablehlo.convert %121 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %123 = stablehlo.broadcast_in_dim %51, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %124 = stablehlo.compare  GT, %116, %123 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %125 = stablehlo.convert %124 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %126 = stablehlo.multiply %122, %125 : tensor<7x1024xf32>
    %127 = stablehlo.convert %126 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %128 = stablehlo.reshape %127 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %129 = stablehlo.broadcast_in_dim %128, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %130 = stablehlo.add %115, %129 : tensor<1x24x7x1024xbf16>
    %131 = stablehlo.convert %130 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %132 = stablehlo.reduce(%131 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %133 = stablehlo.broadcast_in_dim %132, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %134 = stablehlo.subtract %131, %133 : tensor<1x24x7x1024xf32>
    %135 = stablehlo.exponential %134 : tensor<1x24x7x1024xf32>
    %136 = stablehlo.reduce(%135 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %137 = stablehlo.broadcast_in_dim %136, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %138 = stablehlo.divide %135, %137 : tensor<1x24x7x1024xf32>
    %139 = stablehlo.convert %138 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %140 = stablehlo.reshape %139 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %141 = stablehlo.custom_call @tt.mark_argument(%arg11) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_3"}} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %142 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %143 = stablehlo.custom_call @tt.mark_argument(%142) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %144 = stablehlo.reshape %143 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %145 = stablehlo.transpose %144, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %146 = stablehlo.dot_general %37, %145, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %147 = stablehlo.reshape %146 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %148 = stablehlo.transpose %147, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %149 = "stablehlo.scatter"(%141, %84, %148) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %150 = stablehlo.broadcast_in_dim %149, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %151 = stablehlo.reshape %150 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %152 = stablehlo.dot_general %140, %151, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %153 = stablehlo.reshape %152 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %154 = stablehlo.transpose %153, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %155 = stablehlo.reshape %154 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %156 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %157 = stablehlo.custom_call @tt.mark_argument(%156) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %158 = stablehlo.reshape %157 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %159 = stablehlo.transpose %158, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %160 = stablehlo.dot_general %155, %159, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %161 = stablehlo.reshape %160 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.add %16, %161 : tensor<1x7x3072xbf16>
    %163 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %164 = stablehlo.custom_call @tt.mark_argument(%163) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %166 = stablehlo.convert %165 : (tensor<3072xbf16>) -> tensor<3072xf32>
    %167 = stablehlo.broadcast_in_dim %166, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %168 = stablehlo.convert %162 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %169 = stablehlo.power %168, %2 : tensor<1x7x3072xf32>
    %170 = stablehlo.reduce(%169 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %171 = stablehlo.multiply %170, %cst_3 : tensor<1x7xf32>
    %172 = stablehlo.reshape %171 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %173 = stablehlo.add %172, %27 : tensor<1x7x1xf32>
    %174 = stablehlo.rsqrt %173 : tensor<1x7x1xf32>
    %175 = stablehlo.reshape %174 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %176 = stablehlo.broadcast_in_dim %175, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %177 = stablehlo.multiply %168, %176 : tensor<1x7x3072xf32>
    %178 = stablehlo.convert %177 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %179 = stablehlo.convert %178 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %180 = stablehlo.multiply %167, %179 : tensor<1x7x3072xf32>
    %181 = stablehlo.convert %180 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %182 = stablehlo.reshape %181 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %183 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %184 = stablehlo.custom_call @tt.mark_argument(%183) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %186 = stablehlo.transpose %185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %187 = stablehlo.dot_general %182, %186, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %188 = stablehlo.reshape %187 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %189 = stablehlo.convert %188 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %190 = stablehlo.logistic %188 : tensor<1x7x8192xbf16>
    %191 = stablehlo.convert %190 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %192 = stablehlo.multiply %189, %191 : tensor<1x7x8192xf32>
    %193 = stablehlo.convert %192 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %194 = stablehlo.convert %193 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %195 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %196 = stablehlo.custom_call @tt.mark_argument(%195) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %197 = stablehlo.reshape %196 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %198 = stablehlo.transpose %197, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %199 = stablehlo.dot_general %182, %198, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %200 = stablehlo.reshape %199 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %201 = stablehlo.convert %200 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %202 = stablehlo.multiply %194, %201 : tensor<1x7x8192xf32>
    %203 = stablehlo.convert %202 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %204 = stablehlo.reshape %203 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %205 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %206 = stablehlo.custom_call @tt.mark_argument(%205) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}} : (tensor<1x3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %207 = stablehlo.reshape %206 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %208 = stablehlo.transpose %207, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %209 = stablehlo.dot_general %204, %208, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %210 = stablehlo.reshape %209 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %211 = stablehlo.add %162, %210 : tensor<1x7x3072xbf16>
    %212 = stablehlo.convert %211 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %213 = stablehlo.power %212, %2 : tensor<1x7x3072xf32>
    %214 = stablehlo.reduce(%213 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %215 = stablehlo.multiply %214, %cst_3 : tensor<1x7xf32>
    %216 = stablehlo.reshape %215 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %217 = stablehlo.add %216, %27 : tensor<1x7x1xf32>
    %218 = stablehlo.rsqrt %217 : tensor<1x7x1xf32>
    %219 = stablehlo.reshape %218 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %220 = stablehlo.broadcast_in_dim %219, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %221 = stablehlo.multiply %212, %220 : tensor<1x7x3072xf32>
    %222 = stablehlo.convert %221 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %223 = stablehlo.convert %222 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %224 = stablehlo.multiply %7, %223 : tensor<1x7x3072xf32>
    %225 = stablehlo.convert %224 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %226 = stablehlo.reshape %225 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %227 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %228 = stablehlo.custom_call @tt.mark_argument(%227) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___lm_head_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %229 = stablehlo.reshape %228 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %230 = stablehlo.transpose %229, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %231 = stablehlo.dot_general %226, %230, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %232 = stablehlo.reshape %231 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %232 : tensor<1x7x128256xbf16>
  }
}


2025-09-09 19:22:20.114 (   8.830s) [        56CD8000]      module_builder.cc:185      1| Is using shardy? true
2025-09-09 19:22:20.118 (   8.834s) [        56CD8000]      module_builder.cc:203      1| SHLO Module:
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>}) -> tensor<1x7x128256xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.custom_call @tt.mark_argument(%3) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_norm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %5 = stablehlo.convert %4 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %6 = stablehlo.reshape %5 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %7 = stablehlo.broadcast_in_dim %6, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %8 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %9 = stablehlo.custom_call @tt.mark_argument(%8) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_embed_tokens_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %10 = stablehlo.reshape %9 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %11 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %12 = stablehlo.custom_call @tt.mark_argument(%11) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x1x7xi64>) -> tensor<1x1x7xi64>
    %13 = stablehlo.convert %12 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %14 = stablehlo.reshape %13 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %15 = "stablehlo.gather"(%10, %14) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %16 = stablehlo.reshape %15 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %17 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %18 = stablehlo.custom_call @tt.mark_argument(%17) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %19 = stablehlo.convert %18 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %20 = stablehlo.reshape %19 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %21 = stablehlo.broadcast_in_dim %20, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %22 = stablehlo.convert %16 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %23 = stablehlo.power %22, %2 : tensor<1x7x3072xf32>
    %24 = stablehlo.reduce(%23 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %25 = stablehlo.multiply %24, %cst_3 : tensor<1x7xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %27 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %28 = stablehlo.add %26, %27 : tensor<1x7x1xf32>
    %29 = stablehlo.rsqrt %28 : tensor<1x7x1xf32>
    %30 = stablehlo.reshape %29 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %31 = stablehlo.broadcast_in_dim %30, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %32 = stablehlo.multiply %22, %31 : tensor<1x7x3072xf32>
    %33 = stablehlo.convert %32 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %34 = stablehlo.convert %33 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %35 = stablehlo.multiply %21, %34 : tensor<1x7x3072xf32>
    %36 = stablehlo.convert %35 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %37 = stablehlo.reshape %36 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %39 = stablehlo.custom_call @tt.mark_argument(%38) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %40 = stablehlo.reshape %39 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %41 = stablehlo.transpose %40, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %42 = stablehlo.dot_general %37, %41, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %43 = stablehlo.reshape %42 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %44 = stablehlo.transpose %43, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %45 = stablehlo.convert %44 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %46 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %47 = stablehlo.custom_call @tt.mark_argument(%46) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "l__self___model_rotary_emb_inv_freq"}} : (tensor<1x1x64xf32>) -> tensor<1x1x64xf32>
    %48 = stablehlo.reshape %47 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %49 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %50 = stablehlo.custom_call @tt.mark_argument(%49) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<1x1x7xi64>) -> tensor<1x1x7xi64>
    %51 = stablehlo.reshape %50 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %52 = stablehlo.convert %50 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %53 = stablehlo.dot_general %48, %52, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %54 = stablehlo.transpose %53, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %55 = stablehlo.concatenate %54, %54, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %56 = stablehlo.cosine %55 : tensor<1x7x128xf32>
    %57 = stablehlo.convert %56 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %58 = stablehlo.convert %57 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %59 = stablehlo.broadcast_in_dim %58, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.multiply %45, %59 : tensor<1x24x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %62 = stablehlo.slice %44 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %63 = stablehlo.negate %62 : tensor<1x24x7x64xbf16>
    %64 = stablehlo.slice %44 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %65 = stablehlo.concatenate %63, %64, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.convert %65 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %67 = stablehlo.sine %55 : tensor<1x7x128xf32>
    %68 = stablehlo.convert %67 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %69 = stablehlo.convert %68 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %70 = stablehlo.broadcast_in_dim %69, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %71 = stablehlo.multiply %66, %70 : tensor<1x24x7x128xf32>
    %72 = stablehlo.convert %71 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %73 = stablehlo.add %61, %72 : tensor<1x24x7x128xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %75 = stablehlo.custom_call @tt.mark_argument(%arg16) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_2"}} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %76 = stablehlo.compare  LT, %51, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %77 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %78 = stablehlo.add %51, %77 : tensor<7xi64>
    %79 = stablehlo.select %76, %78, %51 : tensor<7xi1>, tensor<7xi64>
    %80 = stablehlo.reshape %79 : (tensor<7xi64>) -> tensor<7x1xi64>
    %81 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %82 = stablehlo.custom_call @tt.mark_argument(%81) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %83 = stablehlo.reshape %82 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %84 = stablehlo.transpose %83, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %85 = stablehlo.dot_general %37, %84, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %86 = stablehlo.reshape %85 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %87 = stablehlo.transpose %86, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %88 = stablehlo.convert %87 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.broadcast_in_dim %58, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %90 = stablehlo.multiply %88, %89 : tensor<1x8x7x128xf32>
    %91 = stablehlo.convert %90 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %92 = stablehlo.slice %87 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %93 = stablehlo.negate %92 : tensor<1x8x7x64xbf16>
    %94 = stablehlo.slice %87 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %95 = stablehlo.concatenate %93, %94, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %96 = stablehlo.convert %95 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %97 = stablehlo.broadcast_in_dim %69, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %98 = stablehlo.multiply %96, %97 : tensor<1x8x7x128xf32>
    %99 = stablehlo.convert %98 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %100 = stablehlo.add %91, %99 : tensor<1x8x7x128xbf16>
    %101 = "stablehlo.scatter"(%75, %80, %100) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %102 = stablehlo.broadcast_in_dim %101, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %103 = stablehlo.reshape %102 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %104 = stablehlo.transpose %103, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %105 = stablehlo.reshape %104 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %106 = stablehlo.dot_general %74, %105, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %107 = stablehlo.convert %106 : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %108 = stablehlo.reshape %107 : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %109 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %110 = stablehlo.multiply %108, %109 : tensor<1x24x7x1024xf32>
    %111 = stablehlo.convert %110 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %112 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %113 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %114 = stablehlo.subtract %112, %113 : tensor<7x1024xi64>
    %115 = stablehlo.compare  GE, %114, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %116 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %117 = stablehlo.select %115, %116, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %118 = stablehlo.convert %117 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %119 = stablehlo.broadcast_in_dim %51, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %120 = stablehlo.compare  GT, %112, %119 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %121 = stablehlo.convert %120 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %122 = stablehlo.multiply %118, %121 : tensor<7x1024xf32>
    %123 = stablehlo.convert %122 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %124 = stablehlo.reshape %123 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %126 = stablehlo.add %111, %125 : tensor<1x24x7x1024xbf16>
    %127 = stablehlo.convert %126 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %128 = stablehlo.reduce(%127 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %129 = stablehlo.broadcast_in_dim %128, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %130 = stablehlo.subtract %127, %129 : tensor<1x24x7x1024xf32>
    %131 = stablehlo.exponential %130 : tensor<1x24x7x1024xf32>
    %132 = stablehlo.reduce(%131 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %133 = stablehlo.broadcast_in_dim %132, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %134 = stablehlo.divide %131, %133 : tensor<1x24x7x1024xf32>
    %135 = stablehlo.convert %134 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %137 = stablehlo.custom_call @tt.mark_argument(%arg11) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_3"}} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %138 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %139 = stablehlo.custom_call @tt.mark_argument(%138) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %140 = stablehlo.reshape %139 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %141 = stablehlo.transpose %140, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %142 = stablehlo.dot_general %37, %141, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %143 = stablehlo.reshape %142 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %144 = stablehlo.transpose %143, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %145 = "stablehlo.scatter"(%137, %80, %144) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %146 = stablehlo.broadcast_in_dim %145, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %147 = stablehlo.reshape %146 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %148 = stablehlo.dot_general %136, %147, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %149 = stablehlo.reshape %148 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %150 = stablehlo.transpose %149, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %151 = stablehlo.reshape %150 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %152 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %153 = stablehlo.custom_call @tt.mark_argument(%152) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %154 = stablehlo.reshape %153 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %155 = stablehlo.transpose %154, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %156 = stablehlo.dot_general %151, %155, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %157 = stablehlo.reshape %156 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %158 = stablehlo.add %16, %157 : tensor<1x7x3072xbf16>
    %159 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %160 = stablehlo.custom_call @tt.mark_argument(%159) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16>
    %161 = stablehlo.convert %160 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %162 = stablehlo.reshape %161 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %163 = stablehlo.broadcast_in_dim %162, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %164 = stablehlo.convert %158 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %165 = stablehlo.power %164, %2 : tensor<1x7x3072xf32>
    %166 = stablehlo.reduce(%165 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %167 = stablehlo.multiply %166, %cst_3 : tensor<1x7xf32>
    %168 = stablehlo.reshape %167 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %169 = stablehlo.add %168, %27 : tensor<1x7x1xf32>
    %170 = stablehlo.rsqrt %169 : tensor<1x7x1xf32>
    %171 = stablehlo.reshape %170 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %172 = stablehlo.broadcast_in_dim %171, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %173 = stablehlo.multiply %164, %172 : tensor<1x7x3072xf32>
    %174 = stablehlo.convert %173 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %175 = stablehlo.convert %174 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %176 = stablehlo.multiply %163, %175 : tensor<1x7x3072xf32>
    %177 = stablehlo.convert %176 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %178 = stablehlo.reshape %177 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %179 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %180 = stablehlo.custom_call @tt.mark_argument(%179) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %181 = stablehlo.reshape %180 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %182 = stablehlo.transpose %181, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %183 = stablehlo.dot_general %178, %182, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %184 = stablehlo.reshape %183 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.convert %184 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %186 = stablehlo.logistic %184 : tensor<1x7x8192xbf16>
    %187 = stablehlo.convert %186 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %188 = stablehlo.multiply %185, %187 : tensor<1x7x8192xf32>
    %189 = stablehlo.convert %188 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %190 = stablehlo.convert %189 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %191 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %192 = stablehlo.custom_call @tt.mark_argument(%191) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %193 = stablehlo.reshape %192 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %194 = stablehlo.transpose %193, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %195 = stablehlo.dot_general %178, %194, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %196 = stablehlo.convert %195 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %197 = stablehlo.reshape %196 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %198 = stablehlo.multiply %190, %197 : tensor<1x7x8192xf32>
    %199 = stablehlo.convert %198 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %200 = stablehlo.reshape %199 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %201 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %202 = stablehlo.custom_call @tt.mark_argument(%201) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}} : (tensor<1x3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %203 = stablehlo.reshape %202 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %204 = stablehlo.transpose %203, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %205 = stablehlo.dot_general %200, %204, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %207 = stablehlo.add %158, %206 : tensor<1x7x3072xbf16>
    %208 = stablehlo.convert %207 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %209 = stablehlo.power %208, %2 : tensor<1x7x3072xf32>
    %210 = stablehlo.reduce(%209 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %211 = stablehlo.multiply %210, %cst_3 : tensor<1x7xf32>
    %212 = stablehlo.reshape %211 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %213 = stablehlo.add %212, %27 : tensor<1x7x1xf32>
    %214 = stablehlo.rsqrt %213 : tensor<1x7x1xf32>
    %215 = stablehlo.reshape %214 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %216 = stablehlo.broadcast_in_dim %215, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %217 = stablehlo.multiply %208, %216 : tensor<1x7x3072xf32>
    %218 = stablehlo.convert %217 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %219 = stablehlo.convert %218 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %220 = stablehlo.multiply %7, %219 : tensor<1x7x3072xf32>
    %221 = stablehlo.convert %220 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %222 = stablehlo.reshape %221 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %223 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %224 = stablehlo.custom_call @tt.mark_argument(%223) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___lm_head_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %225 = stablehlo.reshape %224 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %226 = stablehlo.transpose %225, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %227 = stablehlo.dot_general %222, %226, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %228 = stablehlo.reshape %227 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %228 : tensor<1x7x128256xbf16>
  }
}
2025-09-09 19:22:20.124 (   8.840s) [        56CD8000]      module_builder.cc:212      1| SHLO Module after frontend StableHLO pipeline:
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"}) -> tensor<1x7x128256xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"0x00000000000000000100000000000000020000000000000003000000000000000400000000000000050000000000000006000000000000000700000000000000080000000000000009000000000000000A000000000000000B000000000000000C000000000000000D000000000000000E000000000000000F0000000000000010000000000000001100000000000000120000000000000013000000000000001400000000000000150000000000000016000000000000001700000000000000180000000000000019000000000000001A000000000000001B000000000000001C000000000000001D000000000000001E000000000000001F0000000000000020000000000000002100000000000000220000000000000023000000000000002400000000000000250000000000000026000000000000002700000000000000280000000000000029000000000000002A000000000000002B000000000000002C000000000000002D000000000000002E000000000000002F0000000000000030000000000000003100000000000000320000000000000033000000000000003400000000000000350000000000000036000000000000003700000000000000380000000000000039000000000000003A000000000000003B000000000000003C000000000000003D000000000000003E000000000000003F0000000000000040000000000000004100000000000000420000000000000043000000000000004400000000000000450000000000000046000000000000004700000000000000480000000000000049000000000000004A000000000000004B000000000000004C000000000000004D000000000000004E000000000000004F0000000000000050000000000000005100000000000000520000000000000053000000000000005400000000000000550000000000000056000000000000005700000000000000580000000000000059000000000000005A000000000000005B000000000000005C000000000000005D000000000000005E000000000000005F0000000000000060000000000000006100000000000000620000000000000063000000000000006400000000000000650000000000000066000000000000006700000000000000680000000000000069000000000000006A000000000000006B000000000000006C000000000000006D000000000000006E000000000000006F0000000000000070000000000000007100000000000000720000000000000073000000000000007400000000000000750000000000000076000000000000007700000000000000780000000000000079000000000000007A000000000000007B000000000000007C000000000000007D000000000000007E000000000000007F0000000000000080000000000000008100000000000000820000000000000083000000000000008400000000000000850000000000000086000000000000008700000000000000880000000000000089000000000000008A000000000000008B000000000000008C000000000000008D000000000000008E000000000000008F0000000000000090000000000000009100000000000000920000000000000093000000000000009400000000000000950000000000000096000000000000009700000000000000980000000000000099000000000000009A000000000000009B000000000000009C000000000000009D000000000000009E000000000000009F00000000000000A000000000000000A100000000000000A200000000000000A300000000000000A400000000000000A500000000000000A600000000000000A700000000000000A800000000000000A900000000000000AA00000000000000AB00000000000000AC00000000000000AD00000000000000AE00000000000000AF00000000000000B000000000000000B100000000000000B200000000000000B300000000000000B400000000000000B500000000000000B600000000000000B700000000000000B800000000000000B900000000000000BA00000000000000BB00000000000000BC00000000000000BD00000000000000BE00000000000000BF00000000000000C000000000000000C100000000000000C200000000000000C300000000000000C400000000000000C500000000000000C600000000000000C700000000000000C800000000000000C900000000000000CA00000000000000CB00000000000000CC00000000000000CD00000000000000CE00000000000000CF00000000000000D000000000000000D100000000000000D200000000000000D300000000000000D400000000000000D500000000000000D600000000000000D700000000000000D800000000000000D900000000000000DA00000000000000DB00000000000000DC00000000000000DD00000000000000DE00000000000000DF00000000000000E000000000000000E100000000000000E200000000000000E300000000000000E400000000000000E500000000000000E600000000000000E700000000000000E800000000000000E900000000000000EA00000000000000EB00000000000000EC00000000000000ED00000000000000EE00000000000000EF00000000000000F000000000000000F100000000000000F200000000000000F300000000000000F400000000000000F500000000000000F600000000000000F700000000000000F800000000000000F900000000000000FA00000000000000FB00000000000000FC00000000000000FD00000000000000FE00000000000000FF0000000000000000010000000000000101000000000000020100000000000003010000000000000401000000000000050100000000000006010000000000000701000000000000080100000000000009010000000000000A010000000000000B010000000000000C010000000000000D010000000000000E010000000000000F0100000000000010010000000000001101000000000000120100000000000013010000000000001401000000000000150100000000000016010000000000001701000000000000180100000000000019010000000000001A010000000000001B010000000000001C010000000000001D010000000000001E010000000000001F0100000000000020010000000000002101000000000000220100000000000023010000000000002401000000000000250100000000000026010000000000002701000000000000280100000000000029010000000000002A010000000000002B010000000000002C010000000000002D010000000000002E010000000000002F0100000000000030010000000000003101000000000000320100000000000033010000000000003401000000000000350100000000000036010000000000003701000000000000380100000000000039010000000000003A010000000000003B010000000000003C010000000000003D010000000000003E010000000000003F0100000000000040010000000000004101000000000000420100000000000043010000000000004401000000000000450100000000000046010000000000004701000000000000480100000000000049010000000000004A010000000000004B010000000000004C010000000000004D010000000000004E010000000000004F0100000000000050010000000000005101000000000000520100000000000053010000000000005401000000000000550100000000000056010000000000005701000000000000580100000000000059010000000000005A010000000000005B010000000000005C010000000000005D010000000000005E010000000000005F0100000000000060010000000000006101000000000000620100000000000063010000000000006401000000000000650100000000000066010000000000006701000000000000680100000000000069010000000000006A010000000000006B010000000000006C010000000000006D010000000000006E010000000000006F0100000000000070010000000000007101000000000000720100000000000073010000000000007401000000000000750100000000000076010000000000007701000000000000780100000000000079010000000000007A010000000000007B010000000000007C010000000000007D010000000000007E010000000000007F0100000000000080010000000000008101000000000000820100000000000083010000000000008401000000000000850100000000000086010000000000008701000000000000880100000000000089010000000000008A010000000000008B010000000000008C010000000000008D010000000000008E010000000000008F0100000000000090010000000000009101000000000000920100000000000093010000000000009401000000000000950100000000000096010000000000009701000000000000980100000000000099010000000000009A010000000000009B010000000000009C010000000000009D010000000000009E010000000000009F01000000000000A001000000000000A101000000000000A201000000000000A301000000000000A401000000000000A501000000000000A601000000000000A701000000000000A801000000000000A901000000000000AA01000000000000AB01000000000000AC01000000000000AD01000000000000AE01000000000000AF01000000000000B001000000000000B101000000000000B201000000000000B301000000000000B401000000000000B501000000000000B601000000000000B701000000000000B801000000000000B901000000000000BA01000000000000BB01000000000000BC01000000000000BD01000000000000BE01000000000000BF01000000000000C001000000000000C101000000000000C201000000000000C301000000000000C401000000000000C501000000000000C601000000000000C701000000000000C801000000000000C901000000000000CA01000000000000CB01000000000000CC01000000000000CD01000000000000CE01000000000000CF01000000000000D001000000000000D101000000000000D201000000000000D301000000000000D401000000000000D501000000000000D601000000000000D701000000000000D801000000000000D901000000000000DA01000000000000DB01000000000000DC01000000000000DD01000000000000DE01000000000000DF01000000000000E001000000000000E101000000000000E201000000000000E301000000000000E401000000000000E501000000000000E601000000000000E701000000000000E801000000000000E901000000000000EA01000000000000EB01000000000000EC01000000000000ED01000000000000EE01000000000000EF01000000000000F001000000000000F101000000000000F201000000000000F301000000000000F401000000000000F501000000000000F601000000000000F701000000000000F801000000000000F901000000000000FA01000000000000FB01000000000000FC01000000000000FD01000000000000FE01000000000000FF0100000000000000020000000000000102000000000000020200000000000003020000000000000402000000000000050200000000000006020000000000000702000000000000080200000000000009020000000000000A020000000000000B020000000000000C020000000000000D020000000000000E020000000000000F0200000000000010020000000000001102000000000000120200000000000013020000000000001402000000000000150200000000000016020000000000001702000000000000180200000000000019020000000000001A020000000000001B020000000000001C020000000000001D020000000000001E020000000000001F0200000000000020020000000000002102000000000000220200000000000023020000000000002402000000000000250200000000000026020000000000002702000000000000280200000000000029020000000000002A020000000000002B020000000000002C020000000000002D020000000000002E020000000000002F0200000000000030020000000000003102000000000000320200000000000033020000000000003402000000000000350200000000000036020000000000003702000000000000380200000000000039020000000000003A020000000000003B020000000000003C020000000000003D020000000000003E020000000000003F0200000000000040020000000000004102000000000000420200000000000043020000000000004402000000000000450200000000000046020000000000004702000000000000480200000000000049020000000000004A020000000000004B020000000000004C020000000000004D020000000000004E020000000000004F0200000000000050020000000000005102000000000000520200000000000053020000000000005402000000000000550200000000000056020000000000005702000000000000580200000000000059020000000000005A020000000000005B020000000000005C020000000000005D020000000000005E020000000000005F0200000000000060020000000000006102000000000000620200000000000063020000000000006402000000000000650200000000000066020000000000006702000000000000680200000000000069020000000000006A020000000000006B020000000000006C020000000000006D020000000000006E020000000000006F0200000000000070020000000000007102000000000000720200000000000073020000000000007402000000000000750200000000000076020000000000007702000000000000780200000000000079020000000000007A020000000000007B020000000000007C020000000000007D020000000000007E020000000000007F0200000000000080020000000000008102000000000000820200000000000083020000000000008402000000000000850200000000000086020000000000008702000000000000880200000000000089020000000000008A020000000000008B020000000000008C020000000000008D020000000000008E020000000000008F0200000000000090020000000000009102000000000000920200000000000093020000000000009402000000000000950200000000000096020000000000009702000000000000980200000000000099020000000000009A020000000000009B020000000000009C020000000000009D020000000000009E020000000000009F02000000000000A002000000000000A102000000000000A202000000000000A302000000000000A402000000000000A502000000000000A602000000000000A702000000000000A802000000000000A902000000000000AA02000000000000AB02000000000000AC02000000000000AD02000000000000AE02000000000000AF02000000000000B002000000000000B102000000000000B202000000000000B302000000000000B402000000000000B502000000000000B602000000000000B702000000000000B802000000000000B902000000000000BA02000000000000BB02000000000000BC02000000000000BD02000000000000BE02000000000000BF02000000000000C002000000000000C102000000000000C202000000000000C302000000000000C402000000000000C502000000000000C602000000000000C702000000000000C802000000000000C902000000000000CA02000000000000CB02000000000000CC02000000000000CD02000000000000CE02000000000000CF02000000000000D002000000000000D102000000000000D202000000000000D302000000000000D402000000000000D502000000000000D602000000000000D702000000000000D802000000000000D902000000000000DA02000000000000DB02000000000000DC02000000000000DD02000000000000DE02000000000000DF02000000000000E002000000000000E102000000000000E202000000000000E302000000000000E402000000000000E502000000000000E602000000000000E702000000000000E802000000000000E902000000000000EA02000000000000EB02000000000000EC02000000000000ED02000000000000EE02000000000000EF02000000000000F002000000000000F102000000000000F202000000000000F302000000000000F402000000000000F502000000000000F602000000000000F702000000000000F802000000000000F902000000000000FA02000000000000FB02000000000000FC02000000000000FD02000000000000FE02000000000000FF0200000000000000030000000000000103000000000000020300000000000003030000000000000403000000000000050300000000000006030000000000000703000000000000080300000000000009030000000000000A030000000000000B030000000000000C030000000000000D030000000000000E030000000000000F0300000000000010030000000000001103000000000000120300000000000013030000000000001403000000000000150300000000000016030000000000001703000000000000180300000000000019030000000000001A030000000000001B030000000000001C030000000000001D030000000000001E030000000000001F0300000000000020030000000000002103000000000000220300000000000023030000000000002403000000000000250300000000000026030000000000002703000000000000280300000000000029030000000000002A030000000000002B030000000000002C030000000000002D030000000000002E030000000000002F0300000000000030030000000000003103000000000000320300000000000033030000000000003403000000000000350300000000000036030000000000003703000000000000380300000000000039030000000000003A030000000000003B030000000000003C030000000000003D030000000000003E030000000000003F0300000000000040030000000000004103000000000000420300000000000043030000000000004403000000000000450300000000000046030000000000004703000000000000480300000000000049030000000000004A030000000000004B030000000000004C030000000000004D030000000000004E030000000000004F0300000000000050030000000000005103000000000000520300000000000053030000000000005403000000000000550300000000000056030000000000005703000000000000580300000000000059030000000000005A030000000000005B030000000000005C030000000000005D030000000000005E030000000000005F0300000000000060030000000000006103000000000000620300000000000063030000000000006403000000000000650300000000000066030000000000006703000000000000680300000000000069030000000000006A030000000000006B030000000000006C030000000000006D030000000000006E030000000000006F0300000000000070030000000000007103000000000000720300000000000073030000000000007403000000000000750300000000000076030000000000007703000000000000780300000000000079030000000000007A030000000000007B030000000000007C030000000000007D030000000000007E030000000000007F0300000000000080030000000000008103000000000000820300000000000083030000000000008403000000000000850300000000000086030000000000008703000000000000880300000000000089030000000000008A030000000000008B030000000000008C030000000000008D030000000000008E030000000000008F0300000000000090030000000000009103000000000000920300000000000093030000000000009403000000000000950300000000000096030000000000009703000000000000980300000000000099030000000000009A030000000000009B030000000000009C030000000000009D030000000000009E030000000000009F03000000000000A003000000000000A103000000000000A203000000000000A303000000000000A403000000000000A503000000000000A603000000000000A703000000000000A803000000000000A903000000000000AA03000000000000AB03000000000000AC03000000000000AD03000000000000AE03000000000000AF03000000000000B003000000000000B103000000000000B203000000000000B303000000000000B403000000000000B503000000000000B603000000000000B703000000000000B803000000000000B903000000000000BA03000000000000BB03000000000000BC03000000000000BD03000000000000BE03000000000000BF03000000000000C003000000000000C103000000000000C203000000000000C303000000000000C403000000000000C503000000000000C603000000000000C703000000000000C803000000000000C903000000000000CA03000000000000CB03000000000000CC03000000000000CD03000000000000CE03000000000000CF03000000000000D003000000000000D103000000000000D203000000000000D303000000000000D403000000000000D503000000000000D603000000000000D703000000000000D803000000000000D903000000000000DA03000000000000DB03000000000000DC03000000000000DD03000000000000DE03000000000000DF03000000000000E003000000000000E103000000000000E203000000000000E303000000000000E403000000000000E503000000000000E603000000000000E703000000000000E803000000000000E903000000000000EA03000000000000EB03000000000000EC03000000000000ED03000000000000EE03000000000000EF03000000000000F003000000000000F103000000000000F203000000000000F303000000000000F403000000000000F503000000000000F603000000000000F703000000000000F803000000000000F903000000000000FA03000000000000FB03000000000000FC03000000000000FD03000000000000FE03000000000000FF03000000000000"> : tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = stablehlo.reshape %144 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %146 = stablehlo.add %13, %145 : tensor<1x7x3072xbf16>
    %147 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %151 = stablehlo.convert %146 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.power %151, %2 : tensor<1x7x3072xf32>
    %153 = stablehlo.reduce(%152 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %154 = stablehlo.multiply %153, %cst_3 : tensor<1x7xf32>
    %155 = stablehlo.reshape %154 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %156 = stablehlo.add %155, %23 : tensor<1x7x1xf32>
    %157 = stablehlo.rsqrt %156 : tensor<1x7x1xf32>
    %158 = stablehlo.reshape %157 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %159 = stablehlo.broadcast_in_dim %158, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %160 = stablehlo.multiply %151, %159 : tensor<1x7x3072xf32>
    %161 = stablehlo.convert %160 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.multiply %150, %162 : tensor<1x7x3072xf32>
    %164 = stablehlo.convert %163 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %166 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %167 = stablehlo.reshape %166 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %170 = stablehlo.reshape %169 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %171 = stablehlo.convert %170 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %172 = stablehlo.logistic %170 : tensor<1x7x8192xbf16>
    %173 = stablehlo.convert %172 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %174 = stablehlo.multiply %171, %173 : tensor<1x7x8192xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %176 = stablehlo.convert %175 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %177 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %178 = stablehlo.reshape %177 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %180 = stablehlo.dot_general %165, %179, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %181 = stablehlo.convert %180 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %182 = stablehlo.reshape %181 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %183 = stablehlo.multiply %176, %182 : tensor<1x7x8192xf32>
    %184 = stablehlo.convert %183 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %186 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %187 = stablehlo.reshape %186 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %190 = stablehlo.reshape %189 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %191 = stablehlo.add %146, %190 : tensor<1x7x3072xbf16>
    %192 = stablehlo.convert %191 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %193 = stablehlo.power %192, %2 : tensor<1x7x3072xf32>
    %194 = stablehlo.reduce(%193 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %195 = stablehlo.multiply %194, %cst_3 : tensor<1x7xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %197 = stablehlo.add %196, %23 : tensor<1x7x1xf32>
    %198 = stablehlo.rsqrt %197 : tensor<1x7x1xf32>
    %199 = stablehlo.reshape %198 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %200 = stablehlo.broadcast_in_dim %199, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %201 = stablehlo.multiply %192, %200 : tensor<1x7x3072xf32>
    %202 = stablehlo.convert %201 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %204 = stablehlo.multiply %6, %203 : tensor<1x7x3072xf32>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %210 = stablehlo.dot_general %206, %209, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %211 = stablehlo.reshape %210 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %211 : tensor<1x7x128256xbf16>
  }
}
// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"}) -> tensor<1x7x128256xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = stablehlo.reshape %144 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %146 = stablehlo.add %13, %145 : tensor<1x7x3072xbf16>
    %147 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %151 = stablehlo.convert %146 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.power %151, %2 : tensor<1x7x3072xf32>
    %153 = stablehlo.reduce(%152 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %154 = stablehlo.multiply %153, %cst_3 : tensor<1x7xf32>
    %155 = stablehlo.reshape %154 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %156 = stablehlo.add %155, %23 : tensor<1x7x1xf32>
    %157 = stablehlo.rsqrt %156 : tensor<1x7x1xf32>
    %158 = stablehlo.reshape %157 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %159 = stablehlo.broadcast_in_dim %158, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %160 = stablehlo.multiply %151, %159 : tensor<1x7x3072xf32>
    %161 = stablehlo.convert %160 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.multiply %150, %162 : tensor<1x7x3072xf32>
    %164 = stablehlo.convert %163 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %166 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %167 = stablehlo.reshape %166 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %170 = stablehlo.reshape %169 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %171 = stablehlo.convert %170 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %172 = stablehlo.logistic %170 : tensor<1x7x8192xbf16>
    %173 = stablehlo.convert %172 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %174 = stablehlo.multiply %171, %173 : tensor<1x7x8192xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %176 = stablehlo.convert %175 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %177 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %178 = stablehlo.reshape %177 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %180 = stablehlo.dot_general %165, %179, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %181 = stablehlo.convert %180 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %182 = stablehlo.reshape %181 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %183 = stablehlo.multiply %176, %182 : tensor<1x7x8192xf32>
    %184 = stablehlo.convert %183 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %186 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %187 = stablehlo.reshape %186 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %190 = stablehlo.reshape %189 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %191 = stablehlo.add %146, %190 : tensor<1x7x3072xbf16>
    %192 = stablehlo.convert %191 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %193 = stablehlo.power %192, %2 : tensor<1x7x3072xf32>
    %194 = stablehlo.reduce(%193 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %195 = stablehlo.multiply %194, %cst_3 : tensor<1x7xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %197 = stablehlo.add %196, %23 : tensor<1x7x1xf32>
    %198 = stablehlo.rsqrt %197 : tensor<1x7x1xf32>
    %199 = stablehlo.reshape %198 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %200 = stablehlo.broadcast_in_dim %199, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %201 = stablehlo.multiply %192, %200 : tensor<1x7x3072xf32>
    %202 = stablehlo.convert %201 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %204 = stablehlo.multiply %6, %203 : tensor<1x7x3072xf32>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %210 = stablehlo.dot_general %206, %209, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %211 = stablehlo.reshape %210 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %211 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"}) -> tensor<1x7x128256xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = stablehlo.reshape %144 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %146 = stablehlo.add %13, %145 : tensor<1x7x3072xbf16>
    %147 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %151 = stablehlo.convert %146 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.power %151, %2 : tensor<1x7x3072xf32>
    %153 = stablehlo.reduce(%152 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %154 = stablehlo.multiply %153, %cst_3 : tensor<1x7xf32>
    %155 = stablehlo.reshape %154 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %156 = stablehlo.add %155, %23 : tensor<1x7x1xf32>
    %157 = stablehlo.rsqrt %156 : tensor<1x7x1xf32>
    %158 = stablehlo.reshape %157 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %159 = stablehlo.broadcast_in_dim %158, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %160 = stablehlo.multiply %151, %159 : tensor<1x7x3072xf32>
    %161 = stablehlo.convert %160 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.multiply %150, %162 : tensor<1x7x3072xf32>
    %164 = stablehlo.convert %163 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %166 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %167 = stablehlo.reshape %166 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %170 = stablehlo.reshape %169 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %171 = stablehlo.convert %170 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %172 = stablehlo.logistic %170 : tensor<1x7x8192xbf16>
    %173 = stablehlo.convert %172 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %174 = stablehlo.multiply %171, %173 : tensor<1x7x8192xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %176 = stablehlo.convert %175 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %177 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %178 = stablehlo.reshape %177 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %180 = stablehlo.dot_general %165, %179, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %181 = stablehlo.convert %180 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %182 = stablehlo.reshape %181 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %183 = stablehlo.multiply %176, %182 : tensor<1x7x8192xf32>
    %184 = stablehlo.convert %183 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %186 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %187 = stablehlo.reshape %186 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %190 = stablehlo.reshape %189 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %191 = stablehlo.add %146, %190 : tensor<1x7x3072xbf16>
    %192 = stablehlo.convert %191 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %193 = stablehlo.power %192, %2 : tensor<1x7x3072xf32>
    %194 = stablehlo.reduce(%193 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %195 = stablehlo.multiply %194, %cst_3 : tensor<1x7xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %197 = stablehlo.add %196, %23 : tensor<1x7x1xf32>
    %198 = stablehlo.rsqrt %197 : tensor<1x7x1xf32>
    %199 = stablehlo.reshape %198 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %200 = stablehlo.broadcast_in_dim %199, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %201 = stablehlo.multiply %192, %200 : tensor<1x7x3072xf32>
    %202 = stablehlo.convert %201 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %204 = stablehlo.multiply %6, %203 : tensor<1x7x3072xf32>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %210 = stablehlo.dot_general %206, %209, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %211 = stablehlo.reshape %210 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %211 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"}) -> tensor<1x7x128256xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = stablehlo.reshape %144 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %146 = stablehlo.add %13, %145 : tensor<1x7x3072xbf16>
    %147 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %151 = stablehlo.convert %146 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.power %151, %2 : tensor<1x7x3072xf32>
    %153 = stablehlo.reduce(%152 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %154 = stablehlo.multiply %153, %cst_3 : tensor<1x7xf32>
    %155 = stablehlo.reshape %154 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %156 = stablehlo.add %155, %23 : tensor<1x7x1xf32>
    %157 = stablehlo.rsqrt %156 : tensor<1x7x1xf32>
    %158 = stablehlo.reshape %157 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %159 = stablehlo.broadcast_in_dim %158, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %160 = stablehlo.multiply %151, %159 : tensor<1x7x3072xf32>
    %161 = stablehlo.convert %160 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.multiply %150, %162 : tensor<1x7x3072xf32>
    %164 = stablehlo.convert %163 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %166 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %167 = stablehlo.reshape %166 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %170 = stablehlo.reshape %169 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %171 = stablehlo.convert %170 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %172 = stablehlo.logistic %170 : tensor<1x7x8192xbf16>
    %173 = stablehlo.convert %172 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %174 = stablehlo.multiply %171, %173 : tensor<1x7x8192xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %176 = stablehlo.convert %175 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %177 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %178 = stablehlo.reshape %177 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %180 = stablehlo.dot_general %165, %179, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %181 = stablehlo.convert %180 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %182 = stablehlo.reshape %181 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %183 = stablehlo.multiply %176, %182 : tensor<1x7x8192xf32>
    %184 = stablehlo.convert %183 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %186 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %187 = stablehlo.reshape %186 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %190 = stablehlo.reshape %189 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %191 = stablehlo.add %146, %190 : tensor<1x7x3072xbf16>
    %192 = stablehlo.convert %191 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %193 = stablehlo.power %192, %2 : tensor<1x7x3072xf32>
    %194 = stablehlo.reduce(%193 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %195 = stablehlo.multiply %194, %cst_3 : tensor<1x7xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %197 = stablehlo.add %196, %23 : tensor<1x7x1xf32>
    %198 = stablehlo.rsqrt %197 : tensor<1x7x1xf32>
    %199 = stablehlo.reshape %198 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %200 = stablehlo.broadcast_in_dim %199, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %201 = stablehlo.multiply %192, %200 : tensor<1x7x3072xf32>
    %202 = stablehlo.convert %201 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %204 = stablehlo.multiply %6, %203 : tensor<1x7x3072xf32>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %210 = stablehlo.dot_general %206, %209, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %211 = stablehlo.reshape %210 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %211 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump Before ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"}) -> tensor<1x7x128256xbf16> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = stablehlo.reshape %144 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %146 = stablehlo.add %13, %145 : tensor<1x7x3072xbf16>
    %147 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %151 = stablehlo.convert %146 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.power %151, %2 : tensor<1x7x3072xf32>
    %153 = stablehlo.reduce(%152 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %154 = stablehlo.multiply %153, %cst_3 : tensor<1x7xf32>
    %155 = stablehlo.reshape %154 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %156 = stablehlo.add %155, %23 : tensor<1x7x1xf32>
    %157 = stablehlo.rsqrt %156 : tensor<1x7x1xf32>
    %158 = stablehlo.reshape %157 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %159 = stablehlo.broadcast_in_dim %158, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %160 = stablehlo.multiply %151, %159 : tensor<1x7x3072xf32>
    %161 = stablehlo.convert %160 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.multiply %150, %162 : tensor<1x7x3072xf32>
    %164 = stablehlo.convert %163 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %166 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %167 = stablehlo.reshape %166 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %170 = stablehlo.reshape %169 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %171 = stablehlo.convert %170 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %172 = stablehlo.logistic %170 : tensor<1x7x8192xbf16>
    %173 = stablehlo.convert %172 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %174 = stablehlo.multiply %171, %173 : tensor<1x7x8192xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %176 = stablehlo.convert %175 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %177 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %178 = stablehlo.reshape %177 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %180 = stablehlo.dot_general %165, %179, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %181 = stablehlo.convert %180 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %182 = stablehlo.reshape %181 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %183 = stablehlo.multiply %176, %182 : tensor<1x7x8192xf32>
    %184 = stablehlo.convert %183 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %186 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %187 = stablehlo.reshape %186 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %190 = stablehlo.reshape %189 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %191 = stablehlo.add %146, %190 : tensor<1x7x3072xbf16>
    %192 = stablehlo.convert %191 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %193 = stablehlo.power %192, %2 : tensor<1x7x3072xf32>
    %194 = stablehlo.reduce(%193 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %195 = stablehlo.multiply %194, %cst_3 : tensor<1x7xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %197 = stablehlo.add %196, %23 : tensor<1x7x1xf32>
    %198 = stablehlo.rsqrt %197 : tensor<1x7x1xf32>
    %199 = stablehlo.reshape %198 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %200 = stablehlo.broadcast_in_dim %199, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %201 = stablehlo.multiply %192, %200 : tensor<1x7x3072xf32>
    %202 = stablehlo.convert %201 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %204 = stablehlo.multiply %6, %203 : tensor<1x7x3072xf32>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %210 = stablehlo.dot_general %206, %209, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %211 = stablehlo.reshape %210 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %211 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump After ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = stablehlo.reshape %144 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %146 = stablehlo.add %13, %145 : tensor<1x7x3072xbf16>
    %147 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %151 = stablehlo.convert %146 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.power %151, %2 : tensor<1x7x3072xf32>
    %153 = stablehlo.reduce(%152 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %154 = stablehlo.multiply %153, %cst_3 : tensor<1x7xf32>
    %155 = stablehlo.reshape %154 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %156 = stablehlo.add %155, %23 : tensor<1x7x1xf32>
    %157 = stablehlo.rsqrt %156 : tensor<1x7x1xf32>
    %158 = stablehlo.reshape %157 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %159 = stablehlo.broadcast_in_dim %158, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %160 = stablehlo.multiply %151, %159 : tensor<1x7x3072xf32>
    %161 = stablehlo.convert %160 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.multiply %150, %162 : tensor<1x7x3072xf32>
    %164 = stablehlo.convert %163 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %166 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %167 = stablehlo.reshape %166 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %170 = stablehlo.reshape %169 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %171 = stablehlo.convert %170 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %172 = stablehlo.logistic %170 : tensor<1x7x8192xbf16>
    %173 = stablehlo.convert %172 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %174 = stablehlo.multiply %171, %173 : tensor<1x7x8192xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %176 = stablehlo.convert %175 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %177 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %178 = stablehlo.reshape %177 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %180 = stablehlo.dot_general %165, %179, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %181 = stablehlo.convert %180 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %182 = stablehlo.reshape %181 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %183 = stablehlo.multiply %176, %182 : tensor<1x7x8192xf32>
    %184 = stablehlo.convert %183 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %186 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %187 = stablehlo.reshape %186 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %190 = stablehlo.reshape %189 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %191 = stablehlo.add %146, %190 : tensor<1x7x3072xbf16>
    %192 = stablehlo.convert %191 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %193 = stablehlo.power %192, %2 : tensor<1x7x3072xf32>
    %194 = stablehlo.reduce(%193 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %195 = stablehlo.multiply %194, %cst_3 : tensor<1x7xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %197 = stablehlo.add %196, %23 : tensor<1x7x1xf32>
    %198 = stablehlo.rsqrt %197 : tensor<1x7x1xf32>
    %199 = stablehlo.reshape %198 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %200 = stablehlo.broadcast_in_dim %199, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %201 = stablehlo.multiply %192, %200 : tensor<1x7x3072xf32>
    %202 = stablehlo.convert %201 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %204 = stablehlo.multiply %6, %203 : tensor<1x7x3072xf32>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %210 = stablehlo.dot_general %206, %209, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %211 = stablehlo.reshape %210 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %211 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump Before AnalyzeMeshPass (analyze-mesh) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = stablehlo.reshape %144 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %146 = stablehlo.add %13, %145 : tensor<1x7x3072xbf16>
    %147 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %151 = stablehlo.convert %146 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.power %151, %2 : tensor<1x7x3072xf32>
    %153 = stablehlo.reduce(%152 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %154 = stablehlo.multiply %153, %cst_3 : tensor<1x7xf32>
    %155 = stablehlo.reshape %154 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %156 = stablehlo.add %155, %23 : tensor<1x7x1xf32>
    %157 = stablehlo.rsqrt %156 : tensor<1x7x1xf32>
    %158 = stablehlo.reshape %157 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %159 = stablehlo.broadcast_in_dim %158, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %160 = stablehlo.multiply %151, %159 : tensor<1x7x3072xf32>
    %161 = stablehlo.convert %160 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.multiply %150, %162 : tensor<1x7x3072xf32>
    %164 = stablehlo.convert %163 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %166 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %167 = stablehlo.reshape %166 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %170 = stablehlo.reshape %169 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %171 = stablehlo.convert %170 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %172 = stablehlo.logistic %170 : tensor<1x7x8192xbf16>
    %173 = stablehlo.convert %172 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %174 = stablehlo.multiply %171, %173 : tensor<1x7x8192xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %176 = stablehlo.convert %175 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %177 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %178 = stablehlo.reshape %177 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %180 = stablehlo.dot_general %165, %179, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %181 = stablehlo.convert %180 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %182 = stablehlo.reshape %181 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %183 = stablehlo.multiply %176, %182 : tensor<1x7x8192xf32>
    %184 = stablehlo.convert %183 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %186 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %187 = stablehlo.reshape %186 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %190 = stablehlo.reshape %189 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %191 = stablehlo.add %146, %190 : tensor<1x7x3072xbf16>
    %192 = stablehlo.convert %191 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %193 = stablehlo.power %192, %2 : tensor<1x7x3072xf32>
    %194 = stablehlo.reduce(%193 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %195 = stablehlo.multiply %194, %cst_3 : tensor<1x7xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %197 = stablehlo.add %196, %23 : tensor<1x7x1xf32>
    %198 = stablehlo.rsqrt %197 : tensor<1x7x1xf32>
    %199 = stablehlo.reshape %198 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %200 = stablehlo.broadcast_in_dim %199, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %201 = stablehlo.multiply %192, %200 : tensor<1x7x3072xf32>
    %202 = stablehlo.convert %201 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %204 = stablehlo.multiply %6, %203 : tensor<1x7x3072xf32>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %210 = stablehlo.dot_general %206, %209, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %211 = stablehlo.reshape %210 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %211 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump After AnalyzeMeshPass (analyze-mesh) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = stablehlo.reshape %144 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %146 = stablehlo.add %13, %145 : tensor<1x7x3072xbf16>
    %147 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %151 = stablehlo.convert %146 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.power %151, %2 : tensor<1x7x3072xf32>
    %153 = stablehlo.reduce(%152 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %154 = stablehlo.multiply %153, %cst_3 : tensor<1x7xf32>
    %155 = stablehlo.reshape %154 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %156 = stablehlo.add %155, %23 : tensor<1x7x1xf32>
    %157 = stablehlo.rsqrt %156 : tensor<1x7x1xf32>
    %158 = stablehlo.reshape %157 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %159 = stablehlo.broadcast_in_dim %158, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %160 = stablehlo.multiply %151, %159 : tensor<1x7x3072xf32>
    %161 = stablehlo.convert %160 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.multiply %150, %162 : tensor<1x7x3072xf32>
    %164 = stablehlo.convert %163 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %166 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %167 = stablehlo.reshape %166 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %170 = stablehlo.reshape %169 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %171 = stablehlo.convert %170 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %172 = stablehlo.logistic %170 : tensor<1x7x8192xbf16>
    %173 = stablehlo.convert %172 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %174 = stablehlo.multiply %171, %173 : tensor<1x7x8192xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %176 = stablehlo.convert %175 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %177 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %178 = stablehlo.reshape %177 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %180 = stablehlo.dot_general %165, %179, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %181 = stablehlo.convert %180 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %182 = stablehlo.reshape %181 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %183 = stablehlo.multiply %176, %182 : tensor<1x7x8192xf32>
    %184 = stablehlo.convert %183 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %186 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %187 = stablehlo.reshape %186 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %190 = stablehlo.reshape %189 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %191 = stablehlo.add %146, %190 : tensor<1x7x3072xbf16>
    %192 = stablehlo.convert %191 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %193 = stablehlo.power %192, %2 : tensor<1x7x3072xf32>
    %194 = stablehlo.reduce(%193 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %195 = stablehlo.multiply %194, %cst_3 : tensor<1x7xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %197 = stablehlo.add %196, %23 : tensor<1x7x1xf32>
    %198 = stablehlo.rsqrt %197 : tensor<1x7x1xf32>
    %199 = stablehlo.reshape %198 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %200 = stablehlo.broadcast_in_dim %199, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %201 = stablehlo.multiply %192, %200 : tensor<1x7x3072xf32>
    %202 = stablehlo.convert %201 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %204 = stablehlo.multiply %6, %203 : tensor<1x7x3072xf32>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %210 = stablehlo.dot_general %206, %209, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %211 = stablehlo.reshape %210 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %211 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump Before ApplyShardingConstraintsPass (sdy-apply-sharding-constraints) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"0x00000000000000000100000000000000020000000000000003000000000000000400000000000000050000000000000006000000000000000700000000000000080000000000000009000000000000000A000000000000000B000000000000000C000000000000000D000000000000000E000000000000000F0000000000000010000000000000001100000000000000120000000000000013000000000000001400000000000000150000000000000016000000000000001700000000000000180000000000000019000000000000001A000000000000001B000000000000001C000000000000001D000000000000001E000000000000001F0000000000000020000000000000002100000000000000220000000000000023000000000000002400000000000000250000000000000026000000000000002700000000000000280000000000000029000000000000002A000000000000002B000000000000002C000000000000002D000000000000002E000000000000002F0000000000000030000000000000003100000000000000320000000000000033000000000000003400000000000000350000000000000036000000000000003700000000000000380000000000000039000000000000003A000000000000003B000000000000003C000000000000003D000000000000003E000000000000003F0000000000000040000000000000004100000000000000420000000000000043000000000000004400000000000000450000000000000046000000000000004700000000000000480000000000000049000000000000004A000000000000004B000000000000004C000000000000004D000000000000004E000000000000004F0000000000000050000000000000005100000000000000520000000000000053000000000000005400000000000000550000000000000056000000000000005700000000000000580000000000000059000000000000005A000000000000005B000000000000005C000000000000005D000000000000005E000000000000005F0000000000000060000000000000006100000000000000620000000000000063000000000000006400000000000000650000000000000066000000000000006700000000000000680000000000000069000000000000006A000000000000006B000000000000006C000000000000006D000000000000006E000000000000006F0000000000000070000000000000007100000000000000720000000000000073000000000000007400000000000000750000000000000076000000000000007700000000000000780000000000000079000000000000007A000000000000007B000000000000007C000000000000007D000000000000007E000000000000007F0000000000000080000000000000008100000000000000820000000000000083000000000000008400000000000000850000000000000086000000000000008700000000000000880000000000000089000000000000008A000000000000008B000000000000008C000000000000008D000000000000008E000000000000008F0000000000000090000000000000009100000000000000920000000000000093000000000000009400000000000000950000000000000096000000000000009700000000000000980000000000000099000000000000009A000000000000009B000000000000009C000000000000009D000000000000009E000000000000009F00000000000000A000000000000000A100000000000000A200000000000000A300000000000000A400000000000000A500000000000000A600000000000000A700000000000000A800000000000000A900000000000000AA00000000000000AB00000000000000AC00000000000000AD00000000000000AE00000000000000AF00000000000000B000000000000000B100000000000000B200000000000000B300000000000000B400000000000000B500000000000000B600000000000000B700000000000000B800000000000000B900000000000000BA00000000000000BB00000000000000BC00000000000000BD00000000000000BE00000000000000BF00000000000000C000000000000000C100000000000000C200000000000000C300000000000000C400000000000000C500000000000000C600000000000000C700000000000000C800000000000000C900000000000000CA00000000000000CB00000000000000CC00000000000000CD00000000000000CE00000000000000CF00000000000000D000000000000000D100000000000000D200000000000000D300000000000000D400000000000000D500000000000000D600000000000000D700000000000000D800000000000000D900000000000000DA00000000000000DB00000000000000DC00000000000000DD00000000000000DE00000000000000DF00000000000000E000000000000000E100000000000000E200000000000000E300000000000000E400000000000000E500000000000000E600000000000000E700000000000000E800000000000000E900000000000000EA00000000000000EB00000000000000EC00000000000000ED00000000000000EE00000000000000EF00000000000000F000000000000000F100000000000000F200000000000000F300000000000000F400000000000000F500000000000000F600000000000000F700000000000000F800000000000000F900000000000000FA00000000000000FB00000000000000FC00000000000000FD00000000000000FE00000000000000FF0000000000000000010000000000000101000000000000020100000000000003010000000000000401000000000000050100000000000006010000000000000701000000000000080100000000000009010000000000000A010000000000000B010000000000000C010000000000000D010000000000000E010000000000000F0100000000000010010000000000001101000000000000120100000000000013010000000000001401000000000000150100000000000016010000000000001701000000000000180100000000000019010000000000001A010000000000001B010000000000001C010000000000001D010000000000001E010000000000001F0100000000000020010000000000002101000000000000220100000000000023010000000000002401000000000000250100000000000026010000000000002701000000000000280100000000000029010000000000002A010000000000002B010000000000002C010000000000002D010000000000002E010000000000002F0100000000000030010000000000003101000000000000320100000000000033010000000000003401000000000000350100000000000036010000000000003701000000000000380100000000000039010000000000003A010000000000003B010000000000003C010000000000003D010000000000003E010000000000003F0100000000000040010000000000004101000000000000420100000000000043010000000000004401000000000000450100000000000046010000000000004701000000000000480100000000000049010000000000004A010000000000004B010000000000004C010000000000004D010000000000004E010000000000004F0100000000000050010000000000005101000000000000520100000000000053010000000000005401000000000000550100000000000056010000000000005701000000000000580100000000000059010000000000005A010000000000005B010000000000005C010000000000005D010000000000005E010000000000005F0100000000000060010000000000006101000000000000620100000000000063010000000000006401000000000000650100000000000066010000000000006701000000000000680100000000000069010000000000006A010000000000006B010000000000006C010000000000006D010000000000006E010000000000006F0100000000000070010000000000007101000000000000720100000000000073010000000000007401000000000000750100000000000076010000000000007701000000000000780100000000000079010000000000007A010000000000007B010000000000007C010000000000007D010000000000007E010000000000007F0100000000000080010000000000008101000000000000820100000000000083010000000000008401000000000000850100000000000086010000000000008701000000000000880100000000000089010000000000008A010000000000008B010000000000008C010000000000008D010000000000008E010000000000008F0100000000000090010000000000009101000000000000920100000000000093010000000000009401000000000000950100000000000096010000000000009701000000000000980100000000000099010000000000009A010000000000009B010000000000009C010000000000009D010000000000009E010000000000009F01000000000000A001000000000000A101000000000000A201000000000000A301000000000000A401000000000000A501000000000000A601000000000000A701000000000000A801000000000000A901000000000000AA01000000000000AB01000000000000AC01000000000000AD01000000000000AE01000000000000AF01000000000000B001000000000000B101000000000000B201000000000000B301000000000000B401000000000000B501000000000000B601000000000000B701000000000000B801000000000000B901000000000000BA01000000000000BB01000000000000BC01000000000000BD01000000000000BE01000000000000BF01000000000000C001000000000000C101000000000000C201000000000000C301000000000000C401000000000000C501000000000000C601000000000000C701000000000000C801000000000000C901000000000000CA01000000000000CB01000000000000CC01000000000000CD01000000000000CE01000000000000CF01000000000000D001000000000000D101000000000000D201000000000000D301000000000000D401000000000000D501000000000000D601000000000000D701000000000000D801000000000000D901000000000000DA01000000000000DB01000000000000DC01000000000000DD01000000000000DE01000000000000DF01000000000000E001000000000000E101000000000000E201000000000000E301000000000000E401000000000000E501000000000000E601000000000000E701000000000000E801000000000000E901000000000000EA01000000000000EB01000000000000EC01000000000000ED01000000000000EE01000000000000EF01000000000000F001000000000000F101000000000000F201000000000000F301000000000000F401000000000000F501000000000000F601000000000000F701000000000000F801000000000000F901000000000000FA01000000000000FB01000000000000FC01000000000000FD01000000000000FE01000000000000FF0100000000000000020000000000000102000000000000020200000000000003020000000000000402000000000000050200000000000006020000000000000702000000000000080200000000000009020000000000000A020000000000000B020000000000000C020000000000000D020000000000000E020000000000000F0200000000000010020000000000001102000000000000120200000000000013020000000000001402000000000000150200000000000016020000000000001702000000000000180200000000000019020000000000001A020000000000001B020000000000001C020000000000001D020000000000001E020000000000001F0200000000000020020000000000002102000000000000220200000000000023020000000000002402000000000000250200000000000026020000000000002702000000000000280200000000000029020000000000002A020000000000002B020000000000002C020000000000002D020000000000002E020000000000002F0200000000000030020000000000003102000000000000320200000000000033020000000000003402000000000000350200000000000036020000000000003702000000000000380200000000000039020000000000003A020000000000003B020000000000003C020000000000003D020000000000003E020000000000003F0200000000000040020000000000004102000000000000420200000000000043020000000000004402000000000000450200000000000046020000000000004702000000000000480200000000000049020000000000004A020000000000004B020000000000004C020000000000004D020000000000004E020000000000004F0200000000000050020000000000005102000000000000520200000000000053020000000000005402000000000000550200000000000056020000000000005702000000000000580200000000000059020000000000005A020000000000005B020000000000005C020000000000005D020000000000005E020000000000005F0200000000000060020000000000006102000000000000620200000000000063020000000000006402000000000000650200000000000066020000000000006702000000000000680200000000000069020000000000006A020000000000006B020000000000006C020000000000006D020000000000006E020000000000006F0200000000000070020000000000007102000000000000720200000000000073020000000000007402000000000000750200000000000076020000000000007702000000000000780200000000000079020000000000007A020000000000007B020000000000007C020000000000007D020000000000007E020000000000007F0200000000000080020000000000008102000000000000820200000000000083020000000000008402000000000000850200000000000086020000000000008702000000000000880200000000000089020000000000008A020000000000008B020000000000008C020000000000008D020000000000008E020000000000008F0200000000000090020000000000009102000000000000920200000000000093020000000000009402000000000000950200000000000096020000000000009702000000000000980200000000000099020000000000009A020000000000009B020000000000009C020000000000009D020000000000009E020000000000009F02000000000000A002000000000000A102000000000000A202000000000000A302000000000000A402000000000000A502000000000000A602000000000000A702000000000000A802000000000000A902000000000000AA02000000000000AB02000000000000AC02000000000000AD02000000000000AE02000000000000AF02000000000000B002000000000000B102000000000000B202000000000000B302000000000000B402000000000000B502000000000000B602000000000000B702000000000000B802000000000000B902000000000000BA02000000000000BB02000000000000BC02000000000000BD02000000000000BE02000000000000BF02000000000000C002000000000000C102000000000000C202000000000000C302000000000000C402000000000000C502000000000000C602000000000000C702000000000000C802000000000000C902000000000000CA02000000000000CB02000000000000CC02000000000000CD02000000000000CE02000000000000CF02000000000000D002000000000000D102000000000000D202000000000000D302000000000000D402000000000000D502000000000000D602000000000000D702000000000000D802000000000000D902000000000000DA02000000000000DB02000000000000DC02000000000000DD02000000000000DE02000000000000DF02000000000000E002000000000000E102000000000000E202000000000000E302000000000000E402000000000000E502000000000000E602000000000000E702000000000000E802000000000000E902000000000000EA02000000000000EB02000000000000EC02000000000000ED02000000000000EE02000000000000EF02000000000000F002000000000000F102000000000000F202000000000000F302000000000000F402000000000000F502000000000000F602000000000000F702000000000000F802000000000000F902000000000000FA02000000000000FB02000000000000FC02000000000000FD02000000000000FE02000000000000FF0200000000000000030000000000000103000000000000020300000000000003030000000000000403000000000000050300000000000006030000000000000703000000000000080300000000000009030000000000000A030000000000000B030000000000000C030000000000000D030000000000000E030000000000000F0300000000000010030000000000001103000000000000120300000000000013030000000000001403000000000000150300000000000016030000000000001703000000000000180300000000000019030000000000001A030000000000001B030000000000001C030000000000001D030000000000001E030000000000001F0300000000000020030000000000002103000000000000220300000000000023030000000000002403000000000000250300000000000026030000000000002703000000000000280300000000000029030000000000002A030000000000002B030000000000002C030000000000002D030000000000002E030000000000002F0300000000000030030000000000003103000000000000320300000000000033030000000000003403000000000000350300000000000036030000000000003703000000000000380300000000000039030000000000003A030000000000003B030000000000003C030000000000003D030000000000003E030000000000003F0300000000000040030000000000004103000000000000420300000000000043030000000000004403000000000000450300000000000046030000000000004703000000000000480300000000000049030000000000004A030000000000004B030000000000004C030000000000004D030000000000004E030000000000004F0300000000000050030000000000005103000000000000520300000000000053030000000000005403000000000000550300000000000056030000000000005703000000000000580300000000000059030000000000005A030000000000005B030000000000005C030000000000005D030000000000005E030000000000005F0300000000000060030000000000006103000000000000620300000000000063030000000000006403000000000000650300000000000066030000000000006703000000000000680300000000000069030000000000006A030000000000006B030000000000006C030000000000006D030000000000006E030000000000006F0300000000000070030000000000007103000000000000720300000000000073030000000000007403000000000000750300000000000076030000000000007703000000000000780300000000000079030000000000007A030000000000007B030000000000007C030000000000007D030000000000007E030000000000007F0300000000000080030000000000008103000000000000820300000000000083030000000000008403000000000000850300000000000086030000000000008703000000000000880300000000000089030000000000008A030000000000008B030000000000008C030000000000008D030000000000008E030000000000008F0300000000000090030000000000009103000000000000920300000000000093030000000000009403000000000000950300000000000096030000000000009703000000000000980300000000000099030000000000009A030000000000009B030000000000009C030000000000009D030000000000009E030000000000009F03000000000000A003000000000000A103000000000000A203000000000000A303000000000000A403000000000000A503000000000000A603000000000000A703000000000000A803000000000000A903000000000000AA03000000000000AB03000000000000AC03000000000000AD03000000000000AE03000000000000AF03000000000000B003000000000000B103000000000000B203000000000000B303000000000000B403000000000000B503000000000000B603000000000000B703000000000000B803000000000000B903000000000000BA03000000000000BB03000000000000BC03000000000000BD03000000000000BE03000000000000BF03000000000000C003000000000000C103000000000000C203000000000000C303000000000000C403000000000000C503000000000000C603000000000000C703000000000000C803000000000000C903000000000000CA03000000000000CB03000000000000CC03000000000000CD03000000000000CE03000000000000CF03000000000000D003000000000000D103000000000000D203000000000000D303000000000000D403000000000000D503000000000000D603000000000000D703000000000000D803000000000000D903000000000000DA03000000000000DB03000000000000DC03000000000000DD03000000000000DE03000000000000DF03000000000000E003000000000000E103000000000000E203000000000000E303000000000000E403000000000000E503000000000000E603000000000000E703000000000000E803000000000000E903000000000000EA03000000000000EB03000000000000EC03000000000000ED03000000000000EE03000000000000EF03000000000000F003000000000000F103000000000000F203000000000000F303000000000000F403000000000000F503000000000000F603000000000000F703000000000000F803000000000000F903000000000000FA03000000000000FB03000000000000FC03000000000000FD03000000000000FE03000000000000FF03000000000000"> : tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = stablehlo.reshape %144 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %146 = stablehlo.add %13, %145 : tensor<1x7x3072xbf16>
    %147 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %151 = stablehlo.convert %146 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.power %151, %2 : tensor<1x7x3072xf32>
    %153 = stablehlo.reduce(%152 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %154 = stablehlo.multiply %153, %cst_3 : tensor<1x7xf32>
    %155 = stablehlo.reshape %154 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %156 = stablehlo.add %155, %23 : tensor<1x7x1xf32>
    %157 = stablehlo.rsqrt %156 : tensor<1x7x1xf32>
    %158 = stablehlo.reshape %157 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %159 = stablehlo.broadcast_in_dim %158, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %160 = stablehlo.multiply %151, %159 : tensor<1x7x3072xf32>
    %161 = stablehlo.convert %160 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.multiply %150, %162 : tensor<1x7x3072xf32>
    %164 = stablehlo.convert %163 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %166 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %167 = stablehlo.reshape %166 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %170 = stablehlo.reshape %169 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %171 = stablehlo.convert %170 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %172 = stablehlo.logistic %170 : tensor<1x7x8192xbf16>
    %173 = stablehlo.convert %172 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %174 = stablehlo.multiply %171, %173 : tensor<1x7x8192xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %176 = stablehlo.convert %175 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %177 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %178 = stablehlo.reshape %177 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %180 = stablehlo.dot_general %165, %179, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %181 = stablehlo.convert %180 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %182 = stablehlo.reshape %181 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %183 = stablehlo.multiply %176, %182 : tensor<1x7x8192xf32>
    %184 = stablehlo.convert %183 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %186 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %187 = stablehlo.reshape %186 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %190 = stablehlo.reshape %189 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %191 = stablehlo.add %146, %190 : tensor<1x7x3072xbf16>
    %192 = stablehlo.convert %191 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %193 = stablehlo.power %192, %2 : tensor<1x7x3072xf32>
    %194 = stablehlo.reduce(%193 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %195 = stablehlo.multiply %194, %cst_3 : tensor<1x7xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %197 = stablehlo.add %196, %23 : tensor<1x7x1xf32>
    %198 = stablehlo.rsqrt %197 : tensor<1x7x1xf32>
    %199 = stablehlo.reshape %198 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %200 = stablehlo.broadcast_in_dim %199, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %201 = stablehlo.multiply %192, %200 : tensor<1x7x3072xf32>
    %202 = stablehlo.convert %201 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %204 = stablehlo.multiply %6, %203 : tensor<1x7x3072xf32>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %210 = stablehlo.dot_general %206, %209, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %211 = stablehlo.reshape %210 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %211 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump Before AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = stablehlo.reshape %144 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %146 = stablehlo.add %13, %145 : tensor<1x7x3072xbf16>
    %147 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %151 = stablehlo.convert %146 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.power %151, %2 : tensor<1x7x3072xf32>
    %153 = stablehlo.reduce(%152 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %154 = stablehlo.multiply %153, %cst_3 : tensor<1x7xf32>
    %155 = stablehlo.reshape %154 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %156 = stablehlo.add %155, %23 : tensor<1x7x1xf32>
    %157 = stablehlo.rsqrt %156 : tensor<1x7x1xf32>
    %158 = stablehlo.reshape %157 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %159 = stablehlo.broadcast_in_dim %158, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %160 = stablehlo.multiply %151, %159 : tensor<1x7x3072xf32>
    %161 = stablehlo.convert %160 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.multiply %150, %162 : tensor<1x7x3072xf32>
    %164 = stablehlo.convert %163 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %166 = stablehlo.reshape %arg19 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %167 = stablehlo.reshape %166 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %170 = stablehlo.reshape %169 : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %171 = stablehlo.convert %170 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %172 = stablehlo.logistic %170 : tensor<1x7x8192xbf16>
    %173 = stablehlo.convert %172 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %174 = stablehlo.multiply %171, %173 : tensor<1x7x8192xf32>
    %175 = stablehlo.convert %174 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %176 = stablehlo.convert %175 : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %177 = stablehlo.reshape %arg3 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %178 = stablehlo.reshape %177 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %180 = stablehlo.dot_general %165, %179, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %181 = stablehlo.convert %180 : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %182 = stablehlo.reshape %181 : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %183 = stablehlo.multiply %176, %182 : tensor<1x7x8192xf32>
    %184 = stablehlo.convert %183 : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.reshape %184 : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %186 = stablehlo.reshape %arg2 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %187 = stablehlo.reshape %186 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %190 = stablehlo.reshape %189 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %191 = stablehlo.add %146, %190 : tensor<1x7x3072xbf16>
    %192 = stablehlo.convert %191 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %193 = stablehlo.power %192, %2 : tensor<1x7x3072xf32>
    %194 = stablehlo.reduce(%193 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %195 = stablehlo.multiply %194, %cst_3 : tensor<1x7xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %197 = stablehlo.add %196, %23 : tensor<1x7x1xf32>
    %198 = stablehlo.rsqrt %197 : tensor<1x7x1xf32>
    %199 = stablehlo.reshape %198 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %200 = stablehlo.broadcast_in_dim %199, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %201 = stablehlo.multiply %192, %200 : tensor<1x7x3072xf32>
    %202 = stablehlo.convert %201 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %204 = stablehlo.multiply %6, %203 : tensor<1x7x3072xf32>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %210 = stablehlo.dot_general %206, %209, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %211 = stablehlo.reshape %210 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %211 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump After AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = stablehlo.reshape %144 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %146 = stablehlo.add %13, %145 : tensor<1x7x3072xbf16>
    %147 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %151 = stablehlo.convert %146 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.power %151, %2 : tensor<1x7x3072xf32>
    %153 = stablehlo.reduce(%152 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %154 = stablehlo.multiply %153, %cst_3 : tensor<1x7xf32>
    %155 = stablehlo.reshape %154 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %156 = stablehlo.add %155, %23 : tensor<1x7x1xf32>
    %157 = stablehlo.rsqrt %156 : tensor<1x7x1xf32>
    %158 = stablehlo.reshape %157 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %159 = stablehlo.broadcast_in_dim %158, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %160 = stablehlo.multiply %151, %159 : tensor<1x7x3072xf32>
    %161 = stablehlo.convert %160 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.multiply %150, %162 : tensor<1x7x3072xf32>
    %164 = stablehlo.convert %163 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %166 = stablehlo.reshape %arg19 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %167 = stablehlo.reshape %166 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %170 = stablehlo.reshape %169 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %171 = stablehlo.convert %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %172 = stablehlo.logistic %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xbf16>
    %173 = stablehlo.convert %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %174 = stablehlo.multiply %171, %173 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
    %175 = stablehlo.convert %174 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %176 = stablehlo.convert %175 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %177 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %178 = stablehlo.reshape %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %180 = stablehlo.dot_general %165, %179, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %181 = stablehlo.convert %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %182 = stablehlo.reshape %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %183 = stablehlo.multiply %176, %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
    %184 = stablehlo.convert %183 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.reshape %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %186 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %187 = stablehlo.reshape %186 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %190 = stablehlo.reshape %189 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %191 = stablehlo.add %146, %190 : tensor<1x7x3072xbf16>
    %192 = stablehlo.convert %191 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %193 = stablehlo.power %192, %2 : tensor<1x7x3072xf32>
    %194 = stablehlo.reduce(%193 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %195 = stablehlo.multiply %194, %cst_3 : tensor<1x7xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %197 = stablehlo.add %196, %23 : tensor<1x7x1xf32>
    %198 = stablehlo.rsqrt %197 : tensor<1x7x1xf32>
    %199 = stablehlo.reshape %198 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %200 = stablehlo.broadcast_in_dim %199, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %201 = stablehlo.multiply %192, %200 : tensor<1x7x3072xf32>
    %202 = stablehlo.convert %201 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %204 = stablehlo.multiply %6, %203 : tensor<1x7x3072xf32>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %210 = stablehlo.dot_general %206, %209, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %211 = stablehlo.reshape %210 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %211 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump Before ShardingConstraintToReshardPass (sdy-sharding-constraint-to-reshard) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = stablehlo.reshape %144 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %146 = stablehlo.add %13, %145 : tensor<1x7x3072xbf16>
    %147 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %151 = stablehlo.convert %146 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.power %151, %2 : tensor<1x7x3072xf32>
    %153 = stablehlo.reduce(%152 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %154 = stablehlo.multiply %153, %cst_3 : tensor<1x7xf32>
    %155 = stablehlo.reshape %154 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %156 = stablehlo.add %155, %23 : tensor<1x7x1xf32>
    %157 = stablehlo.rsqrt %156 : tensor<1x7x1xf32>
    %158 = stablehlo.reshape %157 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %159 = stablehlo.broadcast_in_dim %158, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %160 = stablehlo.multiply %151, %159 : tensor<1x7x3072xf32>
    %161 = stablehlo.convert %160 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.multiply %150, %162 : tensor<1x7x3072xf32>
    %164 = stablehlo.convert %163 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %166 = stablehlo.reshape %arg19 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %167 = stablehlo.reshape %166 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %170 = stablehlo.reshape %169 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %171 = stablehlo.convert %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %172 = stablehlo.logistic %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xbf16>
    %173 = stablehlo.convert %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %174 = stablehlo.multiply %171, %173 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
    %175 = stablehlo.convert %174 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %176 = stablehlo.convert %175 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %177 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %178 = stablehlo.reshape %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %180 = stablehlo.dot_general %165, %179, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %181 = stablehlo.convert %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %182 = stablehlo.reshape %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %183 = stablehlo.multiply %176, %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
    %184 = stablehlo.convert %183 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.reshape %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %186 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %187 = stablehlo.reshape %186 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %190 = stablehlo.reshape %189 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %191 = stablehlo.add %146, %190 : tensor<1x7x3072xbf16>
    %192 = stablehlo.convert %191 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %193 = stablehlo.power %192, %2 : tensor<1x7x3072xf32>
    %194 = stablehlo.reduce(%193 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %195 = stablehlo.multiply %194, %cst_3 : tensor<1x7xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %197 = stablehlo.add %196, %23 : tensor<1x7x1xf32>
    %198 = stablehlo.rsqrt %197 : tensor<1x7x1xf32>
    %199 = stablehlo.reshape %198 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %200 = stablehlo.broadcast_in_dim %199, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %201 = stablehlo.multiply %192, %200 : tensor<1x7x3072xf32>
    %202 = stablehlo.convert %201 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %204 = stablehlo.multiply %6, %203 : tensor<1x7x3072xf32>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %210 = stablehlo.dot_general %206, %209, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %211 = stablehlo.reshape %210 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %211 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump Before InsertExplicitReshardsPass (sdy-insert-explicit-reshards) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = stablehlo.reshape %144 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %146 = stablehlo.add %13, %145 : tensor<1x7x3072xbf16>
    %147 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %148 = stablehlo.convert %147 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %149 = stablehlo.reshape %148 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %150 = stablehlo.broadcast_in_dim %149, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %151 = stablehlo.convert %146 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.power %151, %2 : tensor<1x7x3072xf32>
    %153 = stablehlo.reduce(%152 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %154 = stablehlo.multiply %153, %cst_3 : tensor<1x7xf32>
    %155 = stablehlo.reshape %154 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %156 = stablehlo.add %155, %23 : tensor<1x7x1xf32>
    %157 = stablehlo.rsqrt %156 : tensor<1x7x1xf32>
    %158 = stablehlo.reshape %157 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %159 = stablehlo.broadcast_in_dim %158, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %160 = stablehlo.multiply %151, %159 : tensor<1x7x3072xf32>
    %161 = stablehlo.convert %160 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %163 = stablehlo.multiply %150, %162 : tensor<1x7x3072xf32>
    %164 = stablehlo.convert %163 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %165 = stablehlo.reshape %164 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %166 = stablehlo.reshape %arg19 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %167 = stablehlo.reshape %166 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %168 = stablehlo.transpose %167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %169 = stablehlo.dot_general %165, %168, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %170 = stablehlo.reshape %169 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %171 = stablehlo.convert %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %172 = stablehlo.logistic %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xbf16>
    %173 = stablehlo.convert %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %174 = stablehlo.multiply %171, %173 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
    %175 = stablehlo.convert %174 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %176 = stablehlo.convert %175 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %177 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %178 = stablehlo.reshape %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %179 = stablehlo.transpose %178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %180 = stablehlo.dot_general %165, %179, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %181 = stablehlo.convert %180 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %182 = stablehlo.reshape %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %183 = stablehlo.multiply %176, %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
    %184 = stablehlo.convert %183 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %185 = stablehlo.reshape %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %186 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %187 = stablehlo.reshape %186 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %190 = stablehlo.reshape %189 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %191 = stablehlo.add %146, %190 : tensor<1x7x3072xbf16>
    %192 = stablehlo.convert %191 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %193 = stablehlo.power %192, %2 : tensor<1x7x3072xf32>
    %194 = stablehlo.reduce(%193 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %195 = stablehlo.multiply %194, %cst_3 : tensor<1x7xf32>
    %196 = stablehlo.reshape %195 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %197 = stablehlo.add %196, %23 : tensor<1x7x1xf32>
    %198 = stablehlo.rsqrt %197 : tensor<1x7x1xf32>
    %199 = stablehlo.reshape %198 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %200 = stablehlo.broadcast_in_dim %199, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %201 = stablehlo.multiply %192, %200 : tensor<1x7x3072xf32>
    %202 = stablehlo.convert %201 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %203 = stablehlo.convert %202 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %204 = stablehlo.multiply %6, %203 : tensor<1x7x3072xf32>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %206 = stablehlo.reshape %205 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %207 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %210 = stablehlo.dot_general %206, %209, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %211 = stablehlo.reshape %210 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %211 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump After InsertExplicitReshardsPass (sdy-insert-explicit-reshards) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = sdy.all_reduce {"_axis_0"} %144 out_sharding=<@mesh, [{}, {}]> : tensor<7x3072xbf16>
    %146 = stablehlo.reshape %145 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %147 = stablehlo.add %13, %146 : tensor<1x7x3072xbf16>
    %148 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %149 = stablehlo.convert %148 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %150 = stablehlo.reshape %149 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %151 = stablehlo.broadcast_in_dim %150, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.convert %147 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %153 = stablehlo.power %152, %2 : tensor<1x7x3072xf32>
    %154 = stablehlo.reduce(%153 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %155 = stablehlo.multiply %154, %cst_3 : tensor<1x7xf32>
    %156 = stablehlo.reshape %155 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %157 = stablehlo.add %156, %23 : tensor<1x7x1xf32>
    %158 = stablehlo.rsqrt %157 : tensor<1x7x1xf32>
    %159 = stablehlo.reshape %158 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %160 = stablehlo.broadcast_in_dim %159, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %161 = stablehlo.multiply %152, %160 : tensor<1x7x3072xf32>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %163 = stablehlo.convert %162 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %164 = stablehlo.multiply %151, %163 : tensor<1x7x3072xf32>
    %165 = stablehlo.convert %164 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %166 = stablehlo.reshape %165 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %167 = stablehlo.reshape %arg19 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %168 = stablehlo.reshape %167 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %169 = stablehlo.transpose %168, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %170 = stablehlo.dot_general %166, %169, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %171 = stablehlo.reshape %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %172 = stablehlo.convert %171 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %173 = stablehlo.logistic %171 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xbf16>
    %174 = stablehlo.convert %173 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %175 = stablehlo.multiply %172, %174 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
    %176 = stablehlo.convert %175 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %177 = stablehlo.convert %176 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %178 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %179 = stablehlo.reshape %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %180 = stablehlo.transpose %179, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %181 = stablehlo.dot_general %166, %180, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %182 = stablehlo.convert %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %183 = stablehlo.reshape %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %184 = stablehlo.multiply %177, %183 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
    %185 = stablehlo.convert %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %186 = stablehlo.reshape %185 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %187 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %189 = stablehlo.transpose %188, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %190 = stablehlo.dot_general %186, %189, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %191 = sdy.all_reduce {"_axis_0"} %190 out_sharding=<@mesh, [{}, {}]> : tensor<7x3072xbf16>
    %192 = stablehlo.reshape %191 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %193 = stablehlo.add %147, %192 : tensor<1x7x3072xbf16>
    %194 = stablehlo.convert %193 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %195 = stablehlo.power %194, %2 : tensor<1x7x3072xf32>
    %196 = stablehlo.reduce(%195 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %197 = stablehlo.multiply %196, %cst_3 : tensor<1x7xf32>
    %198 = stablehlo.reshape %197 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %199 = stablehlo.add %198, %23 : tensor<1x7x1xf32>
    %200 = stablehlo.rsqrt %199 : tensor<1x7x1xf32>
    %201 = stablehlo.reshape %200 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %202 = stablehlo.broadcast_in_dim %201, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %203 = stablehlo.multiply %194, %202 : tensor<1x7x3072xf32>
    %204 = stablehlo.convert %203 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %206 = stablehlo.multiply %6, %205 : tensor<1x7x3072xf32>
    %207 = stablehlo.convert %206 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %209 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %210 = stablehlo.reshape %209 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %211 = stablehlo.transpose %210, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %212 = stablehlo.dot_general %208, %211, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %213 = stablehlo.reshape %212 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %213 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump Before WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant dense<"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tensor<1024xi64>
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
    %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
    %c_5 = stablehlo.constant dense<1> : tensor<i64>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
    %0 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %1 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
    %2 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
    %3 = stablehlo.reshape %arg20 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %4 = stablehlo.convert %3 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %5 = stablehlo.reshape %4 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %6 = stablehlo.broadcast_in_dim %5, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %7 = stablehlo.reshape %arg7 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %8 = stablehlo.reshape %7 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %9 = stablehlo.reshape %arg6 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
    %10 = stablehlo.convert %9 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
    %11 = stablehlo.reshape %10 : (tensor<1x1x7xui32>) -> tensor<7xui32>
    %12 = "stablehlo.gather"(%8, %11) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
    %13 = stablehlo.reshape %12 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %14 = stablehlo.reshape %arg8 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %15 = stablehlo.convert %14 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %16 = stablehlo.reshape %15 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %17 = stablehlo.broadcast_in_dim %16, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %18 = stablehlo.convert %13 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %19 = stablehlo.power %18, %2 : tensor<1x7x3072xf32>
    %20 = stablehlo.reduce(%19 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %21 = stablehlo.multiply %20, %cst_3 : tensor<1x7xf32>
    %22 = stablehlo.reshape %21 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %23 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
    %24 = stablehlo.add %22, %23 : tensor<1x7x1xf32>
    %25 = stablehlo.rsqrt %24 : tensor<1x7x1xf32>
    %26 = stablehlo.reshape %25 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %27 = stablehlo.broadcast_in_dim %26, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %28 = stablehlo.multiply %18, %27 : tensor<1x7x3072xf32>
    %29 = stablehlo.convert %28 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %30 = stablehlo.convert %29 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %31 = stablehlo.multiply %17, %30 : tensor<1x7x3072xf32>
    %32 = stablehlo.convert %31 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %33 = stablehlo.reshape %32 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %34 = stablehlo.reshape %arg17 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %35 = stablehlo.reshape %34 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %36 = stablehlo.transpose %35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %37 = stablehlo.dot_general %33, %36, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %38 = stablehlo.reshape %37 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
    %39 = stablehlo.transpose %38, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
    %40 = stablehlo.convert %39 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %41 = stablehlo.reshape %arg14 : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %43 = stablehlo.reshape %arg9 : (tensor<7xi64>) -> tensor<1x1x7xi64>
    %44 = stablehlo.reshape %43 : (tensor<1x1x7xi64>) -> tensor<7xi64>
    %45 = stablehlo.convert %43 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
    %46 = stablehlo.dot_general %42, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
    %47 = stablehlo.transpose %46, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
    %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
    %49 = stablehlo.cosine %48 : tensor<1x7x128xf32>
    %50 = stablehlo.convert %49 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %51 = stablehlo.convert %50 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %52 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %53 = stablehlo.multiply %40, %52 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
    %54 = stablehlo.convert %53 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %55 = stablehlo.slice %39 [0:1, 0:24, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %56 = stablehlo.negate %55 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x64xbf16>
    %57 = stablehlo.slice %39 [0:1, 0:24, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
    %58 = stablehlo.concatenate %56, %57, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
    %59 = stablehlo.convert %58 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
    %60 = stablehlo.sine %48 : tensor<1x7x128xf32>
    %61 = stablehlo.convert %60 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
    %62 = stablehlo.convert %61 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
    %63 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
    %64 = stablehlo.multiply %59, %63 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
    %65 = stablehlo.convert %64 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
    %66 = stablehlo.add %54, %65 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xbf16>
    %67 = stablehlo.reshape %66 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
    %68 = stablehlo.compare  LT, %44, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
    %69 = stablehlo.broadcast_in_dim %arg10, dims = [] : (tensor<i64>) -> tensor<7xi64>
    %70 = stablehlo.add %44, %69 : tensor<7xi64>
    %71 = stablehlo.select %68, %70, %44 : tensor<7xi1>, tensor<7xi64>
    %72 = stablehlo.reshape %71 : (tensor<7xi64>) -> tensor<7x1xi64>
    %73 = stablehlo.reshape %arg15 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %74 = stablehlo.reshape %73 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %75 = stablehlo.transpose %74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %76 = stablehlo.dot_general %33, %75, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %77 = stablehlo.reshape %76 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %78 = stablehlo.transpose %77, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %79 = stablehlo.convert %78 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %80 = stablehlo.broadcast_in_dim %51, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %81 = stablehlo.multiply %79, %80 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
    %82 = stablehlo.convert %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %83 = stablehlo.slice %78 [0:1, 0:8, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %84 = stablehlo.negate %83 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x64xbf16>
    %85 = stablehlo.slice %78 [0:1, 0:8, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
    %86 = stablehlo.concatenate %84, %85, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
    %87 = stablehlo.convert %86 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
    %88 = stablehlo.broadcast_in_dim %62, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
    %89 = stablehlo.multiply %87, %88 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
    %90 = stablehlo.convert %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
    %91 = stablehlo.add %82, %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xbf16>
    %92 = "stablehlo.scatter"(%arg16, %72, %91) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %93 = stablehlo.broadcast_in_dim %92, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %94 = stablehlo.reshape %93 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
    %96 = stablehlo.reshape %95 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
    %97 = stablehlo.dot_general %67, %96, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
    %98 = stablehlo.convert %97 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
    %99 = stablehlo.reshape %98 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
    %100 = stablehlo.broadcast_in_dim %arg13, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<1x24x7x1024xf32>
    %101 = stablehlo.multiply %99, %100 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %102 = stablehlo.convert %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %103 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
    %104 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %105 = stablehlo.subtract %103, %104 : tensor<7x1024xi64>
    %106 = stablehlo.compare  GE, %105, %1 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %107 = stablehlo.broadcast_in_dim %arg12, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
    %108 = stablehlo.select %106, %107, %0 : tensor<7x1024xi1>, tensor<7x1024xbf16>
    %109 = stablehlo.convert %108 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
    %110 = stablehlo.broadcast_in_dim %44, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
    %111 = stablehlo.compare  GT, %103, %110 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
    %112 = stablehlo.convert %111 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
    %113 = stablehlo.multiply %109, %112 : tensor<7x1024xf32>
    %114 = stablehlo.convert %113 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
    %115 = stablehlo.reshape %114 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
    %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
    %117 = stablehlo.add %102, %116 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xbf16>
    %118 = stablehlo.convert %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
    %119 = stablehlo.reduce(%118 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %121 = stablehlo.subtract %118, %120 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %122 = stablehlo.exponential %121 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
    %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
    %125 = stablehlo.divide %122, %124 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
    %126 = stablehlo.convert %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
    %127 = stablehlo.reshape %126 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
    %128 = stablehlo.reshape %arg5 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
    %129 = stablehlo.reshape %128 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
    %131 = stablehlo.dot_general %33, %130, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
    %132 = stablehlo.reshape %131 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
    %133 = stablehlo.transpose %132, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
    %134 = "stablehlo.scatter"(%arg11, %72, %133) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg21: tensor<bf16>, %arg22: tensor<bf16>):
      stablehlo.return %arg22 : tensor<bf16>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
    %136 = stablehlo.reshape %135 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
    %137 = stablehlo.dot_general %127, %136, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
    %138 = stablehlo.reshape %137 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
    %139 = stablehlo.transpose %138, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
    %140 = stablehlo.reshape %139 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
    %141 = stablehlo.reshape %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
    %142 = stablehlo.reshape %141 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
    %144 = stablehlo.dot_general %140, %143, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
    %145 = sdy.all_reduce {"_axis_0"} %144 out_sharding=<@mesh, [{}, {}]> : tensor<7x3072xbf16>
    %146 = stablehlo.reshape %145 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %147 = stablehlo.add %13, %146 : tensor<1x7x3072xbf16>
    %148 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %149 = stablehlo.convert %148 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
    %150 = stablehlo.reshape %149 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
    %151 = stablehlo.broadcast_in_dim %150, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
    %152 = stablehlo.convert %147 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %153 = stablehlo.power %152, %2 : tensor<1x7x3072xf32>
    %154 = stablehlo.reduce(%153 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %155 = stablehlo.multiply %154, %cst_3 : tensor<1x7xf32>
    %156 = stablehlo.reshape %155 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %157 = stablehlo.add %156, %23 : tensor<1x7x1xf32>
    %158 = stablehlo.rsqrt %157 : tensor<1x7x1xf32>
    %159 = stablehlo.reshape %158 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %160 = stablehlo.broadcast_in_dim %159, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %161 = stablehlo.multiply %152, %160 : tensor<1x7x3072xf32>
    %162 = stablehlo.convert %161 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %163 = stablehlo.convert %162 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %164 = stablehlo.multiply %151, %163 : tensor<1x7x3072xf32>
    %165 = stablehlo.convert %164 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %166 = stablehlo.reshape %165 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %167 = stablehlo.reshape %arg19 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %168 = stablehlo.reshape %167 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %169 = stablehlo.transpose %168, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %170 = stablehlo.dot_general %166, %169, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %171 = stablehlo.reshape %170 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
    %172 = stablehlo.convert %171 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %173 = stablehlo.logistic %171 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xbf16>
    %174 = stablehlo.convert %173 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %175 = stablehlo.multiply %172, %174 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
    %176 = stablehlo.convert %175 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %177 = stablehlo.convert %176 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
    %178 = stablehlo.reshape %arg3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
    %179 = stablehlo.reshape %178 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
    %180 = stablehlo.transpose %179, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
    %181 = stablehlo.dot_general %166, %180, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
    %182 = stablehlo.convert %181 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
    %183 = stablehlo.reshape %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
    %184 = stablehlo.multiply %177, %183 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
    %185 = stablehlo.convert %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
    %186 = stablehlo.reshape %185 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
    %187 = stablehlo.reshape %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
    %188 = stablehlo.reshape %187 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
    %189 = stablehlo.transpose %188, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
    %190 = stablehlo.dot_general %186, %189, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
    %191 = sdy.all_reduce {"_axis_0"} %190 out_sharding=<@mesh, [{}, {}]> : tensor<7x3072xbf16>
    %192 = stablehlo.reshape %191 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
    %193 = stablehlo.add %147, %192 : tensor<1x7x3072xbf16>
    %194 = stablehlo.convert %193 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %195 = stablehlo.power %194, %2 : tensor<1x7x3072xf32>
    %196 = stablehlo.reduce(%195 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
    %197 = stablehlo.multiply %196, %cst_3 : tensor<1x7xf32>
    %198 = stablehlo.reshape %197 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
    %199 = stablehlo.add %198, %23 : tensor<1x7x1xf32>
    %200 = stablehlo.rsqrt %199 : tensor<1x7x1xf32>
    %201 = stablehlo.reshape %200 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
    %202 = stablehlo.broadcast_in_dim %201, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
    %203 = stablehlo.multiply %194, %202 : tensor<1x7x3072xf32>
    %204 = stablehlo.convert %203 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %205 = stablehlo.convert %204 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
    %206 = stablehlo.multiply %6, %205 : tensor<1x7x3072xf32>
    %207 = stablehlo.convert %206 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
    %208 = stablehlo.reshape %207 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
    %209 = stablehlo.reshape %arg0 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %210 = stablehlo.reshape %209 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %211 = stablehlo.transpose %210, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %212 = stablehlo.dot_general %208, %211, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
    %213 = stablehlo.reshape %212 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
    return %213 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump After WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18, %arg19, %arg20) in_shardings=[<@mesh, [{}, {}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, []>, <@mesh, []>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{?}, {?}, {?}]>] manual_axes={} (%arg21: tensor<128256x3072xbf16>, %arg22: tensor<f32>, %arg23: tensor<3072x8192xbf16>, %arg24: tensor<8192x3072xbf16>, %arg25: tensor<3072x3072xbf16>, %arg26: tensor<1024x3072xbf16>, %arg27: tensor<1x7xi64>, %arg28: tensor<128256x3072xbf16>, %arg29: tensor<3072xbf16>, %arg30: tensor<7xi64>, %arg31: tensor<i64>, %arg32: tensor<1x8x1024x128xbf16>, %arg33: tensor<bf16>, %arg34: tensor<f32>, %arg35: tensor<64xf32>, %arg36: tensor<1024x3072xbf16>, %arg37: tensor<1x8x1024x128xbf16>, %arg38: tensor<3072x3072xbf16>, %arg39: tensor<3072xbf16>, %arg40: tensor<8192x3072xbf16>, %arg41: tensor<3072xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %c = stablehlo.constant dense<"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tensor<1024xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
      %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
      %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
      %c_5 = stablehlo.constant dense<1> : tensor<i64>
      %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
      %2 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
      %3 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
      %4 = stablehlo.reshape %arg41 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
      %5 = stablehlo.convert %4 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %6 = stablehlo.reshape %5 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
      %7 = stablehlo.broadcast_in_dim %6, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %8 = stablehlo.reshape %arg28 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
      %9 = stablehlo.reshape %8 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
      %10 = stablehlo.reshape %arg27 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
      %11 = stablehlo.convert %10 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
      %12 = stablehlo.reshape %11 : (tensor<1x1x7xui32>) -> tensor<7xui32>
      %13 = "stablehlo.gather"(%9, %12) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
      %14 = stablehlo.reshape %13 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %15 = stablehlo.reshape %arg29 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
      %16 = stablehlo.convert %15 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %17 = stablehlo.reshape %16 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
      %18 = stablehlo.broadcast_in_dim %17, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %19 = stablehlo.convert %14 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %20 = stablehlo.power %19, %3 : tensor<1x7x3072xf32>
      %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %22 = stablehlo.multiply %21, %cst_3 : tensor<1x7xf32>
      %23 = stablehlo.reshape %22 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %24 = stablehlo.broadcast_in_dim %arg22, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
      %25 = stablehlo.add %23, %24 : tensor<1x7x1xf32>
      %26 = stablehlo.rsqrt %25 : tensor<1x7x1xf32>
      %27 = stablehlo.reshape %26 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %28 = stablehlo.broadcast_in_dim %27, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %29 = stablehlo.multiply %19, %28 : tensor<1x7x3072xf32>
      %30 = stablehlo.convert %29 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %31 = stablehlo.convert %30 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %32 = stablehlo.multiply %18, %31 : tensor<1x7x3072xf32>
      %33 = stablehlo.convert %32 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %34 = stablehlo.reshape %33 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %35 = stablehlo.reshape %arg38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
      %36 = stablehlo.reshape %35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %37 = stablehlo.transpose %36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %38 = stablehlo.dot_general %34, %37, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
      %39 = stablehlo.reshape %38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
      %40 = stablehlo.transpose %39, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
      %41 = stablehlo.convert %40 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
      %42 = stablehlo.reshape %arg35 : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %43 = stablehlo.reshape %42 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %44 = stablehlo.reshape %arg30 : (tensor<7xi64>) -> tensor<1x1x7xi64>
      %45 = stablehlo.reshape %44 : (tensor<1x1x7xi64>) -> tensor<7xi64>
      %46 = stablehlo.convert %44 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
      %47 = stablehlo.dot_general %43, %46, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
      %48 = stablehlo.transpose %47, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
      %49 = stablehlo.concatenate %48, %48, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
      %50 = stablehlo.cosine %49 : tensor<1x7x128xf32>
      %51 = stablehlo.convert %50 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
      %52 = stablehlo.convert %51 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
      %53 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
      %54 = stablehlo.multiply %41, %53 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
      %55 = stablehlo.convert %54 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
      %56 = stablehlo.slice %40 [0:1, 0:24, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
      %57 = stablehlo.negate %56 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x64xbf16>
      %58 = stablehlo.slice %40 [0:1, 0:24, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
      %59 = stablehlo.concatenate %57, %58, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
      %60 = stablehlo.convert %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
      %61 = stablehlo.sine %49 : tensor<1x7x128xf32>
      %62 = stablehlo.convert %61 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
      %63 = stablehlo.convert %62 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
      %64 = stablehlo.broadcast_in_dim %63, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
      %65 = stablehlo.multiply %60, %64 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
      %66 = stablehlo.convert %65 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
      %67 = stablehlo.add %55, %66 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xbf16>
      %68 = stablehlo.reshape %67 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
      %69 = stablehlo.compare  LT, %45, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
      %70 = stablehlo.broadcast_in_dim %arg31, dims = [] : (tensor<i64>) -> tensor<7xi64>
      %71 = stablehlo.add %45, %70 : tensor<7xi64>
      %72 = stablehlo.select %69, %71, %45 : tensor<7xi1>, tensor<7xi64>
      %73 = stablehlo.reshape %72 : (tensor<7xi64>) -> tensor<7x1xi64>
      %74 = stablehlo.reshape %arg36 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
      %75 = stablehlo.reshape %74 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
      %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
      %77 = stablehlo.dot_general %34, %76, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
      %78 = stablehlo.reshape %77 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
      %79 = stablehlo.transpose %78, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
      %80 = stablehlo.convert %79 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
      %81 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
      %82 = stablehlo.multiply %80, %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
      %83 = stablehlo.convert %82 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
      %84 = stablehlo.slice %79 [0:1, 0:8, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
      %85 = stablehlo.negate %84 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x64xbf16>
      %86 = stablehlo.slice %79 [0:1, 0:8, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
      %87 = stablehlo.concatenate %85, %86, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
      %88 = stablehlo.convert %87 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
      %89 = stablehlo.broadcast_in_dim %63, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
      %90 = stablehlo.multiply %88, %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
      %91 = stablehlo.convert %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
      %92 = stablehlo.add %83, %91 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xbf16>
      %93 = "stablehlo.scatter"(%arg37, %73, %92) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg42: tensor<bf16>, %arg43: tensor<bf16>):
        stablehlo.return %arg43 : tensor<bf16>
      }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
      %94 = stablehlo.broadcast_in_dim %93, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
      %95 = stablehlo.reshape %94 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
      %96 = stablehlo.transpose %95, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
      %97 = stablehlo.reshape %96 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
      %98 = stablehlo.dot_general %68, %97, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
      %99 = stablehlo.convert %98 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
      %100 = stablehlo.reshape %99 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
      %101 = stablehlo.broadcast_in_dim %arg34, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<1x24x7x1024xf32>
      %102 = stablehlo.multiply %100, %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
      %103 = stablehlo.convert %102 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
      %104 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
      %105 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
      %106 = stablehlo.subtract %104, %105 : tensor<7x1024xi64>
      %107 = stablehlo.compare  GE, %106, %2 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
      %108 = stablehlo.broadcast_in_dim %arg33, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
      %109 = stablehlo.select %107, %108, %1 : tensor<7x1024xi1>, tensor<7x1024xbf16>
      %110 = stablehlo.convert %109 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
      %111 = stablehlo.broadcast_in_dim %45, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
      %112 = stablehlo.compare  GT, %104, %111 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
      %113 = stablehlo.convert %112 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
      %114 = stablehlo.multiply %110, %113 : tensor<7x1024xf32>
      %115 = stablehlo.convert %114 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
      %116 = stablehlo.reshape %115 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
      %117 = stablehlo.broadcast_in_dim %116, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
      %118 = stablehlo.add %103, %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xbf16>
      %119 = stablehlo.convert %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
      %120 = stablehlo.reduce(%119 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
      %121 = stablehlo.broadcast_in_dim %120, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
      %122 = stablehlo.subtract %119, %121 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
      %123 = stablehlo.exponential %122 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
      %124 = stablehlo.reduce(%123 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
      %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
      %126 = stablehlo.divide %123, %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
      %127 = stablehlo.convert %126 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
      %128 = stablehlo.reshape %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
      %129 = stablehlo.reshape %arg26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
      %130 = stablehlo.reshape %129 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
      %131 = stablehlo.transpose %130, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
      %132 = stablehlo.dot_general %34, %131, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
      %133 = stablehlo.reshape %132 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
      %134 = stablehlo.transpose %133, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
      %135 = "stablehlo.scatter"(%arg32, %73, %134) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg42: tensor<bf16>, %arg43: tensor<bf16>):
        stablehlo.return %arg43 : tensor<bf16>
      }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
      %136 = stablehlo.broadcast_in_dim %135, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
      %137 = stablehlo.reshape %136 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
      %138 = stablehlo.dot_general %128, %137, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
      %139 = stablehlo.reshape %138 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
      %140 = stablehlo.transpose %139, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
      %141 = stablehlo.reshape %140 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
      %142 = stablehlo.reshape %arg25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
      %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %144 = stablehlo.transpose %143, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %145 = stablehlo.dot_general %141, %144, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
      %146 = sdy.all_reduce {"_axis_0"} %145 out_sharding=<@mesh, [{}, {}]> : tensor<7x3072xbf16>
      %147 = stablehlo.reshape %146 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %148 = stablehlo.add %14, %147 : tensor<1x7x3072xbf16>
      %149 = stablehlo.reshape %arg39 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
      %150 = stablehlo.convert %149 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %151 = stablehlo.reshape %150 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
      %152 = stablehlo.broadcast_in_dim %151, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %153 = stablehlo.convert %148 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %154 = stablehlo.power %153, %3 : tensor<1x7x3072xf32>
      %155 = stablehlo.reduce(%154 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %156 = stablehlo.multiply %155, %cst_3 : tensor<1x7xf32>
      %157 = stablehlo.reshape %156 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %158 = stablehlo.add %157, %24 : tensor<1x7x1xf32>
      %159 = stablehlo.rsqrt %158 : tensor<1x7x1xf32>
      %160 = stablehlo.reshape %159 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %161 = stablehlo.broadcast_in_dim %160, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %162 = stablehlo.multiply %153, %161 : tensor<1x7x3072xf32>
      %163 = stablehlo.convert %162 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %164 = stablehlo.convert %163 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %165 = stablehlo.multiply %152, %164 : tensor<1x7x3072xf32>
      %166 = stablehlo.convert %165 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %167 = stablehlo.reshape %166 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %168 = stablehlo.reshape %arg40 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
      %169 = stablehlo.reshape %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
      %170 = stablehlo.transpose %169, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
      %171 = stablehlo.dot_general %167, %170, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
      %172 = stablehlo.reshape %171 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
      %173 = stablehlo.convert %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
      %174 = stablehlo.logistic %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xbf16>
      %175 = stablehlo.convert %174 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
      %176 = stablehlo.multiply %173, %175 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
      %177 = stablehlo.convert %176 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
      %178 = stablehlo.convert %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
      %179 = stablehlo.reshape %arg24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
      %180 = stablehlo.reshape %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
      %181 = stablehlo.transpose %180, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
      %182 = stablehlo.dot_general %167, %181, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
      %183 = stablehlo.convert %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
      %184 = stablehlo.reshape %183 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
      %185 = stablehlo.multiply %178, %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
      %186 = stablehlo.convert %185 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
      %187 = stablehlo.reshape %186 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
      %188 = stablehlo.reshape %arg23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
      %189 = stablehlo.reshape %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
      %190 = stablehlo.transpose %189, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
      %191 = stablehlo.dot_general %187, %190, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
      %192 = sdy.all_reduce {"_axis_0"} %191 out_sharding=<@mesh, [{}, {}]> : tensor<7x3072xbf16>
      %193 = stablehlo.reshape %192 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %194 = stablehlo.add %148, %193 : tensor<1x7x3072xbf16>
      %195 = stablehlo.convert %194 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %196 = stablehlo.power %195, %3 : tensor<1x7x3072xf32>
      %197 = stablehlo.reduce(%196 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %198 = stablehlo.multiply %197, %cst_3 : tensor<1x7xf32>
      %199 = stablehlo.reshape %198 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %200 = stablehlo.add %199, %24 : tensor<1x7x1xf32>
      %201 = stablehlo.rsqrt %200 : tensor<1x7x1xf32>
      %202 = stablehlo.reshape %201 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %203 = stablehlo.broadcast_in_dim %202, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %204 = stablehlo.multiply %195, %203 : tensor<1x7x3072xf32>
      %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %206 = stablehlo.convert %205 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %207 = stablehlo.multiply %7, %206 : tensor<1x7x3072xf32>
      %208 = stablehlo.convert %207 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %209 = stablehlo.reshape %208 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %210 = stablehlo.reshape %arg21 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
      %211 = stablehlo.reshape %210 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
      %212 = stablehlo.transpose %211, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
      %213 = stablehlo.dot_general %209, %212, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
      %214 = stablehlo.reshape %213 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
      sdy.return %214 : tensor<1x7x128256xbf16>
    } : (tensor<128256x3072xbf16>, tensor<f32>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<1024x3072xbf16>, tensor<1x7xi64>, tensor<128256x3072xbf16>, tensor<3072xbf16>, tensor<7xi64>, tensor<i64>, tensor<1x8x1024x128xbf16>, tensor<bf16>, tensor<f32>, tensor<64xf32>, tensor<1024x3072xbf16>, tensor<1x8x1024x128xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>) -> tensor<1x7x128256xbf16>
    return %0 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump Before ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18, %arg19, %arg20) in_shardings=[<@mesh, [{}, {}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, []>, <@mesh, []>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{?}, {?}, {?}]>] manual_axes={} (%arg21: tensor<128256x3072xbf16>, %arg22: tensor<f32>, %arg23: tensor<3072x8192xbf16>, %arg24: tensor<8192x3072xbf16>, %arg25: tensor<3072x3072xbf16>, %arg26: tensor<1024x3072xbf16>, %arg27: tensor<1x7xi64>, %arg28: tensor<128256x3072xbf16>, %arg29: tensor<3072xbf16>, %arg30: tensor<7xi64>, %arg31: tensor<i64>, %arg32: tensor<1x8x1024x128xbf16>, %arg33: tensor<bf16>, %arg34: tensor<f32>, %arg35: tensor<64xf32>, %arg36: tensor<1024x3072xbf16>, %arg37: tensor<1x8x1024x128xbf16>, %arg38: tensor<3072x3072xbf16>, %arg39: tensor<3072xbf16>, %arg40: tensor<8192x3072xbf16>, %arg41: tensor<3072xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %c = stablehlo.constant dense<"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tensor<1024xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
      %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
      %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
      %c_5 = stablehlo.constant dense<1> : tensor<i64>
      %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
      %2 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
      %3 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
      %4 = stablehlo.reshape %arg41 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
      %5 = stablehlo.convert %4 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %6 = stablehlo.reshape %5 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
      %7 = stablehlo.broadcast_in_dim %6, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %8 = stablehlo.reshape %arg28 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
      %9 = stablehlo.reshape %8 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
      %10 = stablehlo.reshape %arg27 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
      %11 = stablehlo.convert %10 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
      %12 = stablehlo.reshape %11 : (tensor<1x1x7xui32>) -> tensor<7xui32>
      %13 = "stablehlo.gather"(%9, %12) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
      %14 = stablehlo.reshape %13 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %15 = stablehlo.reshape %arg29 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
      %16 = stablehlo.convert %15 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %17 = stablehlo.reshape %16 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
      %18 = stablehlo.broadcast_in_dim %17, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %19 = stablehlo.convert %14 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %20 = stablehlo.power %19, %3 : tensor<1x7x3072xf32>
      %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %22 = stablehlo.multiply %21, %cst_3 : tensor<1x7xf32>
      %23 = stablehlo.reshape %22 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %24 = stablehlo.broadcast_in_dim %arg22, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
      %25 = stablehlo.add %23, %24 : tensor<1x7x1xf32>
      %26 = stablehlo.rsqrt %25 : tensor<1x7x1xf32>
      %27 = stablehlo.reshape %26 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %28 = stablehlo.broadcast_in_dim %27, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %29 = stablehlo.multiply %19, %28 : tensor<1x7x3072xf32>
      %30 = stablehlo.convert %29 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %31 = stablehlo.convert %30 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %32 = stablehlo.multiply %18, %31 : tensor<1x7x3072xf32>
      %33 = stablehlo.convert %32 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %34 = stablehlo.reshape %33 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %35 = stablehlo.reshape %arg38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
      %36 = stablehlo.reshape %35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %37 = stablehlo.transpose %36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %38 = stablehlo.dot_general %34, %37, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
      %39 = stablehlo.reshape %38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
      %40 = stablehlo.transpose %39, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
      %41 = stablehlo.convert %40 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
      %42 = stablehlo.reshape %arg35 : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %43 = stablehlo.reshape %42 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %44 = stablehlo.reshape %arg30 : (tensor<7xi64>) -> tensor<1x1x7xi64>
      %45 = stablehlo.reshape %44 : (tensor<1x1x7xi64>) -> tensor<7xi64>
      %46 = stablehlo.convert %44 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
      %47 = stablehlo.dot_general %43, %46, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
      %48 = stablehlo.transpose %47, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
      %49 = stablehlo.concatenate %48, %48, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
      %50 = stablehlo.cosine %49 : tensor<1x7x128xf32>
      %51 = stablehlo.convert %50 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
      %52 = stablehlo.convert %51 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
      %53 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
      %54 = stablehlo.multiply %41, %53 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
      %55 = stablehlo.convert %54 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
      %56 = stablehlo.slice %40 [0:1, 0:24, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
      %57 = stablehlo.negate %56 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x64xbf16>
      %58 = stablehlo.slice %40 [0:1, 0:24, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
      %59 = stablehlo.concatenate %57, %58, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
      %60 = stablehlo.convert %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
      %61 = stablehlo.sine %49 : tensor<1x7x128xf32>
      %62 = stablehlo.convert %61 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
      %63 = stablehlo.convert %62 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
      %64 = stablehlo.broadcast_in_dim %63, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
      %65 = stablehlo.multiply %60, %64 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
      %66 = stablehlo.convert %65 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
      %67 = stablehlo.add %55, %66 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xbf16>
      %68 = stablehlo.reshape %67 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
      %69 = stablehlo.compare  LT, %45, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
      %70 = stablehlo.broadcast_in_dim %arg31, dims = [] : (tensor<i64>) -> tensor<7xi64>
      %71 = stablehlo.add %45, %70 : tensor<7xi64>
      %72 = stablehlo.select %69, %71, %45 : tensor<7xi1>, tensor<7xi64>
      %73 = stablehlo.reshape %72 : (tensor<7xi64>) -> tensor<7x1xi64>
      %74 = stablehlo.reshape %arg36 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
      %75 = stablehlo.reshape %74 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
      %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
      %77 = stablehlo.dot_general %34, %76, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
      %78 = stablehlo.reshape %77 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
      %79 = stablehlo.transpose %78, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
      %80 = stablehlo.convert %79 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
      %81 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
      %82 = stablehlo.multiply %80, %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
      %83 = stablehlo.convert %82 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
      %84 = stablehlo.slice %79 [0:1, 0:8, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
      %85 = stablehlo.negate %84 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x64xbf16>
      %86 = stablehlo.slice %79 [0:1, 0:8, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
      %87 = stablehlo.concatenate %85, %86, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
      %88 = stablehlo.convert %87 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
      %89 = stablehlo.broadcast_in_dim %63, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
      %90 = stablehlo.multiply %88, %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
      %91 = stablehlo.convert %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
      %92 = stablehlo.add %83, %91 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xbf16>
      %93 = "stablehlo.scatter"(%arg37, %73, %92) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg42: tensor<bf16>, %arg43: tensor<bf16>):
        stablehlo.return %arg43 : tensor<bf16>
      }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
      %94 = stablehlo.broadcast_in_dim %93, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
      %95 = stablehlo.reshape %94 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
      %96 = stablehlo.transpose %95, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
      %97 = stablehlo.reshape %96 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
      %98 = stablehlo.dot_general %68, %97, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
      %99 = stablehlo.convert %98 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
      %100 = stablehlo.reshape %99 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
      %101 = stablehlo.broadcast_in_dim %arg34, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<1x24x7x1024xf32>
      %102 = stablehlo.multiply %100, %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
      %103 = stablehlo.convert %102 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
      %104 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
      %105 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
      %106 = stablehlo.subtract %104, %105 : tensor<7x1024xi64>
      %107 = stablehlo.compare  GE, %106, %2 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
      %108 = stablehlo.broadcast_in_dim %arg33, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
      %109 = stablehlo.select %107, %108, %1 : tensor<7x1024xi1>, tensor<7x1024xbf16>
      %110 = stablehlo.convert %109 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
      %111 = stablehlo.broadcast_in_dim %45, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
      %112 = stablehlo.compare  GT, %104, %111 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
      %113 = stablehlo.convert %112 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
      %114 = stablehlo.multiply %110, %113 : tensor<7x1024xf32>
      %115 = stablehlo.convert %114 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
      %116 = stablehlo.reshape %115 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
      %117 = stablehlo.broadcast_in_dim %116, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
      %118 = stablehlo.add %103, %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xbf16>
      %119 = stablehlo.convert %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
      %120 = stablehlo.reduce(%119 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
      %121 = stablehlo.broadcast_in_dim %120, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
      %122 = stablehlo.subtract %119, %121 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
      %123 = stablehlo.exponential %122 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
      %124 = stablehlo.reduce(%123 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
      %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
      %126 = stablehlo.divide %123, %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
      %127 = stablehlo.convert %126 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
      %128 = stablehlo.reshape %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
      %129 = stablehlo.reshape %arg26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
      %130 = stablehlo.reshape %129 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
      %131 = stablehlo.transpose %130, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
      %132 = stablehlo.dot_general %34, %131, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
      %133 = stablehlo.reshape %132 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
      %134 = stablehlo.transpose %133, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
      %135 = "stablehlo.scatter"(%arg32, %73, %134) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg42: tensor<bf16>, %arg43: tensor<bf16>):
        stablehlo.return %arg43 : tensor<bf16>
      }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
      %136 = stablehlo.broadcast_in_dim %135, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
      %137 = stablehlo.reshape %136 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
      %138 = stablehlo.dot_general %128, %137, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
      %139 = stablehlo.reshape %138 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
      %140 = stablehlo.transpose %139, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
      %141 = stablehlo.reshape %140 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
      %142 = stablehlo.reshape %arg25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
      %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %144 = stablehlo.transpose %143, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %145 = stablehlo.dot_general %141, %144, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
      %146 = sdy.all_reduce {"_axis_0"} %145 out_sharding=<@mesh, [{}, {}]> : tensor<7x3072xbf16>
      %147 = stablehlo.reshape %146 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %148 = stablehlo.add %14, %147 : tensor<1x7x3072xbf16>
      %149 = stablehlo.reshape %arg39 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
      %150 = stablehlo.convert %149 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %151 = stablehlo.reshape %150 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
      %152 = stablehlo.broadcast_in_dim %151, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %153 = stablehlo.convert %148 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %154 = stablehlo.power %153, %3 : tensor<1x7x3072xf32>
      %155 = stablehlo.reduce(%154 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %156 = stablehlo.multiply %155, %cst_3 : tensor<1x7xf32>
      %157 = stablehlo.reshape %156 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %158 = stablehlo.add %157, %24 : tensor<1x7x1xf32>
      %159 = stablehlo.rsqrt %158 : tensor<1x7x1xf32>
      %160 = stablehlo.reshape %159 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %161 = stablehlo.broadcast_in_dim %160, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %162 = stablehlo.multiply %153, %161 : tensor<1x7x3072xf32>
      %163 = stablehlo.convert %162 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %164 = stablehlo.convert %163 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %165 = stablehlo.multiply %152, %164 : tensor<1x7x3072xf32>
      %166 = stablehlo.convert %165 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %167 = stablehlo.reshape %166 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %168 = stablehlo.reshape %arg40 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
      %169 = stablehlo.reshape %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
      %170 = stablehlo.transpose %169, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
      %171 = stablehlo.dot_general %167, %170, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
      %172 = stablehlo.reshape %171 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
      %173 = stablehlo.convert %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
      %174 = stablehlo.logistic %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xbf16>
      %175 = stablehlo.convert %174 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
      %176 = stablehlo.multiply %173, %175 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
      %177 = stablehlo.convert %176 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
      %178 = stablehlo.convert %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
      %179 = stablehlo.reshape %arg24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
      %180 = stablehlo.reshape %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
      %181 = stablehlo.transpose %180, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
      %182 = stablehlo.dot_general %167, %181, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
      %183 = stablehlo.convert %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
      %184 = stablehlo.reshape %183 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
      %185 = stablehlo.multiply %178, %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
      %186 = stablehlo.convert %185 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
      %187 = stablehlo.reshape %186 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
      %188 = stablehlo.reshape %arg23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
      %189 = stablehlo.reshape %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
      %190 = stablehlo.transpose %189, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
      %191 = stablehlo.dot_general %187, %190, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
      %192 = sdy.all_reduce {"_axis_0"} %191 out_sharding=<@mesh, [{}, {}]> : tensor<7x3072xbf16>
      %193 = stablehlo.reshape %192 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %194 = stablehlo.add %148, %193 : tensor<1x7x3072xbf16>
      %195 = stablehlo.convert %194 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %196 = stablehlo.power %195, %3 : tensor<1x7x3072xf32>
      %197 = stablehlo.reduce(%196 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %198 = stablehlo.multiply %197, %cst_3 : tensor<1x7xf32>
      %199 = stablehlo.reshape %198 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %200 = stablehlo.add %199, %24 : tensor<1x7x1xf32>
      %201 = stablehlo.rsqrt %200 : tensor<1x7x1xf32>
      %202 = stablehlo.reshape %201 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %203 = stablehlo.broadcast_in_dim %202, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %204 = stablehlo.multiply %195, %203 : tensor<1x7x3072xf32>
      %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %206 = stablehlo.convert %205 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %207 = stablehlo.multiply %7, %206 : tensor<1x7x3072xf32>
      %208 = stablehlo.convert %207 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %209 = stablehlo.reshape %208 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %210 = stablehlo.reshape %arg21 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
      %211 = stablehlo.reshape %210 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
      %212 = stablehlo.transpose %211, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
      %213 = stablehlo.dot_general %209, %212, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
      %214 = stablehlo.reshape %213 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
      sdy.return %214 : tensor<1x7x128256xbf16>
    } : (tensor<128256x3072xbf16>, tensor<f32>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<1024x3072xbf16>, tensor<1x7xi64>, tensor<128256x3072xbf16>, tensor<3072xbf16>, tensor<7xi64>, tensor<i64>, tensor<1x8x1024x128xbf16>, tensor<bf16>, tensor<f32>, tensor<64xf32>, tensor<1024x3072xbf16>, tensor<1x8x1024x128xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>) -> tensor<1x7x128256xbf16>
    return %0 : tensor<1x7x128256xbf16>
  }
}


// -----// IR Dump Before UpdateGlobalToLocalShapesPass (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
module @SyncTensorsGraph.448 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, %arg1: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg2: tensor<3072x8192xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, %arg3: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, %arg4: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, %arg5: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, %arg6: tensor<1x7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, %arg7: tensor<128256x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, %arg8: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, %arg9: tensor<7xi64> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg10: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, %arg11: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, %arg12: tensor<bf16> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, %arg13: tensor<f32> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, %arg14: tensor<64xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, %arg15: tensor<1024x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, %arg16: tensor<1x8x1024x128xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, %arg17: tensor<3072x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, %arg18: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, %arg19: tensor<8192x3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{"_axis_0"}, {}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, %arg20: tensor<3072xbf16> {sdy.sharding = #sdy.sharding<@mesh, [{}]>, ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}) -> (tensor<1x7x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18, %arg19, %arg20) in_shardings=[<@mesh, [{}, {}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, []>, <@mesh, []>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{?}, {?}, {?}]>] manual_axes={} (%arg21: tensor<128256x3072xbf16>, %arg22: tensor<f32>, %arg23: tensor<3072x8192xbf16>, %arg24: tensor<8192x3072xbf16>, %arg25: tensor<3072x3072xbf16>, %arg26: tensor<1024x3072xbf16>, %arg27: tensor<1x7xi64>, %arg28: tensor<128256x3072xbf16>, %arg29: tensor<3072xbf16>, %arg30: tensor<7xi64>, %arg31: tensor<i64>, %arg32: tensor<1x8x1024x128xbf16>, %arg33: tensor<bf16>, %arg34: tensor<f32>, %arg35: tensor<64xf32>, %arg36: tensor<1024x3072xbf16>, %arg37: tensor<1x8x1024x128xbf16>, %arg38: tensor<3072x3072xbf16>, %arg39: tensor<3072xbf16>, %arg40: tensor<8192x3072xbf16>, %arg41: tensor<3072xbf16>) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %c = stablehlo.constant dense<"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tensor<1024xi64>
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>
      %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
      %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x7xf32>
      %c_4 = stablehlo.constant dense<0> : tensor<7xi64>
      %c_5 = stablehlo.constant dense<1> : tensor<i64>
      %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<bf16>
      %1 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
      %2 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<i64>) -> tensor<7x1024xi64>
      %3 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x7x3072xf32>
      %4 = stablehlo.reshape %arg41 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
      %5 = stablehlo.convert %4 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %6 = stablehlo.reshape %5 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
      %7 = stablehlo.broadcast_in_dim %6, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %8 = stablehlo.reshape %arg28 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
      %9 = stablehlo.reshape %8 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
      %10 = stablehlo.reshape %arg27 : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
      %11 = stablehlo.convert %10 : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
      %12 = stablehlo.reshape %11 : (tensor<1x1x7xui32>) -> tensor<7xui32>
      %13 = "stablehlo.gather"(%9, %12) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
      %14 = stablehlo.reshape %13 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %15 = stablehlo.reshape %arg29 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
      %16 = stablehlo.convert %15 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %17 = stablehlo.reshape %16 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
      %18 = stablehlo.broadcast_in_dim %17, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %19 = stablehlo.convert %14 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %20 = stablehlo.power %19, %3 : tensor<1x7x3072xf32>
      %21 = stablehlo.reduce(%20 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %22 = stablehlo.multiply %21, %cst_3 : tensor<1x7xf32>
      %23 = stablehlo.reshape %22 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %24 = stablehlo.broadcast_in_dim %arg22, dims = [] : (tensor<f32>) -> tensor<1x7x1xf32>
      %25 = stablehlo.add %23, %24 : tensor<1x7x1xf32>
      %26 = stablehlo.rsqrt %25 : tensor<1x7x1xf32>
      %27 = stablehlo.reshape %26 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %28 = stablehlo.broadcast_in_dim %27, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %29 = stablehlo.multiply %19, %28 : tensor<1x7x3072xf32>
      %30 = stablehlo.convert %29 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %31 = stablehlo.convert %30 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %32 = stablehlo.multiply %18, %31 : tensor<1x7x3072xf32>
      %33 = stablehlo.convert %32 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %34 = stablehlo.reshape %33 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %35 = stablehlo.reshape %arg38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
      %36 = stablehlo.reshape %35 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %37 = stablehlo.transpose %36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %38 = stablehlo.dot_general %34, %37, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
      %39 = stablehlo.reshape %38 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x3072xbf16>) -> tensor<1x7x24x128xbf16>
      %40 = stablehlo.transpose %39, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x24x128xbf16>) -> tensor<1x24x7x128xbf16>
      %41 = stablehlo.convert %40 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
      %42 = stablehlo.reshape %arg35 : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %43 = stablehlo.reshape %42 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %44 = stablehlo.reshape %arg30 : (tensor<7xi64>) -> tensor<1x1x7xi64>
      %45 = stablehlo.reshape %44 : (tensor<1x1x7xi64>) -> tensor<7xi64>
      %46 = stablehlo.convert %44 : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
      %47 = stablehlo.dot_general %43, %46, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
      %48 = stablehlo.transpose %47, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
      %49 = stablehlo.concatenate %48, %48, dim = 2 : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
      %50 = stablehlo.cosine %49 : tensor<1x7x128xf32>
      %51 = stablehlo.convert %50 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
      %52 = stablehlo.convert %51 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
      %53 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
      %54 = stablehlo.multiply %41, %53 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
      %55 = stablehlo.convert %54 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
      %56 = stablehlo.slice %40 [0:1, 0:24, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
      %57 = stablehlo.negate %56 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x64xbf16>
      %58 = stablehlo.slice %40 [0:1, 0:24, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x64xbf16>
      %59 = stablehlo.concatenate %57, %58, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x64xbf16>, tensor<1x24x7x64xbf16>) -> tensor<1x24x7x128xbf16>
      %60 = stablehlo.convert %59 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<1x24x7x128xf32>
      %61 = stablehlo.sine %49 : tensor<1x7x128xf32>
      %62 = stablehlo.convert %61 : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
      %63 = stablehlo.convert %62 : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
      %64 = stablehlo.broadcast_in_dim %63, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x24x7x128xf32>
      %65 = stablehlo.multiply %60, %64 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xf32>
      %66 = stablehlo.convert %65 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xf32>) -> tensor<1x24x7x128xbf16>
      %67 = stablehlo.add %55, %66 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x128xbf16>
      %68 = stablehlo.reshape %67 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x128xbf16>) -> tensor<24x7x128xbf16>
      %69 = stablehlo.compare  LT, %45, %c_4 : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
      %70 = stablehlo.broadcast_in_dim %arg31, dims = [] : (tensor<i64>) -> tensor<7xi64>
      %71 = stablehlo.add %45, %70 : tensor<7xi64>
      %72 = stablehlo.select %69, %71, %45 : tensor<7xi1>, tensor<7xi64>
      %73 = stablehlo.reshape %72 : (tensor<7xi64>) -> tensor<7x1xi64>
      %74 = stablehlo.reshape %arg36 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
      %75 = stablehlo.reshape %74 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
      %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
      %77 = stablehlo.dot_general %34, %76, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
      %78 = stablehlo.reshape %77 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
      %79 = stablehlo.transpose %78, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
      %80 = stablehlo.convert %79 {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
      %81 = stablehlo.broadcast_in_dim %52, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
      %82 = stablehlo.multiply %80, %81 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
      %83 = stablehlo.convert %82 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
      %84 = stablehlo.slice %79 [0:1, 0:8, 0:7, 64:128] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
      %85 = stablehlo.negate %84 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x64xbf16>
      %86 = stablehlo.slice %79 [0:1, 0:8, 0:7, 0:64] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x64xbf16>
      %87 = stablehlo.concatenate %85, %86, dim = 3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x64xbf16>, tensor<1x8x7x64xbf16>) -> tensor<1x8x7x128xbf16>
      %88 = stablehlo.convert %87 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xbf16>) -> tensor<1x8x7x128xf32>
      %89 = stablehlo.broadcast_in_dim %63, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x128xf32>) -> tensor<1x8x7x128xf32>
      %90 = stablehlo.multiply %88, %89 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xf32>
      %91 = stablehlo.convert %90 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x7x128xf32>) -> tensor<1x8x7x128xbf16>
      %92 = stablehlo.add %83, %91 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x8x7x128xbf16>
      %93 = "stablehlo.scatter"(%arg37, %73, %92) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg42: tensor<bf16>, %arg43: tensor<bf16>):
        stablehlo.return %arg43 : tensor<bf16>
      }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
      %94 = stablehlo.broadcast_in_dim %93, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
      %95 = stablehlo.reshape %94 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
      %96 = stablehlo.transpose %95, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
      %97 = stablehlo.reshape %96 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
      %98 = stablehlo.dot_general %68, %97, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
      %99 = stablehlo.convert %98 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
      %100 = stablehlo.reshape %99 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
      %101 = stablehlo.broadcast_in_dim %arg34, dims = [] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<f32>) -> tensor<1x24x7x1024xf32>
      %102 = stablehlo.multiply %100, %101 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
      %103 = stablehlo.convert %102 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
      %104 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<1024xi64>) -> tensor<7x1024xi64>
      %105 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
      %106 = stablehlo.subtract %104, %105 : tensor<7x1024xi64>
      %107 = stablehlo.compare  GE, %106, %2 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
      %108 = stablehlo.broadcast_in_dim %arg33, dims = [] : (tensor<bf16>) -> tensor<7x1024xbf16>
      %109 = stablehlo.select %107, %108, %1 : tensor<7x1024xi1>, tensor<7x1024xbf16>
      %110 = stablehlo.convert %109 : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
      %111 = stablehlo.broadcast_in_dim %45, dims = [0] : (tensor<7xi64>) -> tensor<7x1024xi64>
      %112 = stablehlo.compare  GT, %104, %111 : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
      %113 = stablehlo.convert %112 : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
      %114 = stablehlo.multiply %110, %113 : tensor<7x1024xf32>
      %115 = stablehlo.convert %114 : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
      %116 = stablehlo.reshape %115 : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
      %117 = stablehlo.broadcast_in_dim %116, dims = [0, 2, 3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
      %118 = stablehlo.add %103, %117 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xbf16>
      %119 = stablehlo.convert %118 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
      %120 = stablehlo.reduce(%119 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
      %121 = stablehlo.broadcast_in_dim %120, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
      %122 = stablehlo.subtract %119, %121 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
      %123 = stablehlo.exponential %122 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
      %124 = stablehlo.reduce(%123 init: %cst) applies stablehlo.add across dimensions = [3] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
      %125 = stablehlo.broadcast_in_dim %124, dims = [0, 1, 2] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
      %126 = stablehlo.divide %123, %125 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : tensor<1x24x7x1024xf32>
      %127 = stablehlo.convert %126 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
      %128 = stablehlo.reshape %127 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
      %129 = stablehlo.reshape %arg26 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16>
      %130 = stablehlo.reshape %129 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
      %131 = stablehlo.transpose %130, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
      %132 = stablehlo.dot_general %34, %131, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
      %133 = stablehlo.reshape %132 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>} : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
      %134 = stablehlo.transpose %133, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
      %135 = "stablehlo.scatter"(%arg32, %73, %134) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg42: tensor<bf16>, %arg43: tensor<bf16>):
        stablehlo.return %arg43 : tensor<bf16>
      }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
      %136 = stablehlo.broadcast_in_dim %135, dims = [0, 1, 3, 4] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
      %137 = stablehlo.reshape %136 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
      %138 = stablehlo.dot_general %128, %137, batching_dims = [0] x [0], contracting_dims = [2] x [1] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
      %139 = stablehlo.reshape %138 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
      %140 = stablehlo.transpose %139, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
      %141 = stablehlo.reshape %140 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
      %142 = stablehlo.reshape %arg25 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16>
      %143 = stablehlo.reshape %142 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %144 = stablehlo.transpose %143, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %145 = stablehlo.dot_general %141, %144, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
      %146 = sdy.all_reduce {"_axis_0"} %145 out_sharding=<@mesh, [{}, {}]> : tensor<7x3072xbf16>
      %147 = stablehlo.reshape %146 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %148 = stablehlo.add %14, %147 : tensor<1x7x3072xbf16>
      %149 = stablehlo.reshape %arg39 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
      %150 = stablehlo.convert %149 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %151 = stablehlo.reshape %150 : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
      %152 = stablehlo.broadcast_in_dim %151, dims = [2] : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %153 = stablehlo.convert %148 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %154 = stablehlo.power %153, %3 : tensor<1x7x3072xf32>
      %155 = stablehlo.reduce(%154 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %156 = stablehlo.multiply %155, %cst_3 : tensor<1x7xf32>
      %157 = stablehlo.reshape %156 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %158 = stablehlo.add %157, %24 : tensor<1x7x1xf32>
      %159 = stablehlo.rsqrt %158 : tensor<1x7x1xf32>
      %160 = stablehlo.reshape %159 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %161 = stablehlo.broadcast_in_dim %160, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %162 = stablehlo.multiply %153, %161 : tensor<1x7x3072xf32>
      %163 = stablehlo.convert %162 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %164 = stablehlo.convert %163 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %165 = stablehlo.multiply %152, %164 : tensor<1x7x3072xf32>
      %166 = stablehlo.convert %165 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %167 = stablehlo.reshape %166 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %168 = stablehlo.reshape %arg40 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
      %169 = stablehlo.reshape %168 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
      %170 = stablehlo.transpose %169, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
      %171 = stablehlo.dot_general %167, %170, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
      %172 = stablehlo.reshape %171 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
      %173 = stablehlo.convert %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
      %174 = stablehlo.logistic %172 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xbf16>
      %175 = stablehlo.convert %174 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
      %176 = stablehlo.multiply %173, %175 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
      %177 = stablehlo.convert %176 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
      %178 = stablehlo.convert %177 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
      %179 = stablehlo.reshape %arg24 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}]>]>} : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16>
      %180 = stablehlo.reshape %179 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>} : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
      %181 = stablehlo.transpose %180, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
      %182 = stablehlo.dot_general %167, %181, contracting_dims = [1] x [0] {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
      %183 = stablehlo.convert %182 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
      %184 = stablehlo.reshape %183 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
      %185 = stablehlo.multiply %178, %184 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : tensor<1x7x8192xf32>
      %186 = stablehlo.convert %185 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
      %187 = stablehlo.reshape %186 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
      %188 = stablehlo.reshape %arg23 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {"_axis_0", ?}]>]>} : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16>
      %189 = stablehlo.reshape %188 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}]>]>} : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
      %190 = stablehlo.transpose %189, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"_axis_0", ?}, {?}]>]>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
      %191 = stablehlo.dot_general %187, %190, contracting_dims = [1] x [0] : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
      %192 = sdy.all_reduce {"_axis_0"} %191 out_sharding=<@mesh, [{}, {}]> : tensor<7x3072xbf16>
      %193 = stablehlo.reshape %192 : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %194 = stablehlo.add %148, %193 : tensor<1x7x3072xbf16>
      %195 = stablehlo.convert %194 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %196 = stablehlo.power %195, %3 : tensor<1x7x3072xf32>
      %197 = stablehlo.reduce(%196 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %198 = stablehlo.multiply %197, %cst_3 : tensor<1x7xf32>
      %199 = stablehlo.reshape %198 : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %200 = stablehlo.add %199, %24 : tensor<1x7x1xf32>
      %201 = stablehlo.rsqrt %200 : tensor<1x7x1xf32>
      %202 = stablehlo.reshape %201 : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %203 = stablehlo.broadcast_in_dim %202, dims = [0, 1] : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %204 = stablehlo.multiply %195, %203 : tensor<1x7x3072xf32>
      %205 = stablehlo.convert %204 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %206 = stablehlo.convert %205 : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %207 = stablehlo.multiply %7, %206 : tensor<1x7x3072xf32>
      %208 = stablehlo.convert %207 : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %209 = stablehlo.reshape %208 : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %210 = stablehlo.reshape %arg21 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
      %211 = stablehlo.reshape %210 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
      %212 = stablehlo.transpose %211, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
      %213 = stablehlo.dot_general %209, %212, contracting_dims = [1] x [0] : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
      %214 = stablehlo.reshape %213 : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
      sdy.return %214 : tensor<1x7x128256xbf16>
    } : (tensor<128256x3072xbf16>, tensor<f32>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<1024x3072xbf16>, tensor<1x7xi64>, tensor<128256x3072xbf16>, tensor<3072xbf16>, tensor<7xi64>, tensor<i64>, tensor<1x8x1024x128xbf16>, tensor<bf16>, tensor<f32>, tensor<64xf32>, tensor<1024x3072xbf16>, tensor<1x8x1024x128xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>) -> tensor<1x7x128256xbf16>
    return %0 : tensor<1x7x128256xbf16>
  }
}


loc("scatter.251"): error: Scatter operation is not supported in stablehlo-pipeline for meshes not 1x1: https://github.com/tenstorrent/tt-mlir/issues/3496.
loc("scatter.251"): error: Could not updated attribute dictionary for operation
loc("scatter.251"): error: Could not create a new operation with updated shapes
error: Could not update shapes based on their tensor sharding attributes
// -----// IR Dump After UpdateGlobalToLocalShapesPass Failed (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.448) //----- //
"builtin.module"() <{sym_name = "SyncTensorsGraph.448"}> ({
  "sdy.mesh"() <{mesh = #sdy.mesh<["_axis_0_updated"=1, "_axis_0"=2]>, sym_name = "mesh"}> : () -> ()
  "func.func"() <{arg_attrs = [{ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"}, {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}, {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_1"}, {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"}, {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_2"}, {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_3"}, {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}, {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"}], function_type = (tensor<128256x3072xbf16>, tensor<f32>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<1024x3072xbf16>, tensor<1x7xi64>, tensor<128256x3072xbf16>, tensor<3072xbf16>, tensor<7xi64>, tensor<i64>, tensor<1x8x1024x128xbf16>, tensor<bf16>, tensor<f32>, tensor<64xf32>, tensor<1024x3072xbf16>, tensor<1x8x1024x128xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>) -> tensor<1x7x128256xbf16>, res_attrs = [{ttcore.shard_status = #ttcore.shard_status<unsharded>}], sym_name = "main"}> ({
  ^bb0(%arg0: tensor<128256x3072xbf16>, %arg1: tensor<f32>, %arg2: tensor<3072x8192xbf16>, %arg3: tensor<8192x3072xbf16>, %arg4: tensor<3072x3072xbf16>, %arg5: tensor<1024x3072xbf16>, %arg6: tensor<1x7xi64>, %arg7: tensor<128256x3072xbf16>, %arg8: tensor<3072xbf16>, %arg9: tensor<7xi64>, %arg10: tensor<i64>, %arg11: tensor<1x8x1024x128xbf16>, %arg12: tensor<bf16>, %arg13: tensor<f32>, %arg14: tensor<64xf32>, %arg15: tensor<1024x3072xbf16>, %arg16: tensor<1x8x1024x128xbf16>, %arg17: tensor<3072x3072xbf16>, %arg18: tensor<3072xbf16>, %arg19: tensor<8192x3072xbf16>, %arg20: tensor<3072xbf16>):
    %0 = "sdy.manual_computation"(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18, %arg19, %arg20) <{in_shardings = #sdy.sharding_per_value<[<@mesh, [{}, {}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, []>, <@mesh, []>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>]>, manual_axes = #sdy<manual_axes{"_axis_0_updated", "_axis_0"}>, out_shardings = #sdy.sharding_per_value<[<@mesh, [{?}, {?}, {?}]>]>}> ({
    ^bb0(%arg21: tensor<128256x3072xbf16>, %arg22: tensor<f32>, %arg23: tensor<3072x4096xbf16>, %arg24: tensor<4096x3072xbf16>, %arg25: tensor<3072x1536xbf16>, %arg26: tensor<512x3072xbf16>, %arg27: tensor<1x7xi64>, %arg28: tensor<128256x3072xbf16>, %arg29: tensor<3072xbf16>, %arg30: tensor<7xi64>, %arg31: tensor<i64>, %arg32: tensor<1x4x1024x128xbf16>, %arg33: tensor<bf16>, %arg34: tensor<f32>, %arg35: tensor<64xf32>, %arg36: tensor<512x3072xbf16>, %arg37: tensor<1x4x1024x128xbf16>, %arg38: tensor<1536x3072xbf16>, %arg39: tensor<3072xbf16>, %arg40: tensor<4096x3072xbf16>, %arg41: tensor<3072xbf16>):
      %1 = "stablehlo.constant"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32>
      %2 = "stablehlo.constant"() <{value = dense<"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tensor<1024xi64>}> : () -> tensor<1024xi64>
      %3 = "stablehlo.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6]> : tensor<7xi64>}> : () -> tensor<7xi64>
      %4 = "stablehlo.constant"() <{value = dense<0xFF800000> : tensor<f32>}> : () -> tensor<f32>
      %5 = "stablehlo.constant"() <{value = dense<2.000000e+00> : tensor<f32>}> : () -> tensor<f32>
      %6 = "stablehlo.constant"() <{value = dense<3.25520843E-4> : tensor<1x7xf32>}> : () -> tensor<1x7xf32>
      %7 = "stablehlo.constant"() <{value = dense<0> : tensor<7xi64>}> : () -> tensor<7xi64>
      %8 = "stablehlo.constant"() <{value = dense<1> : tensor<i64>}> : () -> tensor<i64>
      %9 = "stablehlo.constant"() <{value = dense<0.000000e+00> : tensor<bf16>}> : () -> tensor<bf16>
      %10 = "stablehlo.broadcast_in_dim"(%9) <{broadcast_dimensions = array<i64>}> : (tensor<bf16>) -> tensor<7x1024xbf16>
      %11 = "stablehlo.broadcast_in_dim"(%8) <{broadcast_dimensions = array<i64>}> : (tensor<i64>) -> tensor<7x1024xi64>
      %12 = "stablehlo.broadcast_in_dim"(%5) <{broadcast_dimensions = array<i64>}> : (tensor<f32>) -> tensor<1x7x3072xf32>
      %13 = "stablehlo.reshape"(%arg41) : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
      %14 = "stablehlo.convert"(%13) : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %15 = "stablehlo.reshape"(%14) : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
      %16 = "stablehlo.broadcast_in_dim"(%15) <{broadcast_dimensions = array<i64: 2>}> : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %17 = "stablehlo.reshape"(%arg28) : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
      %18 = "stablehlo.reshape"(%17) : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
      %19 = "stablehlo.reshape"(%arg27) : (tensor<1x7xi64>) -> tensor<1x1x7xi64>
      %20 = "stablehlo.convert"(%19) : (tensor<1x1x7xi64>) -> tensor<1x1x7xui32>
      %21 = "stablehlo.reshape"(%20) : (tensor<1x1x7xui32>) -> tensor<7xui32>
      %22 = "stablehlo.gather"(%18, %21) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<7xui32>) -> tensor<7x3072xbf16>
      %23 = "stablehlo.reshape"(%22) : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %24 = "stablehlo.reshape"(%arg29) : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
      %25 = "stablehlo.convert"(%24) : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %26 = "stablehlo.reshape"(%25) : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
      %27 = "stablehlo.broadcast_in_dim"(%26) <{broadcast_dimensions = array<i64: 2>}> : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %28 = "stablehlo.convert"(%23) : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %29 = "stablehlo.power"(%28, %12) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
      %30 = "stablehlo.reduce"(%29, %1) <{dimensions = array<i64: 2>}> ({
      ^bb0(%arg58: tensor<f32>, %arg59: tensor<f32>):
        %230 = "stablehlo.add"(%arg58, %arg59) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%230) : (tensor<f32>) -> ()
      }) : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %31 = "stablehlo.multiply"(%30, %6) : (tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
      %32 = "stablehlo.reshape"(%31) : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %33 = "stablehlo.broadcast_in_dim"(%arg22) <{broadcast_dimensions = array<i64>}> : (tensor<f32>) -> tensor<1x7x1xf32>
      %34 = "stablehlo.add"(%32, %33) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
      %35 = "stablehlo.rsqrt"(%34) : (tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
      %36 = "stablehlo.reshape"(%35) : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %37 = "stablehlo.broadcast_in_dim"(%36) <{broadcast_dimensions = array<i64: 0, 1>}> : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %38 = "stablehlo.multiply"(%28, %37) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
      %39 = "stablehlo.convert"(%38) : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %40 = "stablehlo.convert"(%39) : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %41 = "stablehlo.multiply"(%27, %40) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
      %42 = "stablehlo.convert"(%41) : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %43 = "stablehlo.reshape"(%42) : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %44 = "stablehlo.reshape"(%arg38) : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16>
      %45 = "stablehlo.reshape"(%44) : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16>
      %46 = "stablehlo.transpose"(%45) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
      %47 = "stablehlo.dot_general"(%43, %46) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<7x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<7x1536xbf16>
      %48 = "stablehlo.reshape"(%47) : (tensor<7x1536xbf16>) -> tensor<1x7x12x128xbf16>
      %49 = "stablehlo.transpose"(%48) <{permutation = array<i64: 0, 2, 1, 3>}> {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,7,128]{3,1,2,0}"} : (tensor<1x7x12x128xbf16>) -> tensor<1x12x7x128xbf16>
      %50 = "stablehlo.convert"(%49) {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,24,7,128]{3,1,2,0}"} : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %51 = "stablehlo.reshape"(%arg35) : (tensor<64xf32>) -> tensor<1x1x64xf32>
      %52 = "stablehlo.reshape"(%51) : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
      %53 = "stablehlo.reshape"(%arg30) : (tensor<7xi64>) -> tensor<1x1x7xi64>
      %54 = "stablehlo.reshape"(%53) : (tensor<1x1x7xi64>) -> tensor<7xi64>
      %55 = "stablehlo.convert"(%53) : (tensor<1x1x7xi64>) -> tensor<1x1x7xf32>
      %56 = "stablehlo.dot_general"(%52, %55) <{dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>}> : (tensor<1x64x1xf32>, tensor<1x1x7xf32>) -> tensor<1x64x7xf32>
      %57 = "stablehlo.transpose"(%56) <{permutation = array<i64: 0, 2, 1>}> {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,7,64]{1,2,0}"} : (tensor<1x64x7xf32>) -> tensor<1x7x64xf32>
      %58 = "stablehlo.concatenate"(%57, %57) <{dimension = 2 : i64}> : (tensor<1x7x64xf32>, tensor<1x7x64xf32>) -> tensor<1x7x128xf32>
      %59 = "stablehlo.cosine"(%58) : (tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
      %60 = "stablehlo.convert"(%59) : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
      %61 = "stablehlo.convert"(%60) : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
      %62 = "stablehlo.broadcast_in_dim"(%61) <{broadcast_dimensions = array<i64: 0, 2, 3>}> : (tensor<1x7x128xf32>) -> tensor<1x12x7x128xf32>
      %63 = "stablehlo.multiply"(%50, %62) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
      %64 = "stablehlo.convert"(%63) : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %65 = "stablehlo.slice"(%49) <{limit_indices = array<i64: 1, 12, 7, 128>, start_indices = array<i64: 0, 0, 0, 64>, strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16>
      %66 = "stablehlo.negate"(%65) : (tensor<1x12x7x64xbf16>) -> tensor<1x12x7x64xbf16>
      %67 = "stablehlo.slice"(%49) <{limit_indices = array<i64: 1, 12, 7, 64>, start_indices = array<i64: 0, 0, 0, 0>, strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x64xbf16>
      %68 = "stablehlo.concatenate"(%66, %67) <{dimension = 3 : i64}> : (tensor<1x12x7x64xbf16>, tensor<1x12x7x64xbf16>) -> tensor<1x12x7x128xbf16>
      %69 = "stablehlo.convert"(%68) : (tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xf32>
      %70 = "stablehlo.sine"(%58) : (tensor<1x7x128xf32>) -> tensor<1x7x128xf32>
      %71 = "stablehlo.convert"(%70) : (tensor<1x7x128xf32>) -> tensor<1x7x128xbf16>
      %72 = "stablehlo.convert"(%71) : (tensor<1x7x128xbf16>) -> tensor<1x7x128xf32>
      %73 = "stablehlo.broadcast_in_dim"(%72) <{broadcast_dimensions = array<i64: 0, 2, 3>}> : (tensor<1x7x128xf32>) -> tensor<1x12x7x128xf32>
      %74 = "stablehlo.multiply"(%69, %73) : (tensor<1x12x7x128xf32>, tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xf32>
      %75 = "stablehlo.convert"(%74) : (tensor<1x12x7x128xf32>) -> tensor<1x12x7x128xbf16>
      %76 = "stablehlo.add"(%64, %75) : (tensor<1x12x7x128xbf16>, tensor<1x12x7x128xbf16>) -> tensor<1x12x7x128xbf16>
      %77 = "stablehlo.reshape"(%76) : (tensor<1x12x7x128xbf16>) -> tensor<12x7x128xbf16>
      %78 = "stablehlo.compare"(%54, %7) <{comparison_direction = #stablehlo<comparison_direction LT>}> : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi1>
      %79 = "stablehlo.broadcast_in_dim"(%arg31) <{broadcast_dimensions = array<i64>}> : (tensor<i64>) -> tensor<7xi64>
      %80 = "stablehlo.add"(%54, %79) : (tensor<7xi64>, tensor<7xi64>) -> tensor<7xi64>
      %81 = "stablehlo.select"(%78, %80, %54) : (tensor<7xi1>, tensor<7xi64>, tensor<7xi64>) -> tensor<7xi64>
      %82 = "stablehlo.reshape"(%81) : (tensor<7xi64>) -> tensor<7x1xi64>
      %83 = "stablehlo.reshape"(%arg36) : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
      %84 = "stablehlo.reshape"(%83) : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
      %85 = "stablehlo.transpose"(%84) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
      %86 = "stablehlo.dot_general"(%43, %85) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<7x3072xbf16>, tensor<3072x512xbf16>) -> tensor<7x512xbf16>
      %87 = "stablehlo.reshape"(%86) : (tensor<7x512xbf16>) -> tensor<1x7x4x128xbf16>
      %88 = "stablehlo.transpose"(%87) <{permutation = array<i64: 0, 2, 1, 3>}> {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x4x128xbf16>) -> tensor<1x4x7x128xbf16>
      %89 = "stablehlo.convert"(%88) {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[1,8,7,128]{3,1,2,0}"} : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32>
      %90 = "stablehlo.broadcast_in_dim"(%61) <{broadcast_dimensions = array<i64: 0, 2, 3>}> : (tensor<1x7x128xf32>) -> tensor<1x4x7x128xf32>
      %91 = "stablehlo.multiply"(%89, %90) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
      %92 = "stablehlo.convert"(%91) : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16>
      %93 = "stablehlo.slice"(%88) <{limit_indices = array<i64: 1, 4, 7, 128>, start_indices = array<i64: 0, 0, 0, 64>, strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16>
      %94 = "stablehlo.negate"(%93) : (tensor<1x4x7x64xbf16>) -> tensor<1x4x7x64xbf16>
      %95 = "stablehlo.slice"(%88) <{limit_indices = array<i64: 1, 4, 7, 64>, start_indices = array<i64: 0, 0, 0, 0>, strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x64xbf16>
      %96 = "stablehlo.concatenate"(%94, %95) <{dimension = 3 : i64}> : (tensor<1x4x7x64xbf16>, tensor<1x4x7x64xbf16>) -> tensor<1x4x7x128xbf16>
      %97 = "stablehlo.convert"(%96) : (tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xf32>
      %98 = "stablehlo.broadcast_in_dim"(%72) <{broadcast_dimensions = array<i64: 0, 2, 3>}> : (tensor<1x7x128xf32>) -> tensor<1x4x7x128xf32>
      %99 = "stablehlo.multiply"(%97, %98) : (tensor<1x4x7x128xf32>, tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xf32>
      %100 = "stablehlo.convert"(%99) : (tensor<1x4x7x128xf32>) -> tensor<1x4x7x128xbf16>
      %101 = "stablehlo.add"(%92, %100) : (tensor<1x4x7x128xbf16>, tensor<1x4x7x128xbf16>) -> tensor<1x4x7x128xbf16>
      %102 = "stablehlo.scatter"(%arg37, %82, %101) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg56: tensor<bf16>, %arg57: tensor<bf16>):
        "stablehlo.return"(%arg57) : (tensor<bf16>) -> ()
      }) : (tensor<1x4x1024x128xbf16>, tensor<7x1xi64>, tensor<1x4x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
      %103 = "stablehlo.broadcast_in_dim"(%102) <{broadcast_dimensions = array<i64: 0, 1, 3, 4>}> : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
      %104 = "stablehlo.reshape"(%103) : (tensor<1x8x3x1024x128xbf16>) -> tensor<1x24x1024x128xbf16>
      %105 = "stablehlo.transpose"(%104) <{permutation = array<i64: 0, 1, 3, 2>}> {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,1024]{2,3,1,0}"} : (tensor<1x24x1024x128xbf16>) -> tensor<1x24x128x1024xbf16>
      %106 = "stablehlo.reshape"(%105) : (tensor<1x24x128x1024xbf16>) -> tensor<24x128x1024xbf16>
      %107 = "stablehlo.dot_general"(%77, %106) <{dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>}> : (tensor<12x7x128xbf16>, tensor<24x128x1024xbf16>) -> tensor<24x7x1024xbf16>
      %108 = "stablehlo.convert"(%107) : (tensor<24x7x1024xbf16>) -> tensor<24x7x1024xf32>
      %109 = "stablehlo.reshape"(%108) : (tensor<24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
      %110 = "stablehlo.broadcast_in_dim"(%arg34) <{broadcast_dimensions = array<i64>}> : (tensor<f32>) -> tensor<1x24x7x1024xf32>
      %111 = "stablehlo.multiply"(%109, %110) : (tensor<1x24x7x1024xf32>, tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
      %112 = "stablehlo.convert"(%111) : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
      %113 = "stablehlo.broadcast_in_dim"(%2) <{broadcast_dimensions = array<i64: 1>}> : (tensor<1024xi64>) -> tensor<7x1024xi64>
      %114 = "stablehlo.broadcast_in_dim"(%3) <{broadcast_dimensions = array<i64: 0>}> : (tensor<7xi64>) -> tensor<7x1024xi64>
      %115 = "stablehlo.subtract"(%113, %114) : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi64>
      %116 = "stablehlo.compare"(%115, %11) <{comparison_direction = #stablehlo<comparison_direction GE>}> : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
      %117 = "stablehlo.broadcast_in_dim"(%arg33) <{broadcast_dimensions = array<i64>}> : (tensor<bf16>) -> tensor<7x1024xbf16>
      %118 = "stablehlo.select"(%116, %117, %10) : (tensor<7x1024xi1>, tensor<7x1024xbf16>, tensor<7x1024xbf16>) -> tensor<7x1024xbf16>
      %119 = "stablehlo.convert"(%118) : (tensor<7x1024xbf16>) -> tensor<7x1024xf32>
      %120 = "stablehlo.broadcast_in_dim"(%54) <{broadcast_dimensions = array<i64: 0>}> : (tensor<7xi64>) -> tensor<7x1024xi64>
      %121 = "stablehlo.compare"(%113, %120) <{comparison_direction = #stablehlo<comparison_direction GT>}> : (tensor<7x1024xi64>, tensor<7x1024xi64>) -> tensor<7x1024xi1>
      %122 = "stablehlo.convert"(%121) : (tensor<7x1024xi1>) -> tensor<7x1024xf32>
      %123 = "stablehlo.multiply"(%119, %122) : (tensor<7x1024xf32>, tensor<7x1024xf32>) -> tensor<7x1024xf32>
      %124 = "stablehlo.convert"(%123) : (tensor<7x1024xf32>) -> tensor<7x1024xbf16>
      %125 = "stablehlo.reshape"(%124) : (tensor<7x1024xbf16>) -> tensor<1x7x1024xbf16>
      %126 = "stablehlo.broadcast_in_dim"(%125) <{broadcast_dimensions = array<i64: 0, 2, 3>}> : (tensor<1x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
      %127 = "stablehlo.add"(%112, %126) : (tensor<1x24x7x1024xbf16>, tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xbf16>
      %128 = "stablehlo.convert"(%127) : (tensor<1x24x7x1024xbf16>) -> tensor<1x24x7x1024xf32>
      %129 = "stablehlo.reduce"(%128, %4) <{dimensions = array<i64: 3>}> ({
      ^bb0(%arg54: tensor<f32>, %arg55: tensor<f32>):
        %229 = "stablehlo.maximum"(%arg54, %arg55) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%229) : (tensor<f32>) -> ()
      }) : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
      %130 = "stablehlo.broadcast_in_dim"(%129) <{broadcast_dimensions = array<i64: 0, 1, 2>}> : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
      %131 = "stablehlo.subtract"(%128, %130) : (tensor<1x24x7x1024xf32>, tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
      %132 = "stablehlo.exponential"(%131) : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
      %133 = "stablehlo.reduce"(%132, %1) <{dimensions = array<i64: 3>}> ({
      ^bb0(%arg52: tensor<f32>, %arg53: tensor<f32>):
        %228 = "stablehlo.add"(%arg52, %arg53) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%228) : (tensor<f32>) -> ()
      }) : (tensor<1x24x7x1024xf32>, tensor<f32>) -> tensor<1x24x7xf32>
      %134 = "stablehlo.broadcast_in_dim"(%133) <{broadcast_dimensions = array<i64: 0, 1, 2>}> : (tensor<1x24x7xf32>) -> tensor<1x24x7x1024xf32>
      %135 = "stablehlo.divide"(%132, %134) : (tensor<1x24x7x1024xf32>, tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xf32>
      %136 = "stablehlo.convert"(%135) : (tensor<1x24x7x1024xf32>) -> tensor<1x24x7x1024xbf16>
      %137 = "stablehlo.reshape"(%136) : (tensor<1x24x7x1024xbf16>) -> tensor<24x7x1024xbf16>
      %138 = "stablehlo.reshape"(%arg26) : (tensor<512x3072xbf16>) -> tensor<1x1024x3072xbf16>
      %139 = "stablehlo.reshape"(%138) : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16>
      %140 = "stablehlo.transpose"(%139) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16>
      %141 = "stablehlo.dot_general"(%43, %140) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<7x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<7x1024xbf16>
      %142 = "stablehlo.reshape"(%141) : (tensor<7x1024xbf16>) -> tensor<1x7x8x128xbf16>
      %143 = "stablehlo.transpose"(%142) <{permutation = array<i64: 0, 2, 1, 3>}> {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,7,128]{3,1,2,0}"} : (tensor<1x7x8x128xbf16>) -> tensor<1x8x7x128xbf16>
      %144 = "stablehlo.scatter"(%arg32, %82, %143) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg50: tensor<bf16>, %arg51: tensor<bf16>):
        "stablehlo.return"(%arg51) : (tensor<bf16>) -> ()
      }) : (tensor<1x4x1024x128xbf16>, tensor<7x1xi64>, tensor<1x8x7x128xbf16>) -> tensor<1x8x1024x128xbf16>
      %145 = "stablehlo.broadcast_in_dim"(%144) <{broadcast_dimensions = array<i64: 0, 1, 3, 4>}> : (tensor<1x8x1024x128xbf16>) -> tensor<1x8x3x1024x128xbf16>
      %146 = "stablehlo.reshape"(%145) : (tensor<1x8x3x1024x128xbf16>) -> tensor<24x1024x128xbf16>
      %147 = "stablehlo.dot_general"(%137, %146) <{dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>}> : (tensor<24x7x1024xbf16>, tensor<24x1024x128xbf16>) -> tensor<24x7x128xbf16>
      %148 = "stablehlo.reshape"(%147) : (tensor<24x7x128xbf16>) -> tensor<1x24x7x128xbf16>
      %149 = "stablehlo.transpose"(%148) <{permutation = array<i64: 0, 2, 1, 3>}> {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,7,24,128]{3,1,2,0}"} : (tensor<1x24x7x128xbf16>) -> tensor<1x7x24x128xbf16>
      %150 = "stablehlo.reshape"(%149) : (tensor<1x7x24x128xbf16>) -> tensor<7x3072xbf16>
      %151 = "stablehlo.reshape"(%arg25) : (tensor<3072x1536xbf16>) -> tensor<1x3072x3072xbf16>
      %152 = "stablehlo.reshape"(%151) : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %153 = "stablehlo.transpose"(%152) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16>
      %154 = "stablehlo.dot_general"(%150, %153) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<7x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<7x3072xbf16>
      %155 = "stablehlo.all_reduce"(%154) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg48: tensor<bf16>, %arg49: tensor<bf16>):
        %227 = "stablehlo.add"(%arg48, %arg49) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%227) : (tensor<bf16>) -> ()
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %156 = "stablehlo.reshape"(%155) : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %157 = "stablehlo.add"(%23, %156) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %158 = "stablehlo.reshape"(%arg39) : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
      %159 = "stablehlo.convert"(%158) : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32>
      %160 = "stablehlo.reshape"(%159) : (tensor<1x1x3072xf32>) -> tensor<3072xf32>
      %161 = "stablehlo.broadcast_in_dim"(%160) <{broadcast_dimensions = array<i64: 2>}> : (tensor<3072xf32>) -> tensor<1x7x3072xf32>
      %162 = "stablehlo.convert"(%157) : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %163 = "stablehlo.power"(%162, %12) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
      %164 = "stablehlo.reduce"(%163, %1) <{dimensions = array<i64: 2>}> ({
      ^bb0(%arg46: tensor<f32>, %arg47: tensor<f32>):
        %226 = "stablehlo.add"(%arg46, %arg47) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%226) : (tensor<f32>) -> ()
      }) : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %165 = "stablehlo.multiply"(%164, %6) : (tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
      %166 = "stablehlo.reshape"(%165) : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %167 = "stablehlo.add"(%166, %33) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
      %168 = "stablehlo.rsqrt"(%167) : (tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
      %169 = "stablehlo.reshape"(%168) : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %170 = "stablehlo.broadcast_in_dim"(%169) <{broadcast_dimensions = array<i64: 0, 1>}> : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %171 = "stablehlo.multiply"(%162, %170) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
      %172 = "stablehlo.convert"(%171) : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %173 = "stablehlo.convert"(%172) : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %174 = "stablehlo.multiply"(%161, %173) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
      %175 = "stablehlo.convert"(%174) : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %176 = "stablehlo.reshape"(%175) : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %177 = "stablehlo.reshape"(%arg40) : (tensor<4096x3072xbf16>) -> tensor<1x8192x3072xbf16>
      %178 = "stablehlo.reshape"(%177) : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
      %179 = "stablehlo.transpose"(%178) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
      %180 = "stablehlo.dot_general"(%176, %179) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
      %181 = "stablehlo.reshape"(%180) : (tensor<7x8192xbf16>) -> tensor<1x7x8192xbf16>
      %182 = "stablehlo.convert"(%181) : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
      %183 = "stablehlo.logistic"(%181) : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xbf16>
      %184 = "stablehlo.convert"(%183) : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
      %185 = "stablehlo.multiply"(%182, %184) : (tensor<1x7x8192xf32>, tensor<1x7x8192xf32>) -> tensor<1x7x8192xf32>
      %186 = "stablehlo.convert"(%185) : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
      %187 = "stablehlo.convert"(%186) : (tensor<1x7x8192xbf16>) -> tensor<1x7x8192xf32>
      %188 = "stablehlo.reshape"(%arg24) : (tensor<4096x3072xbf16>) -> tensor<1x8192x3072xbf16>
      %189 = "stablehlo.reshape"(%188) : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16>
      %190 = "stablehlo.transpose"(%189) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16>
      %191 = "stablehlo.dot_general"(%176, %190) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<7x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<7x8192xbf16>
      %192 = "stablehlo.convert"(%191) : (tensor<7x8192xbf16>) -> tensor<7x8192xf32>
      %193 = "stablehlo.reshape"(%192) : (tensor<7x8192xf32>) -> tensor<1x7x8192xf32>
      %194 = "stablehlo.multiply"(%187, %193) : (tensor<1x7x8192xf32>, tensor<1x7x8192xf32>) -> tensor<1x7x8192xf32>
      %195 = "stablehlo.convert"(%194) : (tensor<1x7x8192xf32>) -> tensor<1x7x8192xbf16>
      %196 = "stablehlo.reshape"(%195) : (tensor<1x7x8192xbf16>) -> tensor<7x8192xbf16>
      %197 = "stablehlo.reshape"(%arg23) : (tensor<3072x4096xbf16>) -> tensor<1x3072x8192xbf16>
      %198 = "stablehlo.reshape"(%197) : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16>
      %199 = "stablehlo.transpose"(%198) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16>
      %200 = "stablehlo.dot_general"(%196, %199) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<7x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<7x3072xbf16>
      %201 = "stablehlo.all_reduce"(%200) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg44: tensor<bf16>, %arg45: tensor<bf16>):
        %225 = "stablehlo.add"(%arg44, %arg45) : (tensor<bf16>, tensor<bf16>) -> tensor<bf16>
        "stablehlo.return"(%225) : (tensor<bf16>) -> ()
      }) : (tensor<7x3072xbf16>) -> tensor<7x3072xbf16>
      %202 = "stablehlo.reshape"(%201) : (tensor<7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %203 = "stablehlo.add"(%157, %202) : (tensor<1x7x3072xbf16>, tensor<1x7x3072xbf16>) -> tensor<1x7x3072xbf16>
      %204 = "stablehlo.convert"(%203) : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %205 = "stablehlo.power"(%204, %12) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
      %206 = "stablehlo.reduce"(%205, %1) <{dimensions = array<i64: 2>}> ({
      ^bb0(%arg42: tensor<f32>, %arg43: tensor<f32>):
        %224 = "stablehlo.add"(%arg42, %arg43) : (tensor<f32>, tensor<f32>) -> tensor<f32>
        "stablehlo.return"(%224) : (tensor<f32>) -> ()
      }) : (tensor<1x7x3072xf32>, tensor<f32>) -> tensor<1x7xf32>
      %207 = "stablehlo.multiply"(%206, %6) : (tensor<1x7xf32>, tensor<1x7xf32>) -> tensor<1x7xf32>
      %208 = "stablehlo.reshape"(%207) : (tensor<1x7xf32>) -> tensor<1x7x1xf32>
      %209 = "stablehlo.add"(%208, %33) : (tensor<1x7x1xf32>, tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
      %210 = "stablehlo.rsqrt"(%209) : (tensor<1x7x1xf32>) -> tensor<1x7x1xf32>
      %211 = "stablehlo.reshape"(%210) : (tensor<1x7x1xf32>) -> tensor<1x7xf32>
      %212 = "stablehlo.broadcast_in_dim"(%211) <{broadcast_dimensions = array<i64: 0, 1>}> : (tensor<1x7xf32>) -> tensor<1x7x3072xf32>
      %213 = "stablehlo.multiply"(%204, %212) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
      %214 = "stablehlo.convert"(%213) : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %215 = "stablehlo.convert"(%214) : (tensor<1x7x3072xbf16>) -> tensor<1x7x3072xf32>
      %216 = "stablehlo.multiply"(%16, %215) : (tensor<1x7x3072xf32>, tensor<1x7x3072xf32>) -> tensor<1x7x3072xf32>
      %217 = "stablehlo.convert"(%216) : (tensor<1x7x3072xf32>) -> tensor<1x7x3072xbf16>
      %218 = "stablehlo.reshape"(%217) : (tensor<1x7x3072xbf16>) -> tensor<7x3072xbf16>
      %219 = "stablehlo.reshape"(%arg21) : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
      %220 = "stablehlo.reshape"(%219) : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
      %221 = "stablehlo.transpose"(%220) <{permutation = array<i64: 1, 0>}> {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
      %222 = "stablehlo.dot_general"(%218, %221) <{dot_dimension_numbers = #stablehlo.dot<lhs_contracting_dimensions = [1], rhs_contracting_dimensions = [0]>}> : (tensor<7x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<7x128256xbf16>
      %223 = "stablehlo.reshape"(%222) : (tensor<7x128256xbf16>) -> tensor<1x7x128256xbf16>
      "sdy.return"(%223) : (tensor<1x7x128256xbf16>) -> ()
    }) : (tensor<128256x3072xbf16>, tensor<f32>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<1024x3072xbf16>, tensor<1x7xi64>, tensor<128256x3072xbf16>, tensor<3072xbf16>, tensor<7xi64>, tensor<i64>, tensor<1x8x1024x128xbf16>, tensor<bf16>, tensor<f32>, tensor<64xf32>, tensor<1024x3072xbf16>, tensor<1x8x1024x128xbf16>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>) -> tensor<1x7x128256xbf16>
    "func.return"(%0) : (tensor<1x7x128256xbf16>) -> ()
  }) : () -> ()
}) {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} : () -> ()


2025-09-09 19:22:20.572 (   9.288s) [        56CD8000]      module_builder.cc:481    ERR| Failed to run stablehlo pipeline
2025-09-09 19:22:20.572 (   9.288s) [        56CD8000]      error_instance.cc:49       1| ErrorInstance::PJRT_Error_Message
2025-09-09 19:22:20.572 (   9.288s) [        56CD8000]      error_instance.cc:58       1| ErrorInstance::PJRT_Error_GetCode
2025-09-09 19:22:20.572 (   9.288s) [        56CD8000]      error_instance.cc:43       1| ErrorInstance::PJRT_Error_Destroy
Traceback (most recent call last):
  File "/localdev/jameszianxu/tt-xla/examples/pytorch/llama.py", line 165, in <module>
    llama()
  File "/localdev/jameszianxu/tt-xla/examples/pytorch/llama.py", line 150, in llama
    output: CausalLMOutputWithPast = model(**input_args)
                                     ^^^^^^^^^^^^^^^^^^^
  File "/localdev/jameszianxu/tt-xla/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1749, in _wrapped_call_impl
    return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/localdev/jameszianxu/tt-xla/venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 655, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/localdev/jameszianxu/tt-xla/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/localdev/jameszianxu/tt-xla/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 953, in wrapper
    @wraps(func)
  File "/localdev/jameszianxu/tt-xla/venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 838, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/localdev/jameszianxu/tt-xla/tt_torch/backend/backend.py", line 99, in __call__
    torch_xla._XLAC._xla_sync_multi(list(output), self.devices, wait=False)
ValueError: Error code: 13
2025-09-09 19:22:21.380 (  10.096s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.381 (  10.096s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.381 (  10.096s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.381 (  10.096s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.381 (  10.096s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.381 (  10.097s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.381 (  10.097s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.381 (  10.097s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.613 (  10.329s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.613 (  10.329s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.613 (  10.329s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.613 (  10.329s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.614 (  10.330s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.614 (  10.330s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.614 (  10.330s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.614 (  10.330s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.614 (  10.330s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.653 (  10.369s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.694 (  10.410s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.695 (  10.410s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.695 (  10.410s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.695 (  10.411s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.695 (  10.411s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.695 (  10.411s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.695 (  10.411s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.695 (  10.411s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.695 (  10.411s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.695 (  10.411s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.696 (  10.411s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.696 (  10.411s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.696 (  10.412s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.696 (  10.412s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.696 (  10.412s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.728 (  10.443s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.772 (  10.488s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.772 (  10.488s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.772 (  10.488s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.773 (  10.488s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.773 (  10.489s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.773 (  10.489s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.773 (  10.489s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.773 (  10.489s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.773 (  10.489s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.773 (  10.489s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.773 (  10.489s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.773 (  10.489s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.773 (  10.489s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.773 (  10.489s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.774 (  10.489s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.774 (  10.489s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.774 (  10.490s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.774 (  10.490s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.774 (  10.490s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.774 (  10.490s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.774 (  10.490s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.774 (  10.490s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.774 (  10.490s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.774 (  10.490s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.775 (  10.490s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.775 (  10.490s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.775 (  10.491s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.775 (  10.491s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.775 (  10.491s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.775 (  10.491s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.775 (  10.491s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.775 (  10.491s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.775 (  10.491s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.776 (  10.491s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.776 (  10.492s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.776 (  10.492s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.776 (  10.492s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.776 (  10.492s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.776 (  10.492s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.776 (  10.492s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.776 (  10.492s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.776 (  10.492s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.777 (  10.492s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.777 (  10.493s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.777 (  10.493s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.777 (  10.493s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.777 (  10.493s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.777 (  10.493s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.777 (  10.493s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.777 (  10.493s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.777 (  10.493s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.778 (  10.493s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.778 (  10.494s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.778 (  10.494s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.778 (  10.494s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.778 (  10.494s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.778 (  10.494s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.778 (  10.494s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.778 (  10.494s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.778 (  10.494s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.778 (  10.494s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.778 (  10.494s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.779 (  10.494s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.779 (  10.494s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.779 (  10.495s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.779 (  10.495s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.779 (  10.495s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.779 (  10.495s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.779 (  10.495s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.779 (  10.495s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.779 (  10.495s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.779 (  10.495s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.779 (  10.495s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.780 (  10.495s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.780 (  10.496s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.780 (  10.496s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.780 (  10.496s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.780 (  10.496s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.780 (  10.496s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.780 (  10.496s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.780 (  10.496s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.780 (  10.496s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.780 (  10.496s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.780 (  10.496s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.781 (  10.496s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.781 (  10.496s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.781 (  10.497s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.781 (  10.497s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.781 (  10.497s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.781 (  10.497s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.781 (  10.497s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.781 (  10.497s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.781 (  10.497s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.781 (  10.497s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.782 (  10.497s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.782 (  10.497s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.782 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.782 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.782 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.782 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.782 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.782 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.782 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.782 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.782 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.782 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.782 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.783 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.783 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.783 (  10.498s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.783 (  10.499s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.783 (  10.499s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.783 (  10.499s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.783 (  10.499s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.783 (  10.499s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.783 (  10.499s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.783 (  10.499s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.783 (  10.499s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.783 (  10.499s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.783 (  10.499s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.784 (  10.499s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.784 (  10.499s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.784 (  10.500s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.784 (  10.500s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.784 (  10.500s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.784 (  10.500s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.784 (  10.500s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.784 (  10.500s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.784 (  10.500s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.784 (  10.500s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.784 (  10.500s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.784 (  10.500s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.500s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.500s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.500s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.785 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.501s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.786 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.502s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.787 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.788 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.788 (  10.503s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.788 (  10.504s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.788 (  10.504s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.788 (  10.504s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.788 (  10.504s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.788 (  10.504s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.788 (  10.504s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.788 (  10.504s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.788 (  10.504s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.788 (  10.504s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.788 (  10.504s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.504s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.504s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.504s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.789 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.505s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.790 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.791 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.791 (  10.506s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.791 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.791 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.791 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.791 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.791 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.791 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.791 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.791 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.791 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.791 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.791 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.507s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.792 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.508s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.793 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.509s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.794 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.510s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.795 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.511s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.796 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.512s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.797 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.513s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.798 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.514s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.799 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.515s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.800 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.801 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-09 19:22:21.801 (  10.516s) [        56CD8000]     buffer_instance.cc:398      1| BufferInstance::PJRT_Buffer_Destroy
