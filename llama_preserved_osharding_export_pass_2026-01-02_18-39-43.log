2026-01-02 18:37:28.941 (   0.000s) [        CBC3A000]   plugin_attributes.cc:60       1| PluginAttributes::PJRT_Plugin_Initialize
2026-01-02 18:37:28.941 (   0.000s) [        CBC3A000]     client_instance.cc:554      1| ClientInstance::PJRT_Client_Create
2026-01-02 18:37:28.944 (   0.003s) [        CBC3A000]     client_instance.cc:177      1| ClientInstance::ClientInstance
2026-01-02 18:37:28.944 (   0.003s) [        CBC3A000]     client_instance.cc:198      1| ClientInstance::Initialize
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]              stubs.inc:103   WARN| STUB: PJRT_Client_TopologyDescription
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]     client_instance.cc:608      1| ClientInstance::PJRT_Client_PlatformVersion
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]     client_instance.cc:589      1| ClientInstance::PJRT_Client_PlatformName
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]     client_instance.cc:619      1| ClientInstance::PJRT_Client_Devices
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]     client_instance.cc:632      1| ClientInstance::PJRT_Client_AddressableDevices
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]     client_instance.cc:682      1| ClientInstance::PJRT_Client_AddressableMemories
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]   plugin_attributes.cc:66       1| PluginAttributes::PJRT_Plugin_Attributes
2026-01-02 18:37:30.305331: W torch_xla/csrc/runtime/profiler.cpp:88] Profiler API not found for PJRT plugin
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:30.305 (   1.363s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:30.305 (   1.364s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:30.305 (   1.364s) [        CBC3A000]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-01-02 18:37:30.305 (   1.364s) [        CBC3A000]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2026-01-02 18:37:30.305 (   1.364s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:30.305 (   1.364s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:30.305 (   1.364s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:30.305 (   1.364s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
Using PJRT plugin directory: /localdev/jameszianxu/tt-xla/python_package/pjrt_plugin_tt
Using TT-Metal from the source tree: /localdev/jameszianxu/tt-xla/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
WARNING: TT plugin is setting XLA_STABLEHLO_COMPILE to 1. This is required for TT PJRT plugin to work correctly.
Setting up XLA environment...
XLA environment configured.
Created device mesh: (1, 2) with 2 devices
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 46.84it/s]
2026-01-02 18:37:32.829 (   3.887s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.829 (   3.887s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.830 (   3.888s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.830 (   3.888s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.830 (   3.888s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.831 (   3.890s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.831 (   3.890s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.831 (   3.890s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.831 (   3.890s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.831 (   3.890s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.831 (   3.890s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.831 (   3.890s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.832 (   3.890s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.832 (   3.890s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.832 (   3.890s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.832 (   3.890s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.832 (   3.890s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.832 (   3.891s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.832 (   3.891s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.832 (   3.891s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.832 (   3.891s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.832 (   3.891s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.832 (   3.891s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.832 (   3.891s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.832 (   3.891s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.832 (   3.891s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.839 (   3.898s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.839 (   3.898s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.839 (   3.898s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.839 (   3.898s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.839 (   3.898s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.839 (   3.898s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.839 (   3.898s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.839 (   3.898s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.839 (   3.898s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.839 (   3.898s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.845 (   3.903s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.845 (   3.903s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.851 (   3.910s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.851 (   3.910s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.851 (   3.910s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.852 (   3.910s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.852 (   3.910s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.852 (   3.910s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.852 (   3.910s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.852 (   3.910s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.852 (   3.910s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.852 (   3.910s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.858 (   3.916s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.858 (   3.916s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.867 (   3.925s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.867 (   3.925s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.867 (   3.925s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.867 (   3.926s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.867 (   3.926s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.867 (   3.926s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.867 (   3.926s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.867 (   3.926s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.867 (   3.926s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.867 (   3.926s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.873 (   3.931s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.873 (   3.931s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.875 (   3.934s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.875 (   3.934s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.875 (   3.934s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.876 (   3.934s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.876 (   3.934s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.876 (   3.934s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.876 (   3.934s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.876 (   3.934s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.876 (   3.934s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.876 (   3.934s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.876 (   3.935s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.876 (   3.935s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.877 (   3.935s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.877 (   3.936s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.877 (   3.936s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.877 (   3.936s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.877 (   3.936s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.877 (   3.936s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.877 (   3.936s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.877 (   3.936s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.877 (   3.936s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.877 (   3.936s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.877 (   3.936s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.877 (   3.936s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.879 (   3.938s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.879 (   3.938s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.879 (   3.938s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.879 (   3.938s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.879 (   3.938s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.879 (   3.938s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.879 (   3.938s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.879 (   3.938s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.879 (   3.938s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.879 (   3.938s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.879 (   3.938s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.879 (   3.938s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.881 (   3.940s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.881 (   3.940s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.881 (   3.940s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.881 (   3.940s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.881 (   3.940s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.882 (   3.940s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.882 (   3.940s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.882 (   3.940s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.882 (   3.940s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.882 (   3.940s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.882 (   3.940s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.882 (   3.940s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.888 (   3.946s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.888 (   3.946s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.888 (   3.946s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.888 (   3.947s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.888 (   3.947s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.888 (   3.947s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.888 (   3.947s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.888 (   3.947s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.888 (   3.947s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.888 (   3.947s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.894 (   3.952s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.894 (   3.952s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.900 (   3.958s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.900 (   3.958s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.900 (   3.959s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.900 (   3.959s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.900 (   3.959s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.900 (   3.959s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.900 (   3.959s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.900 (   3.959s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.900 (   3.959s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.900 (   3.959s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.906 (   3.965s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.906 (   3.965s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.912 (   3.971s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.912 (   3.971s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.912 (   3.971s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.913 (   3.971s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.913 (   3.971s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.913 (   3.971s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.913 (   3.971s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.913 (   3.971s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.913 (   3.972s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.913 (   3.972s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.919 (   3.977s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.919 (   3.977s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.920 (   3.979s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.920 (   3.979s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.920 (   3.979s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.920 (   3.979s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.921 (   3.979s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.921 (   3.979s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.921 (   3.979s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.921 (   3.979s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.921 (   3.979s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.921 (   3.979s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.921 (   3.979s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.921 (   3.979s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.921 (   3.980s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.921 (   3.980s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.921 (   3.980s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.921 (   3.980s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.921 (   3.980s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.921 (   3.980s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.921 (   3.980s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.921 (   3.980s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.922 (   3.980s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.922 (   3.980s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.922 (   3.980s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.922 (   3.980s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.923 (   3.982s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.923 (   3.982s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.923 (   3.982s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.923 (   3.982s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.923 (   3.982s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.924 (   3.982s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.924 (   3.982s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.924 (   3.982s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.924 (   3.982s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.924 (   3.982s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.924 (   3.982s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.924 (   3.982s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.925 (   3.984s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.925 (   3.984s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.925 (   3.984s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.925 (   3.984s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.925 (   3.984s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.925 (   3.984s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.925 (   3.984s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.925 (   3.984s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.926 (   3.984s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.926 (   3.984s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.926 (   3.984s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.926 (   3.984s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.931 (   3.990s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.931 (   3.990s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.931 (   3.990s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.932 (   3.990s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.932 (   3.990s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.932 (   3.990s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.932 (   3.990s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.932 (   3.990s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.932 (   3.990s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.932 (   3.990s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.937 (   3.996s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.937 (   3.996s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.943 (   4.002s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.944 (   4.002s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.944 (   4.002s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.944 (   4.002s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.944 (   4.003s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.944 (   4.003s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.944 (   4.003s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.944 (   4.003s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.944 (   4.003s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.944 (   4.003s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.950 (   4.008s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.950 (   4.009s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.957 (   4.016s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.957 (   4.016s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.957 (   4.016s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.957 (   4.016s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.957 (   4.016s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.957 (   4.016s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.957 (   4.016s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.957 (   4.016s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.958 (   4.016s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.958 (   4.016s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.963 (   4.022s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.963 (   4.022s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.965 (   4.023s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.965 (   4.023s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.965 (   4.023s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.965 (   4.024s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.965 (   4.024s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.965 (   4.024s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.965 (   4.024s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.965 (   4.024s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.965 (   4.024s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.965 (   4.024s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.965 (   4.024s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.965 (   4.024s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.966 (   4.024s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.966 (   4.024s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.966 (   4.024s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.966 (   4.025s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.966 (   4.025s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.966 (   4.025s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.966 (   4.025s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.966 (   4.025s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.966 (   4.025s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.966 (   4.025s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.967 (   4.025s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.967 (   4.025s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.968 (   4.026s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.968 (   4.026s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.968 (   4.026s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.968 (   4.027s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.968 (   4.027s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.968 (   4.027s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.968 (   4.027s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.968 (   4.027s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.968 (   4.027s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.968 (   4.027s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.968 (   4.027s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.968 (   4.027s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.970 (   4.028s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.970 (   4.028s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.970 (   4.028s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.970 (   4.029s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.970 (   4.029s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.970 (   4.029s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.970 (   4.029s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.970 (   4.029s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.970 (   4.029s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.970 (   4.029s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.970 (   4.029s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.970 (   4.029s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.976 (   4.034s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.976 (   4.034s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.976 (   4.034s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.976 (   4.035s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.976 (   4.035s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.976 (   4.035s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.976 (   4.035s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.976 (   4.035s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.976 (   4.035s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.976 (   4.035s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.982 (   4.041s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.982 (   4.041s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.988 (   4.047s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.988 (   4.047s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.988 (   4.047s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.988 (   4.047s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.988 (   4.047s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.988 (   4.047s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:32.988 (   4.047s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:32.988 (   4.047s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:32.989 (   4.047s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:32.989 (   4.047s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:32.994 (   4.053s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:32.994 (   4.053s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.000 (   4.059s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.000 (   4.059s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.000 (   4.059s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.001 (   4.060s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.001 (   4.060s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.001 (   4.060s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.001 (   4.060s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.001 (   4.060s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.001 (   4.060s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.001 (   4.060s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.007 (   4.065s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.007 (   4.065s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.008 (   4.067s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.008 (   4.067s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.008 (   4.067s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.009 (   4.067s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.009 (   4.067s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.009 (   4.067s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.009 (   4.067s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.009 (   4.067s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.009 (   4.067s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.009 (   4.067s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.009 (   4.068s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.009 (   4.068s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.009 (   4.068s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.009 (   4.068s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.009 (   4.068s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.010 (   4.068s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.010 (   4.068s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.010 (   4.068s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.010 (   4.068s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.010 (   4.068s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.010 (   4.068s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.010 (   4.068s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.010 (   4.068s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.010 (   4.068s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.011 (   4.070s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.011 (   4.070s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.011 (   4.070s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.011 (   4.070s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.011 (   4.070s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.011 (   4.070s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.011 (   4.070s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.011 (   4.070s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.011 (   4.070s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.011 (   4.070s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.012 (   4.070s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.012 (   4.070s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.013 (   4.072s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.013 (   4.072s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.013 (   4.072s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.013 (   4.072s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.013 (   4.072s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.013 (   4.072s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.013 (   4.072s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.013 (   4.072s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.013 (   4.072s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.013 (   4.072s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.013 (   4.072s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.013 (   4.072s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.019 (   4.078s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.019 (   4.078s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.019 (   4.078s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.019 (   4.078s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.019 (   4.078s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.019 (   4.078s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.019 (   4.078s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.019 (   4.078s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.019 (   4.078s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.019 (   4.078s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.025 (   4.084s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.025 (   4.084s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.031 (   4.090s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.031 (   4.090s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.031 (   4.090s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.032 (   4.090s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.032 (   4.090s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.032 (   4.090s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.032 (   4.090s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.032 (   4.090s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.032 (   4.090s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.032 (   4.090s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.037 (   4.096s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.037 (   4.096s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.044 (   4.102s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.044 (   4.102s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.044 (   4.102s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.044 (   4.103s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.044 (   4.103s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.044 (   4.103s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.044 (   4.103s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.044 (   4.103s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.044 (   4.103s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.044 (   4.103s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.050 (   4.108s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.050 (   4.108s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.052 (   4.110s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.052 (   4.110s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.052 (   4.110s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.052 (   4.110s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.052 (   4.110s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.052 (   4.110s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.052 (   4.110s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.052 (   4.110s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.052 (   4.111s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.052 (   4.111s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.052 (   4.111s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.052 (   4.111s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.053 (   4.111s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.053 (   4.111s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.053 (   4.111s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.053 (   4.111s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.053 (   4.111s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.053 (   4.111s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.053 (   4.111s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.053 (   4.111s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.053 (   4.112s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.053 (   4.112s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.053 (   4.112s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.053 (   4.112s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.054 (   4.113s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.054 (   4.113s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.054 (   4.113s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.055 (   4.113s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.055 (   4.113s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.055 (   4.113s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.055 (   4.113s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.055 (   4.113s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.055 (   4.113s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.055 (   4.113s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.055 (   4.114s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.055 (   4.114s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.056 (   4.115s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.056 (   4.115s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.056 (   4.115s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.057 (   4.115s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.057 (   4.115s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.057 (   4.115s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.057 (   4.115s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.057 (   4.115s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.057 (   4.115s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.057 (   4.115s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.057 (   4.116s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.057 (   4.116s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.062 (   4.121s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.063 (   4.121s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.063 (   4.121s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.063 (   4.121s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.063 (   4.121s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.063 (   4.121s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.063 (   4.121s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.063 (   4.121s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.063 (   4.122s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.063 (   4.122s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.069 (   4.127s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.069 (   4.128s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.076 (   4.134s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.076 (   4.134s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.076 (   4.134s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.076 (   4.135s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.076 (   4.135s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.076 (   4.135s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.076 (   4.135s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.076 (   4.135s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.076 (   4.135s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.076 (   4.135s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.082 (   4.140s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.082 (   4.140s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.088 (   4.146s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.088 (   4.147s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.088 (   4.147s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.088 (   4.147s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.088 (   4.147s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.088 (   4.147s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.088 (   4.147s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.088 (   4.147s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.089 (   4.147s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.089 (   4.147s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.094 (   4.153s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.094 (   4.153s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.096 (   4.154s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.096 (   4.154s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.096 (   4.154s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.096 (   4.155s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.096 (   4.155s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.096 (   4.155s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.096 (   4.155s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.096 (   4.155s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.096 (   4.155s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.096 (   4.155s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.096 (   4.155s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.096 (   4.155s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.097 (   4.155s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.097 (   4.155s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.097 (   4.155s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.097 (   4.156s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.097 (   4.156s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.097 (   4.156s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.097 (   4.156s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.097 (   4.156s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.097 (   4.156s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.097 (   4.156s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.097 (   4.156s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.097 (   4.156s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.099 (   4.157s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.099 (   4.157s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.099 (   4.157s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.099 (   4.157s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.099 (   4.157s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.099 (   4.157s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.099 (   4.157s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.099 (   4.157s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.099 (   4.158s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.099 (   4.158s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.099 (   4.158s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.099 (   4.158s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.101 (   4.159s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.101 (   4.159s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.101 (   4.159s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.101 (   4.159s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.101 (   4.159s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.101 (   4.159s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.101 (   4.159s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.101 (   4.159s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.101 (   4.159s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.101 (   4.159s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.101 (   4.160s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.101 (   4.160s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.107 (   4.165s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.107 (   4.165s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.107 (   4.165s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.107 (   4.166s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.107 (   4.166s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.107 (   4.166s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.107 (   4.166s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.107 (   4.166s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.107 (   4.166s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.107 (   4.166s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.113 (   4.172s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.113 (   4.172s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.119 (   4.178s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.119 (   4.178s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.119 (   4.178s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.119 (   4.178s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.119 (   4.178s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.119 (   4.178s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.119 (   4.178s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.119 (   4.178s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.120 (   4.178s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.120 (   4.178s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.125 (   4.184s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.125 (   4.184s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.132 (   4.190s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.132 (   4.190s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.132 (   4.190s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.132 (   4.191s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.132 (   4.191s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.132 (   4.191s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.132 (   4.191s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.132 (   4.191s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.132 (   4.191s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.132 (   4.191s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.138 (   4.196s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.138 (   4.196s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.140 (   4.198s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.140 (   4.198s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.140 (   4.198s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.140 (   4.199s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.140 (   4.199s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.140 (   4.199s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.140 (   4.199s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.140 (   4.199s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.140 (   4.199s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.140 (   4.199s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.140 (   4.199s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.140 (   4.199s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.141 (   4.199s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.141 (   4.199s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.141 (   4.199s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.141 (   4.200s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.141 (   4.200s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.141 (   4.200s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.141 (   4.200s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.141 (   4.200s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.141 (   4.200s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.141 (   4.200s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.141 (   4.200s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.141 (   4.200s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.142 (   4.201s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.142 (   4.201s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.142 (   4.201s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.142 (   4.201s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.142 (   4.201s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.142 (   4.201s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.142 (   4.201s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.142 (   4.201s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.143 (   4.201s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.143 (   4.201s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.143 (   4.201s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.143 (   4.201s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.144 (   4.203s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.144 (   4.203s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.144 (   4.203s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.144 (   4.203s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.144 (   4.203s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.144 (   4.203s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.144 (   4.203s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.144 (   4.203s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.145 (   4.203s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.145 (   4.203s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.145 (   4.203s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.145 (   4.203s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.150 (   4.209s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.150 (   4.209s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.150 (   4.209s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.151 (   4.209s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.151 (   4.209s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.151 (   4.209s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.151 (   4.209s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.151 (   4.209s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.151 (   4.209s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.151 (   4.209s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.156 (   4.215s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.157 (   4.215s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.163 (   4.221s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.163 (   4.221s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.163 (   4.221s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.163 (   4.222s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.163 (   4.222s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.163 (   4.222s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.163 (   4.222s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.163 (   4.222s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.163 (   4.222s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.163 (   4.222s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.169 (   4.227s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.169 (   4.227s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.176 (   4.234s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.176 (   4.234s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.176 (   4.234s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.176 (   4.235s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.176 (   4.235s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.176 (   4.235s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.176 (   4.235s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.176 (   4.235s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.176 (   4.235s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.176 (   4.235s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.182 (   4.241s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.182 (   4.241s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.185 (   4.243s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.185 (   4.243s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.185 (   4.243s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.185 (   4.244s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.185 (   4.244s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.185 (   4.244s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.185 (   4.244s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.185 (   4.244s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.185 (   4.244s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.185 (   4.244s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.186 (   4.244s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.186 (   4.244s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.186 (   4.245s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.186 (   4.245s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.186 (   4.245s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.186 (   4.245s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.186 (   4.245s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.186 (   4.245s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.186 (   4.245s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.186 (   4.245s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.186 (   4.245s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.186 (   4.245s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.186 (   4.245s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.186 (   4.245s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.188 (   4.247s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.188 (   4.247s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.188 (   4.247s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.188 (   4.247s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.188 (   4.247s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.188 (   4.247s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.188 (   4.247s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.188 (   4.247s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.188 (   4.247s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.188 (   4.247s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.189 (   4.247s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.189 (   4.247s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.190 (   4.249s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.190 (   4.249s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.190 (   4.249s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.190 (   4.249s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.190 (   4.249s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.190 (   4.249s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.190 (   4.249s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.190 (   4.249s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.190 (   4.249s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.190 (   4.249s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.190 (   4.249s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.191 (   4.249s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.196 (   4.255s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.196 (   4.255s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.196 (   4.255s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.196 (   4.255s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.196 (   4.255s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.196 (   4.255s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.196 (   4.255s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.196 (   4.255s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.197 (   4.255s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.197 (   4.255s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.202 (   4.261s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.202 (   4.261s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.208 (   4.267s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.208 (   4.267s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.208 (   4.267s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.209 (   4.267s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.209 (   4.267s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.209 (   4.267s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.209 (   4.267s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.209 (   4.267s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.209 (   4.268s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.209 (   4.268s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.214 (   4.273s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.214 (   4.273s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.221 (   4.279s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.221 (   4.279s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.221 (   4.279s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.221 (   4.280s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.221 (   4.280s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.221 (   4.280s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.221 (   4.280s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.221 (   4.280s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.222 (   4.280s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.222 (   4.280s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.227 (   4.286s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.227 (   4.286s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.229 (   4.288s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.229 (   4.288s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.229 (   4.288s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.229 (   4.288s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.229 (   4.288s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.229 (   4.288s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.229 (   4.288s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.229 (   4.288s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.229 (   4.288s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.229 (   4.288s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.230 (   4.288s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.230 (   4.288s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.230 (   4.289s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.230 (   4.289s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.230 (   4.289s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.230 (   4.289s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.230 (   4.289s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.230 (   4.289s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.230 (   4.289s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.230 (   4.289s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.231 (   4.289s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.231 (   4.289s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.231 (   4.289s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.231 (   4.289s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.232 (   4.290s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.232 (   4.290s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.232 (   4.290s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.232 (   4.290s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.232 (   4.290s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.232 (   4.290s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.232 (   4.290s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.232 (   4.290s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.232 (   4.291s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.232 (   4.291s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.232 (   4.291s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.232 (   4.291s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.234 (   4.292s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.234 (   4.292s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.234 (   4.292s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.234 (   4.292s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.234 (   4.292s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.234 (   4.292s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.234 (   4.292s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.234 (   4.292s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.234 (   4.293s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.234 (   4.293s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.234 (   4.293s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.234 (   4.293s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.240 (   4.298s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.240 (   4.298s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.240 (   4.298s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.240 (   4.299s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.240 (   4.299s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.240 (   4.299s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.240 (   4.299s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.240 (   4.299s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.240 (   4.299s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.240 (   4.299s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.246 (   4.305s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.246 (   4.305s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.252 (   4.311s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.252 (   4.311s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.252 (   4.311s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.252 (   4.311s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.252 (   4.311s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.252 (   4.311s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.252 (   4.311s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.252 (   4.311s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.253 (   4.311s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.253 (   4.311s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.258 (   4.317s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.258 (   4.317s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.265 (   4.323s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.265 (   4.323s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.265 (   4.323s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.265 (   4.324s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.265 (   4.324s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.265 (   4.324s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.265 (   4.324s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.265 (   4.324s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.265 (   4.324s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.265 (   4.324s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.271 (   4.330s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.271 (   4.330s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.273 (   4.331s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.273 (   4.331s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.273 (   4.331s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.273 (   4.332s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.273 (   4.332s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.273 (   4.332s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.273 (   4.332s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.273 (   4.332s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.273 (   4.332s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.273 (   4.332s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.273 (   4.332s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.273 (   4.332s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.274 (   4.332s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.274 (   4.332s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.274 (   4.332s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.274 (   4.332s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.274 (   4.332s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.274 (   4.332s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.274 (   4.332s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.274 (   4.332s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.274 (   4.333s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.274 (   4.333s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.274 (   4.333s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.274 (   4.333s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.276 (   4.334s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.276 (   4.334s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.276 (   4.334s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.276 (   4.334s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.276 (   4.334s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.276 (   4.334s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.276 (   4.335s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.276 (   4.335s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.276 (   4.335s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.276 (   4.335s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.276 (   4.335s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.276 (   4.335s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.278 (   4.336s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.278 (   4.336s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.278 (   4.336s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.278 (   4.337s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.278 (   4.337s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.278 (   4.337s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.278 (   4.337s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.278 (   4.337s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.278 (   4.337s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.278 (   4.337s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.278 (   4.337s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.278 (   4.337s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.284 (   4.342s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.284 (   4.342s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.284 (   4.342s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.284 (   4.343s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.284 (   4.343s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.284 (   4.343s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.284 (   4.343s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.284 (   4.343s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.284 (   4.343s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.284 (   4.343s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.290 (   4.349s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.290 (   4.349s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.296 (   4.355s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.297 (   4.355s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.297 (   4.355s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.297 (   4.356s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.297 (   4.356s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.297 (   4.356s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.297 (   4.356s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.297 (   4.356s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.297 (   4.356s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.297 (   4.356s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.303 (   4.361s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.303 (   4.361s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.309 (   4.368s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.309 (   4.368s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.309 (   4.368s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.310 (   4.368s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.310 (   4.368s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.310 (   4.368s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.310 (   4.368s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.310 (   4.368s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.310 (   4.368s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.310 (   4.368s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.315 (   4.374s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.315 (   4.374s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.317 (   4.376s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.317 (   4.376s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.317 (   4.376s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.317 (   4.376s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.317 (   4.376s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.317 (   4.376s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.317 (   4.376s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.317 (   4.376s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.317 (   4.376s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.317 (   4.376s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.318 (   4.376s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.318 (   4.376s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.318 (   4.377s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.318 (   4.377s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.318 (   4.377s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.318 (   4.377s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.318 (   4.377s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.318 (   4.377s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.318 (   4.377s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.318 (   4.377s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.318 (   4.377s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.318 (   4.377s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.319 (   4.377s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.319 (   4.377s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.320 (   4.378s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.320 (   4.378s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.320 (   4.378s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.320 (   4.379s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.320 (   4.379s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.320 (   4.379s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.320 (   4.379s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.320 (   4.379s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.320 (   4.379s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.320 (   4.379s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.320 (   4.379s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.320 (   4.379s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.322 (   4.380s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.322 (   4.380s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.322 (   4.380s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.322 (   4.381s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.322 (   4.381s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.322 (   4.381s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.322 (   4.381s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.322 (   4.381s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.322 (   4.381s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.322 (   4.381s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.322 (   4.381s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.322 (   4.381s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.328 (   4.386s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.328 (   4.386s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.328 (   4.386s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.328 (   4.387s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.328 (   4.387s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.328 (   4.387s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.328 (   4.387s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.328 (   4.387s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.328 (   4.387s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.328 (   4.387s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.334 (   4.393s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.334 (   4.393s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.340 (   4.399s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.340 (   4.399s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.340 (   4.399s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.340 (   4.399s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.340 (   4.399s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.340 (   4.399s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.340 (   4.399s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.340 (   4.399s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.341 (   4.399s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.341 (   4.399s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.346 (   4.405s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.346 (   4.405s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.353 (   4.411s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.353 (   4.411s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.353 (   4.411s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.353 (   4.412s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.353 (   4.412s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.353 (   4.412s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.353 (   4.412s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.353 (   4.412s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.353 (   4.412s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.353 (   4.412s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.359 (   4.417s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.359 (   4.418s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.361 (   4.420s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.361 (   4.420s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.361 (   4.420s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.361 (   4.420s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.361 (   4.420s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.361 (   4.420s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.361 (   4.420s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.361 (   4.420s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.361 (   4.420s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.361 (   4.420s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.362 (   4.420s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.362 (   4.420s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.362 (   4.421s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.362 (   4.421s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.362 (   4.421s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.362 (   4.421s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.362 (   4.421s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.362 (   4.421s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.362 (   4.421s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.362 (   4.421s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.362 (   4.421s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.362 (   4.421s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.363 (   4.421s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.363 (   4.421s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.364 (   4.422s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.364 (   4.422s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.364 (   4.422s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.364 (   4.422s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.364 (   4.422s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.364 (   4.422s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.364 (   4.422s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.364 (   4.422s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.364 (   4.422s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.364 (   4.422s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.364 (   4.423s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.364 (   4.423s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.366 (   4.424s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.366 (   4.424s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.366 (   4.424s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.366 (   4.424s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.366 (   4.424s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.366 (   4.424s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.366 (   4.424s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.366 (   4.424s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.366 (   4.425s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.366 (   4.425s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.366 (   4.425s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.366 (   4.425s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.372 (   4.430s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.372 (   4.430s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.372 (   4.430s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.372 (   4.431s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.372 (   4.431s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.372 (   4.431s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.372 (   4.431s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.372 (   4.431s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.372 (   4.431s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.372 (   4.431s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.378 (   4.436s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.378 (   4.436s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.384 (   4.442s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.384 (   4.442s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.384 (   4.442s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.384 (   4.443s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.384 (   4.443s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.384 (   4.443s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.384 (   4.443s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.384 (   4.443s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.384 (   4.443s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.384 (   4.443s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.390 (   4.449s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.390 (   4.449s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.397 (   4.455s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.397 (   4.455s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.397 (   4.455s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.397 (   4.456s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.397 (   4.456s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.397 (   4.456s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.397 (   4.456s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.397 (   4.456s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.397 (   4.456s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.397 (   4.456s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.403 (   4.462s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.403 (   4.462s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.406 (   4.464s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.406 (   4.464s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.406 (   4.464s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.406 (   4.465s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.406 (   4.465s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.406 (   4.465s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.406 (   4.465s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.406 (   4.465s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.406 (   4.465s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.406 (   4.465s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.406 (   4.465s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.406 (   4.465s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.407 (   4.466s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.407 (   4.466s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.407 (   4.466s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.407 (   4.466s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.407 (   4.466s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.407 (   4.466s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.407 (   4.466s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.407 (   4.466s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.407 (   4.466s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.407 (   4.466s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.407 (   4.466s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.407 (   4.466s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.409 (   4.468s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.409 (   4.468s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.409 (   4.468s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.409 (   4.468s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.409 (   4.468s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.409 (   4.468s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.409 (   4.468s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.409 (   4.468s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.409 (   4.468s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.409 (   4.468s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.409 (   4.468s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.409 (   4.468s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.411 (   4.470s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.411 (   4.470s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.411 (   4.470s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.411 (   4.470s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.411 (   4.470s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.411 (   4.470s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.411 (   4.470s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.411 (   4.470s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.411 (   4.470s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.411 (   4.470s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.411 (   4.470s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.411 (   4.470s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.417 (   4.476s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.417 (   4.476s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.417 (   4.476s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.417 (   4.476s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.417 (   4.476s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.417 (   4.476s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.417 (   4.476s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.417 (   4.476s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.418 (   4.476s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.418 (   4.476s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.423 (   4.482s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.423 (   4.482s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.429 (   4.488s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.429 (   4.488s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.429 (   4.488s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.430 (   4.488s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.430 (   4.488s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.430 (   4.488s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.430 (   4.488s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.430 (   4.488s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.430 (   4.488s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.430 (   4.488s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.436 (   4.494s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.436 (   4.494s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.442 (   4.501s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.442 (   4.501s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.442 (   4.501s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.442 (   4.501s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.442 (   4.501s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.442 (   4.501s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.442 (   4.501s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.442 (   4.501s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.443 (   4.501s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.443 (   4.501s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.448 (   4.507s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.448 (   4.507s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.450 (   4.509s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.450 (   4.509s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.450 (   4.509s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.451 (   4.509s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.451 (   4.509s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.451 (   4.509s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.451 (   4.509s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.451 (   4.509s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.451 (   4.509s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.451 (   4.509s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.451 (   4.509s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.451 (   4.510s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.451 (   4.510s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.451 (   4.510s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.451 (   4.510s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.452 (   4.510s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.452 (   4.510s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.452 (   4.510s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.452 (   4.510s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.452 (   4.510s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.452 (   4.510s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.452 (   4.510s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.452 (   4.511s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.452 (   4.511s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.453 (   4.511s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.453 (   4.511s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.453 (   4.511s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.453 (   4.512s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.453 (   4.512s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.453 (   4.512s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.453 (   4.512s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.453 (   4.512s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.453 (   4.512s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.453 (   4.512s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.453 (   4.512s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.453 (   4.512s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.455 (   4.513s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.455 (   4.513s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.455 (   4.514s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.455 (   4.514s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.455 (   4.514s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.455 (   4.514s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.455 (   4.514s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.455 (   4.514s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.455 (   4.514s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.455 (   4.514s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.455 (   4.514s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.455 (   4.514s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.461 (   4.520s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.461 (   4.520s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.461 (   4.520s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.461 (   4.520s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.461 (   4.520s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.461 (   4.520s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.461 (   4.520s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.461 (   4.520s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.461 (   4.520s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.461 (   4.520s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.467 (   4.526s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.467 (   4.526s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.473 (   4.532s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.473 (   4.532s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.473 (   4.532s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.474 (   4.532s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.474 (   4.532s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.474 (   4.532s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.474 (   4.532s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.474 (   4.532s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.474 (   4.532s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.474 (   4.533s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.479 (   4.538s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.479 (   4.538s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.486 (   4.544s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.486 (   4.544s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.486 (   4.544s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.486 (   4.545s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.486 (   4.545s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.486 (   4.545s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.486 (   4.545s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.486 (   4.545s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.486 (   4.545s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.486 (   4.545s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.492 (   4.551s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.492 (   4.551s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.494 (   4.552s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.494 (   4.552s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.494 (   4.552s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.494 (   4.553s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.494 (   4.553s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.494 (   4.553s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.494 (   4.553s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.494 (   4.553s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.494 (   4.553s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.494 (   4.553s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.494 (   4.553s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.494 (   4.553s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.495 (   4.553s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.495 (   4.553s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.495 (   4.553s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.495 (   4.554s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.495 (   4.554s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.495 (   4.554s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.495 (   4.554s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.495 (   4.554s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.495 (   4.554s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.495 (   4.554s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.495 (   4.554s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.495 (   4.554s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.496 (   4.555s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.496 (   4.555s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.496 (   4.555s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.496 (   4.555s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.496 (   4.555s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.496 (   4.555s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.496 (   4.555s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.496 (   4.555s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.497 (   4.555s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.497 (   4.555s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.497 (   4.555s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.497 (   4.555s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.498 (   4.557s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.498 (   4.557s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.498 (   4.557s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.499 (   4.557s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.499 (   4.557s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.499 (   4.557s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.499 (   4.557s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.499 (   4.557s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.499 (   4.557s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.499 (   4.557s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.499 (   4.557s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.499 (   4.557s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.504 (   4.563s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.504 (   4.563s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.504 (   4.563s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.505 (   4.563s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.505 (   4.563s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.505 (   4.563s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.505 (   4.563s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.505 (   4.563s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.505 (   4.564s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.505 (   4.564s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.511 (   4.570s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.511 (   4.570s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.517 (   4.576s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.517 (   4.576s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.517 (   4.576s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.518 (   4.576s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.518 (   4.576s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.518 (   4.576s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.518 (   4.576s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.518 (   4.576s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.518 (   4.576s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.518 (   4.576s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.523 (   4.582s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.523 (   4.582s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.529 (   4.588s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.530 (   4.588s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.530 (   4.588s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.530 (   4.589s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.530 (   4.589s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.530 (   4.589s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.530 (   4.589s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.530 (   4.589s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.530 (   4.589s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.530 (   4.589s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.536 (   4.594s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.536 (   4.594s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.537 (   4.596s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.537 (   4.596s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.537 (   4.596s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.537 (   4.596s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.537 (   4.596s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.537 (   4.596s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.537 (   4.596s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.537 (   4.596s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.538 (   4.596s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.538 (   4.596s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.538 (   4.596s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.538 (   4.596s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.538 (   4.597s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.538 (   4.597s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.538 (   4.597s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.538 (   4.597s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.538 (   4.597s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.538 (   4.597s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.538 (   4.597s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.538 (   4.597s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.538 (   4.597s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.539 (   4.597s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.539 (   4.597s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.539 (   4.597s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.539 (   4.598s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.539 (   4.598s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.539 (   4.598s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.539 (   4.598s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.539 (   4.598s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.539 (   4.598s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.539 (   4.598s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.539 (   4.598s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.540 (   4.598s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.540 (   4.598s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.540 (   4.598s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.540 (   4.598s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.541 (   4.600s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.542 (   4.600s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.542 (   4.600s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.542 (   4.600s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.542 (   4.600s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.542 (   4.600s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.542 (   4.600s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.542 (   4.600s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.542 (   4.600s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.542 (   4.600s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.542 (   4.601s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.542 (   4.601s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.548 (   4.606s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.548 (   4.606s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.548 (   4.606s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.548 (   4.607s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.548 (   4.607s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.548 (   4.607s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.548 (   4.607s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.548 (   4.607s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.548 (   4.607s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.548 (   4.607s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.554 (   4.612s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.554 (   4.612s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.560 (   4.618s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.560 (   4.618s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.560 (   4.618s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.560 (   4.619s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.560 (   4.619s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.560 (   4.619s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.560 (   4.619s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.560 (   4.619s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.560 (   4.619s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.560 (   4.619s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.566 (   4.624s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.566 (   4.624s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.572 (   4.631s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.572 (   4.631s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.572 (   4.631s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.573 (   4.631s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.573 (   4.631s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.573 (   4.631s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.573 (   4.631s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.573 (   4.631s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.573 (   4.631s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.573 (   4.631s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.578 (   4.637s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.578 (   4.637s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.580 (   4.639s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.580 (   4.639s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.580 (   4.639s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.580 (   4.639s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.580 (   4.639s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.580 (   4.639s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.580 (   4.639s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.580 (   4.639s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.581 (   4.639s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.581 (   4.639s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.581 (   4.639s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.581 (   4.639s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.581 (   4.640s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.581 (   4.640s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.581 (   4.640s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.581 (   4.640s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.581 (   4.640s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.581 (   4.640s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.581 (   4.640s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.581 (   4.640s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.582 (   4.640s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.582 (   4.640s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.582 (   4.640s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.582 (   4.640s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.583 (   4.642s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.583 (   4.642s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.583 (   4.642s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.583 (   4.642s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.583 (   4.642s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.583 (   4.642s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.583 (   4.642s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.583 (   4.642s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.583 (   4.642s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.583 (   4.642s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.583 (   4.642s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.583 (   4.642s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.585 (   4.644s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.585 (   4.644s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.585 (   4.644s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.585 (   4.644s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.585 (   4.644s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.585 (   4.644s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.585 (   4.644s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.585 (   4.644s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.585 (   4.644s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.585 (   4.644s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.585 (   4.644s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.585 (   4.644s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.591 (   4.650s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.591 (   4.650s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.591 (   4.650s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.591 (   4.650s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.591 (   4.650s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.591 (   4.650s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.591 (   4.650s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.591 (   4.650s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.592 (   4.650s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.592 (   4.650s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.597 (   4.656s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.597 (   4.656s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.603 (   4.662s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.603 (   4.662s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.603 (   4.662s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.604 (   4.662s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.604 (   4.662s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.604 (   4.662s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.604 (   4.662s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.604 (   4.662s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.604 (   4.662s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.604 (   4.662s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.609 (   4.668s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.609 (   4.668s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.616 (   4.675s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.616 (   4.675s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.616 (   4.675s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.617 (   4.675s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.617 (   4.675s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.617 (   4.675s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.617 (   4.675s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.617 (   4.675s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.617 (   4.676s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.617 (   4.676s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.622 (   4.681s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.623 (   4.681s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.624 (   4.683s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.625 (   4.683s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.625 (   4.683s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.625 (   4.683s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.625 (   4.683s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.625 (   4.683s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.625 (   4.683s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.625 (   4.683s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.625 (   4.684s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.625 (   4.684s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.625 (   4.684s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.625 (   4.684s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.626 (   4.684s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.626 (   4.684s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.626 (   4.684s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.626 (   4.684s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.626 (   4.684s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.626 (   4.684s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.626 (   4.684s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.626 (   4.684s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.626 (   4.685s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.626 (   4.685s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.626 (   4.685s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.626 (   4.685s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.627 (   4.686s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.627 (   4.686s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.627 (   4.686s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.627 (   4.686s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.627 (   4.686s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.627 (   4.686s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.627 (   4.686s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.627 (   4.686s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.627 (   4.686s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.627 (   4.686s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.628 (   4.686s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.628 (   4.686s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.629 (   4.688s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.629 (   4.688s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.629 (   4.688s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.629 (   4.688s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.629 (   4.688s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.629 (   4.688s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.629 (   4.688s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.629 (   4.688s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.630 (   4.688s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.630 (   4.688s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.630 (   4.688s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.630 (   4.688s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.635 (   4.694s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.635 (   4.694s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.635 (   4.694s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.636 (   4.694s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.636 (   4.694s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.636 (   4.694s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.636 (   4.694s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.636 (   4.694s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.636 (   4.695s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.636 (   4.695s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.642 (   4.700s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.642 (   4.700s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.648 (   4.706s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.648 (   4.706s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.648 (   4.706s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.648 (   4.707s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.648 (   4.707s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.648 (   4.707s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.648 (   4.707s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.648 (   4.707s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.648 (   4.707s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.648 (   4.707s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.654 (   4.712s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.654 (   4.712s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.660 (   4.719s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.660 (   4.719s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.660 (   4.719s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.661 (   4.719s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.661 (   4.719s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.661 (   4.719s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.661 (   4.719s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.661 (   4.719s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.661 (   4.719s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.661 (   4.719s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.666 (   4.725s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.666 (   4.725s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.668 (   4.727s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.668 (   4.727s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.668 (   4.727s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.668 (   4.727s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.668 (   4.727s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.668 (   4.727s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.668 (   4.727s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.668 (   4.727s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.669 (   4.727s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.669 (   4.727s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.669 (   4.727s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.669 (   4.727s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.669 (   4.728s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.669 (   4.728s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.669 (   4.728s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.669 (   4.728s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.669 (   4.728s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.669 (   4.728s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.669 (   4.728s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.669 (   4.728s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.670 (   4.728s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.670 (   4.728s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.670 (   4.728s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.670 (   4.728s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.671 (   4.730s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.671 (   4.730s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.671 (   4.730s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.671 (   4.730s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.671 (   4.730s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.671 (   4.730s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.671 (   4.730s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.671 (   4.730s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.671 (   4.730s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.671 (   4.730s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.671 (   4.730s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.671 (   4.730s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.673 (   4.732s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.673 (   4.732s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.673 (   4.732s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.673 (   4.732s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.673 (   4.732s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.673 (   4.732s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.673 (   4.732s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.673 (   4.732s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.673 (   4.732s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.673 (   4.732s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.673 (   4.732s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.673 (   4.732s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.679 (   4.738s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.679 (   4.738s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.679 (   4.738s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.679 (   4.738s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.679 (   4.738s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.679 (   4.738s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.679 (   4.738s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.679 (   4.738s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.680 (   4.738s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.680 (   4.738s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.685 (   4.744s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.685 (   4.744s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.691 (   4.750s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.691 (   4.750s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.691 (   4.750s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.692 (   4.750s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.692 (   4.750s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.692 (   4.750s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.692 (   4.750s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.692 (   4.750s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.692 (   4.750s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.692 (   4.751s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.697 (   4.756s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.698 (   4.756s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.704 (   4.762s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.704 (   4.762s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.704 (   4.762s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.704 (   4.763s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.704 (   4.763s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.704 (   4.763s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.704 (   4.763s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.704 (   4.763s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.704 (   4.763s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.704 (   4.763s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.710 (   4.769s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.710 (   4.769s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.712 (   4.771s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.712 (   4.771s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.712 (   4.771s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.712 (   4.771s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.712 (   4.771s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.712 (   4.771s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.712 (   4.771s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.712 (   4.771s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.712 (   4.771s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.712 (   4.771s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.713 (   4.771s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.713 (   4.771s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.713 (   4.772s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.713 (   4.772s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.713 (   4.772s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.713 (   4.772s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.713 (   4.772s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.713 (   4.772s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.713 (   4.772s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.713 (   4.772s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.714 (   4.772s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.714 (   4.772s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.714 (   4.772s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.714 (   4.772s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.715 (   4.774s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.715 (   4.774s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.715 (   4.774s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.715 (   4.774s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.715 (   4.774s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.715 (   4.774s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.715 (   4.774s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.715 (   4.774s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.715 (   4.774s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.715 (   4.774s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.716 (   4.774s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.716 (   4.774s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.717 (   4.776s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.717 (   4.776s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.717 (   4.776s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.717 (   4.776s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.717 (   4.776s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.717 (   4.776s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.717 (   4.776s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.717 (   4.776s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.718 (   4.776s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.718 (   4.776s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.718 (   4.776s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.718 (   4.776s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.723 (   4.782s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.723 (   4.782s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.723 (   4.782s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.724 (   4.782s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.724 (   4.782s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.724 (   4.782s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.724 (   4.782s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.724 (   4.782s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.724 (   4.782s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.724 (   4.782s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.729 (   4.788s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.729 (   4.788s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.735 (   4.794s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.735 (   4.794s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.735 (   4.794s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.736 (   4.794s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.736 (   4.794s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.736 (   4.794s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.736 (   4.794s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.736 (   4.794s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.736 (   4.795s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.736 (   4.795s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.742 (   4.800s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.742 (   4.800s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.748 (   4.806s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.748 (   4.806s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.748 (   4.806s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.748 (   4.807s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.748 (   4.807s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.748 (   4.807s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.748 (   4.807s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.748 (   4.807s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.748 (   4.807s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.749 (   4.807s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.754 (   4.813s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.754 (   4.813s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.756 (   4.814s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.756 (   4.814s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.756 (   4.814s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.756 (   4.815s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.756 (   4.815s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.756 (   4.815s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.756 (   4.815s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.756 (   4.815s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.756 (   4.815s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.756 (   4.815s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.756 (   4.815s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.756 (   4.815s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.757 (   4.815s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.757 (   4.815s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.757 (   4.815s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.757 (   4.816s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.757 (   4.816s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.757 (   4.816s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.757 (   4.816s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.757 (   4.816s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.757 (   4.816s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.757 (   4.816s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.757 (   4.816s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.757 (   4.816s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.759 (   4.817s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.759 (   4.817s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.759 (   4.817s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.759 (   4.817s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.759 (   4.817s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.759 (   4.817s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.759 (   4.817s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.759 (   4.817s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.759 (   4.818s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.759 (   4.818s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.759 (   4.818s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.759 (   4.818s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.761 (   4.819s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.761 (   4.819s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.761 (   4.819s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.761 (   4.819s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.761 (   4.819s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.761 (   4.819s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.761 (   4.819s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.761 (   4.819s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.761 (   4.820s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.761 (   4.820s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.761 (   4.820s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.761 (   4.820s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.767 (   4.825s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.767 (   4.825s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.767 (   4.825s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.767 (   4.826s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.767 (   4.826s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.767 (   4.826s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.767 (   4.826s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.767 (   4.826s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.767 (   4.826s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.767 (   4.826s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.773 (   4.831s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.773 (   4.831s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.779 (   4.837s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.779 (   4.837s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.779 (   4.837s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.779 (   4.838s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.779 (   4.838s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.779 (   4.838s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.779 (   4.838s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.779 (   4.838s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.779 (   4.838s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.779 (   4.838s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.785 (   4.844s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.785 (   4.844s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.791 (   4.850s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.791 (   4.850s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.791 (   4.850s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.792 (   4.850s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.792 (   4.850s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.792 (   4.850s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.792 (   4.850s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.792 (   4.850s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.792 (   4.850s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.792 (   4.851s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.797 (   4.856s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.797 (   4.856s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.799 (   4.858s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.799 (   4.858s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.799 (   4.858s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.800 (   4.858s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.800 (   4.858s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.800 (   4.858s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.800 (   4.858s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.800 (   4.858s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.800 (   4.858s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.800 (   4.858s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.800 (   4.859s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.800 (   4.859s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.801 (   4.859s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.801 (   4.859s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.801 (   4.859s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.801 (   4.859s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.801 (   4.859s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.801 (   4.859s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.801 (   4.859s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.801 (   4.859s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.801 (   4.859s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.801 (   4.859s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.801 (   4.860s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.801 (   4.860s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.802 (   4.861s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.802 (   4.861s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.802 (   4.861s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.802 (   4.861s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.802 (   4.861s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.802 (   4.861s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.802 (   4.861s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.802 (   4.861s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.803 (   4.861s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.803 (   4.861s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.803 (   4.861s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.803 (   4.861s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.805 (   4.863s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.805 (   4.863s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.805 (   4.863s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.805 (   4.863s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.805 (   4.863s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.805 (   4.863s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.805 (   4.863s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.805 (   4.863s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.805 (   4.864s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.805 (   4.864s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.805 (   4.864s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.805 (   4.864s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.811 (   4.869s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.811 (   4.869s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.811 (   4.869s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.811 (   4.870s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.811 (   4.870s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.811 (   4.870s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.811 (   4.870s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.811 (   4.870s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.811 (   4.870s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.811 (   4.870s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.817 (   4.876s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.817 (   4.876s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.824 (   4.882s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.824 (   4.882s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.824 (   4.882s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.824 (   4.883s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.824 (   4.883s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.824 (   4.883s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.824 (   4.883s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.824 (   4.883s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.824 (   4.883s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.824 (   4.883s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.830 (   4.888s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.830 (   4.888s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.836 (   4.895s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.836 (   4.895s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.836 (   4.895s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.837 (   4.895s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.837 (   4.895s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.837 (   4.895s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.837 (   4.895s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.837 (   4.895s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.837 (   4.895s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.837 (   4.895s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.842 (   4.901s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.842 (   4.901s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.844 (   4.903s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.844 (   4.903s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.844 (   4.903s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.844 (   4.903s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.844 (   4.903s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.844 (   4.903s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.844 (   4.903s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.844 (   4.903s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.845 (   4.903s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.845 (   4.903s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.845 (   4.903s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.845 (   4.903s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.845 (   4.904s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.845 (   4.904s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.845 (   4.904s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.845 (   4.904s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.845 (   4.904s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.845 (   4.904s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.845 (   4.904s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.845 (   4.904s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.845 (   4.904s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.845 (   4.904s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.846 (   4.904s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.846 (   4.904s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.847 (   4.905s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.847 (   4.905s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.847 (   4.905s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.847 (   4.906s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.847 (   4.906s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.847 (   4.906s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.847 (   4.906s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.847 (   4.906s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.847 (   4.906s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.847 (   4.906s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.847 (   4.906s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.847 (   4.906s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.849 (   4.907s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.849 (   4.907s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.849 (   4.907s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.849 (   4.908s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.849 (   4.908s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.849 (   4.908s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.849 (   4.908s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.849 (   4.908s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.849 (   4.908s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.849 (   4.908s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.849 (   4.908s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.849 (   4.908s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.855 (   4.914s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.855 (   4.914s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.855 (   4.914s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.855 (   4.914s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.855 (   4.914s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.855 (   4.914s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.855 (   4.914s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.855 (   4.914s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.855 (   4.914s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.856 (   4.914s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.861 (   4.920s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.861 (   4.920s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.867 (   4.926s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.867 (   4.926s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.867 (   4.926s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.868 (   4.926s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.868 (   4.926s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.868 (   4.926s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.868 (   4.926s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.868 (   4.926s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.868 (   4.926s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.868 (   4.926s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.873 (   4.932s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.873 (   4.932s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.880 (   4.938s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.880 (   4.938s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.880 (   4.938s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.880 (   4.939s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.880 (   4.939s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.880 (   4.939s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.880 (   4.939s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.880 (   4.939s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.880 (   4.939s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.881 (   4.939s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.886 (   4.945s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.886 (   4.945s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.888 (   4.947s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.888 (   4.947s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.888 (   4.947s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.889 (   4.947s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.889 (   4.947s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.889 (   4.947s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.889 (   4.947s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.889 (   4.947s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.889 (   4.947s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.889 (   4.947s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.889 (   4.948s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.889 (   4.948s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.890 (   4.948s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.890 (   4.948s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.890 (   4.948s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.890 (   4.948s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.890 (   4.948s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.890 (   4.948s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.890 (   4.948s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.890 (   4.948s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.890 (   4.949s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.890 (   4.949s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.890 (   4.949s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.890 (   4.949s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.891 (   4.950s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.891 (   4.950s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.891 (   4.950s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.891 (   4.950s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.891 (   4.950s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.891 (   4.950s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.891 (   4.950s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.891 (   4.950s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.892 (   4.950s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.892 (   4.950s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.892 (   4.950s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.892 (   4.950s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.893 (   4.952s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.893 (   4.952s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.893 (   4.952s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.894 (   4.952s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.894 (   4.952s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.894 (   4.952s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.894 (   4.952s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.894 (   4.952s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.894 (   4.952s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.894 (   4.952s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.894 (   4.952s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.894 (   4.952s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.900 (   4.959s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.900 (   4.959s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.900 (   4.959s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.901 (   4.959s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.901 (   4.959s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.901 (   4.959s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.901 (   4.959s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.901 (   4.959s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.901 (   4.959s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.901 (   4.959s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.907 (   4.965s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.907 (   4.965s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.913 (   4.971s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.913 (   4.971s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.913 (   4.971s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.913 (   4.972s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.913 (   4.972s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.913 (   4.972s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.913 (   4.972s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.913 (   4.972s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.913 (   4.972s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.913 (   4.972s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.919 (   4.978s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.919 (   4.978s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.926 (   4.984s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.926 (   4.984s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.926 (   4.984s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.926 (   4.985s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.926 (   4.985s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.926 (   4.985s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.926 (   4.985s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.926 (   4.985s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.926 (   4.985s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.926 (   4.985s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.932 (   4.991s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.932 (   4.991s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.934 (   4.993s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.934 (   4.993s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.934 (   4.993s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.934 (   4.993s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.934 (   4.993s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.934 (   4.993s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.934 (   4.993s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.934 (   4.993s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.934 (   4.993s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.934 (   4.993s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.935 (   4.993s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.935 (   4.993s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.935 (   4.994s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.935 (   4.994s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.935 (   4.994s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.935 (   4.994s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.935 (   4.994s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.935 (   4.994s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.935 (   4.994s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.935 (   4.994s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.935 (   4.994s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.935 (   4.994s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.935 (   4.994s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.935 (   4.994s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.937 (   4.995s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.937 (   4.995s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.937 (   4.995s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.937 (   4.995s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.937 (   4.996s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.937 (   4.996s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.937 (   4.996s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.937 (   4.996s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.937 (   4.996s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.937 (   4.996s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.937 (   4.996s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.937 (   4.996s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.939 (   4.997s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.939 (   4.997s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.939 (   4.997s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.939 (   4.998s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.939 (   4.998s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.939 (   4.998s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.939 (   4.998s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.939 (   4.998s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.939 (   4.998s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.939 (   4.998s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.939 (   4.998s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.939 (   4.998s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.945 (   5.003s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.945 (   5.004s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.945 (   5.004s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.945 (   5.004s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.945 (   5.004s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.945 (   5.004s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.945 (   5.004s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.945 (   5.004s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.946 (   5.004s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.946 (   5.004s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.951 (   5.010s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.951 (   5.010s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.957 (   5.016s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.957 (   5.016s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.957 (   5.016s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.958 (   5.016s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.958 (   5.016s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.958 (   5.016s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.958 (   5.016s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.958 (   5.016s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.958 (   5.016s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.958 (   5.016s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.963 (   5.022s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.963 (   5.022s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.970 (   5.028s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.970 (   5.028s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.970 (   5.028s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.970 (   5.029s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.970 (   5.029s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.970 (   5.029s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.970 (   5.029s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.970 (   5.029s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.971 (   5.029s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.971 (   5.029s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.976 (   5.035s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.976 (   5.035s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.978 (   5.037s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.978 (   5.037s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.978 (   5.037s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.978 (   5.037s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.978 (   5.037s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.978 (   5.037s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.978 (   5.037s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.978 (   5.037s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.979 (   5.037s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.979 (   5.037s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.979 (   5.037s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.979 (   5.037s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.979 (   5.038s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.979 (   5.038s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.979 (   5.038s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.979 (   5.038s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.979 (   5.038s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.979 (   5.038s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.979 (   5.038s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.979 (   5.038s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.980 (   5.038s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.980 (   5.038s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.980 (   5.038s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.980 (   5.038s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.981 (   5.040s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.981 (   5.040s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.981 (   5.040s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.981 (   5.040s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.981 (   5.040s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.981 (   5.040s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.981 (   5.040s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.981 (   5.040s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.981 (   5.040s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.981 (   5.040s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.981 (   5.040s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.981 (   5.040s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.983 (   5.042s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.983 (   5.042s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.983 (   5.042s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.984 (   5.042s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.984 (   5.042s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.984 (   5.042s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.984 (   5.042s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.984 (   5.042s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.984 (   5.042s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.984 (   5.042s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.984 (   5.042s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.984 (   5.042s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.989 (   5.048s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.989 (   5.048s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.989 (   5.048s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.990 (   5.048s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.990 (   5.048s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.990 (   5.048s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:33.990 (   5.048s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:33.990 (   5.048s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:33.990 (   5.049s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:33.990 (   5.049s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:33.996 (   5.054s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:33.996 (   5.054s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.002 (   5.060s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.002 (   5.060s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.002 (   5.060s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.002 (   5.061s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.002 (   5.061s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.002 (   5.061s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.002 (   5.061s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.002 (   5.061s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.002 (   5.061s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.002 (   5.061s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.008 (   5.067s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.008 (   5.067s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.014 (   5.073s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.014 (   5.073s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.014 (   5.073s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.015 (   5.074s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.015 (   5.074s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.015 (   5.074s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.015 (   5.074s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.015 (   5.074s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.015 (   5.074s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.015 (   5.074s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.021 (   5.080s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.021 (   5.080s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.024 (   5.082s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.024 (   5.082s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.024 (   5.082s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.024 (   5.083s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.024 (   5.083s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.024 (   5.083s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.024 (   5.083s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.024 (   5.083s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.024 (   5.083s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.024 (   5.083s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.025 (   5.083s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.025 (   5.083s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.025 (   5.084s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.025 (   5.084s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.025 (   5.084s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.025 (   5.084s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.025 (   5.084s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.025 (   5.084s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.025 (   5.084s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.025 (   5.084s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.025 (   5.084s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.025 (   5.084s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.026 (   5.084s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.026 (   5.084s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.027 (   5.085s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.027 (   5.085s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.027 (   5.085s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.027 (   5.086s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.027 (   5.086s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.027 (   5.086s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.027 (   5.086s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.027 (   5.086s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.027 (   5.086s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.027 (   5.086s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.027 (   5.086s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.027 (   5.086s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.029 (   5.087s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.029 (   5.087s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.029 (   5.087s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.029 (   5.088s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.029 (   5.088s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.029 (   5.088s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.029 (   5.088s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.029 (   5.088s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.029 (   5.088s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.029 (   5.088s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.030 (   5.088s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.030 (   5.088s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.035 (   5.094s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.035 (   5.094s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.035 (   5.094s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.036 (   5.094s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.036 (   5.094s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.036 (   5.094s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.036 (   5.094s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.036 (   5.094s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.036 (   5.094s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.036 (   5.094s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.042 (   5.100s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.042 (   5.100s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.048 (   5.106s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.048 (   5.106s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.048 (   5.106s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.048 (   5.107s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.048 (   5.107s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.048 (   5.107s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.048 (   5.107s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.048 (   5.107s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.048 (   5.107s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.048 (   5.107s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.054 (   5.113s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.054 (   5.113s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.061 (   5.119s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.061 (   5.119s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.061 (   5.119s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.061 (   5.120s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.061 (   5.120s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.061 (   5.120s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.061 (   5.120s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.061 (   5.120s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.061 (   5.120s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.061 (   5.120s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.065 (   5.124s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.065 (   5.124s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.067 (   5.126s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.067 (   5.126s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.067 (   5.126s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.067 (   5.126s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.067 (   5.126s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.067 (   5.126s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.067 (   5.126s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.067 (   5.126s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.067 (   5.126s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.067 (   5.126s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.067 (   5.126s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.067 (   5.126s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.068 (   5.127s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.068 (   5.127s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.068 (   5.127s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.068 (   5.127s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.068 (   5.127s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.068 (   5.127s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.068 (   5.127s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.068 (   5.127s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.068 (   5.127s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.068 (   5.127s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.068 (   5.127s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.068 (   5.127s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.069 (   5.128s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.069 (   5.128s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.069 (   5.128s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.069 (   5.128s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.069 (   5.128s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.069 (   5.128s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.069 (   5.128s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.069 (   5.128s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.069 (   5.128s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.070 (   5.128s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.070 (   5.128s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.070 (   5.128s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:34.071 (   5.130s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.071 (   5.130s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.071 (   5.130s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.071 (   5.130s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.071 (   5.130s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:34.071 (   5.130s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:34.071 (   5.130s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:34.071 (   5.130s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:34.071 (   5.130s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:34.071 (   5.130s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy

=== DEBUG: construct_inputs ===
Input prompt: '['I like taking walks in the']'
Input IDs shape: torch.Size([1, 32])
Input IDs: tensor([[128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,
         128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001,
         128001, 128001, 128001, 128001, 128001, 128001, 128001, 128000,     40,
           1093,   4737,  23291,    304,    279]])
Attention mask shape: torch.Size([1, 32])
Attention mask: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 1, 1, 1, 1, 1, 1, 1]])
Cache position shape: torch.Size([32])
Cache position: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
Actual sequence length (non-padding): 7
==================================================
RUNNING PREFILL
RUNNING DECODE
2026-01-02 18:37:36.105 (   7.164s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.105 (   7.164s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.105 (   7.164s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.105 (   7.164s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.105 (   7.164s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.106 (   7.164s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.106 (   7.164s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.106 (   7.164s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.106 (   7.164s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.106 (   7.164s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.106 (   7.164s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.106 (   7.164s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.106 (   7.165s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.106 (   7.165s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.106 (   7.165s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.106 (   7.165s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.106 (   7.165s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.106 (   7.165s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.106 (   7.165s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.106 (   7.165s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.106 (   7.165s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.106 (   7.165s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.106 (   7.165s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.106 (   7.165s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.107 (   7.165s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.107 (   7.165s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.107 (   7.165s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.107 (   7.165s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.107 (   7.165s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.107 (   7.165s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.107 (   7.165s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.107 (   7.165s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.107 (   7.165s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.107 (   7.165s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.107 (   7.166s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.107 (   7.166s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.107 (   7.166s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.107 (   7.166s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.199 (   7.257s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.199 (   7.257s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.199 (   7.257s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.199 (   7.258s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.199 (   7.258s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.199 (   7.258s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.199 (   7.258s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.199 (   7.258s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.199 (   7.258s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.199 (   7.258s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.249 (   7.308s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.249 (   7.308s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.340 (   7.399s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.341 (   7.399s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.341 (   7.399s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.341 (   7.400s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.341 (   7.400s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.341 (   7.400s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.341 (   7.400s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.341 (   7.400s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.341 (   7.400s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.341 (   7.400s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.391 (   7.449s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.391 (   7.449s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.391 (   7.449s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.391 (   7.449s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.391 (   7.449s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.391 (   7.450s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.391 (   7.450s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.391 (   7.450s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.391 (   7.450s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.391 (   7.450s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.391 (   7.450s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.392 (   7.450s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.392 (   7.450s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.392 (   7.450s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.392 (   7.450s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.392 (   7.450s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.392 (   7.450s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.392 (   7.451s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.392 (   7.451s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.392 (   7.451s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.392 (   7.451s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.392 (   7.451s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.392 (   7.451s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.392 (   7.451s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.393 (   7.451s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.393 (   7.451s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.393 (   7.451s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.393 (   7.451s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.393 (   7.451s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.393 (   7.451s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.393 (   7.451s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.393 (   7.452s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.393 (   7.452s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.393 (   7.452s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.393 (   7.452s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.393 (   7.452s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.393 (   7.452s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.393 (   7.452s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.393 (   7.452s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.393 (   7.452s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.393 (   7.452s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.394 (   7.452s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.394 (   7.452s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.394 (   7.452s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.394 (   7.452s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.394 (   7.452s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.394 (   7.452s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.394 (   7.452s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.397 (   7.455s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.397 (   7.455s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.397 (   7.455s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.397 (   7.455s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.397 (   7.455s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.397 (   7.455s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.397 (   7.455s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.397 (   7.455s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.397 (   7.455s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.397 (   7.455s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.397 (   7.456s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.397 (   7.456s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.405 (   7.463s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.405 (   7.463s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.405 (   7.463s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.405 (   7.463s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.405 (   7.463s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.405 (   7.463s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.405 (   7.463s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.405 (   7.463s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.405 (   7.463s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.405 (   7.463s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.405 (   7.464s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.406 (   7.464s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.406 (   7.465s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.407 (   7.465s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.407 (   7.465s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.407 (   7.465s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.407 (   7.465s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.407 (   7.465s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.407 (   7.465s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.407 (   7.465s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.407 (   7.465s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.407 (   7.465s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.407 (   7.465s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.407 (   7.465s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.407 (   7.465s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.407 (   7.465s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.407 (   7.466s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.408 (   7.466s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.408 (   7.466s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.408 (   7.466s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.408 (   7.466s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.408 (   7.466s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.408 (   7.466s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.408 (   7.466s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.408 (   7.466s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.408 (   7.466s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.408 (   7.466s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.408 (   7.466s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.408 (   7.466s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.408 (   7.466s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.408 (   7.467s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.409 (   7.467s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.409 (   7.467s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.409 (   7.467s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.409 (   7.467s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.409 (   7.467s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.409 (   7.467s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.409 (   7.467s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.409 (   7.467s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.409 (   7.467s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.409 (   7.467s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.409 (   7.467s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.409 (   7.467s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.409 (   7.468s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.410 (   7.468s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.410 (   7.468s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.410 (   7.468s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.410 (   7.468s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.410 (   7.468s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.410 (   7.468s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.410 (   7.468s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.410 (   7.468s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.410 (   7.468s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.410 (   7.468s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.410 (   7.468s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.410 (   7.468s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.410 (   7.469s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.411 (   7.469s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.411 (   7.470s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.412 (   7.470s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.412 (   7.471s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.413 (   7.471s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.413 (   7.472s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.414 (   7.472s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.414 (   7.473s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.415 (   7.473s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.415 (   7.474s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.416 (   7.474s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.416 (   7.475s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.417 (   7.475s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.417 (   7.476s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.418 (   7.476s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.418 (   7.476s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.418 (   7.476s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.418 (   7.476s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.418 (   7.476s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.418 (   7.476s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.418 (   7.476s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.418 (   7.476s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.418 (   7.476s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.418 (   7.476s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.418 (   7.476s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.418 (   7.476s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.418 (   7.477s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.419 (   7.477s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.419 (   7.477s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.419 (   7.477s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.419 (   7.477s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.419 (   7.477s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.419 (   7.477s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.419 (   7.477s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.419 (   7.477s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.419 (   7.477s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.419 (   7.477s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.419 (   7.477s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.419 (   7.477s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.419 (   7.477s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.419 (   7.478s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.420 (   7.478s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.420 (   7.479s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.421 (   7.479s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.421 (   7.480s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.422 (   7.480s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.422 (   7.480s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.422 (   7.480s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.422 (   7.480s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.422 (   7.480s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.422 (   7.480s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.422 (   7.480s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.422 (   7.480s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.422 (   7.480s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.422 (   7.480s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.422 (   7.480s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.422 (   7.480s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.422 (   7.481s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.423 (   7.481s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.423 (   7.481s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.423 (   7.481s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.423 (   7.481s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:36.423 (   7.481s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.423 (   7.481s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.423 (   7.481s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.423 (   7.481s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.423 (   7.481s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.423 (   7.481s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:36.423 (   7.481s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:36.423 (   7.481s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.423 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.424 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.424 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.424 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.424 (   7.482s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.424 (   7.483s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.424 (   7.483s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.424 (   7.483s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.424 (   7.483s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.424 (   7.483s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.424 (   7.483s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.424 (   7.483s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.425 (   7.483s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.425 (   7.484s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.425 (   7.484s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.426 (   7.484s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.426 (   7.484s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.426 (   7.484s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:36.461 (   7.520s) [        CBC3A000]     client_instance.cc:695      1| ClientInstance::PJRT_Client_Compile
2026-01-02 18:37:36.462 (   7.521s) [        CBC3A000]     client_instance.cc:327      1| MLIR code size: 14072 bytes
=== MLIR Code (size=14072) ===
MLRStableHLO_v1.11.0
=== End MLIR Code ===
2026-01-02 18:37:36.462 (   7.521s) [        CBC3A000]      module_builder.cc:213      1| ModuleBuilder::buildModule
2026-01-02 18:37:36.469 (   7.527s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module vhlo:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.30")
#loc4 = loc("p3.38")
#loc5 = loc("p4.43")
#loc6 = loc("p5.79")
#loc7 = loc("p6.121")
#loc8 = loc("p7.129")
#loc9 = loc("p8.151")
#loc10 = loc("p9.159")
#loc11 = loc("p10.168")
#loc12 = loc("p11.173")
#loc13 = loc("p12.182")
#loc14 = loc("p13.286")
#loc15 = loc("p14.321")
#loc16 = loc("p15.358")
#loc17 = loc("p16.448")
#loc18 = loc("p17.457")
#loc19 = loc("p18.503")
#loc43 = loc("reduce.59")
#loc82 = loc("scatter.127")
#loc91 = loc("scatter.157")
#loc159 = loc("reduce.396")
#loc164 = loc("reduce.405")
#loc187 = loc("reduce.428")
#loc224 = loc("reduce.483")
module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<32x!vhlo.i64_v1> loc("p0.3"), %arg1: !vhlo.tensor_v1<64x!vhlo.f32_v1> loc("p1.13"), %arg2: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc("p2.30"), %arg3: !vhlo.tensor_v1<1x32x!vhlo.i64_v1> loc("p3.38"), %arg4: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc("p4.43"), %arg5: !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc("p5.79"), %arg6: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1> loc("p6.121"), %arg7: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc("p7.129"), %arg8: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1> loc("p8.151"), %arg9: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc("p9.159"), %arg10: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc("p10.168"), %arg11: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc("p11.173"), %arg12: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc("p12.182"), %arg13: !vhlo.tensor_v1<1x32x!vhlo.i64_v1> loc("p13.286"), %arg14: !vhlo.tensor_v1<!vhlo.bool_v1> loc("p14.321"), %arg15: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc("p15.358"), %arg16: !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc("p16.448"), %arg17: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc("p17.457"), %arg18: !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc("p18.503")) -> (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<32x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x32x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"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tensor<128xi64>>}> : () -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc)
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xi64>>}> : () -> !vhlo.tensor_v1<32x!vhlo.i64_v1> loc(#loc)
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<128> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<3.25520843E-4> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.99999974E-6> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %8 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<8.837890e-02> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %9 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1>>}> : () -> !vhlo.tensor_v1<128x!vhlo.bool_v1> loc(#loc)
    %10 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<1> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %11 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %12 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %13 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %14 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>>}> : () -> !vhlo.tensor_v1<128x!vhlo.f32_v1> loc(#loc)
    %15 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<31> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %16 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<32> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %17 = "vhlo.broadcast_in_dim_v1"(%16) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc)
    %18 = "vhlo.broadcast_in_dim_v1"(%15) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc)
    %19 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc)
    %20 = "vhlo.broadcast_in_dim_v1"(%12) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x32x32x!vhlo.bf16_v1> loc(#loc)
    %21 = "vhlo.broadcast_in_dim_v1"(%11) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x32x32x!vhlo.bf16_v1> loc(#loc)
    %22 = "vhlo.broadcast_in_dim_v1"(%11) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.bf16_v1> loc(#loc)
    %23 = "vhlo.broadcast_in_dim_v1"(%12) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.bf16_v1> loc(#loc)
    %24 = "vhlo.broadcast_in_dim_v1"(%10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.i64_v1> loc(#loc)
    %25 = "vhlo.broadcast_in_dim_v1"(%11) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x32x128x!vhlo.bf16_v1> loc(#loc)
    %26 = "vhlo.broadcast_in_dim_v1"(%8) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc)
    %27 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x1x!vhlo.f32_v1> loc(#loc)
    %28 = "vhlo.broadcast_in_dim_v1"(%6) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x!vhlo.f32_v1> loc(#loc)
    %29 = "vhlo.broadcast_in_dim_v1"(%5) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1> loc(#loc)
    %30 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x!vhlo.i64_v1> loc(#loc)
    %31 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x!vhlo.i64_v1> loc(#loc)
    %32 = "vhlo.custom_call_v1"(%arg6) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_2">}>} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1> loc(#loc20)
    %33 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x32x!vhlo.i64_v1> loc(#loc21)
    %34 = "vhlo.custom_call_v1"(%33) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x32x!vhlo.i64_v1> loc(#loc22)
    %35 = "vhlo.reshape_v1"(%34) : (!vhlo.tensor_v1<1x1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x!vhlo.i64_v1> loc(#loc23)
    %36 = "vhlo.compare_v1"(%35, %31) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<32x!vhlo.i64_v1>, !vhlo.tensor_v1<32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x!vhlo.bool_v1> loc(#loc24)
    %37 = "vhlo.add_v1"(%35, %30) : (!vhlo.tensor_v1<32x!vhlo.i64_v1>, !vhlo.tensor_v1<32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x!vhlo.i64_v1> loc(#loc25)
    %38 = "vhlo.select_v1"(%36, %37, %35) : (!vhlo.tensor_v1<32x!vhlo.bool_v1>, !vhlo.tensor_v1<32x!vhlo.i64_v1>, !vhlo.tensor_v1<32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x!vhlo.i64_v1> loc(#loc26)
    %39 = "vhlo.reshape_v1"(%38) : (!vhlo.tensor_v1<32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x1x!vhlo.i64_v1> loc(#loc27)
    %40 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc28)
    %41 = "vhlo.custom_call_v1"(%40) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc29)
    %42 = "vhlo.reshape_v1"(%41) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc(#loc30)
    %43 = "vhlo.broadcast_in_dim_v1"(%42) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc31)
    %44 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc32)
    %45 = "vhlo.custom_call_v1"(%44) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc33)
    %46 = "vhlo.reshape_v1"(%45) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc(#loc34)
    %47 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x32x!vhlo.i64_v1> loc(#loc35)
    %48 = "vhlo.custom_call_v1"(%47) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x32x!vhlo.i64_v1> loc(#loc36)
    %49 = "vhlo.reshape_v1"(%48) : (!vhlo.tensor_v1<1x1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x!vhlo.i64_v1> loc(#loc37)
    %50 = "vhlo.convert_v1"(%49) : (!vhlo.tensor_v1<32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x!vhlo.ui32_v1> loc(#loc38)
    %51 = "vhlo.gather_v2"(%46, %50) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3072]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<32x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<32x3072x!vhlo.bf16_v1> loc(#loc39)
    %52 = "vhlo.reshape_v1"(%51) : (!vhlo.tensor_v1<32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc40)
    %53 = "vhlo.convert_v1"(%52) : (!vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1> loc(#loc41)
    %54 = "vhlo.power_v1"(%53, %29) : (!vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1> loc(#loc42)
    %55 = "vhlo.reduce_v1"(%54, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.59"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.59")):
      %249 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc44)
      "vhlo.return_v1"(%249) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x!vhlo.f32_v1> loc(#loc43)
    %56 = "vhlo.multiply_v1"(%55, %28) : (!vhlo.tensor_v1<1x32x!vhlo.f32_v1>, !vhlo.tensor_v1<1x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x!vhlo.f32_v1> loc(#loc45)
    %57 = "vhlo.reshape_v1"(%56) : (!vhlo.tensor_v1<1x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x1x!vhlo.f32_v1> loc(#loc46)
    %58 = "vhlo.add_v1"(%57, %27) : (!vhlo.tensor_v1<1x32x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x32x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x1x!vhlo.f32_v1> loc(#loc47)
    %59 = "vhlo.rsqrt_v2"(%58) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x32x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x1x!vhlo.f32_v1> loc(#loc48)
    %60 = "vhlo.reshape_v1"(%59) : (!vhlo.tensor_v1<1x32x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x!vhlo.f32_v1> loc(#loc49)
    %61 = "vhlo.broadcast_in_dim_v1"(%60) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1> loc(#loc50)
    %62 = "vhlo.multiply_v1"(%53, %61) : (!vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1> loc(#loc51)
    %63 = "vhlo.convert_v1"(%62) : (!vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc52)
    %64 = "vhlo.multiply_v1"(%43, %63) : (!vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc53)
    %65 = "vhlo.reshape_v1"(%64) : (!vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x3072x!vhlo.bf16_v1> loc(#loc54)
    %66 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc55)
    %67 = "vhlo.custom_call_v1"(%66) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc56)
    %68 = "vhlo.reshape_v1"(%67) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc(#loc57)
    %69 = "vhlo.transpose_v1"(%68) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1> loc(#loc58)
    %70 = "vhlo.dot_general_v2"(%65, %69) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<32x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x1024x!vhlo.bf16_v1> loc(#loc59)
    %71 = "vhlo.reshape_v1"(%70) : (!vhlo.tensor_v1<32x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x8x128x!vhlo.bf16_v1> loc(#loc60)
    %72 = "vhlo.transpose_v1"(%71) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,32,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x32x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1> loc(#loc61)
    %73 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc62)
    %74 = "vhlo.custom_call_v1"(%73) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"constant">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc63)
    %75 = "vhlo.reshape_v1"(%74) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1> loc(#loc64)
    %76 = "vhlo.convert_v1"(%34) : (!vhlo.tensor_v1<1x1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x32x!vhlo.f32_v1> loc(#loc65)
    %77 = "vhlo.dot_general_v2"(%75, %76) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x32x!vhlo.f32_v1> loc(#loc66)
    %78 = "vhlo.transpose_v1"(%77) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1]> : tensor<3xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[1, 2, 0]> : tensor<3xindex>>, xla_shape = #vhlo.string_v1<"f32[1,32,64]{1,2,0}">} : (!vhlo.tensor_v1<1x64x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x64x!vhlo.f32_v1> loc(#loc67)
    %79 = "vhlo.concatenate_v1"(%78, %78) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x32x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x32x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x128x!vhlo.f32_v1> loc(#loc68)
    %80 = "vhlo.cosine_v2"(%79) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x32x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x128x!vhlo.f32_v1> loc(#loc69)
    %81 = "vhlo.convert_v1"(%80) : (!vhlo.tensor_v1<1x32x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x128x!vhlo.bf16_v1> loc(#loc70)
    %82 = "vhlo.broadcast_in_dim_v1"(%81) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1> loc(#loc71)
    %83 = "vhlo.multiply_v1"(%72, %82) : (!vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1> loc(#loc72)
    %84 = "vhlo.slice_v1"(%72) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 32, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x32x64x!vhlo.bf16_v1> loc(#loc73)
    %85 = "vhlo.negate_v1"(%84) : (!vhlo.tensor_v1<1x8x32x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x32x64x!vhlo.bf16_v1> loc(#loc74)
    %86 = "vhlo.slice_v1"(%72) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 32, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x32x64x!vhlo.bf16_v1> loc(#loc75)
    %87 = "vhlo.concatenate_v1"(%85, %86) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x32x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x32x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1> loc(#loc76)
    %88 = "vhlo.sine_v2"(%79) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x32x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x128x!vhlo.f32_v1> loc(#loc77)
    %89 = "vhlo.convert_v1"(%88) : (!vhlo.tensor_v1<1x32x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x128x!vhlo.bf16_v1> loc(#loc78)
    %90 = "vhlo.broadcast_in_dim_v1"(%89) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1> loc(#loc79)
    %91 = "vhlo.multiply_v1"(%87, %90) : (!vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1> loc(#loc80)
    %92 = "vhlo.add_v1"(%83, %91) : (!vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1> loc(#loc81)
    %93 = "vhlo.scatter_v2"(%32, %39, %92) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.127"), %arg20: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.127")):
      "vhlo.return_v1"(%arg20) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<32x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1> loc(#loc82)
    %94 = "vhlo.custom_call_v1"(%arg8) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_4">}>} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1> loc(#loc83)
    %95 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc84)
    %96 = "vhlo.custom_call_v1"(%95) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc85)
    %97 = "vhlo.reshape_v1"(%96) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc(#loc86)
    %98 = "vhlo.transpose_v1"(%97) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1> loc(#loc87)
    %99 = "vhlo.dot_general_v2"(%65, %98) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<32x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x1024x!vhlo.bf16_v1> loc(#loc88)
    %100 = "vhlo.reshape_v1"(%99) : (!vhlo.tensor_v1<32x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x8x128x!vhlo.bf16_v1> loc(#loc89)
    %101 = "vhlo.transpose_v1"(%100) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,8,32,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x32x8x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1> loc(#loc90)
    %102 = "vhlo.scatter_v2"(%94, %39, %101) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.157"), %arg20: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.157")):
      "vhlo.return_v1"(%arg20) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<32x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1> loc(#loc91)
    %103 = "vhlo.reshape_v1"(%arg18) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc92)
    %104 = "vhlo.custom_call_v1"(%103) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_norm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc93)
    %105 = "vhlo.reshape_v1"(%104) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc(#loc94)
    %106 = "vhlo.broadcast_in_dim_v1"(%105) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc95)
    %107 = "vhlo.reshape_v1"(%arg15) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc96)
    %108 = "vhlo.custom_call_v1"(%107) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc97)
    %109 = "vhlo.reshape_v1"(%108) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc98)
    %110 = "vhlo.transpose_v1"(%109) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc99)
    %111 = "vhlo.dot_general_v2"(%65, %110) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<32x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x3072x!vhlo.bf16_v1> loc(#loc100)
    %112 = "vhlo.reshape_v1"(%111) : (!vhlo.tensor_v1<32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x24x128x!vhlo.bf16_v1> loc(#loc101)
    %113 = "vhlo.transpose_v1"(%112) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,32,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x32x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc102)
    %114 = "vhlo.broadcast_in_dim_v1"(%81) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc103)
    %115 = "vhlo.multiply_v1"(%113, %114) : (!vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc104)
    %116 = "vhlo.slice_v1"(%113) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 32, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x64x!vhlo.bf16_v1> loc(#loc105)
    %117 = "vhlo.negate_v1"(%116) : (!vhlo.tensor_v1<1x24x32x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x64x!vhlo.bf16_v1> loc(#loc106)
    %118 = "vhlo.slice_v1"(%113) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 32, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x64x!vhlo.bf16_v1> loc(#loc107)
    %119 = "vhlo.concatenate_v1"(%117, %118) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x32x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x32x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc108)
    %120 = "vhlo.broadcast_in_dim_v1"(%89) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc109)
    %121 = "vhlo.multiply_v1"(%119, %120) : (!vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc110)
    %122 = "vhlo.add_v1"(%115, %121) : (!vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc111)
    %123 = "vhlo.broadcast_in_dim_v1"(%93) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1> loc(#loc112)
    %124 = "vhlo.reshape_v1"(%123) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1> loc(#loc113)
    %125 = "vhlo.transpose_v1"(%124) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1> loc(#loc114)
    %126 = "vhlo.dot_general_v2"(%122, %125) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"grad_x"> = #vhlo.string_v1<"false">, #vhlo.string_v1<"grad_y"> = #vhlo.string_v1<"false">}>} : (!vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc115)
    %127 = "vhlo.multiply_v1"(%126, %26) : (!vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc116)
    %128 = "vhlo.broadcast_in_dim_v1"(%arg14) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bool_v1>) -> !vhlo.tensor_v1<128x!vhlo.bool_v1> loc(#loc117)
    %129 = "vhlo.and_v1"(%128, %9) : (!vhlo.tensor_v1<128x!vhlo.bool_v1>, !vhlo.tensor_v1<128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<128x!vhlo.bool_v1> loc(#loc118)
    %130 = "vhlo.reshape_v1"(%129) : (!vhlo.tensor_v1<128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bool_v1> loc(#loc119)
    %131 = "vhlo.reshape_v1"(%129) : (!vhlo.tensor_v1<128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bool_v1> loc(#loc120)
    %132 = "vhlo.broadcast_in_dim_v1"(%131) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<1x1x32x128x!vhlo.bool_v1> loc(#loc121)
    %133 = "vhlo.not_v1"(%130) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bool_v1> loc(#loc122)
    %134 = "vhlo.reshape_v1"(%133) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bool_v1> loc(#loc123)
    %135 = "vhlo.broadcast_in_dim_v1"(%134) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<1x1x32x128x!vhlo.bool_v1> loc(#loc124)
    %136 = "vhlo.broadcast_in_dim_v1"(%1) <{broadcast_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>}> : (!vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.i64_v1> loc(#loc125)
    %137 = "vhlo.broadcast_in_dim_v1"(%2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.i64_v1> loc(#loc126)
    %138 = "vhlo.subtract_v1"(%136, %137) : (!vhlo.tensor_v1<32x128x!vhlo.i64_v1>, !vhlo.tensor_v1<32x128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.i64_v1> loc(#loc127)
    %139 = "vhlo.compare_v1"(%138, %24) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GE>}> : (!vhlo.tensor_v1<32x128x!vhlo.i64_v1>, !vhlo.tensor_v1<32x128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.bool_v1> loc(#loc128)
    %140 = "vhlo.select_v1"(%139, %23, %22) : (!vhlo.tensor_v1<32x128x!vhlo.bool_v1>, !vhlo.tensor_v1<32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.bf16_v1> loc(#loc129)
    %141 = "vhlo.broadcast_in_dim_v1"(%35) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.i64_v1> loc(#loc130)
    %142 = "vhlo.compare_v1"(%136, %141) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<32x128x!vhlo.i64_v1>, !vhlo.tensor_v1<32x128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.bool_v1> loc(#loc131)
    %143 = "vhlo.convert_v1"(%142) : (!vhlo.tensor_v1<32x128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.bf16_v1> loc(#loc132)
    %144 = "vhlo.multiply_v1"(%140, %143) : (!vhlo.tensor_v1<32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.bf16_v1> loc(#loc133)
    %145 = "vhlo.reshape_v1"(%144) : (!vhlo.tensor_v1<32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x32x128x!vhlo.bf16_v1> loc(#loc134)
    %146 = "vhlo.slice_v1"(%145) <{limit_indices = #vhlo.tensor_v1<dense<[1, 1, 32, 32]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x1x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x32x32x!vhlo.bf16_v1> loc(#loc135)
    %147 = "vhlo.reshape_v1"(%arg13) : (!vhlo.tensor_v1<1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x32x!vhlo.i64_v1> loc(#loc136)
    %148 = "vhlo.custom_call_v1"(%147) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_3">}>} : (!vhlo.tensor_v1<1x1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x32x!vhlo.i64_v1> loc(#loc137)
    %149 = "vhlo.reshape_v1"(%148) : (!vhlo.tensor_v1<1x1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x32x!vhlo.i64_v1> loc(#loc138)
    %150 = "vhlo.convert_v1"(%149) : (!vhlo.tensor_v1<1x1x1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1> loc(#loc139)
    %151 = "vhlo.reshape_v1"(%150) : (!vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x32x!vhlo.bf16_v1> loc(#loc140)
    %152 = "vhlo.broadcast_in_dim_v1"(%151) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x32x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x32x32x!vhlo.bf16_v1> loc(#loc141)
    %153 = "vhlo.add_v1"(%146, %152) : (!vhlo.tensor_v1<1x1x32x32x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x32x32x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x32x32x!vhlo.bf16_v1> loc(#loc142)
    %154 = "vhlo.compare_v1"(%153, %21) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 EQ>}> : (!vhlo.tensor_v1<1x1x32x32x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x32x32x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x32x32x!vhlo.bool_v1> loc(#loc143)
    %155 = "vhlo.select_v1"(%154, %20, %146) : (!vhlo.tensor_v1<1x1x32x32x!vhlo.bool_v1>, !vhlo.tensor_v1<1x1x32x32x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x32x32x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x32x32x!vhlo.bf16_v1> loc(#loc144)
    %156 = "vhlo.floor_v1"(%14) : (!vhlo.tensor_v1<128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<128x!vhlo.f32_v1> loc(#loc145)
    %157 = "vhlo.convert_v1"(%156) : (!vhlo.tensor_v1<128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc146)
    %158 = "vhlo.clamp_v1"(%19, %157, %18) : (!vhlo.tensor_v1<128x!vhlo.i64_v1>, !vhlo.tensor_v1<128x!vhlo.i64_v1>, !vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc147)
    %159 = "vhlo.compare_v1"(%158, %19) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<128x!vhlo.i64_v1>, !vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.bool_v1> loc(#loc148)
    %160 = "vhlo.add_v1"(%158, %17) : (!vhlo.tensor_v1<128x!vhlo.i64_v1>, !vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc149)
    %161 = "vhlo.select_v1"(%159, %160, %158) : (!vhlo.tensor_v1<128x!vhlo.bool_v1>, !vhlo.tensor_v1<128x!vhlo.i64_v1>, !vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc150)
    %162 = "vhlo.reshape_v1"(%161) : (!vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x1x!vhlo.i64_v1> loc(#loc151)
    %163 = "vhlo.gather_v2"(%155, %162) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 1, 32, 1]> : tensor<4xi64>>, start_index_map = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<1x1x32x32x!vhlo.bf16_v1>, !vhlo.tensor_v1<128x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x32x128x!vhlo.bf16_v1> loc(#loc152)
    %164 = "vhlo.select_v1"(%135, %25, %163) : (!vhlo.tensor_v1<1x1x32x128x!vhlo.bool_v1>, !vhlo.tensor_v1<1x1x32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x32x128x!vhlo.bf16_v1> loc(#loc153)
    %165 = "vhlo.select_v1"(%132, %164, %145) : (!vhlo.tensor_v1<1x1x32x128x!vhlo.bool_v1>, !vhlo.tensor_v1<1x1x32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x32x128x!vhlo.bf16_v1> loc(#loc154)
    %166 = "vhlo.reshape_v1"(%165) : (!vhlo.tensor_v1<1x1x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x128x!vhlo.bf16_v1> loc(#loc155)
    %167 = "vhlo.broadcast_in_dim_v1"(%166) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc156)
    %168 = "vhlo.add_v1"(%127, %167) : (!vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc157)
    %169 = "vhlo.convert_v1"(%168) : (!vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1> loc(#loc158)
    %170 = "vhlo.reduce_v1"(%169, %3) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.396"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.396")):
      %249 = "vhlo.maximum_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc160)
      "vhlo.return_v1"(%249) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x32x!vhlo.f32_v1> loc(#loc159)
    %171 = "vhlo.broadcast_in_dim_v1"(%170) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1> loc(#loc161)
    %172 = "vhlo.subtract_v1"(%169, %171) : (!vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1> loc(#loc162)
    %173 = "vhlo.exponential_v2"(%172) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1> loc(#loc163)
    %174 = "vhlo.reduce_v1"(%173, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.405"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.405")):
      %249 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc165)
      "vhlo.return_v1"(%249) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x32x!vhlo.f32_v1> loc(#loc164)
    %175 = "vhlo.broadcast_in_dim_v1"(%174) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1> loc(#loc166)
    %176 = "vhlo.divide_v1"(%173, %175) : (!vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1> loc(#loc167)
    %177 = "vhlo.convert_v1"(%176) : (!vhlo.tensor_v1<1x24x32x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc168)
    %178 = "vhlo.broadcast_in_dim_v1"(%102) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1> loc(#loc169)
    %179 = "vhlo.reshape_v1"(%178) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1> loc(#loc170)
    %180 = "vhlo.dot_general_v2"(%177, %179) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"grad_x"> = #vhlo.string_v1<"false">, #vhlo.string_v1<"grad_y"> = #vhlo.string_v1<"false">}>} : (!vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1> loc(#loc171)
    %181 = "vhlo.transpose_v1"(%180) <{permutation = #vhlo.tensor_v1<dense<[0, 2, 1, 3]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[3, 1, 2, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,32,24,128]{3,1,2,0}">} : (!vhlo.tensor_v1<1x24x32x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x24x128x!vhlo.bf16_v1> loc(#loc172)
    %182 = "vhlo.reshape_v1"(%181) : (!vhlo.tensor_v1<1x32x24x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x3072x!vhlo.bf16_v1> loc(#loc173)
    %183 = "vhlo.reshape_v1"(%arg12) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc174)
    %184 = "vhlo.custom_call_v1"(%183) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc175)
    %185 = "vhlo.reshape_v1"(%184) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc176)
    %186 = "vhlo.transpose_v1"(%185) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc177)
    %187 = "vhlo.dot_general_v2"(%182, %186) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<32x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x3072x!vhlo.bf16_v1> loc(#loc178)
    %188 = "vhlo.reshape_v1"(%187) : (!vhlo.tensor_v1<32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc179)
    %189 = "vhlo.add_v1"(%52, %188) : (!vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc180)
    %190 = "vhlo.reshape_v1"(%arg16) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc181)
    %191 = "vhlo.custom_call_v1"(%190) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc182)
    %192 = "vhlo.reshape_v1"(%191) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc(#loc183)
    %193 = "vhlo.broadcast_in_dim_v1"(%192) <{broadcast_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc184)
    %194 = "vhlo.convert_v1"(%189) : (!vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1> loc(#loc185)
    %195 = "vhlo.power_v1"(%194, %29) : (!vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1> loc(#loc186)
    %196 = "vhlo.reduce_v1"(%195, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.428"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.428")):
      %249 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc188)
      "vhlo.return_v1"(%249) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x!vhlo.f32_v1> loc(#loc187)
    %197 = "vhlo.multiply_v1"(%196, %28) : (!vhlo.tensor_v1<1x32x!vhlo.f32_v1>, !vhlo.tensor_v1<1x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x!vhlo.f32_v1> loc(#loc189)
    %198 = "vhlo.reshape_v1"(%197) : (!vhlo.tensor_v1<1x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x1x!vhlo.f32_v1> loc(#loc190)
    %199 = "vhlo.add_v1"(%198, %27) : (!vhlo.tensor_v1<1x32x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x32x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x1x!vhlo.f32_v1> loc(#loc191)
    %200 = "vhlo.rsqrt_v2"(%199) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x32x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x1x!vhlo.f32_v1> loc(#loc192)
    %201 = "vhlo.reshape_v1"(%200) : (!vhlo.tensor_v1<1x32x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x!vhlo.f32_v1> loc(#loc193)
    %202 = "vhlo.broadcast_in_dim_v1"(%201) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1> loc(#loc194)
    %203 = "vhlo.multiply_v1"(%194, %202) : (!vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1> loc(#loc195)
    %204 = "vhlo.convert_v1"(%203) : (!vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc196)
    %205 = "vhlo.multiply_v1"(%193, %204) : (!vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc197)
    %206 = "vhlo.reshape_v1"(%205) : (!vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x3072x!vhlo.bf16_v1> loc(#loc198)
    %207 = "vhlo.reshape_v1"(%arg17) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc199)
    %208 = "vhlo.custom_call_v1"(%207) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc200)
    %209 = "vhlo.reshape_v1"(%208) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc(#loc201)
    %210 = "vhlo.transpose_v1"(%209) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc(#loc202)
    %211 = "vhlo.dot_general_v2"(%206, %210) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<32x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x8192x!vhlo.bf16_v1> loc(#loc203)
    %212 = "vhlo.reshape_v1"(%211) : (!vhlo.tensor_v1<32x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x8192x!vhlo.bf16_v1> loc(#loc204)
    %213 = "vhlo.logistic_v2"(%212) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x32x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x8192x!vhlo.bf16_v1> loc(#loc205)
    %214 = "vhlo.multiply_v1"(%212, %213) : (!vhlo.tensor_v1<1x32x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x32x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x8192x!vhlo.bf16_v1> loc(#loc206)
    %215 = "vhlo.reshape_v1"(%arg11) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc207)
    %216 = "vhlo.custom_call_v1"(%215) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc208)
    %217 = "vhlo.reshape_v1"(%216) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc(#loc209)
    %218 = "vhlo.transpose_v1"(%217) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc(#loc210)
    %219 = "vhlo.dot_general_v2"(%206, %218) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<32x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x8192x!vhlo.bf16_v1> loc(#loc211)
    %220 = "vhlo.reshape_v1"(%219) : (!vhlo.tensor_v1<32x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x8192x!vhlo.bf16_v1> loc(#loc212)
    %221 = "vhlo.multiply_v1"(%214, %220) : (!vhlo.tensor_v1<1x32x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x32x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x8192x!vhlo.bf16_v1> loc(#loc213)
    %222 = "vhlo.reshape_v1"(%221) : (!vhlo.tensor_v1<1x32x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x8192x!vhlo.bf16_v1> loc(#loc214)
    %223 = "vhlo.reshape_v1"(%arg10) : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1> loc(#loc215)
    %224 = "vhlo.custom_call_v1"(%223) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1> loc(#loc216)
    %225 = "vhlo.reshape_v1"(%224) : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc(#loc217)
    %226 = "vhlo.transpose_v1"(%225) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc(#loc218)
    %227 = "vhlo.dot_general_v2"(%222, %226) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<32x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x3072x!vhlo.bf16_v1> loc(#loc219)
    %228 = "vhlo.reshape_v1"(%227) : (!vhlo.tensor_v1<32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc220)
    %229 = "vhlo.add_v1"(%189, %228) : (!vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc221)
    %230 = "vhlo.convert_v1"(%229) : (!vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1> loc(#loc222)
    %231 = "vhlo.power_v1"(%230, %29) : (!vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1> loc(#loc223)
    %232 = "vhlo.reduce_v1"(%231, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.483"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.483")):
      %249 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc225)
      "vhlo.return_v1"(%249) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x!vhlo.f32_v1> loc(#loc224)
    %233 = "vhlo.multiply_v1"(%232, %28) : (!vhlo.tensor_v1<1x32x!vhlo.f32_v1>, !vhlo.tensor_v1<1x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x!vhlo.f32_v1> loc(#loc226)
    %234 = "vhlo.reshape_v1"(%233) : (!vhlo.tensor_v1<1x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x1x!vhlo.f32_v1> loc(#loc227)
    %235 = "vhlo.add_v1"(%234, %27) : (!vhlo.tensor_v1<1x32x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x32x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x1x!vhlo.f32_v1> loc(#loc228)
    %236 = "vhlo.rsqrt_v2"(%235) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x32x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x1x!vhlo.f32_v1> loc(#loc229)
    %237 = "vhlo.reshape_v1"(%236) : (!vhlo.tensor_v1<1x32x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x!vhlo.f32_v1> loc(#loc230)
    %238 = "vhlo.broadcast_in_dim_v1"(%237) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x32x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1> loc(#loc231)
    %239 = "vhlo.multiply_v1"(%230, %238) : (!vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1> loc(#loc232)
    %240 = "vhlo.convert_v1"(%239) : (!vhlo.tensor_v1<1x32x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc233)
    %241 = "vhlo.multiply_v1"(%106, %240) : (!vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1> loc(#loc234)
    %242 = "vhlo.reshape_v1"(%241) : (!vhlo.tensor_v1<1x32x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x3072x!vhlo.bf16_v1> loc(#loc235)
    %243 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc236)
    %244 = "vhlo.custom_call_v1"(%243) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___lm_head_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc237)
    %245 = "vhlo.reshape_v1"(%244) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc(#loc238)
    %246 = "vhlo.transpose_v1"(%245) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,128256]{0,1}">} : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1> loc(#loc239)
    %247 = "vhlo.dot_general_v2"(%242, %246) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<32x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<32x128256x!vhlo.bf16_v1> loc(#loc240)
    %248 = "vhlo.reshape_v1"(%247) : (!vhlo.tensor_v1<32x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x32x128256x!vhlo.bf16_v1> loc(#loc241)
    "vhlo.return_v1"(%93, %102, %247, %248) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<32x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x32x128256x!vhlo.bf16_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc20 = loc("custom-call.122")
#loc21 = loc("reshape.4")
#loc22 = loc("custom-call.5")
#loc23 = loc("reshape.6")
#loc24 = loc("compare.117")
#loc25 = loc("add.114")
#loc26 = loc("select.118")
#loc27 = loc("reshape.119")
#loc28 = loc("reshape.80")
#loc29 = loc("custom-call.81")
#loc30 = loc("reshape.82")
#loc31 = loc("broadcast.83")
#loc32 = loc("reshape.44")
#loc33 = loc("custom-call.45")
#loc34 = loc("reshape.46")
#loc35 = loc("reshape.39")
#loc36 = loc("custom-call.40")
#loc37 = loc("reshape.42")
#loc38 = loc("convert.47")
#loc39 = loc("gather.48")
#loc40 = loc("reshape.49")
#loc41 = loc("convert.50")
#loc42 = loc("power.52")
#loc44 = loc("add.58")
#loc45 = loc("multiply.68")
#loc46 = loc("reshape.69")
#loc47 = loc("add.73")
#loc48 = loc("rsqrt.74")
#loc49 = loc("reshape.75")
#loc50 = loc("broadcast.76")
#loc51 = loc("multiply.77")
#loc52 = loc("convert.78")
#loc53 = loc("multiply.84")
#loc54 = loc("reshape.85")
#loc55 = loc("reshape.31")
#loc56 = loc("custom-call.32")
#loc57 = loc("reshape.33")
#loc58 = loc("transpose.34")
#loc59 = loc("dot.86")
#loc60 = loc("reshape.88")
#loc61 = loc("transpose.89")
#loc62 = loc("reshape.14")
#loc63 = loc("custom-call.15")
#loc64 = loc("reshape.19")
#loc65 = loc("convert.11")
#loc66 = loc("dot.22")
#loc67 = loc("transpose.23")
#loc68 = loc("concatenate.24")
#loc69 = loc("cosine.98")
#loc70 = loc("convert.101")
#loc71 = loc("broadcast.104")
#loc72 = loc("multiply.105")
#loc73 = loc("slice.91")
#loc74 = loc("negate.92")
#loc75 = loc("slice.90")
#loc76 = loc("concatenate.93")
#loc77 = loc("sine.25")
#loc78 = loc("convert.28")
#loc79 = loc("broadcast.95")
#loc80 = loc("multiply.96")
#loc81 = loc("add.108")
#loc83 = loc("custom-call.152")
#loc84 = loc("reshape.130")
#loc85 = loc("custom-call.131")
#loc86 = loc("reshape.132")
#loc87 = loc("transpose.133")
#loc88 = loc("dot.135")
#loc89 = loc("reshape.137")
#loc90 = loc("transpose.138")
#loc92 = loc("reshape.504")
#loc93 = loc("custom-call.505")
#loc94 = loc("reshape.506")
#loc95 = loc("broadcast.507")
#loc96 = loc("reshape.359")
#loc97 = loc("custom-call.360")
#loc98 = loc("reshape.361")
#loc99 = loc("transpose.362")
#loc100 = loc("dot.364")
#loc101 = loc("reshape.366")
#loc102 = loc("transpose.367")
#loc103 = loc("broadcast.376")
#loc104 = loc("multiply.377")
#loc105 = loc("slice.369")
#loc106 = loc("negate.370")
#loc107 = loc("slice.368")
#loc108 = loc("concatenate.371")
#loc109 = loc("broadcast.373")
#loc110 = loc("multiply.374")
#loc111 = loc("add.380")
#loc112 = loc("broadcast.354")
#loc113 = loc("reshape.355")
#loc114 = loc("transpose.356")
#loc115 = loc("dot.381")
#loc116 = loc("multiply.384")
#loc117 = loc("broadcast.325")
#loc118 = loc("and.328")
#loc119 = loc("reshape.329")
#loc120 = loc("reshape.337")
#loc121 = loc("broadcast.338")
#loc122 = loc("not.330")
#loc123 = loc("reshape.332")
#loc124 = loc("broadcast.333")
#loc125 = loc("broadcast.225")
#loc126 = loc("broadcast.227")
#loc127 = loc("subtract.228")
#loc128 = loc("compare.230")
#loc129 = loc("select.232")
#loc130 = loc("broadcast.201")
#loc131 = loc("compare.202")
#loc132 = loc("convert.203")
#loc133 = loc("multiply.233")
#loc134 = loc("reshape.235")
#loc135 = loc("slice.297")
#loc136 = loc("reshape.287")
#loc137 = loc("custom-call.288")
#loc138 = loc("reshape.292")
#loc139 = loc("convert.298")
#loc140 = loc("reshape.301")
#loc141 = loc("broadcast.302")
#loc142 = loc("add.303")
#loc143 = loc("compare.306")
#loc144 = loc("select.308")
#loc145 = loc("floor.256")
#loc146 = loc("convert.257")
#loc147 = loc("clamp.260")
#loc148 = loc("compare.269")
#loc149 = loc("add.266")
#loc150 = loc("select.270")
#loc151 = loc("reshape.271")
#loc152 = loc("gather.310")
#loc153 = loc("select.334")
#loc154 = loc("select.339")
#loc155 = loc("reshape.387")
#loc156 = loc("broadcast.388")
#loc157 = loc("add.389")
#loc158 = loc("convert.390")
#loc160 = loc("maximum.395")
#loc161 = loc("broadcast.397")
#loc162 = loc("subtract.398")
#loc163 = loc("exponential.399")
#loc165 = loc("add.404")
#loc166 = loc("broadcast.406")
#loc167 = loc("divide.407")
#loc168 = loc("convert.408")
#loc169 = loc("broadcast.194")
#loc170 = loc("reshape.195")
#loc171 = loc("dot.409")
#loc172 = loc("transpose.411")
#loc173 = loc("reshape.413")
#loc174 = loc("reshape.183")
#loc175 = loc("custom-call.184")
#loc176 = loc("reshape.185")
#loc177 = loc("transpose.186")
#loc178 = loc("dot.414")
#loc179 = loc("reshape.415")
#loc180 = loc("add.418")
#loc181 = loc("reshape.449")
#loc182 = loc("custom-call.450")
#loc183 = loc("reshape.451")
#loc184 = loc("broadcast.452")
#loc185 = loc("convert.419")
#loc186 = loc("power.421")
#loc188 = loc("add.427")
#loc189 = loc("multiply.437")
#loc190 = loc("reshape.438")
#loc191 = loc("add.442")
#loc192 = loc("rsqrt.443")
#loc193 = loc("reshape.444")
#loc194 = loc("broadcast.445")
#loc195 = loc("multiply.446")
#loc196 = loc("convert.447")
#loc197 = loc("multiply.453")
#loc198 = loc("reshape.462")
#loc199 = loc("reshape.458")
#loc200 = loc("custom-call.459")
#loc201 = loc("reshape.460")
#loc202 = loc("transpose.461")
#loc203 = loc("dot.463")
#loc204 = loc("reshape.464")
#loc205 = loc("logistic.465")
#loc206 = loc("multiply.466")
#loc207 = loc("reshape.174")
#loc208 = loc("custom-call.175")
#loc209 = loc("reshape.176")
#loc210 = loc("transpose.177")
#loc211 = loc("dot.455")
#loc212 = loc("reshape.456")
#loc213 = loc("multiply.467")
#loc214 = loc("reshape.468")
#loc215 = loc("reshape.169")
#loc216 = loc("custom-call.170")
#loc217 = loc("reshape.171")
#loc218 = loc("transpose.172")
#loc219 = loc("dot.469")
#loc220 = loc("reshape.470")
#loc221 = loc("add.473")
#loc222 = loc("convert.474")
#loc223 = loc("power.476")
#loc225 = loc("add.482")
#loc226 = loc("multiply.492")
#loc227 = loc("reshape.493")
#loc228 = loc("add.497")
#loc229 = loc("rsqrt.498")
#loc230 = loc("reshape.499")
#loc231 = loc("broadcast.500")
#loc232 = loc("multiply.501")
#loc233 = loc("convert.502")
#loc234 = loc("multiply.508")
#loc235 = loc("reshape.512")
#loc236 = loc("reshape.160")
#loc237 = loc("custom-call.161")
#loc238 = loc("reshape.162")
#loc239 = loc("transpose.163")
#loc240 = loc("dot.513")
#loc241 = loc("reshape.514")
------------------ END OF MLIR MODULE ------------------
2026-01-02 18:37:36.493 (   7.551s) [        CBC3A000]      module_builder.cc:229      1| Extracting checkpointed MLIR code after VHLO Compiler pass
2026-01-02 18:37:36.535 (   7.593s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module shlo:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.30")
#loc4 = loc("p3.38")
#loc5 = loc("p4.43")
#loc6 = loc("p5.79")
#loc7 = loc("p6.121")
#loc8 = loc("p7.129")
#loc9 = loc("p8.151")
#loc10 = loc("p9.159")
#loc11 = loc("p10.168")
#loc12 = loc("p11.173")
#loc13 = loc("p12.182")
#loc14 = loc("p13.286")
#loc15 = loc("p14.321")
#loc16 = loc("p15.358")
#loc17 = loc("p16.448")
#loc18 = loc("p17.457")
#loc19 = loc("p18.503")
#loc81 = loc("scatter.127")
#loc90 = loc("scatter.157")
module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p0.3"), %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p2.30"), %arg3: tensor<1x32xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p3.38"), %arg4: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p4.43"), %arg5: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p5.79"), %arg6: tensor<1x8x128x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} loc("p6.121"), %arg7: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p7.129"), %arg8: tensor<1x8x128x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} loc("p8.151"), %arg9: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p9.159"), %arg10: tensor<3072x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p10.168"), %arg11: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p11.173"), %arg12: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p12.182"), %arg13: tensor<1x32xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p13.286"), %arg14: tensor<i1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"} loc("p14.321"), %arg15: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p15.358"), %arg16: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p16.448"), %arg17: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p17.457"), %arg18: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p18.503")) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %c = stablehlo.constant dense<"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tensor<128xi64> loc(#loc)
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xi64> loc(#loc)
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %c_2 = stablehlo.constant dense<128> : tensor<i64> loc(#loc)
    %cst_3 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_4 = stablehlo.constant dense<3.25520843E-4> : tensor<f32> loc(#loc)
    %cst_5 = stablehlo.constant dense<9.99999974E-6> : tensor<f32> loc(#loc)
    %cst_6 = stablehlo.constant dense<8.837890e-02> : tensor<bf16> loc(#loc)
    %c_7 = stablehlo.constant dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1> loc(#loc)
    %c_8 = stablehlo.constant dense<1> : tensor<i64> loc(#loc)
    %cst_9 = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
    %cst_10 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc)
    %c_11 = stablehlo.constant dense<0> : tensor<i64> loc(#loc)
    %cst_12 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32> loc(#loc)
    %c_13 = stablehlo.constant dense<31> : tensor<i64> loc(#loc)
    %c_14 = stablehlo.constant dense<32> : tensor<i64> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %c_14, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %c_13, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
    %3 = stablehlo.broadcast_in_dim %cst_10, dims = [] : (tensor<bf16>) -> tensor<1x1x32x32xbf16> loc(#loc)
    %4 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<bf16>) -> tensor<1x1x32x32xbf16> loc(#loc)
    %5 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<bf16>) -> tensor<32x128xbf16> loc(#loc)
    %6 = stablehlo.broadcast_in_dim %cst_10, dims = [] : (tensor<bf16>) -> tensor<32x128xbf16> loc(#loc)
    %7 = stablehlo.broadcast_in_dim %c_8, dims = [] : (tensor<i64>) -> tensor<32x128xi64> loc(#loc)
    %8 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<bf16>) -> tensor<1x1x32x128xbf16> loc(#loc)
    %9 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<1x24x32x128xbf16> loc(#loc)
    %10 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<1x32x1xf32> loc(#loc)
    %11 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<1x32xf32> loc(#loc)
    %12 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<1x32x3072xf32> loc(#loc)
    %13 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<i64>) -> tensor<32xi64> loc(#loc)
    %14 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<i64>) -> tensor<32xi64> loc(#loc)
    %15 = stablehlo.custom_call @tt.mark_argument(%arg6) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_2"}} : (tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc20)
    %16 = stablehlo.reshape %arg0 : (tensor<32xi64>) -> tensor<1x1x32xi64> loc(#loc21)
    %17 = stablehlo.custom_call @tt.mark_argument(%16) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<1x1x32xi64>) -> tensor<1x1x32xi64> loc(#loc22)
    %18 = stablehlo.reshape %17 : (tensor<1x1x32xi64>) -> tensor<32xi64> loc(#loc23)
    %19 = stablehlo.compare  LT, %18, %14 : (tensor<32xi64>, tensor<32xi64>) -> tensor<32xi1> loc(#loc24)
    %20 = stablehlo.add %18, %13 : tensor<32xi64> loc(#loc25)
    %21 = stablehlo.select %19, %20, %18 : tensor<32xi1>, tensor<32xi64> loc(#loc26)
    %22 = stablehlo.reshape %21 : (tensor<32xi64>) -> tensor<32x1xi64> loc(#loc27)
    %23 = stablehlo.reshape %arg5 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc28)
    %24 = stablehlo.custom_call @tt.mark_argument(%23) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc29)
    %25 = stablehlo.reshape %24 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc30)
    %26 = stablehlo.broadcast_in_dim %25, dims = [2] : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc31)
    %27 = stablehlo.reshape %arg4 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc32)
    %28 = stablehlo.custom_call @tt.mark_argument(%27) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_embed_tokens_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc33)
    %29 = stablehlo.reshape %28 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc34)
    %30 = stablehlo.reshape %arg3 : (tensor<1x32xi64>) -> tensor<1x1x32xi64> loc(#loc35)
    %31 = stablehlo.custom_call @tt.mark_argument(%30) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x1x32xi64>) -> tensor<1x1x32xi64> loc(#loc36)
    %32 = stablehlo.reshape %31 : (tensor<1x1x32xi64>) -> tensor<32xi64> loc(#loc37)
    %33 = stablehlo.convert %32 : (tensor<32xi64>) -> tensor<32xui32> loc(#loc38)
    %34 = "stablehlo.gather"(%29, %33) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<32xui32>) -> tensor<32x3072xbf16> loc(#loc39)
    %35 = stablehlo.reshape %34 : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc40)
    %36 = stablehlo.convert %35 : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32> loc(#loc41)
    %37 = stablehlo.power %36, %12 : tensor<1x32x3072xf32> loc(#loc42)
    %38 = stablehlo.reduce(%37 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32> loc(#loc43)
    %39 = stablehlo.multiply %38, %11 : tensor<1x32xf32> loc(#loc44)
    %40 = stablehlo.reshape %39 : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc45)
    %41 = stablehlo.add %40, %10 : tensor<1x32x1xf32> loc(#loc46)
    %42 = stablehlo.rsqrt %41 : tensor<1x32x1xf32> loc(#loc47)
    %43 = stablehlo.reshape %42 : (tensor<1x32x1xf32>) -> tensor<1x32xf32> loc(#loc48)
    %44 = stablehlo.broadcast_in_dim %43, dims = [0, 1] : (tensor<1x32xf32>) -> tensor<1x32x3072xf32> loc(#loc49)
    %45 = stablehlo.multiply %36, %44 : tensor<1x32x3072xf32> loc(#loc50)
    %46 = stablehlo.convert %45 : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16> loc(#loc51)
    %47 = stablehlo.multiply %26, %46 : tensor<1x32x3072xbf16> loc(#loc52)
    %48 = stablehlo.reshape %47 : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc53)
    %49 = stablehlo.reshape %arg2 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc54)
    %50 = stablehlo.custom_call @tt.mark_argument(%49) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc55)
    %51 = stablehlo.reshape %50 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc56)
    %52 = stablehlo.transpose %51, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc57)
    %53 = stablehlo.dot_general %48, %52, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<32x1024xbf16> loc(#loc58)
    %54 = stablehlo.reshape %53 : (tensor<32x1024xbf16>) -> tensor<1x32x8x128xbf16> loc(#loc59)
    %55 = stablehlo.transpose %54, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x8x128xbf16>) -> tensor<1x8x32x128xbf16> loc(#loc60)
    %56 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc61)
    %57 = stablehlo.custom_call @tt.mark_argument(%56) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "constant", ttir.name = "l__self___model_rotary_emb_inv_freq"}} : (tensor<1x1x64xf32>) -> tensor<1x1x64xf32> loc(#loc62)
    %58 = stablehlo.reshape %57 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc63)
    %59 = stablehlo.convert %17 : (tensor<1x1x32xi64>) -> tensor<1x1x32xf32> loc(#loc64)
    %60 = stablehlo.dot_general %58, %59, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x32xf32>) -> tensor<1x64x32xf32> loc(#loc65)
    %61 = stablehlo.transpose %60, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,32,64]{1,2,0}"} : (tensor<1x64x32xf32>) -> tensor<1x32x64xf32> loc(#loc66)
    %62 = stablehlo.concatenate %61, %61, dim = 2 : (tensor<1x32x64xf32>, tensor<1x32x64xf32>) -> tensor<1x32x128xf32> loc(#loc67)
    %63 = stablehlo.cosine %62 : tensor<1x32x128xf32> loc(#loc68)
    %64 = stablehlo.convert %63 : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16> loc(#loc69)
    %65 = stablehlo.broadcast_in_dim %64, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x8x32x128xbf16> loc(#loc70)
    %66 = stablehlo.multiply %55, %65 : tensor<1x8x32x128xbf16> loc(#loc71)
    %67 = stablehlo.slice %55 [0:1, 0:8, 0:32, 64:128] : (tensor<1x8x32x128xbf16>) -> tensor<1x8x32x64xbf16> loc(#loc72)
    %68 = stablehlo.negate %67 : tensor<1x8x32x64xbf16> loc(#loc73)
    %69 = stablehlo.slice %55 [0:1, 0:8, 0:32, 0:64] : (tensor<1x8x32x128xbf16>) -> tensor<1x8x32x64xbf16> loc(#loc74)
    %70 = stablehlo.concatenate %68, %69, dim = 3 : (tensor<1x8x32x64xbf16>, tensor<1x8x32x64xbf16>) -> tensor<1x8x32x128xbf16> loc(#loc75)
    %71 = stablehlo.sine %62 : tensor<1x32x128xf32> loc(#loc76)
    %72 = stablehlo.convert %71 : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16> loc(#loc77)
    %73 = stablehlo.broadcast_in_dim %72, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x8x32x128xbf16> loc(#loc78)
    %74 = stablehlo.multiply %70, %73 : tensor<1x8x32x128xbf16> loc(#loc79)
    %75 = stablehlo.add %66, %74 : tensor<1x8x32x128xbf16> loc(#loc80)
    %76 = "stablehlo.scatter"(%15, %22, %75) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16> loc("scatter.127"), %arg20: tensor<bf16> loc("scatter.127")):
      stablehlo.return %arg20 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x128x128xbf16>, tensor<32x1xi64>, tensor<1x8x32x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc81)
    %77 = stablehlo.custom_call @tt.mark_argument(%arg8) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_4"}} : (tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc82)
    %78 = stablehlo.reshape %arg7 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc83)
    %79 = stablehlo.custom_call @tt.mark_argument(%78) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc84)
    %80 = stablehlo.reshape %79 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc85)
    %81 = stablehlo.transpose %80, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc86)
    %82 = stablehlo.dot_general %48, %81, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<32x1024xbf16> loc(#loc87)
    %83 = stablehlo.reshape %82 : (tensor<32x1024xbf16>) -> tensor<1x32x8x128xbf16> loc(#loc88)
    %84 = stablehlo.transpose %83, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x8x128xbf16>) -> tensor<1x8x32x128xbf16> loc(#loc89)
    %85 = "stablehlo.scatter"(%77, %22, %84) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16> loc("scatter.157"), %arg20: tensor<bf16> loc("scatter.157")):
      stablehlo.return %arg20 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x128x128xbf16>, tensor<32x1xi64>, tensor<1x8x32x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc90)
    %86 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc91)
    %87 = stablehlo.custom_call @tt.mark_argument(%86) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_norm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc92)
    %88 = stablehlo.reshape %87 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc93)
    %89 = stablehlo.broadcast_in_dim %88, dims = [2] : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc94)
    %90 = stablehlo.reshape %arg15 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc95)
    %91 = stablehlo.custom_call @tt.mark_argument(%90) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc96)
    %92 = stablehlo.reshape %91 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc97)
    %93 = stablehlo.transpose %92, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc98)
    %94 = stablehlo.dot_general %48, %93, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc99)
    %95 = stablehlo.reshape %94 : (tensor<32x3072xbf16>) -> tensor<1x32x24x128xbf16> loc(#loc100)
    %96 = stablehlo.transpose %95, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,32,128]{3,1,2,0}"} : (tensor<1x32x24x128xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc101)
    %97 = stablehlo.broadcast_in_dim %64, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc102)
    %98 = stablehlo.multiply %96, %97 : tensor<1x24x32x128xbf16> loc(#loc103)
    %99 = stablehlo.slice %96 [0:1, 0:24, 0:32, 64:128] : (tensor<1x24x32x128xbf16>) -> tensor<1x24x32x64xbf16> loc(#loc104)
    %100 = stablehlo.negate %99 : tensor<1x24x32x64xbf16> loc(#loc105)
    %101 = stablehlo.slice %96 [0:1, 0:24, 0:32, 0:64] : (tensor<1x24x32x128xbf16>) -> tensor<1x24x32x64xbf16> loc(#loc106)
    %102 = stablehlo.concatenate %100, %101, dim = 3 : (tensor<1x24x32x64xbf16>, tensor<1x24x32x64xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc107)
    %103 = stablehlo.broadcast_in_dim %72, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc108)
    %104 = stablehlo.multiply %102, %103 : tensor<1x24x32x128xbf16> loc(#loc109)
    %105 = stablehlo.add %98, %104 : tensor<1x24x32x128xbf16> loc(#loc110)
    %106 = stablehlo.broadcast_in_dim %76, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16> loc(#loc111)
    %107 = stablehlo.reshape %106 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16> loc(#loc112)
    %108 = stablehlo.transpose %107, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16> loc(#loc113)
    %109 = stablehlo.dot_general %105, %108, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x24x32x128xbf16>, tensor<1x24x128x128xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc114)
    %110 = stablehlo.multiply %109, %9 : tensor<1x24x32x128xbf16> loc(#loc115)
    %111 = stablehlo.broadcast_in_dim %arg14, dims = [] : (tensor<i1>) -> tensor<128xi1> loc(#loc116)
    %112 = stablehlo.and %111, %c_7 : tensor<128xi1> loc(#loc117)
    %113 = stablehlo.reshape %112 : (tensor<128xi1>) -> tensor<1x1x1x128xi1> loc(#loc118)
    %114 = stablehlo.reshape %112 : (tensor<128xi1>) -> tensor<1x1x128xi1> loc(#loc119)
    %115 = stablehlo.broadcast_in_dim %114, dims = [0, 1, 3] : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1> loc(#loc120)
    %116 = stablehlo.not %113 : tensor<1x1x1x128xi1> loc(#loc121)
    %117 = stablehlo.reshape %116 : (tensor<1x1x1x128xi1>) -> tensor<1x1x128xi1> loc(#loc122)
    %118 = stablehlo.broadcast_in_dim %117, dims = [0, 1, 3] : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1> loc(#loc123)
    %119 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<128xi64>) -> tensor<32x128xi64> loc(#loc124)
    %120 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<32xi64>) -> tensor<32x128xi64> loc(#loc125)
    %121 = stablehlo.subtract %119, %120 : tensor<32x128xi64> loc(#loc126)
    %122 = stablehlo.compare  GE, %121, %7 : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1> loc(#loc127)
    %123 = stablehlo.select %122, %6, %5 : tensor<32x128xi1>, tensor<32x128xbf16> loc(#loc128)
    %124 = stablehlo.broadcast_in_dim %18, dims = [0] : (tensor<32xi64>) -> tensor<32x128xi64> loc(#loc129)
    %125 = stablehlo.compare  GT, %119, %124 : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1> loc(#loc130)
    %126 = stablehlo.convert %125 : (tensor<32x128xi1>) -> tensor<32x128xbf16> loc(#loc131)
    %127 = stablehlo.multiply %123, %126 : tensor<32x128xbf16> loc(#loc132)
    %128 = stablehlo.reshape %127 : (tensor<32x128xbf16>) -> tensor<1x1x32x128xbf16> loc(#loc133)
    %129 = stablehlo.slice %128 [0:1, 0:1, 0:32, 0:32] : (tensor<1x1x32x128xbf16>) -> tensor<1x1x32x32xbf16> loc(#loc134)
    %130 = stablehlo.reshape %arg13 : (tensor<1x32xi64>) -> tensor<1x1x32xi64> loc(#loc135)
    %131 = stablehlo.custom_call @tt.mark_argument(%130) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_3"}} : (tensor<1x1x32xi64>) -> tensor<1x1x32xi64> loc(#loc136)
    %132 = stablehlo.reshape %131 : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64> loc(#loc137)
    %133 = stablehlo.convert %132 : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16> loc(#loc138)
    %134 = stablehlo.reshape %133 : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32xbf16> loc(#loc139)
    %135 = stablehlo.broadcast_in_dim %134, dims = [0, 1, 3] : (tensor<1x1x32xbf16>) -> tensor<1x1x32x32xbf16> loc(#loc140)
    %136 = stablehlo.add %129, %135 : tensor<1x1x32x32xbf16> loc(#loc141)
    %137 = stablehlo.compare  EQ, %136, %4 : (tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xi1> loc(#loc142)
    %138 = stablehlo.select %137, %3, %129 : tensor<1x1x32x32xi1>, tensor<1x1x32x32xbf16> loc(#loc143)
    %139 = stablehlo.floor %cst_12 : tensor<128xf32> loc(#loc144)
    %140 = stablehlo.convert %139 : (tensor<128xf32>) -> tensor<128xi64> loc(#loc145)
    %141 = stablehlo.clamp %2, %140, %1 : tensor<128xi64> loc(#loc146)
    %142 = stablehlo.compare  LT, %141, %2 : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1> loc(#loc147)
    %143 = stablehlo.add %141, %0 : tensor<128xi64> loc(#loc148)
    %144 = stablehlo.select %142, %143, %141 : tensor<128xi1>, tensor<128xi64> loc(#loc149)
    %145 = stablehlo.reshape %144 : (tensor<128xi64>) -> tensor<128x1xi64> loc(#loc150)
    %146 = "stablehlo.gather"(%138, %145) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 32, 1>}> : (tensor<1x1x32x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x32x128xbf16> loc(#loc151)
    %147 = stablehlo.select %118, %8, %146 : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16> loc(#loc152)
    %148 = stablehlo.select %115, %147, %128 : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16> loc(#loc153)
    %149 = stablehlo.reshape %148 : (tensor<1x1x32x128xbf16>) -> tensor<1x32x128xbf16> loc(#loc154)
    %150 = stablehlo.broadcast_in_dim %149, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc155)
    %151 = stablehlo.add %110, %150 : tensor<1x24x32x128xbf16> loc(#loc156)
    %152 = stablehlo.convert %151 : (tensor<1x24x32x128xbf16>) -> tensor<1x24x32x128xf32> loc(#loc157)
    %153 = stablehlo.reduce(%152 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x32x128xf32>, tensor<f32>) -> tensor<1x24x32xf32> loc(#loc158)
    %154 = stablehlo.broadcast_in_dim %153, dims = [0, 1, 2] : (tensor<1x24x32xf32>) -> tensor<1x24x32x128xf32> loc(#loc159)
    %155 = stablehlo.subtract %152, %154 : tensor<1x24x32x128xf32> loc(#loc160)
    %156 = stablehlo.exponential %155 : tensor<1x24x32x128xf32> loc(#loc161)
    %157 = stablehlo.reduce(%156 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x32x128xf32>, tensor<f32>) -> tensor<1x24x32xf32> loc(#loc162)
    %158 = stablehlo.broadcast_in_dim %157, dims = [0, 1, 2] : (tensor<1x24x32xf32>) -> tensor<1x24x32x128xf32> loc(#loc163)
    %159 = stablehlo.divide %156, %158 : tensor<1x24x32x128xf32> loc(#loc164)
    %160 = stablehlo.convert %159 : (tensor<1x24x32x128xf32>) -> tensor<1x24x32x128xbf16> loc(#loc165)
    %161 = stablehlo.broadcast_in_dim %85, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16> loc(#loc166)
    %162 = stablehlo.reshape %161 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16> loc(#loc167)
    %163 = stablehlo.dot_general %160, %162, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x24x32x128xbf16>, tensor<1x24x128x128xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc168)
    %164 = stablehlo.transpose %163, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,32,24,128]{3,1,2,0}"} : (tensor<1x24x32x128xbf16>) -> tensor<1x32x24x128xbf16> loc(#loc169)
    %165 = stablehlo.reshape %164 : (tensor<1x32x24x128xbf16>) -> tensor<32x3072xbf16> loc(#loc170)
    %166 = stablehlo.reshape %arg12 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc171)
    %167 = stablehlo.custom_call @tt.mark_argument(%166) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc172)
    %168 = stablehlo.reshape %167 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc173)
    %169 = stablehlo.transpose %168, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc174)
    %170 = stablehlo.dot_general %165, %169, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc175)
    %171 = stablehlo.reshape %170 : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc176)
    %172 = stablehlo.add %35, %171 : tensor<1x32x3072xbf16> loc(#loc177)
    %173 = stablehlo.reshape %arg16 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc178)
    %174 = stablehlo.custom_call @tt.mark_argument(%173) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc179)
    %175 = stablehlo.reshape %174 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc180)
    %176 = stablehlo.broadcast_in_dim %175, dims = [2] : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc181)
    %177 = stablehlo.convert %172 : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32> loc(#loc182)
    %178 = stablehlo.power %177, %12 : tensor<1x32x3072xf32> loc(#loc183)
    %179 = stablehlo.reduce(%178 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32> loc(#loc184)
    %180 = stablehlo.multiply %179, %11 : tensor<1x32xf32> loc(#loc185)
    %181 = stablehlo.reshape %180 : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc186)
    %182 = stablehlo.add %181, %10 : tensor<1x32x1xf32> loc(#loc187)
    %183 = stablehlo.rsqrt %182 : tensor<1x32x1xf32> loc(#loc188)
    %184 = stablehlo.reshape %183 : (tensor<1x32x1xf32>) -> tensor<1x32xf32> loc(#loc189)
    %185 = stablehlo.broadcast_in_dim %184, dims = [0, 1] : (tensor<1x32xf32>) -> tensor<1x32x3072xf32> loc(#loc190)
    %186 = stablehlo.multiply %177, %185 : tensor<1x32x3072xf32> loc(#loc191)
    %187 = stablehlo.convert %186 : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16> loc(#loc192)
    %188 = stablehlo.multiply %176, %187 : tensor<1x32x3072xbf16> loc(#loc193)
    %189 = stablehlo.reshape %188 : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc194)
    %190 = stablehlo.reshape %arg17 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc195)
    %191 = stablehlo.custom_call @tt.mark_argument(%190) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc196)
    %192 = stablehlo.reshape %191 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc197)
    %193 = stablehlo.transpose %192, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc198)
    %194 = stablehlo.dot_general %189, %193, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<32x8192xbf16> loc(#loc199)
    %195 = stablehlo.reshape %194 : (tensor<32x8192xbf16>) -> tensor<1x32x8192xbf16> loc(#loc200)
    %196 = stablehlo.logistic %195 : tensor<1x32x8192xbf16> loc(#loc201)
    %197 = stablehlo.multiply %195, %196 : tensor<1x32x8192xbf16> loc(#loc202)
    %198 = stablehlo.reshape %arg11 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc203)
    %199 = stablehlo.custom_call @tt.mark_argument(%198) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc204)
    %200 = stablehlo.reshape %199 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc205)
    %201 = stablehlo.transpose %200, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc206)
    %202 = stablehlo.dot_general %189, %201, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<32x8192xbf16> loc(#loc207)
    %203 = stablehlo.reshape %202 : (tensor<32x8192xbf16>) -> tensor<1x32x8192xbf16> loc(#loc208)
    %204 = stablehlo.multiply %197, %203 : tensor<1x32x8192xbf16> loc(#loc209)
    %205 = stablehlo.reshape %204 : (tensor<1x32x8192xbf16>) -> tensor<32x8192xbf16> loc(#loc210)
    %206 = stablehlo.reshape %arg10 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16> loc(#loc211)
    %207 = stablehlo.custom_call @tt.mark_argument(%206) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}} : (tensor<1x3072x8192xbf16>) -> tensor<1x3072x8192xbf16> loc(#loc212)
    %208 = stablehlo.reshape %207 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16> loc(#loc213)
    %209 = stablehlo.transpose %208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16> loc(#loc214)
    %210 = stablehlo.dot_general %205, %209, contracting_dims = [1] x [0] : (tensor<32x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc215)
    %211 = stablehlo.reshape %210 : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc216)
    %212 = stablehlo.add %172, %211 : tensor<1x32x3072xbf16> loc(#loc217)
    %213 = stablehlo.convert %212 : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32> loc(#loc218)
    %214 = stablehlo.power %213, %12 : tensor<1x32x3072xf32> loc(#loc219)
    %215 = stablehlo.reduce(%214 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32> loc(#loc220)
    %216 = stablehlo.multiply %215, %11 : tensor<1x32xf32> loc(#loc221)
    %217 = stablehlo.reshape %216 : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc222)
    %218 = stablehlo.add %217, %10 : tensor<1x32x1xf32> loc(#loc223)
    %219 = stablehlo.rsqrt %218 : tensor<1x32x1xf32> loc(#loc224)
    %220 = stablehlo.reshape %219 : (tensor<1x32x1xf32>) -> tensor<1x32xf32> loc(#loc225)
    %221 = stablehlo.broadcast_in_dim %220, dims = [0, 1] : (tensor<1x32xf32>) -> tensor<1x32x3072xf32> loc(#loc226)
    %222 = stablehlo.multiply %213, %221 : tensor<1x32x3072xf32> loc(#loc227)
    %223 = stablehlo.convert %222 : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16> loc(#loc228)
    %224 = stablehlo.multiply %89, %223 : tensor<1x32x3072xbf16> loc(#loc229)
    %225 = stablehlo.reshape %224 : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc230)
    %226 = stablehlo.reshape %arg9 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc231)
    %227 = stablehlo.custom_call @tt.mark_argument(%226) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___lm_head_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc232)
    %228 = stablehlo.reshape %227 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc233)
    %229 = stablehlo.transpose %228, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc234)
    %230 = stablehlo.dot_general %225, %229, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<32x128256xbf16> loc(#loc235)
    %231 = stablehlo.reshape %230 : (tensor<32x128256xbf16>) -> tensor<1x32x128256xbf16> loc(#loc236)
    return %76, %85, %230, %231 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc20 = loc("custom-call.122")
#loc21 = loc("reshape.4")
#loc22 = loc("custom-call.5")
#loc23 = loc("reshape.6")
#loc24 = loc("compare.117")
#loc25 = loc("add.114")
#loc26 = loc("select.118")
#loc27 = loc("reshape.119")
#loc28 = loc("reshape.80")
#loc29 = loc("custom-call.81")
#loc30 = loc("reshape.82")
#loc31 = loc("broadcast.83")
#loc32 = loc("reshape.44")
#loc33 = loc("custom-call.45")
#loc34 = loc("reshape.46")
#loc35 = loc("reshape.39")
#loc36 = loc("custom-call.40")
#loc37 = loc("reshape.42")
#loc38 = loc("convert.47")
#loc39 = loc("gather.48")
#loc40 = loc("reshape.49")
#loc41 = loc("convert.50")
#loc42 = loc("power.52")
#loc43 = loc("reduce.59")
#loc44 = loc("multiply.68")
#loc45 = loc("reshape.69")
#loc46 = loc("add.73")
#loc47 = loc("rsqrt.74")
#loc48 = loc("reshape.75")
#loc49 = loc("broadcast.76")
#loc50 = loc("multiply.77")
#loc51 = loc("convert.78")
#loc52 = loc("multiply.84")
#loc53 = loc("reshape.85")
#loc54 = loc("reshape.31")
#loc55 = loc("custom-call.32")
#loc56 = loc("reshape.33")
#loc57 = loc("transpose.34")
#loc58 = loc("dot.86")
#loc59 = loc("reshape.88")
#loc60 = loc("transpose.89")
#loc61 = loc("reshape.14")
#loc62 = loc("custom-call.15")
#loc63 = loc("reshape.19")
#loc64 = loc("convert.11")
#loc65 = loc("dot.22")
#loc66 = loc("transpose.23")
#loc67 = loc("concatenate.24")
#loc68 = loc("cosine.98")
#loc69 = loc("convert.101")
#loc70 = loc("broadcast.104")
#loc71 = loc("multiply.105")
#loc72 = loc("slice.91")
#loc73 = loc("negate.92")
#loc74 = loc("slice.90")
#loc75 = loc("concatenate.93")
#loc76 = loc("sine.25")
#loc77 = loc("convert.28")
#loc78 = loc("broadcast.95")
#loc79 = loc("multiply.96")
#loc80 = loc("add.108")
#loc82 = loc("custom-call.152")
#loc83 = loc("reshape.130")
#loc84 = loc("custom-call.131")
#loc85 = loc("reshape.132")
#loc86 = loc("transpose.133")
#loc87 = loc("dot.135")
#loc88 = loc("reshape.137")
#loc89 = loc("transpose.138")
#loc91 = loc("reshape.504")
#loc92 = loc("custom-call.505")
#loc93 = loc("reshape.506")
#loc94 = loc("broadcast.507")
#loc95 = loc("reshape.359")
#loc96 = loc("custom-call.360")
#loc97 = loc("reshape.361")
#loc98 = loc("transpose.362")
#loc99 = loc("dot.364")
#loc100 = loc("reshape.366")
#loc101 = loc("transpose.367")
#loc102 = loc("broadcast.376")
#loc103 = loc("multiply.377")
#loc104 = loc("slice.369")
#loc105 = loc("negate.370")
#loc106 = loc("slice.368")
#loc107 = loc("concatenate.371")
#loc108 = loc("broadcast.373")
#loc109 = loc("multiply.374")
#loc110 = loc("add.380")
#loc111 = loc("broadcast.354")
#loc112 = loc("reshape.355")
#loc113 = loc("transpose.356")
#loc114 = loc("dot.381")
#loc115 = loc("multiply.384")
#loc116 = loc("broadcast.325")
#loc117 = loc("and.328")
#loc118 = loc("reshape.329")
#loc119 = loc("reshape.337")
#loc120 = loc("broadcast.338")
#loc121 = loc("not.330")
#loc122 = loc("reshape.332")
#loc123 = loc("broadcast.333")
#loc124 = loc("broadcast.225")
#loc125 = loc("broadcast.227")
#loc126 = loc("subtract.228")
#loc127 = loc("compare.230")
#loc128 = loc("select.232")
#loc129 = loc("broadcast.201")
#loc130 = loc("compare.202")
#loc131 = loc("convert.203")
#loc132 = loc("multiply.233")
#loc133 = loc("reshape.235")
#loc134 = loc("slice.297")
#loc135 = loc("reshape.287")
#loc136 = loc("custom-call.288")
#loc137 = loc("reshape.292")
#loc138 = loc("convert.298")
#loc139 = loc("reshape.301")
#loc140 = loc("broadcast.302")
#loc141 = loc("add.303")
#loc142 = loc("compare.306")
#loc143 = loc("select.308")
#loc144 = loc("floor.256")
#loc145 = loc("convert.257")
#loc146 = loc("clamp.260")
#loc147 = loc("compare.269")
#loc148 = loc("add.266")
#loc149 = loc("select.270")
#loc150 = loc("reshape.271")
#loc151 = loc("gather.310")
#loc152 = loc("select.334")
#loc153 = loc("select.339")
#loc154 = loc("reshape.387")
#loc155 = loc("broadcast.388")
#loc156 = loc("add.389")
#loc157 = loc("convert.390")
#loc158 = loc("reduce.396")
#loc159 = loc("broadcast.397")
#loc160 = loc("subtract.398")
#loc161 = loc("exponential.399")
#loc162 = loc("reduce.405")
#loc163 = loc("broadcast.406")
#loc164 = loc("divide.407")
#loc165 = loc("convert.408")
#loc166 = loc("broadcast.194")
#loc167 = loc("reshape.195")
#loc168 = loc("dot.409")
#loc169 = loc("transpose.411")
#loc170 = loc("reshape.413")
#loc171 = loc("reshape.183")
#loc172 = loc("custom-call.184")
#loc173 = loc("reshape.185")
#loc174 = loc("transpose.186")
#loc175 = loc("dot.414")
#loc176 = loc("reshape.415")
#loc177 = loc("add.418")
#loc178 = loc("reshape.449")
#loc179 = loc("custom-call.450")
#loc180 = loc("reshape.451")
#loc181 = loc("broadcast.452")
#loc182 = loc("convert.419")
#loc183 = loc("power.421")
#loc184 = loc("reduce.428")
#loc185 = loc("multiply.437")
#loc186 = loc("reshape.438")
#loc187 = loc("add.442")
#loc188 = loc("rsqrt.443")
#loc189 = loc("reshape.444")
#loc190 = loc("broadcast.445")
#loc191 = loc("multiply.446")
#loc192 = loc("convert.447")
#loc193 = loc("multiply.453")
#loc194 = loc("reshape.462")
#loc195 = loc("reshape.458")
#loc196 = loc("custom-call.459")
#loc197 = loc("reshape.460")
#loc198 = loc("transpose.461")
#loc199 = loc("dot.463")
#loc200 = loc("reshape.464")
#loc201 = loc("logistic.465")
#loc202 = loc("multiply.466")
#loc203 = loc("reshape.174")
#loc204 = loc("custom-call.175")
#loc205 = loc("reshape.176")
#loc206 = loc("transpose.177")
#loc207 = loc("dot.455")
#loc208 = loc("reshape.456")
#loc209 = loc("multiply.467")
#loc210 = loc("reshape.468")
#loc211 = loc("reshape.169")
#loc212 = loc("custom-call.170")
#loc213 = loc("reshape.171")
#loc214 = loc("transpose.172")
#loc215 = loc("dot.469")
#loc216 = loc("reshape.470")
#loc217 = loc("add.473")
#loc218 = loc("convert.474")
#loc219 = loc("power.476")
#loc220 = loc("reduce.483")
#loc221 = loc("multiply.492")
#loc222 = loc("reshape.493")
#loc223 = loc("add.497")
#loc224 = loc("rsqrt.498")
#loc225 = loc("reshape.499")
#loc226 = loc("broadcast.500")
#loc227 = loc("multiply.501")
#loc228 = loc("convert.502")
#loc229 = loc("multiply.508")
#loc230 = loc("reshape.512")
#loc231 = loc("reshape.160")
#loc232 = loc("custom-call.161")
#loc233 = loc("reshape.162")
#loc234 = loc("transpose.163")
#loc235 = loc("dot.513")
#loc236 = loc("reshape.514")
------------------ END OF MLIR MODULE ------------------
2026-01-02 18:37:36.553 (   7.612s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module shlo_frontend:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.30")
#loc4 = loc("p3.38")
#loc5 = loc("p4.43")
#loc6 = loc("p5.79")
#loc7 = loc("p6.121")
#loc8 = loc("p7.129")
#loc9 = loc("p8.151")
#loc10 = loc("p9.159")
#loc11 = loc("p10.168")
#loc12 = loc("p11.173")
#loc13 = loc("p12.182")
#loc14 = loc("p13.286")
#loc15 = loc("p14.321")
#loc16 = loc("p15.358")
#loc17 = loc("p16.448")
#loc18 = loc("p17.457")
#loc19 = loc("p18.503")
#loc74 = loc("scatter.127")
#loc81 = loc("scatter.157")
module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.30"), %arg3: tensor<1x32xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("p3.38"), %arg4: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p4.43"), %arg5: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p5.79"), %arg6: tensor<1x8x128x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"} loc("p6.121"), %arg7: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p7.129"), %arg8: tensor<1x8x128x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_4"} loc("p8.151"), %arg9: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"} loc("p9.159"), %arg10: tensor<3072x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p10.168"), %arg11: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p11.173"), %arg12: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p12.182"), %arg13: tensor<1x32xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_3"} loc("p13.286"), %arg14: tensor<i1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>} loc("p14.321"), %arg15: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p15.358"), %arg16: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p16.448"), %arg17: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p17.457"), %arg18: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"} loc("p18.503")) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %c = stablehlo.constant dense<"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tensor<128xi64> loc(#loc)
    %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xi64> loc(#loc)
    %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %c_2 = stablehlo.constant dense<128> : tensor<i64> loc(#loc)
    %cst_3 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_4 = stablehlo.constant dense<3.25520843E-4> : tensor<f32> loc(#loc)
    %cst_5 = stablehlo.constant dense<9.99999974E-6> : tensor<f32> loc(#loc)
    %cst_6 = stablehlo.constant dense<8.837890e-02> : tensor<bf16> loc(#loc)
    %c_7 = stablehlo.constant dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1> loc(#loc)
    %c_8 = stablehlo.constant dense<1> : tensor<i64> loc(#loc)
    %cst_9 = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
    %cst_10 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc)
    %c_11 = stablehlo.constant dense<0> : tensor<i64> loc(#loc)
    %cst_12 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32> loc(#loc)
    %c_13 = stablehlo.constant dense<31> : tensor<i64> loc(#loc)
    %c_14 = stablehlo.constant dense<32> : tensor<i64> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %c_14, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %c_13, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
    %3 = stablehlo.broadcast_in_dim %cst_10, dims = [] : (tensor<bf16>) -> tensor<1x1x32x32xbf16> loc(#loc)
    %4 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<bf16>) -> tensor<1x1x32x32xbf16> loc(#loc)
    %5 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<bf16>) -> tensor<32x128xbf16> loc(#loc)
    %6 = stablehlo.broadcast_in_dim %cst_10, dims = [] : (tensor<bf16>) -> tensor<32x128xbf16> loc(#loc)
    %7 = stablehlo.broadcast_in_dim %c_8, dims = [] : (tensor<i64>) -> tensor<32x128xi64> loc(#loc)
    %8 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<bf16>) -> tensor<1x1x32x128xbf16> loc(#loc)
    %9 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<1x24x32x128xbf16> loc(#loc)
    %10 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<1x32x1xf32> loc(#loc)
    %11 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<1x32xf32> loc(#loc)
    %12 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<1x32x3072xf32> loc(#loc)
    %13 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<i64>) -> tensor<32xi64> loc(#loc)
    %14 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<i64>) -> tensor<32xi64> loc(#loc)
    %15 = stablehlo.reshape %arg0 : (tensor<32xi64>) -> tensor<1x1x32xi64> loc(#loc20)
    %16 = stablehlo.reshape %15 : (tensor<1x1x32xi64>) -> tensor<32xi64> loc(#loc21)
    %17 = stablehlo.compare  LT, %16, %14 : (tensor<32xi64>, tensor<32xi64>) -> tensor<32xi1> loc(#loc22)
    %18 = stablehlo.add %16, %13 : tensor<32xi64> loc(#loc23)
    %19 = stablehlo.select %17, %18, %16 : tensor<32xi1>, tensor<32xi64> loc(#loc24)
    %20 = stablehlo.reshape %19 : (tensor<32xi64>) -> tensor<32x1xi64> loc(#loc25)
    %21 = stablehlo.reshape %arg5 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc26)
    %22 = stablehlo.reshape %21 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc27)
    %23 = stablehlo.broadcast_in_dim %22, dims = [2] : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc28)
    %24 = stablehlo.reshape %arg4 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc29)
    %25 = stablehlo.reshape %24 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc30)
    %26 = stablehlo.reshape %arg3 : (tensor<1x32xi64>) -> tensor<1x1x32xi64> loc(#loc31)
    %27 = stablehlo.reshape %26 : (tensor<1x1x32xi64>) -> tensor<32xi64> loc(#loc32)
    %28 = stablehlo.convert %27 : (tensor<32xi64>) -> tensor<32xui32> loc(#loc33)
    %29 = "stablehlo.gather"(%25, %28) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<32xui32>) -> tensor<32x3072xbf16> loc(#loc34)
    %30 = stablehlo.reshape %29 : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc35)
    %31 = stablehlo.convert %30 : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32> loc(#loc36)
    %32 = stablehlo.power %31, %12 : tensor<1x32x3072xf32> loc(#loc37)
    %33 = stablehlo.reduce(%32 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32> loc(#loc38)
    %34 = stablehlo.multiply %33, %11 : tensor<1x32xf32> loc(#loc39)
    %35 = stablehlo.reshape %34 : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc40)
    %36 = stablehlo.add %35, %10 : tensor<1x32x1xf32> loc(#loc41)
    %37 = stablehlo.rsqrt %36 : tensor<1x32x1xf32> loc(#loc42)
    %38 = stablehlo.reshape %37 : (tensor<1x32x1xf32>) -> tensor<1x32xf32> loc(#loc43)
    %39 = stablehlo.broadcast_in_dim %38, dims = [0, 1] : (tensor<1x32xf32>) -> tensor<1x32x3072xf32> loc(#loc44)
    %40 = stablehlo.multiply %31, %39 : tensor<1x32x3072xf32> loc(#loc45)
    %41 = stablehlo.convert %40 : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16> loc(#loc46)
    %42 = stablehlo.multiply %23, %41 : tensor<1x32x3072xbf16> loc(#loc47)
    %43 = stablehlo.reshape %42 : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc48)
    %44 = stablehlo.reshape %arg2 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc49)
    %45 = stablehlo.reshape %44 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc50)
    %46 = stablehlo.transpose %45, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc51)
    %47 = stablehlo.dot_general %43, %46, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<32x1024xbf16> loc(#loc52)
    %48 = stablehlo.reshape %47 : (tensor<32x1024xbf16>) -> tensor<1x32x8x128xbf16> loc(#loc53)
    %49 = stablehlo.transpose %48, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x8x128xbf16>) -> tensor<1x8x32x128xbf16> loc(#loc54)
    %50 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc55)
    %51 = stablehlo.reshape %50 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc56)
    %52 = stablehlo.convert %15 : (tensor<1x1x32xi64>) -> tensor<1x1x32xf32> loc(#loc57)
    %53 = stablehlo.dot_general %51, %52, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x32xf32>) -> tensor<1x64x32xf32> loc(#loc58)
    %54 = stablehlo.transpose %53, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,32,64]{1,2,0}"} : (tensor<1x64x32xf32>) -> tensor<1x32x64xf32> loc(#loc59)
    %55 = stablehlo.concatenate %54, %54, dim = 2 : (tensor<1x32x64xf32>, tensor<1x32x64xf32>) -> tensor<1x32x128xf32> loc(#loc60)
    %56 = stablehlo.cosine %55 : tensor<1x32x128xf32> loc(#loc61)
    %57 = stablehlo.convert %56 : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16> loc(#loc62)
    %58 = stablehlo.broadcast_in_dim %57, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x8x32x128xbf16> loc(#loc63)
    %59 = stablehlo.multiply %49, %58 : tensor<1x8x32x128xbf16> loc(#loc64)
    %60 = stablehlo.slice %49 [0:1, 0:8, 0:32, 64:128] : (tensor<1x8x32x128xbf16>) -> tensor<1x8x32x64xbf16> loc(#loc65)
    %61 = stablehlo.negate %60 : tensor<1x8x32x64xbf16> loc(#loc66)
    %62 = stablehlo.slice %49 [0:1, 0:8, 0:32, 0:64] : (tensor<1x8x32x128xbf16>) -> tensor<1x8x32x64xbf16> loc(#loc67)
    %63 = stablehlo.concatenate %61, %62, dim = 3 : (tensor<1x8x32x64xbf16>, tensor<1x8x32x64xbf16>) -> tensor<1x8x32x128xbf16> loc(#loc68)
    %64 = stablehlo.sine %55 : tensor<1x32x128xf32> loc(#loc69)
    %65 = stablehlo.convert %64 : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16> loc(#loc70)
    %66 = stablehlo.broadcast_in_dim %65, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x8x32x128xbf16> loc(#loc71)
    %67 = stablehlo.multiply %63, %66 : tensor<1x8x32x128xbf16> loc(#loc72)
    %68 = stablehlo.add %59, %67 : tensor<1x8x32x128xbf16> loc(#loc73)
    %69 = "stablehlo.scatter"(%arg6, %20, %68) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16> loc("scatter.127"), %arg20: tensor<bf16> loc("scatter.127")):
      stablehlo.return %arg20 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x128x128xbf16>, tensor<32x1xi64>, tensor<1x8x32x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc74)
    %70 = stablehlo.reshape %arg7 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc75)
    %71 = stablehlo.reshape %70 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc76)
    %72 = stablehlo.transpose %71, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc77)
    %73 = stablehlo.dot_general %43, %72, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<32x1024xbf16> loc(#loc78)
    %74 = stablehlo.reshape %73 : (tensor<32x1024xbf16>) -> tensor<1x32x8x128xbf16> loc(#loc79)
    %75 = stablehlo.transpose %74, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x8x128xbf16>) -> tensor<1x8x32x128xbf16> loc(#loc80)
    %76 = "stablehlo.scatter"(%arg8, %20, %75) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16> loc("scatter.157"), %arg20: tensor<bf16> loc("scatter.157")):
      stablehlo.return %arg20 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x128x128xbf16>, tensor<32x1xi64>, tensor<1x8x32x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc81)
    %77 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc82)
    %78 = stablehlo.reshape %77 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc83)
    %79 = stablehlo.broadcast_in_dim %78, dims = [2] : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc84)
    %80 = stablehlo.reshape %arg15 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc85)
    %81 = stablehlo.reshape %80 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc86)
    %82 = stablehlo.transpose %81, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc87)
    %83 = stablehlo.dot_general %43, %82, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc88)
    %84 = stablehlo.reshape %83 : (tensor<32x3072xbf16>) -> tensor<1x32x24x128xbf16> loc(#loc89)
    %85 = stablehlo.transpose %84, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,32,128]{3,1,2,0}"} : (tensor<1x32x24x128xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc90)
    %86 = stablehlo.broadcast_in_dim %57, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc91)
    %87 = stablehlo.multiply %85, %86 : tensor<1x24x32x128xbf16> loc(#loc92)
    %88 = stablehlo.slice %85 [0:1, 0:24, 0:32, 64:128] : (tensor<1x24x32x128xbf16>) -> tensor<1x24x32x64xbf16> loc(#loc93)
    %89 = stablehlo.negate %88 : tensor<1x24x32x64xbf16> loc(#loc94)
    %90 = stablehlo.slice %85 [0:1, 0:24, 0:32, 0:64] : (tensor<1x24x32x128xbf16>) -> tensor<1x24x32x64xbf16> loc(#loc95)
    %91 = stablehlo.concatenate %89, %90, dim = 3 : (tensor<1x24x32x64xbf16>, tensor<1x24x32x64xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc96)
    %92 = stablehlo.broadcast_in_dim %65, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc97)
    %93 = stablehlo.multiply %91, %92 : tensor<1x24x32x128xbf16> loc(#loc98)
    %94 = stablehlo.add %87, %93 : tensor<1x24x32x128xbf16> loc(#loc99)
    %95 = stablehlo.broadcast_in_dim %69, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16> loc(#loc100)
    %96 = stablehlo.reshape %95 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16> loc(#loc101)
    %97 = stablehlo.transpose %96, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16> loc(#loc102)
    %98 = stablehlo.dot_general %94, %97, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x24x32x128xbf16>, tensor<1x24x128x128xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc103)
    %99 = stablehlo.multiply %98, %9 : tensor<1x24x32x128xbf16> loc(#loc104)
    %100 = stablehlo.broadcast_in_dim %arg14, dims = [] : (tensor<i1>) -> tensor<128xi1> loc(#loc105)
    %101 = stablehlo.and %100, %c_7 : tensor<128xi1> loc(#loc106)
    %102 = stablehlo.reshape %101 : (tensor<128xi1>) -> tensor<1x1x1x128xi1> loc(#loc107)
    %103 = stablehlo.reshape %101 : (tensor<128xi1>) -> tensor<1x1x128xi1> loc(#loc108)
    %104 = stablehlo.broadcast_in_dim %103, dims = [0, 1, 3] : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1> loc(#loc109)
    %105 = stablehlo.not %102 : tensor<1x1x1x128xi1> loc(#loc110)
    %106 = stablehlo.reshape %105 : (tensor<1x1x1x128xi1>) -> tensor<1x1x128xi1> loc(#loc111)
    %107 = stablehlo.broadcast_in_dim %106, dims = [0, 1, 3] : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1> loc(#loc112)
    %108 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<128xi64>) -> tensor<32x128xi64> loc(#loc113)
    %109 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<32xi64>) -> tensor<32x128xi64> loc(#loc114)
    %110 = stablehlo.subtract %108, %109 : tensor<32x128xi64> loc(#loc115)
    %111 = stablehlo.compare  GE, %110, %7 : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1> loc(#loc116)
    %112 = stablehlo.select %111, %6, %5 : tensor<32x128xi1>, tensor<32x128xbf16> loc(#loc117)
    %113 = stablehlo.broadcast_in_dim %16, dims = [0] : (tensor<32xi64>) -> tensor<32x128xi64> loc(#loc118)
    %114 = stablehlo.compare  GT, %108, %113 : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1> loc(#loc119)
    %115 = stablehlo.convert %114 : (tensor<32x128xi1>) -> tensor<32x128xbf16> loc(#loc120)
    %116 = stablehlo.multiply %112, %115 : tensor<32x128xbf16> loc(#loc121)
    %117 = stablehlo.reshape %116 : (tensor<32x128xbf16>) -> tensor<1x1x32x128xbf16> loc(#loc122)
    %118 = stablehlo.slice %117 [0:1, 0:1, 0:32, 0:32] : (tensor<1x1x32x128xbf16>) -> tensor<1x1x32x32xbf16> loc(#loc123)
    %119 = stablehlo.reshape %arg13 : (tensor<1x32xi64>) -> tensor<1x1x32xi64> loc(#loc124)
    %120 = stablehlo.reshape %119 : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64> loc(#loc125)
    %121 = stablehlo.convert %120 : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16> loc(#loc126)
    %122 = stablehlo.reshape %121 : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32xbf16> loc(#loc127)
    %123 = stablehlo.broadcast_in_dim %122, dims = [0, 1, 3] : (tensor<1x1x32xbf16>) -> tensor<1x1x32x32xbf16> loc(#loc128)
    %124 = stablehlo.add %118, %123 : tensor<1x1x32x32xbf16> loc(#loc129)
    %125 = stablehlo.compare  EQ, %124, %4 : (tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xi1> loc(#loc130)
    %126 = stablehlo.select %125, %3, %118 : tensor<1x1x32x32xi1>, tensor<1x1x32x32xbf16> loc(#loc131)
    %127 = stablehlo.floor %cst_12 : tensor<128xf32> loc(#loc132)
    %128 = stablehlo.convert %127 : (tensor<128xf32>) -> tensor<128xi64> loc(#loc133)
    %129 = stablehlo.clamp %2, %128, %1 : tensor<128xi64> loc(#loc134)
    %130 = stablehlo.compare  LT, %129, %2 : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1> loc(#loc135)
    %131 = stablehlo.add %129, %0 : tensor<128xi64> loc(#loc136)
    %132 = stablehlo.select %130, %131, %129 : tensor<128xi1>, tensor<128xi64> loc(#loc137)
    %133 = stablehlo.reshape %132 : (tensor<128xi64>) -> tensor<128x1xi64> loc(#loc138)
    %134 = "stablehlo.gather"(%126, %133) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 32, 1>}> : (tensor<1x1x32x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x32x128xbf16> loc(#loc139)
    %135 = stablehlo.select %107, %8, %134 : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16> loc(#loc140)
    %136 = stablehlo.select %104, %135, %117 : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16> loc(#loc141)
    %137 = stablehlo.reshape %136 : (tensor<1x1x32x128xbf16>) -> tensor<1x32x128xbf16> loc(#loc142)
    %138 = stablehlo.broadcast_in_dim %137, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc143)
    %139 = stablehlo.add %99, %138 : tensor<1x24x32x128xbf16> loc(#loc144)
    %140 = stablehlo.convert %139 : (tensor<1x24x32x128xbf16>) -> tensor<1x24x32x128xf32> loc(#loc145)
    %141 = stablehlo.reduce(%140 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x32x128xf32>, tensor<f32>) -> tensor<1x24x32xf32> loc(#loc146)
    %142 = stablehlo.broadcast_in_dim %141, dims = [0, 1, 2] : (tensor<1x24x32xf32>) -> tensor<1x24x32x128xf32> loc(#loc147)
    %143 = stablehlo.subtract %140, %142 : tensor<1x24x32x128xf32> loc(#loc148)
    %144 = stablehlo.exponential %143 : tensor<1x24x32x128xf32> loc(#loc149)
    %145 = stablehlo.reduce(%144 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x32x128xf32>, tensor<f32>) -> tensor<1x24x32xf32> loc(#loc150)
    %146 = stablehlo.broadcast_in_dim %145, dims = [0, 1, 2] : (tensor<1x24x32xf32>) -> tensor<1x24x32x128xf32> loc(#loc151)
    %147 = stablehlo.divide %144, %146 : tensor<1x24x32x128xf32> loc(#loc152)
    %148 = stablehlo.convert %147 : (tensor<1x24x32x128xf32>) -> tensor<1x24x32x128xbf16> loc(#loc153)
    %149 = stablehlo.broadcast_in_dim %76, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16> loc(#loc154)
    %150 = stablehlo.reshape %149 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16> loc(#loc155)
    %151 = stablehlo.dot_general %148, %150, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x24x32x128xbf16>, tensor<1x24x128x128xbf16>) -> tensor<1x24x32x128xbf16> loc(#loc156)
    %152 = stablehlo.transpose %151, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,32,24,128]{3,1,2,0}"} : (tensor<1x24x32x128xbf16>) -> tensor<1x32x24x128xbf16> loc(#loc157)
    %153 = stablehlo.reshape %152 : (tensor<1x32x24x128xbf16>) -> tensor<32x3072xbf16> loc(#loc158)
    %154 = stablehlo.reshape %arg12 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc159)
    %155 = stablehlo.reshape %154 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc160)
    %156 = stablehlo.transpose %155, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc161)
    %157 = stablehlo.dot_general %153, %156, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc162)
    %158 = stablehlo.reshape %157 : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc163)
    %159 = stablehlo.add %30, %158 : tensor<1x32x3072xbf16> loc(#loc164)
    %160 = stablehlo.reshape %arg16 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc165)
    %161 = stablehlo.reshape %160 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc166)
    %162 = stablehlo.broadcast_in_dim %161, dims = [2] : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc167)
    %163 = stablehlo.convert %159 : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32> loc(#loc168)
    %164 = stablehlo.power %163, %12 : tensor<1x32x3072xf32> loc(#loc169)
    %165 = stablehlo.reduce(%164 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32> loc(#loc170)
    %166 = stablehlo.multiply %165, %11 : tensor<1x32xf32> loc(#loc171)
    %167 = stablehlo.reshape %166 : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc172)
    %168 = stablehlo.add %167, %10 : tensor<1x32x1xf32> loc(#loc173)
    %169 = stablehlo.rsqrt %168 : tensor<1x32x1xf32> loc(#loc174)
    %170 = stablehlo.reshape %169 : (tensor<1x32x1xf32>) -> tensor<1x32xf32> loc(#loc175)
    %171 = stablehlo.broadcast_in_dim %170, dims = [0, 1] : (tensor<1x32xf32>) -> tensor<1x32x3072xf32> loc(#loc176)
    %172 = stablehlo.multiply %163, %171 : tensor<1x32x3072xf32> loc(#loc177)
    %173 = stablehlo.convert %172 : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16> loc(#loc178)
    %174 = stablehlo.multiply %162, %173 : tensor<1x32x3072xbf16> loc(#loc179)
    %175 = stablehlo.reshape %174 : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc180)
    %176 = stablehlo.reshape %arg17 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc181)
    %177 = stablehlo.reshape %176 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc182)
    %178 = stablehlo.transpose %177, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc183)
    %179 = stablehlo.dot_general %175, %178, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<32x8192xbf16> loc(#loc184)
    %180 = stablehlo.reshape %179 : (tensor<32x8192xbf16>) -> tensor<1x32x8192xbf16> loc(#loc185)
    %181 = stablehlo.logistic %180 : tensor<1x32x8192xbf16> loc(#loc186)
    %182 = stablehlo.multiply %180, %181 : tensor<1x32x8192xbf16> loc(#loc187)
    %183 = stablehlo.reshape %arg11 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc188)
    %184 = stablehlo.reshape %183 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc189)
    %185 = stablehlo.transpose %184, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc190)
    %186 = stablehlo.dot_general %175, %185, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<32x8192xbf16> loc(#loc191)
    %187 = stablehlo.reshape %186 : (tensor<32x8192xbf16>) -> tensor<1x32x8192xbf16> loc(#loc192)
    %188 = stablehlo.multiply %182, %187 : tensor<1x32x8192xbf16> loc(#loc193)
    %189 = stablehlo.reshape %188 : (tensor<1x32x8192xbf16>) -> tensor<32x8192xbf16> loc(#loc194)
    %190 = stablehlo.reshape %arg10 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16> loc(#loc195)
    %191 = stablehlo.reshape %190 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16> loc(#loc196)
    %192 = stablehlo.transpose %191, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16> loc(#loc197)
    %193 = stablehlo.dot_general %189, %192, contracting_dims = [1] x [0] : (tensor<32x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc198)
    %194 = stablehlo.reshape %193 : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc199)
    %195 = stablehlo.add %159, %194 : tensor<1x32x3072xbf16> loc(#loc200)
    %196 = stablehlo.convert %195 : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32> loc(#loc201)
    %197 = stablehlo.power %196, %12 : tensor<1x32x3072xf32> loc(#loc202)
    %198 = stablehlo.reduce(%197 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32> loc(#loc203)
    %199 = stablehlo.multiply %198, %11 : tensor<1x32xf32> loc(#loc204)
    %200 = stablehlo.reshape %199 : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc205)
    %201 = stablehlo.add %200, %10 : tensor<1x32x1xf32> loc(#loc206)
    %202 = stablehlo.rsqrt %201 : tensor<1x32x1xf32> loc(#loc207)
    %203 = stablehlo.reshape %202 : (tensor<1x32x1xf32>) -> tensor<1x32xf32> loc(#loc208)
    %204 = stablehlo.broadcast_in_dim %203, dims = [0, 1] : (tensor<1x32xf32>) -> tensor<1x32x3072xf32> loc(#loc209)
    %205 = stablehlo.multiply %196, %204 : tensor<1x32x3072xf32> loc(#loc210)
    %206 = stablehlo.convert %205 : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16> loc(#loc211)
    %207 = stablehlo.multiply %79, %206 : tensor<1x32x3072xbf16> loc(#loc212)
    %208 = stablehlo.reshape %207 : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc213)
    %209 = stablehlo.reshape %arg9 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc214)
    %210 = stablehlo.reshape %209 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc215)
    %211 = stablehlo.transpose %210, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc216)
    %212 = stablehlo.dot_general %208, %211, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<32x128256xbf16> loc(#loc217)
    %213 = stablehlo.reshape %212 : (tensor<32x128256xbf16>) -> tensor<1x32x128256xbf16> loc(#loc218)
    return %69, %76, %212, %213 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc20 = loc("reshape.4")
#loc21 = loc("reshape.6")
#loc22 = loc("compare.117")
#loc23 = loc("add.114")
#loc24 = loc("select.118")
#loc25 = loc("reshape.119")
#loc26 = loc("reshape.80")
#loc27 = loc("reshape.82")
#loc28 = loc("broadcast.83")
#loc29 = loc("reshape.44")
#loc30 = loc("reshape.46")
#loc31 = loc("reshape.39")
#loc32 = loc("reshape.42")
#loc33 = loc("convert.47")
#loc34 = loc("gather.48")
#loc35 = loc("reshape.49")
#loc36 = loc("convert.50")
#loc37 = loc("power.52")
#loc38 = loc("reduce.59")
#loc39 = loc("multiply.68")
#loc40 = loc("reshape.69")
#loc41 = loc("add.73")
#loc42 = loc("rsqrt.74")
#loc43 = loc("reshape.75")
#loc44 = loc("broadcast.76")
#loc45 = loc("multiply.77")
#loc46 = loc("convert.78")
#loc47 = loc("multiply.84")
#loc48 = loc("reshape.85")
#loc49 = loc("reshape.31")
#loc50 = loc("reshape.33")
#loc51 = loc("transpose.34")
#loc52 = loc("dot.86")
#loc53 = loc("reshape.88")
#loc54 = loc("transpose.89")
#loc55 = loc("reshape.14")
#loc56 = loc("reshape.19")
#loc57 = loc("convert.11")
#loc58 = loc("dot.22")
#loc59 = loc("transpose.23")
#loc60 = loc("concatenate.24")
#loc61 = loc("cosine.98")
#loc62 = loc("convert.101")
#loc63 = loc("broadcast.104")
#loc64 = loc("multiply.105")
#loc65 = loc("slice.91")
#loc66 = loc("negate.92")
#loc67 = loc("slice.90")
#loc68 = loc("concatenate.93")
#loc69 = loc("sine.25")
#loc70 = loc("convert.28")
#loc71 = loc("broadcast.95")
#loc72 = loc("multiply.96")
#loc73 = loc("add.108")
#loc75 = loc("reshape.130")
#loc76 = loc("reshape.132")
#loc77 = loc("transpose.133")
#loc78 = loc("dot.135")
#loc79 = loc("reshape.137")
#loc80 = loc("transpose.138")
#loc82 = loc("reshape.504")
#loc83 = loc("reshape.506")
#loc84 = loc("broadcast.507")
#loc85 = loc("reshape.359")
#loc86 = loc("reshape.361")
#loc87 = loc("transpose.362")
#loc88 = loc("dot.364")
#loc89 = loc("reshape.366")
#loc90 = loc("transpose.367")
#loc91 = loc("broadcast.376")
#loc92 = loc("multiply.377")
#loc93 = loc("slice.369")
#loc94 = loc("negate.370")
#loc95 = loc("slice.368")
#loc96 = loc("concatenate.371")
#loc97 = loc("broadcast.373")
#loc98 = loc("multiply.374")
#loc99 = loc("add.380")
#loc100 = loc("broadcast.354")
#loc101 = loc("reshape.355")
#loc102 = loc("transpose.356")
#loc103 = loc("dot.381")
#loc104 = loc("multiply.384")
#loc105 = loc("broadcast.325")
#loc106 = loc("and.328")
#loc107 = loc("reshape.329")
#loc108 = loc("reshape.337")
#loc109 = loc("broadcast.338")
#loc110 = loc("not.330")
#loc111 = loc("reshape.332")
#loc112 = loc("broadcast.333")
#loc113 = loc("broadcast.225")
#loc114 = loc("broadcast.227")
#loc115 = loc("subtract.228")
#loc116 = loc("compare.230")
#loc117 = loc("select.232")
#loc118 = loc("broadcast.201")
#loc119 = loc("compare.202")
#loc120 = loc("convert.203")
#loc121 = loc("multiply.233")
#loc122 = loc("reshape.235")
#loc123 = loc("slice.297")
#loc124 = loc("reshape.287")
#loc125 = loc("reshape.292")
#loc126 = loc("convert.298")
#loc127 = loc("reshape.301")
#loc128 = loc("broadcast.302")
#loc129 = loc("add.303")
#loc130 = loc("compare.306")
#loc131 = loc("select.308")
#loc132 = loc("floor.256")
#loc133 = loc("convert.257")
#loc134 = loc("clamp.260")
#loc135 = loc("compare.269")
#loc136 = loc("add.266")
#loc137 = loc("select.270")
#loc138 = loc("reshape.271")
#loc139 = loc("gather.310")
#loc140 = loc("select.334")
#loc141 = loc("select.339")
#loc142 = loc("reshape.387")
#loc143 = loc("broadcast.388")
#loc144 = loc("add.389")
#loc145 = loc("convert.390")
#loc146 = loc("reduce.396")
#loc147 = loc("broadcast.397")
#loc148 = loc("subtract.398")
#loc149 = loc("exponential.399")
#loc150 = loc("reduce.405")
#loc151 = loc("broadcast.406")
#loc152 = loc("divide.407")
#loc153 = loc("convert.408")
#loc154 = loc("broadcast.194")
#loc155 = loc("reshape.195")
#loc156 = loc("dot.409")
#loc157 = loc("transpose.411")
#loc158 = loc("reshape.413")
#loc159 = loc("reshape.183")
#loc160 = loc("reshape.185")
#loc161 = loc("transpose.186")
#loc162 = loc("dot.414")
#loc163 = loc("reshape.415")
#loc164 = loc("add.418")
#loc165 = loc("reshape.449")
#loc166 = loc("reshape.451")
#loc167 = loc("broadcast.452")
#loc168 = loc("convert.419")
#loc169 = loc("power.421")
#loc170 = loc("reduce.428")
#loc171 = loc("multiply.437")
#loc172 = loc("reshape.438")
#loc173 = loc("add.442")
#loc174 = loc("rsqrt.443")
#loc175 = loc("reshape.444")
#loc176 = loc("broadcast.445")
#loc177 = loc("multiply.446")
#loc178 = loc("convert.447")
#loc179 = loc("multiply.453")
#loc180 = loc("reshape.462")
#loc181 = loc("reshape.458")
#loc182 = loc("reshape.460")
#loc183 = loc("transpose.461")
#loc184 = loc("dot.463")
#loc185 = loc("reshape.464")
#loc186 = loc("logistic.465")
#loc187 = loc("multiply.466")
#loc188 = loc("reshape.174")
#loc189 = loc("reshape.176")
#loc190 = loc("transpose.177")
#loc191 = loc("dot.455")
#loc192 = loc("reshape.456")
#loc193 = loc("multiply.467")
#loc194 = loc("reshape.468")
#loc195 = loc("reshape.169")
#loc196 = loc("reshape.171")
#loc197 = loc("transpose.172")
#loc198 = loc("dot.469")
#loc199 = loc("reshape.470")
#loc200 = loc("add.473")
#loc201 = loc("convert.474")
#loc202 = loc("power.476")
#loc203 = loc("reduce.483")
#loc204 = loc("multiply.492")
#loc205 = loc("reshape.493")
#loc206 = loc("add.497")
#loc207 = loc("rsqrt.498")
#loc208 = loc("reshape.499")
#loc209 = loc("broadcast.500")
#loc210 = loc("multiply.501")
#loc211 = loc("convert.502")
#loc212 = loc("multiply.508")
#loc213 = loc("reshape.512")
#loc214 = loc("reshape.160")
#loc215 = loc("reshape.162")
#loc216 = loc("transpose.163")
#loc217 = loc("dot.513")
#loc218 = loc("reshape.514")
------------------ END OF MLIR MODULE ------------------
[james] gspmdAnnotationsExist force-set to false 
[james] gspmdAnnotationsExist force-set to false 
[james] gspmdAnnotationsExist force-set to false 
[james] gspmdAnnotationsExist force-set to false 
2026-01-02 18:37:36.781 (   7.839s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module shlo_compiler:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.30")
#loc4 = loc("p3.38")
#loc5 = loc("p4.43")
#loc6 = loc("p5.79")
#loc7 = loc("p6.121")
#loc8 = loc("p7.129")
#loc9 = loc("p8.151")
#loc10 = loc("p9.159")
#loc11 = loc("p10.168")
#loc12 = loc("p11.173")
#loc13 = loc("p12.182")
#loc14 = loc("p13.286")
#loc15 = loc("p14.321")
#loc16 = loc("p15.358")
#loc17 = loc("p16.448")
#loc18 = loc("p17.457")
#loc19 = loc("p18.503")
#loc74 = loc("scatter.127")
#loc81 = loc("scatter.157")
#loc162 = loc("dot.414")
#loc198 = loc("dot.469")
module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]> loc(#loc)
  func.func @main(%arg0: tensor<32xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.30"), %arg3: tensor<1x32xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p3.38"), %arg4: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p4.43"), %arg5: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p5.79"), %arg6: tensor<1x8x128x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p6.121"), %arg7: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p7.129"), %arg8: tensor<1x8x128x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_4"} loc("p8.151"), %arg9: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"} loc("p9.159"), %arg10: tensor<3072x8192xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p10.168"), %arg11: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p11.173"), %arg12: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p12.182"), %arg13: tensor<1x32xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p13.286"), %arg14: tensor<i1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p14.321"), %arg15: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p15.358"), %arg16: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p16.448"), %arg17: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p17.457"), %arg18: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"} loc("p18.503")) -> (tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<32x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x32x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:4 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18) in_shardings=[<@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{}, {}]>, <@mesh, []>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg19: tensor<32xi64> loc("p0.3"), %arg20: tensor<64xf32> loc("p1.13"), %arg21: tensor<512x3072xbf16> loc("p2.30"), %arg22: tensor<1x32xi64> loc("p3.38"), %arg23: tensor<128256x3072xbf16> loc("p4.43"), %arg24: tensor<3072xbf16> loc("p5.79"), %arg25: tensor<1x4x128x128xbf16> loc("p6.121"), %arg26: tensor<512x3072xbf16> loc("p7.129"), %arg27: tensor<1x4x128x128xbf16> loc("p8.151"), %arg28: tensor<128256x3072xbf16> loc("p9.159"), %arg29: tensor<3072x4096xbf16> loc("p10.168"), %arg30: tensor<4096x3072xbf16> loc("p11.173"), %arg31: tensor<3072x1536xbf16> loc("p12.182"), %arg32: tensor<1x32xi64> loc("p13.286"), %arg33: tensor<i1> loc("p14.321"), %arg34: tensor<1536x3072xbf16> loc("p15.358"), %arg35: tensor<3072xbf16> loc("p16.448"), %arg36: tensor<4096x3072xbf16> loc("p17.457"), %arg37: tensor<3072xbf16> loc("p18.503")) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
      %c = stablehlo.constant dense<"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tensor<128xi64> loc(#loc)
      %c_0 = stablehlo.constant dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xi64> loc(#loc)
      %cst_1 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
      %c_2 = stablehlo.constant dense<128> : tensor<i64> loc(#loc)
      %cst_3 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
      %cst_4 = stablehlo.constant dense<3.25520843E-4> : tensor<f32> loc(#loc)
      %cst_5 = stablehlo.constant dense<9.99999974E-6> : tensor<f32> loc(#loc)
      %cst_6 = stablehlo.constant dense<8.837890e-02> : tensor<bf16> loc(#loc)
      %c_7 = stablehlo.constant dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1> loc(#loc)
      %c_8 = stablehlo.constant dense<1> : tensor<i64> loc(#loc)
      %cst_9 = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
      %cst_10 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc)
      %c_11 = stablehlo.constant dense<0> : tensor<i64> loc(#loc)
      %cst_12 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32> loc(#loc)
      %c_13 = stablehlo.constant dense<31> : tensor<i64> loc(#loc)
      %c_14 = stablehlo.constant dense<32> : tensor<i64> loc(#loc)
      %1 = stablehlo.broadcast_in_dim %c_14, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
      %2 = stablehlo.broadcast_in_dim %c_13, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
      %3 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
      %4 = stablehlo.broadcast_in_dim %cst_10, dims = [] : (tensor<bf16>) -> tensor<1x1x32x32xbf16> loc(#loc)
      %5 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<bf16>) -> tensor<1x1x32x32xbf16> loc(#loc)
      %6 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<bf16>) -> tensor<32x128xbf16> loc(#loc)
      %7 = stablehlo.broadcast_in_dim %cst_10, dims = [] : (tensor<bf16>) -> tensor<32x128xbf16> loc(#loc)
      %8 = stablehlo.broadcast_in_dim %c_8, dims = [] : (tensor<i64>) -> tensor<32x128xi64> loc(#loc)
      %9 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<bf16>) -> tensor<1x1x32x128xbf16> loc(#loc)
      %10 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<bf16>) -> tensor<1x12x32x128xbf16> loc(#loc)
      %11 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<1x32x1xf32> loc(#loc)
      %12 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<1x32xf32> loc(#loc)
      %13 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<1x32x3072xf32> loc(#loc)
      %14 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<i64>) -> tensor<32xi64> loc(#loc)
      %15 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<i64>) -> tensor<32xi64> loc(#loc)
      %16 = stablehlo.reshape %arg19 : (tensor<32xi64>) -> tensor<1x1x32xi64> loc(#loc20)
      %17 = stablehlo.reshape %16 : (tensor<1x1x32xi64>) -> tensor<32xi64> loc(#loc21)
      %18 = stablehlo.compare  LT, %17, %15 : (tensor<32xi64>, tensor<32xi64>) -> tensor<32xi1> loc(#loc22)
      %19 = stablehlo.add %17, %14 : tensor<32xi64> loc(#loc23)
      %20 = stablehlo.select %18, %19, %17 : tensor<32xi1>, tensor<32xi64> loc(#loc24)
      %21 = stablehlo.reshape %20 : (tensor<32xi64>) -> tensor<32x1xi64> loc(#loc25)
      %22 = stablehlo.reshape %arg24 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc26)
      %23 = stablehlo.reshape %22 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc27)
      %24 = stablehlo.broadcast_in_dim %23, dims = [2] : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc28)
      %25 = stablehlo.reshape %arg23 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc29)
      %26 = stablehlo.reshape %25 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc30)
      %27 = stablehlo.reshape %arg22 : (tensor<1x32xi64>) -> tensor<1x1x32xi64> loc(#loc31)
      %28 = stablehlo.reshape %27 : (tensor<1x1x32xi64>) -> tensor<32xi64> loc(#loc32)
      %29 = stablehlo.convert %28 : (tensor<32xi64>) -> tensor<32xui32> loc(#loc33)
      %30 = "stablehlo.gather"(%26, %29) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<32xui32>) -> tensor<32x3072xbf16> loc(#loc34)
      %31 = stablehlo.reshape %30 : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc35)
      %32 = stablehlo.convert %31 : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32> loc(#loc36)
      %33 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<1x32x3072xf32> loc(#loc)
      %34 = stablehlo.power %32, %33 : tensor<1x32x3072xf32> loc(#loc37)
      %35 = stablehlo.reduce(%34 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32> loc(#loc38)
      %36 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<1x32xf32> loc(#loc)
      %37 = stablehlo.multiply %35, %36 : tensor<1x32xf32> loc(#loc39)
      %38 = stablehlo.reshape %37 : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc40)
      %39 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<1x32x1xf32> loc(#loc)
      %40 = stablehlo.add %38, %39 : tensor<1x32x1xf32> loc(#loc41)
      %41 = stablehlo.rsqrt %40 : tensor<1x32x1xf32> loc(#loc42)
      %42 = stablehlo.reshape %41 : (tensor<1x32x1xf32>) -> tensor<1x32xf32> loc(#loc43)
      %43 = stablehlo.broadcast_in_dim %42, dims = [0, 1] : (tensor<1x32xf32>) -> tensor<1x32x3072xf32> loc(#loc44)
      %44 = stablehlo.multiply %32, %43 : tensor<1x32x3072xf32> loc(#loc45)
      %45 = stablehlo.convert %44 : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16> loc(#loc46)
      %46 = stablehlo.multiply %24, %45 : tensor<1x32x3072xbf16> loc(#loc47)
      %47 = stablehlo.reshape %46 : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc48)
      %48 = stablehlo.reshape %arg21 : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc49)
      %49 = stablehlo.reshape %48 : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc50)
      %50 = stablehlo.transpose %49, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16> loc(#loc51)
      %51 = stablehlo.dot_general %47, %50, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16> loc(#loc52)
      %52 = stablehlo.reshape %51 : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16> loc(#loc53)
      %53 = stablehlo.transpose %52, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16> loc(#loc54)
      %54 = stablehlo.reshape %arg20 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc55)
      %55 = stablehlo.reshape %54 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc56)
      %56 = stablehlo.convert %16 : (tensor<1x1x32xi64>) -> tensor<1x1x32xf32> loc(#loc57)
      %57 = stablehlo.dot_general %55, %56, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x32xf32>) -> tensor<1x64x32xf32> loc(#loc58)
      %58 = stablehlo.transpose %57, dims = [0, 2, 1] {result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,32,64]{1,2,0}"} : (tensor<1x64x32xf32>) -> tensor<1x32x64xf32> loc(#loc59)
      %59 = stablehlo.concatenate %58, %58, dim = 2 : (tensor<1x32x64xf32>, tensor<1x32x64xf32>) -> tensor<1x32x128xf32> loc(#loc60)
      %60 = stablehlo.cosine %59 : tensor<1x32x128xf32> loc(#loc61)
      %61 = stablehlo.convert %60 : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16> loc(#loc62)
      %62 = stablehlo.broadcast_in_dim %61, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16> loc(#loc63)
      %63 = stablehlo.multiply %53, %62 : tensor<1x4x32x128xbf16> loc(#loc64)
      %64 = stablehlo.slice %53 [0:1, 0:4, 0:32, 64:128] : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16> loc(#loc65)
      %65 = stablehlo.negate %64 : tensor<1x4x32x64xbf16> loc(#loc66)
      %66 = stablehlo.slice %53 [0:1, 0:4, 0:32, 0:64] : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16> loc(#loc67)
      %67 = stablehlo.concatenate %65, %66, dim = 3 : (tensor<1x4x32x64xbf16>, tensor<1x4x32x64xbf16>) -> tensor<1x4x32x128xbf16> loc(#loc68)
      %68 = stablehlo.sine %59 : tensor<1x32x128xf32> loc(#loc69)
      %69 = stablehlo.convert %68 : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16> loc(#loc70)
      %70 = stablehlo.broadcast_in_dim %69, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16> loc(#loc71)
      %71 = stablehlo.multiply %67, %70 : tensor<1x4x32x128xbf16> loc(#loc72)
      %72 = stablehlo.add %63, %71 : tensor<1x4x32x128xbf16> loc(#loc73)
      %73 = "stablehlo.scatter"(%arg25, %21, %72) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg38: tensor<bf16> loc("scatter.127"), %arg39: tensor<bf16> loc("scatter.127")):
        stablehlo.return %arg39 : tensor<bf16> loc(#loc)
      }) : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16> loc(#loc74)
      %74 = stablehlo.reshape %arg26 : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc75)
      %75 = stablehlo.reshape %74 : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc76)
      %76 = stablehlo.transpose %75, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16> loc(#loc77)
      %77 = stablehlo.dot_general %47, %76, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16> loc(#loc78)
      %78 = stablehlo.reshape %77 : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16> loc(#loc79)
      %79 = stablehlo.transpose %78, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16> loc(#loc80)
      %80 = "stablehlo.scatter"(%arg27, %21, %79) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg38: tensor<bf16> loc("scatter.157"), %arg39: tensor<bf16> loc("scatter.157")):
        stablehlo.return %arg39 : tensor<bf16> loc(#loc)
      }) : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16> loc(#loc81)
      %81 = stablehlo.reshape %arg37 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc82)
      %82 = stablehlo.reshape %81 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc83)
      %83 = stablehlo.broadcast_in_dim %82, dims = [2] : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc84)
      %84 = stablehlo.reshape %arg34 : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16> loc(#loc85)
      %85 = stablehlo.reshape %84 : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc86)
      %86 = stablehlo.transpose %85, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16> loc(#loc87)
      %87 = stablehlo.dot_general %47, %86, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<32x1536xbf16> loc(#loc88)
      %88 = stablehlo.reshape %87 : (tensor<32x1536xbf16>) -> tensor<1x32x12x128xbf16> loc(#loc89)
      %89 = stablehlo.transpose %88, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,32,128]{3,1,2,0}"} : (tensor<1x32x12x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc90)
      %90 = stablehlo.broadcast_in_dim %61, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc91)
      %91 = stablehlo.multiply %89, %90 : tensor<1x12x32x128xbf16> loc(#loc92)
      %92 = stablehlo.slice %89 [0:1, 0:12, 0:32, 64:128] : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16> loc(#loc93)
      %93 = stablehlo.negate %92 : tensor<1x12x32x64xbf16> loc(#loc94)
      %94 = stablehlo.slice %89 [0:1, 0:12, 0:32, 0:64] : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16> loc(#loc95)
      %95 = stablehlo.concatenate %93, %94, dim = 3 : (tensor<1x12x32x64xbf16>, tensor<1x12x32x64xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc96)
      %96 = stablehlo.broadcast_in_dim %69, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc97)
      %97 = stablehlo.multiply %95, %96 : tensor<1x12x32x128xbf16> loc(#loc98)
      %98 = stablehlo.add %91, %97 : tensor<1x12x32x128xbf16> loc(#loc99)
      %99 = stablehlo.broadcast_in_dim %73, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16> loc(#loc100)
      %100 = stablehlo.reshape %99 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16> loc(#loc101)
      %101 = stablehlo.transpose %100, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16> loc(#loc102)
      %102 = stablehlo.dot_general %98, %101, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc103)
      %103 = stablehlo.multiply %102, %10 : tensor<1x12x32x128xbf16> loc(#loc104)
      %104 = stablehlo.broadcast_in_dim %arg33, dims = [] : (tensor<i1>) -> tensor<128xi1> loc(#loc105)
      %105 = stablehlo.and %104, %c_7 : tensor<128xi1> loc(#loc106)
      %106 = stablehlo.reshape %105 : (tensor<128xi1>) -> tensor<1x1x1x128xi1> loc(#loc107)
      %107 = stablehlo.reshape %105 : (tensor<128xi1>) -> tensor<1x1x128xi1> loc(#loc108)
      %108 = stablehlo.broadcast_in_dim %107, dims = [0, 1, 3] : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1> loc(#loc109)
      %109 = stablehlo.not %106 : tensor<1x1x1x128xi1> loc(#loc110)
      %110 = stablehlo.reshape %109 : (tensor<1x1x1x128xi1>) -> tensor<1x1x128xi1> loc(#loc111)
      %111 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 3] : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1> loc(#loc112)
      %112 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<128xi64>) -> tensor<32x128xi64> loc(#loc113)
      %113 = stablehlo.broadcast_in_dim %c_0, dims = [0] : (tensor<32xi64>) -> tensor<32x128xi64> loc(#loc114)
      %114 = stablehlo.broadcast_in_dim %c, dims = [1] : (tensor<128xi64>) -> tensor<32x128xi64> loc(#loc113)
      %115 = stablehlo.subtract %114, %113 : tensor<32x128xi64> loc(#loc115)
      %116 = stablehlo.compare  GE, %115, %8 : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1> loc(#loc116)
      %117 = stablehlo.select %116, %7, %6 : tensor<32x128xi1>, tensor<32x128xbf16> loc(#loc117)
      %118 = stablehlo.broadcast_in_dim %17, dims = [0] : (tensor<32xi64>) -> tensor<32x128xi64> loc(#loc118)
      %119 = stablehlo.compare  GT, %112, %118 : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1> loc(#loc119)
      %120 = stablehlo.convert %119 : (tensor<32x128xi1>) -> tensor<32x128xbf16> loc(#loc120)
      %121 = stablehlo.multiply %117, %120 : tensor<32x128xbf16> loc(#loc121)
      %122 = stablehlo.reshape %121 : (tensor<32x128xbf16>) -> tensor<1x1x32x128xbf16> loc(#loc122)
      %123 = stablehlo.slice %122 [0:1, 0:1, 0:32, 0:32] : (tensor<1x1x32x128xbf16>) -> tensor<1x1x32x32xbf16> loc(#loc123)
      %124 = stablehlo.reshape %arg32 : (tensor<1x32xi64>) -> tensor<1x1x32xi64> loc(#loc124)
      %125 = stablehlo.reshape %124 : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64> loc(#loc125)
      %126 = stablehlo.convert %125 : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16> loc(#loc126)
      %127 = stablehlo.reshape %126 : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32xbf16> loc(#loc127)
      %128 = stablehlo.broadcast_in_dim %127, dims = [0, 1, 3] : (tensor<1x1x32xbf16>) -> tensor<1x1x32x32xbf16> loc(#loc128)
      %129 = stablehlo.add %123, %128 : tensor<1x1x32x32xbf16> loc(#loc129)
      %130 = stablehlo.compare  EQ, %129, %5 : (tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xi1> loc(#loc130)
      %131 = stablehlo.select %130, %4, %123 : tensor<1x1x32x32xi1>, tensor<1x1x32x32xbf16> loc(#loc131)
      %132 = stablehlo.floor %cst_12 : tensor<128xf32> loc(#loc132)
      %133 = stablehlo.convert %132 : (tensor<128xf32>) -> tensor<128xi64> loc(#loc133)
      %134 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
      %135 = stablehlo.clamp %134, %133, %2 : tensor<128xi64> loc(#loc134)
      %136 = stablehlo.compare  LT, %135, %3 : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1> loc(#loc135)
      %137 = stablehlo.add %135, %1 : tensor<128xi64> loc(#loc136)
      %138 = stablehlo.select %136, %137, %135 : tensor<128xi1>, tensor<128xi64> loc(#loc137)
      %139 = stablehlo.reshape %138 : (tensor<128xi64>) -> tensor<128x1xi64> loc(#loc138)
      %140 = "stablehlo.gather"(%131, %139) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 32, 1>}> : (tensor<1x1x32x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x32x128xbf16> loc(#loc139)
      %141 = stablehlo.select %111, %9, %140 : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16> loc(#loc140)
      %142 = stablehlo.select %108, %141, %122 : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16> loc(#loc141)
      %143 = stablehlo.reshape %142 : (tensor<1x1x32x128xbf16>) -> tensor<1x32x128xbf16> loc(#loc142)
      %144 = stablehlo.broadcast_in_dim %143, dims = [0, 2, 3] : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc143)
      %145 = stablehlo.add %103, %144 : tensor<1x12x32x128xbf16> loc(#loc144)
      %146 = stablehlo.convert %145 : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xf32> loc(#loc145)
      %147 = stablehlo.reduce(%146 init: %cst_1) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32> loc(#loc146)
      %148 = stablehlo.broadcast_in_dim %147, dims = [0, 1, 2] : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32> loc(#loc147)
      %149 = stablehlo.subtract %146, %148 : tensor<1x12x32x128xf32> loc(#loc148)
      %150 = stablehlo.exponential %149 : tensor<1x12x32x128xf32> loc(#loc149)
      %151 = stablehlo.reduce(%150 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32> loc(#loc150)
      %152 = stablehlo.broadcast_in_dim %151, dims = [0, 1, 2] : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32> loc(#loc151)
      %153 = stablehlo.divide %150, %152 : tensor<1x12x32x128xf32> loc(#loc152)
      %154 = stablehlo.convert %153 : (tensor<1x12x32x128xf32>) -> tensor<1x12x32x128xbf16> loc(#loc153)
      %155 = stablehlo.broadcast_in_dim %80, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16> loc(#loc154)
      %156 = stablehlo.reshape %155 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16> loc(#loc155)
      %157 = stablehlo.dot_general %154, %156, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc156)
      %158 = stablehlo.transpose %157, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,32,24,128]{3,1,2,0}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x32x12x128xbf16> loc(#loc157)
      %159 = stablehlo.reshape %158 : (tensor<1x32x12x128xbf16>) -> tensor<32x1536xbf16> loc(#loc158)
      %160 = stablehlo.reshape %arg31 : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16> loc(#loc159)
      %161 = stablehlo.reshape %160 : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16> loc(#loc160)
      %162 = stablehlo.transpose %161, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16> loc(#loc161)
      %163 = stablehlo.dot_general %159, %162, contracting_dims = [1] x [0] : (tensor<32x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc162)
      %164 = "stablehlo.all_reduce"(%163) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg38: tensor<bf16> loc("dot.414"), %arg39: tensor<bf16> loc("dot.414")):
        %225 = stablehlo.add %arg38, %arg39 : tensor<bf16> loc(#loc162)
        stablehlo.return %225 : tensor<bf16> loc(#loc162)
      }) : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc162)
      %165 = stablehlo.reshape %164 : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc163)
      %166 = stablehlo.add %31, %165 : tensor<1x32x3072xbf16> loc(#loc164)
      %167 = stablehlo.reshape %arg35 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc165)
      %168 = stablehlo.reshape %167 : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc166)
      %169 = stablehlo.broadcast_in_dim %168, dims = [2] : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc167)
      %170 = stablehlo.convert %166 : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32> loc(#loc168)
      %171 = stablehlo.broadcast_in_dim %cst_3, dims = [] : (tensor<f32>) -> tensor<1x32x3072xf32> loc(#loc)
      %172 = stablehlo.power %170, %171 : tensor<1x32x3072xf32> loc(#loc169)
      %173 = stablehlo.reduce(%172 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32> loc(#loc170)
      %174 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<1x32xf32> loc(#loc)
      %175 = stablehlo.multiply %173, %174 : tensor<1x32xf32> loc(#loc171)
      %176 = stablehlo.reshape %175 : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc172)
      %177 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<1x32x1xf32> loc(#loc)
      %178 = stablehlo.add %176, %177 : tensor<1x32x1xf32> loc(#loc173)
      %179 = stablehlo.rsqrt %178 : tensor<1x32x1xf32> loc(#loc174)
      %180 = stablehlo.reshape %179 : (tensor<1x32x1xf32>) -> tensor<1x32xf32> loc(#loc175)
      %181 = stablehlo.broadcast_in_dim %180, dims = [0, 1] : (tensor<1x32xf32>) -> tensor<1x32x3072xf32> loc(#loc176)
      %182 = stablehlo.multiply %170, %181 : tensor<1x32x3072xf32> loc(#loc177)
      %183 = stablehlo.convert %182 : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16> loc(#loc178)
      %184 = stablehlo.multiply %169, %183 : tensor<1x32x3072xbf16> loc(#loc179)
      %185 = stablehlo.reshape %184 : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc180)
      %186 = stablehlo.reshape %arg36 : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc181)
      %187 = stablehlo.reshape %186 : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc182)
      %188 = stablehlo.transpose %187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16> loc(#loc183)
      %189 = stablehlo.dot_general %185, %188, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16> loc(#loc184)
      %190 = stablehlo.reshape %189 : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16> loc(#loc185)
      %191 = stablehlo.logistic %190 : tensor<1x32x4096xbf16> loc(#loc186)
      %192 = stablehlo.multiply %190, %191 : tensor<1x32x4096xbf16> loc(#loc187)
      %193 = stablehlo.reshape %arg30 : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc188)
      %194 = stablehlo.reshape %193 : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc189)
      %195 = stablehlo.transpose %194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16> loc(#loc190)
      %196 = stablehlo.dot_general %185, %195, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16> loc(#loc191)
      %197 = stablehlo.reshape %196 : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16> loc(#loc192)
      %198 = stablehlo.multiply %192, %197 : tensor<1x32x4096xbf16> loc(#loc193)
      %199 = stablehlo.reshape %198 : (tensor<1x32x4096xbf16>) -> tensor<32x4096xbf16> loc(#loc194)
      %200 = stablehlo.reshape %arg29 : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16> loc(#loc195)
      %201 = stablehlo.reshape %200 : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc196)
      %202 = stablehlo.transpose %201, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16> loc(#loc197)
      %203 = stablehlo.dot_general %199, %202, contracting_dims = [1] x [0] : (tensor<32x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc198)
      %204 = "stablehlo.all_reduce"(%203) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg38: tensor<bf16> loc("dot.469"), %arg39: tensor<bf16> loc("dot.469")):
        %225 = stablehlo.add %arg38, %arg39 : tensor<bf16> loc(#loc198)
        stablehlo.return %225 : tensor<bf16> loc(#loc198)
      }) : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc198)
      %205 = stablehlo.reshape %204 : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc199)
      %206 = stablehlo.add %166, %205 : tensor<1x32x3072xbf16> loc(#loc200)
      %207 = stablehlo.convert %206 : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32> loc(#loc201)
      %208 = stablehlo.power %207, %13 : tensor<1x32x3072xf32> loc(#loc202)
      %209 = stablehlo.reduce(%208 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32> loc(#loc203)
      %210 = stablehlo.multiply %209, %12 : tensor<1x32xf32> loc(#loc204)
      %211 = stablehlo.reshape %210 : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc205)
      %212 = stablehlo.add %211, %11 : tensor<1x32x1xf32> loc(#loc206)
      %213 = stablehlo.rsqrt %212 : tensor<1x32x1xf32> loc(#loc207)
      %214 = stablehlo.reshape %213 : (tensor<1x32x1xf32>) -> tensor<1x32xf32> loc(#loc208)
      %215 = stablehlo.broadcast_in_dim %214, dims = [0, 1] : (tensor<1x32xf32>) -> tensor<1x32x3072xf32> loc(#loc209)
      %216 = stablehlo.multiply %207, %215 : tensor<1x32x3072xf32> loc(#loc210)
      %217 = stablehlo.convert %216 : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16> loc(#loc211)
      %218 = stablehlo.multiply %83, %217 : tensor<1x32x3072xbf16> loc(#loc212)
      %219 = stablehlo.reshape %218 : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc213)
      %220 = stablehlo.reshape %arg28 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc214)
      %221 = stablehlo.reshape %220 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc215)
      %222 = stablehlo.transpose %221, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc216)
      %223 = stablehlo.dot_general %219, %222, contracting_dims = [1] x [0] : (tensor<32x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<32x128256xbf16> loc(#loc217)
      %224 = stablehlo.reshape %223 : (tensor<32x128256xbf16>) -> tensor<1x32x128256xbf16> loc(#loc218)
      sdy.return %73, %80, %223, %224 : tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16> loc(#loc)
    } : (tensor<32xi64>, tensor<64xf32>, tensor<1024x3072xbf16>, tensor<1x32xi64>, tensor<128256x3072xbf16>, tensor<3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<128256x3072xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<1x32xi64>, tensor<i1>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>) loc(#loc)
    return %0#0, %0#1, %0#2, %0#3 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc20 = loc("reshape.4")
#loc21 = loc("reshape.6")
#loc22 = loc("compare.117")
#loc23 = loc("add.114")
#loc24 = loc("select.118")
#loc25 = loc("reshape.119")
#loc26 = loc("reshape.80")
#loc27 = loc("reshape.82")
#loc28 = loc("broadcast.83")
#loc29 = loc("reshape.44")
#loc30 = loc("reshape.46")
#loc31 = loc("reshape.39")
#loc32 = loc("reshape.42")
#loc33 = loc("convert.47")
#loc34 = loc("gather.48")
#loc35 = loc("reshape.49")
#loc36 = loc("convert.50")
#loc37 = loc("power.52")
#loc38 = loc("reduce.59")
#loc39 = loc("multiply.68")
#loc40 = loc("reshape.69")
#loc41 = loc("add.73")
#loc42 = loc("rsqrt.74")
#loc43 = loc("reshape.75")
#loc44 = loc("broadcast.76")
#loc45 = loc("multiply.77")
#loc46 = loc("convert.78")
#loc47 = loc("multiply.84")
#loc48 = loc("reshape.85")
#loc49 = loc("reshape.31")
#loc50 = loc("reshape.33")
#loc51 = loc("transpose.34")
#loc52 = loc("dot.86")
#loc53 = loc("reshape.88")
#loc54 = loc("transpose.89")
#loc55 = loc("reshape.14")
#loc56 = loc("reshape.19")
#loc57 = loc("convert.11")
#loc58 = loc("dot.22")
#loc59 = loc("transpose.23")
#loc60 = loc("concatenate.24")
#loc61 = loc("cosine.98")
#loc62 = loc("convert.101")
#loc63 = loc("broadcast.104")
#loc64 = loc("multiply.105")
#loc65 = loc("slice.91")
#loc66 = loc("negate.92")
#loc67 = loc("slice.90")
#loc68 = loc("concatenate.93")
#loc69 = loc("sine.25")
#loc70 = loc("convert.28")
#loc71 = loc("broadcast.95")
#loc72 = loc("multiply.96")
#loc73 = loc("add.108")
#loc75 = loc("reshape.130")
#loc76 = loc("reshape.132")
#loc77 = loc("transpose.133")
#loc78 = loc("dot.135")
#loc79 = loc("reshape.137")
#loc80 = loc("transpose.138")
#loc82 = loc("reshape.504")
#loc83 = loc("reshape.506")
#loc84 = loc("broadcast.507")
#loc85 = loc("reshape.359")
#loc86 = loc("reshape.361")
#loc87 = loc("transpose.362")
#loc88 = loc("dot.364")
#loc89 = loc("reshape.366")
#loc90 = loc("transpose.367")
#loc91 = loc("broadcast.376")
#loc92 = loc("multiply.377")
#loc93 = loc("slice.369")
#loc94 = loc("negate.370")
#loc95 = loc("slice.368")
#loc96 = loc("concatenate.371")
#loc97 = loc("broadcast.373")
#loc98 = loc("multiply.374")
#loc99 = loc("add.380")
#loc100 = loc("broadcast.354")
#loc101 = loc("reshape.355")
#loc102 = loc("transpose.356")
#loc103 = loc("dot.381")
#loc104 = loc("multiply.384")
#loc105 = loc("broadcast.325")
#loc106 = loc("and.328")
#loc107 = loc("reshape.329")
#loc108 = loc("reshape.337")
#loc109 = loc("broadcast.338")
#loc110 = loc("not.330")
#loc111 = loc("reshape.332")
#loc112 = loc("broadcast.333")
#loc113 = loc("broadcast.225")
#loc114 = loc("broadcast.227")
#loc115 = loc("subtract.228")
#loc116 = loc("compare.230")
#loc117 = loc("select.232")
#loc118 = loc("broadcast.201")
#loc119 = loc("compare.202")
#loc120 = loc("convert.203")
#loc121 = loc("multiply.233")
#loc122 = loc("reshape.235")
#loc123 = loc("slice.297")
#loc124 = loc("reshape.287")
#loc125 = loc("reshape.292")
#loc126 = loc("convert.298")
#loc127 = loc("reshape.301")
#loc128 = loc("broadcast.302")
#loc129 = loc("add.303")
#loc130 = loc("compare.306")
#loc131 = loc("select.308")
#loc132 = loc("floor.256")
#loc133 = loc("convert.257")
#loc134 = loc("clamp.260")
#loc135 = loc("compare.269")
#loc136 = loc("add.266")
#loc137 = loc("select.270")
#loc138 = loc("reshape.271")
#loc139 = loc("gather.310")
#loc140 = loc("select.334")
#loc141 = loc("select.339")
#loc142 = loc("reshape.387")
#loc143 = loc("broadcast.388")
#loc144 = loc("add.389")
#loc145 = loc("convert.390")
#loc146 = loc("reduce.396")
#loc147 = loc("broadcast.397")
#loc148 = loc("subtract.398")
#loc149 = loc("exponential.399")
#loc150 = loc("reduce.405")
#loc151 = loc("broadcast.406")
#loc152 = loc("divide.407")
#loc153 = loc("convert.408")
#loc154 = loc("broadcast.194")
#loc155 = loc("reshape.195")
#loc156 = loc("dot.409")
#loc157 = loc("transpose.411")
#loc158 = loc("reshape.413")
#loc159 = loc("reshape.183")
#loc160 = loc("reshape.185")
#loc161 = loc("transpose.186")
#loc163 = loc("reshape.415")
#loc164 = loc("add.418")
#loc165 = loc("reshape.449")
#loc166 = loc("reshape.451")
#loc167 = loc("broadcast.452")
#loc168 = loc("convert.419")
#loc169 = loc("power.421")
#loc170 = loc("reduce.428")
#loc171 = loc("multiply.437")
#loc172 = loc("reshape.438")
#loc173 = loc("add.442")
#loc174 = loc("rsqrt.443")
#loc175 = loc("reshape.444")
#loc176 = loc("broadcast.445")
#loc177 = loc("multiply.446")
#loc178 = loc("convert.447")
#loc179 = loc("multiply.453")
#loc180 = loc("reshape.462")
#loc181 = loc("reshape.458")
#loc182 = loc("reshape.460")
#loc183 = loc("transpose.461")
#loc184 = loc("dot.463")
#loc185 = loc("reshape.464")
#loc186 = loc("logistic.465")
#loc187 = loc("multiply.466")
#loc188 = loc("reshape.174")
#loc189 = loc("reshape.176")
#loc190 = loc("transpose.177")
#loc191 = loc("dot.455")
#loc192 = loc("reshape.456")
#loc193 = loc("multiply.467")
#loc194 = loc("reshape.468")
#loc195 = loc("reshape.169")
#loc196 = loc("reshape.171")
#loc197 = loc("transpose.172")
#loc199 = loc("reshape.470")
#loc200 = loc("add.473")
#loc201 = loc("convert.474")
#loc202 = loc("power.476")
#loc203 = loc("reduce.483")
#loc204 = loc("multiply.492")
#loc205 = loc("reshape.493")
#loc206 = loc("add.497")
#loc207 = loc("rsqrt.498")
#loc208 = loc("reshape.499")
#loc209 = loc("broadcast.500")
#loc210 = loc("multiply.501")
#loc211 = loc("convert.502")
#loc212 = loc("multiply.508")
#loc213 = loc("reshape.512")
#loc214 = loc("reshape.160")
#loc215 = loc("reshape.162")
#loc216 = loc("transpose.163")
#loc217 = loc("dot.513")
#loc218 = loc("reshape.514")
------------------ END OF MLIR MODULE ------------------
2026-01-02 18:37:36.795 (   7.853s) [        CBC3A000]      module_builder.cc:271      1| Cleaning for XLA ingestion
Out sharding: #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>
Out sharding: #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>
Out sharding: #sdy.sharding<@mesh, [{}, {}]>
Out sharding: #sdy.sharding<@mesh, [{}, {}, {}]>
  Out sharding #0, dim #0, axisName.size()=0
  Out sharding #0, dim #1, axisName.size()=1
  Out sharding #0, dim #2, axisName.size()=0
  Out sharding #0, dim #3, axisName.size()=0
Out sharding str for out sharding #0 is: {devices=[1,2,1,1]<=[2]}
  Out sharding #1, dim #0, axisName.size()=0
  Out sharding #1, dim #1, axisName.size()=1
  Out sharding #1, dim #2, axisName.size()=0
  Out sharding #1, dim #3, axisName.size()=0
Out sharding str for out sharding #1 is: {devices=[1,2,1,1]<=[2]}
  Out sharding #2, dim #0, axisName.size()=0
  Out sharding #2, dim #1, axisName.size()=0
Out sharding str for out sharding #2 is: {replicated}
  Out sharding #3, dim #0, axisName.size()=0
  Out sharding #3, dim #1, axisName.size()=0
  Out sharding #3, dim #2, axisName.size()=0
Out sharding str for out sharding #3 is: {replicated}
Module after injecting out sharding result and simplifying main function:
module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_shardings = "{{devices=[1,2,1,1]<=[2]},{devices=[1,2,1,1]<=[2]},{replicated},{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32xi64>, %arg1: tensor<64xf32>, %arg2: tensor<1024x3072xbf16>, %arg3: tensor<1x32xi64>, %arg4: tensor<128256x3072xbf16>, %arg5: tensor<3072xbf16>, %arg6: tensor<1x8x128x128xbf16>, %arg7: tensor<1024x3072xbf16>, %arg8: tensor<1x8x128x128xbf16>, %arg9: tensor<128256x3072xbf16>, %arg10: tensor<3072x8192xbf16>, %arg11: tensor<8192x3072xbf16>, %arg12: tensor<3072x3072xbf16>, %arg13: tensor<1x32xi64>, %arg14: tensor<i1>, %arg15: tensor<3072x3072xbf16>, %arg16: tensor<3072xbf16>, %arg17: tensor<8192x3072xbf16>, %arg18: tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<1x8x128x128xbf16>
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<1x8x128x128xbf16>
    %cst_1 = stablehlo.constant dense<0.000000e+00> : tensor<32x128256xbf16>
    %cst_2 = stablehlo.constant dense<0.000000e+00> : tensor<1x32x128256xbf16>
    return %cst, %cst_0, %cst_1, %cst_2 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>
  }
}
2026-01-02 18:37:36.800 (   7.859s) [        CBC3A000]      module_builder.cc:276      1| Done cleaning for XLA ingestion - resulting module:
2026-01-02 18:37:36.800 (   7.859s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module shlo_compiler_cleaned:
#loc = loc(unknown)
module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_shardings = "{{devices=[1,2,1,1]<=[2]},{devices=[1,2,1,1]<=[2]},{replicated},{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32xi64> loc(unknown), %arg1: tensor<64xf32> loc(unknown), %arg2: tensor<1024x3072xbf16> loc(unknown), %arg3: tensor<1x32xi64> loc(unknown), %arg4: tensor<128256x3072xbf16> loc(unknown), %arg5: tensor<3072xbf16> loc(unknown), %arg6: tensor<1x8x128x128xbf16> loc(unknown), %arg7: tensor<1024x3072xbf16> loc(unknown), %arg8: tensor<1x8x128x128xbf16> loc(unknown), %arg9: tensor<128256x3072xbf16> loc(unknown), %arg10: tensor<3072x8192xbf16> loc(unknown), %arg11: tensor<8192x3072xbf16> loc(unknown), %arg12: tensor<3072x3072xbf16> loc(unknown), %arg13: tensor<1x32xi64> loc(unknown), %arg14: tensor<i1> loc(unknown), %arg15: tensor<3072x3072xbf16> loc(unknown), %arg16: tensor<3072xbf16> loc(unknown), %arg17: tensor<8192x3072xbf16> loc(unknown), %arg18: tensor<3072xbf16> loc(unknown)) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<1x8x128x128xbf16> loc(#loc)
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<1x8x128x128xbf16> loc(#loc)
    %cst_1 = stablehlo.constant dense<0.000000e+00> : tensor<32x128256xbf16> loc(#loc)
    %cst_2 = stablehlo.constant dense<0.000000e+00> : tensor<1x32x128256xbf16> loc(#loc)
    return %cst, %cst_0, %cst_1, %cst_2 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
------------------ END OF MLIR MODULE ------------------
2026-01-02 18:37:36.846 (   7.905s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module ttir:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.30")
#loc4 = loc("p3.38")
#loc5 = loc("p4.43")
#loc6 = loc("p5.79")
#loc7 = loc("p6.121")
#loc8 = loc("p7.129")
#loc9 = loc("p8.151")
#loc10 = loc("p9.159")
#loc11 = loc("p10.168")
#loc12 = loc("p11.173")
#loc13 = loc("p12.182")
#loc14 = loc("p13.286")
#loc15 = loc("p14.321")
#loc16 = loc("p15.358")
#loc17 = loc("p16.448")
#loc18 = loc("p17.457")
#loc19 = loc("p18.503")
module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
      func.func @main(%arg0: tensor<32xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.30"), %arg3: tensor<1x32xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p3.38"), %arg4: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p4.43"), %arg5: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p5.79"), %arg6: tensor<1x8x128x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p6.121"), %arg7: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p7.129"), %arg8: tensor<1x8x128x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_4"} loc("p8.151"), %arg9: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"} loc("p9.159"), %arg10: tensor<3072x8192xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p10.168"), %arg11: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p11.173"), %arg12: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p12.182"), %arg13: tensor<1x32xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p13.286"), %arg14: tensor<i1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p14.321"), %arg15: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p15.358"), %arg16: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p16.448"), %arg17: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p17.457"), %arg18: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"} loc("p18.503")) -> (tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<32x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x32x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<32xi64>) -> tensor<32xi64> loc(#loc)
        %1 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32>) -> tensor<64xf32> loc(#loc)
        %2 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc)
        %3 = "ttir.mesh_shard"(%arg3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x32xi64>) -> tensor<1x32xi64> loc(#loc)
        %4 = "ttir.mesh_shard"(%arg4) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc)
        %5 = "ttir.mesh_shard"(%arg5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc)
        %6 = "ttir.mesh_shard"(%arg6) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16> loc(#loc)
        %7 = "ttir.mesh_shard"(%arg7) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc)
        %8 = "ttir.mesh_shard"(%arg8) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16> loc(#loc)
        %9 = "ttir.mesh_shard"(%arg9) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc)
        %10 = "ttir.mesh_shard"(%arg10) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>) -> tensor<3072x4096xbf16> loc(#loc)
        %11 = "ttir.mesh_shard"(%arg11) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc)
        %12 = "ttir.mesh_shard"(%arg12) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>) -> tensor<3072x1536xbf16> loc(#loc)
        %13 = "ttir.mesh_shard"(%arg13) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x32xi64>) -> tensor<1x32xi64> loc(#loc)
        %14 = "ttir.mesh_shard"(%arg14) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<i1>) -> tensor<i1> loc(#loc)
        %15 = "ttir.mesh_shard"(%arg15) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc)
        %16 = "ttir.mesh_shard"(%arg16) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc)
        %17 = "ttir.mesh_shard"(%arg17) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc)
        %18 = "ttir.mesh_shard"(%arg18) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc)
        %19 = "ttir.constant"() <{value = dense<"0x00000000000000000100000000000000020000000000000003000000000000000400000000000000050000000000000006000000000000000700000000000000080000000000000009000000000000000A000000000000000B000000000000000C000000000000000D000000000000000E000000000000000F0000000000000010000000000000001100000000000000120000000000000013000000000000001400000000000000150000000000000016000000000000001700000000000000180000000000000019000000000000001A000000000000001B000000000000001C000000000000001D000000000000001E000000000000001F0000000000000020000000000000002100000000000000220000000000000023000000000000002400000000000000250000000000000026000000000000002700000000000000280000000000000029000000000000002A000000000000002B000000000000002C000000000000002D000000000000002E000000000000002F0000000000000030000000000000003100000000000000320000000000000033000000000000003400000000000000350000000000000036000000000000003700000000000000380000000000000039000000000000003A000000000000003B000000000000003C000000000000003D000000000000003E000000000000003F0000000000000040000000000000004100000000000000420000000000000043000000000000004400000000000000450000000000000046000000000000004700000000000000480000000000000049000000000000004A000000000000004B000000000000004C000000000000004D000000000000004E000000000000004F0000000000000050000000000000005100000000000000520000000000000053000000000000005400000000000000550000000000000056000000000000005700000000000000580000000000000059000000000000005A000000000000005B000000000000005C000000000000005D000000000000005E000000000000005F0000000000000060000000000000006100000000000000620000000000000063000000000000006400000000000000650000000000000066000000000000006700000000000000680000000000000069000000000000006A000000000000006B000000000000006C000000000000006D000000000000006E000000000000006F0000000000000070000000000000007100000000000000720000000000000073000000000000007400000000000000750000000000000076000000000000007700000000000000780000000000000079000000000000007A000000000000007B000000000000007C000000000000007D000000000000007E000000000000007F00000000000000"> : tensor<128xi64>}> : () -> tensor<128xi64> loc(#loc)
        %20 = "ttir.constant"() <{value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xi64>}> : () -> tensor<32xi64> loc(#loc)
        %21 = "ttir.constant"() <{value = dense<128> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
        %22 = "ttir.constant"() <{value = dense<2.000000e+00> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
        %23 = "ttir.constant"() <{value = dense<3.25520843E-4> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
        %24 = "ttir.constant"() <{value = dense<9.99999974E-6> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
        %25 = "ttir.constant"() <{value = dense<8.837890e-02> : tensor<bf16>}> : () -> tensor<bf16> loc(#loc)
        %26 = "ttir.constant"() <{value = dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1>}> : () -> tensor<128xi1> loc(#loc)
        %27 = "ttir.constant"() <{value = dense<1> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
        %28 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<bf16>}> : () -> tensor<bf16> loc(#loc)
        %29 = "ttir.constant"() <{value = dense<-3.389530e+38> : tensor<bf16>}> : () -> tensor<bf16> loc(#loc)
        %30 = "ttir.constant"() <{value = dense<0> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
        %31 = "ttir.constant"() <{value = dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>}> : () -> tensor<128xf32> loc(#loc)
        %32 = "ttir.constant"() <{value = dense<31> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
        %33 = "ttir.constant"() <{value = dense<32> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
        %34 = "ttir.reshape"(%33) <{shape = [1 : i32]}> : (tensor<i64>) -> tensor<1xi64> loc(#loc)
        %35 = "ttir.broadcast"(%34) <{broadcast_dimensions = array<i64: 128>}> : (tensor<1xi64>) -> tensor<128xi64> loc(#loc)
        %36 = "ttir.reshape"(%32) <{shape = [1 : i32]}> : (tensor<i64>) -> tensor<1xi64> loc(#loc)
        %37 = "ttir.broadcast"(%36) <{broadcast_dimensions = array<i64: 128>}> : (tensor<1xi64>) -> tensor<128xi64> loc(#loc)
        %38 = "ttir.reshape"(%30) <{shape = [1 : i32]}> : (tensor<i64>) -> tensor<1xi64> loc(#loc)
        %39 = "ttir.broadcast"(%38) <{broadcast_dimensions = array<i64: 128>}> : (tensor<1xi64>) -> tensor<128xi64> loc(#loc)
        %40 = "ttir.reshape"(%29) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>) -> tensor<1x1x1x1xbf16> loc(#loc)
        %41 = "ttir.broadcast"(%40) <{broadcast_dimensions = array<i64: 1, 1, 32, 32>}> : (tensor<1x1x1x1xbf16>) -> tensor<1x1x32x32xbf16> loc(#loc)
        %42 = "ttir.reshape"(%28) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>) -> tensor<1x1x1x1xbf16> loc(#loc)
        %43 = "ttir.broadcast"(%42) <{broadcast_dimensions = array<i64: 1, 1, 32, 32>}> : (tensor<1x1x1x1xbf16>) -> tensor<1x1x32x32xbf16> loc(#loc)
        %44 = "ttir.reshape"(%28) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>) -> tensor<1x1xbf16> loc(#loc)
        %45 = "ttir.broadcast"(%44) <{broadcast_dimensions = array<i64: 32, 128>}> : (tensor<1x1xbf16>) -> tensor<32x128xbf16> loc(#loc)
        %46 = "ttir.reshape"(%29) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>) -> tensor<1x1xbf16> loc(#loc)
        %47 = "ttir.broadcast"(%46) <{broadcast_dimensions = array<i64: 32, 128>}> : (tensor<1x1xbf16>) -> tensor<32x128xbf16> loc(#loc)
        %48 = "ttir.reshape"(%27) <{shape = [1 : i32, 1 : i32]}> : (tensor<i64>) -> tensor<1x1xi64> loc(#loc)
        %49 = "ttir.broadcast"(%48) <{broadcast_dimensions = array<i64: 32, 128>}> : (tensor<1x1xi64>) -> tensor<32x128xi64> loc(#loc)
        %50 = "ttir.broadcast"(%42) <{broadcast_dimensions = array<i64: 1, 1, 32, 128>}> : (tensor<1x1x1x1xbf16>) -> tensor<1x1x32x128xbf16> loc(#loc)
        %51 = "ttir.reshape"(%25) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>) -> tensor<1x1x1x1xbf16> loc(#loc)
        %52 = "ttir.broadcast"(%51) <{broadcast_dimensions = array<i64: 1, 12, 32, 128>}> : (tensor<1x1x1x1xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc)
        %53 = "ttir.reshape"(%24) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>) -> tensor<1x1x1xf32> loc(#loc)
        %54 = "ttir.broadcast"(%53) <{broadcast_dimensions = array<i64: 1, 32, 1>}> : (tensor<1x1x1xf32>) -> tensor<1x32x1xf32> loc(#loc)
        %55 = "ttir.reshape"(%23) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32>) -> tensor<1x1xf32> loc(#loc)
        %56 = "ttir.broadcast"(%55) <{broadcast_dimensions = array<i64: 1, 32>}> : (tensor<1x1xf32>) -> tensor<1x32xf32> loc(#loc)
        %57 = "ttir.reshape"(%22) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>) -> tensor<1x1x1xf32> loc(#loc)
        %58 = "ttir.broadcast"(%57) <{broadcast_dimensions = array<i64: 1, 32, 3072>}> : (tensor<1x1x1xf32>) -> tensor<1x32x3072xf32> loc(#loc)
        %59 = "ttir.reshape"(%21) <{shape = [1 : i32]}> : (tensor<i64>) -> tensor<1xi64> loc(#loc)
        %60 = "ttir.broadcast"(%59) <{broadcast_dimensions = array<i64: 32>}> : (tensor<1xi64>) -> tensor<32xi64> loc(#loc)
        %61 = "ttir.broadcast"(%38) <{broadcast_dimensions = array<i64: 32>}> : (tensor<1xi64>) -> tensor<32xi64> loc(#loc)
        %62 = "ttir.reshape"(%0) <{shape = [1 : i32, 1 : i32, 32 : i32]}> : (tensor<32xi64>) -> tensor<1x1x32xi64> loc(#loc20)
        %63 = "ttir.reshape"(%62) <{shape = [32 : i32]}> : (tensor<1x1x32xi64>) -> tensor<32xi64> loc(#loc21)
        %64 = "ttir.lt"(%63, %61) : (tensor<32xi64>, tensor<32xi64>) -> tensor<32xi1> loc(#loc22)
        %65 = "ttir.add"(%63, %60) : (tensor<32xi64>, tensor<32xi64>) -> tensor<32xi64> loc(#loc23)
        %66 = "ttir.where"(%64, %65, %63) : (tensor<32xi1>, tensor<32xi64>, tensor<32xi64>) -> tensor<32xi64> loc(#loc24)
        %67 = "ttir.reshape"(%5) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc25)
        %68 = "ttir.reshape"(%67) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc26)
        %69 = "ttir.reshape"(%68) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc27)
        %70 = "ttir.broadcast"(%69) <{broadcast_dimensions = array<i64: 1, 32, 1>}> : (tensor<1x1x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc27)
        %71 = "ttir.reshape"(%4) <{shape = [1 : i32, 128256 : i32, 3072 : i32]}> : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc28)
        %72 = "ttir.reshape"(%71) <{shape = [128256 : i32, 3072 : i32]}> : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc29)
        %73 = "ttir.reshape"(%3) <{shape = [1 : i32, 1 : i32, 32 : i32]}> : (tensor<1x32xi64>) -> tensor<1x1x32xi64> loc(#loc30)
        %74 = "ttir.reshape"(%73) <{shape = [32 : i32]}> : (tensor<1x1x32xi64>) -> tensor<32xi64> loc(#loc31)
        %75 = "ttir.typecast"(%74) <{conservative_folding = false}> : (tensor<32xi64>) -> tensor<32xui32> loc(#loc32)
        %76 = "ttir.gather"(%72, %75) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3072>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<128256x3072xbf16>, tensor<32xui32>) -> tensor<32x3072xbf16> loc(#loc33)
        %77 = "ttir.reshape"(%76) <{shape = [1 : i32, 32 : i32, 3072 : i32]}> : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc34)
        %78 = "ttir.typecast"(%77) <{conservative_folding = false}> : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32> loc(#loc35)
        %79 = "ttir.pow"(%78, %58) : (tensor<1x32x3072xf32>, tensor<1x32x3072xf32>) -> tensor<1x32x3072xf32> loc(#loc36)
        %80 = "ttir.sum"(%79) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x32x3072xf32>) -> tensor<1x32xf32> loc(#loc37)
        %81 = "ttir.multiply"(%80, %56) : (tensor<1x32xf32>, tensor<1x32xf32>) -> tensor<1x32xf32> loc(#loc38)
        %82 = "ttir.reshape"(%81) <{shape = [1 : i32, 32 : i32, 1 : i32]}> : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc39)
        %83 = "ttir.add"(%82, %54) : (tensor<1x32x1xf32>, tensor<1x32x1xf32>) -> tensor<1x32x1xf32> loc(#loc40)
        %84 = "ttir.rsqrt"(%83) : (tensor<1x32x1xf32>) -> tensor<1x32x1xf32> loc(#loc41)
        %85 = "ttir.reshape"(%84) <{shape = [1 : i32, 32 : i32]}> : (tensor<1x32x1xf32>) -> tensor<1x32xf32> loc(#loc42)
        %86 = "ttir.reshape"(%85) <{shape = [1 : i32, 32 : i32, 1 : i32]}> : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc43)
        %87 = "ttir.broadcast"(%86) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x32x1xf32>) -> tensor<1x32x3072xf32> loc(#loc43)
        %88 = "ttir.multiply"(%78, %87) : (tensor<1x32x3072xf32>, tensor<1x32x3072xf32>) -> tensor<1x32x3072xf32> loc(#loc44)
        %89 = "ttir.typecast"(%88) <{conservative_folding = false}> : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16> loc(#loc45)
        %90 = "ttir.multiply"(%70, %89) : (tensor<1x32x3072xbf16>, tensor<1x32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc46)
        %91 = "ttir.reshape"(%90) <{shape = [32 : i32, 3072 : i32]}> : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc47)
        %92 = "ttir.reshape"(%2) <{shape = [1 : i32, 512 : i32, 3072 : i32]}> : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc48)
        %93 = "ttir.reshape"(%92) <{shape = [512 : i32, 3072 : i32]}> : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc49)
        %94 = "ttir.permute"(%93) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16> loc(#loc50)
        %95 = "ttir.dot_general"(%91, %94) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16> loc(#loc51)
        %96 = "ttir.reshape"(%95) <{shape = [1 : i32, 32 : i32, 4 : i32, 128 : i32]}> : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16> loc(#loc52)
        %97 = "ttir.permute"(%96) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16> loc(#loc53)
        %98 = "ttir.reshape"(%1) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc54)
        %99 = "ttir.reshape"(%98) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc55)
        %100 = "ttir.typecast"(%62) <{conservative_folding = false}> : (tensor<1x1x32xi64>) -> tensor<1x1x32xf32> loc(#loc56)
        %101 = "ttir.dot_general"(%99, %100) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<1x64x1xf32>, tensor<1x1x32xf32>) -> tensor<1x64x32xf32> loc(#loc57)
        %102 = "ttir.permute"(%101) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x32xf32>) -> tensor<1x32x64xf32> loc(#loc58)
        %103 = "ttir.concat"(%102, %102) <{dim = 2 : si32}> : (tensor<1x32x64xf32>, tensor<1x32x64xf32>) -> tensor<1x32x128xf32> loc(#loc59)
        %104 = "ttir.cos"(%103) : (tensor<1x32x128xf32>) -> tensor<1x32x128xf32> loc(#loc60)
        %105 = "ttir.typecast"(%104) <{conservative_folding = false}> : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16> loc(#loc61)
        %106 = "ttir.reshape"(%105) <{shape = [1 : i32, 1 : i32, 32 : i32, 128 : i32]}> : (tensor<1x32x128xbf16>) -> tensor<1x1x32x128xbf16> loc(#loc62)
        %107 = "ttir.broadcast"(%106) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x32x128xbf16>) -> tensor<1x4x32x128xbf16> loc(#loc62)
        %108 = "ttir.multiply"(%97, %107) : (tensor<1x4x32x128xbf16>, tensor<1x4x32x128xbf16>) -> tensor<1x4x32x128xbf16> loc(#loc63)
        %109 = "ttir.slice_static"(%97) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 32 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16> loc(#loc64)
        %110 = "ttir.neg"(%109) : (tensor<1x4x32x64xbf16>) -> tensor<1x4x32x64xbf16> loc(#loc65)
        %111 = "ttir.slice_static"(%97) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 32 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16> loc(#loc66)
        %112 = "ttir.concat"(%110, %111) <{dim = 3 : si32}> : (tensor<1x4x32x64xbf16>, tensor<1x4x32x64xbf16>) -> tensor<1x4x32x128xbf16> loc(#loc67)
        %113 = "ttir.sin"(%103) : (tensor<1x32x128xf32>) -> tensor<1x32x128xf32> loc(#loc68)
        %114 = "ttir.typecast"(%113) <{conservative_folding = false}> : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16> loc(#loc69)
        %115 = "ttir.reshape"(%114) <{shape = [1 : i32, 1 : i32, 32 : i32, 128 : i32]}> : (tensor<1x32x128xbf16>) -> tensor<1x1x32x128xbf16> loc(#loc70)
        %116 = "ttir.broadcast"(%115) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x32x128xbf16>) -> tensor<1x4x32x128xbf16> loc(#loc70)
        %117 = "ttir.multiply"(%112, %116) : (tensor<1x4x32x128xbf16>, tensor<1x4x32x128xbf16>) -> tensor<1x4x32x128xbf16> loc(#loc71)
        %118 = "ttir.add"(%108, %117) : (tensor<1x4x32x128xbf16>, tensor<1x4x32x128xbf16>) -> tensor<1x4x32x128xbf16> loc(#loc72)
        %119 = "ttir.fill_cache"(%6, %118) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16> loc(#loc73)
        %120 = "ttir.reshape"(%7) <{shape = [1 : i32, 512 : i32, 3072 : i32]}> : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc74)
        %121 = "ttir.reshape"(%120) <{shape = [512 : i32, 3072 : i32]}> : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc75)
        %122 = "ttir.permute"(%121) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16> loc(#loc76)
        %123 = "ttir.dot_general"(%91, %122) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16> loc(#loc77)
        %124 = "ttir.reshape"(%123) <{shape = [1 : i32, 32 : i32, 4 : i32, 128 : i32]}> : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16> loc(#loc78)
        %125 = "ttir.permute"(%124) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16> loc(#loc79)
        %126 = "ttir.fill_cache"(%8, %125) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16> loc(#loc80)
        %127 = "ttir.reshape"(%18) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc81)
        %128 = "ttir.reshape"(%127) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc82)
        %129 = "ttir.reshape"(%128) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc83)
        %130 = "ttir.broadcast"(%129) <{broadcast_dimensions = array<i64: 1, 32, 1>}> : (tensor<1x1x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc83)
        %131 = "ttir.reshape"(%15) <{shape = [1 : i32, 1536 : i32, 3072 : i32]}> : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16> loc(#loc84)
        %132 = "ttir.reshape"(%131) <{shape = [1536 : i32, 3072 : i32]}> : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc85)
        %133 = "ttir.permute"(%132) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16> loc(#loc86)
        %134 = "ttir.dot_general"(%91, %133) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<32x1536xbf16> loc(#loc87)
        %135 = "ttir.reshape"(%134) <{shape = [1 : i32, 32 : i32, 12 : i32, 128 : i32]}> : (tensor<32x1536xbf16>) -> tensor<1x32x12x128xbf16> loc(#loc88)
        %136 = "ttir.permute"(%135) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x32x12x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc89)
        %137 = "ttir.broadcast"(%106) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x32x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc90)
        %138 = "ttir.multiply"(%136, %137) : (tensor<1x12x32x128xbf16>, tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc91)
        %139 = "ttir.slice_static"(%136) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 32 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16> loc(#loc92)
        %140 = "ttir.neg"(%139) : (tensor<1x12x32x64xbf16>) -> tensor<1x12x32x64xbf16> loc(#loc93)
        %141 = "ttir.slice_static"(%136) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 32 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16> loc(#loc94)
        %142 = "ttir.concat"(%140, %141) <{dim = 3 : si32}> : (tensor<1x12x32x64xbf16>, tensor<1x12x32x64xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc95)
        %143 = "ttir.broadcast"(%115) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x32x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc96)
        %144 = "ttir.multiply"(%142, %143) : (tensor<1x12x32x128xbf16>, tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc97)
        %145 = "ttir.add"(%138, %144) : (tensor<1x12x32x128xbf16>, tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc98)
        %146 = "ttir.reshape"(%119) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>) -> tensor<1x4x1x128x128xbf16> loc(#loc99)
        %147 = "ttir.broadcast"(%146) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>) -> tensor<1x4x3x128x128xbf16> loc(#loc99)
        %148 = "ttir.reshape"(%147) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16> loc(#loc100)
        %149 = "ttir.permute"(%148) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16> loc(#loc101)
        %150 = "ttir.dot_general"(%145, %149) <{batch_dims_lhs = array<i64: 0, 1>, batch_dims_rhs = array<i64: 0, 1>, contract_dims_lhs = array<i64: 3>, contract_dims_rhs = array<i64: 2>}> : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc102)
        %151 = "ttir.multiply"(%150, %52) : (tensor<1x12x32x128xbf16>, tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc103)
        %152 = "ttir.reshape"(%14) <{shape = [1 : i32]}> : (tensor<i1>) -> tensor<1xi1> loc(#loc104)
        %153 = "ttir.broadcast"(%152) <{broadcast_dimensions = array<i64: 128>}> : (tensor<1xi1>) -> tensor<128xi1> loc(#loc104)
        %154 = "ttir.logical_and"(%153, %26) : (tensor<128xi1>, tensor<128xi1>) -> tensor<128xi1> loc(#loc105)
        %155 = "ttir.reshape"(%154) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xi1>) -> tensor<1x1x1x128xi1> loc(#loc106)
        %156 = "ttir.reshape"(%154) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xi1>) -> tensor<1x1x128xi1> loc(#loc107)
        %157 = "ttir.reshape"(%156) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xi1>) -> tensor<1x1x1x128xi1> loc(#loc108)
        %158 = "ttir.broadcast"(%157) <{broadcast_dimensions = array<i64: 1, 1, 32, 1>}> : (tensor<1x1x1x128xi1>) -> tensor<1x1x32x128xi1> loc(#loc108)
        %159 = "ttir.logical_not"(%155) : (tensor<1x1x1x128xi1>) -> tensor<1x1x1x128xi1> loc(#loc109)
        %160 = "ttir.reshape"(%159) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x1x128xi1>) -> tensor<1x1x128xi1> loc(#loc110)
        %161 = "ttir.reshape"(%160) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xi1>) -> tensor<1x1x1x128xi1> loc(#loc111)
        %162 = "ttir.broadcast"(%161) <{broadcast_dimensions = array<i64: 1, 1, 32, 1>}> : (tensor<1x1x1x128xi1>) -> tensor<1x1x32x128xi1> loc(#loc111)
        %163 = "ttir.reshape"(%19) <{shape = [1 : i32, 128 : i32]}> : (tensor<128xi64>) -> tensor<1x128xi64> loc(#loc112)
        %164 = "ttir.broadcast"(%163) <{broadcast_dimensions = array<i64: 32, 1>}> : (tensor<1x128xi64>) -> tensor<32x128xi64> loc(#loc112)
        %165 = "ttir.reshape"(%20) <{shape = [32 : i32, 1 : i32]}> : (tensor<32xi64>) -> tensor<32x1xi64> loc(#loc113)
        %166 = "ttir.broadcast"(%165) <{broadcast_dimensions = array<i64: 1, 128>}> : (tensor<32x1xi64>) -> tensor<32x128xi64> loc(#loc113)
        %167 = "ttir.subtract"(%164, %166) : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi64> loc(#loc114)
        %168 = "ttir.ge"(%167, %49) : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1> loc(#loc115)
        %169 = "ttir.where"(%168, %47, %45) : (tensor<32x128xi1>, tensor<32x128xbf16>, tensor<32x128xbf16>) -> tensor<32x128xbf16> loc(#loc116)
        %170 = "ttir.reshape"(%63) <{shape = [32 : i32, 1 : i32]}> : (tensor<32xi64>) -> tensor<32x1xi64> loc(#loc117)
        %171 = "ttir.broadcast"(%170) <{broadcast_dimensions = array<i64: 1, 128>}> : (tensor<32x1xi64>) -> tensor<32x128xi64> loc(#loc117)
        %172 = "ttir.gt"(%164, %171) : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1> loc(#loc118)
        %173 = "ttir.typecast"(%172) <{conservative_folding = false}> : (tensor<32x128xi1>) -> tensor<32x128xbf16> loc(#loc119)
        %174 = "ttir.multiply"(%169, %173) : (tensor<32x128xbf16>, tensor<32x128xbf16>) -> tensor<32x128xbf16> loc(#loc120)
        %175 = "ttir.reshape"(%174) <{shape = [1 : i32, 1 : i32, 32 : i32, 128 : i32]}> : (tensor<32x128xbf16>) -> tensor<1x1x32x128xbf16> loc(#loc121)
        %176 = "ttir.slice_static"(%175) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 1 : i32, 32 : i32, 32 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1x32x128xbf16>) -> tensor<1x1x32x32xbf16> loc(#loc122)
        %177 = "ttir.reshape"(%13) <{shape = [1 : i32, 1 : i32, 32 : i32]}> : (tensor<1x32xi64>) -> tensor<1x1x32xi64> loc(#loc123)
        %178 = "ttir.reshape"(%177) <{shape = [1 : i32, 1 : i32, 1 : i32, 32 : i32]}> : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64> loc(#loc124)
        %179 = "ttir.typecast"(%178) <{conservative_folding = false}> : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16> loc(#loc125)
        %180 = "ttir.reshape"(%179) <{shape = [1 : i32, 1 : i32, 32 : i32]}> : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32xbf16> loc(#loc126)
        %181 = "ttir.reshape"(%180) <{shape = [1 : i32, 1 : i32, 1 : i32, 32 : i32]}> : (tensor<1x1x32xbf16>) -> tensor<1x1x1x32xbf16> loc(#loc127)
        %182 = "ttir.broadcast"(%181) <{broadcast_dimensions = array<i64: 1, 1, 32, 1>}> : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32x32xbf16> loc(#loc127)
        %183 = "ttir.add"(%176, %182) : (tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xbf16> loc(#loc128)
        %184 = "ttir.eq"(%183, %43) : (tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xi1> loc(#loc129)
        %185 = "ttir.where"(%184, %41, %176) : (tensor<1x1x32x32xi1>, tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xbf16> loc(#loc130)
        %186 = "ttir.floor"(%31) : (tensor<128xf32>) -> tensor<128xf32> loc(#loc131)
        %187 = "ttir.typecast"(%186) <{conservative_folding = false}> : (tensor<128xf32>) -> tensor<128xi64> loc(#loc132)
        %188 = "ttir.clamp_tensor"(%187, %39, %37) : (tensor<128xi64>, tensor<128xi64>, tensor<128xi64>) -> tensor<128xi64> loc(#loc133)
        %189 = "ttir.lt"(%188, %39) : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1> loc(#loc134)
        %190 = "ttir.add"(%188, %35) : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi64> loc(#loc135)
        %191 = "ttir.where"(%189, %190, %188) : (tensor<128xi1>, tensor<128xi64>, tensor<128xi64>) -> tensor<128xi64> loc(#loc136)
        %192 = "ttir.reshape"(%191) <{shape = [128 : i32, 1 : i32]}> : (tensor<128xi64>) -> tensor<128x1xi64> loc(#loc137)
        %193 = "ttir.gather"(%185, %192) <{collapsed_slice_dims = array<i64: 3>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 0, 1, 2>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 1, 32, 1>, start_index_map = array<i64: 3>, start_indices_batching_dims = array<i64>}> : (tensor<1x1x32x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x32x128xbf16> loc(#loc138)
        %194 = "ttir.where"(%162, %50, %193) : (tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>, tensor<1x1x32x128xbf16>) -> tensor<1x1x32x128xbf16> loc(#loc139)
        %195 = "ttir.where"(%158, %194, %175) : (tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>, tensor<1x1x32x128xbf16>) -> tensor<1x1x32x128xbf16> loc(#loc140)
        %196 = "ttir.reshape"(%195) <{shape = [1 : i32, 32 : i32, 128 : i32]}> : (tensor<1x1x32x128xbf16>) -> tensor<1x32x128xbf16> loc(#loc141)
        %197 = "ttir.reshape"(%196) <{shape = [1 : i32, 1 : i32, 32 : i32, 128 : i32]}> : (tensor<1x32x128xbf16>) -> tensor<1x1x32x128xbf16> loc(#loc142)
        %198 = "ttir.broadcast"(%197) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x32x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc142)
        %199 = "ttir.add"(%151, %198) : (tensor<1x12x32x128xbf16>, tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc143)
        %200 = "ttir.typecast"(%199) <{conservative_folding = false}> : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xf32> loc(#loc144)
        %201 = "ttir.max"(%200) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x32x128xf32>) -> tensor<1x12x32xf32> loc(#loc145)
        %202 = "ttir.reshape"(%201) <{shape = [1 : i32, 12 : i32, 32 : i32, 1 : i32]}> : (tensor<1x12x32xf32>) -> tensor<1x12x32x1xf32> loc(#loc146)
        %203 = "ttir.broadcast"(%202) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x32x1xf32>) -> tensor<1x12x32x128xf32> loc(#loc146)
        %204 = "ttir.subtract"(%200, %203) : (tensor<1x12x32x128xf32>, tensor<1x12x32x128xf32>) -> tensor<1x12x32x128xf32> loc(#loc147)
        %205 = "ttir.exp"(%204) : (tensor<1x12x32x128xf32>) -> tensor<1x12x32x128xf32> loc(#loc148)
        %206 = "ttir.sum"(%205) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x32x128xf32>) -> tensor<1x12x32xf32> loc(#loc149)
        %207 = "ttir.reshape"(%206) <{shape = [1 : i32, 12 : i32, 32 : i32, 1 : i32]}> : (tensor<1x12x32xf32>) -> tensor<1x12x32x1xf32> loc(#loc150)
        %208 = "ttir.broadcast"(%207) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x32x1xf32>) -> tensor<1x12x32x128xf32> loc(#loc150)
        %209 = "ttir.div"(%205, %208) : (tensor<1x12x32x128xf32>, tensor<1x12x32x128xf32>) -> tensor<1x12x32x128xf32> loc(#loc151)
        %210 = "ttir.typecast"(%209) <{conservative_folding = false}> : (tensor<1x12x32x128xf32>) -> tensor<1x12x32x128xbf16> loc(#loc152)
        %211 = "ttir.reshape"(%126) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>) -> tensor<1x4x1x128x128xbf16> loc(#loc153)
        %212 = "ttir.broadcast"(%211) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>) -> tensor<1x4x3x128x128xbf16> loc(#loc153)
        %213 = "ttir.reshape"(%212) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16> loc(#loc154)
        %214 = "ttir.dot_general"(%210, %213) <{batch_dims_lhs = array<i64: 0, 1>, batch_dims_rhs = array<i64: 0, 1>, contract_dims_lhs = array<i64: 3>, contract_dims_rhs = array<i64: 2>}> : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16> loc(#loc155)
        %215 = "ttir.permute"(%214) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x12x32x128xbf16>) -> tensor<1x32x12x128xbf16> loc(#loc156)
        %216 = "ttir.reshape"(%215) <{shape = [32 : i32, 1536 : i32]}> : (tensor<1x32x12x128xbf16>) -> tensor<32x1536xbf16> loc(#loc157)
        %217 = "ttir.reshape"(%12) <{shape = [1 : i32, 3072 : i32, 1536 : i32]}> : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16> loc(#loc158)
        %218 = "ttir.reshape"(%217) <{shape = [3072 : i32, 1536 : i32]}> : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16> loc(#loc159)
        %219 = "ttir.permute"(%218) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16> loc(#loc160)
        %220 = "ttir.dot_general"(%216, %219) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc161)
        %221 = "ttir.all_reduce"(%220) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc161)
        %222 = "ttir.reshape"(%221) <{shape = [1 : i32, 32 : i32, 3072 : i32]}> : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc162)
        %223 = "ttir.add"(%77, %222) : (tensor<1x32x3072xbf16>, tensor<1x32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc163)
        %224 = "ttir.reshape"(%16) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc164)
        %225 = "ttir.reshape"(%224) <{shape = [3072 : i32]}> : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16> loc(#loc165)
        %226 = "ttir.reshape"(%225) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc166)
        %227 = "ttir.broadcast"(%226) <{broadcast_dimensions = array<i64: 1, 32, 1>}> : (tensor<1x1x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc166)
        %228 = "ttir.typecast"(%223) <{conservative_folding = false}> : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32> loc(#loc167)
        %229 = "ttir.pow"(%228, %58) : (tensor<1x32x3072xf32>, tensor<1x32x3072xf32>) -> tensor<1x32x3072xf32> loc(#loc168)
        %230 = "ttir.sum"(%229) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x32x3072xf32>) -> tensor<1x32xf32> loc(#loc169)
        %231 = "ttir.multiply"(%230, %56) : (tensor<1x32xf32>, tensor<1x32xf32>) -> tensor<1x32xf32> loc(#loc170)
        %232 = "ttir.reshape"(%231) <{shape = [1 : i32, 32 : i32, 1 : i32]}> : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc171)
        %233 = "ttir.add"(%232, %54) : (tensor<1x32x1xf32>, tensor<1x32x1xf32>) -> tensor<1x32x1xf32> loc(#loc172)
        %234 = "ttir.rsqrt"(%233) : (tensor<1x32x1xf32>) -> tensor<1x32x1xf32> loc(#loc173)
        %235 = "ttir.reshape"(%234) <{shape = [1 : i32, 32 : i32]}> : (tensor<1x32x1xf32>) -> tensor<1x32xf32> loc(#loc174)
        %236 = "ttir.reshape"(%235) <{shape = [1 : i32, 32 : i32, 1 : i32]}> : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc175)
        %237 = "ttir.broadcast"(%236) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x32x1xf32>) -> tensor<1x32x3072xf32> loc(#loc175)
        %238 = "ttir.multiply"(%228, %237) : (tensor<1x32x3072xf32>, tensor<1x32x3072xf32>) -> tensor<1x32x3072xf32> loc(#loc176)
        %239 = "ttir.typecast"(%238) <{conservative_folding = false}> : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16> loc(#loc177)
        %240 = "ttir.multiply"(%227, %239) : (tensor<1x32x3072xbf16>, tensor<1x32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc178)
        %241 = "ttir.reshape"(%240) <{shape = [32 : i32, 3072 : i32]}> : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc179)
        %242 = "ttir.reshape"(%17) <{shape = [1 : i32, 4096 : i32, 3072 : i32]}> : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc180)
        %243 = "ttir.reshape"(%242) <{shape = [4096 : i32, 3072 : i32]}> : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc181)
        %244 = "ttir.permute"(%243) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16> loc(#loc182)
        %245 = "ttir.dot_general"(%241, %244) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16> loc(#loc183)
        %246 = "ttir.reshape"(%245) <{shape = [1 : i32, 32 : i32, 4096 : i32]}> : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16> loc(#loc184)
        %247 = "ttir.sigmoid"(%246) : (tensor<1x32x4096xbf16>) -> tensor<1x32x4096xbf16> loc(#loc185)
        %248 = "ttir.multiply"(%246, %247) : (tensor<1x32x4096xbf16>, tensor<1x32x4096xbf16>) -> tensor<1x32x4096xbf16> loc(#loc186)
        %249 = "ttir.reshape"(%11) <{shape = [1 : i32, 4096 : i32, 3072 : i32]}> : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc187)
        %250 = "ttir.reshape"(%249) <{shape = [4096 : i32, 3072 : i32]}> : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc188)
        %251 = "ttir.permute"(%250) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16> loc(#loc189)
        %252 = "ttir.dot_general"(%241, %251) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16> loc(#loc190)
        %253 = "ttir.reshape"(%252) <{shape = [1 : i32, 32 : i32, 4096 : i32]}> : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16> loc(#loc191)
        %254 = "ttir.multiply"(%248, %253) : (tensor<1x32x4096xbf16>, tensor<1x32x4096xbf16>) -> tensor<1x32x4096xbf16> loc(#loc192)
        %255 = "ttir.reshape"(%254) <{shape = [32 : i32, 4096 : i32]}> : (tensor<1x32x4096xbf16>) -> tensor<32x4096xbf16> loc(#loc193)
        %256 = "ttir.reshape"(%10) <{shape = [1 : i32, 3072 : i32, 4096 : i32]}> : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16> loc(#loc194)
        %257 = "ttir.reshape"(%256) <{shape = [3072 : i32, 4096 : i32]}> : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc195)
        %258 = "ttir.permute"(%257) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16> loc(#loc196)
        %259 = "ttir.dot_general"(%255, %258) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc197)
        %260 = "ttir.all_reduce"(%259) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc197)
        %261 = "ttir.reshape"(%260) <{shape = [1 : i32, 32 : i32, 3072 : i32]}> : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc198)
        %262 = "ttir.add"(%223, %261) : (tensor<1x32x3072xbf16>, tensor<1x32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc199)
        %263 = "ttir.typecast"(%262) <{conservative_folding = false}> : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32> loc(#loc200)
        %264 = "ttir.pow"(%263, %58) : (tensor<1x32x3072xf32>, tensor<1x32x3072xf32>) -> tensor<1x32x3072xf32> loc(#loc201)
        %265 = "ttir.sum"(%264) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x32x3072xf32>) -> tensor<1x32xf32> loc(#loc202)
        %266 = "ttir.multiply"(%265, %56) : (tensor<1x32xf32>, tensor<1x32xf32>) -> tensor<1x32xf32> loc(#loc203)
        %267 = "ttir.reshape"(%266) <{shape = [1 : i32, 32 : i32, 1 : i32]}> : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc204)
        %268 = "ttir.add"(%267, %54) : (tensor<1x32x1xf32>, tensor<1x32x1xf32>) -> tensor<1x32x1xf32> loc(#loc205)
        %269 = "ttir.rsqrt"(%268) : (tensor<1x32x1xf32>) -> tensor<1x32x1xf32> loc(#loc206)
        %270 = "ttir.reshape"(%269) <{shape = [1 : i32, 32 : i32]}> : (tensor<1x32x1xf32>) -> tensor<1x32xf32> loc(#loc207)
        %271 = "ttir.reshape"(%270) <{shape = [1 : i32, 32 : i32, 1 : i32]}> : (tensor<1x32xf32>) -> tensor<1x32x1xf32> loc(#loc208)
        %272 = "ttir.broadcast"(%271) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x32x1xf32>) -> tensor<1x32x3072xf32> loc(#loc208)
        %273 = "ttir.multiply"(%263, %272) : (tensor<1x32x3072xf32>, tensor<1x32x3072xf32>) -> tensor<1x32x3072xf32> loc(#loc209)
        %274 = "ttir.typecast"(%273) <{conservative_folding = false}> : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16> loc(#loc210)
        %275 = "ttir.multiply"(%130, %274) : (tensor<1x32x3072xbf16>, tensor<1x32x3072xbf16>) -> tensor<1x32x3072xbf16> loc(#loc211)
        %276 = "ttir.reshape"(%275) <{shape = [32 : i32, 3072 : i32]}> : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16> loc(#loc212)
        %277 = "ttir.reshape"(%9) <{shape = [1 : i32, 128256 : i32, 3072 : i32]}> : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc213)
        %278 = "ttir.reshape"(%277) <{shape = [128256 : i32, 3072 : i32]}> : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc214)
        %279 = "ttir.permute"(%278) <{permutation = array<i64: 1, 0>}> : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc215)
        %280 = "ttir.dot_general"(%276, %279) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<32x128256xbf16> loc(#loc216)
        %281 = "ttir.reshape"(%280) <{shape = [1 : i32, 32 : i32, 128256 : i32]}> : (tensor<32x128256xbf16>) -> tensor<1x32x128256xbf16> loc(#loc217)
        %282 = "ttir.mesh_shard"(%119) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc)
        %283 = "ttir.mesh_shard"(%126) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc)
        %284 = "ttir.mesh_shard"(%280) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<32x128256xbf16>) -> tensor<32x128256xbf16> loc(#loc)
        %285 = "ttir.mesh_shard"(%281) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x32x128256xbf16>) -> tensor<1x32x128256xbf16> loc(#loc)
        return %282, %283, %284, %285 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc20 = loc("reshape.4")
#loc21 = loc("reshape.6")
#loc22 = loc("compare.117")
#loc23 = loc("add.114")
#loc24 = loc("select.118")
#loc25 = loc("reshape.80")
#loc26 = loc("reshape.82")
#loc27 = loc("broadcast.83")
#loc28 = loc("reshape.44")
#loc29 = loc("reshape.46")
#loc30 = loc("reshape.39")
#loc31 = loc("reshape.42")
#loc32 = loc("convert.47")
#loc33 = loc("gather.48")
#loc34 = loc("reshape.49")
#loc35 = loc("convert.50")
#loc36 = loc("power.52")
#loc37 = loc("reduce.59")
#loc38 = loc("multiply.68")
#loc39 = loc("reshape.69")
#loc40 = loc("add.73")
#loc41 = loc("rsqrt.74")
#loc42 = loc("reshape.75")
#loc43 = loc("broadcast.76")
#loc44 = loc("multiply.77")
#loc45 = loc("convert.78")
#loc46 = loc("multiply.84")
#loc47 = loc("reshape.85")
#loc48 = loc("reshape.31")
#loc49 = loc("reshape.33")
#loc50 = loc("transpose.34")
#loc51 = loc("dot.86")
#loc52 = loc("reshape.88")
#loc53 = loc("transpose.89")
#loc54 = loc("reshape.14")
#loc55 = loc("reshape.19")
#loc56 = loc("convert.11")
#loc57 = loc("dot.22")
#loc58 = loc("transpose.23")
#loc59 = loc("concatenate.24")
#loc60 = loc("cosine.98")
#loc61 = loc("convert.101")
#loc62 = loc("broadcast.104")
#loc63 = loc("multiply.105")
#loc64 = loc("slice.91")
#loc65 = loc("negate.92")
#loc66 = loc("slice.90")
#loc67 = loc("concatenate.93")
#loc68 = loc("sine.25")
#loc69 = loc("convert.28")
#loc70 = loc("broadcast.95")
#loc71 = loc("multiply.96")
#loc72 = loc("add.108")
#loc73 = loc("scatter.127")
#loc74 = loc("reshape.130")
#loc75 = loc("reshape.132")
#loc76 = loc("transpose.133")
#loc77 = loc("dot.135")
#loc78 = loc("reshape.137")
#loc79 = loc("transpose.138")
#loc80 = loc("scatter.157")
#loc81 = loc("reshape.504")
#loc82 = loc("reshape.506")
#loc83 = loc("broadcast.507")
#loc84 = loc("reshape.359")
#loc85 = loc("reshape.361")
#loc86 = loc("transpose.362")
#loc87 = loc("dot.364")
#loc88 = loc("reshape.366")
#loc89 = loc("transpose.367")
#loc90 = loc("broadcast.376")
#loc91 = loc("multiply.377")
#loc92 = loc("slice.369")
#loc93 = loc("negate.370")
#loc94 = loc("slice.368")
#loc95 = loc("concatenate.371")
#loc96 = loc("broadcast.373")
#loc97 = loc("multiply.374")
#loc98 = loc("add.380")
#loc99 = loc("broadcast.354")
#loc100 = loc("reshape.355")
#loc101 = loc("transpose.356")
#loc102 = loc("dot.381")
#loc103 = loc("multiply.384")
#loc104 = loc("broadcast.325")
#loc105 = loc("and.328")
#loc106 = loc("reshape.329")
#loc107 = loc("reshape.337")
#loc108 = loc("broadcast.338")
#loc109 = loc("not.330")
#loc110 = loc("reshape.332")
#loc111 = loc("broadcast.333")
#loc112 = loc("broadcast.225")
#loc113 = loc("broadcast.227")
#loc114 = loc("subtract.228")
#loc115 = loc("compare.230")
#loc116 = loc("select.232")
#loc117 = loc("broadcast.201")
#loc118 = loc("compare.202")
#loc119 = loc("convert.203")
#loc120 = loc("multiply.233")
#loc121 = loc("reshape.235")
#loc122 = loc("slice.297")
#loc123 = loc("reshape.287")
#loc124 = loc("reshape.292")
#loc125 = loc("convert.298")
#loc126 = loc("reshape.301")
#loc127 = loc("broadcast.302")
#loc128 = loc("add.303")
#loc129 = loc("compare.306")
#loc130 = loc("select.308")
#loc131 = loc("floor.256")
#loc132 = loc("convert.257")
#loc133 = loc("clamp.260")
#loc134 = loc("compare.269")
#loc135 = loc("add.266")
#loc136 = loc("select.270")
#loc137 = loc("reshape.271")
#loc138 = loc("gather.310")
#loc139 = loc("select.334")
#loc140 = loc("select.339")
#loc141 = loc("reshape.387")
#loc142 = loc("broadcast.388")
#loc143 = loc("add.389")
#loc144 = loc("convert.390")
#loc145 = loc("reduce.396")
#loc146 = loc("broadcast.397")
#loc147 = loc("subtract.398")
#loc148 = loc("exponential.399")
#loc149 = loc("reduce.405")
#loc150 = loc("broadcast.406")
#loc151 = loc("divide.407")
#loc152 = loc("convert.408")
#loc153 = loc("broadcast.194")
#loc154 = loc("reshape.195")
#loc155 = loc("dot.409")
#loc156 = loc("transpose.411")
#loc157 = loc("reshape.413")
#loc158 = loc("reshape.183")
#loc159 = loc("reshape.185")
#loc160 = loc("transpose.186")
#loc161 = loc("dot.414")
#loc162 = loc("reshape.415")
#loc163 = loc("add.418")
#loc164 = loc("reshape.449")
#loc165 = loc("reshape.451")
#loc166 = loc("broadcast.452")
#loc167 = loc("convert.419")
#loc168 = loc("power.421")
#loc169 = loc("reduce.428")
#loc170 = loc("multiply.437")
#loc171 = loc("reshape.438")
#loc172 = loc("add.442")
#loc173 = loc("rsqrt.443")
#loc174 = loc("reshape.444")
#loc175 = loc("broadcast.445")
#loc176 = loc("multiply.446")
#loc177 = loc("convert.447")
#loc178 = loc("multiply.453")
#loc179 = loc("reshape.462")
#loc180 = loc("reshape.458")
#loc181 = loc("reshape.460")
#loc182 = loc("transpose.461")
#loc183 = loc("dot.463")
#loc184 = loc("reshape.464")
#loc185 = loc("logistic.465")
#loc186 = loc("multiply.466")
#loc187 = loc("reshape.174")
#loc188 = loc("reshape.176")
#loc189 = loc("transpose.177")
#loc190 = loc("dot.455")
#loc191 = loc("reshape.456")
#loc192 = loc("multiply.467")
#loc193 = loc("reshape.468")
#loc194 = loc("reshape.169")
#loc195 = loc("reshape.171")
#loc196 = loc("transpose.172")
#loc197 = loc("dot.469")
#loc198 = loc("reshape.470")
#loc199 = loc("add.473")
#loc200 = loc("convert.474")
#loc201 = loc("power.476")
#loc202 = loc("reduce.483")
#loc203 = loc("multiply.492")
#loc204 = loc("reshape.493")
#loc205 = loc("add.497")
#loc206 = loc("rsqrt.498")
#loc207 = loc("reshape.499")
#loc208 = loc("broadcast.500")
#loc209 = loc("multiply.501")
#loc210 = loc("convert.502")
#loc211 = loc("multiply.508")
#loc212 = loc("reshape.512")
#loc213 = loc("reshape.160")
#loc214 = loc("reshape.162")
#loc215 = loc("transpose.163")
#loc216 = loc("dot.513")
#loc217 = loc("reshape.514")
------------------ END OF MLIR MODULE ------------------
2026-01-02 18:37:36.859 (   7.918s) [        CBC3A000]      module_builder.cc:785   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2026-01-02 18:37:36.859 (   7.918s) [        CBC3A000]      module_builder.cc:799   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2026-01-02 18:37:36.859 (   7.918s) [        CBC3A000]      module_builder.cc:809   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2026-01-02 18:37:37.099 (   8.157s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module ttnn:
#dram = #ttnn.buffer_type<dram>
#loc = loc(unknown)
#loc23 = loc("p0.3")
#loc24 = loc("p1.13")
#loc25 = loc("p2.30")
#loc26 = loc("p3.38")
#loc27 = loc("p4.43")
#loc28 = loc("p5.79")
#loc29 = loc("p6.121")
#loc30 = loc("p7.129")
#loc31 = loc("p8.151")
#loc32 = loc("p9.159")
#loc33 = loc("p10.168")
#loc34 = loc("p11.173")
#loc35 = loc("p12.182")
#loc36 = loc("p13.286")
#loc37 = loc("p14.321")
#loc38 = loc("p15.358")
#loc39 = loc("p16.448")
#loc40 = loc("p17.457")
#loc41 = loc("p18.503")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073168640, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073177216, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout11 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout12 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout13 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3072xbf16, #system_memory>>
#ttnn_layout14 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout15 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3072xbf16, #dram>, <interleaved>>
#ttnn_layout16 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout17 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x64xf32, #system_memory>>
#ttnn_layout18 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout19 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x64xf32, #dram>, <interleaved>>
#ttnn_layout20 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout21 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout22 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x1xui32, #dram>, <interleaved>>
#ttnn_layout23 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout24 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout25 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4x1x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout26 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128256x3072xbf16, #system_memory>>
#ttnn_layout27 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128256x3072xbf16, #dram>, <interleaved>>
#ttnn_layout28 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x32xsi32, #dram>, <interleaved>>
#ttnn_layout29 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout30 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32xsi32, #dram>, <interleaved>>
#ttnn_layout31 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout32 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout33 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout34 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout35 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout36 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1xbf16, #dram>, <interleaved>>
#ttnn_layout37 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #system_memory>>
#ttnn_layout38 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x128256xbf16, #system_memory>>
#ttnn_layout39 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<32x128256xbf16, #system_memory>>
#ttnn_layout40 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout41 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout42 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout43 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout44 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x16x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout45 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x32x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout46 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout47 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout48 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout49 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32xui32, #dram>, <interleaved>>
#ttnn_layout50 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout51 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout52 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout53 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout54 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout55 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout56 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x32x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout57 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout58 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout59 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout60 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout61 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout62 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout63 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout64 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout65 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout66 = #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout67 = #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout68 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout69 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout70 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<32x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout71 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x32xbf16, #dram>, <interleaved>>
#ttnn_layout72 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<128x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout73 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<128x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout74 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout75 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout76 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout77 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout78 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout79 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #dram>, <interleaved>>
#ttnn_layout80 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #system_memory>>
#ttnn_layout81 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x128256xbf16, #dram>, <interleaved>>
#ttnn_layout82 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<32x128256xbf16, #dram>, <interleaved>>
module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]> loc(#loc)
      func.func private @main_const_eval_0() -> (tensor<1x1x1x1xbf16, #ttnn_layout>, tensor<1x1x32x128xsi32, #ttnn_layout1>, tensor<1x1x32x128xbf16, #ttnn_layout2>, tensor<1x1x32x32xbf16, #ttnn_layout>, tensor<1x1x32x128xbf16, #ttnn_layout2>) attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<"0x000000000100000002000000030000000400000005000000060000000700000008000000090000000A0000000B0000000C0000000D0000000E0000000F000000100000001100000012000000130000001400000015000000160000001700000018000000190000001A0000001B0000001C0000001D0000001E0000001F000000200000002100000022000000230000002400000025000000260000002700000028000000290000002A0000002B0000002C0000002D0000002E0000002F000000300000003100000032000000330000003400000035000000360000003700000038000000390000003A0000003B0000003C0000003D0000003E0000003F000000400000004100000042000000430000004400000045000000460000004700000048000000490000004A0000004B0000004C0000004D0000004E0000004F000000500000005100000052000000530000005400000055000000560000005700000058000000590000005A0000005B0000005C0000005D0000005E0000005F000000600000006100000062000000630000006400000065000000660000006700000068000000690000006A0000006B0000006C0000006D0000006E0000006F000000700000007100000072000000730000007400000075000000760000007700000078000000790000007A0000007B0000007C0000007D0000007E0000007F000000"> : tensor<128xsi32>}> : (!ttnn.device) -> tensor<128xsi32, #ttnn_layout3> loc(#loc)
        %2 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xsi32>}> : (!ttnn.device) -> tensor<32xsi32, #ttnn_layout4> loc(#loc)
        %3 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout5> loc(#loc)
        %4 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout5> loc(#loc)
        %5 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = 1 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn_layout6> loc(#loc)
        %6 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout5>) -> tensor<1x1x1x1xbf16, #ttnn_layout> loc(#loc)
        %7 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout5>) -> tensor<1x1x1x1xbf16, #ttnn_layout> loc(#loc)
        %8 = "ttnn.reshape"(%4) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout5>) -> tensor<1x1xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<bf16, #ttnn_layout5>) -> () loc(#loc)
        %9 = "ttnn.reshape"(%3) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout5>) -> tensor<1x1xbf16, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<bf16, #ttnn_layout5>) -> () loc(#loc)
        %10 = "ttnn.reshape"(%5) <{shape = [1 : i32, 1 : i32]}> : (tensor<si32, #ttnn_layout6>) -> tensor<1x1xsi32, #ttnn_layout8> loc(#loc)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<si32, #ttnn_layout6>) -> () loc(#loc)
        %11 = "ttnn.reshape"(%1) <{shape = [1 : i32, 128 : i32]}> : (tensor<128xsi32, #ttnn_layout3>) -> tensor<1x128xsi32, #ttnn_layout9> loc(#loc1)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<128xsi32, #ttnn_layout3>) -> () loc(#loc1)
        %12 = "ttnn.repeat"(%11) <{repeat_dims = #ttnn.shape<32x1>}> : (tensor<1x128xsi32, #ttnn_layout9>) -> tensor<32x128xsi32, #ttnn_layout9> loc(#loc1)
        %13 = "ttnn.reshape"(%2) <{shape = [32 : i32, 1 : i32]}> : (tensor<32xsi32, #ttnn_layout4>) -> tensor<32x1xsi32, #ttnn_layout8> loc(#loc2)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<32xsi32, #ttnn_layout4>) -> () loc(#loc2)
        %14 = "ttnn.neg"(%13) : (tensor<32x1xsi32, #ttnn_layout8>) -> tensor<32x1xsi32, #ttnn_layout8> loc(#loc133)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<32x1xsi32, #ttnn_layout8>) -> () loc(#loc133)
        %15 = "ttnn.add"(%11, %14) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<1x128xsi32, #ttnn_layout9>, tensor<32x1xsi32, #ttnn_layout8>) -> tensor<32x128xsi32, #ttnn_layout9> loc(#loc3)
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<32x1xsi32, #ttnn_layout8>) -> () loc(#loc3)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x128xsi32, #ttnn_layout9>) -> () loc(#loc3)
        %16 = "ttnn.ge"(%15, %10) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<32x128xsi32, #ttnn_layout9>, tensor<1x1xsi32, #ttnn_layout8>) -> tensor<32x128xbf16, #ttnn_layout10> loc(#loc4)
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<32x128xsi32, #ttnn_layout9>) -> () loc(#loc4)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<1x1xsi32, #ttnn_layout8>) -> () loc(#loc4)
        %17 = "ttnn.repeat"(%9) <{repeat_dims = #ttnn.shape<32x128>}> : (tensor<1x1xbf16, #ttnn_layout7>) -> tensor<32x128xbf16, #ttnn_layout10> loc(#loc5)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x1xbf16, #ttnn_layout7>) -> () loc(#loc5)
        %18 = "ttnn.repeat"(%8) <{repeat_dims = #ttnn.shape<32x128>}> : (tensor<1x1xbf16, #ttnn_layout7>) -> tensor<32x128xbf16, #ttnn_layout10> loc(#loc5)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x1xbf16, #ttnn_layout7>) -> () loc(#loc5)
        %19 = "ttnn.where"(%16, %17, %18) : (tensor<32x128xbf16, #ttnn_layout10>, tensor<32x128xbf16, #ttnn_layout10>, tensor<32x128xbf16, #ttnn_layout10>) -> tensor<32x128xbf16, #ttnn_layout10> loc(#loc5)
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<32x128xbf16, #ttnn_layout10>) -> () loc(#loc5)
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<32x128xbf16, #ttnn_layout10>) -> () loc(#loc5)
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<32x128xbf16, #ttnn_layout10>) -> () loc(#loc5)
        %20 = "ttnn.reshape"(%12) <{shape = [1 : i32, 1 : i32, 32 : i32, 128 : i32]}> : (tensor<32x128xsi32, #ttnn_layout9>) -> tensor<1x1x32x128xsi32, #ttnn_layout1> loc(#loc156)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<32x128xsi32, #ttnn_layout9>) -> () loc(#loc156)
        %21 = "ttnn.reshape"(%19) <{shape = [1 : i32, 1 : i32, 32 : i32, 128 : i32]}> : (tensor<32x128xbf16, #ttnn_layout10>) -> tensor<1x1x32x128xbf16, #ttnn_layout2> loc(#loc135)
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<32x128xbf16, #ttnn_layout10>) -> () loc(#loc135)
        %22 = "ttnn.repeat"(%6) <{repeat_dims = #ttnn.shape<1x1x32x32>}> : (tensor<1x1x1x1xbf16, #ttnn_layout>) -> tensor<1x1x32x32xbf16, #ttnn_layout> loc(#loc7)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout>) -> () loc(#loc7)
        %23 = "ttnn.repeat"(%7) <{repeat_dims = #ttnn.shape<1x1x32x128>}> : (tensor<1x1x1x1xbf16, #ttnn_layout>) -> tensor<1x1x32x128xbf16, #ttnn_layout2> loc(#loc8)
        return %7, %20, %21, %22, %23 : tensor<1x1x1x1xbf16, #ttnn_layout>, tensor<1x1x32x128xsi32, #ttnn_layout1>, tensor<1x1x32x128xbf16, #ttnn_layout2>, tensor<1x1x32x32xbf16, #ttnn_layout>, tensor<1x1x32x128xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_1() -> tensor<1x1xf32, #ttnn_layout11> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 9.99999974E-6 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn_layout12> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout12>) -> tensor<1x1xf32, #ttnn_layout11> loc(#loc175)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn_layout12>) -> () loc(#loc175)
        return %2 : tensor<1x1xf32, #ttnn_layout11> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_2() -> tensor<1x1x1x1xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.0883789062 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout5> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout5>) -> tensor<1x1x1x1xbf16, #ttnn_layout> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<bf16, #ttnn_layout5>) -> () loc(#loc)
        return %2 : tensor<1x1x1x1xbf16, #ttnn_layout> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_3(%arg0: tensor<3072xbf16, #ttnn_layout13> loc(unknown)) -> tensor<1x3072xbf16, #ttnn_layout14> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<3072xbf16, #ttnn_layout13>, !ttnn.device) -> tensor<3072xbf16, #ttnn_layout15> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<3072xbf16, #ttnn_layout15>) -> tensor<3072xbf16, #ttnn_layout16> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072xbf16, #ttnn_layout15>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn_layout16>) -> tensor<1x3072xbf16, #ttnn_layout14> loc(#loc137)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<3072xbf16, #ttnn_layout16>) -> () loc(#loc137)
        return %3 : tensor<1x3072xbf16, #ttnn_layout14> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_4(%arg0: tensor<64xf32, #ttnn_layout17> loc(unknown)) -> tensor<1x64x1xf32, #ttnn_layout18> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<64xf32, #ttnn_layout17>, !ttnn.device) -> tensor<64xf32, #ttnn_layout19> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<64xf32, #ttnn_layout19>) -> tensor<64xf32, #ttnn_layout20> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<64xf32, #ttnn_layout19>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32, #ttnn_layout20>) -> tensor<1x64x1xf32, #ttnn_layout18> loc(#loc11)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<64xf32, #ttnn_layout20>) -> () loc(#loc11)
        return %3 : tensor<1x64x1xf32, #ttnn_layout18> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_5() -> tensor<1x1x1x128xbf16, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<"0x803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"> : tensor<128xbf16>}> : (!ttnn.device) -> tensor<128xbf16, #ttnn_layout21> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16, #ttnn_layout21>) -> tensor<1x1x1x128xbf16, #ttnn_layout2> loc(#loc138)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<128xbf16, #ttnn_layout21>) -> () loc(#loc138)
        return %2 : tensor<1x1x1x128xbf16, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_6() -> tensor<128x1xui32, #ttnn_layout22> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>}> : (!ttnn.device) -> tensor<128xf32, #ttnn_layout23> loc(#loc)
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = 32 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn_layout6> loc(#loc)
        %3 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = 0 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn_layout6> loc(#loc)
        %4 = "ttnn.reshape"(%2) <{shape = [1 : i32]}> : (tensor<si32, #ttnn_layout6>) -> tensor<1xsi32, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<si32, #ttnn_layout6>) -> () loc(#loc)
        %5 = "ttnn.reshape"(%3) <{shape = [1 : i32]}> : (tensor<si32, #ttnn_layout6>) -> tensor<1xsi32, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<si32, #ttnn_layout6>) -> () loc(#loc)
        %6 = "ttnn.floor"(%1) : (tensor<128xf32, #ttnn_layout23>) -> tensor<128xf32, #ttnn_layout23> loc(#loc13)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<128xf32, #ttnn_layout23>) -> () loc(#loc13)
        %7 = "ttnn.typecast"(%6) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<128xf32, #ttnn_layout23>) -> tensor<128xsi32, #ttnn_layout3> loc(#loc14)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<128xf32, #ttnn_layout23>) -> () loc(#loc14)
        %8 = "ttnn.clamp_scalar"(%7) <{max = 3.100000e+01 : f32, min = 0.000000e+00 : f32}> : (tensor<128xsi32, #ttnn_layout3>) -> tensor<128xsi32, #ttnn_layout3> loc(#loc15)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<128xsi32, #ttnn_layout3>) -> () loc(#loc15)
        %9 = "ttnn.lt"(%8, %5) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<128xsi32, #ttnn_layout3>, tensor<1xsi32, #ttnn_layout4>) -> tensor<128xbf16, #ttnn_layout21> loc(#loc16)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1xsi32, #ttnn_layout4>) -> () loc(#loc16)
        %10 = "ttnn.add"(%8, %4) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<128xsi32, #ttnn_layout3>, tensor<1xsi32, #ttnn_layout4>) -> tensor<128xsi32, #ttnn_layout3> loc(#loc17)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1xsi32, #ttnn_layout4>) -> () loc(#loc17)
        %11 = "ttnn.typecast"(%9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<128xbf16, #ttnn_layout21>) -> tensor<128xf32, #ttnn_layout23> loc(#loc139)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<128xbf16, #ttnn_layout21>) -> () loc(#loc139)
        %12 = "ttnn.typecast"(%10) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<128xsi32, #ttnn_layout3>) -> tensor<128xf32, #ttnn_layout23> loc(#loc139)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<128xsi32, #ttnn_layout3>) -> () loc(#loc139)
        %13 = "ttnn.typecast"(%8) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<128xsi32, #ttnn_layout3>) -> tensor<128xf32, #ttnn_layout23> loc(#loc139)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<128xsi32, #ttnn_layout3>) -> () loc(#loc139)
        %14 = "ttnn.where"(%11, %12, %13) : (tensor<128xf32, #ttnn_layout23>, tensor<128xf32, #ttnn_layout23>, tensor<128xf32, #ttnn_layout23>) -> tensor<128xf32, #ttnn_layout23> loc(#loc18)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<128xf32, #ttnn_layout23>) -> () loc(#loc18)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<128xf32, #ttnn_layout23>) -> () loc(#loc18)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<128xf32, #ttnn_layout23>) -> () loc(#loc18)
        %15 = "ttnn.typecast"(%14) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<128xf32, #ttnn_layout23>) -> tensor<128xsi32, #ttnn_layout3> loc(#loc139)
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<128xf32, #ttnn_layout23>) -> () loc(#loc139)
        %16 = "ttnn.reshape"(%15) <{shape = [128 : i32, 1 : i32]}> : (tensor<128xsi32, #ttnn_layout3>) -> tensor<128x1xsi32, #ttnn_layout24> loc(#loc19)
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<128xsi32, #ttnn_layout3>) -> () loc(#loc19)
        %17 = "ttnn.typecast"(%16) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<128x1xsi32, #ttnn_layout24>) -> tensor<128x1xui32, #ttnn_layout25> loc(#loc140)
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<128x1xsi32, #ttnn_layout24>) -> () loc(#loc140)
        %18 = "ttnn.to_layout"(%17) <{layout = #ttnn.layout<row_major>}> : (tensor<128x1xui32, #ttnn_layout25>) -> tensor<128x1xui32, #ttnn_layout22> loc(#loc140)
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<128x1xui32, #ttnn_layout25>) -> () loc(#loc140)
        return %18 : tensor<128x1xui32, #ttnn_layout22> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_7() -> tensor<1x1xf32, #ttnn_layout11> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 3.25520843E-4 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<f32, #ttnn_layout12> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32]}> : (tensor<f32, #ttnn_layout12>) -> tensor<1x1xf32, #ttnn_layout11> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<f32, #ttnn_layout12>) -> () loc(#loc)
        return %2 : tensor<1x1xf32, #ttnn_layout11> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_8(%arg0: tensor<3072xbf16, #ttnn_layout13> loc(unknown)) -> tensor<1x3072xbf16, #ttnn_layout14> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<3072xbf16, #ttnn_layout13>, !ttnn.device) -> tensor<3072xbf16, #ttnn_layout15> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<3072xbf16, #ttnn_layout15>) -> tensor<3072xbf16, #ttnn_layout16> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072xbf16, #ttnn_layout15>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn_layout16>) -> tensor<1x3072xbf16, #ttnn_layout14> loc(#loc141)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<3072xbf16, #ttnn_layout16>) -> () loc(#loc141)
        return %3 : tensor<1x3072xbf16, #ttnn_layout14> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_9(%arg0: tensor<3072xbf16, #ttnn_layout13> loc(unknown)) -> tensor<1x3072xbf16, #ttnn_layout14> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<3072xbf16, #ttnn_layout13>, !ttnn.device) -> tensor<3072xbf16, #ttnn_layout15> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<3072xbf16, #ttnn_layout15>) -> tensor<3072xbf16, #ttnn_layout16> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072xbf16, #ttnn_layout15>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn_layout16>) -> tensor<1x3072xbf16, #ttnn_layout14> loc(#loc142)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<3072xbf16, #ttnn_layout16>) -> () loc(#loc142)
        return %3 : tensor<1x3072xbf16, #ttnn_layout14> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_10(%arg0: tensor<128256x3072xbf16, #ttnn_layout26> loc(unknown)) -> tensor<128256x3072xbf16, #ttnn_layout27> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc143)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<128256x3072xbf16, #ttnn_layout26>, !ttnn.device) -> tensor<128256x3072xbf16, #ttnn_layout27> loc(#loc143)
        return %1 : tensor<128256x3072xbf16, #ttnn_layout27> loc(#loc)
      } loc(#loc)
      func.func @main(%arg0: tensor<32xsi32, #ttnn_layout28> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32, #ttnn_layout17> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16, #ttnn_layout29> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.30"), %arg3: tensor<1x32xsi32, #ttnn_layout30> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p3.38"), %arg4: tensor<128256x3072xbf16, #ttnn_layout26> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p4.43"), %arg5: tensor<3072xbf16, #ttnn_layout13> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p5.79"), %arg6: tensor<1x8x128x128xbf16, #ttnn_layout31> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p6.121"), %arg7: tensor<1024x3072xbf16, #ttnn_layout29> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p7.129"), %arg8: tensor<1x8x128x128xbf16, #ttnn_layout31> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_4"} loc("p8.151"), %arg9: tensor<128256x3072xbf16, #ttnn_layout32> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"} loc("p9.159"), %arg10: tensor<3072x8192xbf16, #ttnn_layout33> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p10.168"), %arg11: tensor<8192x3072xbf16, #ttnn_layout34> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p11.173"), %arg12: tensor<3072x3072xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p12.182"), %arg13: tensor<1x32xsi32, #ttnn_layout30> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p13.286"), %arg14: tensor<bf16, #ttnn_layout36> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p14.321"), %arg15: tensor<3072x3072xbf16, #ttnn_layout35> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p15.358"), %arg16: tensor<3072xbf16, #ttnn_layout13> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p16.448"), %arg17: tensor<8192x3072xbf16, #ttnn_layout34> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p17.457"), %arg18: tensor<3072xbf16, #ttnn_layout13> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"} loc("p18.503")) -> (tensor<1x8x128x128xbf16, #ttnn_layout37> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn_layout37> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<32x128256xbf16, #ttnn_layout38> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x32x128256xbf16, #ttnn_layout39> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0:5 = ttcore.load_cached(@main_const_eval_0, []) : () -> (tensor<1x1x1x1xbf16, #ttnn_layout>, tensor<1x1x32x128xsi32, #ttnn_layout1>, tensor<1x1x32x128xbf16, #ttnn_layout2>, tensor<1x1x32x32xbf16, #ttnn_layout>, tensor<1x1x32x128xbf16, #ttnn_layout2>) loc(#loc)
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x1xf32, #ttnn_layout11> loc(#loc)
        %2 = ttcore.load_cached(@main_const_eval_2, []) : () -> tensor<1x1x1x1xbf16, #ttnn_layout> loc(#loc)
        %3 = ttcore.load_cached(@main_const_eval_3, [%arg18]) : (tensor<3072xbf16, #ttnn_layout13>) -> tensor<1x3072xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%arg18) <{force = false}> : (tensor<3072xbf16, #ttnn_layout13>) -> () loc(#loc)
        %4 = ttcore.load_cached(@main_const_eval_4, [%arg1]) : (tensor<64xf32, #ttnn_layout17>) -> tensor<1x64x1xf32, #ttnn_layout18> loc(#loc)
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<64xf32, #ttnn_layout17>) -> () loc(#loc)
        %5 = ttcore.load_cached(@main_const_eval_5, []) : () -> tensor<1x1x1x128xbf16, #ttnn_layout2> loc(#loc)
        %6 = ttcore.load_cached(@main_const_eval_6, []) : () -> tensor<128x1xui32, #ttnn_layout22> loc(#loc)
        %7 = ttcore.load_cached(@main_const_eval_7, []) : () -> tensor<1x1xf32, #ttnn_layout11> loc(#loc)
        %8 = ttcore.load_cached(@main_const_eval_8, [%arg16]) : (tensor<3072xbf16, #ttnn_layout13>) -> tensor<1x3072xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%arg16) <{force = false}> : (tensor<3072xbf16, #ttnn_layout13>) -> () loc(#loc)
        %9 = ttcore.load_cached(@main_const_eval_9, [%arg5]) : (tensor<3072xbf16, #ttnn_layout13>) -> tensor<1x3072xbf16, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%arg5) <{force = false}> : (tensor<3072xbf16, #ttnn_layout13>) -> () loc(#loc)
        %10 = ttcore.load_cached(@main_const_eval_10, [%arg4]) : (tensor<128256x3072xbf16, #ttnn_layout26>) -> tensor<128256x3072xbf16, #ttnn_layout27> loc(#loc)
        "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout26>) -> () loc(#loc)
        %11 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %12 = "ttnn.mesh_shard"(%arg15, %11) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn_layout35>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn_layout40> loc(#loc)
        "ttnn.deallocate"(%arg15) <{force = false}> : (tensor<3072x3072xbf16, #ttnn_layout35>) -> () loc(#loc)
        %13 = "ttnn.mesh_shard"(%arg17, %11) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn_layout34>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn_layout41> loc(#loc)
        "ttnn.deallocate"(%arg17) <{force = false}> : (tensor<8192x3072xbf16, #ttnn_layout34>) -> () loc(#loc)
        %14 = "ttnn.mesh_shard"(%arg10, %11) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn_layout33>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn_layout42> loc(#loc)
        "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<3072x8192xbf16, #ttnn_layout33>) -> () loc(#loc)
        %15 = "ttnn.mesh_shard"(%arg11, %11) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn_layout34>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn_layout41> loc(#loc)
        "ttnn.deallocate"(%arg11) <{force = false}> : (tensor<8192x3072xbf16, #ttnn_layout34>) -> () loc(#loc)
        %16 = "ttnn.mesh_shard"(%arg2, %11) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn_layout29>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn_layout43> loc(#loc)
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<1024x3072xbf16, #ttnn_layout29>) -> () loc(#loc)
        %17 = "ttnn.mesh_shard"(%arg7, %11) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn_layout29>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn_layout43> loc(#loc)
        "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<1024x3072xbf16, #ttnn_layout29>) -> () loc(#loc)
        %18 = "ttnn.permute"(%16) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16, #ttnn_layout43>) -> tensor<3072x512xbf16, #ttnn_layout44> loc(#loc42)
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<512x3072xbf16, #ttnn_layout43>) -> () loc(#loc42)
        %19 = "ttnn.permute"(%17) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16, #ttnn_layout43>) -> tensor<3072x512xbf16, #ttnn_layout44> loc(#loc43)
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<512x3072xbf16, #ttnn_layout43>) -> () loc(#loc43)
        %20 = "ttnn.concat"(%18, %19) <{dim = 1 : si32}> : (tensor<3072x512xbf16, #ttnn_layout44>, tensor<3072x512xbf16, #ttnn_layout44>) -> tensor<3072x1024xbf16, #ttnn_layout45> loc(#loc43)
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<3072x512xbf16, #ttnn_layout44>) -> () loc(#loc43)
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<3072x512xbf16, #ttnn_layout44>) -> () loc(#loc43)
        %21 = "ttnn.mesh_shard"(%arg12, %11) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn_layout35>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn_layout46> loc(#loc)
        "ttnn.deallocate"(%arg12) <{force = false}> : (tensor<3072x3072xbf16, #ttnn_layout35>) -> () loc(#loc)
        %22 = "ttnn.mesh_shard"(%arg6, %11) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn_layout31>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn_layout47> loc(#loc)
        "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn_layout31>) -> () loc(#loc)
        %23 = "ttnn.mesh_shard"(%arg8, %11) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn_layout31>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn_layout47> loc(#loc)
        "ttnn.deallocate"(%arg8) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn_layout31>) -> () loc(#loc)
        %24 = "ttnn.to_layout"(%arg3) <{layout = #ttnn.layout<tile>}> : (tensor<1x32xsi32, #ttnn_layout30>) -> tensor<1x32xsi32, #ttnn_layout8> loc(#loc44)
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<1x32xsi32, #ttnn_layout30>) -> () loc(#loc44)
        %25 = "ttnn.typecast"(%24) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x32xsi32, #ttnn_layout8>) -> tensor<1x32xui32, #ttnn_layout48> loc(#loc45)
        "ttnn.deallocate"(%24) <{force = false}> : (tensor<1x32xsi32, #ttnn_layout8>) -> () loc(#loc45)
        %26 = "ttnn.to_layout"(%25) <{layout = #ttnn.layout<row_major>}> : (tensor<1x32xui32, #ttnn_layout48>) -> tensor<1x32xui32, #ttnn_layout49> loc(#loc143)
        "ttnn.deallocate"(%25) <{force = false}> : (tensor<1x32xui32, #ttnn_layout48>) -> () loc(#loc143)
        %27 = "ttnn.embedding"(%26, %10) : (tensor<1x32xui32, #ttnn_layout49>, tensor<128256x3072xbf16, #ttnn_layout27>) -> tensor<1x32x3072xbf16, #ttnn_layout50> loc(#loc22)
        "ttnn.deallocate"(%26) <{force = false}> : (tensor<1x32xui32, #ttnn_layout49>) -> () loc(#loc22)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout27>) -> () loc(#loc22)
        %28 = "ttnn.typecast"(%27) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x32x3072xbf16, #ttnn_layout50>) -> tensor<1x32x3072xf32, #ttnn_layout51> loc(#loc46)
        %29 = "ttnn.pow_scalar"(%28) <{rhs = 2.000000e+00 : f32}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> tensor<1x32x3072xf32, #ttnn_layout51> loc(#loc47)
        %30 = "ttnn.sum"(%29) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> tensor<1x32xf32, #ttnn_layout11> loc(#loc48)
        "ttnn.deallocate"(%29) <{force = false}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> () loc(#loc48)
        %31 = "ttnn.reshape"(%30) <{shape = [32 : i32, 1 : i32]}> : (tensor<1x32xf32, #ttnn_layout11>) -> tensor<32x1xf32, #ttnn_layout11> loc(#loc179)
        "ttnn.deallocate"(%30) <{force = false}> : (tensor<1x32xf32, #ttnn_layout11>) -> () loc(#loc179)
        %32 = "ttnn.multiply"(%31, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<32x1xf32, #ttnn_layout11>, tensor<1x1xf32, #ttnn_layout11>) -> tensor<32x1xf32, #ttnn_layout11> loc(#loc49)
        "ttnn.deallocate"(%31) <{force = false}> : (tensor<32x1xf32, #ttnn_layout11>) -> () loc(#loc49)
        %33 = "ttnn.add"(%32, %1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<32x1xf32, #ttnn_layout11>, tensor<1x1xf32, #ttnn_layout11>) -> tensor<32x1xf32, #ttnn_layout11> loc(#loc50)
        "ttnn.deallocate"(%32) <{force = false}> : (tensor<32x1xf32, #ttnn_layout11>) -> () loc(#loc50)
        %34 = "ttnn.rsqrt"(%33) : (tensor<32x1xf32, #ttnn_layout11>) -> tensor<32x1xf32, #ttnn_layout11> loc(#loc51)
        "ttnn.deallocate"(%33) <{force = false}> : (tensor<32x1xf32, #ttnn_layout11>) -> () loc(#loc51)
        %35 = "ttnn.reshape"(%28) <{shape = [32 : i32, 3072 : i32]}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> tensor<32x3072xf32, #ttnn_layout52> loc(#loc167)
        "ttnn.deallocate"(%28) <{force = false}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> () loc(#loc167)
        %36 = "ttnn.multiply"(%35, %34) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<32x3072xf32, #ttnn_layout52>, tensor<32x1xf32, #ttnn_layout11>) -> tensor<32x3072xf32, #ttnn_layout52> loc(#loc52)
        "ttnn.deallocate"(%35) <{force = false}> : (tensor<32x3072xf32, #ttnn_layout52>) -> () loc(#loc52)
        "ttnn.deallocate"(%34) <{force = false}> : (tensor<32x1xf32, #ttnn_layout11>) -> () loc(#loc52)
        %37 = "ttnn.typecast"(%36) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<32x3072xf32, #ttnn_layout52>) -> tensor<32x3072xbf16, #ttnn_layout14> loc(#loc53)
        "ttnn.deallocate"(%36) <{force = false}> : (tensor<32x3072xf32, #ttnn_layout52>) -> () loc(#loc53)
        %38 = "ttnn.multiply"(%9, %37) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn_layout14>, tensor<32x3072xbf16, #ttnn_layout14>) -> tensor<32x3072xbf16, #ttnn_layout14> loc(#loc54)
        "ttnn.deallocate"(%37) <{force = false}> : (tensor<32x3072xbf16, #ttnn_layout14>) -> () loc(#loc54)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout14>) -> () loc(#loc54)
        %39 = "ttnn.matmul"(%38, %12) <{transpose_a = false, transpose_b = true}> : (tensor<32x3072xbf16, #ttnn_layout14>, tensor<1536x3072xbf16, #ttnn_layout40>) -> tensor<32x1536xbf16, #ttnn_layout53> loc(#loc55)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<1536x3072xbf16, #ttnn_layout40>) -> () loc(#loc55)
        %40 = "ttnn.matmul"(%38, %20) <{transpose_a = false, transpose_b = false}> : (tensor<32x3072xbf16, #ttnn_layout14>, tensor<3072x1024xbf16, #ttnn_layout45>) -> tensor<32x1024xbf16, #ttnn_layout54> loc(#loc56)
        "ttnn.deallocate"(%38) <{force = false}> : (tensor<32x3072xbf16, #ttnn_layout14>) -> () loc(#loc56)
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<3072x1024xbf16, #ttnn_layout45>) -> () loc(#loc56)
        %41 = "ttnn.reshape"(%39) <{shape = [1 : i32, 32 : i32, 1536 : i32]}> : (tensor<32x1536xbf16, #ttnn_layout53>) -> tensor<1x32x1536xbf16, #ttnn_layout55> loc(#loc56)
        "ttnn.deallocate"(%39) <{force = false}> : (tensor<32x1536xbf16, #ttnn_layout53>) -> () loc(#loc56)
        %42 = "ttnn.reshape"(%40) <{shape = [1 : i32, 32 : i32, 1024 : i32]}> : (tensor<32x1024xbf16, #ttnn_layout54>) -> tensor<1x32x1024xbf16, #ttnn_layout56> loc(#loc56)
        "ttnn.deallocate"(%40) <{force = false}> : (tensor<32x1024xbf16, #ttnn_layout54>) -> () loc(#loc56)
        %query, %key, %value = "ttnn.split_query_key_value_and_split_heads"(%41, %42) <{num_heads = 12 : ui32, num_kv_heads = 4 : ui32, transpose_key = false}> : (tensor<1x32x1536xbf16, #ttnn_layout55>, tensor<1x32x1024xbf16, #ttnn_layout56>) -> (tensor<1x12x32x128xbf16, #ttnn_layout57>, tensor<1x4x32x128xbf16, #ttnn_layout58>, tensor<1x4x32x128xbf16, #ttnn_layout58>) loc(#loc56)
        "ttnn.deallocate"(%42) <{force = false}> : (tensor<1x32x1024xbf16, #ttnn_layout56>) -> () loc(#loc56)
        "ttnn.deallocate"(%41) <{force = false}> : (tensor<1x32x1536xbf16, #ttnn_layout55>) -> () loc(#loc56)
        %43 = "ttnn.to_layout"(%arg0) <{layout = #ttnn.layout<tile>}> : (tensor<32xsi32, #ttnn_layout28>) -> tensor<32xsi32, #ttnn_layout4> loc(#loc57)
        %44 = "ttnn.typecast"(%43) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<32xsi32, #ttnn_layout4>) -> tensor<32xf32, #ttnn_layout59> loc(#loc58)
        "ttnn.deallocate"(%43) <{force = false}> : (tensor<32xsi32, #ttnn_layout4>) -> () loc(#loc58)
        %45 = "ttnn.reshape"(%44) <{shape = [1 : i32, 1 : i32, 32 : i32]}> : (tensor<32xf32, #ttnn_layout59>) -> tensor<1x1x32xf32, #ttnn_layout60> loc(#loc58)
        "ttnn.deallocate"(%44) <{force = false}> : (tensor<32xf32, #ttnn_layout59>) -> () loc(#loc58)
        %46 = "ttnn.matmul"(%4, %45) <{transpose_a = false, transpose_b = false}> : (tensor<1x64x1xf32, #ttnn_layout18>, tensor<1x1x32xf32, #ttnn_layout60>) -> tensor<1x64x32xf32, #ttnn_layout18> loc(#loc59)
        "ttnn.deallocate"(%45) <{force = false}> : (tensor<1x1x32xf32, #ttnn_layout60>) -> () loc(#loc59)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1x64x1xf32, #ttnn_layout18>) -> () loc(#loc59)
        %47 = "ttnn.permute"(%46) <{permutation = array<i64: 0, 2, 1>}> : (tensor<1x64x32xf32, #ttnn_layout18>) -> tensor<1x32x64xf32, #ttnn_layout61> loc(#loc60)
        "ttnn.deallocate"(%46) <{force = false}> : (tensor<1x64x32xf32, #ttnn_layout18>) -> () loc(#loc60)
        %48 = "ttnn.reshape"(%47) <{shape = [1 : i32, 1 : i32, 32 : i32, 64 : i32]}> : (tensor<1x32x64xf32, #ttnn_layout61>) -> tensor<1x1x32x64xf32, #ttnn_layout62> loc(#loc61)
        %49 = "ttnn.reshape"(%47) <{shape = [1 : i32, 1 : i32, 32 : i32, 64 : i32]}> : (tensor<1x32x64xf32, #ttnn_layout61>) -> tensor<1x1x32x64xf32, #ttnn_layout62> loc(#loc61)
        "ttnn.deallocate"(%47) <{force = false}> : (tensor<1x32x64xf32, #ttnn_layout61>) -> () loc(#loc61)
        %50 = "ttnn.concat"(%48, %49) <{dim = 3 : si32}> : (tensor<1x1x32x64xf32, #ttnn_layout62>, tensor<1x1x32x64xf32, #ttnn_layout62>) -> tensor<1x1x32x128xf32, #ttnn_layout63> loc(#loc61)
        "ttnn.deallocate"(%49) <{force = false}> : (tensor<1x1x32x64xf32, #ttnn_layout62>) -> () loc(#loc61)
        "ttnn.deallocate"(%48) <{force = false}> : (tensor<1x1x32x64xf32, #ttnn_layout62>) -> () loc(#loc61)
        %51 = "ttnn.cos"(%50) : (tensor<1x1x32x128xf32, #ttnn_layout63>) -> tensor<1x1x32x128xf32, #ttnn_layout63> loc(#loc62)
        %52 = "ttnn.typecast"(%51) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x32x128xf32, #ttnn_layout63>) -> tensor<1x1x32x128xbf16, #ttnn_layout2> loc(#loc63)
        "ttnn.deallocate"(%51) <{force = false}> : (tensor<1x1x32x128xf32, #ttnn_layout63>) -> () loc(#loc63)
        %53 = "ttnn.multiply"(%key, %52) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x32x128xbf16, #ttnn_layout58>, tensor<1x1x32x128xbf16, #ttnn_layout2>) -> tensor<1x4x32x128xbf16, #ttnn_layout58> loc(#loc64)
        %54 = "ttnn.slice_static"(%key) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 32 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x32x128xbf16, #ttnn_layout58>) -> tensor<1x4x32x64xbf16, #ttnn_layout64> loc(#loc65)
        %55 = "ttnn.neg"(%54) : (tensor<1x4x32x64xbf16, #ttnn_layout64>) -> tensor<1x4x32x64xbf16, #ttnn_layout64> loc(#loc66)
        "ttnn.deallocate"(%54) <{force = false}> : (tensor<1x4x32x64xbf16, #ttnn_layout64>) -> () loc(#loc66)
        %56 = "ttnn.slice_static"(%key) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 32 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x32x128xbf16, #ttnn_layout58>) -> tensor<1x4x32x64xbf16, #ttnn_layout64> loc(#loc67)
        "ttnn.deallocate"(%key) <{force = false}> : (tensor<1x4x32x128xbf16, #ttnn_layout58>) -> () loc(#loc67)
        %57 = "ttnn.concat"(%55, %56) <{dim = 3 : si32}> : (tensor<1x4x32x64xbf16, #ttnn_layout64>, tensor<1x4x32x64xbf16, #ttnn_layout64>) -> tensor<1x4x32x128xbf16, #ttnn_layout58> loc(#loc68)
        "ttnn.deallocate"(%56) <{force = false}> : (tensor<1x4x32x64xbf16, #ttnn_layout64>) -> () loc(#loc68)
        "ttnn.deallocate"(%55) <{force = false}> : (tensor<1x4x32x64xbf16, #ttnn_layout64>) -> () loc(#loc68)
        %58 = "ttnn.sin"(%50) : (tensor<1x1x32x128xf32, #ttnn_layout63>) -> tensor<1x1x32x128xf32, #ttnn_layout63> loc(#loc69)
        "ttnn.deallocate"(%50) <{force = false}> : (tensor<1x1x32x128xf32, #ttnn_layout63>) -> () loc(#loc69)
        %59 = "ttnn.typecast"(%58) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x32x128xf32, #ttnn_layout63>) -> tensor<1x1x32x128xbf16, #ttnn_layout2> loc(#loc70)
        "ttnn.deallocate"(%58) <{force = false}> : (tensor<1x1x32x128xf32, #ttnn_layout63>) -> () loc(#loc70)
        %60 = "ttnn.multiply"(%57, %59) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x32x128xbf16, #ttnn_layout58>, tensor<1x1x32x128xbf16, #ttnn_layout2>) -> tensor<1x4x32x128xbf16, #ttnn_layout58> loc(#loc71)
        "ttnn.deallocate"(%57) <{force = false}> : (tensor<1x4x32x128xbf16, #ttnn_layout58>) -> () loc(#loc71)
        %61 = "ttnn.add"(%53, %60) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4x32x128xbf16, #ttnn_layout58>, tensor<1x4x32x128xbf16, #ttnn_layout58>) -> tensor<1x4x32x128xbf16, #ttnn_layout58> loc(#loc72)
        "ttnn.deallocate"(%60) <{force = false}> : (tensor<1x4x32x128xbf16, #ttnn_layout58>) -> () loc(#loc72)
        "ttnn.deallocate"(%53) <{force = false}> : (tensor<1x4x32x128xbf16, #ttnn_layout58>) -> () loc(#loc72)
        "ttnn.fill_cache"(%22, %61) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn_layout47>, tensor<1x4x32x128xbf16, #ttnn_layout58>) -> () loc(#loc73)
        "ttnn.deallocate"(%61) <{force = false}> : (tensor<1x4x32x128xbf16, #ttnn_layout58>) -> () loc(#loc73)
        "ttnn.fill_cache"(%23, %value) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16, #ttnn_layout47>, tensor<1x4x32x128xbf16, #ttnn_layout58>) -> () loc(#loc74)
        "ttnn.deallocate"(%value) <{force = false}> : (tensor<1x4x32x128xbf16, #ttnn_layout58>) -> () loc(#loc74)
        %62 = "ttnn.multiply"(%query, %52) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>, tensor<1x1x32x128xbf16, #ttnn_layout2>) -> tensor<1x12x32x128xbf16, #ttnn_layout57> loc(#loc75)
        "ttnn.deallocate"(%52) <{force = false}> : (tensor<1x1x32x128xbf16, #ttnn_layout2>) -> () loc(#loc75)
        %63 = "ttnn.slice_static"(%query) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 32 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> tensor<1x12x32x64xbf16, #ttnn_layout65> loc(#loc76)
        %64 = "ttnn.neg"(%63) : (tensor<1x12x32x64xbf16, #ttnn_layout65>) -> tensor<1x12x32x64xbf16, #ttnn_layout65> loc(#loc77)
        "ttnn.deallocate"(%63) <{force = false}> : (tensor<1x12x32x64xbf16, #ttnn_layout65>) -> () loc(#loc77)
        %65 = "ttnn.slice_static"(%query) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 32 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> tensor<1x12x32x64xbf16, #ttnn_layout65> loc(#loc78)
        "ttnn.deallocate"(%query) <{force = false}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> () loc(#loc78)
        %66 = "ttnn.concat"(%64, %65) <{dim = 3 : si32}> : (tensor<1x12x32x64xbf16, #ttnn_layout65>, tensor<1x12x32x64xbf16, #ttnn_layout65>) -> tensor<1x12x32x128xbf16, #ttnn_layout57> loc(#loc79)
        "ttnn.deallocate"(%65) <{force = false}> : (tensor<1x12x32x64xbf16, #ttnn_layout65>) -> () loc(#loc79)
        "ttnn.deallocate"(%64) <{force = false}> : (tensor<1x12x32x64xbf16, #ttnn_layout65>) -> () loc(#loc79)
        %67 = "ttnn.multiply"(%66, %59) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>, tensor<1x1x32x128xbf16, #ttnn_layout2>) -> tensor<1x12x32x128xbf16, #ttnn_layout57> loc(#loc80)
        "ttnn.deallocate"(%66) <{force = false}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> () loc(#loc80)
        "ttnn.deallocate"(%59) <{force = false}> : (tensor<1x1x32x128xbf16, #ttnn_layout2>) -> () loc(#loc80)
        %68 = "ttnn.add"(%62, %67) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>, tensor<1x12x32x128xbf16, #ttnn_layout57>) -> tensor<1x12x32x128xbf16, #ttnn_layout57> loc(#loc81)
        "ttnn.deallocate"(%67) <{force = false}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> () loc(#loc81)
        "ttnn.deallocate"(%62) <{force = false}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> () loc(#loc81)
        %69 = "ttnn.reshape"(%22) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn_layout47>) -> tensor<1x4x1x128x128xbf16, #ttnn_layout66> loc(#loc82)
        %70 = "ttnn.repeat"(%69) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn_layout66>) -> tensor<1x4x3x128x128xbf16, #ttnn_layout67> loc(#loc82)
        "ttnn.deallocate"(%69) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn_layout66>) -> () loc(#loc82)
        %71 = "ttnn.reshape"(%70) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn_layout67>) -> tensor<1x12x128x128xbf16, #ttnn_layout68> loc(#loc83)
        "ttnn.deallocate"(%70) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn_layout67>) -> () loc(#loc83)
        %72 = "ttnn.matmul"(%68, %71) <{transpose_a = false, transpose_b = true}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>, tensor<1x12x128x128xbf16, #ttnn_layout68>) -> tensor<1x12x32x128xbf16, #ttnn_layout57> loc(#loc84)
        "ttnn.deallocate"(%71) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn_layout68>) -> () loc(#loc84)
        "ttnn.deallocate"(%68) <{force = false}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> () loc(#loc84)
        %73 = "ttnn.multiply"(%72, %2) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>, tensor<1x1x1x1xbf16, #ttnn_layout>) -> tensor<1x12x32x128xbf16, #ttnn_layout57> loc(#loc85)
        "ttnn.deallocate"(%72) <{force = false}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> () loc(#loc85)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout>) -> () loc(#loc85)
        %74 = "ttnn.to_layout"(%arg14) <{layout = #ttnn.layout<tile>}> : (tensor<bf16, #ttnn_layout36>) -> tensor<bf16, #ttnn_layout5> loc(#loc144)
        "ttnn.deallocate"(%arg14) <{force = false}> : (tensor<bf16, #ttnn_layout36>) -> () loc(#loc144)
        %75 = "ttnn.reshape"(%74) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout5>) -> tensor<1x1x1x1xbf16, #ttnn_layout> loc(#loc145)
        "ttnn.deallocate"(%74) <{force = false}> : (tensor<bf16, #ttnn_layout5>) -> () loc(#loc145)
        %76 = "ttnn.logical_and"(%75, %5) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x1xbf16, #ttnn_layout>, tensor<1x1x1x128xbf16, #ttnn_layout2>) -> tensor<1x1x1x128xbf16, #ttnn_layout2> loc(#loc86)
        "ttnn.deallocate"(%75) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout>) -> () loc(#loc86)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout2>) -> () loc(#loc86)
        %77 = "ttnn.logical_not"(%76) : (tensor<1x1x1x128xbf16, #ttnn_layout2>) -> tensor<1x1x1x128xbf16, #ttnn_layout2> loc(#loc87)
        %78 = "ttnn.to_layout"(%arg0) <{layout = #ttnn.layout<tile>}> : (tensor<32xsi32, #ttnn_layout28>) -> tensor<32xsi32, #ttnn_layout4> loc(#loc158)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<32xsi32, #ttnn_layout28>) -> () loc(#loc158)
        %79 = "ttnn.reshape"(%78) <{shape = [1 : i32, 1 : i32, 32 : i32, 1 : i32]}> : (tensor<32xsi32, #ttnn_layout4>) -> tensor<1x1x32x1xsi32, #ttnn_layout69> loc(#loc159)
        "ttnn.deallocate"(%78) <{force = false}> : (tensor<32xsi32, #ttnn_layout4>) -> () loc(#loc159)
        %80 = "ttnn.gt"(%0#1, %79) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x32x128xsi32, #ttnn_layout1>, tensor<1x1x32x1xsi32, #ttnn_layout69>) -> tensor<1x1x32x128xbf16, #ttnn_layout2> loc(#loc88)
        "ttnn.deallocate"(%79) <{force = false}> : (tensor<1x1x32x1xsi32, #ttnn_layout69>) -> () loc(#loc88)
        "ttnn.deallocate"(%0#1) <{force = false}> : (tensor<1x1x32x128xsi32, #ttnn_layout1>) -> () loc(#loc88)
        %81 = "ttnn.multiply"(%0#2, %80) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x32x128xbf16, #ttnn_layout2>, tensor<1x1x32x128xbf16, #ttnn_layout2>) -> tensor<1x1x32x128xbf16, #ttnn_layout2> loc(#loc89)
        "ttnn.deallocate"(%80) <{force = false}> : (tensor<1x1x32x128xbf16, #ttnn_layout2>) -> () loc(#loc89)
        "ttnn.deallocate"(%0#2) <{force = false}> : (tensor<1x1x32x128xbf16, #ttnn_layout2>) -> () loc(#loc89)
        %82 = "ttnn.slice_static"(%81) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 1 : i32, 32 : i32, 32 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1x32x128xbf16, #ttnn_layout2>) -> tensor<1x1x32x32xbf16, #ttnn_layout> loc(#loc90)
        %83 = "ttnn.to_layout"(%arg13) <{layout = #ttnn.layout<tile>}> : (tensor<1x32xsi32, #ttnn_layout30>) -> tensor<1x32xsi32, #ttnn_layout8> loc(#loc91)
        "ttnn.deallocate"(%arg13) <{force = false}> : (tensor<1x32xsi32, #ttnn_layout30>) -> () loc(#loc91)
        %84 = "ttnn.typecast"(%83) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x32xsi32, #ttnn_layout8>) -> tensor<1x32xbf16, #ttnn_layout7> loc(#loc92)
        "ttnn.deallocate"(%83) <{force = false}> : (tensor<1x32xsi32, #ttnn_layout8>) -> () loc(#loc92)
        %85 = "ttnn.reshape"(%84) <{shape = [1 : i32, 1 : i32, 1 : i32, 32 : i32]}> : (tensor<1x32xbf16, #ttnn_layout7>) -> tensor<1x1x1x32xbf16, #ttnn_layout> loc(#loc92)
        "ttnn.deallocate"(%84) <{force = false}> : (tensor<1x32xbf16, #ttnn_layout7>) -> () loc(#loc92)
        %86 = "ttnn.add"(%82, %85) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x32x32xbf16, #ttnn_layout>, tensor<1x1x1x32xbf16, #ttnn_layout>) -> tensor<1x1x32x32xbf16, #ttnn_layout> loc(#loc93)
        "ttnn.deallocate"(%85) <{force = false}> : (tensor<1x1x1x32xbf16, #ttnn_layout>) -> () loc(#loc93)
        %87 = "ttnn.eq"(%86, %0#0) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x32x32xbf16, #ttnn_layout>, tensor<1x1x1x1xbf16, #ttnn_layout>) -> tensor<1x1x32x32xbf16, #ttnn_layout> loc(#loc94)
        "ttnn.deallocate"(%86) <{force = false}> : (tensor<1x1x32x32xbf16, #ttnn_layout>) -> () loc(#loc94)
        "ttnn.deallocate"(%0#0) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout>) -> () loc(#loc94)
        %88 = "ttnn.where"(%87, %0#3, %82) : (tensor<1x1x32x32xbf16, #ttnn_layout>, tensor<1x1x32x32xbf16, #ttnn_layout>, tensor<1x1x32x32xbf16, #ttnn_layout>) -> tensor<1x1x32x32xbf16, #ttnn_layout> loc(#loc7)
        "ttnn.deallocate"(%87) <{force = false}> : (tensor<1x1x32x32xbf16, #ttnn_layout>) -> () loc(#loc7)
        "ttnn.deallocate"(%82) <{force = false}> : (tensor<1x1x32x32xbf16, #ttnn_layout>) -> () loc(#loc7)
        "ttnn.deallocate"(%0#3) <{force = false}> : (tensor<1x1x32x32xbf16, #ttnn_layout>) -> () loc(#loc7)
        %89 = "ttnn.permute"(%88) <{permutation = array<i64: 3, 0, 1, 2>}> : (tensor<1x1x32x32xbf16, #ttnn_layout>) -> tensor<32x1x1x32xbf16, #ttnn_layout70> loc(#loc146)
        "ttnn.deallocate"(%88) <{force = false}> : (tensor<1x1x32x32xbf16, #ttnn_layout>) -> () loc(#loc146)
        %90 = "ttnn.reshape"(%89) <{shape = [32 : i32, 32 : i32]}> : (tensor<32x1x1x32xbf16, #ttnn_layout70>) -> tensor<32x32xbf16, #ttnn_layout7> loc(#loc147)
        "ttnn.deallocate"(%89) <{force = false}> : (tensor<32x1x1x32xbf16, #ttnn_layout70>) -> () loc(#loc147)
        %91 = "ttnn.to_layout"(%90) <{layout = #ttnn.layout<row_major>}> : (tensor<32x32xbf16, #ttnn_layout7>) -> tensor<32x32xbf16, #ttnn_layout71> loc(#loc140)
        "ttnn.deallocate"(%90) <{force = false}> : (tensor<32x32xbf16, #ttnn_layout7>) -> () loc(#loc140)
        %92 = "ttnn.embedding"(%6, %91) : (tensor<128x1xui32, #ttnn_layout22>, tensor<32x32xbf16, #ttnn_layout71>) -> tensor<128x1x32xbf16, #ttnn_layout72> loc(#loc20)
        "ttnn.deallocate"(%91) <{force = false}> : (tensor<32x32xbf16, #ttnn_layout71>) -> () loc(#loc20)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<128x1xui32, #ttnn_layout22>) -> () loc(#loc20)
        %93 = "ttnn.reshape"(%92) <{shape = [128 : i32, 1 : i32, 1 : i32, 32 : i32]}> : (tensor<128x1x32xbf16, #ttnn_layout72>) -> tensor<128x1x1x32xbf16, #ttnn_layout73> loc(#loc148)
        "ttnn.deallocate"(%92) <{force = false}> : (tensor<128x1x32xbf16, #ttnn_layout72>) -> () loc(#loc148)
        %94 = "ttnn.permute"(%93) <{permutation = array<i64: 1, 2, 3, 0>}> : (tensor<128x1x1x32xbf16, #ttnn_layout73>) -> tensor<1x1x32x128xbf16, #ttnn_layout2> loc(#loc149)
        "ttnn.deallocate"(%93) <{force = false}> : (tensor<128x1x1x32xbf16, #ttnn_layout73>) -> () loc(#loc149)
        %95 = "ttnn.repeat"(%77) <{repeat_dims = #ttnn.shape<1x1x32x1>}> : (tensor<1x1x1x128xbf16, #ttnn_layout2>) -> tensor<1x1x32x128xbf16, #ttnn_layout2> loc(#loc8)
        "ttnn.deallocate"(%77) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout2>) -> () loc(#loc8)
        %96 = "ttnn.where"(%95, %0#4, %94) : (tensor<1x1x32x128xbf16, #ttnn_layout2>, tensor<1x1x32x128xbf16, #ttnn_layout2>, tensor<1x1x32x128xbf16, #ttnn_layout2>) -> tensor<1x1x32x128xbf16, #ttnn_layout2> loc(#loc8)
        "ttnn.deallocate"(%95) <{force = false}> : (tensor<1x1x32x128xbf16, #ttnn_layout2>) -> () loc(#loc8)
        "ttnn.deallocate"(%94) <{force = false}> : (tensor<1x1x32x128xbf16, #ttnn_layout2>) -> () loc(#loc8)
        "ttnn.deallocate"(%0#4) <{force = false}> : (tensor<1x1x32x128xbf16, #ttnn_layout2>) -> () loc(#loc8)
        %97 = "ttnn.repeat"(%76) <{repeat_dims = #ttnn.shape<1x1x32x1>}> : (tensor<1x1x1x128xbf16, #ttnn_layout2>) -> tensor<1x1x32x128xbf16, #ttnn_layout2> loc(#loc95)
        "ttnn.deallocate"(%76) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout2>) -> () loc(#loc95)
        %98 = "ttnn.where"(%97, %96, %81) : (tensor<1x1x32x128xbf16, #ttnn_layout2>, tensor<1x1x32x128xbf16, #ttnn_layout2>, tensor<1x1x32x128xbf16, #ttnn_layout2>) -> tensor<1x1x32x128xbf16, #ttnn_layout2> loc(#loc95)
        "ttnn.deallocate"(%97) <{force = false}> : (tensor<1x1x32x128xbf16, #ttnn_layout2>) -> () loc(#loc95)
        "ttnn.deallocate"(%96) <{force = false}> : (tensor<1x1x32x128xbf16, #ttnn_layout2>) -> () loc(#loc95)
        "ttnn.deallocate"(%81) <{force = false}> : (tensor<1x1x32x128xbf16, #ttnn_layout2>) -> () loc(#loc95)
        %99 = "ttnn.add"(%73, %98) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>, tensor<1x1x32x128xbf16, #ttnn_layout2>) -> tensor<1x12x32x128xbf16, #ttnn_layout57> loc(#loc96)
        "ttnn.deallocate"(%98) <{force = false}> : (tensor<1x1x32x128xbf16, #ttnn_layout2>) -> () loc(#loc96)
        "ttnn.deallocate"(%73) <{force = false}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> () loc(#loc96)
        %100 = "ttnn.typecast"(%99) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> tensor<1x12x32x128xf32, #ttnn_layout74> loc(#loc97)
        "ttnn.deallocate"(%99) <{force = false}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> () loc(#loc97)
        %101 = "ttnn.softmax"(%100) <{dimension = 3 : si32, numericStable = true}> : (tensor<1x12x32x128xf32, #ttnn_layout74>) -> tensor<1x12x32x128xf32, #ttnn_layout74> loc(#loc98)
        "ttnn.deallocate"(%100) <{force = false}> : (tensor<1x12x32x128xf32, #ttnn_layout74>) -> () loc(#loc98)
        %102 = "ttnn.typecast"(%101) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x32x128xf32, #ttnn_layout74>) -> tensor<1x12x32x128xbf16, #ttnn_layout57> loc(#loc99)
        "ttnn.deallocate"(%101) <{force = false}> : (tensor<1x12x32x128xf32, #ttnn_layout74>) -> () loc(#loc99)
        %103 = "ttnn.reshape"(%23) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn_layout47>) -> tensor<1x4x1x128x128xbf16, #ttnn_layout66> loc(#loc100)
        %104 = "ttnn.repeat"(%103) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn_layout66>) -> tensor<1x4x3x128x128xbf16, #ttnn_layout67> loc(#loc100)
        "ttnn.deallocate"(%103) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn_layout66>) -> () loc(#loc100)
        %105 = "ttnn.reshape"(%104) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn_layout67>) -> tensor<1x12x128x128xbf16, #ttnn_layout68> loc(#loc101)
        "ttnn.deallocate"(%104) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn_layout67>) -> () loc(#loc101)
        %106 = "ttnn.matmul"(%102, %105) <{transpose_a = false, transpose_b = false}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>, tensor<1x12x128x128xbf16, #ttnn_layout68>) -> tensor<1x12x32x128xbf16, #ttnn_layout57> loc(#loc102)
        "ttnn.deallocate"(%105) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn_layout68>) -> () loc(#loc102)
        "ttnn.deallocate"(%102) <{force = false}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> () loc(#loc102)
        %107 = "ttnn.concatenate_heads"(%106) : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> tensor<1x32x1536xbf16, #ttnn_layout55> loc(#loc103)
        "ttnn.deallocate"(%106) <{force = false}> : (tensor<1x12x32x128xbf16, #ttnn_layout57>) -> () loc(#loc103)
        %108 = "ttnn.reshape"(%107) <{shape = [32 : i32, 1536 : i32]}> : (tensor<1x32x1536xbf16, #ttnn_layout55>) -> tensor<32x1536xbf16, #ttnn_layout53> loc(#loc103)
        "ttnn.deallocate"(%107) <{force = false}> : (tensor<1x32x1536xbf16, #ttnn_layout55>) -> () loc(#loc103)
        %109 = "ttnn.matmul"(%108, %21) <{transpose_a = false, transpose_b = true}> : (tensor<32x1536xbf16, #ttnn_layout53>, tensor<3072x1536xbf16, #ttnn_layout46>) -> tensor<32x3072xbf16, #ttnn_layout14> loc(#loc104)
        "ttnn.deallocate"(%108) <{force = false}> : (tensor<32x1536xbf16, #ttnn_layout53>) -> () loc(#loc104)
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<3072x1536xbf16, #ttnn_layout46>) -> () loc(#loc104)
        %110 = "ttnn.reshape"(%109) <{shape = [1 : i32, 1 : i32, 32 : i32, 3072 : i32]}> : (tensor<32x3072xbf16, #ttnn_layout14>) -> tensor<1x1x32x3072xbf16, #ttnn_layout75> loc(#loc160)
        "ttnn.deallocate"(%109) <{force = false}> : (tensor<32x3072xbf16, #ttnn_layout14>) -> () loc(#loc160)
        %111 = "ttnn.reduce_scatter"(%110) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 2 : si32}> : (tensor<1x1x32x3072xbf16, #ttnn_layout75>) -> tensor<1x1x16x3072xbf16, #ttnn_layout75> loc(#loc161)
        "ttnn.deallocate"(%110) <{force = false}> : (tensor<1x1x32x3072xbf16, #ttnn_layout75>) -> () loc(#loc161)
        %112 = "ttnn.all_gather"(%111) <{all_gather_dim = 2 : si32, cluster_axis = 1 : ui32}> : (tensor<1x1x16x3072xbf16, #ttnn_layout75>) -> tensor<1x1x32x3072xbf16, #ttnn_layout75> loc(#loc151)
        "ttnn.deallocate"(%111) <{force = false}> : (tensor<1x1x16x3072xbf16, #ttnn_layout75>) -> () loc(#loc151)
        %113 = "ttnn.reshape"(%112) <{shape = [1 : i32, 32 : i32, 3072 : i32]}> : (tensor<1x1x32x3072xbf16, #ttnn_layout75>) -> tensor<1x32x3072xbf16, #ttnn_layout50> loc(#loc105)
        "ttnn.deallocate"(%112) <{force = false}> : (tensor<1x1x32x3072xbf16, #ttnn_layout75>) -> () loc(#loc105)
        %114 = "ttnn.add"(%27, %113) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x32x3072xbf16, #ttnn_layout50>, tensor<1x32x3072xbf16, #ttnn_layout50>) -> tensor<1x32x3072xbf16, #ttnn_layout50> loc(#loc106)
        "ttnn.deallocate"(%113) <{force = false}> : (tensor<1x32x3072xbf16, #ttnn_layout50>) -> () loc(#loc106)
        "ttnn.deallocate"(%27) <{force = false}> : (tensor<1x32x3072xbf16, #ttnn_layout50>) -> () loc(#loc106)
        %115 = "ttnn.typecast"(%114) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x32x3072xbf16, #ttnn_layout50>) -> tensor<1x32x3072xf32, #ttnn_layout51> loc(#loc107)
        %116 = "ttnn.pow_scalar"(%115) <{rhs = 2.000000e+00 : f32}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> tensor<1x32x3072xf32, #ttnn_layout51> loc(#loc108)
        %117 = "ttnn.sum"(%116) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> tensor<1x32xf32, #ttnn_layout11> loc(#loc109)
        "ttnn.deallocate"(%116) <{force = false}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> () loc(#loc109)
        %118 = "ttnn.reshape"(%117) <{shape = [32 : i32, 1 : i32]}> : (tensor<1x32xf32, #ttnn_layout11>) -> tensor<32x1xf32, #ttnn_layout11> loc(#loc180)
        "ttnn.deallocate"(%117) <{force = false}> : (tensor<1x32xf32, #ttnn_layout11>) -> () loc(#loc180)
        %119 = "ttnn.multiply"(%118, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<32x1xf32, #ttnn_layout11>, tensor<1x1xf32, #ttnn_layout11>) -> tensor<32x1xf32, #ttnn_layout11> loc(#loc110)
        "ttnn.deallocate"(%118) <{force = false}> : (tensor<32x1xf32, #ttnn_layout11>) -> () loc(#loc110)
        %120 = "ttnn.add"(%119, %1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<32x1xf32, #ttnn_layout11>, tensor<1x1xf32, #ttnn_layout11>) -> tensor<32x1xf32, #ttnn_layout11> loc(#loc111)
        "ttnn.deallocate"(%119) <{force = false}> : (tensor<32x1xf32, #ttnn_layout11>) -> () loc(#loc111)
        %121 = "ttnn.rsqrt"(%120) : (tensor<32x1xf32, #ttnn_layout11>) -> tensor<32x1xf32, #ttnn_layout11> loc(#loc112)
        "ttnn.deallocate"(%120) <{force = false}> : (tensor<32x1xf32, #ttnn_layout11>) -> () loc(#loc112)
        %122 = "ttnn.reshape"(%115) <{shape = [32 : i32, 3072 : i32]}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> tensor<32x3072xf32, #ttnn_layout52> loc(#loc169)
        "ttnn.deallocate"(%115) <{force = false}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> () loc(#loc169)
        %123 = "ttnn.multiply"(%122, %121) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<32x3072xf32, #ttnn_layout52>, tensor<32x1xf32, #ttnn_layout11>) -> tensor<32x3072xf32, #ttnn_layout52> loc(#loc113)
        "ttnn.deallocate"(%122) <{force = false}> : (tensor<32x3072xf32, #ttnn_layout52>) -> () loc(#loc113)
        "ttnn.deallocate"(%121) <{force = false}> : (tensor<32x1xf32, #ttnn_layout11>) -> () loc(#loc113)
        %124 = "ttnn.typecast"(%123) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<32x3072xf32, #ttnn_layout52>) -> tensor<32x3072xbf16, #ttnn_layout14> loc(#loc114)
        "ttnn.deallocate"(%123) <{force = false}> : (tensor<32x3072xf32, #ttnn_layout52>) -> () loc(#loc114)
        %125 = "ttnn.multiply"(%8, %124) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn_layout14>, tensor<32x3072xbf16, #ttnn_layout14>) -> tensor<32x3072xbf16, #ttnn_layout14> loc(#loc115)
        "ttnn.deallocate"(%124) <{force = false}> : (tensor<32x3072xbf16, #ttnn_layout14>) -> () loc(#loc115)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout14>) -> () loc(#loc115)
        %126 = "ttnn.matmul"(%125, %13) <{activation = "silu", transpose_a = false, transpose_b = true}> : (tensor<32x3072xbf16, #ttnn_layout14>, tensor<4096x3072xbf16, #ttnn_layout41>) -> tensor<32x4096xbf16, #ttnn_layout76> loc(#loc116)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<4096x3072xbf16, #ttnn_layout41>) -> () loc(#loc116)
        %127 = "ttnn.matmul"(%125, %15) <{transpose_a = false, transpose_b = true}> : (tensor<32x3072xbf16, #ttnn_layout14>, tensor<4096x3072xbf16, #ttnn_layout41>) -> tensor<32x4096xbf16, #ttnn_layout76> loc(#loc117)
        "ttnn.deallocate"(%125) <{force = false}> : (tensor<32x3072xbf16, #ttnn_layout14>) -> () loc(#loc117)
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<4096x3072xbf16, #ttnn_layout41>) -> () loc(#loc117)
        %128 = "ttnn.multiply"(%126, %127) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<32x4096xbf16, #ttnn_layout76>, tensor<32x4096xbf16, #ttnn_layout76>) -> tensor<32x4096xbf16, #ttnn_layout76> loc(#loc118)
        "ttnn.deallocate"(%127) <{force = false}> : (tensor<32x4096xbf16, #ttnn_layout76>) -> () loc(#loc118)
        "ttnn.deallocate"(%126) <{force = false}> : (tensor<32x4096xbf16, #ttnn_layout76>) -> () loc(#loc118)
        %129 = "ttnn.matmul"(%128, %14) <{transpose_a = false, transpose_b = true}> : (tensor<32x4096xbf16, #ttnn_layout76>, tensor<3072x4096xbf16, #ttnn_layout42>) -> tensor<32x3072xbf16, #ttnn_layout14> loc(#loc119)
        "ttnn.deallocate"(%128) <{force = false}> : (tensor<32x4096xbf16, #ttnn_layout76>) -> () loc(#loc119)
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<3072x4096xbf16, #ttnn_layout42>) -> () loc(#loc119)
        %130 = "ttnn.reshape"(%129) <{shape = [1 : i32, 1 : i32, 32 : i32, 3072 : i32]}> : (tensor<32x3072xbf16, #ttnn_layout14>) -> tensor<1x1x32x3072xbf16, #ttnn_layout75> loc(#loc163)
        "ttnn.deallocate"(%129) <{force = false}> : (tensor<32x3072xbf16, #ttnn_layout14>) -> () loc(#loc163)
        %131 = "ttnn.reduce_scatter"(%130) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 2 : si32}> : (tensor<1x1x32x3072xbf16, #ttnn_layout75>) -> tensor<1x1x16x3072xbf16, #ttnn_layout75> loc(#loc164)
        "ttnn.deallocate"(%130) <{force = false}> : (tensor<1x1x32x3072xbf16, #ttnn_layout75>) -> () loc(#loc164)
        %132 = "ttnn.all_gather"(%131) <{all_gather_dim = 2 : si32, cluster_axis = 1 : ui32}> : (tensor<1x1x16x3072xbf16, #ttnn_layout75>) -> tensor<1x1x32x3072xbf16, #ttnn_layout75> loc(#loc154)
        "ttnn.deallocate"(%131) <{force = false}> : (tensor<1x1x16x3072xbf16, #ttnn_layout75>) -> () loc(#loc154)
        %133 = "ttnn.reshape"(%132) <{shape = [1 : i32, 32 : i32, 3072 : i32]}> : (tensor<1x1x32x3072xbf16, #ttnn_layout75>) -> tensor<1x32x3072xbf16, #ttnn_layout50> loc(#loc120)
        "ttnn.deallocate"(%132) <{force = false}> : (tensor<1x1x32x3072xbf16, #ttnn_layout75>) -> () loc(#loc120)
        %134 = "ttnn.add"(%114, %133) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x32x3072xbf16, #ttnn_layout50>, tensor<1x32x3072xbf16, #ttnn_layout50>) -> tensor<1x32x3072xbf16, #ttnn_layout50> loc(#loc121)
        "ttnn.deallocate"(%133) <{force = false}> : (tensor<1x32x3072xbf16, #ttnn_layout50>) -> () loc(#loc121)
        "ttnn.deallocate"(%114) <{force = false}> : (tensor<1x32x3072xbf16, #ttnn_layout50>) -> () loc(#loc121)
        %135 = "ttnn.typecast"(%134) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x32x3072xbf16, #ttnn_layout50>) -> tensor<1x32x3072xf32, #ttnn_layout51> loc(#loc122)
        "ttnn.deallocate"(%134) <{force = false}> : (tensor<1x32x3072xbf16, #ttnn_layout50>) -> () loc(#loc122)
        %136 = "ttnn.pow_scalar"(%135) <{rhs = 2.000000e+00 : f32}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> tensor<1x32x3072xf32, #ttnn_layout51> loc(#loc123)
        %137 = "ttnn.sum"(%136) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> tensor<1x32xf32, #ttnn_layout11> loc(#loc124)
        "ttnn.deallocate"(%136) <{force = false}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> () loc(#loc124)
        %138 = "ttnn.reshape"(%137) <{shape = [32 : i32, 1 : i32]}> : (tensor<1x32xf32, #ttnn_layout11>) -> tensor<32x1xf32, #ttnn_layout11> loc(#loc181)
        "ttnn.deallocate"(%137) <{force = false}> : (tensor<1x32xf32, #ttnn_layout11>) -> () loc(#loc181)
        %139 = "ttnn.multiply"(%138, %7) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<32x1xf32, #ttnn_layout11>, tensor<1x1xf32, #ttnn_layout11>) -> tensor<32x1xf32, #ttnn_layout11> loc(#loc125)
        "ttnn.deallocate"(%138) <{force = false}> : (tensor<32x1xf32, #ttnn_layout11>) -> () loc(#loc125)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1xf32, #ttnn_layout11>) -> () loc(#loc125)
        %140 = "ttnn.add"(%139, %1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<32x1xf32, #ttnn_layout11>, tensor<1x1xf32, #ttnn_layout11>) -> tensor<32x1xf32, #ttnn_layout11> loc(#loc126)
        "ttnn.deallocate"(%139) <{force = false}> : (tensor<32x1xf32, #ttnn_layout11>) -> () loc(#loc126)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x1xf32, #ttnn_layout11>) -> () loc(#loc126)
        %141 = "ttnn.rsqrt"(%140) : (tensor<32x1xf32, #ttnn_layout11>) -> tensor<32x1xf32, #ttnn_layout11> loc(#loc127)
        "ttnn.deallocate"(%140) <{force = false}> : (tensor<32x1xf32, #ttnn_layout11>) -> () loc(#loc127)
        %142 = "ttnn.reshape"(%135) <{shape = [32 : i32, 3072 : i32]}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> tensor<32x3072xf32, #ttnn_layout52> loc(#loc171)
        "ttnn.deallocate"(%135) <{force = false}> : (tensor<1x32x3072xf32, #ttnn_layout51>) -> () loc(#loc171)
        %143 = "ttnn.multiply"(%142, %141) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<32x3072xf32, #ttnn_layout52>, tensor<32x1xf32, #ttnn_layout11>) -> tensor<32x3072xf32, #ttnn_layout52> loc(#loc128)
        "ttnn.deallocate"(%142) <{force = false}> : (tensor<32x3072xf32, #ttnn_layout52>) -> () loc(#loc128)
        "ttnn.deallocate"(%141) <{force = false}> : (tensor<32x1xf32, #ttnn_layout11>) -> () loc(#loc128)
        %144 = "ttnn.typecast"(%143) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<32x3072xf32, #ttnn_layout52>) -> tensor<32x3072xbf16, #ttnn_layout14> loc(#loc129)
        "ttnn.deallocate"(%143) <{force = false}> : (tensor<32x3072xf32, #ttnn_layout52>) -> () loc(#loc129)
        %145 = "ttnn.multiply"(%3, %144) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn_layout14>, tensor<32x3072xbf16, #ttnn_layout14>) -> tensor<32x3072xbf16, #ttnn_layout14> loc(#loc130)
        "ttnn.deallocate"(%144) <{force = false}> : (tensor<32x3072xbf16, #ttnn_layout14>) -> () loc(#loc130)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout14>) -> () loc(#loc130)
        %146 = "ttnn.matmul"(%145, %arg9) <{transpose_a = false, transpose_b = true}> : (tensor<32x3072xbf16, #ttnn_layout14>, tensor<128256x3072xbf16, #ttnn_layout32>) -> tensor<32x128256xbf16, #ttnn_layout77> loc(#loc131)
        "ttnn.deallocate"(%145) <{force = false}> : (tensor<32x3072xbf16, #ttnn_layout14>) -> () loc(#loc131)
        "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout32>) -> () loc(#loc131)
        %147 = "ttnn.reshape"(%146) <{shape = [1 : i32, 32 : i32, 128256 : i32]}> : (tensor<32x128256xbf16, #ttnn_layout77>) -> tensor<1x32x128256xbf16, #ttnn_layout78> loc(#loc132)
        %148 = "ttnn.to_layout"(%22) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn_layout47>) -> tensor<1x4x128x128xbf16, #ttnn_layout79> loc(#loc)
        "ttnn.deallocate"(%22) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout47>) -> () loc(#loc)
        %149 = "ttnn.from_device"(%148) : (tensor<1x4x128x128xbf16, #ttnn_layout79>) -> tensor<1x4x128x128xbf16, #ttnn_layout80> loc(#loc)
        "ttnn.deallocate"(%148) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout79>) -> () loc(#loc)
        %150 = "ttnn.aggregate_tensor"(%149, %11) <{composer_config = #ttnn.mesh_composer_config<dims = [3 : i32, 1 : i32], mesh_shape_override = [1 : ui32, 2 : ui32]>}> : (tensor<1x4x128x128xbf16, #ttnn_layout80>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn_layout37> loc(#loc)
        "ttnn.deallocate"(%149) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout80>) -> () loc(#loc)
        %151 = "ttnn.to_layout"(%23) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn_layout47>) -> tensor<1x4x128x128xbf16, #ttnn_layout79> loc(#loc)
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout47>) -> () loc(#loc)
        %152 = "ttnn.from_device"(%151) : (tensor<1x4x128x128xbf16, #ttnn_layout79>) -> tensor<1x4x128x128xbf16, #ttnn_layout80> loc(#loc)
        "ttnn.deallocate"(%151) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout79>) -> () loc(#loc)
        %153 = "ttnn.aggregate_tensor"(%152, %11) <{composer_config = #ttnn.mesh_composer_config<dims = [3 : i32, 1 : i32], mesh_shape_override = [1 : ui32, 2 : ui32]>}> : (tensor<1x4x128x128xbf16, #ttnn_layout80>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn_layout37> loc(#loc)
        "ttnn.deallocate"(%152) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout80>) -> () loc(#loc)
        %154 = "ttnn.to_layout"(%146) <{layout = #ttnn.layout<row_major>}> : (tensor<32x128256xbf16, #ttnn_layout77>) -> tensor<32x128256xbf16, #ttnn_layout81> loc(#loc)
        "ttnn.deallocate"(%146) <{force = false}> : (tensor<32x128256xbf16, #ttnn_layout77>) -> () loc(#loc)
        %155 = "ttnn.from_device"(%154) : (tensor<32x128256xbf16, #ttnn_layout81>) -> tensor<32x128256xbf16, #ttnn_layout38> loc(#loc)
        "ttnn.deallocate"(%154) <{force = false}> : (tensor<32x128256xbf16, #ttnn_layout81>) -> () loc(#loc)
        %156 = "ttnn.aggregate_tensor"(%155, %11) <{composer_config = #ttnn.mesh_composer_config<dims = [0 : i32], mesh_shape_override = [1 : ui32]>}> : (tensor<32x128256xbf16, #ttnn_layout38>, !ttnn.device) -> tensor<32x128256xbf16, #ttnn_layout38> loc(#loc)
        "ttnn.deallocate"(%155) <{force = false}> : (tensor<32x128256xbf16, #ttnn_layout38>) -> () loc(#loc)
        %157 = "ttnn.to_layout"(%147) <{layout = #ttnn.layout<row_major>}> : (tensor<1x32x128256xbf16, #ttnn_layout78>) -> tensor<1x32x128256xbf16, #ttnn_layout82> loc(#loc)
        "ttnn.deallocate"(%147) <{force = false}> : (tensor<1x32x128256xbf16, #ttnn_layout78>) -> () loc(#loc)
        %158 = "ttnn.from_device"(%157) : (tensor<1x32x128256xbf16, #ttnn_layout82>) -> tensor<1x32x128256xbf16, #ttnn_layout39> loc(#loc)
        "ttnn.deallocate"(%157) <{force = false}> : (tensor<1x32x128256xbf16, #ttnn_layout82>) -> () loc(#loc)
        %159 = "ttnn.aggregate_tensor"(%158, %11) <{composer_config = #ttnn.mesh_composer_config<dims = [0 : i32], mesh_shape_override = [1 : ui32]>}> : (tensor<1x32x128256xbf16, #ttnn_layout39>, !ttnn.device) -> tensor<1x32x128256xbf16, #ttnn_layout39> loc(#loc)
        "ttnn.deallocate"(%158) <{force = false}> : (tensor<1x32x128256xbf16, #ttnn_layout39>) -> () loc(#loc)
        return %150, %153, %156, %159 : tensor<1x8x128x128xbf16, #ttnn_layout37>, tensor<1x8x128x128xbf16, #ttnn_layout37>, tensor<32x128256xbf16, #ttnn_layout38>, tensor<1x32x128256xbf16, #ttnn_layout39> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("broadcast.225")
#loc2 = loc("broadcast.227")
#loc3 = loc("subtract.228")
#loc4 = loc("compare.230")
#loc5 = loc("select.232")
#loc6 = loc("reshape.235")
#loc7 = loc("select.308")
#loc8 = loc("select.334")
#loc9 = loc("reshape.85")
#loc10 = loc("reshape.512")
#loc11 = loc("reshape.19")
#loc12 = loc("broadcast.338")
#loc13 = loc("floor.256")
#loc14 = loc("convert.257")
#loc15 = loc("clamp.260")
#loc16 = loc("compare.269")
#loc17 = loc("add.266")
#loc18 = loc("select.270")
#loc19 = loc("reshape.271")
#loc20 = loc("gather.310")
#loc21 = loc("reshape.462")
#loc22 = loc("gather.48")
#loc42 = loc("transpose.34")
#loc43 = loc("transpose.133")
#loc44 = loc("convert.47_in_0_layout")
#loc45 = loc("convert.47")
#loc46 = loc("convert.50")
#loc47 = loc("power.52")
#loc48 = loc("reduce.59")
#loc49 = loc("multiply.68")
#loc50 = loc("add.73")
#loc51 = loc("rsqrt.74")
#loc52 = loc("multiply.77")
#loc53 = loc("convert.78")
#loc54 = loc("multiply.84")
#loc55 = loc("dot.364")
#loc56 = loc("dot.86")
#loc57 = loc("convert.11_in_0_layout")
#loc58 = loc("convert.11")
#loc59 = loc("dot.22")
#loc60 = loc("transpose.23")
#loc61 = loc("concatenate.24")
#loc62 = loc("cosine.98")
#loc63 = loc("convert.101")
#loc64 = loc("multiply.105")
#loc65 = loc("slice.91")
#loc66 = loc("negate.92")
#loc67 = loc("slice.90")
#loc68 = loc("concatenate.93")
#loc69 = loc("sine.25")
#loc70 = loc("convert.28")
#loc71 = loc("multiply.96")
#loc72 = loc("add.108")
#loc73 = loc("scatter.127")
#loc74 = loc("scatter.157")
#loc75 = loc("multiply.377")
#loc76 = loc("slice.369")
#loc77 = loc("negate.370")
#loc78 = loc("slice.368")
#loc79 = loc("concatenate.371")
#loc80 = loc("multiply.374")
#loc81 = loc("add.380")
#loc82 = loc("broadcast.354")
#loc83 = loc("reshape.355")
#loc84 = loc("dot.381")
#loc85 = loc("multiply.384")
#loc86 = loc("and.328")
#loc87 = loc("not.330")
#loc88 = loc("compare.202")
#loc89 = loc("multiply.233")
#loc90 = loc("slice.297")
#loc91 = loc("convert.298_in_0_layout")
#loc92 = loc("convert.298")
#loc93 = loc("add.303")
#loc94 = loc("compare.306")
#loc95 = loc("select.339")
#loc96 = loc("add.389")
#loc97 = loc("convert.390")
#loc98 = loc("divide.407")
#loc99 = loc("convert.408")
#loc100 = loc("broadcast.194")
#loc101 = loc("reshape.195")
#loc102 = loc("dot.409")
#loc103 = loc("reshape.413")
#loc104 = loc("dot.414")
#loc105 = loc("reshape.415")
#loc106 = loc("add.418")
#loc107 = loc("convert.419")
#loc108 = loc("power.421")
#loc109 = loc("reduce.428")
#loc110 = loc("multiply.437")
#loc111 = loc("add.442")
#loc112 = loc("rsqrt.443")
#loc113 = loc("multiply.446")
#loc114 = loc("convert.447")
#loc115 = loc("multiply.453")
#loc116 = loc("dot.463")
#loc117 = loc("dot.455")
#loc118 = loc("multiply.467")
#loc119 = loc("dot.469")
#loc120 = loc("reshape.470")
#loc121 = loc("add.473")
#loc122 = loc("convert.474")
#loc123 = loc("power.476")
#loc124 = loc("reduce.483")
#loc125 = loc("multiply.492")
#loc126 = loc("add.497")
#loc127 = loc("rsqrt.498")
#loc128 = loc("multiply.501")
#loc129 = loc("convert.502")
#loc130 = loc("multiply.508")
#loc131 = loc("dot.513")
#loc132 = loc("reshape.514")
#loc133 = loc("subtract.228_neg"(#loc3))
#loc134 = loc("reshape.235_tm1"(#loc6))
#loc135 = loc("reshape.235_tm0"(#loc6))
#loc136 = loc("reshape.85_tm1"(#loc9))
#loc137 = loc("reshape.512_tm0"(#loc10))
#loc138 = loc("broadcast.338_tm1"(#loc12))
#loc139 = loc("select.270_workaround"(#loc18))
#loc140 = loc("gather.310_workaround"(#loc20))
#loc141 = loc("reshape.462_tm0"(#loc21))
#loc142 = loc("reshape.85_tm0"(#loc9))
#loc143 = loc("gather.48_workaround"(#loc22))
#loc144 = loc("broadcast.338_tm0_in_0_layout"(#loc12))
#loc145 = loc("broadcast.338_tm0"(#loc12))
#loc146 = loc("gather.310_permuteInput"(#loc20))
#loc147 = loc("gather.310_reshapeInput"(#loc20))
#loc148 = loc("gather.310_reshapeOutput"(#loc20))
#loc149 = loc("gather.310_permuteOutput"(#loc20))
#loc150 = loc("dot.414_reduceScatter"(#loc104))
#loc151 = loc("dot.414_all_gather_4d"(#loc104))
#loc152 = loc("reshape.462_tm1"(#loc21))
#loc153 = loc("dot.469_reduceScatter"(#loc119))
#loc154 = loc("dot.469_all_gather_4d"(#loc119))
#loc155 = loc("reshape.512_tm1"(#loc10))
#loc156 = loc("reshape.235_tm1_tm0"(#loc134))
#loc157 = loc("reshape.85_tm1_tm0"(#loc136))
#loc158 = loc("reshape.235_tm1_tm1_in_0_layout"(#loc134))
#loc159 = loc("reshape.235_tm1_tm1"(#loc134))
#loc160 = loc("dot.414_reduceScatter_reshape_to_4d"(#loc150))
#loc161 = loc("dot.414_reduceScatter_reduce_scatter_4d"(#loc150))
#loc162 = loc("reshape.462_tm1_tm0"(#loc152))
#loc163 = loc("dot.469_reduceScatter_reshape_to_4d"(#loc153))
#loc164 = loc("dot.469_reduceScatter_reduce_scatter_4d"(#loc153))
#loc165 = loc("reshape.512_tm1_tm0"(#loc155))
#loc166 = loc("reshape.85_tm1_tm0_tm1"(#loc157))
#loc167 = loc("reshape.85_tm1_tm0_tm0"(#loc157))
#loc168 = loc("reshape.462_tm1_tm0_tm1"(#loc162))
#loc169 = loc("reshape.462_tm1_tm0_tm0"(#loc162))
#loc170 = loc("reshape.512_tm1_tm0_tm1"(#loc165))
#loc171 = loc("reshape.512_tm1_tm0_tm0"(#loc165))
#loc172 = loc("reshape.85_tm1_tm0_tm1_tm0"(#loc166))
#loc173 = loc("reshape.462_tm1_tm0_tm1_tm0"(#loc168))
#loc174 = loc("reshape.512_tm1_tm0_tm1_tm0"(#loc170))
#loc175 = loc("reshape.85_tm1_tm0_tm1_tm0_tm1"(#loc172))
#loc176 = loc("reshape.85_tm1_tm0_tm1_tm0_tm0"(#loc172))
#loc177 = loc("reshape.462_tm1_tm0_tm1_tm0_tm0"(#loc173))
#loc178 = loc("reshape.512_tm1_tm0_tm1_tm0_tm0"(#loc174))
#loc179 = loc("reshape.85_tm1_tm0_tm1_tm0_tm0_tm0"(#loc176))
#loc180 = loc("reshape.462_tm1_tm0_tm1_tm0_tm0_tm0"(#loc177))
#loc181 = loc("reshape.512_tm1_tm0_tm1_tm0_tm0_tm0"(#loc178))
------------------ END OF MLIR MODULE ------------------
2026-01-02 18:37:37.196 (   8.255s) [        CBC3A000]loaded_executable_insta:290      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2026-01-02 18:37:37.196 (   8.255s) [        CBC3A000]loaded_executable_insta:309      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2026-01-02 18:37:37.198 (   8.256s) [        CBC3A000]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2026-01-02 18:37:37.198 (   8.256s) [        CBC3A000]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-01-02 18:37:37.198 (   8.256s) [        CBC3A000]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-01-02 18:37:37.198 (   8.256s) [        CBC3A000]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-01-02 18:37:37.198 (   8.256s) [        CBC3A000] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-02 18:37:37.198 (   8.256s) [        CBC3A000] executable_instance.cc:157      1| Successfully read MLIR code from: pjrt_implementation/test_data/cursed.mlir (size=40801 bytes)
2026-01-02 18:37:37.198 (   8.256s) [        CBC3A000] executable_instance.cc:179      1| Literal MLIR code (size=40801):

module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, mhlo.spmd_output_sharding="{{devices=[1,2,1,1]<=[2]},{devices=[1,2,1,1]<=[2]},{replicated},{replicated}}"
} {
  func.func @main(%arg0: tensor<32xi64>, %arg1: tensor<64xf32>, %arg2: tensor<1024x3072xbf16>, %arg3: tensor<1x32xi64>, %arg4: tensor<128256x3072xbf16>, %arg5: tensor<3072xbf16>, %arg6: tensor<1x8x128x128xbf16>, %arg7: tensor<1024x3072xbf16>, %arg8: tensor<1x8x128x128xbf16>, %arg9: tensor<128256x3072xbf16>, %arg10: tensor<3072x8192xbf16>, %arg11: tensor<8192x3072xbf16>, %arg12: tensor<3072x3072xbf16>, %arg13: tensor<1x32xi64>, %arg14: tensor<i1>, %arg15: tensor<3072x3072xbf16>, %arg16: tensor<3072xbf16>, %arg17: tensor<8192x3072xbf16>, %arg18: tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>) {
    %0 = mhlo.copy %arg0 {mhlo.sharding = "{replicated}"} : tensor<32xi64>
    %1 = stablehlo.custom_call @SPMDFullToShardShape(%0) {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xi64>
    %2 = mhlo.copy %arg1 {mhlo.sharding = "{replicated}"} : tensor<64xf32>
    %3 = stablehlo.custom_call @SPMDFullToShardShape(%2) {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<64xf32>
    %4 = mhlo.copy %arg2 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %5 = stablehlo.custom_call @SPMDFullToShardShape(%4) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %6 = mhlo.copy %arg3 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %7 = stablehlo.custom_call @SPMDFullToShardShape(%6) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %8 = mhlo.copy %arg4 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %9 = stablehlo.custom_call @SPMDFullToShardShape(%8) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %10 = mhlo.copy %arg5 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %11 = stablehlo.custom_call @SPMDFullToShardShape(%10) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %12 = mhlo.copy %arg6 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %13 = stablehlo.custom_call @SPMDFullToShardShape(%12) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %14 = mhlo.copy %arg7 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %15 = stablehlo.custom_call @SPMDFullToShardShape(%14) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %16 = mhlo.copy %arg8 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %17 = stablehlo.custom_call @SPMDFullToShardShape(%16) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %18 = mhlo.copy %arg9 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %19 = stablehlo.custom_call @SPMDFullToShardShape(%18) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %20 = mhlo.copy %arg10 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x8192xbf16>
    %21 = stablehlo.custom_call @SPMDFullToShardShape(%20) {mhlo.sharding = "{manual}"} : (tensor<3072x8192xbf16>) -> tensor<3072x4096xbf16>
    %22 = mhlo.copy %arg11 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %23 = stablehlo.custom_call @SPMDFullToShardShape(%22) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %24 = mhlo.copy %arg12 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x3072xbf16>
    %25 = stablehlo.custom_call @SPMDFullToShardShape(%24) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<3072x1536xbf16>
    %26 = mhlo.copy %arg13 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %27 = stablehlo.custom_call @SPMDFullToShardShape(%26) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %28 = mhlo.copy %arg14 {mhlo.sharding = "{replicated}"} : tensor<i1>
    %29 = stablehlo.custom_call @SPMDFullToShardShape(%28) {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<i1>
    %30 = mhlo.copy %arg15 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<3072x3072xbf16>
    %31 = stablehlo.custom_call @SPMDFullToShardShape(%30) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<1536x3072xbf16>
    %32 = mhlo.copy %arg16 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %33 = stablehlo.custom_call @SPMDFullToShardShape(%32) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %34 = mhlo.copy %arg17 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %35 = stablehlo.custom_call @SPMDFullToShardShape(%34) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %36 = mhlo.copy %arg18 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %37 = stablehlo.custom_call @SPMDFullToShardShape(%36) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %cst = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"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tensor<128xi64>
    %c_0 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xi64>
    %cst_1 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0xFF800000> : tensor<f32>
    %c_2 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<128> : tensor<i64>
    %cst_3 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<2.000000e+00> : tensor<f32>
    %cst_4 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<3.25520843E-4> : tensor<f32>
    %cst_5 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<9.99999974E-6> : tensor<f32>
    %cst_6 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<8.837890e-02> : tensor<bf16>
    %c_7 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1>
    %c_8 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<1> : tensor<i64>
    %cst_9 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<bf16>
    %cst_10 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<-3.389530e+38> : tensor<bf16>
    %c_11 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0> : tensor<i64>
    %cst_12 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>
    %c_13 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<31> : tensor<i64>
    %c_14 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<32> : tensor<i64>
    %38 = stablehlo.broadcast_in_dim %c_14, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %39 = stablehlo.broadcast_in_dim %c_13, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %40 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %41 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %42 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %43 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %44 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %45 = stablehlo.broadcast_in_dim %c_8, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32x128xi64>
    %46 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x128xbf16>
    %47 = stablehlo.broadcast_in_dim %cst_6, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x12x32x128xbf16>
    %48 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %49 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %50 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %51 = stablehlo.broadcast_in_dim %c_2, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %52 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %53 = stablehlo.reshape %1 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<1x1x32xi64>
    %54 = stablehlo.reshape %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %55 = stablehlo.compare  LT, %54, %52 {mhlo.sharding = "{manual}"} : (tensor<32xi64>, tensor<32xi64>) -> tensor<32xi1>
    %56 = stablehlo.add %54, %51 {mhlo.sharding = "{manual}"} : tensor<32xi64>
    %57 = stablehlo.select %55, %56, %54 {mhlo.sharding = "{manual}"} : tensor<32xi1>, tensor<32xi64>
    %58 = stablehlo.reshape %57 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x1xi64>
    %59 = stablehlo.reshape %11 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %60 = stablehlo.reshape %59 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %62 = stablehlo.reshape %9 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %63 = stablehlo.reshape %62 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %64 = stablehlo.reshape %7 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %65 = stablehlo.reshape %64 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %66 = stablehlo.convert %65 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xui32>
    %67 = "stablehlo.gather"(%63, %66) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>, tensor<32xui32>) -> tensor<32x3072xbf16>
    %68 = stablehlo.reshape %67 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %69 = stablehlo.convert %68 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %70 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %71 = stablehlo.power %69, %70 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %72 = stablehlo.reduce(%71 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %73 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %74 = stablehlo.multiply %72, %73 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %75 = stablehlo.reshape %74 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %76 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %77 = stablehlo.add %75, %76 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %78 = stablehlo.rsqrt %77 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %79 = stablehlo.reshape %78 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %80 = stablehlo.broadcast_in_dim %79, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %81 = stablehlo.multiply %69, %80 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %82 = stablehlo.convert %81 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %83 = stablehlo.multiply %61, %82 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %84 = stablehlo.reshape %83 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %85 = stablehlo.reshape %5 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %86 = stablehlo.reshape %85 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %87 = stablehlo.transpose %86, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %88 = stablehlo.dot_general %84, %87, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %89 = stablehlo.reshape %88 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %90 = stablehlo.transpose %89, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %91 = stablehlo.reshape %3 {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %92 = stablehlo.reshape %91 {mhlo.sharding = "{manual}"} : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %93 = stablehlo.convert %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x32xf32>
    %94 = stablehlo.dot_general %92, %93, batching_dims = [0] x [0], contracting_dims = [2] x [1] {mhlo.sharding = "{manual}"} : (tensor<1x64x1xf32>, tensor<1x1x32xf32>) -> tensor<1x64x32xf32>
    %95 = stablehlo.transpose %94, dims = [0, 2, 1] {mhlo.sharding = "{manual}", result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,32,64]{1,2,0}"} : (tensor<1x64x32xf32>) -> tensor<1x32x64xf32>
    %96 = stablehlo.concatenate %95, %95, dim = 2 {mhlo.sharding = "{manual}"} : (tensor<1x32x64xf32>, tensor<1x32x64xf32>) -> tensor<1x32x128xf32>
    %97 = stablehlo.cosine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %98 = stablehlo.convert %97 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %100 = stablehlo.multiply %90, %99 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %101 = stablehlo.slice %90 [0:1, 0:4, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %102 = stablehlo.negate %101 {mhlo.sharding = "{manual}"} : tensor<1x4x32x64xbf16>
    %103 = stablehlo.slice %90 [0:1, 0:4, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %104 = stablehlo.concatenate %102, %103, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x4x32x64xbf16>, tensor<1x4x32x64xbf16>) -> tensor<1x4x32x128xbf16>
    %105 = stablehlo.sine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %106 = stablehlo.convert %105 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %107 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %108 = stablehlo.multiply %104, %107 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %109 = stablehlo.add %100, %108 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %110 = "stablehlo.scatter"(%13, %58, %109) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %111 = stablehlo.reshape %15 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %112 = stablehlo.reshape %111 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %113 = stablehlo.transpose %112, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %114 = stablehlo.dot_general %84, %113, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %115 = stablehlo.reshape %114 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %116 = stablehlo.transpose %115, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %117 = "stablehlo.scatter"(%17, %58, %116) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %118 = stablehlo.reshape %37 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %119 = stablehlo.reshape %118 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %120 = stablehlo.broadcast_in_dim %119, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %121 = stablehlo.reshape %31 {mhlo.sharding = "{manual}"} : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16>
    %122 = stablehlo.reshape %121 {mhlo.sharding = "{manual}"} : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %123 = stablehlo.transpose %122, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
    %124 = stablehlo.dot_general %84, %123, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<32x1536xbf16>
    %125 = stablehlo.reshape %124 {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>) -> tensor<1x32x12x128xbf16>
    %126 = stablehlo.transpose %125, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,32,128]{3,1,2,0}"} : (tensor<1x32x12x128xbf16>) -> tensor<1x12x32x128xbf16>
    %127 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %128 = stablehlo.multiply %126, %127 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %129 = stablehlo.slice %126 [0:1, 0:12, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %130 = stablehlo.negate %129 {mhlo.sharding = "{manual}"} : tensor<1x12x32x64xbf16>
    %131 = stablehlo.slice %126 [0:1, 0:12, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %132 = stablehlo.concatenate %130, %131, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x64xbf16>, tensor<1x12x32x64xbf16>) -> tensor<1x12x32x128xbf16>
    %133 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %134 = stablehlo.multiply %132, %133 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %135 = stablehlo.add %128, %134 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %136 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %137 = stablehlo.reshape %136 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %138 = stablehlo.transpose %137, dims = [0, 1, 3, 2] {mhlo.sharding = "{manual}", result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %139 = stablehlo.dot_general %135, %138, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %140 = stablehlo.multiply %139, %47 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %141 = stablehlo.broadcast_in_dim %29, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<128xi1>
    %142 = stablehlo.and %141, %c_7 {mhlo.sharding = "{manual}"} : tensor<128xi1>
    %143 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x1x128xi1>
    %144 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x128xi1>
    %145 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %146 = stablehlo.not %143 {mhlo.sharding = "{manual}"} : tensor<1x1x1x128xi1>
    %147 = stablehlo.reshape %146 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x128xi1>) -> tensor<1x1x128xi1>
    %148 = stablehlo.broadcast_in_dim %147, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %149 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %150 = stablehlo.broadcast_in_dim %c_0, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %151 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %152 = stablehlo.subtract %151, %150 {mhlo.sharding = "{manual}"} : tensor<32x128xi64>
    %153 = stablehlo.compare  GE, %152, %45 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %154 = stablehlo.select %153, %44, %43 {mhlo.sharding = "{manual}"} : tensor<32x128xi1>, tensor<32x128xbf16>
    %155 = stablehlo.broadcast_in_dim %54, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %156 = stablehlo.compare  GT, %149, %155 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %157 = stablehlo.convert %156 {mhlo.sharding = "{manual}"} : (tensor<32x128xi1>) -> tensor<32x128xbf16>
    %158 = stablehlo.multiply %154, %157 {mhlo.sharding = "{manual}"} : tensor<32x128xbf16>
    %159 = stablehlo.reshape %158 {mhlo.sharding = "{manual}"} : (tensor<32x128xbf16>) -> tensor<1x1x32x128xbf16>
    %160 = stablehlo.slice %159 [0:1, 0:1, 0:32, 0:32] {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x1x32x32xbf16>
    %161 = stablehlo.reshape %27 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %162 = stablehlo.reshape %161 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64>
    %163 = stablehlo.convert %162 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16>
    %164 = stablehlo.reshape %163 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32xbf16>
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x32xbf16>) -> tensor<1x1x32x32xbf16>
    %166 = stablehlo.add %160, %165 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xbf16>
    %167 = stablehlo.compare  EQ, %166, %42 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xi1>
    %168 = stablehlo.select %167, %41, %160 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xi1>, tensor<1x1x32x32xbf16>
    %169 = stablehlo.floor %cst_12 {mhlo.sharding = "{manual}"} : tensor<128xf32>
    %170 = stablehlo.convert %169 {mhlo.sharding = "{manual}"} : (tensor<128xf32>) -> tensor<128xi64>
    %171 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %172 = stablehlo.clamp %171, %170, %39 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %173 = stablehlo.compare  LT, %172, %40 {mhlo.sharding = "{manual}"} : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1>
    %174 = stablehlo.add %172, %38 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %175 = stablehlo.select %173, %174, %172 {mhlo.sharding = "{manual}"} : tensor<128xi1>, tensor<128xi64>
    %176 = stablehlo.reshape %175 {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<128x1xi64>
    %177 = "stablehlo.gather"(%168, %176) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 32, 1>}> {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x32x128xbf16>
    %178 = stablehlo.select %148, %46, %177 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %179 = stablehlo.select %145, %178, %159 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %180 = stablehlo.reshape %179 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x32x128xbf16>
    %181 = stablehlo.broadcast_in_dim %180, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %182 = stablehlo.add %140, %181 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %183 = stablehlo.convert %182 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xf32>
    %184 = stablehlo.reduce(%183 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %185 = stablehlo.broadcast_in_dim %184, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %186 = stablehlo.subtract %183, %185 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %187 = stablehlo.exponential %186 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %188 = stablehlo.reduce(%187 init: %cst) applies stablehlo.add across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %189 = stablehlo.broadcast_in_dim %188, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %190 = stablehlo.divide %187, %189 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %191 = stablehlo.convert %190 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>) -> tensor<1x12x32x128xbf16>
    %192 = stablehlo.broadcast_in_dim %117, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %193 = stablehlo.reshape %192 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %194 = stablehlo.dot_general %191, %193, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %195 = stablehlo.transpose %194, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,32,24,128]{3,1,2,0}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x32x12x128xbf16>
    %196 = stablehlo.reshape %195 {mhlo.sharding = "{manual}"} : (tensor<1x32x12x128xbf16>) -> tensor<32x1536xbf16>
    %197 = stablehlo.reshape %25 {mhlo.sharding = "{manual}"} : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16>
    %198 = stablehlo.reshape %197 {mhlo.sharding = "{manual}"} : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %199 = stablehlo.transpose %198, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
    %200 = stablehlo.dot_general %196, %199, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<32x3072xbf16>
    %201 = "stablehlo.all_reduce"(%200) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %202 = stablehlo.reshape %201 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %203 = stablehlo.add %68, %202 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %204 = stablehlo.reshape %33 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %205 = stablehlo.reshape %204 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %206 = stablehlo.broadcast_in_dim %205, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %207 = stablehlo.convert %203 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %208 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %209 = stablehlo.power %207, %208 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %210 = stablehlo.reduce(%209 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %211 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %212 = stablehlo.multiply %210, %211 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %213 = stablehlo.reshape %212 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %214 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %215 = stablehlo.add %213, %214 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %216 = stablehlo.rsqrt %215 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %217 = stablehlo.reshape %216 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %218 = stablehlo.broadcast_in_dim %217, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %219 = stablehlo.multiply %207, %218 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %220 = stablehlo.convert %219 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %221 = stablehlo.multiply %206, %220 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %222 = stablehlo.reshape %221 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %223 = stablehlo.reshape %35 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %224 = stablehlo.reshape %223 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %225 = stablehlo.transpose %224, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %226 = stablehlo.dot_general %222, %225, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %227 = stablehlo.reshape %226 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %228 = stablehlo.logistic %227 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %229 = stablehlo.multiply %227, %228 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %230 = stablehlo.reshape %23 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %231 = stablehlo.reshape %230 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %232 = stablehlo.transpose %231, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %233 = stablehlo.dot_general %222, %232, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %234 = stablehlo.reshape %233 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %235 = stablehlo.multiply %229, %234 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %236 = stablehlo.reshape %235 {mhlo.sharding = "{manual}"} : (tensor<1x32x4096xbf16>) -> tensor<32x4096xbf16>
    %237 = stablehlo.reshape %21 {mhlo.sharding = "{manual}"} : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16>
    %238 = stablehlo.reshape %237 {mhlo.sharding = "{manual}"} : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %239 = stablehlo.transpose %238, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
    %240 = stablehlo.dot_general %236, %239, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<32x3072xbf16>
    %241 = "stablehlo.all_reduce"(%240) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %242 = stablehlo.reshape %241 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %243 = stablehlo.add %203, %242 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %244 = stablehlo.convert %243 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %245 = stablehlo.power %244, %50 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %246 = stablehlo.reduce(%245 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %247 = stablehlo.multiply %246, %49 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %248 = stablehlo.reshape %247 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %249 = stablehlo.add %248, %48 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %250 = stablehlo.rsqrt %249 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %251 = stablehlo.reshape %250 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %252 = stablehlo.broadcast_in_dim %251, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %253 = stablehlo.multiply %244, %252 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %254 = stablehlo.convert %253 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %255 = stablehlo.multiply %120, %254 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %256 = stablehlo.reshape %255 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %257 = stablehlo.reshape %19 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %258 = stablehlo.reshape %257 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %259 = stablehlo.transpose %258, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %260 = stablehlo.dot_general %256, %259, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<32x128256xbf16>
    %261 = stablehlo.reshape %260 {mhlo.sharding = "{manual}"} : (tensor<32x128256xbf16>) -> tensor<1x32x128256xbf16>
    %262 = mhlo.copy %110 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %263 = stablehlo.custom_call @SPMDShardToFullShape(%262) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %264 = mhlo.copy %117 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %265 = stablehlo.custom_call @SPMDShardToFullShape(%264) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %266 = mhlo.copy %260 {mhlo.sharding = "{manual}"} : tensor<32x128256xbf16>
    %267 = stablehlo.custom_call @SPMDShardToFullShape(%266) {mhlo.sharding = "{replicated}"} : (tensor<32x128256xbf16>) -> tensor<32x128256xbf16>
    %268 = mhlo.copy %261 {mhlo.sharding = "{manual}"} : tensor<1x32x128256xbf16>
    %269 = stablehlo.custom_call @SPMDShardToFullShape(%268) {mhlo.sharding = "{replicated}"} : (tensor<1x32x128256xbf16>) -> tensor<1x32x128256xbf16>
    return %263, %265, %267, %269 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>
  }
}


2026-01-02 18:37:37.198 (   8.257s) [        CBC3A000] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-02 18:37:37.198 (   8.257s) [        CBC3A000] executable_instance.cc:179      1| Literal MLIR code (size=40801):

module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, mhlo.spmd_output_sharding="{{devices=[1,2,1,1]<=[2]},{devices=[1,2,1,1]<=[2]},{replicated},{replicated}}"
} {
  func.func @main(%arg0: tensor<32xi64>, %arg1: tensor<64xf32>, %arg2: tensor<1024x3072xbf16>, %arg3: tensor<1x32xi64>, %arg4: tensor<128256x3072xbf16>, %arg5: tensor<3072xbf16>, %arg6: tensor<1x8x128x128xbf16>, %arg7: tensor<1024x3072xbf16>, %arg8: tensor<1x8x128x128xbf16>, %arg9: tensor<128256x3072xbf16>, %arg10: tensor<3072x8192xbf16>, %arg11: tensor<8192x3072xbf16>, %arg12: tensor<3072x3072xbf16>, %arg13: tensor<1x32xi64>, %arg14: tensor<i1>, %arg15: tensor<3072x3072xbf16>, %arg16: tensor<3072xbf16>, %arg17: tensor<8192x3072xbf16>, %arg18: tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>) {
    %0 = mhlo.copy %arg0 {mhlo.sharding = "{replicated}"} : tensor<32xi64>
    %1 = stablehlo.custom_call @SPMDFullToShardShape(%0) {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xi64>
    %2 = mhlo.copy %arg1 {mhlo.sharding = "{replicated}"} : tensor<64xf32>
    %3 = stablehlo.custom_call @SPMDFullToShardShape(%2) {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<64xf32>
    %4 = mhlo.copy %arg2 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %5 = stablehlo.custom_call @SPMDFullToShardShape(%4) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %6 = mhlo.copy %arg3 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %7 = stablehlo.custom_call @SPMDFullToShardShape(%6) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %8 = mhlo.copy %arg4 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %9 = stablehlo.custom_call @SPMDFullToShardShape(%8) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %10 = mhlo.copy %arg5 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %11 = stablehlo.custom_call @SPMDFullToShardShape(%10) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %12 = mhlo.copy %arg6 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %13 = stablehlo.custom_call @SPMDFullToShardShape(%12) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %14 = mhlo.copy %arg7 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %15 = stablehlo.custom_call @SPMDFullToShardShape(%14) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %16 = mhlo.copy %arg8 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %17 = stablehlo.custom_call @SPMDFullToShardShape(%16) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %18 = mhlo.copy %arg9 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %19 = stablehlo.custom_call @SPMDFullToShardShape(%18) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %20 = mhlo.copy %arg10 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x8192xbf16>
    %21 = stablehlo.custom_call @SPMDFullToShardShape(%20) {mhlo.sharding = "{manual}"} : (tensor<3072x8192xbf16>) -> tensor<3072x4096xbf16>
    %22 = mhlo.copy %arg11 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %23 = stablehlo.custom_call @SPMDFullToShardShape(%22) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %24 = mhlo.copy %arg12 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x3072xbf16>
    %25 = stablehlo.custom_call @SPMDFullToShardShape(%24) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<3072x1536xbf16>
    %26 = mhlo.copy %arg13 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %27 = stablehlo.custom_call @SPMDFullToShardShape(%26) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %28 = mhlo.copy %arg14 {mhlo.sharding = "{replicated}"} : tensor<i1>
    %29 = stablehlo.custom_call @SPMDFullToShardShape(%28) {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<i1>
    %30 = mhlo.copy %arg15 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<3072x3072xbf16>
    %31 = stablehlo.custom_call @SPMDFullToShardShape(%30) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<1536x3072xbf16>
    %32 = mhlo.copy %arg16 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %33 = stablehlo.custom_call @SPMDFullToShardShape(%32) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %34 = mhlo.copy %arg17 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %35 = stablehlo.custom_call @SPMDFullToShardShape(%34) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %36 = mhlo.copy %arg18 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %37 = stablehlo.custom_call @SPMDFullToShardShape(%36) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %cst = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"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tensor<128xi64>
    %c_0 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xi64>
    %cst_1 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0xFF800000> : tensor<f32>
    %c_2 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<128> : tensor<i64>
    %cst_3 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<2.000000e+00> : tensor<f32>
    %cst_4 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<3.25520843E-4> : tensor<f32>
    %cst_5 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<9.99999974E-6> : tensor<f32>
    %cst_6 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<8.837890e-02> : tensor<bf16>
    %c_7 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1>
    %c_8 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<1> : tensor<i64>
    %cst_9 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<bf16>
    %cst_10 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<-3.389530e+38> : tensor<bf16>
    %c_11 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0> : tensor<i64>
    %cst_12 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>
    %c_13 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<31> : tensor<i64>
    %c_14 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<32> : tensor<i64>
    %38 = stablehlo.broadcast_in_dim %c_14, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %39 = stablehlo.broadcast_in_dim %c_13, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %40 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %41 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %42 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %43 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %44 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %45 = stablehlo.broadcast_in_dim %c_8, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32x128xi64>
    %46 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x128xbf16>
    %47 = stablehlo.broadcast_in_dim %cst_6, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x12x32x128xbf16>
    %48 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %49 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %50 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %51 = stablehlo.broadcast_in_dim %c_2, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %52 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %53 = stablehlo.reshape %1 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<1x1x32xi64>
    %54 = stablehlo.reshape %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %55 = stablehlo.compare  LT, %54, %52 {mhlo.sharding = "{manual}"} : (tensor<32xi64>, tensor<32xi64>) -> tensor<32xi1>
    %56 = stablehlo.add %54, %51 {mhlo.sharding = "{manual}"} : tensor<32xi64>
    %57 = stablehlo.select %55, %56, %54 {mhlo.sharding = "{manual}"} : tensor<32xi1>, tensor<32xi64>
    %58 = stablehlo.reshape %57 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x1xi64>
    %59 = stablehlo.reshape %11 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %60 = stablehlo.reshape %59 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %62 = stablehlo.reshape %9 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %63 = stablehlo.reshape %62 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %64 = stablehlo.reshape %7 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %65 = stablehlo.reshape %64 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %66 = stablehlo.convert %65 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xui32>
    %67 = "stablehlo.gather"(%63, %66) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>, tensor<32xui32>) -> tensor<32x3072xbf16>
    %68 = stablehlo.reshape %67 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %69 = stablehlo.convert %68 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %70 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %71 = stablehlo.power %69, %70 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %72 = stablehlo.reduce(%71 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %73 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %74 = stablehlo.multiply %72, %73 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %75 = stablehlo.reshape %74 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %76 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %77 = stablehlo.add %75, %76 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %78 = stablehlo.rsqrt %77 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %79 = stablehlo.reshape %78 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %80 = stablehlo.broadcast_in_dim %79, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %81 = stablehlo.multiply %69, %80 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %82 = stablehlo.convert %81 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %83 = stablehlo.multiply %61, %82 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %84 = stablehlo.reshape %83 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %85 = stablehlo.reshape %5 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %86 = stablehlo.reshape %85 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %87 = stablehlo.transpose %86, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %88 = stablehlo.dot_general %84, %87, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %89 = stablehlo.reshape %88 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %90 = stablehlo.transpose %89, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %91 = stablehlo.reshape %3 {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %92 = stablehlo.reshape %91 {mhlo.sharding = "{manual}"} : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %93 = stablehlo.convert %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x32xf32>
    %94 = stablehlo.dot_general %92, %93, batching_dims = [0] x [0], contracting_dims = [2] x [1] {mhlo.sharding = "{manual}"} : (tensor<1x64x1xf32>, tensor<1x1x32xf32>) -> tensor<1x64x32xf32>
    %95 = stablehlo.transpose %94, dims = [0, 2, 1] {mhlo.sharding = "{manual}", result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,32,64]{1,2,0}"} : (tensor<1x64x32xf32>) -> tensor<1x32x64xf32>
    %96 = stablehlo.concatenate %95, %95, dim = 2 {mhlo.sharding = "{manual}"} : (tensor<1x32x64xf32>, tensor<1x32x64xf32>) -> tensor<1x32x128xf32>
    %97 = stablehlo.cosine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %98 = stablehlo.convert %97 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %100 = stablehlo.multiply %90, %99 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %101 = stablehlo.slice %90 [0:1, 0:4, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %102 = stablehlo.negate %101 {mhlo.sharding = "{manual}"} : tensor<1x4x32x64xbf16>
    %103 = stablehlo.slice %90 [0:1, 0:4, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %104 = stablehlo.concatenate %102, %103, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x4x32x64xbf16>, tensor<1x4x32x64xbf16>) -> tensor<1x4x32x128xbf16>
    %105 = stablehlo.sine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %106 = stablehlo.convert %105 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %107 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %108 = stablehlo.multiply %104, %107 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %109 = stablehlo.add %100, %108 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %110 = "stablehlo.scatter"(%13, %58, %109) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %111 = stablehlo.reshape %15 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %112 = stablehlo.reshape %111 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %113 = stablehlo.transpose %112, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %114 = stablehlo.dot_general %84, %113, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %115 = stablehlo.reshape %114 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %116 = stablehlo.transpose %115, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %117 = "stablehlo.scatter"(%17, %58, %116) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %118 = stablehlo.reshape %37 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %119 = stablehlo.reshape %118 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %120 = stablehlo.broadcast_in_dim %119, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %121 = stablehlo.reshape %31 {mhlo.sharding = "{manual}"} : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16>
    %122 = stablehlo.reshape %121 {mhlo.sharding = "{manual}"} : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %123 = stablehlo.transpose %122, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
    %124 = stablehlo.dot_general %84, %123, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<32x1536xbf16>
    %125 = stablehlo.reshape %124 {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>) -> tensor<1x32x12x128xbf16>
    %126 = stablehlo.transpose %125, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,32,128]{3,1,2,0}"} : (tensor<1x32x12x128xbf16>) -> tensor<1x12x32x128xbf16>
    %127 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %128 = stablehlo.multiply %126, %127 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %129 = stablehlo.slice %126 [0:1, 0:12, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %130 = stablehlo.negate %129 {mhlo.sharding = "{manual}"} : tensor<1x12x32x64xbf16>
    %131 = stablehlo.slice %126 [0:1, 0:12, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %132 = stablehlo.concatenate %130, %131, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x64xbf16>, tensor<1x12x32x64xbf16>) -> tensor<1x12x32x128xbf16>
    %133 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %134 = stablehlo.multiply %132, %133 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %135 = stablehlo.add %128, %134 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %136 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %137 = stablehlo.reshape %136 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %138 = stablehlo.transpose %137, dims = [0, 1, 3, 2] {mhlo.sharding = "{manual}", result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %139 = stablehlo.dot_general %135, %138, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %140 = stablehlo.multiply %139, %47 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %141 = stablehlo.broadcast_in_dim %29, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<128xi1>
    %142 = stablehlo.and %141, %c_7 {mhlo.sharding = "{manual}"} : tensor<128xi1>
    %143 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x1x128xi1>
    %144 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x128xi1>
    %145 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %146 = stablehlo.not %143 {mhlo.sharding = "{manual}"} : tensor<1x1x1x128xi1>
    %147 = stablehlo.reshape %146 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x128xi1>) -> tensor<1x1x128xi1>
    %148 = stablehlo.broadcast_in_dim %147, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %149 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %150 = stablehlo.broadcast_in_dim %c_0, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %151 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %152 = stablehlo.subtract %151, %150 {mhlo.sharding = "{manual}"} : tensor<32x128xi64>
    %153 = stablehlo.compare  GE, %152, %45 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %154 = stablehlo.select %153, %44, %43 {mhlo.sharding = "{manual}"} : tensor<32x128xi1>, tensor<32x128xbf16>
    %155 = stablehlo.broadcast_in_dim %54, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %156 = stablehlo.compare  GT, %149, %155 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %157 = stablehlo.convert %156 {mhlo.sharding = "{manual}"} : (tensor<32x128xi1>) -> tensor<32x128xbf16>
    %158 = stablehlo.multiply %154, %157 {mhlo.sharding = "{manual}"} : tensor<32x128xbf16>
    %159 = stablehlo.reshape %158 {mhlo.sharding = "{manual}"} : (tensor<32x128xbf16>) -> tensor<1x1x32x128xbf16>
    %160 = stablehlo.slice %159 [0:1, 0:1, 0:32, 0:32] {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x1x32x32xbf16>
    %161 = stablehlo.reshape %27 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %162 = stablehlo.reshape %161 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64>
    %163 = stablehlo.convert %162 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16>
    %164 = stablehlo.reshape %163 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32xbf16>
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x32xbf16>) -> tensor<1x1x32x32xbf16>
    %166 = stablehlo.add %160, %165 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xbf16>
    %167 = stablehlo.compare  EQ, %166, %42 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xi1>
    %168 = stablehlo.select %167, %41, %160 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xi1>, tensor<1x1x32x32xbf16>
    %169 = stablehlo.floor %cst_12 {mhlo.sharding = "{manual}"} : tensor<128xf32>
    %170 = stablehlo.convert %169 {mhlo.sharding = "{manual}"} : (tensor<128xf32>) -> tensor<128xi64>
    %171 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %172 = stablehlo.clamp %171, %170, %39 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %173 = stablehlo.compare  LT, %172, %40 {mhlo.sharding = "{manual}"} : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1>
    %174 = stablehlo.add %172, %38 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %175 = stablehlo.select %173, %174, %172 {mhlo.sharding = "{manual}"} : tensor<128xi1>, tensor<128xi64>
    %176 = stablehlo.reshape %175 {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<128x1xi64>
    %177 = "stablehlo.gather"(%168, %176) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 32, 1>}> {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x32x128xbf16>
    %178 = stablehlo.select %148, %46, %177 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %179 = stablehlo.select %145, %178, %159 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %180 = stablehlo.reshape %179 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x32x128xbf16>
    %181 = stablehlo.broadcast_in_dim %180, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %182 = stablehlo.add %140, %181 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %183 = stablehlo.convert %182 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xf32>
    %184 = stablehlo.reduce(%183 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %185 = stablehlo.broadcast_in_dim %184, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %186 = stablehlo.subtract %183, %185 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %187 = stablehlo.exponential %186 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %188 = stablehlo.reduce(%187 init: %cst) applies stablehlo.add across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %189 = stablehlo.broadcast_in_dim %188, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %190 = stablehlo.divide %187, %189 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %191 = stablehlo.convert %190 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>) -> tensor<1x12x32x128xbf16>
    %192 = stablehlo.broadcast_in_dim %117, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %193 = stablehlo.reshape %192 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %194 = stablehlo.dot_general %191, %193, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %195 = stablehlo.transpose %194, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,32,24,128]{3,1,2,0}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x32x12x128xbf16>
    %196 = stablehlo.reshape %195 {mhlo.sharding = "{manual}"} : (tensor<1x32x12x128xbf16>) -> tensor<32x1536xbf16>
    %197 = stablehlo.reshape %25 {mhlo.sharding = "{manual}"} : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16>
    %198 = stablehlo.reshape %197 {mhlo.sharding = "{manual}"} : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %199 = stablehlo.transpose %198, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
    %200 = stablehlo.dot_general %196, %199, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<32x3072xbf16>
    %201 = "stablehlo.all_reduce"(%200) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %202 = stablehlo.reshape %201 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %203 = stablehlo.add %68, %202 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %204 = stablehlo.reshape %33 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %205 = stablehlo.reshape %204 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %206 = stablehlo.broadcast_in_dim %205, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %207 = stablehlo.convert %203 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %208 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %209 = stablehlo.power %207, %208 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %210 = stablehlo.reduce(%209 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %211 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %212 = stablehlo.multiply %210, %211 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %213 = stablehlo.reshape %212 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %214 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %215 = stablehlo.add %213, %214 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %216 = stablehlo.rsqrt %215 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %217 = stablehlo.reshape %216 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %218 = stablehlo.broadcast_in_dim %217, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %219 = stablehlo.multiply %207, %218 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %220 = stablehlo.convert %219 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %221 = stablehlo.multiply %206, %220 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %222 = stablehlo.reshape %221 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %223 = stablehlo.reshape %35 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %224 = stablehlo.reshape %223 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %225 = stablehlo.transpose %224, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %226 = stablehlo.dot_general %222, %225, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %227 = stablehlo.reshape %226 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %228 = stablehlo.logistic %227 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %229 = stablehlo.multiply %227, %228 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %230 = stablehlo.reshape %23 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %231 = stablehlo.reshape %230 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %232 = stablehlo.transpose %231, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %233 = stablehlo.dot_general %222, %232, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %234 = stablehlo.reshape %233 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %235 = stablehlo.multiply %229, %234 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %236 = stablehlo.reshape %235 {mhlo.sharding = "{manual}"} : (tensor<1x32x4096xbf16>) -> tensor<32x4096xbf16>
    %237 = stablehlo.reshape %21 {mhlo.sharding = "{manual}"} : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16>
    %238 = stablehlo.reshape %237 {mhlo.sharding = "{manual}"} : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %239 = stablehlo.transpose %238, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
    %240 = stablehlo.dot_general %236, %239, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<32x3072xbf16>
    %241 = "stablehlo.all_reduce"(%240) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %242 = stablehlo.reshape %241 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %243 = stablehlo.add %203, %242 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %244 = stablehlo.convert %243 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %245 = stablehlo.power %244, %50 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %246 = stablehlo.reduce(%245 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %247 = stablehlo.multiply %246, %49 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %248 = stablehlo.reshape %247 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %249 = stablehlo.add %248, %48 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %250 = stablehlo.rsqrt %249 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %251 = stablehlo.reshape %250 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %252 = stablehlo.broadcast_in_dim %251, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %253 = stablehlo.multiply %244, %252 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %254 = stablehlo.convert %253 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %255 = stablehlo.multiply %120, %254 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %256 = stablehlo.reshape %255 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %257 = stablehlo.reshape %19 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %258 = stablehlo.reshape %257 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %259 = stablehlo.transpose %258, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %260 = stablehlo.dot_general %256, %259, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<32x128256xbf16>
    %261 = stablehlo.reshape %260 {mhlo.sharding = "{manual}"} : (tensor<32x128256xbf16>) -> tensor<1x32x128256xbf16>
    %262 = mhlo.copy %110 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %263 = stablehlo.custom_call @SPMDShardToFullShape(%262) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %264 = mhlo.copy %117 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %265 = stablehlo.custom_call @SPMDShardToFullShape(%264) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %266 = mhlo.copy %260 {mhlo.sharding = "{manual}"} : tensor<32x128256xbf16>
    %267 = stablehlo.custom_call @SPMDShardToFullShape(%266) {mhlo.sharding = "{replicated}"} : (tensor<32x128256xbf16>) -> tensor<32x128256xbf16>
    %268 = mhlo.copy %261 {mhlo.sharding = "{manual}"} : tensor<1x32x128256xbf16>
    %269 = stablehlo.custom_call @SPMDShardToFullShape(%268) {mhlo.sharding = "{replicated}"} : (tensor<1x32x128256xbf16>) -> tensor<1x32x128256xbf16>
    return %263, %265, %267, %269 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>
  }
}


2026-01-02 18:37:37.216 (   8.274s) [        CBC3A000] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-02 18:37:37.216 (   8.275s) [        CBC3A000] executable_instance.cc:179      1| Literal MLIR code (size=40801):

module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, mhlo.spmd_output_sharding="{{devices=[1,2,1,1]<=[2]},{devices=[1,2,1,1]<=[2]},{replicated},{replicated}}"
} {
  func.func @main(%arg0: tensor<32xi64>, %arg1: tensor<64xf32>, %arg2: tensor<1024x3072xbf16>, %arg3: tensor<1x32xi64>, %arg4: tensor<128256x3072xbf16>, %arg5: tensor<3072xbf16>, %arg6: tensor<1x8x128x128xbf16>, %arg7: tensor<1024x3072xbf16>, %arg8: tensor<1x8x128x128xbf16>, %arg9: tensor<128256x3072xbf16>, %arg10: tensor<3072x8192xbf16>, %arg11: tensor<8192x3072xbf16>, %arg12: tensor<3072x3072xbf16>, %arg13: tensor<1x32xi64>, %arg14: tensor<i1>, %arg15: tensor<3072x3072xbf16>, %arg16: tensor<3072xbf16>, %arg17: tensor<8192x3072xbf16>, %arg18: tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>) {
    %0 = mhlo.copy %arg0 {mhlo.sharding = "{replicated}"} : tensor<32xi64>
    %1 = stablehlo.custom_call @SPMDFullToShardShape(%0) {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xi64>
    %2 = mhlo.copy %arg1 {mhlo.sharding = "{replicated}"} : tensor<64xf32>
    %3 = stablehlo.custom_call @SPMDFullToShardShape(%2) {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<64xf32>
    %4 = mhlo.copy %arg2 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %5 = stablehlo.custom_call @SPMDFullToShardShape(%4) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %6 = mhlo.copy %arg3 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %7 = stablehlo.custom_call @SPMDFullToShardShape(%6) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %8 = mhlo.copy %arg4 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %9 = stablehlo.custom_call @SPMDFullToShardShape(%8) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %10 = mhlo.copy %arg5 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %11 = stablehlo.custom_call @SPMDFullToShardShape(%10) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %12 = mhlo.copy %arg6 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %13 = stablehlo.custom_call @SPMDFullToShardShape(%12) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %14 = mhlo.copy %arg7 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %15 = stablehlo.custom_call @SPMDFullToShardShape(%14) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %16 = mhlo.copy %arg8 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %17 = stablehlo.custom_call @SPMDFullToShardShape(%16) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %18 = mhlo.copy %arg9 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %19 = stablehlo.custom_call @SPMDFullToShardShape(%18) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %20 = mhlo.copy %arg10 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x8192xbf16>
    %21 = stablehlo.custom_call @SPMDFullToShardShape(%20) {mhlo.sharding = "{manual}"} : (tensor<3072x8192xbf16>) -> tensor<3072x4096xbf16>
    %22 = mhlo.copy %arg11 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %23 = stablehlo.custom_call @SPMDFullToShardShape(%22) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %24 = mhlo.copy %arg12 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x3072xbf16>
    %25 = stablehlo.custom_call @SPMDFullToShardShape(%24) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<3072x1536xbf16>
    %26 = mhlo.copy %arg13 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %27 = stablehlo.custom_call @SPMDFullToShardShape(%26) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %28 = mhlo.copy %arg14 {mhlo.sharding = "{replicated}"} : tensor<i1>
    %29 = stablehlo.custom_call @SPMDFullToShardShape(%28) {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<i1>
    %30 = mhlo.copy %arg15 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<3072x3072xbf16>
    %31 = stablehlo.custom_call @SPMDFullToShardShape(%30) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<1536x3072xbf16>
    %32 = mhlo.copy %arg16 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %33 = stablehlo.custom_call @SPMDFullToShardShape(%32) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %34 = mhlo.copy %arg17 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %35 = stablehlo.custom_call @SPMDFullToShardShape(%34) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %36 = mhlo.copy %arg18 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %37 = stablehlo.custom_call @SPMDFullToShardShape(%36) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %cst = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"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tensor<128xi64>
    %c_0 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xi64>
    %cst_1 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0xFF800000> : tensor<f32>
    %c_2 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<128> : tensor<i64>
    %cst_3 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<2.000000e+00> : tensor<f32>
    %cst_4 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<3.25520843E-4> : tensor<f32>
    %cst_5 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<9.99999974E-6> : tensor<f32>
    %cst_6 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<8.837890e-02> : tensor<bf16>
    %c_7 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1>
    %c_8 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<1> : tensor<i64>
    %cst_9 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<bf16>
    %cst_10 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<-3.389530e+38> : tensor<bf16>
    %c_11 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0> : tensor<i64>
    %cst_12 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>
    %c_13 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<31> : tensor<i64>
    %c_14 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<32> : tensor<i64>
    %38 = stablehlo.broadcast_in_dim %c_14, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %39 = stablehlo.broadcast_in_dim %c_13, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %40 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %41 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %42 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %43 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %44 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %45 = stablehlo.broadcast_in_dim %c_8, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32x128xi64>
    %46 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x128xbf16>
    %47 = stablehlo.broadcast_in_dim %cst_6, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x12x32x128xbf16>
    %48 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %49 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %50 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %51 = stablehlo.broadcast_in_dim %c_2, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %52 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %53 = stablehlo.reshape %1 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<1x1x32xi64>
    %54 = stablehlo.reshape %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %55 = stablehlo.compare  LT, %54, %52 {mhlo.sharding = "{manual}"} : (tensor<32xi64>, tensor<32xi64>) -> tensor<32xi1>
    %56 = stablehlo.add %54, %51 {mhlo.sharding = "{manual}"} : tensor<32xi64>
    %57 = stablehlo.select %55, %56, %54 {mhlo.sharding = "{manual}"} : tensor<32xi1>, tensor<32xi64>
    %58 = stablehlo.reshape %57 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x1xi64>
    %59 = stablehlo.reshape %11 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %60 = stablehlo.reshape %59 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %62 = stablehlo.reshape %9 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %63 = stablehlo.reshape %62 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %64 = stablehlo.reshape %7 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %65 = stablehlo.reshape %64 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %66 = stablehlo.convert %65 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xui32>
    %67 = "stablehlo.gather"(%63, %66) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>, tensor<32xui32>) -> tensor<32x3072xbf16>
    %68 = stablehlo.reshape %67 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %69 = stablehlo.convert %68 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %70 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %71 = stablehlo.power %69, %70 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %72 = stablehlo.reduce(%71 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %73 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %74 = stablehlo.multiply %72, %73 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %75 = stablehlo.reshape %74 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %76 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %77 = stablehlo.add %75, %76 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %78 = stablehlo.rsqrt %77 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %79 = stablehlo.reshape %78 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %80 = stablehlo.broadcast_in_dim %79, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %81 = stablehlo.multiply %69, %80 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %82 = stablehlo.convert %81 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %83 = stablehlo.multiply %61, %82 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %84 = stablehlo.reshape %83 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %85 = stablehlo.reshape %5 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %86 = stablehlo.reshape %85 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %87 = stablehlo.transpose %86, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %88 = stablehlo.dot_general %84, %87, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %89 = stablehlo.reshape %88 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %90 = stablehlo.transpose %89, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %91 = stablehlo.reshape %3 {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %92 = stablehlo.reshape %91 {mhlo.sharding = "{manual}"} : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %93 = stablehlo.convert %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x32xf32>
    %94 = stablehlo.dot_general %92, %93, batching_dims = [0] x [0], contracting_dims = [2] x [1] {mhlo.sharding = "{manual}"} : (tensor<1x64x1xf32>, tensor<1x1x32xf32>) -> tensor<1x64x32xf32>
    %95 = stablehlo.transpose %94, dims = [0, 2, 1] {mhlo.sharding = "{manual}", result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,32,64]{1,2,0}"} : (tensor<1x64x32xf32>) -> tensor<1x32x64xf32>
    %96 = stablehlo.concatenate %95, %95, dim = 2 {mhlo.sharding = "{manual}"} : (tensor<1x32x64xf32>, tensor<1x32x64xf32>) -> tensor<1x32x128xf32>
    %97 = stablehlo.cosine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %98 = stablehlo.convert %97 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %100 = stablehlo.multiply %90, %99 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %101 = stablehlo.slice %90 [0:1, 0:4, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %102 = stablehlo.negate %101 {mhlo.sharding = "{manual}"} : tensor<1x4x32x64xbf16>
    %103 = stablehlo.slice %90 [0:1, 0:4, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %104 = stablehlo.concatenate %102, %103, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x4x32x64xbf16>, tensor<1x4x32x64xbf16>) -> tensor<1x4x32x128xbf16>
    %105 = stablehlo.sine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %106 = stablehlo.convert %105 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %107 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %108 = stablehlo.multiply %104, %107 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %109 = stablehlo.add %100, %108 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %110 = "stablehlo.scatter"(%13, %58, %109) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %111 = stablehlo.reshape %15 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %112 = stablehlo.reshape %111 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %113 = stablehlo.transpose %112, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %114 = stablehlo.dot_general %84, %113, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %115 = stablehlo.reshape %114 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %116 = stablehlo.transpose %115, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %117 = "stablehlo.scatter"(%17, %58, %116) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %118 = stablehlo.reshape %37 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %119 = stablehlo.reshape %118 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %120 = stablehlo.broadcast_in_dim %119, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %121 = stablehlo.reshape %31 {mhlo.sharding = "{manual}"} : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16>
    %122 = stablehlo.reshape %121 {mhlo.sharding = "{manual}"} : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %123 = stablehlo.transpose %122, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
    %124 = stablehlo.dot_general %84, %123, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<32x1536xbf16>
    %125 = stablehlo.reshape %124 {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>) -> tensor<1x32x12x128xbf16>
    %126 = stablehlo.transpose %125, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,32,128]{3,1,2,0}"} : (tensor<1x32x12x128xbf16>) -> tensor<1x12x32x128xbf16>
    %127 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %128 = stablehlo.multiply %126, %127 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %129 = stablehlo.slice %126 [0:1, 0:12, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %130 = stablehlo.negate %129 {mhlo.sharding = "{manual}"} : tensor<1x12x32x64xbf16>
    %131 = stablehlo.slice %126 [0:1, 0:12, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %132 = stablehlo.concatenate %130, %131, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x64xbf16>, tensor<1x12x32x64xbf16>) -> tensor<1x12x32x128xbf16>
    %133 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %134 = stablehlo.multiply %132, %133 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %135 = stablehlo.add %128, %134 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %136 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %137 = stablehlo.reshape %136 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %138 = stablehlo.transpose %137, dims = [0, 1, 3, 2] {mhlo.sharding = "{manual}", result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %139 = stablehlo.dot_general %135, %138, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %140 = stablehlo.multiply %139, %47 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %141 = stablehlo.broadcast_in_dim %29, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<128xi1>
    %142 = stablehlo.and %141, %c_7 {mhlo.sharding = "{manual}"} : tensor<128xi1>
    %143 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x1x128xi1>
    %144 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x128xi1>
    %145 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %146 = stablehlo.not %143 {mhlo.sharding = "{manual}"} : tensor<1x1x1x128xi1>
    %147 = stablehlo.reshape %146 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x128xi1>) -> tensor<1x1x128xi1>
    %148 = stablehlo.broadcast_in_dim %147, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %149 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %150 = stablehlo.broadcast_in_dim %c_0, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %151 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %152 = stablehlo.subtract %151, %150 {mhlo.sharding = "{manual}"} : tensor<32x128xi64>
    %153 = stablehlo.compare  GE, %152, %45 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %154 = stablehlo.select %153, %44, %43 {mhlo.sharding = "{manual}"} : tensor<32x128xi1>, tensor<32x128xbf16>
    %155 = stablehlo.broadcast_in_dim %54, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %156 = stablehlo.compare  GT, %149, %155 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %157 = stablehlo.convert %156 {mhlo.sharding = "{manual}"} : (tensor<32x128xi1>) -> tensor<32x128xbf16>
    %158 = stablehlo.multiply %154, %157 {mhlo.sharding = "{manual}"} : tensor<32x128xbf16>
    %159 = stablehlo.reshape %158 {mhlo.sharding = "{manual}"} : (tensor<32x128xbf16>) -> tensor<1x1x32x128xbf16>
    %160 = stablehlo.slice %159 [0:1, 0:1, 0:32, 0:32] {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x1x32x32xbf16>
    %161 = stablehlo.reshape %27 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %162 = stablehlo.reshape %161 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64>
    %163 = stablehlo.convert %162 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16>
    %164 = stablehlo.reshape %163 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32xbf16>
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x32xbf16>) -> tensor<1x1x32x32xbf16>
    %166 = stablehlo.add %160, %165 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xbf16>
    %167 = stablehlo.compare  EQ, %166, %42 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xi1>
    %168 = stablehlo.select %167, %41, %160 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xi1>, tensor<1x1x32x32xbf16>
    %169 = stablehlo.floor %cst_12 {mhlo.sharding = "{manual}"} : tensor<128xf32>
    %170 = stablehlo.convert %169 {mhlo.sharding = "{manual}"} : (tensor<128xf32>) -> tensor<128xi64>
    %171 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %172 = stablehlo.clamp %171, %170, %39 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %173 = stablehlo.compare  LT, %172, %40 {mhlo.sharding = "{manual}"} : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1>
    %174 = stablehlo.add %172, %38 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %175 = stablehlo.select %173, %174, %172 {mhlo.sharding = "{manual}"} : tensor<128xi1>, tensor<128xi64>
    %176 = stablehlo.reshape %175 {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<128x1xi64>
    %177 = "stablehlo.gather"(%168, %176) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 32, 1>}> {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x32x128xbf16>
    %178 = stablehlo.select %148, %46, %177 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %179 = stablehlo.select %145, %178, %159 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %180 = stablehlo.reshape %179 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x32x128xbf16>
    %181 = stablehlo.broadcast_in_dim %180, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %182 = stablehlo.add %140, %181 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %183 = stablehlo.convert %182 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xf32>
    %184 = stablehlo.reduce(%183 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %185 = stablehlo.broadcast_in_dim %184, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %186 = stablehlo.subtract %183, %185 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %187 = stablehlo.exponential %186 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %188 = stablehlo.reduce(%187 init: %cst) applies stablehlo.add across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %189 = stablehlo.broadcast_in_dim %188, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %190 = stablehlo.divide %187, %189 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %191 = stablehlo.convert %190 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>) -> tensor<1x12x32x128xbf16>
    %192 = stablehlo.broadcast_in_dim %117, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %193 = stablehlo.reshape %192 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %194 = stablehlo.dot_general %191, %193, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %195 = stablehlo.transpose %194, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,32,24,128]{3,1,2,0}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x32x12x128xbf16>
    %196 = stablehlo.reshape %195 {mhlo.sharding = "{manual}"} : (tensor<1x32x12x128xbf16>) -> tensor<32x1536xbf16>
    %197 = stablehlo.reshape %25 {mhlo.sharding = "{manual}"} : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16>
    %198 = stablehlo.reshape %197 {mhlo.sharding = "{manual}"} : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %199 = stablehlo.transpose %198, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
    %200 = stablehlo.dot_general %196, %199, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<32x3072xbf16>
    %201 = "stablehlo.all_reduce"(%200) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %202 = stablehlo.reshape %201 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %203 = stablehlo.add %68, %202 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %204 = stablehlo.reshape %33 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %205 = stablehlo.reshape %204 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %206 = stablehlo.broadcast_in_dim %205, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %207 = stablehlo.convert %203 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %208 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %209 = stablehlo.power %207, %208 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %210 = stablehlo.reduce(%209 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %211 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %212 = stablehlo.multiply %210, %211 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %213 = stablehlo.reshape %212 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %214 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %215 = stablehlo.add %213, %214 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %216 = stablehlo.rsqrt %215 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %217 = stablehlo.reshape %216 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %218 = stablehlo.broadcast_in_dim %217, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %219 = stablehlo.multiply %207, %218 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %220 = stablehlo.convert %219 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %221 = stablehlo.multiply %206, %220 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %222 = stablehlo.reshape %221 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %223 = stablehlo.reshape %35 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %224 = stablehlo.reshape %223 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %225 = stablehlo.transpose %224, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %226 = stablehlo.dot_general %222, %225, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %227 = stablehlo.reshape %226 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %228 = stablehlo.logistic %227 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %229 = stablehlo.multiply %227, %228 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %230 = stablehlo.reshape %23 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %231 = stablehlo.reshape %230 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %232 = stablehlo.transpose %231, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %233 = stablehlo.dot_general %222, %232, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %234 = stablehlo.reshape %233 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %235 = stablehlo.multiply %229, %234 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %236 = stablehlo.reshape %235 {mhlo.sharding = "{manual}"} : (tensor<1x32x4096xbf16>) -> tensor<32x4096xbf16>
    %237 = stablehlo.reshape %21 {mhlo.sharding = "{manual}"} : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16>
    %238 = stablehlo.reshape %237 {mhlo.sharding = "{manual}"} : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %239 = stablehlo.transpose %238, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
    %240 = stablehlo.dot_general %236, %239, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<32x3072xbf16>
    %241 = "stablehlo.all_reduce"(%240) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %242 = stablehlo.reshape %241 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %243 = stablehlo.add %203, %242 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %244 = stablehlo.convert %243 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %245 = stablehlo.power %244, %50 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %246 = stablehlo.reduce(%245 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %247 = stablehlo.multiply %246, %49 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %248 = stablehlo.reshape %247 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %249 = stablehlo.add %248, %48 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %250 = stablehlo.rsqrt %249 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %251 = stablehlo.reshape %250 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %252 = stablehlo.broadcast_in_dim %251, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %253 = stablehlo.multiply %244, %252 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %254 = stablehlo.convert %253 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %255 = stablehlo.multiply %120, %254 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %256 = stablehlo.reshape %255 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %257 = stablehlo.reshape %19 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %258 = stablehlo.reshape %257 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %259 = stablehlo.transpose %258, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %260 = stablehlo.dot_general %256, %259, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<32x128256xbf16>
    %261 = stablehlo.reshape %260 {mhlo.sharding = "{manual}"} : (tensor<32x128256xbf16>) -> tensor<1x32x128256xbf16>
    %262 = mhlo.copy %110 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %263 = stablehlo.custom_call @SPMDShardToFullShape(%262) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %264 = mhlo.copy %117 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %265 = stablehlo.custom_call @SPMDShardToFullShape(%264) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %266 = mhlo.copy %260 {mhlo.sharding = "{manual}"} : tensor<32x128256xbf16>
    %267 = stablehlo.custom_call @SPMDShardToFullShape(%266) {mhlo.sharding = "{replicated}"} : (tensor<32x128256xbf16>) -> tensor<32x128256xbf16>
    %268 = mhlo.copy %261 {mhlo.sharding = "{manual}"} : tensor<1x32x128256xbf16>
    %269 = stablehlo.custom_call @SPMDShardToFullShape(%268) {mhlo.sharding = "{replicated}"} : (tensor<1x32x128256xbf16>) -> tensor<1x32x128256xbf16>
    return %263, %265, %267, %269 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>
  }
}


2026-01-02 18:37:37.216 (   8.275s) [        CBC3A000] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-02 18:37:37.216 (   8.275s) [        CBC3A000] executable_instance.cc:179      1| Literal MLIR code (size=40801):

module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, mhlo.spmd_output_sharding="{{devices=[1,2,1,1]<=[2]},{devices=[1,2,1,1]<=[2]},{replicated},{replicated}}"
} {
  func.func @main(%arg0: tensor<32xi64>, %arg1: tensor<64xf32>, %arg2: tensor<1024x3072xbf16>, %arg3: tensor<1x32xi64>, %arg4: tensor<128256x3072xbf16>, %arg5: tensor<3072xbf16>, %arg6: tensor<1x8x128x128xbf16>, %arg7: tensor<1024x3072xbf16>, %arg8: tensor<1x8x128x128xbf16>, %arg9: tensor<128256x3072xbf16>, %arg10: tensor<3072x8192xbf16>, %arg11: tensor<8192x3072xbf16>, %arg12: tensor<3072x3072xbf16>, %arg13: tensor<1x32xi64>, %arg14: tensor<i1>, %arg15: tensor<3072x3072xbf16>, %arg16: tensor<3072xbf16>, %arg17: tensor<8192x3072xbf16>, %arg18: tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>) {
    %0 = mhlo.copy %arg0 {mhlo.sharding = "{replicated}"} : tensor<32xi64>
    %1 = stablehlo.custom_call @SPMDFullToShardShape(%0) {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xi64>
    %2 = mhlo.copy %arg1 {mhlo.sharding = "{replicated}"} : tensor<64xf32>
    %3 = stablehlo.custom_call @SPMDFullToShardShape(%2) {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<64xf32>
    %4 = mhlo.copy %arg2 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %5 = stablehlo.custom_call @SPMDFullToShardShape(%4) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %6 = mhlo.copy %arg3 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %7 = stablehlo.custom_call @SPMDFullToShardShape(%6) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %8 = mhlo.copy %arg4 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %9 = stablehlo.custom_call @SPMDFullToShardShape(%8) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %10 = mhlo.copy %arg5 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %11 = stablehlo.custom_call @SPMDFullToShardShape(%10) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %12 = mhlo.copy %arg6 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %13 = stablehlo.custom_call @SPMDFullToShardShape(%12) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %14 = mhlo.copy %arg7 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %15 = stablehlo.custom_call @SPMDFullToShardShape(%14) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %16 = mhlo.copy %arg8 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %17 = stablehlo.custom_call @SPMDFullToShardShape(%16) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %18 = mhlo.copy %arg9 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %19 = stablehlo.custom_call @SPMDFullToShardShape(%18) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %20 = mhlo.copy %arg10 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x8192xbf16>
    %21 = stablehlo.custom_call @SPMDFullToShardShape(%20) {mhlo.sharding = "{manual}"} : (tensor<3072x8192xbf16>) -> tensor<3072x4096xbf16>
    %22 = mhlo.copy %arg11 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %23 = stablehlo.custom_call @SPMDFullToShardShape(%22) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %24 = mhlo.copy %arg12 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x3072xbf16>
    %25 = stablehlo.custom_call @SPMDFullToShardShape(%24) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<3072x1536xbf16>
    %26 = mhlo.copy %arg13 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %27 = stablehlo.custom_call @SPMDFullToShardShape(%26) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %28 = mhlo.copy %arg14 {mhlo.sharding = "{replicated}"} : tensor<i1>
    %29 = stablehlo.custom_call @SPMDFullToShardShape(%28) {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<i1>
    %30 = mhlo.copy %arg15 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<3072x3072xbf16>
    %31 = stablehlo.custom_call @SPMDFullToShardShape(%30) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<1536x3072xbf16>
    %32 = mhlo.copy %arg16 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %33 = stablehlo.custom_call @SPMDFullToShardShape(%32) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %34 = mhlo.copy %arg17 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %35 = stablehlo.custom_call @SPMDFullToShardShape(%34) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %36 = mhlo.copy %arg18 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %37 = stablehlo.custom_call @SPMDFullToShardShape(%36) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %cst = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"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tensor<128xi64>
    %c_0 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xi64>
    %cst_1 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0xFF800000> : tensor<f32>
    %c_2 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<128> : tensor<i64>
    %cst_3 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<2.000000e+00> : tensor<f32>
    %cst_4 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<3.25520843E-4> : tensor<f32>
    %cst_5 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<9.99999974E-6> : tensor<f32>
    %cst_6 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<8.837890e-02> : tensor<bf16>
    %c_7 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1>
    %c_8 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<1> : tensor<i64>
    %cst_9 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<bf16>
    %cst_10 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<-3.389530e+38> : tensor<bf16>
    %c_11 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0> : tensor<i64>
    %cst_12 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>
    %c_13 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<31> : tensor<i64>
    %c_14 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<32> : tensor<i64>
    %38 = stablehlo.broadcast_in_dim %c_14, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %39 = stablehlo.broadcast_in_dim %c_13, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %40 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %41 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %42 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %43 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %44 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %45 = stablehlo.broadcast_in_dim %c_8, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32x128xi64>
    %46 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x128xbf16>
    %47 = stablehlo.broadcast_in_dim %cst_6, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x12x32x128xbf16>
    %48 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %49 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %50 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %51 = stablehlo.broadcast_in_dim %c_2, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %52 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %53 = stablehlo.reshape %1 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<1x1x32xi64>
    %54 = stablehlo.reshape %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %55 = stablehlo.compare  LT, %54, %52 {mhlo.sharding = "{manual}"} : (tensor<32xi64>, tensor<32xi64>) -> tensor<32xi1>
    %56 = stablehlo.add %54, %51 {mhlo.sharding = "{manual}"} : tensor<32xi64>
    %57 = stablehlo.select %55, %56, %54 {mhlo.sharding = "{manual}"} : tensor<32xi1>, tensor<32xi64>
    %58 = stablehlo.reshape %57 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x1xi64>
    %59 = stablehlo.reshape %11 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %60 = stablehlo.reshape %59 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %62 = stablehlo.reshape %9 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %63 = stablehlo.reshape %62 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %64 = stablehlo.reshape %7 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %65 = stablehlo.reshape %64 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %66 = stablehlo.convert %65 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xui32>
    %67 = "stablehlo.gather"(%63, %66) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>, tensor<32xui32>) -> tensor<32x3072xbf16>
    %68 = stablehlo.reshape %67 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %69 = stablehlo.convert %68 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %70 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %71 = stablehlo.power %69, %70 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %72 = stablehlo.reduce(%71 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %73 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %74 = stablehlo.multiply %72, %73 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %75 = stablehlo.reshape %74 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %76 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %77 = stablehlo.add %75, %76 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %78 = stablehlo.rsqrt %77 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %79 = stablehlo.reshape %78 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %80 = stablehlo.broadcast_in_dim %79, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %81 = stablehlo.multiply %69, %80 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %82 = stablehlo.convert %81 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %83 = stablehlo.multiply %61, %82 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %84 = stablehlo.reshape %83 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %85 = stablehlo.reshape %5 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %86 = stablehlo.reshape %85 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %87 = stablehlo.transpose %86, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %88 = stablehlo.dot_general %84, %87, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %89 = stablehlo.reshape %88 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %90 = stablehlo.transpose %89, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %91 = stablehlo.reshape %3 {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %92 = stablehlo.reshape %91 {mhlo.sharding = "{manual}"} : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %93 = stablehlo.convert %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x32xf32>
    %94 = stablehlo.dot_general %92, %93, batching_dims = [0] x [0], contracting_dims = [2] x [1] {mhlo.sharding = "{manual}"} : (tensor<1x64x1xf32>, tensor<1x1x32xf32>) -> tensor<1x64x32xf32>
    %95 = stablehlo.transpose %94, dims = [0, 2, 1] {mhlo.sharding = "{manual}", result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,32,64]{1,2,0}"} : (tensor<1x64x32xf32>) -> tensor<1x32x64xf32>
    %96 = stablehlo.concatenate %95, %95, dim = 2 {mhlo.sharding = "{manual}"} : (tensor<1x32x64xf32>, tensor<1x32x64xf32>) -> tensor<1x32x128xf32>
    %97 = stablehlo.cosine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %98 = stablehlo.convert %97 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %100 = stablehlo.multiply %90, %99 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %101 = stablehlo.slice %90 [0:1, 0:4, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %102 = stablehlo.negate %101 {mhlo.sharding = "{manual}"} : tensor<1x4x32x64xbf16>
    %103 = stablehlo.slice %90 [0:1, 0:4, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %104 = stablehlo.concatenate %102, %103, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x4x32x64xbf16>, tensor<1x4x32x64xbf16>) -> tensor<1x4x32x128xbf16>
    %105 = stablehlo.sine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %106 = stablehlo.convert %105 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %107 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %108 = stablehlo.multiply %104, %107 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %109 = stablehlo.add %100, %108 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %110 = "stablehlo.scatter"(%13, %58, %109) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %111 = stablehlo.reshape %15 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %112 = stablehlo.reshape %111 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %113 = stablehlo.transpose %112, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %114 = stablehlo.dot_general %84, %113, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %115 = stablehlo.reshape %114 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %116 = stablehlo.transpose %115, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %117 = "stablehlo.scatter"(%17, %58, %116) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %118 = stablehlo.reshape %37 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %119 = stablehlo.reshape %118 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %120 = stablehlo.broadcast_in_dim %119, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %121 = stablehlo.reshape %31 {mhlo.sharding = "{manual}"} : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16>
    %122 = stablehlo.reshape %121 {mhlo.sharding = "{manual}"} : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %123 = stablehlo.transpose %122, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
    %124 = stablehlo.dot_general %84, %123, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<32x1536xbf16>
    %125 = stablehlo.reshape %124 {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>) -> tensor<1x32x12x128xbf16>
    %126 = stablehlo.transpose %125, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,32,128]{3,1,2,0}"} : (tensor<1x32x12x128xbf16>) -> tensor<1x12x32x128xbf16>
    %127 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %128 = stablehlo.multiply %126, %127 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %129 = stablehlo.slice %126 [0:1, 0:12, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %130 = stablehlo.negate %129 {mhlo.sharding = "{manual}"} : tensor<1x12x32x64xbf16>
    %131 = stablehlo.slice %126 [0:1, 0:12, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %132 = stablehlo.concatenate %130, %131, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x64xbf16>, tensor<1x12x32x64xbf16>) -> tensor<1x12x32x128xbf16>
    %133 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %134 = stablehlo.multiply %132, %133 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %135 = stablehlo.add %128, %134 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %136 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %137 = stablehlo.reshape %136 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %138 = stablehlo.transpose %137, dims = [0, 1, 3, 2] {mhlo.sharding = "{manual}", result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %139 = stablehlo.dot_general %135, %138, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %140 = stablehlo.multiply %139, %47 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %141 = stablehlo.broadcast_in_dim %29, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<128xi1>
    %142 = stablehlo.and %141, %c_7 {mhlo.sharding = "{manual}"} : tensor<128xi1>
    %143 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x1x128xi1>
    %144 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x128xi1>
    %145 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %146 = stablehlo.not %143 {mhlo.sharding = "{manual}"} : tensor<1x1x1x128xi1>
    %147 = stablehlo.reshape %146 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x128xi1>) -> tensor<1x1x128xi1>
    %148 = stablehlo.broadcast_in_dim %147, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %149 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %150 = stablehlo.broadcast_in_dim %c_0, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %151 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %152 = stablehlo.subtract %151, %150 {mhlo.sharding = "{manual}"} : tensor<32x128xi64>
    %153 = stablehlo.compare  GE, %152, %45 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %154 = stablehlo.select %153, %44, %43 {mhlo.sharding = "{manual}"} : tensor<32x128xi1>, tensor<32x128xbf16>
    %155 = stablehlo.broadcast_in_dim %54, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %156 = stablehlo.compare  GT, %149, %155 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %157 = stablehlo.convert %156 {mhlo.sharding = "{manual}"} : (tensor<32x128xi1>) -> tensor<32x128xbf16>
    %158 = stablehlo.multiply %154, %157 {mhlo.sharding = "{manual}"} : tensor<32x128xbf16>
    %159 = stablehlo.reshape %158 {mhlo.sharding = "{manual}"} : (tensor<32x128xbf16>) -> tensor<1x1x32x128xbf16>
    %160 = stablehlo.slice %159 [0:1, 0:1, 0:32, 0:32] {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x1x32x32xbf16>
    %161 = stablehlo.reshape %27 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %162 = stablehlo.reshape %161 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64>
    %163 = stablehlo.convert %162 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16>
    %164 = stablehlo.reshape %163 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32xbf16>
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x32xbf16>) -> tensor<1x1x32x32xbf16>
    %166 = stablehlo.add %160, %165 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xbf16>
    %167 = stablehlo.compare  EQ, %166, %42 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xi1>
    %168 = stablehlo.select %167, %41, %160 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xi1>, tensor<1x1x32x32xbf16>
    %169 = stablehlo.floor %cst_12 {mhlo.sharding = "{manual}"} : tensor<128xf32>
    %170 = stablehlo.convert %169 {mhlo.sharding = "{manual}"} : (tensor<128xf32>) -> tensor<128xi64>
    %171 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %172 = stablehlo.clamp %171, %170, %39 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %173 = stablehlo.compare  LT, %172, %40 {mhlo.sharding = "{manual}"} : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1>
    %174 = stablehlo.add %172, %38 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %175 = stablehlo.select %173, %174, %172 {mhlo.sharding = "{manual}"} : tensor<128xi1>, tensor<128xi64>
    %176 = stablehlo.reshape %175 {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<128x1xi64>
    %177 = "stablehlo.gather"(%168, %176) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 32, 1>}> {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x32x128xbf16>
    %178 = stablehlo.select %148, %46, %177 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %179 = stablehlo.select %145, %178, %159 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %180 = stablehlo.reshape %179 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x32x128xbf16>
    %181 = stablehlo.broadcast_in_dim %180, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %182 = stablehlo.add %140, %181 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %183 = stablehlo.convert %182 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xf32>
    %184 = stablehlo.reduce(%183 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %185 = stablehlo.broadcast_in_dim %184, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %186 = stablehlo.subtract %183, %185 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %187 = stablehlo.exponential %186 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %188 = stablehlo.reduce(%187 init: %cst) applies stablehlo.add across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %189 = stablehlo.broadcast_in_dim %188, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %190 = stablehlo.divide %187, %189 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %191 = stablehlo.convert %190 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>) -> tensor<1x12x32x128xbf16>
    %192 = stablehlo.broadcast_in_dim %117, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %193 = stablehlo.reshape %192 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %194 = stablehlo.dot_general %191, %193, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %195 = stablehlo.transpose %194, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,32,24,128]{3,1,2,0}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x32x12x128xbf16>
    %196 = stablehlo.reshape %195 {mhlo.sharding = "{manual}"} : (tensor<1x32x12x128xbf16>) -> tensor<32x1536xbf16>
    %197 = stablehlo.reshape %25 {mhlo.sharding = "{manual}"} : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16>
    %198 = stablehlo.reshape %197 {mhlo.sharding = "{manual}"} : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %199 = stablehlo.transpose %198, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
    %200 = stablehlo.dot_general %196, %199, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<32x3072xbf16>
    %201 = "stablehlo.all_reduce"(%200) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %202 = stablehlo.reshape %201 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %203 = stablehlo.add %68, %202 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %204 = stablehlo.reshape %33 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %205 = stablehlo.reshape %204 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %206 = stablehlo.broadcast_in_dim %205, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %207 = stablehlo.convert %203 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %208 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %209 = stablehlo.power %207, %208 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %210 = stablehlo.reduce(%209 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %211 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %212 = stablehlo.multiply %210, %211 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %213 = stablehlo.reshape %212 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %214 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %215 = stablehlo.add %213, %214 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %216 = stablehlo.rsqrt %215 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %217 = stablehlo.reshape %216 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %218 = stablehlo.broadcast_in_dim %217, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %219 = stablehlo.multiply %207, %218 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %220 = stablehlo.convert %219 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %221 = stablehlo.multiply %206, %220 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %222 = stablehlo.reshape %221 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %223 = stablehlo.reshape %35 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %224 = stablehlo.reshape %223 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %225 = stablehlo.transpose %224, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %226 = stablehlo.dot_general %222, %225, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %227 = stablehlo.reshape %226 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %228 = stablehlo.logistic %227 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %229 = stablehlo.multiply %227, %228 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %230 = stablehlo.reshape %23 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %231 = stablehlo.reshape %230 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %232 = stablehlo.transpose %231, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %233 = stablehlo.dot_general %222, %232, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %234 = stablehlo.reshape %233 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %235 = stablehlo.multiply %229, %234 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %236 = stablehlo.reshape %235 {mhlo.sharding = "{manual}"} : (tensor<1x32x4096xbf16>) -> tensor<32x4096xbf16>
    %237 = stablehlo.reshape %21 {mhlo.sharding = "{manual}"} : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16>
    %238 = stablehlo.reshape %237 {mhlo.sharding = "{manual}"} : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %239 = stablehlo.transpose %238, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
    %240 = stablehlo.dot_general %236, %239, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<32x3072xbf16>
    %241 = "stablehlo.all_reduce"(%240) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %242 = stablehlo.reshape %241 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %243 = stablehlo.add %203, %242 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %244 = stablehlo.convert %243 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %245 = stablehlo.power %244, %50 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %246 = stablehlo.reduce(%245 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %247 = stablehlo.multiply %246, %49 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %248 = stablehlo.reshape %247 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %249 = stablehlo.add %248, %48 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %250 = stablehlo.rsqrt %249 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %251 = stablehlo.reshape %250 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %252 = stablehlo.broadcast_in_dim %251, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %253 = stablehlo.multiply %244, %252 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %254 = stablehlo.convert %253 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %255 = stablehlo.multiply %120, %254 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %256 = stablehlo.reshape %255 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %257 = stablehlo.reshape %19 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %258 = stablehlo.reshape %257 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %259 = stablehlo.transpose %258, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %260 = stablehlo.dot_general %256, %259, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<32x128256xbf16>
    %261 = stablehlo.reshape %260 {mhlo.sharding = "{manual}"} : (tensor<32x128256xbf16>) -> tensor<1x32x128256xbf16>
    %262 = mhlo.copy %110 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %263 = stablehlo.custom_call @SPMDShardToFullShape(%262) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %264 = mhlo.copy %117 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %265 = stablehlo.custom_call @SPMDShardToFullShape(%264) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %266 = mhlo.copy %260 {mhlo.sharding = "{manual}"} : tensor<32x128256xbf16>
    %267 = stablehlo.custom_call @SPMDShardToFullShape(%266) {mhlo.sharding = "{replicated}"} : (tensor<32x128256xbf16>) -> tensor<32x128256xbf16>
    %268 = mhlo.copy %261 {mhlo.sharding = "{manual}"} : tensor<1x32x128256xbf16>
    %269 = stablehlo.custom_call @SPMDShardToFullShape(%268) {mhlo.sharding = "{replicated}"} : (tensor<1x32x128256xbf16>) -> tensor<1x32x128256xbf16>
    return %263, %265, %267, %269 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>
  }
}


2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.290 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640] executable_instance.cc:202      1| ExecutableInstance::PJRT_Executable_NumOutputs
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]loaded_executable_insta:345      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2026-01-02 18:37:37.291 (   8.349s) [        3AFFD640]flatbuffer_loaded_execu:260      1| FlatbufferLoadedExecutableInstance::Execute
2026-01-02 18:37:37.291 (   8.350s) [        3AFFD640]     client_instance.cc:424      1| ClientInstance::getOrCreateMeshDevice - reusing already opened mesh device [1, 2]
2026-01-02 18:37:45.096 (  16.154s) [        3AFFD640]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 0 with shape [1, 8, 128, 128] and UID 524
2026-01-02 18:37:45.096 (  16.154s) [        3AFFD640]flatbuffer_loaded_execu:195      1| Filled output at output_index 0 device_index 1 with shape [1, 8, 128, 128] and UID 525
2026-01-02 18:37:45.096 (  16.154s) [        3AFFD640]flatbuffer_loaded_execu:195      1| Filled output at output_index 1 device_index 0 with shape [1, 8, 128, 128] and UID 526
2026-01-02 18:37:45.096 (  16.154s) [        3AFFD640]flatbuffer_loaded_execu:195      1| Filled output at output_index 1 device_index 1 with shape [1, 8, 128, 128] and UID 527
2026-01-02 18:37:45.096 (  16.154s) [        3AFFD640]flatbuffer_loaded_execu:195      1| Filled output at output_index 2 device_index 0 with shape [32, 128256] and UID 528
2026-01-02 18:37:45.096 (  16.154s) [        3AFFD640]flatbuffer_loaded_execu:195      1| Filled output at output_index 2 device_index 1 with shape [32, 128256] and UID 529
2026-01-02 18:37:45.096 (  16.154s) [        3AFFD640]flatbuffer_loaded_execu:195      1| Filled output at output_index 3 device_index 0 with shape [1, 32, 128256] and UID 530
2026-01-02 18:37:45.096 (  16.154s) [        3AFFD640]flatbuffer_loaded_execu:195      1| Filled output at output_index 3 device_index 1 with shape [1, 32, 128256] and UID 531
2026-01-02 18:37:45.096 (  16.154s) [        3AFFD640]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:45.096 (  16.154s) [        3AFFD640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:576      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-02 18:37:45.096 (  16.155s) [        3AFFD640]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:45.097 (  16.155s) [        3AFFD640]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:45.097 (  16.155s) [        3AFFD640]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:45.097 (  16.155s) [        3AFFD640]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:45.097 (  16.156s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:45.097 (  16.156s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:45.097 (  16.156s) [        CBC3A000]     buffer_instance.cc:564      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2026-01-02 18:37:45.097 (  16.156s) [        CBC3A000]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-02 18:37:45.097 (  16.156s) [        CBC3A000]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.097 (  16.156s) [        CBC3A000]     buffer_instance.cc:586      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2026-01-02 18:37:45.097 (  16.156s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:45.098 (  16.156s) [        9F87B640]     buffer_instance.cc:425      1| Returning tensor to host with host_runtime_tensors ct = 1 from device 0 with buffer UID 530 and shape [1, 32, 128256]
2026-01-02 18:37:45.099 (  16.157s) [        9F07A640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:45.104 (  16.162s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:45.104 (  16.162s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:45.104 (  16.163s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:45.104 (  16.163s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:45.104 (  16.163s) [        CBC3A000]     buffer_instance.cc:564      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2026-01-02 18:37:45.104 (  16.163s) [        CBC3A000]     buffer_instance.cc:545      1| BufferInstance::PJRT_Buffer_ElementType
2026-01-02 18:37:45.104 (  16.163s) [        CBC3A000]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Dimensions
2026-01-02 18:37:45.104 (  16.163s) [        CBC3A000]     buffer_instance.cc:586      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2026-01-02 18:37:45.104 (  16.163s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:45.109 (  16.168s) [        A007C640]     buffer_instance.cc:425      1| Returning tensor to host with host_runtime_tensors ct = 2 from device 0 with buffer UID 410 and shape [32]
2026-01-02 18:37:45.110 (  16.168s) [        9F07A640]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:45.110 (  16.168s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:45.110 (  16.168s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
[james] NOT REAPPLYING SHARDINGS at step 0
Shard spec for static caches after execution
Shard spec for static cache key {devices=[1,2,1,1]<=[2]}
Shard spec for static cache value {devices=[1,2,1,1]<=[2]}
2026-01-02 18:37:46.685 (  17.743s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:46.685 (  17.743s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:46.685 (  17.743s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:46.685 (  17.743s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:46.685 (  17.743s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:46.685 (  17.744s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:46.685 (  17.744s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:46.686 (  17.744s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:46.686 (  17.744s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:46.686 (  17.744s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:46.686 (  17.744s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:46.686 (  17.744s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:46.686 (  17.744s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:46.686 (  17.744s) [        CBC3A000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:46.686 (  17.744s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:46.686 (  17.745s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:46.686 (  17.745s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:46.686 (  17.745s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:46.686 (  17.745s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:46.686 (  17.745s) [        CBC3A000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2026-01-02 18:37:46.686 (  17.745s) [        CBC3A000]     client_instance.cc:743      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2026-01-02 18:37:46.686 (  17.745s) [        CBC3A000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2026-01-02 18:37:46.686 (  17.745s) [        CBC3A000]      event_instance.cc:223      1| EventInstance::PJRT_Event_OnReady
2026-01-02 18:37:46.686 (  17.745s) [        CBC3A000]      event_instance.cc:172      1| EventInstance::PJRT_Event_Destroy
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.695 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.754s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.755s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.755s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.755s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.755s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.696 (  17.755s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.697 (  17.755s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.697 (  17.755s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.697 (  17.755s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.697 (  17.755s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.697 (  17.756s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.697 (  17.756s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.697 (  17.756s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.698 (  17.756s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.698 (  17.756s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.698 (  17.756s) [        CBC3A000]     buffer_instance.cc:638      1| BufferInstance::PJRT_Buffer_IsDeleted
2026-01-02 18:37:46.730 (  17.789s) [        CBC3A000]     client_instance.cc:695      1| ClientInstance::PJRT_Client_Compile
2026-01-02 18:37:46.730 (  17.789s) [        CBC3A000]     client_instance.cc:327      1| MLIR code size: 12603 bytes
=== MLIR Code (size=12603) ===
MLRStableHLO_v1.11.0
=== End MLIR Code ===
2026-01-02 18:37:46.730 (  17.789s) [        CBC3A000]      module_builder.cc:213      1| ModuleBuilder::buildModule
2026-01-02 18:37:46.733 (  17.791s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module vhlo:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.30")
#loc4 = loc("p3.38")
#loc5 = loc("p4.43")
#loc6 = loc("p5.79")
#loc7 = loc("p6.119")
#loc8 = loc("p7.127")
#loc9 = loc("p8.147")
#loc10 = loc("p9.155")
#loc11 = loc("p10.164")
#loc12 = loc("p11.169")
#loc13 = loc("p12.178")
#loc14 = loc("p13.257")
#loc15 = loc("p14.290")
#loc16 = loc("p15.321")
#loc17 = loc("p16.411")
#loc18 = loc("p17.420")
#loc19 = loc("p18.466")
#loc41 = loc("reduce.59")
#loc79 = loc("scatter.125")
#loc87 = loc("scatter.153")
#loc141 = loc("reduce.359")
#loc146 = loc("reduce.368")
#loc166 = loc("reduce.391")
#loc203 = loc("reduce.446")
module @SyncTensorsGraph.479 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1x!vhlo.i64_v1> loc("p0.3"), %arg1: !vhlo.tensor_v1<64x!vhlo.f32_v1> loc("p1.13"), %arg2: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc("p2.30"), %arg3: !vhlo.tensor_v1<1x1x!vhlo.i64_v1> loc("p3.38"), %arg4: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc("p4.43"), %arg5: !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc("p5.79"), %arg6: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1> loc("p6.119"), %arg7: !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc("p7.127"), %arg8: !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1> loc("p8.147"), %arg9: !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc("p9.155"), %arg10: !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc("p10.164"), %arg11: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc("p11.169"), %arg12: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc("p12.178"), %arg13: !vhlo.tensor_v1<1x32x!vhlo.i64_v1> loc("p13.257"), %arg14: !vhlo.tensor_v1<!vhlo.bool_v1> loc("p14.290"), %arg15: !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc("p15.321"), %arg16: !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc("p16.411"), %arg17: !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc("p17.420"), %arg18: !vhlo.tensor_v1<3072x!vhlo.bf16_v1> loc("p18.466")) -> (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %1 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0xFF800000> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %2 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : () -> !vhlo.tensor_v1<1x!vhlo.i64_v1> loc(#loc)
    %3 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<128> : tensor<1xi64>>}> : () -> !vhlo.tensor_v1<1x!vhlo.i64_v1> loc(#loc)
    %4 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<2.000000e+00> : tensor<f32>>}> : () -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc)
    %5 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<3.25520843E-4> : tensor<1x1xf32>>}> : () -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc)
    %6 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<9.99999974E-6> : tensor<1x1x1xf32>>}> : () -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc)
    %7 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<8.837890e-02> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %8 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1>>}> : () -> !vhlo.tensor_v1<128x!vhlo.bool_v1> loc(#loc)
    %9 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0.000000e+00> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %10 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<-3.389530e+38> : tensor<bf16>>}> : () -> !vhlo.tensor_v1<!vhlo.bf16_v1> loc(#loc)
    %11 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %12 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>>}> : () -> !vhlo.tensor_v1<128x!vhlo.f32_v1> loc(#loc)
    %13 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<31> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %14 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<"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tensor<1x128xi64>>}> : () -> !vhlo.tensor_v1<1x128x!vhlo.i64_v1> loc(#loc)
    %15 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<32> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %16 = "vhlo.broadcast_in_dim_v1"(%15) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc)
    %17 = "vhlo.broadcast_in_dim_v1"(%13) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc)
    %18 = "vhlo.broadcast_in_dim_v1"(%11) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc)
    %19 = "vhlo.broadcast_in_dim_v1"(%10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1> loc(#loc)
    %20 = "vhlo.broadcast_in_dim_v1"(%9) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1> loc(#loc)
    %21 = "vhlo.broadcast_in_dim_v1"(%10) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.bf16_v1> loc(#loc)
    %22 = "vhlo.broadcast_in_dim_v1"(%9) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1> loc(#loc)
    %23 = "vhlo.broadcast_in_dim_v1"(%7) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc)
    %24 = "vhlo.broadcast_in_dim_v1"(%4) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc)
    %25 = "vhlo.custom_call_v1"(%arg6) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_2">}>} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1> loc(#loc20)
    %26 = "vhlo.reshape_v1"(%arg0) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.i64_v1> loc(#loc21)
    %27 = "vhlo.custom_call_v1"(%26) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.i64_v1> loc(#loc22)
    %28 = "vhlo.reshape_v1"(%27) : (!vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1> loc(#loc23)
    %29 = "vhlo.compare_v1"(%28, %2) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.bool_v1> loc(#loc24)
    %30 = "vhlo.add_v1"(%28, %3) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1> loc(#loc25)
    %31 = "vhlo.select_v1"(%29, %30, %28) : (!vhlo.tensor_v1<1x!vhlo.bool_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1> loc(#loc26)
    %32 = "vhlo.reshape_v1"(%31) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.i64_v1> loc(#loc27)
    %33 = "vhlo.reshape_v1"(%arg5) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc28)
    %34 = "vhlo.custom_call_v1"(%33) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___input_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc29)
    %35 = "vhlo.reshape_v1"(%arg4) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc30)
    %36 = "vhlo.custom_call_v1"(%35) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_embed_tokens_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc31)
    %37 = "vhlo.reshape_v1"(%36) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc(#loc32)
    %38 = "vhlo.reshape_v1"(%arg3) : (!vhlo.tensor_v1<1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.i64_v1> loc(#loc33)
    %39 = "vhlo.custom_call_v1"(%38) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.i64_v1> loc(#loc34)
    %40 = "vhlo.reshape_v1"(%39) : (!vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.i64_v1> loc(#loc35)
    %41 = "vhlo.convert_v1"(%40) : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x!vhlo.ui32_v1> loc(#loc36)
    %42 = "vhlo.gather_v2"(%37, %41) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<[1, 3072]> : tensor<2xi64>>, start_index_map = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x!vhlo.ui32_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc37)
    %43 = "vhlo.reshape_v1"(%42) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc38)
    %44 = "vhlo.convert_v1"(%43) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc39)
    %45 = "vhlo.power_v1"(%44, %24) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc40)
    %46 = "vhlo.reduce_v1"(%45, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.59"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.59")):
      %220 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc42)
      "vhlo.return_v1"(%220) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc41)
    %47 = "vhlo.multiply_v1"(%46, %5) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc43)
    %48 = "vhlo.reshape_v1"(%47) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc44)
    %49 = "vhlo.add_v1"(%48, %6) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc45)
    %50 = "vhlo.rsqrt_v2"(%49) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc46)
    %51 = "vhlo.reshape_v1"(%50) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc47)
    %52 = "vhlo.broadcast_in_dim_v1"(%51) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc48)
    %53 = "vhlo.multiply_v1"(%44, %52) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc49)
    %54 = "vhlo.convert_v1"(%53) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc50)
    %55 = "vhlo.multiply_v1"(%34, %54) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc51)
    %56 = "vhlo.reshape_v1"(%55) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc52)
    %57 = "vhlo.reshape_v1"(%arg2) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc53)
    %58 = "vhlo.custom_call_v1"(%57) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_k_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc54)
    %59 = "vhlo.reshape_v1"(%58) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc(#loc55)
    %60 = "vhlo.transpose_v1"(%59) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1> loc(#loc56)
    %61 = "vhlo.dot_general_v2"(%56, %60) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1> loc(#loc57)
    %62 = "vhlo.reshape_v1"(%61) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc58)
    %63 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc59)
    %64 = "vhlo.custom_call_v1"(%63) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"constant">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_rotary_emb_inv_freq">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc60)
    %65 = "vhlo.reshape_v1"(%64) : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1> loc(#loc61)
    %66 = "vhlo.convert_v1"(%27) : (!vhlo.tensor_v1<1x1x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc62)
    %67 = "vhlo.dot_general_v2"(%65, %66) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x64x1x!vhlo.f32_v1> loc(#loc63)
    %68 = "vhlo.reshape_v1"(%67) : (!vhlo.tensor_v1<1x64x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1> loc(#loc64)
    %69 = "vhlo.concatenate_v1"(%68, %68) <{dimension = #vhlo.integer_v1<2 : i64>}> : (!vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x64x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1> loc(#loc65)
    %70 = "vhlo.cosine_v2"(%69) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1> loc(#loc66)
    %71 = "vhlo.convert_v1"(%70) : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1> loc(#loc67)
    %72 = "vhlo.broadcast_in_dim_v1"(%71) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc68)
    %73 = "vhlo.multiply_v1"(%62, %72) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc69)
    %74 = "vhlo.slice_v1"(%62) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1> loc(#loc70)
    %75 = "vhlo.negate_v1"(%74) : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1> loc(#loc71)
    %76 = "vhlo.slice_v1"(%62) <{limit_indices = #vhlo.tensor_v1<dense<[1, 8, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1> loc(#loc72)
    %77 = "vhlo.concatenate_v1"(%75, %76) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc73)
    %78 = "vhlo.sine_v2"(%69) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.f32_v1> loc(#loc74)
    %79 = "vhlo.convert_v1"(%78) : (!vhlo.tensor_v1<1x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1> loc(#loc75)
    %80 = "vhlo.broadcast_in_dim_v1"(%79) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc76)
    %81 = "vhlo.multiply_v1"(%77, %80) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc77)
    %82 = "vhlo.add_v1"(%73, %81) : (!vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc78)
    %83 = "vhlo.scatter_v2"(%25, %32, %82) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.125"), %arg20: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.125")):
      "vhlo.return_v1"(%arg20) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1> loc(#loc79)
    %84 = "vhlo.custom_call_v1"(%arg8) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_4">}>} : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1> loc(#loc80)
    %85 = "vhlo.reshape_v1"(%arg7) : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc81)
    %86 = "vhlo.custom_call_v1"(%85) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_v_proj_weight">}>} : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1> loc(#loc82)
    %87 = "vhlo.reshape_v1"(%86) : (!vhlo.tensor_v1<1x1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1> loc(#loc83)
    %88 = "vhlo.transpose_v1"(%87) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,1024]{0,1}">} : (!vhlo.tensor_v1<1024x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1> loc(#loc84)
    %89 = "vhlo.dot_general_v2"(%56, %88) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1024x!vhlo.bf16_v1> loc(#loc85)
    %90 = "vhlo.reshape_v1"(%89) : (!vhlo.tensor_v1<1x1024x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1> loc(#loc86)
    %91 = "vhlo.scatter_v2"(%84, %32, %90) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.153"), %arg20: !vhlo.tensor_v1<!vhlo.bf16_v1> loc("scatter.153")):
      "vhlo.return_v1"(%arg20) : (!vhlo.tensor_v1<!vhlo.bf16_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1> loc(#loc87)
    %92 = "vhlo.reshape_v1"(%arg18) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc88)
    %93 = "vhlo.custom_call_v1"(%92) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_norm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc89)
    %94 = "vhlo.reshape_v1"(%arg15) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc90)
    %95 = "vhlo.custom_call_v1"(%94) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_q_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc91)
    %96 = "vhlo.reshape_v1"(%95) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc92)
    %97 = "vhlo.transpose_v1"(%96) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc93)
    %98 = "vhlo.dot_general_v2"(%56, %97) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc94)
    %99 = "vhlo.reshape_v1"(%98) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc95)
    %100 = "vhlo.broadcast_in_dim_v1"(%71) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc96)
    %101 = "vhlo.multiply_v1"(%99, %100) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc97)
    %102 = "vhlo.slice_v1"(%99) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 128]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<[0, 0, 0, 64]> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1> loc(#loc98)
    %103 = "vhlo.negate_v1"(%102) : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1> loc(#loc99)
    %104 = "vhlo.slice_v1"(%99) <{limit_indices = #vhlo.tensor_v1<dense<[1, 24, 1, 64]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1> loc(#loc100)
    %105 = "vhlo.concatenate_v1"(%103, %104) <{dimension = #vhlo.integer_v1<3 : i64>}> : (!vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x64x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc101)
    %106 = "vhlo.broadcast_in_dim_v1"(%79) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc102)
    %107 = "vhlo.multiply_v1"(%105, %106) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc103)
    %108 = "vhlo.add_v1"(%101, %107) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc104)
    %109 = "vhlo.broadcast_in_dim_v1"(%83) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1> loc(#loc105)
    %110 = "vhlo.reshape_v1"(%109) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1> loc(#loc106)
    %111 = "vhlo.transpose_v1"(%110) <{permutation = #vhlo.tensor_v1<dense<[0, 1, 3, 2]> : tensor<4xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[2, 3, 1, 0]> : tensor<4xindex>>, xla_shape = #vhlo.string_v1<"bf16[1,24,128,128]{2,3,1,0}">} : (!vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1> loc(#loc107)
    %112 = "vhlo.dot_general_v2"(%108, %111) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"grad_x"> = #vhlo.string_v1<"false">, #vhlo.string_v1<"grad_y"> = #vhlo.string_v1<"false">}>} : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc108)
    %113 = "vhlo.multiply_v1"(%112, %23) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc109)
    %114 = "vhlo.broadcast_in_dim_v1"(%arg14) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.bool_v1>) -> !vhlo.tensor_v1<128x!vhlo.bool_v1> loc(#loc110)
    %115 = "vhlo.and_v1"(%114, %8) : (!vhlo.tensor_v1<128x!vhlo.bool_v1>, !vhlo.tensor_v1<128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<128x!vhlo.bool_v1> loc(#loc111)
    %116 = "vhlo.reshape_v1"(%115) : (!vhlo.tensor_v1<128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bool_v1> loc(#loc112)
    %117 = "vhlo.broadcast_in_dim_v1"(%28) <{broadcast_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>}> : (!vhlo.tensor_v1<1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.i64_v1> loc(#loc113)
    %118 = "vhlo.compare_v1"(%14, %117) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 GT>}> : (!vhlo.tensor_v1<1x128x!vhlo.i64_v1>, !vhlo.tensor_v1<1x128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.bool_v1> loc(#loc114)
    %119 = "vhlo.convert_v1"(%118) : (!vhlo.tensor_v1<1x128x!vhlo.bool_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.bf16_v1> loc(#loc115)
    %120 = "vhlo.multiply_v1"(%119, %21) : (!vhlo.tensor_v1<1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128x!vhlo.bf16_v1> loc(#loc116)
    %121 = "vhlo.reshape_v1"(%120) : (!vhlo.tensor_v1<1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1> loc(#loc117)
    %122 = "vhlo.slice_v1"(%121) <{limit_indices = #vhlo.tensor_v1<dense<[1, 1, 1, 32]> : tensor<4xi64>>, start_indices = #vhlo.tensor_v1<dense<0> : tensor<4xi64>>, strides = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1> loc(#loc118)
    %123 = "vhlo.reshape_v1"(%arg13) : (!vhlo.tensor_v1<1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x32x!vhlo.i64_v1> loc(#loc119)
    %124 = "vhlo.custom_call_v1"(%123) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_3">}>} : (!vhlo.tensor_v1<1x1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x32x!vhlo.i64_v1> loc(#loc120)
    %125 = "vhlo.reshape_v1"(%124) : (!vhlo.tensor_v1<1x1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x32x!vhlo.i64_v1> loc(#loc121)
    %126 = "vhlo.convert_v1"(%125) : (!vhlo.tensor_v1<1x1x1x32x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1> loc(#loc122)
    %127 = "vhlo.add_v1"(%122, %126) : (!vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1> loc(#loc123)
    %128 = "vhlo.compare_v1"(%127, %20) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 EQ>}> : (!vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x32x!vhlo.bool_v1> loc(#loc124)
    %129 = "vhlo.select_v1"(%128, %19, %122) : (!vhlo.tensor_v1<1x1x1x32x!vhlo.bool_v1>, !vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1> loc(#loc125)
    %130 = "vhlo.floor_v1"(%12) : (!vhlo.tensor_v1<128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<128x!vhlo.f32_v1> loc(#loc126)
    %131 = "vhlo.convert_v1"(%130) : (!vhlo.tensor_v1<128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc127)
    %132 = "vhlo.clamp_v1"(%18, %131, %17) : (!vhlo.tensor_v1<128x!vhlo.i64_v1>, !vhlo.tensor_v1<128x!vhlo.i64_v1>, !vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc128)
    %133 = "vhlo.compare_v1"(%132, %18) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<128x!vhlo.i64_v1>, !vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.bool_v1> loc(#loc129)
    %134 = "vhlo.add_v1"(%132, %16) : (!vhlo.tensor_v1<128x!vhlo.i64_v1>, !vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc130)
    %135 = "vhlo.select_v1"(%133, %134, %132) : (!vhlo.tensor_v1<128x!vhlo.bool_v1>, !vhlo.tensor_v1<128x!vhlo.i64_v1>, !vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x!vhlo.i64_v1> loc(#loc131)
    %136 = "vhlo.reshape_v1"(%135) : (!vhlo.tensor_v1<128x!vhlo.i64_v1>) -> !vhlo.tensor_v1<128x1x!vhlo.i64_v1> loc(#loc132)
    %137 = "vhlo.gather_v2"(%129, %136) <{collapsed_slice_dims = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>, index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, offset_dims = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>, operand_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, slice_sizes = #vhlo.tensor_v1<dense<1> : tensor<4xi64>>, start_index_map = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>, start_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<1x1x1x32x!vhlo.bf16_v1>, !vhlo.tensor_v1<128x1x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1> loc(#loc133)
    %138 = "vhlo.select_v1"(%116, %137, %22) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bool_v1>, !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1> loc(#loc221)
    %139 = "vhlo.select_v1"(%116, %138, %121) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bool_v1>, !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1> loc(#loc136)
    %140 = "vhlo.reshape_v1"(%139) : (!vhlo.tensor_v1<1x1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1> loc(#loc137)
    %141 = "vhlo.broadcast_in_dim_v1"(%140) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 2, 3]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc138)
    %142 = "vhlo.add_v1"(%113, %141) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc139)
    %143 = "vhlo.convert_v1"(%142) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1> loc(#loc140)
    %144 = "vhlo.reduce_v1"(%143, %1) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.359"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.359")):
      %220 = "vhlo.maximum_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc142)
      "vhlo.return_v1"(%220) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1> loc(#loc141)
    %145 = "vhlo.broadcast_in_dim_v1"(%144) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1> loc(#loc143)
    %146 = "vhlo.subtract_v1"(%143, %145) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1> loc(#loc144)
    %147 = "vhlo.exponential_v2"(%146) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1> loc(#loc145)
    %148 = "vhlo.reduce_v1"(%147, %0) <{dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.368"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.368")):
      %220 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc147)
      "vhlo.return_v1"(%220) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x!vhlo.f32_v1> loc(#loc146)
    %149 = "vhlo.broadcast_in_dim_v1"(%148) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 2]> : tensor<3xi64>>}> : (!vhlo.tensor_v1<1x24x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1> loc(#loc148)
    %150 = "vhlo.divide_v1"(%147, %149) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>, !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1> loc(#loc149)
    %151 = "vhlo.convert_v1"(%150) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc150)
    %152 = "vhlo.broadcast_in_dim_v1"(%91) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1, 3, 4]> : tensor<4xi64>>}> : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1> loc(#loc151)
    %153 = "vhlo.reshape_v1"(%152) : (!vhlo.tensor_v1<1x8x3x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1> loc(#loc152)
    %154 = "vhlo.dot_general_v2"(%151, %153) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<3> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"grad_x"> = #vhlo.string_v1<"false">, #vhlo.string_v1<"grad_y"> = #vhlo.string_v1<"false">}>} : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x24x128x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1> loc(#loc153)
    %155 = "vhlo.reshape_v1"(%154) : (!vhlo.tensor_v1<1x24x1x128x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc154)
    %156 = "vhlo.reshape_v1"(%arg12) : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc155)
    %157 = "vhlo.custom_call_v1"(%156) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___self_attn_o_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1> loc(#loc156)
    %158 = "vhlo.reshape_v1"(%157) : (!vhlo.tensor_v1<1x3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc157)
    %159 = "vhlo.transpose_v1"(%158) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,3072]{0,1}">} : (!vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1> loc(#loc158)
    %160 = "vhlo.dot_general_v2"(%155, %159) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc159)
    %161 = "vhlo.reshape_v1"(%160) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc160)
    %162 = "vhlo.add_v1"(%43, %161) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc161)
    %163 = "vhlo.reshape_v1"(%arg16) : (!vhlo.tensor_v1<3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc162)
    %164 = "vhlo.custom_call_v1"(%163) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___post_attention_layernorm_weight">}>} : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc163)
    %165 = "vhlo.convert_v1"(%162) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc164)
    %166 = "vhlo.power_v1"(%165, %24) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc165)
    %167 = "vhlo.reduce_v1"(%166, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.391"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.391")):
      %220 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc167)
      "vhlo.return_v1"(%220) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc166)
    %168 = "vhlo.multiply_v1"(%167, %5) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc168)
    %169 = "vhlo.reshape_v1"(%168) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc169)
    %170 = "vhlo.add_v1"(%169, %6) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc170)
    %171 = "vhlo.rsqrt_v2"(%170) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc171)
    %172 = "vhlo.reshape_v1"(%171) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc172)
    %173 = "vhlo.broadcast_in_dim_v1"(%172) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc173)
    %174 = "vhlo.multiply_v1"(%165, %173) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc174)
    %175 = "vhlo.convert_v1"(%174) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc175)
    %176 = "vhlo.multiply_v1"(%164, %175) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc176)
    %177 = "vhlo.reshape_v1"(%176) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc177)
    %178 = "vhlo.reshape_v1"(%arg17) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc178)
    %179 = "vhlo.custom_call_v1"(%178) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_gate_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc179)
    %180 = "vhlo.reshape_v1"(%179) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc(#loc180)
    %181 = "vhlo.transpose_v1"(%180) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc(#loc181)
    %182 = "vhlo.dot_general_v2"(%177, %181) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1> loc(#loc182)
    %183 = "vhlo.reshape_v1"(%182) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc183)
    %184 = "vhlo.logistic_v2"(%183) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc184)
    %185 = "vhlo.multiply_v1"(%183, %184) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc185)
    %186 = "vhlo.reshape_v1"(%arg11) : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc186)
    %187 = "vhlo.custom_call_v1"(%186) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_up_proj_weight">}>} : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1> loc(#loc187)
    %188 = "vhlo.reshape_v1"(%187) : (!vhlo.tensor_v1<1x8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc(#loc188)
    %189 = "vhlo.transpose_v1"(%188) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,8192]{0,1}">} : (!vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc(#loc189)
    %190 = "vhlo.dot_general_v2"(%177, %189) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1> loc(#loc190)
    %191 = "vhlo.reshape_v1"(%190) : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc191)
    %192 = "vhlo.multiply_v1"(%185, %191) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1> loc(#loc192)
    %193 = "vhlo.reshape_v1"(%192) : (!vhlo.tensor_v1<1x1x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x8192x!vhlo.bf16_v1> loc(#loc193)
    %194 = "vhlo.reshape_v1"(%arg10) : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1> loc(#loc194)
    %195 = "vhlo.custom_call_v1"(%194) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___model_layers__modules__0___mlp_down_proj_weight">}>} : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1> loc(#loc195)
    %196 = "vhlo.reshape_v1"(%195) : (!vhlo.tensor_v1<1x3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1> loc(#loc196)
    %197 = "vhlo.transpose_v1"(%196) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[8192,3072]{0,1}">} : (!vhlo.tensor_v1<3072x8192x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1> loc(#loc197)
    %198 = "vhlo.dot_general_v2"(%193, %197) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x8192x!vhlo.bf16_v1>, !vhlo.tensor_v1<8192x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc198)
    %199 = "vhlo.reshape_v1"(%198) : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc199)
    %200 = "vhlo.add_v1"(%162, %199) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc200)
    %201 = "vhlo.convert_v1"(%200) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc201)
    %202 = "vhlo.power_v1"(%201, %24) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc202)
    %203 = "vhlo.reduce_v1"(%202, %0) <{dimensions = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>}> ({
    ^bb0(%arg19: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.446"), %arg20: !vhlo.tensor_v1<!vhlo.f32_v1> loc("reduce.446")):
      %220 = "vhlo.add_v1"(%arg19, %arg20) : (!vhlo.tensor_v1<!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<!vhlo.f32_v1> loc(#loc204)
      "vhlo.return_v1"(%220) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc203)
    %204 = "vhlo.multiply_v1"(%203, %5) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc205)
    %205 = "vhlo.reshape_v1"(%204) : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc206)
    %206 = "vhlo.add_v1"(%205, %6) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc207)
    %207 = "vhlo.rsqrt_v2"(%206) <{result_accuracy = #vhlo.result_accuracy_v1<atol = 0.000000e+00, rtol = 0.000000e+00, ulps = 0, mode = #vhlo<result_accuracy_mode_v1 DEFAULT>>}> : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x1x!vhlo.f32_v1> loc(#loc208)
    %208 = "vhlo.reshape_v1"(%207) : (!vhlo.tensor_v1<1x1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x!vhlo.f32_v1> loc(#loc209)
    %209 = "vhlo.broadcast_in_dim_v1"(%208) <{broadcast_dimensions = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xi64>>}> : (!vhlo.tensor_v1<1x1x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc210)
    %210 = "vhlo.multiply_v1"(%201, %209) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1> loc(#loc211)
    %211 = "vhlo.convert_v1"(%210) : (!vhlo.tensor_v1<1x1x3072x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc212)
    %212 = "vhlo.multiply_v1"(%93, %211) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1> loc(#loc213)
    %213 = "vhlo.reshape_v1"(%212) : (!vhlo.tensor_v1<1x1x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x3072x!vhlo.bf16_v1> loc(#loc214)
    %214 = "vhlo.reshape_v1"(%arg9) : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc215)
    %215 = "vhlo.custom_call_v1"(%214) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"parameter">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___lm_head_weight">}>} : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1> loc(#loc216)
    %216 = "vhlo.reshape_v1"(%215) : (!vhlo.tensor_v1<1x128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1> loc(#loc217)
    %217 = "vhlo.transpose_v1"(%216) <{permutation = #vhlo.tensor_v1<dense<[1, 0]> : tensor<2xi64>>}> {result_layout = #vhlo.tensor_v1<dense<[0, 1]> : tensor<2xindex>>, xla_shape = #vhlo.string_v1<"bf16[3072,128256]{0,1}">} : (!vhlo.tensor_v1<128256x3072x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1> loc(#loc218)
    %218 = "vhlo.dot_general_v2"(%213, %217) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<1x3072x!vhlo.bf16_v1>, !vhlo.tensor_v1<3072x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1> loc(#loc219)
    %219 = "vhlo.reshape_v1"(%218) : (!vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>) -> !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1> loc(#loc220)
    "vhlo.return_v1"(%83, %91, %218, %219) : (!vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x8x128x128x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x128256x!vhlo.bf16_v1>, !vhlo.tensor_v1<1x1x128256x!vhlo.bf16_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[2,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc20 = loc("custom-call.120")
#loc21 = loc("reshape.4")
#loc22 = loc("custom-call.5")
#loc23 = loc("reshape.6")
#loc24 = loc("compare.115")
#loc25 = loc("add.112")
#loc26 = loc("select.116")
#loc27 = loc("reshape.117")
#loc28 = loc("reshape.80")
#loc29 = loc("custom-call.81")
#loc30 = loc("reshape.44")
#loc31 = loc("custom-call.45")
#loc32 = loc("reshape.46")
#loc33 = loc("reshape.39")
#loc34 = loc("custom-call.40")
#loc35 = loc("reshape.42")
#loc36 = loc("convert.47")
#loc37 = loc("gather.48")
#loc38 = loc("reshape.49")
#loc39 = loc("convert.50")
#loc40 = loc("power.52")
#loc42 = loc("add.58")
#loc43 = loc("multiply.68")
#loc44 = loc("reshape.69")
#loc45 = loc("add.73")
#loc46 = loc("rsqrt.74")
#loc47 = loc("reshape.75")
#loc48 = loc("broadcast.76")
#loc49 = loc("multiply.77")
#loc50 = loc("convert.78")
#loc51 = loc("multiply.84")
#loc52 = loc("reshape.85")
#loc53 = loc("reshape.31")
#loc54 = loc("custom-call.32")
#loc55 = loc("reshape.33")
#loc56 = loc("transpose.34")
#loc57 = loc("dot.86")
#loc58 = loc("transpose.89")
#loc59 = loc("reshape.14")
#loc60 = loc("custom-call.15")
#loc61 = loc("reshape.19")
#loc62 = loc("convert.11")
#loc63 = loc("dot.22")
#loc64 = loc("transpose.23")
#loc65 = loc("concatenate.24")
#loc66 = loc("cosine.98")
#loc67 = loc("convert.101")
#loc68 = loc("broadcast.104")
#loc69 = loc("multiply.105")
#loc70 = loc("slice.91")
#loc71 = loc("negate.92")
#loc72 = loc("slice.90")
#loc73 = loc("concatenate.93")
#loc74 = loc("sine.25")
#loc75 = loc("convert.28")
#loc76 = loc("broadcast.95")
#loc77 = loc("multiply.96")
#loc78 = loc("add.108")
#loc80 = loc("custom-call.148")
#loc81 = loc("reshape.128")
#loc82 = loc("custom-call.129")
#loc83 = loc("reshape.130")
#loc84 = loc("transpose.131")
#loc85 = loc("dot.133")
#loc86 = loc("transpose.136")
#loc88 = loc("reshape.467")
#loc89 = loc("custom-call.468")
#loc90 = loc("reshape.322")
#loc91 = loc("custom-call.323")
#loc92 = loc("reshape.324")
#loc93 = loc("transpose.325")
#loc94 = loc("dot.327")
#loc95 = loc("transpose.330")
#loc96 = loc("broadcast.339")
#loc97 = loc("multiply.340")
#loc98 = loc("slice.332")
#loc99 = loc("negate.333")
#loc100 = loc("slice.331")
#loc101 = loc("concatenate.334")
#loc102 = loc("broadcast.336")
#loc103 = loc("multiply.337")
#loc104 = loc("add.343")
#loc105 = loc("broadcast.317")
#loc106 = loc("reshape.318")
#loc107 = loc("transpose.319")
#loc108 = loc("dot.344")
#loc109 = loc("multiply.347")
#loc110 = loc("broadcast.294")
#loc111 = loc("and.297")
#loc112 = loc("reshape.298")
#loc113 = loc("broadcast.197")
#loc114 = loc("compare.198")
#loc115 = loc("convert.199")
#loc116 = loc("multiply.205")
#loc117 = loc("reshape.207")
#loc118 = loc("slice.268")
#loc119 = loc("reshape.258")
#loc120 = loc("custom-call.259")
#loc121 = loc("reshape.263")
#loc122 = loc("convert.269")
#loc123 = loc("add.272")
#loc124 = loc("compare.275")
#loc125 = loc("select.277")
#loc126 = loc("floor.227")
#loc127 = loc("convert.228")
#loc128 = loc("clamp.231")
#loc129 = loc("compare.240")
#loc130 = loc("add.237")
#loc131 = loc("select.241")
#loc132 = loc("reshape.242")
#loc133 = loc("gather.279")
#loc134 = loc("select.301")
#loc135 = loc("not.299")
#loc136 = loc("select.302")
#loc137 = loc("reshape.350")
#loc138 = loc("broadcast.351")
#loc139 = loc("add.352")
#loc140 = loc("convert.353")
#loc142 = loc("maximum.358")
#loc143 = loc("broadcast.360")
#loc144 = loc("subtract.361")
#loc145 = loc("exponential.362")
#loc147 = loc("add.367")
#loc148 = loc("broadcast.369")
#loc149 = loc("divide.370")
#loc150 = loc("convert.371")
#loc151 = loc("broadcast.190")
#loc152 = loc("reshape.191")
#loc153 = loc("dot.372")
#loc154 = loc("reshape.376")
#loc155 = loc("reshape.179")
#loc156 = loc("custom-call.180")
#loc157 = loc("reshape.181")
#loc158 = loc("transpose.182")
#loc159 = loc("dot.377")
#loc160 = loc("reshape.378")
#loc161 = loc("add.381")
#loc162 = loc("reshape.412")
#loc163 = loc("custom-call.413")
#loc164 = loc("convert.382")
#loc165 = loc("power.384")
#loc167 = loc("add.390")
#loc168 = loc("multiply.400")
#loc169 = loc("reshape.401")
#loc170 = loc("add.405")
#loc171 = loc("rsqrt.406")
#loc172 = loc("reshape.407")
#loc173 = loc("broadcast.408")
#loc174 = loc("multiply.409")
#loc175 = loc("convert.410")
#loc176 = loc("multiply.416")
#loc177 = loc("reshape.425")
#loc178 = loc("reshape.421")
#loc179 = loc("custom-call.422")
#loc180 = loc("reshape.423")
#loc181 = loc("transpose.424")
#loc182 = loc("dot.426")
#loc183 = loc("reshape.427")
#loc184 = loc("logistic.428")
#loc185 = loc("multiply.429")
#loc186 = loc("reshape.170")
#loc187 = loc("custom-call.171")
#loc188 = loc("reshape.172")
#loc189 = loc("transpose.173")
#loc190 = loc("dot.418")
#loc191 = loc("reshape.419")
#loc192 = loc("multiply.430")
#loc193 = loc("reshape.431")
#loc194 = loc("reshape.165")
#loc195 = loc("custom-call.166")
#loc196 = loc("reshape.167")
#loc197 = loc("transpose.168")
#loc198 = loc("dot.432")
#loc199 = loc("reshape.433")
#loc200 = loc("add.436")
#loc201 = loc("convert.437")
#loc202 = loc("power.439")
#loc204 = loc("add.445")
#loc205 = loc("multiply.455")
#loc206 = loc("reshape.456")
#loc207 = loc("add.460")
#loc208 = loc("rsqrt.461")
#loc209 = loc("reshape.462")
#loc210 = loc("broadcast.463")
#loc211 = loc("multiply.464")
#loc212 = loc("convert.465")
#loc213 = loc("multiply.471")
#loc214 = loc("reshape.475")
#loc215 = loc("reshape.156")
#loc216 = loc("custom-call.157")
#loc217 = loc("reshape.158")
#loc218 = loc("transpose.159")
#loc219 = loc("dot.476")
#loc220 = loc("reshape.477")
#loc221 = loc(fused[#loc134, #loc135])
------------------ END OF MLIR MODULE ------------------
2026-01-02 18:37:46.755 (  17.813s) [        CBC3A000]      module_builder.cc:229      1| Extracting checkpointed MLIR code after VHLO Compiler pass
2026-01-02 18:37:46.787 (  17.846s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module shlo:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.30")
#loc4 = loc("p3.38")
#loc5 = loc("p4.43")
#loc6 = loc("p5.79")
#loc7 = loc("p6.119")
#loc8 = loc("p7.127")
#loc9 = loc("p8.147")
#loc10 = loc("p9.155")
#loc11 = loc("p10.164")
#loc12 = loc("p11.169")
#loc13 = loc("p12.178")
#loc14 = loc("p13.257")
#loc15 = loc("p14.290")
#loc16 = loc("p15.321")
#loc17 = loc("p16.411")
#loc18 = loc("p17.420")
#loc19 = loc("p18.466")
#loc78 = loc("scatter.125")
#loc86 = loc("scatter.153")
module @SyncTensorsGraph.479 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p0.3"), %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p2.30"), %arg3: tensor<1x1xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p3.38"), %arg4: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p4.43"), %arg5: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p5.79"), %arg6: tensor<1x8x128x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} loc("p6.119"), %arg7: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p7.127"), %arg8: tensor<1x8x128x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} loc("p8.147"), %arg9: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p9.155"), %arg10: tensor<3072x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p10.164"), %arg11: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p11.169"), %arg12: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"} loc("p12.178"), %arg13: tensor<1x32xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"} loc("p13.257"), %arg14: tensor<i1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"} loc("p14.290"), %arg15: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p15.321"), %arg16: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p16.411"), %arg17: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}"} loc("p17.420"), %arg18: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p18.466")) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %c = stablehlo.constant dense<0> : tensor<1xi64> loc(#loc)
    %c_1 = stablehlo.constant dense<128> : tensor<1xi64> loc(#loc)
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x1xf32> loc(#loc)
    %cst_4 = stablehlo.constant dense<9.99999974E-6> : tensor<1x1x1xf32> loc(#loc)
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16> loc(#loc)
    %c_6 = stablehlo.constant dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1> loc(#loc)
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc)
    %c_9 = stablehlo.constant dense<0> : tensor<i64> loc(#loc)
    %cst_10 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32> loc(#loc)
    %c_11 = stablehlo.constant dense<31> : tensor<i64> loc(#loc)
    %c_12 = stablehlo.constant dense<"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tensor<1x128xi64> loc(#loc)
    %c_13 = stablehlo.constant dense<32> : tensor<i64> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %c_13, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<1x1x1x32xbf16> loc(#loc)
    %4 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<1x1x1x32xbf16> loc(#loc)
    %5 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<1x128xbf16> loc(#loc)
    %6 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<1x1x1x128xbf16> loc(#loc)
    %7 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<1x24x1x128xbf16> loc(#loc)
    %8 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32> loc(#loc)
    %9 = stablehlo.custom_call @tt.mark_argument(%arg6) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_2"}} : (tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc20)
    %10 = stablehlo.reshape %arg0 : (tensor<1xi64>) -> tensor<1x1x1xi64> loc(#loc21)
    %11 = stablehlo.custom_call @tt.mark_argument(%10) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<1x1x1xi64>) -> tensor<1x1x1xi64> loc(#loc22)
    %12 = stablehlo.reshape %11 : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc23)
    %13 = stablehlo.compare  LT, %12, %c : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1> loc(#loc24)
    %14 = stablehlo.add %12, %c_1 : tensor<1xi64> loc(#loc25)
    %15 = stablehlo.select %13, %14, %12 : tensor<1xi1>, tensor<1xi64> loc(#loc26)
    %16 = stablehlo.reshape %15 : (tensor<1xi64>) -> tensor<1x1xi64> loc(#loc27)
    %17 = stablehlo.reshape %arg5 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc28)
    %18 = stablehlo.custom_call @tt.mark_argument(%17) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc29)
    %19 = stablehlo.reshape %arg4 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc30)
    %20 = stablehlo.custom_call @tt.mark_argument(%19) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_embed_tokens_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc31)
    %21 = stablehlo.reshape %20 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc32)
    %22 = stablehlo.reshape %arg3 : (tensor<1x1xi64>) -> tensor<1x1x1xi64> loc(#loc33)
    %23 = stablehlo.custom_call @tt.mark_argument(%22) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x1x1xi64>) -> tensor<1x1x1xi64> loc(#loc34)
    %24 = stablehlo.reshape %23 : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc35)
    %25 = stablehlo.convert %24 : (tensor<1xi64>) -> tensor<1xui32> loc(#loc36)
    %26 = "stablehlo.gather"(%21, %25) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16> loc(#loc37)
    %27 = stablehlo.reshape %26 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc38)
    %28 = stablehlo.convert %27 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc39)
    %29 = stablehlo.power %28, %8 : tensor<1x1x3072xf32> loc(#loc40)
    %30 = stablehlo.reduce(%29 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc41)
    %31 = stablehlo.multiply %30, %cst_3 : tensor<1x1xf32> loc(#loc42)
    %32 = stablehlo.reshape %31 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc43)
    %33 = stablehlo.add %32, %cst_4 : tensor<1x1x1xf32> loc(#loc44)
    %34 = stablehlo.rsqrt %33 : tensor<1x1x1xf32> loc(#loc45)
    %35 = stablehlo.reshape %34 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc46)
    %36 = stablehlo.broadcast_in_dim %35, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc47)
    %37 = stablehlo.multiply %28, %36 : tensor<1x1x3072xf32> loc(#loc48)
    %38 = stablehlo.convert %37 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc49)
    %39 = stablehlo.multiply %18, %38 : tensor<1x1x3072xbf16> loc(#loc50)
    %40 = stablehlo.reshape %39 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc51)
    %41 = stablehlo.reshape %arg2 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc52)
    %42 = stablehlo.custom_call @tt.mark_argument(%41) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc53)
    %43 = stablehlo.reshape %42 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc54)
    %44 = stablehlo.transpose %43, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc55)
    %45 = stablehlo.dot_general %40, %44, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16> loc(#loc56)
    %46 = stablehlo.reshape %45 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc57)
    %47 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc58)
    %48 = stablehlo.custom_call @tt.mark_argument(%47) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "constant", ttir.name = "l__self___model_rotary_emb_inv_freq"}} : (tensor<1x1x64xf32>) -> tensor<1x1x64xf32> loc(#loc59)
    %49 = stablehlo.reshape %48 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc60)
    %50 = stablehlo.convert %11 : (tensor<1x1x1xi64>) -> tensor<1x1x1xf32> loc(#loc61)
    %51 = stablehlo.dot_general %49, %50, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32> loc(#loc62)
    %52 = stablehlo.reshape %51 : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32> loc(#loc63)
    %53 = stablehlo.concatenate %52, %52, dim = 2 : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32> loc(#loc64)
    %54 = stablehlo.cosine %53 : tensor<1x1x128xf32> loc(#loc65)
    %55 = stablehlo.convert %54 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc66)
    %56 = stablehlo.broadcast_in_dim %55, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc67)
    %57 = stablehlo.multiply %46, %56 : tensor<1x8x1x128xbf16> loc(#loc68)
    %58 = stablehlo.slice %46 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16> loc(#loc69)
    %59 = stablehlo.negate %58 : tensor<1x8x1x64xbf16> loc(#loc70)
    %60 = stablehlo.slice %46 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16> loc(#loc71)
    %61 = stablehlo.concatenate %59, %60, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc72)
    %62 = stablehlo.sine %53 : tensor<1x1x128xf32> loc(#loc73)
    %63 = stablehlo.convert %62 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc74)
    %64 = stablehlo.broadcast_in_dim %63, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc75)
    %65 = stablehlo.multiply %61, %64 : tensor<1x8x1x128xbf16> loc(#loc76)
    %66 = stablehlo.add %57, %65 : tensor<1x8x1x128xbf16> loc(#loc77)
    %67 = "stablehlo.scatter"(%9, %16, %66) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16> loc("scatter.125"), %arg20: tensor<bf16> loc("scatter.125")):
      stablehlo.return %arg20 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc78)
    %68 = stablehlo.custom_call @tt.mark_argument(%arg8) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_4"}} : (tensor<1x8x128x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc79)
    %69 = stablehlo.reshape %arg7 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc80)
    %70 = stablehlo.custom_call @tt.mark_argument(%69) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"}} : (tensor<1x1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc81)
    %71 = stablehlo.reshape %70 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc82)
    %72 = stablehlo.transpose %71, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc83)
    %73 = stablehlo.dot_general %40, %72, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16> loc(#loc84)
    %74 = stablehlo.reshape %73 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc85)
    %75 = "stablehlo.scatter"(%68, %16, %74) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16> loc("scatter.153"), %arg20: tensor<bf16> loc("scatter.153")):
      stablehlo.return %arg20 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc86)
    %76 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc87)
    %77 = stablehlo.custom_call @tt.mark_argument(%76) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_norm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc88)
    %78 = stablehlo.reshape %arg15 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc89)
    %79 = stablehlo.custom_call @tt.mark_argument(%78) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc90)
    %80 = stablehlo.reshape %79 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc91)
    %81 = stablehlo.transpose %80, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc92)
    %82 = stablehlo.dot_general %40, %81, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc93)
    %83 = stablehlo.reshape %82 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc94)
    %84 = stablehlo.broadcast_in_dim %55, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc95)
    %85 = stablehlo.multiply %83, %84 : tensor<1x24x1x128xbf16> loc(#loc96)
    %86 = stablehlo.slice %83 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16> loc(#loc97)
    %87 = stablehlo.negate %86 : tensor<1x24x1x64xbf16> loc(#loc98)
    %88 = stablehlo.slice %83 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16> loc(#loc99)
    %89 = stablehlo.concatenate %87, %88, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc100)
    %90 = stablehlo.broadcast_in_dim %63, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc101)
    %91 = stablehlo.multiply %89, %90 : tensor<1x24x1x128xbf16> loc(#loc102)
    %92 = stablehlo.add %85, %91 : tensor<1x24x1x128xbf16> loc(#loc103)
    %93 = stablehlo.broadcast_in_dim %67, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16> loc(#loc104)
    %94 = stablehlo.reshape %93 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16> loc(#loc105)
    %95 = stablehlo.transpose %94, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16> loc(#loc106)
    %96 = stablehlo.dot_general %92, %95, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x24x1x128xbf16>, tensor<1x24x128x128xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc107)
    %97 = stablehlo.multiply %96, %7 : tensor<1x24x1x128xbf16> loc(#loc108)
    %98 = stablehlo.broadcast_in_dim %arg14, dims = [] : (tensor<i1>) -> tensor<128xi1> loc(#loc109)
    %99 = stablehlo.and %98, %c_6 : tensor<128xi1> loc(#loc110)
    %100 = stablehlo.reshape %99 : (tensor<128xi1>) -> tensor<1x1x1x128xi1> loc(#loc111)
    %101 = stablehlo.broadcast_in_dim %12, dims = [0] : (tensor<1xi64>) -> tensor<1x128xi64> loc(#loc112)
    %102 = stablehlo.compare  GT, %c_12, %101 : (tensor<1x128xi64>, tensor<1x128xi64>) -> tensor<1x128xi1> loc(#loc113)
    %103 = stablehlo.convert %102 : (tensor<1x128xi1>) -> tensor<1x128xbf16> loc(#loc114)
    %104 = stablehlo.multiply %103, %5 : tensor<1x128xbf16> loc(#loc115)
    %105 = stablehlo.reshape %104 : (tensor<1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc116)
    %106 = stablehlo.slice %105 [0:1, 0:1, 0:1, 0:32] : (tensor<1x1x1x128xbf16>) -> tensor<1x1x1x32xbf16> loc(#loc117)
    %107 = stablehlo.reshape %arg13 : (tensor<1x32xi64>) -> tensor<1x1x32xi64> loc(#loc118)
    %108 = stablehlo.custom_call @tt.mark_argument(%107) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_3"}} : (tensor<1x1x32xi64>) -> tensor<1x1x32xi64> loc(#loc119)
    %109 = stablehlo.reshape %108 : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64> loc(#loc120)
    %110 = stablehlo.convert %109 : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16> loc(#loc121)
    %111 = stablehlo.add %106, %110 : tensor<1x1x1x32xbf16> loc(#loc122)
    %112 = stablehlo.compare  EQ, %111, %4 : (tensor<1x1x1x32xbf16>, tensor<1x1x1x32xbf16>) -> tensor<1x1x1x32xi1> loc(#loc123)
    %113 = stablehlo.select %112, %3, %106 : tensor<1x1x1x32xi1>, tensor<1x1x1x32xbf16> loc(#loc124)
    %114 = stablehlo.floor %cst_10 : tensor<128xf32> loc(#loc125)
    %115 = stablehlo.convert %114 : (tensor<128xf32>) -> tensor<128xi64> loc(#loc126)
    %116 = stablehlo.clamp %2, %115, %1 : tensor<128xi64> loc(#loc127)
    %117 = stablehlo.compare  LT, %116, %2 : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1> loc(#loc128)
    %118 = stablehlo.add %116, %0 : tensor<128xi64> loc(#loc129)
    %119 = stablehlo.select %117, %118, %116 : tensor<128xi1>, tensor<128xi64> loc(#loc130)
    %120 = stablehlo.reshape %119 : (tensor<128xi64>) -> tensor<128x1xi64> loc(#loc131)
    %121 = "stablehlo.gather"(%113, %120) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x1x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x1x128xbf16> loc(#loc132)
    %122 = stablehlo.select %100, %121, %6 : tensor<1x1x1x128xi1>, tensor<1x1x1x128xbf16> loc(#loc216)
    %123 = stablehlo.select %100, %122, %105 : tensor<1x1x1x128xi1>, tensor<1x1x1x128xbf16> loc(#loc135)
    %124 = stablehlo.reshape %123 : (tensor<1x1x1x128xbf16>) -> tensor<1x1x128xbf16> loc(#loc136)
    %125 = stablehlo.broadcast_in_dim %124, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc137)
    %126 = stablehlo.add %97, %125 : tensor<1x24x1x128xbf16> loc(#loc138)
    %127 = stablehlo.convert %126 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32> loc(#loc139)
    %128 = stablehlo.reduce(%127 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32> loc(#loc140)
    %129 = stablehlo.broadcast_in_dim %128, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32> loc(#loc141)
    %130 = stablehlo.subtract %127, %129 : tensor<1x24x1x128xf32> loc(#loc142)
    %131 = stablehlo.exponential %130 : tensor<1x24x1x128xf32> loc(#loc143)
    %132 = stablehlo.reduce(%131 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32> loc(#loc144)
    %133 = stablehlo.broadcast_in_dim %132, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32> loc(#loc145)
    %134 = stablehlo.divide %131, %133 : tensor<1x24x1x128xf32> loc(#loc146)
    %135 = stablehlo.convert %134 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16> loc(#loc147)
    %136 = stablehlo.broadcast_in_dim %75, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16> loc(#loc148)
    %137 = stablehlo.reshape %136 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16> loc(#loc149)
    %138 = stablehlo.dot_general %135, %137, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x24x1x128xbf16>, tensor<1x24x128x128xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc150)
    %139 = stablehlo.reshape %138 : (tensor<1x24x1x128xbf16>) -> tensor<1x3072xbf16> loc(#loc151)
    %140 = stablehlo.reshape %arg12 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc152)
    %141 = stablehlo.custom_call @tt.mark_argument(%140) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"}} : (tensor<1x3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc153)
    %142 = stablehlo.reshape %141 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc154)
    %143 = stablehlo.transpose %142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc155)
    %144 = stablehlo.dot_general %139, %143, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc156)
    %145 = stablehlo.reshape %144 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc157)
    %146 = stablehlo.add %27, %145 : tensor<1x1x3072xbf16> loc(#loc158)
    %147 = stablehlo.reshape %arg16 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc159)
    %148 = stablehlo.custom_call @tt.mark_argument(%147) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"}} : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc160)
    %149 = stablehlo.convert %146 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc161)
    %150 = stablehlo.power %149, %8 : tensor<1x1x3072xf32> loc(#loc162)
    %151 = stablehlo.reduce(%150 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc163)
    %152 = stablehlo.multiply %151, %cst_3 : tensor<1x1xf32> loc(#loc164)
    %153 = stablehlo.reshape %152 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc165)
    %154 = stablehlo.add %153, %cst_4 : tensor<1x1x1xf32> loc(#loc166)
    %155 = stablehlo.rsqrt %154 : tensor<1x1x1xf32> loc(#loc167)
    %156 = stablehlo.reshape %155 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc168)
    %157 = stablehlo.broadcast_in_dim %156, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc169)
    %158 = stablehlo.multiply %149, %157 : tensor<1x1x3072xf32> loc(#loc170)
    %159 = stablehlo.convert %158 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc171)
    %160 = stablehlo.multiply %148, %159 : tensor<1x1x3072xbf16> loc(#loc172)
    %161 = stablehlo.reshape %160 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc173)
    %162 = stablehlo.reshape %arg17 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc174)
    %163 = stablehlo.custom_call @tt.mark_argument(%162) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc175)
    %164 = stablehlo.reshape %163 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc176)
    %165 = stablehlo.transpose %164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc177)
    %166 = stablehlo.dot_general %161, %165, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16> loc(#loc178)
    %167 = stablehlo.reshape %166 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc179)
    %168 = stablehlo.logistic %167 : tensor<1x1x8192xbf16> loc(#loc180)
    %169 = stablehlo.multiply %167, %168 : tensor<1x1x8192xbf16> loc(#loc181)
    %170 = stablehlo.reshape %arg11 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc182)
    %171 = stablehlo.custom_call @tt.mark_argument(%170) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"}} : (tensor<1x8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc183)
    %172 = stablehlo.reshape %171 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc184)
    %173 = stablehlo.transpose %172, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc185)
    %174 = stablehlo.dot_general %161, %173, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16> loc(#loc186)
    %175 = stablehlo.reshape %174 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc187)
    %176 = stablehlo.multiply %169, %175 : tensor<1x1x8192xbf16> loc(#loc188)
    %177 = stablehlo.reshape %176 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16> loc(#loc189)
    %178 = stablehlo.reshape %arg10 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16> loc(#loc190)
    %179 = stablehlo.custom_call @tt.mark_argument(%178) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"}} : (tensor<1x3072x8192xbf16>) -> tensor<1x3072x8192xbf16> loc(#loc191)
    %180 = stablehlo.reshape %179 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16> loc(#loc192)
    %181 = stablehlo.transpose %180, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16> loc(#loc193)
    %182 = stablehlo.dot_general %177, %181, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc194)
    %183 = stablehlo.reshape %182 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc195)
    %184 = stablehlo.add %146, %183 : tensor<1x1x3072xbf16> loc(#loc196)
    %185 = stablehlo.convert %184 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc197)
    %186 = stablehlo.power %185, %8 : tensor<1x1x3072xf32> loc(#loc198)
    %187 = stablehlo.reduce(%186 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc199)
    %188 = stablehlo.multiply %187, %cst_3 : tensor<1x1xf32> loc(#loc200)
    %189 = stablehlo.reshape %188 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc201)
    %190 = stablehlo.add %189, %cst_4 : tensor<1x1x1xf32> loc(#loc202)
    %191 = stablehlo.rsqrt %190 : tensor<1x1x1xf32> loc(#loc203)
    %192 = stablehlo.reshape %191 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc204)
    %193 = stablehlo.broadcast_in_dim %192, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc205)
    %194 = stablehlo.multiply %185, %193 : tensor<1x1x3072xf32> loc(#loc206)
    %195 = stablehlo.convert %194 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc207)
    %196 = stablehlo.multiply %77, %195 : tensor<1x1x3072xbf16> loc(#loc208)
    %197 = stablehlo.reshape %196 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc209)
    %198 = stablehlo.reshape %arg9 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc210)
    %199 = stablehlo.custom_call @tt.mark_argument(%198) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "parameter", ttir.name = "l__self___lm_head_weight"}} : (tensor<1x128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc211)
    %200 = stablehlo.reshape %199 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc212)
    %201 = stablehlo.transpose %200, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc213)
    %202 = stablehlo.dot_general %197, %201, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<1x128256xbf16> loc(#loc214)
    %203 = stablehlo.reshape %202 : (tensor<1x128256xbf16>) -> tensor<1x1x128256xbf16> loc(#loc215)
    return %67, %75, %202, %203 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc20 = loc("custom-call.120")
#loc21 = loc("reshape.4")
#loc22 = loc("custom-call.5")
#loc23 = loc("reshape.6")
#loc24 = loc("compare.115")
#loc25 = loc("add.112")
#loc26 = loc("select.116")
#loc27 = loc("reshape.117")
#loc28 = loc("reshape.80")
#loc29 = loc("custom-call.81")
#loc30 = loc("reshape.44")
#loc31 = loc("custom-call.45")
#loc32 = loc("reshape.46")
#loc33 = loc("reshape.39")
#loc34 = loc("custom-call.40")
#loc35 = loc("reshape.42")
#loc36 = loc("convert.47")
#loc37 = loc("gather.48")
#loc38 = loc("reshape.49")
#loc39 = loc("convert.50")
#loc40 = loc("power.52")
#loc41 = loc("reduce.59")
#loc42 = loc("multiply.68")
#loc43 = loc("reshape.69")
#loc44 = loc("add.73")
#loc45 = loc("rsqrt.74")
#loc46 = loc("reshape.75")
#loc47 = loc("broadcast.76")
#loc48 = loc("multiply.77")
#loc49 = loc("convert.78")
#loc50 = loc("multiply.84")
#loc51 = loc("reshape.85")
#loc52 = loc("reshape.31")
#loc53 = loc("custom-call.32")
#loc54 = loc("reshape.33")
#loc55 = loc("transpose.34")
#loc56 = loc("dot.86")
#loc57 = loc("transpose.89")
#loc58 = loc("reshape.14")
#loc59 = loc("custom-call.15")
#loc60 = loc("reshape.19")
#loc61 = loc("convert.11")
#loc62 = loc("dot.22")
#loc63 = loc("transpose.23")
#loc64 = loc("concatenate.24")
#loc65 = loc("cosine.98")
#loc66 = loc("convert.101")
#loc67 = loc("broadcast.104")
#loc68 = loc("multiply.105")
#loc69 = loc("slice.91")
#loc70 = loc("negate.92")
#loc71 = loc("slice.90")
#loc72 = loc("concatenate.93")
#loc73 = loc("sine.25")
#loc74 = loc("convert.28")
#loc75 = loc("broadcast.95")
#loc76 = loc("multiply.96")
#loc77 = loc("add.108")
#loc79 = loc("custom-call.148")
#loc80 = loc("reshape.128")
#loc81 = loc("custom-call.129")
#loc82 = loc("reshape.130")
#loc83 = loc("transpose.131")
#loc84 = loc("dot.133")
#loc85 = loc("transpose.136")
#loc87 = loc("reshape.467")
#loc88 = loc("custom-call.468")
#loc89 = loc("reshape.322")
#loc90 = loc("custom-call.323")
#loc91 = loc("reshape.324")
#loc92 = loc("transpose.325")
#loc93 = loc("dot.327")
#loc94 = loc("transpose.330")
#loc95 = loc("broadcast.339")
#loc96 = loc("multiply.340")
#loc97 = loc("slice.332")
#loc98 = loc("negate.333")
#loc99 = loc("slice.331")
#loc100 = loc("concatenate.334")
#loc101 = loc("broadcast.336")
#loc102 = loc("multiply.337")
#loc103 = loc("add.343")
#loc104 = loc("broadcast.317")
#loc105 = loc("reshape.318")
#loc106 = loc("transpose.319")
#loc107 = loc("dot.344")
#loc108 = loc("multiply.347")
#loc109 = loc("broadcast.294")
#loc110 = loc("and.297")
#loc111 = loc("reshape.298")
#loc112 = loc("broadcast.197")
#loc113 = loc("compare.198")
#loc114 = loc("convert.199")
#loc115 = loc("multiply.205")
#loc116 = loc("reshape.207")
#loc117 = loc("slice.268")
#loc118 = loc("reshape.258")
#loc119 = loc("custom-call.259")
#loc120 = loc("reshape.263")
#loc121 = loc("convert.269")
#loc122 = loc("add.272")
#loc123 = loc("compare.275")
#loc124 = loc("select.277")
#loc125 = loc("floor.227")
#loc126 = loc("convert.228")
#loc127 = loc("clamp.231")
#loc128 = loc("compare.240")
#loc129 = loc("add.237")
#loc130 = loc("select.241")
#loc131 = loc("reshape.242")
#loc132 = loc("gather.279")
#loc133 = loc("select.301")
#loc134 = loc("not.299")
#loc135 = loc("select.302")
#loc136 = loc("reshape.350")
#loc137 = loc("broadcast.351")
#loc138 = loc("add.352")
#loc139 = loc("convert.353")
#loc140 = loc("reduce.359")
#loc141 = loc("broadcast.360")
#loc142 = loc("subtract.361")
#loc143 = loc("exponential.362")
#loc144 = loc("reduce.368")
#loc145 = loc("broadcast.369")
#loc146 = loc("divide.370")
#loc147 = loc("convert.371")
#loc148 = loc("broadcast.190")
#loc149 = loc("reshape.191")
#loc150 = loc("dot.372")
#loc151 = loc("reshape.376")
#loc152 = loc("reshape.179")
#loc153 = loc("custom-call.180")
#loc154 = loc("reshape.181")
#loc155 = loc("transpose.182")
#loc156 = loc("dot.377")
#loc157 = loc("reshape.378")
#loc158 = loc("add.381")
#loc159 = loc("reshape.412")
#loc160 = loc("custom-call.413")
#loc161 = loc("convert.382")
#loc162 = loc("power.384")
#loc163 = loc("reduce.391")
#loc164 = loc("multiply.400")
#loc165 = loc("reshape.401")
#loc166 = loc("add.405")
#loc167 = loc("rsqrt.406")
#loc168 = loc("reshape.407")
#loc169 = loc("broadcast.408")
#loc170 = loc("multiply.409")
#loc171 = loc("convert.410")
#loc172 = loc("multiply.416")
#loc173 = loc("reshape.425")
#loc174 = loc("reshape.421")
#loc175 = loc("custom-call.422")
#loc176 = loc("reshape.423")
#loc177 = loc("transpose.424")
#loc178 = loc("dot.426")
#loc179 = loc("reshape.427")
#loc180 = loc("logistic.428")
#loc181 = loc("multiply.429")
#loc182 = loc("reshape.170")
#loc183 = loc("custom-call.171")
#loc184 = loc("reshape.172")
#loc185 = loc("transpose.173")
#loc186 = loc("dot.418")
#loc187 = loc("reshape.419")
#loc188 = loc("multiply.430")
#loc189 = loc("reshape.431")
#loc190 = loc("reshape.165")
#loc191 = loc("custom-call.166")
#loc192 = loc("reshape.167")
#loc193 = loc("transpose.168")
#loc194 = loc("dot.432")
#loc195 = loc("reshape.433")
#loc196 = loc("add.436")
#loc197 = loc("convert.437")
#loc198 = loc("power.439")
#loc199 = loc("reduce.446")
#loc200 = loc("multiply.455")
#loc201 = loc("reshape.456")
#loc202 = loc("add.460")
#loc203 = loc("rsqrt.461")
#loc204 = loc("reshape.462")
#loc205 = loc("broadcast.463")
#loc206 = loc("multiply.464")
#loc207 = loc("convert.465")
#loc208 = loc("multiply.471")
#loc209 = loc("reshape.475")
#loc210 = loc("reshape.156")
#loc211 = loc("custom-call.157")
#loc212 = loc("reshape.158")
#loc213 = loc("transpose.159")
#loc214 = loc("dot.476")
#loc215 = loc("reshape.477")
#loc216 = loc(fused[#loc133, #loc134])
------------------ END OF MLIR MODULE ------------------
2026-01-02 18:37:46.803 (  17.861s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module shlo_frontend:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.30")
#loc4 = loc("p3.38")
#loc5 = loc("p4.43")
#loc6 = loc("p5.79")
#loc7 = loc("p6.119")
#loc8 = loc("p7.127")
#loc9 = loc("p8.147")
#loc10 = loc("p9.155")
#loc11 = loc("p10.164")
#loc12 = loc("p11.169")
#loc13 = loc("p12.178")
#loc14 = loc("p13.257")
#loc15 = loc("p14.290")
#loc16 = loc("p15.321")
#loc17 = loc("p16.411")
#loc18 = loc("p17.420")
#loc19 = loc("p18.466")
#loc71 = loc("scatter.125")
#loc77 = loc("scatter.153")
module @SyncTensorsGraph.479 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.30"), %arg3: tensor<1x1xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("p3.38"), %arg4: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p4.43"), %arg5: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p5.79"), %arg6: tensor<1x8x128x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_2"} loc("p6.119"), %arg7: tensor<1024x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p7.127"), %arg8: tensor<1x8x128x128xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_4"} loc("p8.147"), %arg9: tensor<128256x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___lm_head_weight"} loc("p9.155"), %arg10: tensor<3072x8192xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p10.164"), %arg11: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p11.169"), %arg12: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p12.178"), %arg13: tensor<1x32xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_3"} loc("p13.257"), %arg14: tensor<i1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>} loc("p14.290"), %arg15: tensor<3072x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p15.321"), %arg16: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p16.411"), %arg17: tensor<8192x3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\22_axis_0\22}, {}]>"}, mhlo.sharding = "{devices=[2,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p17.420"), %arg18: tensor<3072xbf16> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<parameter>, ttir.name = "l__self___model_norm_weight"} loc("p18.466")) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
    %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
    %c = stablehlo.constant dense<0> : tensor<1xi64> loc(#loc)
    %c_1 = stablehlo.constant dense<128> : tensor<1xi64> loc(#loc)
    %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
    %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x1xf32> loc(#loc)
    %cst_4 = stablehlo.constant dense<9.99999974E-6> : tensor<1x1x1xf32> loc(#loc)
    %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16> loc(#loc)
    %c_6 = stablehlo.constant dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1> loc(#loc)
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
    %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc)
    %c_9 = stablehlo.constant dense<0> : tensor<i64> loc(#loc)
    %cst_10 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32> loc(#loc)
    %c_11 = stablehlo.constant dense<31> : tensor<i64> loc(#loc)
    %c_12 = stablehlo.constant dense<"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tensor<1x128xi64> loc(#loc)
    %c_13 = stablehlo.constant dense<32> : tensor<i64> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %c_13, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
    %1 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
    %2 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
    %3 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<1x1x1x32xbf16> loc(#loc)
    %4 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<1x1x1x32xbf16> loc(#loc)
    %5 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<1x128xbf16> loc(#loc)
    %6 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<1x1x1x128xbf16> loc(#loc)
    %7 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<1x24x1x128xbf16> loc(#loc)
    %8 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32> loc(#loc)
    %9 = stablehlo.reshape %arg0 : (tensor<1xi64>) -> tensor<1x1x1xi64> loc(#loc20)
    %10 = stablehlo.reshape %9 : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc21)
    %11 = stablehlo.compare  LT, %10, %c : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1> loc(#loc22)
    %12 = stablehlo.add %10, %c_1 : tensor<1xi64> loc(#loc23)
    %13 = stablehlo.select %11, %12, %10 : tensor<1xi1>, tensor<1xi64> loc(#loc24)
    %14 = stablehlo.reshape %13 : (tensor<1xi64>) -> tensor<1x1xi64> loc(#loc25)
    %15 = stablehlo.reshape %arg5 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc26)
    %16 = stablehlo.reshape %arg4 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc27)
    %17 = stablehlo.reshape %16 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc28)
    %18 = stablehlo.reshape %arg3 : (tensor<1x1xi64>) -> tensor<1x1x1xi64> loc(#loc29)
    %19 = stablehlo.reshape %18 : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc30)
    %20 = stablehlo.convert %19 : (tensor<1xi64>) -> tensor<1xui32> loc(#loc31)
    %21 = "stablehlo.gather"(%17, %20) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16> loc(#loc32)
    %22 = stablehlo.reshape %21 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc33)
    %23 = stablehlo.convert %22 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc34)
    %24 = stablehlo.power %23, %8 : tensor<1x1x3072xf32> loc(#loc35)
    %25 = stablehlo.reduce(%24 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc36)
    %26 = stablehlo.multiply %25, %cst_3 : tensor<1x1xf32> loc(#loc37)
    %27 = stablehlo.reshape %26 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc38)
    %28 = stablehlo.add %27, %cst_4 : tensor<1x1x1xf32> loc(#loc39)
    %29 = stablehlo.rsqrt %28 : tensor<1x1x1xf32> loc(#loc40)
    %30 = stablehlo.reshape %29 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc41)
    %31 = stablehlo.broadcast_in_dim %30, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc42)
    %32 = stablehlo.multiply %23, %31 : tensor<1x1x3072xf32> loc(#loc43)
    %33 = stablehlo.convert %32 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc44)
    %34 = stablehlo.multiply %15, %33 : tensor<1x1x3072xbf16> loc(#loc45)
    %35 = stablehlo.reshape %34 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc46)
    %36 = stablehlo.reshape %arg2 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc47)
    %37 = stablehlo.reshape %36 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc48)
    %38 = stablehlo.transpose %37, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc49)
    %39 = stablehlo.dot_general %35, %38, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16> loc(#loc50)
    %40 = stablehlo.reshape %39 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc51)
    %41 = stablehlo.reshape %arg1 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc52)
    %42 = stablehlo.reshape %41 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc53)
    %43 = stablehlo.convert %9 : (tensor<1x1x1xi64>) -> tensor<1x1x1xf32> loc(#loc54)
    %44 = stablehlo.dot_general %42, %43, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32> loc(#loc55)
    %45 = stablehlo.reshape %44 : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32> loc(#loc56)
    %46 = stablehlo.concatenate %45, %45, dim = 2 : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32> loc(#loc57)
    %47 = stablehlo.cosine %46 : tensor<1x1x128xf32> loc(#loc58)
    %48 = stablehlo.convert %47 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc59)
    %49 = stablehlo.broadcast_in_dim %48, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc60)
    %50 = stablehlo.multiply %40, %49 : tensor<1x8x1x128xbf16> loc(#loc61)
    %51 = stablehlo.slice %40 [0:1, 0:8, 0:1, 64:128] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16> loc(#loc62)
    %52 = stablehlo.negate %51 : tensor<1x8x1x64xbf16> loc(#loc63)
    %53 = stablehlo.slice %40 [0:1, 0:8, 0:1, 0:64] : (tensor<1x8x1x128xbf16>) -> tensor<1x8x1x64xbf16> loc(#loc64)
    %54 = stablehlo.concatenate %52, %53, dim = 3 : (tensor<1x8x1x64xbf16>, tensor<1x8x1x64xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc65)
    %55 = stablehlo.sine %46 : tensor<1x1x128xf32> loc(#loc66)
    %56 = stablehlo.convert %55 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc67)
    %57 = stablehlo.broadcast_in_dim %56, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc68)
    %58 = stablehlo.multiply %54, %57 : tensor<1x8x1x128xbf16> loc(#loc69)
    %59 = stablehlo.add %50, %58 : tensor<1x8x1x128xbf16> loc(#loc70)
    %60 = "stablehlo.scatter"(%arg6, %14, %59) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16> loc("scatter.125"), %arg20: tensor<bf16> loc("scatter.125")):
      stablehlo.return %arg20 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc71)
    %61 = stablehlo.reshape %arg7 : (tensor<1024x3072xbf16>) -> tensor<1x1024x3072xbf16> loc(#loc72)
    %62 = stablehlo.reshape %61 : (tensor<1x1024x3072xbf16>) -> tensor<1024x3072xbf16> loc(#loc73)
    %63 = stablehlo.transpose %62, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<1024x3072xbf16>) -> tensor<3072x1024xbf16> loc(#loc74)
    %64 = stablehlo.dot_general %35, %63, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1024xbf16>) -> tensor<1x1024xbf16> loc(#loc75)
    %65 = stablehlo.reshape %64 : (tensor<1x1024xbf16>) -> tensor<1x8x1x128xbf16> loc(#loc76)
    %66 = "stablehlo.scatter"(%arg8, %14, %65) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16> loc("scatter.153"), %arg20: tensor<bf16> loc("scatter.153")):
      stablehlo.return %arg20 : tensor<bf16> loc(#loc)
    }) : (tensor<1x8x128x128xbf16>, tensor<1x1xi64>, tensor<1x8x1x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc77)
    %67 = stablehlo.reshape %arg18 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc78)
    %68 = stablehlo.reshape %arg15 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc79)
    %69 = stablehlo.reshape %68 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc80)
    %70 = stablehlo.transpose %69, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc81)
    %71 = stablehlo.dot_general %35, %70, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc82)
    %72 = stablehlo.reshape %71 : (tensor<1x3072xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc83)
    %73 = stablehlo.broadcast_in_dim %48, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc84)
    %74 = stablehlo.multiply %72, %73 : tensor<1x24x1x128xbf16> loc(#loc85)
    %75 = stablehlo.slice %72 [0:1, 0:24, 0:1, 64:128] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16> loc(#loc86)
    %76 = stablehlo.negate %75 : tensor<1x24x1x64xbf16> loc(#loc87)
    %77 = stablehlo.slice %72 [0:1, 0:24, 0:1, 0:64] : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x64xbf16> loc(#loc88)
    %78 = stablehlo.concatenate %76, %77, dim = 3 : (tensor<1x24x1x64xbf16>, tensor<1x24x1x64xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc89)
    %79 = stablehlo.broadcast_in_dim %56, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc90)
    %80 = stablehlo.multiply %78, %79 : tensor<1x24x1x128xbf16> loc(#loc91)
    %81 = stablehlo.add %74, %80 : tensor<1x24x1x128xbf16> loc(#loc92)
    %82 = stablehlo.broadcast_in_dim %60, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16> loc(#loc93)
    %83 = stablehlo.reshape %82 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16> loc(#loc94)
    %84 = stablehlo.transpose %83, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x24x128x128xbf16>) -> tensor<1x24x128x128xbf16> loc(#loc95)
    %85 = stablehlo.dot_general %81, %84, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x24x1x128xbf16>, tensor<1x24x128x128xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc96)
    %86 = stablehlo.multiply %85, %7 : tensor<1x24x1x128xbf16> loc(#loc97)
    %87 = stablehlo.broadcast_in_dim %arg14, dims = [] : (tensor<i1>) -> tensor<128xi1> loc(#loc98)
    %88 = stablehlo.and %87, %c_6 : tensor<128xi1> loc(#loc99)
    %89 = stablehlo.reshape %88 : (tensor<128xi1>) -> tensor<1x1x1x128xi1> loc(#loc100)
    %90 = stablehlo.broadcast_in_dim %10, dims = [0] : (tensor<1xi64>) -> tensor<1x128xi64> loc(#loc101)
    %91 = stablehlo.compare  GT, %c_12, %90 : (tensor<1x128xi64>, tensor<1x128xi64>) -> tensor<1x128xi1> loc(#loc102)
    %92 = stablehlo.convert %91 : (tensor<1x128xi1>) -> tensor<1x128xbf16> loc(#loc103)
    %93 = stablehlo.multiply %92, %5 : tensor<1x128xbf16> loc(#loc104)
    %94 = stablehlo.reshape %93 : (tensor<1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc105)
    %95 = stablehlo.slice %94 [0:1, 0:1, 0:1, 0:32] : (tensor<1x1x1x128xbf16>) -> tensor<1x1x1x32xbf16> loc(#loc106)
    %96 = stablehlo.reshape %arg13 : (tensor<1x32xi64>) -> tensor<1x1x32xi64> loc(#loc107)
    %97 = stablehlo.reshape %96 : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64> loc(#loc108)
    %98 = stablehlo.convert %97 : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16> loc(#loc109)
    %99 = stablehlo.add %95, %98 : tensor<1x1x1x32xbf16> loc(#loc110)
    %100 = stablehlo.compare  EQ, %99, %4 : (tensor<1x1x1x32xbf16>, tensor<1x1x1x32xbf16>) -> tensor<1x1x1x32xi1> loc(#loc111)
    %101 = stablehlo.select %100, %3, %95 : tensor<1x1x1x32xi1>, tensor<1x1x1x32xbf16> loc(#loc112)
    %102 = stablehlo.floor %cst_10 : tensor<128xf32> loc(#loc113)
    %103 = stablehlo.convert %102 : (tensor<128xf32>) -> tensor<128xi64> loc(#loc114)
    %104 = stablehlo.clamp %2, %103, %1 : tensor<128xi64> loc(#loc115)
    %105 = stablehlo.compare  LT, %104, %2 : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1> loc(#loc116)
    %106 = stablehlo.add %104, %0 : tensor<128xi64> loc(#loc117)
    %107 = stablehlo.select %105, %106, %104 : tensor<128xi1>, tensor<128xi64> loc(#loc118)
    %108 = stablehlo.reshape %107 : (tensor<128xi64>) -> tensor<128x1xi64> loc(#loc119)
    %109 = "stablehlo.gather"(%101, %108) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x1x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x1x128xbf16> loc(#loc120)
    %110 = stablehlo.select %89, %109, %6 : tensor<1x1x1x128xi1>, tensor<1x1x1x128xbf16> loc(#loc198)
    %111 = stablehlo.select %89, %110, %94 : tensor<1x1x1x128xi1>, tensor<1x1x1x128xbf16> loc(#loc123)
    %112 = stablehlo.reshape %111 : (tensor<1x1x1x128xbf16>) -> tensor<1x1x128xbf16> loc(#loc124)
    %113 = stablehlo.broadcast_in_dim %112, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc125)
    %114 = stablehlo.add %86, %113 : tensor<1x24x1x128xbf16> loc(#loc126)
    %115 = stablehlo.convert %114 : (tensor<1x24x1x128xbf16>) -> tensor<1x24x1x128xf32> loc(#loc127)
    %116 = stablehlo.reduce(%115 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32> loc(#loc128)
    %117 = stablehlo.broadcast_in_dim %116, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32> loc(#loc129)
    %118 = stablehlo.subtract %115, %117 : tensor<1x24x1x128xf32> loc(#loc130)
    %119 = stablehlo.exponential %118 : tensor<1x24x1x128xf32> loc(#loc131)
    %120 = stablehlo.reduce(%119 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x24x1x128xf32>, tensor<f32>) -> tensor<1x24x1xf32> loc(#loc132)
    %121 = stablehlo.broadcast_in_dim %120, dims = [0, 1, 2] : (tensor<1x24x1xf32>) -> tensor<1x24x1x128xf32> loc(#loc133)
    %122 = stablehlo.divide %119, %121 : tensor<1x24x1x128xf32> loc(#loc134)
    %123 = stablehlo.convert %122 : (tensor<1x24x1x128xf32>) -> tensor<1x24x1x128xbf16> loc(#loc135)
    %124 = stablehlo.broadcast_in_dim %66, dims = [0, 1, 3, 4] : (tensor<1x8x128x128xbf16>) -> tensor<1x8x3x128x128xbf16> loc(#loc136)
    %125 = stablehlo.reshape %124 : (tensor<1x8x3x128x128xbf16>) -> tensor<1x24x128x128xbf16> loc(#loc137)
    %126 = stablehlo.dot_general %123, %125, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x24x1x128xbf16>, tensor<1x24x128x128xbf16>) -> tensor<1x24x1x128xbf16> loc(#loc138)
    %127 = stablehlo.reshape %126 : (tensor<1x24x1x128xbf16>) -> tensor<1x3072xbf16> loc(#loc139)
    %128 = stablehlo.reshape %arg12 : (tensor<3072x3072xbf16>) -> tensor<1x3072x3072xbf16> loc(#loc140)
    %129 = stablehlo.reshape %128 : (tensor<1x3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc141)
    %130 = stablehlo.transpose %129, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x3072xbf16>) -> tensor<3072x3072xbf16> loc(#loc142)
    %131 = stablehlo.dot_general %127, %130, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc143)
    %132 = stablehlo.reshape %131 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc144)
    %133 = stablehlo.add %22, %132 : tensor<1x1x3072xbf16> loc(#loc145)
    %134 = stablehlo.reshape %arg16 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc146)
    %135 = stablehlo.convert %133 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc147)
    %136 = stablehlo.power %135, %8 : tensor<1x1x3072xf32> loc(#loc148)
    %137 = stablehlo.reduce(%136 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc149)
    %138 = stablehlo.multiply %137, %cst_3 : tensor<1x1xf32> loc(#loc150)
    %139 = stablehlo.reshape %138 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc151)
    %140 = stablehlo.add %139, %cst_4 : tensor<1x1x1xf32> loc(#loc152)
    %141 = stablehlo.rsqrt %140 : tensor<1x1x1xf32> loc(#loc153)
    %142 = stablehlo.reshape %141 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc154)
    %143 = stablehlo.broadcast_in_dim %142, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc155)
    %144 = stablehlo.multiply %135, %143 : tensor<1x1x3072xf32> loc(#loc156)
    %145 = stablehlo.convert %144 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc157)
    %146 = stablehlo.multiply %134, %145 : tensor<1x1x3072xbf16> loc(#loc158)
    %147 = stablehlo.reshape %146 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc159)
    %148 = stablehlo.reshape %arg17 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc160)
    %149 = stablehlo.reshape %148 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc161)
    %150 = stablehlo.transpose %149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc162)
    %151 = stablehlo.dot_general %147, %150, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16> loc(#loc163)
    %152 = stablehlo.reshape %151 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc164)
    %153 = stablehlo.logistic %152 : tensor<1x1x8192xbf16> loc(#loc165)
    %154 = stablehlo.multiply %152, %153 : tensor<1x1x8192xbf16> loc(#loc166)
    %155 = stablehlo.reshape %arg11 : (tensor<8192x3072xbf16>) -> tensor<1x8192x3072xbf16> loc(#loc167)
    %156 = stablehlo.reshape %155 : (tensor<1x8192x3072xbf16>) -> tensor<8192x3072xbf16> loc(#loc168)
    %157 = stablehlo.transpose %156, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<8192x3072xbf16>) -> tensor<3072x8192xbf16> loc(#loc169)
    %158 = stablehlo.dot_general %147, %157, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x8192xbf16>) -> tensor<1x8192xbf16> loc(#loc170)
    %159 = stablehlo.reshape %158 : (tensor<1x8192xbf16>) -> tensor<1x1x8192xbf16> loc(#loc171)
    %160 = stablehlo.multiply %154, %159 : tensor<1x1x8192xbf16> loc(#loc172)
    %161 = stablehlo.reshape %160 : (tensor<1x1x8192xbf16>) -> tensor<1x8192xbf16> loc(#loc173)
    %162 = stablehlo.reshape %arg10 : (tensor<3072x8192xbf16>) -> tensor<1x3072x8192xbf16> loc(#loc174)
    %163 = stablehlo.reshape %162 : (tensor<1x3072x8192xbf16>) -> tensor<3072x8192xbf16> loc(#loc175)
    %164 = stablehlo.transpose %163, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x8192xbf16>) -> tensor<8192x3072xbf16> loc(#loc176)
    %165 = stablehlo.dot_general %161, %164, contracting_dims = [1] x [0] : (tensor<1x8192xbf16>, tensor<8192x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc177)
    %166 = stablehlo.reshape %165 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc178)
    %167 = stablehlo.add %133, %166 : tensor<1x1x3072xbf16> loc(#loc179)
    %168 = stablehlo.convert %167 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc180)
    %169 = stablehlo.power %168, %8 : tensor<1x1x3072xf32> loc(#loc181)
    %170 = stablehlo.reduce(%169 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc182)
    %171 = stablehlo.multiply %170, %cst_3 : tensor<1x1xf32> loc(#loc183)
    %172 = stablehlo.reshape %171 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc184)
    %173 = stablehlo.add %172, %cst_4 : tensor<1x1x1xf32> loc(#loc185)
    %174 = stablehlo.rsqrt %173 : tensor<1x1x1xf32> loc(#loc186)
    %175 = stablehlo.reshape %174 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc187)
    %176 = stablehlo.broadcast_in_dim %175, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc188)
    %177 = stablehlo.multiply %168, %176 : tensor<1x1x3072xf32> loc(#loc189)
    %178 = stablehlo.convert %177 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc190)
    %179 = stablehlo.multiply %67, %178 : tensor<1x1x3072xbf16> loc(#loc191)
    %180 = stablehlo.reshape %179 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc192)
    %181 = stablehlo.reshape %arg9 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc193)
    %182 = stablehlo.reshape %181 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc194)
    %183 = stablehlo.transpose %182, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc195)
    %184 = stablehlo.dot_general %180, %183, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<1x128256xbf16> loc(#loc196)
    %185 = stablehlo.reshape %184 : (tensor<1x128256xbf16>) -> tensor<1x1x128256xbf16> loc(#loc197)
    return %60, %66, %184, %185 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc20 = loc("reshape.4")
#loc21 = loc("reshape.6")
#loc22 = loc("compare.115")
#loc23 = loc("add.112")
#loc24 = loc("select.116")
#loc25 = loc("reshape.117")
#loc26 = loc("reshape.80")
#loc27 = loc("reshape.44")
#loc28 = loc("reshape.46")
#loc29 = loc("reshape.39")
#loc30 = loc("reshape.42")
#loc31 = loc("convert.47")
#loc32 = loc("gather.48")
#loc33 = loc("reshape.49")
#loc34 = loc("convert.50")
#loc35 = loc("power.52")
#loc36 = loc("reduce.59")
#loc37 = loc("multiply.68")
#loc38 = loc("reshape.69")
#loc39 = loc("add.73")
#loc40 = loc("rsqrt.74")
#loc41 = loc("reshape.75")
#loc42 = loc("broadcast.76")
#loc43 = loc("multiply.77")
#loc44 = loc("convert.78")
#loc45 = loc("multiply.84")
#loc46 = loc("reshape.85")
#loc47 = loc("reshape.31")
#loc48 = loc("reshape.33")
#loc49 = loc("transpose.34")
#loc50 = loc("dot.86")
#loc51 = loc("transpose.89")
#loc52 = loc("reshape.14")
#loc53 = loc("reshape.19")
#loc54 = loc("convert.11")
#loc55 = loc("dot.22")
#loc56 = loc("transpose.23")
#loc57 = loc("concatenate.24")
#loc58 = loc("cosine.98")
#loc59 = loc("convert.101")
#loc60 = loc("broadcast.104")
#loc61 = loc("multiply.105")
#loc62 = loc("slice.91")
#loc63 = loc("negate.92")
#loc64 = loc("slice.90")
#loc65 = loc("concatenate.93")
#loc66 = loc("sine.25")
#loc67 = loc("convert.28")
#loc68 = loc("broadcast.95")
#loc69 = loc("multiply.96")
#loc70 = loc("add.108")
#loc72 = loc("reshape.128")
#loc73 = loc("reshape.130")
#loc74 = loc("transpose.131")
#loc75 = loc("dot.133")
#loc76 = loc("transpose.136")
#loc78 = loc("reshape.467")
#loc79 = loc("reshape.322")
#loc80 = loc("reshape.324")
#loc81 = loc("transpose.325")
#loc82 = loc("dot.327")
#loc83 = loc("transpose.330")
#loc84 = loc("broadcast.339")
#loc85 = loc("multiply.340")
#loc86 = loc("slice.332")
#loc87 = loc("negate.333")
#loc88 = loc("slice.331")
#loc89 = loc("concatenate.334")
#loc90 = loc("broadcast.336")
#loc91 = loc("multiply.337")
#loc92 = loc("add.343")
#loc93 = loc("broadcast.317")
#loc94 = loc("reshape.318")
#loc95 = loc("transpose.319")
#loc96 = loc("dot.344")
#loc97 = loc("multiply.347")
#loc98 = loc("broadcast.294")
#loc99 = loc("and.297")
#loc100 = loc("reshape.298")
#loc101 = loc("broadcast.197")
#loc102 = loc("compare.198")
#loc103 = loc("convert.199")
#loc104 = loc("multiply.205")
#loc105 = loc("reshape.207")
#loc106 = loc("slice.268")
#loc107 = loc("reshape.258")
#loc108 = loc("reshape.263")
#loc109 = loc("convert.269")
#loc110 = loc("add.272")
#loc111 = loc("compare.275")
#loc112 = loc("select.277")
#loc113 = loc("floor.227")
#loc114 = loc("convert.228")
#loc115 = loc("clamp.231")
#loc116 = loc("compare.240")
#loc117 = loc("add.237")
#loc118 = loc("select.241")
#loc119 = loc("reshape.242")
#loc120 = loc("gather.279")
#loc121 = loc("select.301")
#loc122 = loc("not.299")
#loc123 = loc("select.302")
#loc124 = loc("reshape.350")
#loc125 = loc("broadcast.351")
#loc126 = loc("add.352")
#loc127 = loc("convert.353")
#loc128 = loc("reduce.359")
#loc129 = loc("broadcast.360")
#loc130 = loc("subtract.361")
#loc131 = loc("exponential.362")
#loc132 = loc("reduce.368")
#loc133 = loc("broadcast.369")
#loc134 = loc("divide.370")
#loc135 = loc("convert.371")
#loc136 = loc("broadcast.190")
#loc137 = loc("reshape.191")
#loc138 = loc("dot.372")
#loc139 = loc("reshape.376")
#loc140 = loc("reshape.179")
#loc141 = loc("reshape.181")
#loc142 = loc("transpose.182")
#loc143 = loc("dot.377")
#loc144 = loc("reshape.378")
#loc145 = loc("add.381")
#loc146 = loc("reshape.412")
#loc147 = loc("convert.382")
#loc148 = loc("power.384")
#loc149 = loc("reduce.391")
#loc150 = loc("multiply.400")
#loc151 = loc("reshape.401")
#loc152 = loc("add.405")
#loc153 = loc("rsqrt.406")
#loc154 = loc("reshape.407")
#loc155 = loc("broadcast.408")
#loc156 = loc("multiply.409")
#loc157 = loc("convert.410")
#loc158 = loc("multiply.416")
#loc159 = loc("reshape.425")
#loc160 = loc("reshape.421")
#loc161 = loc("reshape.423")
#loc162 = loc("transpose.424")
#loc163 = loc("dot.426")
#loc164 = loc("reshape.427")
#loc165 = loc("logistic.428")
#loc166 = loc("multiply.429")
#loc167 = loc("reshape.170")
#loc168 = loc("reshape.172")
#loc169 = loc("transpose.173")
#loc170 = loc("dot.418")
#loc171 = loc("reshape.419")
#loc172 = loc("multiply.430")
#loc173 = loc("reshape.431")
#loc174 = loc("reshape.165")
#loc175 = loc("reshape.167")
#loc176 = loc("transpose.168")
#loc177 = loc("dot.432")
#loc178 = loc("reshape.433")
#loc179 = loc("add.436")
#loc180 = loc("convert.437")
#loc181 = loc("power.439")
#loc182 = loc("reduce.446")
#loc183 = loc("multiply.455")
#loc184 = loc("reshape.456")
#loc185 = loc("add.460")
#loc186 = loc("rsqrt.461")
#loc187 = loc("reshape.462")
#loc188 = loc("broadcast.463")
#loc189 = loc("multiply.464")
#loc190 = loc("convert.465")
#loc191 = loc("multiply.471")
#loc192 = loc("reshape.475")
#loc193 = loc("reshape.156")
#loc194 = loc("reshape.158")
#loc195 = loc("transpose.159")
#loc196 = loc("dot.476")
#loc197 = loc("reshape.477")
#loc198 = loc(fused[#loc121, #loc122])
------------------ END OF MLIR MODULE ------------------
[james] gspmdAnnotationsExist force-set to false 
[james] gspmdAnnotationsExist force-set to false 
[james] gspmdAnnotationsExist force-set to false 
[james] gspmdAnnotationsExist force-set to false 
2026-01-02 18:37:47.011 (  18.070s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module shlo_compiler:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.30")
#loc4 = loc("p3.38")
#loc5 = loc("p4.43")
#loc6 = loc("p5.79")
#loc7 = loc("p6.119")
#loc8 = loc("p7.127")
#loc9 = loc("p8.147")
#loc10 = loc("p9.155")
#loc11 = loc("p10.164")
#loc12 = loc("p11.169")
#loc13 = loc("p12.178")
#loc14 = loc("p13.257")
#loc15 = loc("p14.290")
#loc16 = loc("p15.321")
#loc17 = loc("p16.411")
#loc18 = loc("p17.420")
#loc19 = loc("p18.466")
#loc71 = loc("scatter.125")
#loc77 = loc("scatter.153")
#loc143 = loc("dot.377")
#loc177 = loc("dot.432")
module @SyncTensorsGraph.479 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]> loc(#loc)
  func.func @main(%arg0: tensor<1xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.30"), %arg3: tensor<1x1xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p3.38"), %arg4: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p4.43"), %arg5: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p5.79"), %arg6: tensor<1x8x128x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p6.119"), %arg7: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p7.127"), %arg8: tensor<1x8x128x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_4"} loc("p8.147"), %arg9: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"} loc("p9.155"), %arg10: tensor<3072x8192xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p10.164"), %arg11: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p11.169"), %arg12: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p12.178"), %arg13: tensor<1x32xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p13.257"), %arg14: tensor<i1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p14.290"), %arg15: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p15.321"), %arg16: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p16.411"), %arg17: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p17.420"), %arg18: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"} loc("p18.466")) -> (tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0:4 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18) in_shardings=[<@mesh, [{}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}, {"_axis_0"}]>, <@mesh, [{}, {}]>, <@mesh, []>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>, <@mesh, [{"_axis_0"}, {}]>, <@mesh, [{}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}, {}]>, <@mesh, [{}, {}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg19: tensor<1xi64> loc("p0.3"), %arg20: tensor<64xf32> loc("p1.13"), %arg21: tensor<512x3072xbf16> loc("p2.30"), %arg22: tensor<1x1xi64> loc("p3.38"), %arg23: tensor<128256x3072xbf16> loc("p4.43"), %arg24: tensor<3072xbf16> loc("p5.79"), %arg25: tensor<1x4x128x128xbf16> loc("p6.119"), %arg26: tensor<512x3072xbf16> loc("p7.127"), %arg27: tensor<1x4x128x128xbf16> loc("p8.147"), %arg28: tensor<128256x3072xbf16> loc("p9.155"), %arg29: tensor<3072x4096xbf16> loc("p10.164"), %arg30: tensor<4096x3072xbf16> loc("p11.169"), %arg31: tensor<3072x1536xbf16> loc("p12.178"), %arg32: tensor<1x32xi64> loc("p13.257"), %arg33: tensor<i1> loc("p14.290"), %arg34: tensor<1536x3072xbf16> loc("p15.321"), %arg35: tensor<3072xbf16> loc("p16.411"), %arg36: tensor<4096x3072xbf16> loc("p17.420"), %arg37: tensor<3072xbf16> loc("p18.466")) {
      %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc)
      %cst_0 = stablehlo.constant dense<0xFF800000> : tensor<f32> loc(#loc)
      %c = stablehlo.constant dense<0> : tensor<1xi64> loc(#loc)
      %c_1 = stablehlo.constant dense<128> : tensor<1xi64> loc(#loc)
      %cst_2 = stablehlo.constant dense<2.000000e+00> : tensor<f32> loc(#loc)
      %cst_3 = stablehlo.constant dense<3.25520843E-4> : tensor<1x1xf32> loc(#loc)
      %cst_4 = stablehlo.constant dense<9.99999974E-6> : tensor<1x1x1xf32> loc(#loc)
      %cst_5 = stablehlo.constant dense<8.837890e-02> : tensor<bf16> loc(#loc)
      %c_6 = stablehlo.constant dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1> loc(#loc)
      %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<bf16> loc(#loc)
      %cst_8 = stablehlo.constant dense<-3.389530e+38> : tensor<bf16> loc(#loc)
      %c_9 = stablehlo.constant dense<0> : tensor<i64> loc(#loc)
      %cst_10 = stablehlo.constant dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32> loc(#loc)
      %c_11 = stablehlo.constant dense<31> : tensor<i64> loc(#loc)
      %c_12 = stablehlo.constant dense<"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tensor<1x128xi64> loc(#loc)
      %c_13 = stablehlo.constant dense<32> : tensor<i64> loc(#loc)
      %1 = stablehlo.broadcast_in_dim %c_13, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
      %2 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
      %3 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
      %4 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<1x1x1x32xbf16> loc(#loc)
      %5 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<1x1x1x32xbf16> loc(#loc)
      %6 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<bf16>) -> tensor<1x128xbf16> loc(#loc)
      %7 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<bf16>) -> tensor<1x1x1x128xbf16> loc(#loc)
      %8 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<bf16>) -> tensor<1x12x1x128xbf16> loc(#loc)
      %9 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32> loc(#loc)
      %10 = stablehlo.reshape %arg19 : (tensor<1xi64>) -> tensor<1x1x1xi64> loc(#loc20)
      %11 = stablehlo.reshape %10 : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc21)
      %12 = stablehlo.compare  LT, %11, %c : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1> loc(#loc22)
      %13 = stablehlo.add %11, %c_1 : tensor<1xi64> loc(#loc23)
      %14 = stablehlo.select %12, %13, %11 : tensor<1xi1>, tensor<1xi64> loc(#loc24)
      %15 = stablehlo.reshape %14 : (tensor<1xi64>) -> tensor<1x1xi64> loc(#loc25)
      %16 = stablehlo.reshape %arg24 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc26)
      %17 = stablehlo.reshape %arg23 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc27)
      %18 = stablehlo.reshape %17 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc28)
      %19 = stablehlo.reshape %arg22 : (tensor<1x1xi64>) -> tensor<1x1x1xi64> loc(#loc29)
      %20 = stablehlo.reshape %19 : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc30)
      %21 = stablehlo.convert %20 : (tensor<1xi64>) -> tensor<1xui32> loc(#loc31)
      %22 = "stablehlo.gather"(%18, %21) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> : (tensor<128256x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16> loc(#loc32)
      %23 = stablehlo.reshape %22 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc33)
      %24 = stablehlo.convert %23 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc34)
      %25 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32> loc(#loc)
      %26 = stablehlo.power %24, %25 : tensor<1x1x3072xf32> loc(#loc35)
      %27 = stablehlo.reduce(%26 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc36)
      %28 = stablehlo.multiply %27, %cst_3 : tensor<1x1xf32> loc(#loc37)
      %29 = stablehlo.reshape %28 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc38)
      %30 = stablehlo.add %29, %cst_4 : tensor<1x1x1xf32> loc(#loc39)
      %31 = stablehlo.rsqrt %30 : tensor<1x1x1xf32> loc(#loc40)
      %32 = stablehlo.reshape %31 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc41)
      %33 = stablehlo.broadcast_in_dim %32, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc42)
      %34 = stablehlo.multiply %24, %33 : tensor<1x1x3072xf32> loc(#loc43)
      %35 = stablehlo.convert %34 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc44)
      %36 = stablehlo.multiply %16, %35 : tensor<1x1x3072xbf16> loc(#loc45)
      %37 = stablehlo.reshape %36 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc46)
      %38 = stablehlo.reshape %arg21 : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc47)
      %39 = stablehlo.reshape %38 : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc48)
      %40 = stablehlo.transpose %39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16> loc(#loc49)
      %41 = stablehlo.dot_general %37, %40, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16> loc(#loc50)
      %42 = stablehlo.reshape %41 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc51)
      %43 = stablehlo.reshape %arg20 : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc52)
      %44 = stablehlo.reshape %43 : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc53)
      %45 = stablehlo.convert %10 : (tensor<1x1x1xi64>) -> tensor<1x1x1xf32> loc(#loc54)
      %46 = stablehlo.dot_general %44, %45, batching_dims = [0] x [0], contracting_dims = [2] x [1] : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32> loc(#loc55)
      %47 = stablehlo.reshape %46 : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32> loc(#loc56)
      %48 = stablehlo.concatenate %47, %47, dim = 2 : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32> loc(#loc57)
      %49 = stablehlo.cosine %48 : tensor<1x1x128xf32> loc(#loc58)
      %50 = stablehlo.convert %49 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc59)
      %51 = stablehlo.broadcast_in_dim %50, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc60)
      %52 = stablehlo.multiply %42, %51 : tensor<1x4x1x128xbf16> loc(#loc61)
      %53 = stablehlo.slice %42 [0:1, 0:4, 0:1, 64:128] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16> loc(#loc62)
      %54 = stablehlo.negate %53 : tensor<1x4x1x64xbf16> loc(#loc63)
      %55 = stablehlo.slice %42 [0:1, 0:4, 0:1, 0:64] : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16> loc(#loc64)
      %56 = stablehlo.concatenate %54, %55, dim = 3 : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc65)
      %57 = stablehlo.sine %48 : tensor<1x1x128xf32> loc(#loc66)
      %58 = stablehlo.convert %57 : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc67)
      %59 = stablehlo.broadcast_in_dim %58, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc68)
      %60 = stablehlo.multiply %56, %59 : tensor<1x4x1x128xbf16> loc(#loc69)
      %61 = stablehlo.add %52, %60 : tensor<1x4x1x128xbf16> loc(#loc70)
      %62 = "stablehlo.scatter"(%arg25, %15, %61) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg38: tensor<bf16> loc("scatter.125"), %arg39: tensor<bf16> loc("scatter.125")):
        stablehlo.return %arg39 : tensor<bf16> loc(#loc)
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16> loc(#loc71)
      %63 = stablehlo.reshape %arg26 : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc72)
      %64 = stablehlo.reshape %63 : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc73)
      %65 = stablehlo.transpose %64, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16> loc(#loc74)
      %66 = stablehlo.dot_general %37, %65, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16> loc(#loc75)
      %67 = stablehlo.reshape %66 : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc76)
      %68 = "stablehlo.scatter"(%arg27, %15, %67) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg38: tensor<bf16> loc("scatter.153"), %arg39: tensor<bf16> loc("scatter.153")):
        stablehlo.return %arg39 : tensor<bf16> loc(#loc)
      }) : (tensor<1x4x128x128xbf16>, tensor<1x1xi64>, tensor<1x4x1x128xbf16>) -> tensor<1x4x128x128xbf16> loc(#loc77)
      %69 = stablehlo.reshape %arg37 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc78)
      %70 = stablehlo.reshape %arg34 : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16> loc(#loc79)
      %71 = stablehlo.reshape %70 : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc80)
      %72 = stablehlo.transpose %71, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16> loc(#loc81)
      %73 = stablehlo.dot_general %37, %72, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16> loc(#loc82)
      %74 = stablehlo.reshape %73 : (tensor<1x1536xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc83)
      %75 = stablehlo.broadcast_in_dim %50, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc84)
      %76 = stablehlo.multiply %74, %75 : tensor<1x12x1x128xbf16> loc(#loc85)
      %77 = stablehlo.slice %74 [0:1, 0:12, 0:1, 64:128] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16> loc(#loc86)
      %78 = stablehlo.negate %77 : tensor<1x12x1x64xbf16> loc(#loc87)
      %79 = stablehlo.slice %74 [0:1, 0:12, 0:1, 0:64] : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16> loc(#loc88)
      %80 = stablehlo.concatenate %78, %79, dim = 3 : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc89)
      %81 = stablehlo.broadcast_in_dim %58, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc90)
      %82 = stablehlo.multiply %80, %81 : tensor<1x12x1x128xbf16> loc(#loc91)
      %83 = stablehlo.add %76, %82 : tensor<1x12x1x128xbf16> loc(#loc92)
      %84 = stablehlo.broadcast_in_dim %62, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16> loc(#loc93)
      %85 = stablehlo.reshape %84 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16> loc(#loc94)
      %86 = stablehlo.transpose %85, dims = [0, 1, 3, 2] {result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16> loc(#loc95)
      %87 = stablehlo.dot_general %83, %86, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x12x1x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc96)
      %88 = stablehlo.multiply %87, %8 : tensor<1x12x1x128xbf16> loc(#loc97)
      %89 = stablehlo.broadcast_in_dim %arg33, dims = [] : (tensor<i1>) -> tensor<128xi1> loc(#loc98)
      %90 = stablehlo.and %89, %c_6 : tensor<128xi1> loc(#loc99)
      %91 = stablehlo.reshape %90 : (tensor<128xi1>) -> tensor<1x1x1x128xi1> loc(#loc100)
      %92 = stablehlo.broadcast_in_dim %11, dims = [0] : (tensor<1xi64>) -> tensor<1x128xi64> loc(#loc101)
      %93 = stablehlo.compare  GT, %c_12, %92 : (tensor<1x128xi64>, tensor<1x128xi64>) -> tensor<1x128xi1> loc(#loc102)
      %94 = stablehlo.convert %93 : (tensor<1x128xi1>) -> tensor<1x128xbf16> loc(#loc103)
      %95 = stablehlo.multiply %94, %6 : tensor<1x128xbf16> loc(#loc104)
      %96 = stablehlo.reshape %95 : (tensor<1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc105)
      %97 = stablehlo.slice %96 [0:1, 0:1, 0:1, 0:32] : (tensor<1x1x1x128xbf16>) -> tensor<1x1x1x32xbf16> loc(#loc106)
      %98 = stablehlo.reshape %arg32 : (tensor<1x32xi64>) -> tensor<1x1x32xi64> loc(#loc107)
      %99 = stablehlo.reshape %98 : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64> loc(#loc108)
      %100 = stablehlo.convert %99 : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16> loc(#loc109)
      %101 = stablehlo.add %97, %100 : tensor<1x1x1x32xbf16> loc(#loc110)
      %102 = stablehlo.compare  EQ, %101, %5 : (tensor<1x1x1x32xbf16>, tensor<1x1x1x32xbf16>) -> tensor<1x1x1x32xi1> loc(#loc111)
      %103 = stablehlo.select %102, %4, %97 : tensor<1x1x1x32xi1>, tensor<1x1x1x32xbf16> loc(#loc112)
      %104 = stablehlo.floor %cst_10 : tensor<128xf32> loc(#loc113)
      %105 = stablehlo.convert %104 : (tensor<128xf32>) -> tensor<128xi64> loc(#loc114)
      %106 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<i64>) -> tensor<128xi64> loc(#loc)
      %107 = stablehlo.clamp %106, %105, %2 : tensor<128xi64> loc(#loc115)
      %108 = stablehlo.compare  LT, %107, %3 : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1> loc(#loc116)
      %109 = stablehlo.add %107, %1 : tensor<128xi64> loc(#loc117)
      %110 = stablehlo.select %108, %109, %107 : tensor<128xi1>, tensor<128xi64> loc(#loc118)
      %111 = stablehlo.reshape %110 : (tensor<128xi64>) -> tensor<128x1xi64> loc(#loc119)
      %112 = "stablehlo.gather"(%103, %111) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x1x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x1x128xbf16> loc(#loc120)
      %113 = stablehlo.select %91, %112, %7 : tensor<1x1x1x128xi1>, tensor<1x1x1x128xbf16> loc(#loc198)
      %114 = stablehlo.select %91, %113, %96 : tensor<1x1x1x128xi1>, tensor<1x1x1x128xbf16> loc(#loc123)
      %115 = stablehlo.reshape %114 : (tensor<1x1x1x128xbf16>) -> tensor<1x1x128xbf16> loc(#loc124)
      %116 = stablehlo.broadcast_in_dim %115, dims = [0, 2, 3] : (tensor<1x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc125)
      %117 = stablehlo.add %88, %116 : tensor<1x12x1x128xbf16> loc(#loc126)
      %118 = stablehlo.convert %117 : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32> loc(#loc127)
      %119 = stablehlo.reduce(%118 init: %cst_0) applies stablehlo.maximum across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32> loc(#loc128)
      %120 = stablehlo.broadcast_in_dim %119, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32> loc(#loc129)
      %121 = stablehlo.subtract %118, %120 : tensor<1x12x1x128xf32> loc(#loc130)
      %122 = stablehlo.exponential %121 : tensor<1x12x1x128xf32> loc(#loc131)
      %123 = stablehlo.reduce(%122 init: %cst) applies stablehlo.add across dimensions = [3] : (tensor<1x12x1x128xf32>, tensor<f32>) -> tensor<1x12x1xf32> loc(#loc132)
      %124 = stablehlo.broadcast_in_dim %123, dims = [0, 1, 2] : (tensor<1x12x1xf32>) -> tensor<1x12x1x128xf32> loc(#loc133)
      %125 = stablehlo.divide %122, %124 : tensor<1x12x1x128xf32> loc(#loc134)
      %126 = stablehlo.convert %125 : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16> loc(#loc135)
      %127 = stablehlo.broadcast_in_dim %68, dims = [0, 1, 3, 4] : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16> loc(#loc136)
      %128 = stablehlo.reshape %127 : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16> loc(#loc137)
      %129 = stablehlo.dot_general %126, %128, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}} : (tensor<1x12x1x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc138)
      %130 = stablehlo.reshape %129 : (tensor<1x12x1x128xbf16>) -> tensor<1x1536xbf16> loc(#loc139)
      %131 = stablehlo.reshape %arg31 : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16> loc(#loc140)
      %132 = stablehlo.reshape %131 : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16> loc(#loc141)
      %133 = stablehlo.transpose %132, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16> loc(#loc142)
      %134 = stablehlo.dot_general %130, %133, contracting_dims = [1] x [0] : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc143)
      %135 = "stablehlo.all_reduce"(%134) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg38: tensor<bf16> loc("dot.377"), %arg39: tensor<bf16> loc("dot.377")):
        %192 = stablehlo.add %arg38, %arg39 : tensor<bf16> loc(#loc143)
        stablehlo.return %192 : tensor<bf16> loc(#loc143)
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc143)
      %136 = stablehlo.reshape %135 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc144)
      %137 = stablehlo.add %23, %136 : tensor<1x1x3072xbf16> loc(#loc145)
      %138 = stablehlo.reshape %arg35 : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc146)
      %139 = stablehlo.convert %137 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc147)
      %140 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<1x1x3072xf32> loc(#loc)
      %141 = stablehlo.power %139, %140 : tensor<1x1x3072xf32> loc(#loc148)
      %142 = stablehlo.reduce(%141 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc149)
      %143 = stablehlo.multiply %142, %cst_3 : tensor<1x1xf32> loc(#loc150)
      %144 = stablehlo.reshape %143 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc151)
      %145 = stablehlo.add %144, %cst_4 : tensor<1x1x1xf32> loc(#loc152)
      %146 = stablehlo.rsqrt %145 : tensor<1x1x1xf32> loc(#loc153)
      %147 = stablehlo.reshape %146 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc154)
      %148 = stablehlo.broadcast_in_dim %147, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc155)
      %149 = stablehlo.multiply %139, %148 : tensor<1x1x3072xf32> loc(#loc156)
      %150 = stablehlo.convert %149 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc157)
      %151 = stablehlo.multiply %138, %150 : tensor<1x1x3072xbf16> loc(#loc158)
      %152 = stablehlo.reshape %151 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc159)
      %153 = stablehlo.reshape %arg36 : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc160)
      %154 = stablehlo.reshape %153 : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc161)
      %155 = stablehlo.transpose %154, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16> loc(#loc162)
      %156 = stablehlo.dot_general %152, %155, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16> loc(#loc163)
      %157 = stablehlo.reshape %156 : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc164)
      %158 = stablehlo.logistic %157 : tensor<1x1x4096xbf16> loc(#loc165)
      %159 = stablehlo.multiply %157, %158 : tensor<1x1x4096xbf16> loc(#loc166)
      %160 = stablehlo.reshape %arg30 : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc167)
      %161 = stablehlo.reshape %160 : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc168)
      %162 = stablehlo.transpose %161, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16> loc(#loc169)
      %163 = stablehlo.dot_general %152, %162, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16> loc(#loc170)
      %164 = stablehlo.reshape %163 : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc171)
      %165 = stablehlo.multiply %159, %164 : tensor<1x1x4096xbf16> loc(#loc172)
      %166 = stablehlo.reshape %165 : (tensor<1x1x4096xbf16>) -> tensor<1x4096xbf16> loc(#loc173)
      %167 = stablehlo.reshape %arg29 : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16> loc(#loc174)
      %168 = stablehlo.reshape %167 : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc175)
      %169 = stablehlo.transpose %168, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16> loc(#loc176)
      %170 = stablehlo.dot_general %166, %169, contracting_dims = [1] x [0] : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc177)
      %171 = "stablehlo.all_reduce"(%170) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
      ^bb0(%arg38: tensor<bf16> loc("dot.432"), %arg39: tensor<bf16> loc("dot.432")):
        %192 = stablehlo.add %arg38, %arg39 : tensor<bf16> loc(#loc177)
        stablehlo.return %192 : tensor<bf16> loc(#loc177)
      }) : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc177)
      %172 = stablehlo.reshape %171 : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc178)
      %173 = stablehlo.add %137, %172 : tensor<1x1x3072xbf16> loc(#loc179)
      %174 = stablehlo.convert %173 : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc180)
      %175 = stablehlo.power %174, %9 : tensor<1x1x3072xf32> loc(#loc181)
      %176 = stablehlo.reduce(%175 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<1x1x3072xf32>, tensor<f32>) -> tensor<1x1xf32> loc(#loc182)
      %177 = stablehlo.multiply %176, %cst_3 : tensor<1x1xf32> loc(#loc183)
      %178 = stablehlo.reshape %177 : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc184)
      %179 = stablehlo.add %178, %cst_4 : tensor<1x1x1xf32> loc(#loc185)
      %180 = stablehlo.rsqrt %179 : tensor<1x1x1xf32> loc(#loc186)
      %181 = stablehlo.reshape %180 : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc187)
      %182 = stablehlo.broadcast_in_dim %181, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc188)
      %183 = stablehlo.multiply %174, %182 : tensor<1x1x3072xf32> loc(#loc189)
      %184 = stablehlo.convert %183 : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc190)
      %185 = stablehlo.multiply %69, %184 : tensor<1x1x3072xbf16> loc(#loc191)
      %186 = stablehlo.reshape %185 : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc192)
      %187 = stablehlo.reshape %arg28 : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc193)
      %188 = stablehlo.reshape %187 : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc194)
      %189 = stablehlo.transpose %188, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc195)
      %190 = stablehlo.dot_general %186, %189, contracting_dims = [1] x [0] : (tensor<1x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<1x128256xbf16> loc(#loc196)
      %191 = stablehlo.reshape %190 : (tensor<1x128256xbf16>) -> tensor<1x1x128256xbf16> loc(#loc197)
      sdy.return %62, %68, %190, %191 : tensor<1x4x128x128xbf16>, tensor<1x4x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16> loc(#loc)
    } : (tensor<1xi64>, tensor<64xf32>, tensor<1024x3072xbf16>, tensor<1x1xi64>, tensor<128256x3072xbf16>, tensor<3072xbf16>, tensor<1x8x128x128xbf16>, tensor<1024x3072xbf16>, tensor<1x8x128x128xbf16>, tensor<128256x3072xbf16>, tensor<3072x8192xbf16>, tensor<8192x3072xbf16>, tensor<3072x3072xbf16>, tensor<1x32xi64>, tensor<i1>, tensor<3072x3072xbf16>, tensor<3072xbf16>, tensor<8192x3072xbf16>, tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) loc(#loc)
    return %0#0, %0#1, %0#2, %0#3 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc20 = loc("reshape.4")
#loc21 = loc("reshape.6")
#loc22 = loc("compare.115")
#loc23 = loc("add.112")
#loc24 = loc("select.116")
#loc25 = loc("reshape.117")
#loc26 = loc("reshape.80")
#loc27 = loc("reshape.44")
#loc28 = loc("reshape.46")
#loc29 = loc("reshape.39")
#loc30 = loc("reshape.42")
#loc31 = loc("convert.47")
#loc32 = loc("gather.48")
#loc33 = loc("reshape.49")
#loc34 = loc("convert.50")
#loc35 = loc("power.52")
#loc36 = loc("reduce.59")
#loc37 = loc("multiply.68")
#loc38 = loc("reshape.69")
#loc39 = loc("add.73")
#loc40 = loc("rsqrt.74")
#loc41 = loc("reshape.75")
#loc42 = loc("broadcast.76")
#loc43 = loc("multiply.77")
#loc44 = loc("convert.78")
#loc45 = loc("multiply.84")
#loc46 = loc("reshape.85")
#loc47 = loc("reshape.31")
#loc48 = loc("reshape.33")
#loc49 = loc("transpose.34")
#loc50 = loc("dot.86")
#loc51 = loc("transpose.89")
#loc52 = loc("reshape.14")
#loc53 = loc("reshape.19")
#loc54 = loc("convert.11")
#loc55 = loc("dot.22")
#loc56 = loc("transpose.23")
#loc57 = loc("concatenate.24")
#loc58 = loc("cosine.98")
#loc59 = loc("convert.101")
#loc60 = loc("broadcast.104")
#loc61 = loc("multiply.105")
#loc62 = loc("slice.91")
#loc63 = loc("negate.92")
#loc64 = loc("slice.90")
#loc65 = loc("concatenate.93")
#loc66 = loc("sine.25")
#loc67 = loc("convert.28")
#loc68 = loc("broadcast.95")
#loc69 = loc("multiply.96")
#loc70 = loc("add.108")
#loc72 = loc("reshape.128")
#loc73 = loc("reshape.130")
#loc74 = loc("transpose.131")
#loc75 = loc("dot.133")
#loc76 = loc("transpose.136")
#loc78 = loc("reshape.467")
#loc79 = loc("reshape.322")
#loc80 = loc("reshape.324")
#loc81 = loc("transpose.325")
#loc82 = loc("dot.327")
#loc83 = loc("transpose.330")
#loc84 = loc("broadcast.339")
#loc85 = loc("multiply.340")
#loc86 = loc("slice.332")
#loc87 = loc("negate.333")
#loc88 = loc("slice.331")
#loc89 = loc("concatenate.334")
#loc90 = loc("broadcast.336")
#loc91 = loc("multiply.337")
#loc92 = loc("add.343")
#loc93 = loc("broadcast.317")
#loc94 = loc("reshape.318")
#loc95 = loc("transpose.319")
#loc96 = loc("dot.344")
#loc97 = loc("multiply.347")
#loc98 = loc("broadcast.294")
#loc99 = loc("and.297")
#loc100 = loc("reshape.298")
#loc101 = loc("broadcast.197")
#loc102 = loc("compare.198")
#loc103 = loc("convert.199")
#loc104 = loc("multiply.205")
#loc105 = loc("reshape.207")
#loc106 = loc("slice.268")
#loc107 = loc("reshape.258")
#loc108 = loc("reshape.263")
#loc109 = loc("convert.269")
#loc110 = loc("add.272")
#loc111 = loc("compare.275")
#loc112 = loc("select.277")
#loc113 = loc("floor.227")
#loc114 = loc("convert.228")
#loc115 = loc("clamp.231")
#loc116 = loc("compare.240")
#loc117 = loc("add.237")
#loc118 = loc("select.241")
#loc119 = loc("reshape.242")
#loc120 = loc("gather.279")
#loc121 = loc("select.301")
#loc122 = loc("not.299")
#loc123 = loc("select.302")
#loc124 = loc("reshape.350")
#loc125 = loc("broadcast.351")
#loc126 = loc("add.352")
#loc127 = loc("convert.353")
#loc128 = loc("reduce.359")
#loc129 = loc("broadcast.360")
#loc130 = loc("subtract.361")
#loc131 = loc("exponential.362")
#loc132 = loc("reduce.368")
#loc133 = loc("broadcast.369")
#loc134 = loc("divide.370")
#loc135 = loc("convert.371")
#loc136 = loc("broadcast.190")
#loc137 = loc("reshape.191")
#loc138 = loc("dot.372")
#loc139 = loc("reshape.376")
#loc140 = loc("reshape.179")
#loc141 = loc("reshape.181")
#loc142 = loc("transpose.182")
#loc144 = loc("reshape.378")
#loc145 = loc("add.381")
#loc146 = loc("reshape.412")
#loc147 = loc("convert.382")
#loc148 = loc("power.384")
#loc149 = loc("reduce.391")
#loc150 = loc("multiply.400")
#loc151 = loc("reshape.401")
#loc152 = loc("add.405")
#loc153 = loc("rsqrt.406")
#loc154 = loc("reshape.407")
#loc155 = loc("broadcast.408")
#loc156 = loc("multiply.409")
#loc157 = loc("convert.410")
#loc158 = loc("multiply.416")
#loc159 = loc("reshape.425")
#loc160 = loc("reshape.421")
#loc161 = loc("reshape.423")
#loc162 = loc("transpose.424")
#loc163 = loc("dot.426")
#loc164 = loc("reshape.427")
#loc165 = loc("logistic.428")
#loc166 = loc("multiply.429")
#loc167 = loc("reshape.170")
#loc168 = loc("reshape.172")
#loc169 = loc("transpose.173")
#loc170 = loc("dot.418")
#loc171 = loc("reshape.419")
#loc172 = loc("multiply.430")
#loc173 = loc("reshape.431")
#loc174 = loc("reshape.165")
#loc175 = loc("reshape.167")
#loc176 = loc("transpose.168")
#loc178 = loc("reshape.433")
#loc179 = loc("add.436")
#loc180 = loc("convert.437")
#loc181 = loc("power.439")
#loc182 = loc("reduce.446")
#loc183 = loc("multiply.455")
#loc184 = loc("reshape.456")
#loc185 = loc("add.460")
#loc186 = loc("rsqrt.461")
#loc187 = loc("reshape.462")
#loc188 = loc("broadcast.463")
#loc189 = loc("multiply.464")
#loc190 = loc("convert.465")
#loc191 = loc("multiply.471")
#loc192 = loc("reshape.475")
#loc193 = loc("reshape.156")
#loc194 = loc("reshape.158")
#loc195 = loc("transpose.159")
#loc196 = loc("dot.476")
#loc197 = loc("reshape.477")
#loc198 = loc(fused[#loc121, #loc122])
------------------ END OF MLIR MODULE ------------------
2026-01-02 18:37:47.024 (  18.082s) [        CBC3A000]      module_builder.cc:271      1| Cleaning for XLA ingestion
Out sharding: #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>
Out sharding: #sdy.sharding<@mesh, [{}, {"_axis_0"}, {}, {}]>
Out sharding: #sdy.sharding<@mesh, [{}, {}]>
Out sharding: #sdy.sharding<@mesh, [{}, {}, {}]>
  Out sharding #0, dim #0, axisName.size()=0
  Out sharding #0, dim #1, axisName.size()=1
  Out sharding #0, dim #2, axisName.size()=0
  Out sharding #0, dim #3, axisName.size()=0
Out sharding str for out sharding #0 is: {devices=[1,2,1,1]<=[2]}
  Out sharding #1, dim #0, axisName.size()=0
  Out sharding #1, dim #1, axisName.size()=1
  Out sharding #1, dim #2, axisName.size()=0
  Out sharding #1, dim #3, axisName.size()=0
Out sharding str for out sharding #1 is: {devices=[1,2,1,1]<=[2]}
  Out sharding #2, dim #0, axisName.size()=0
  Out sharding #2, dim #1, axisName.size()=0
Out sharding str for out sharding #2 is: {replicated}
  Out sharding #3, dim #0, axisName.size()=0
  Out sharding #3, dim #1, axisName.size()=0
  Out sharding #3, dim #2, axisName.size()=0
Out sharding str for out sharding #3 is: {replicated}
Module after injecting out sharding result and simplifying main function:
module @SyncTensorsGraph.479 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_shardings = "{{devices=[1,2,1,1]<=[2]},{devices=[1,2,1,1]<=[2]},{replicated},{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1xi64>, %arg1: tensor<64xf32>, %arg2: tensor<1024x3072xbf16>, %arg3: tensor<1x1xi64>, %arg4: tensor<128256x3072xbf16>, %arg5: tensor<3072xbf16>, %arg6: tensor<1x8x128x128xbf16>, %arg7: tensor<1024x3072xbf16>, %arg8: tensor<1x8x128x128xbf16>, %arg9: tensor<128256x3072xbf16>, %arg10: tensor<3072x8192xbf16>, %arg11: tensor<8192x3072xbf16>, %arg12: tensor<3072x3072xbf16>, %arg13: tensor<1x32xi64>, %arg14: tensor<i1>, %arg15: tensor<3072x3072xbf16>, %arg16: tensor<3072xbf16>, %arg17: tensor<8192x3072xbf16>, %arg18: tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<1x8x128x128xbf16>
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<1x8x128x128xbf16>
    %cst_1 = stablehlo.constant dense<0.000000e+00> : tensor<1x128256xbf16>
    %cst_2 = stablehlo.constant dense<0.000000e+00> : tensor<1x1x128256xbf16>
    return %cst, %cst_0, %cst_1, %cst_2 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>
  }
}
2026-01-02 18:37:47.028 (  18.087s) [        CBC3A000]      module_builder.cc:276      1| Done cleaning for XLA ingestion - resulting module:
2026-01-02 18:37:47.028 (  18.087s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module shlo_compiler_cleaned:
#loc = loc(unknown)
module @SyncTensorsGraph.479 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.spmd_output_shardings = "{{devices=[1,2,1,1]<=[2]},{devices=[1,2,1,1]<=[2]},{replicated},{replicated}}", mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1xi64> loc(unknown), %arg1: tensor<64xf32> loc(unknown), %arg2: tensor<1024x3072xbf16> loc(unknown), %arg3: tensor<1x1xi64> loc(unknown), %arg4: tensor<128256x3072xbf16> loc(unknown), %arg5: tensor<3072xbf16> loc(unknown), %arg6: tensor<1x8x128x128xbf16> loc(unknown), %arg7: tensor<1024x3072xbf16> loc(unknown), %arg8: tensor<1x8x128x128xbf16> loc(unknown), %arg9: tensor<128256x3072xbf16> loc(unknown), %arg10: tensor<3072x8192xbf16> loc(unknown), %arg11: tensor<8192x3072xbf16> loc(unknown), %arg12: tensor<3072x3072xbf16> loc(unknown), %arg13: tensor<1x32xi64> loc(unknown), %arg14: tensor<i1> loc(unknown), %arg15: tensor<3072x3072xbf16> loc(unknown), %arg16: tensor<3072xbf16> loc(unknown), %arg17: tensor<8192x3072xbf16> loc(unknown), %arg18: tensor<3072xbf16> loc(unknown)) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<1x8x128x128xbf16> loc(#loc)
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<1x8x128x128xbf16> loc(#loc)
    %cst_1 = stablehlo.constant dense<0.000000e+00> : tensor<1x128256xbf16> loc(#loc)
    %cst_2 = stablehlo.constant dense<0.000000e+00> : tensor<1x1x128256xbf16> loc(#loc)
    return %cst, %cst_0, %cst_1, %cst_2 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16> loc(#loc)
  } loc(#loc)
} loc(#loc)
------------------ END OF MLIR MODULE ------------------
2026-01-02 18:37:47.068 (  18.126s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module ttir:
#loc1 = loc("p0.3")
#loc2 = loc("p1.13")
#loc3 = loc("p2.30")
#loc4 = loc("p3.38")
#loc5 = loc("p4.43")
#loc6 = loc("p5.79")
#loc7 = loc("p6.119")
#loc8 = loc("p7.127")
#loc9 = loc("p8.147")
#loc10 = loc("p9.155")
#loc11 = loc("p10.164")
#loc12 = loc("p11.169")
#loc13 = loc("p12.178")
#loc14 = loc("p13.257")
#loc15 = loc("p14.290")
#loc16 = loc("p15.321")
#loc17 = loc("p16.411")
#loc18 = loc("p17.420")
#loc19 = loc("p18.466")
module @SyncTensorsGraph.479 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.479 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
      func.func @main(%arg0: tensor<1xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.30"), %arg3: tensor<1x1xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p3.38"), %arg4: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p4.43"), %arg5: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p5.79"), %arg6: tensor<1x8x128x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p6.119"), %arg7: tensor<1024x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p7.127"), %arg8: tensor<1x8x128x128xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_4"} loc("p8.147"), %arg9: tensor<128256x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"} loc("p9.155"), %arg10: tensor<3072x8192xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p10.164"), %arg11: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p11.169"), %arg12: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p12.178"), %arg13: tensor<1x32xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p13.257"), %arg14: tensor<i1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p14.290"), %arg15: tensor<3072x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p15.321"), %arg16: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p16.411"), %arg17: tensor<8192x3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p17.420"), %arg18: tensor<3072xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"} loc("p18.466")) -> (tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x1x128256xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.mesh_shard"(%arg0) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1xi64>) -> tensor<1xi64> loc(#loc)
        %1 = "ttir.mesh_shard"(%arg1) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xf32>) -> tensor<64xf32> loc(#loc)
        %2 = "ttir.mesh_shard"(%arg2) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc)
        %3 = "ttir.mesh_shard"(%arg3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x1xi64>) -> tensor<1x1xi64> loc(#loc)
        %4 = "ttir.mesh_shard"(%arg4) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc)
        %5 = "ttir.mesh_shard"(%arg5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc)
        %6 = "ttir.mesh_shard"(%arg6) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16> loc(#loc)
        %7 = "ttir.mesh_shard"(%arg7) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc)
        %8 = "ttir.mesh_shard"(%arg8) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16> loc(#loc)
        %9 = "ttir.mesh_shard"(%arg9) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc)
        %10 = "ttir.mesh_shard"(%arg10) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16>) -> tensor<3072x4096xbf16> loc(#loc)
        %11 = "ttir.mesh_shard"(%arg11) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc)
        %12 = "ttir.mesh_shard"(%arg12) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>) -> tensor<3072x1536xbf16> loc(#loc)
        %13 = "ttir.mesh_shard"(%arg13) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x32xi64>) -> tensor<1x32xi64> loc(#loc)
        %14 = "ttir.mesh_shard"(%arg14) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<i1>) -> tensor<i1> loc(#loc)
        %15 = "ttir.mesh_shard"(%arg15) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc)
        %16 = "ttir.mesh_shard"(%arg16) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc)
        %17 = "ttir.mesh_shard"(%arg17) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc)
        %18 = "ttir.mesh_shard"(%arg18) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072xbf16>) -> tensor<3072xbf16> loc(#loc)
        %19 = "ttir.constant"() <{value = dense<0> : tensor<1xi64>}> : () -> tensor<1xi64> loc(#loc)
        %20 = "ttir.constant"() <{value = dense<128> : tensor<1xi64>}> : () -> tensor<1xi64> loc(#loc)
        %21 = "ttir.constant"() <{value = dense<2.000000e+00> : tensor<f32>}> : () -> tensor<f32> loc(#loc)
        %22 = "ttir.constant"() <{value = dense<3.25520843E-4> : tensor<1x1xf32>}> : () -> tensor<1x1xf32> loc(#loc)
        %23 = "ttir.constant"() <{value = dense<9.99999974E-6> : tensor<1x1x1xf32>}> : () -> tensor<1x1x1xf32> loc(#loc)
        %24 = "ttir.constant"() <{value = dense<8.837890e-02> : tensor<bf16>}> : () -> tensor<bf16> loc(#loc)
        %25 = "ttir.constant"() <{value = dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1>}> : () -> tensor<128xi1> loc(#loc)
        %26 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<bf16>}> : () -> tensor<bf16> loc(#loc)
        %27 = "ttir.constant"() <{value = dense<-3.389530e+38> : tensor<bf16>}> : () -> tensor<bf16> loc(#loc)
        %28 = "ttir.constant"() <{value = dense<0> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
        %29 = "ttir.constant"() <{value = dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>}> : () -> tensor<128xf32> loc(#loc)
        %30 = "ttir.constant"() <{value = dense<31> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
        %31 = "ttir.constant"() <{value = dense<"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tensor<1x128xi64>}> : () -> tensor<1x128xi64> loc(#loc)
        %32 = "ttir.constant"() <{value = dense<32> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
        %33 = "ttir.reshape"(%32) <{shape = [1 : i32]}> : (tensor<i64>) -> tensor<1xi64> loc(#loc)
        %34 = "ttir.broadcast"(%33) <{broadcast_dimensions = array<i64: 128>}> : (tensor<1xi64>) -> tensor<128xi64> loc(#loc)
        %35 = "ttir.reshape"(%30) <{shape = [1 : i32]}> : (tensor<i64>) -> tensor<1xi64> loc(#loc)
        %36 = "ttir.broadcast"(%35) <{broadcast_dimensions = array<i64: 128>}> : (tensor<1xi64>) -> tensor<128xi64> loc(#loc)
        %37 = "ttir.reshape"(%28) <{shape = [1 : i32]}> : (tensor<i64>) -> tensor<1xi64> loc(#loc)
        %38 = "ttir.broadcast"(%37) <{broadcast_dimensions = array<i64: 128>}> : (tensor<1xi64>) -> tensor<128xi64> loc(#loc)
        %39 = "ttir.reshape"(%27) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>) -> tensor<1x1x1x1xbf16> loc(#loc)
        %40 = "ttir.broadcast"(%39) <{broadcast_dimensions = array<i64: 1, 1, 1, 32>}> : (tensor<1x1x1x1xbf16>) -> tensor<1x1x1x32xbf16> loc(#loc)
        %41 = "ttir.reshape"(%26) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>) -> tensor<1x1x1x1xbf16> loc(#loc)
        %42 = "ttir.broadcast"(%41) <{broadcast_dimensions = array<i64: 1, 1, 1, 32>}> : (tensor<1x1x1x1xbf16>) -> tensor<1x1x1x32xbf16> loc(#loc)
        %43 = "ttir.reshape"(%27) <{shape = [1 : i32, 1 : i32]}> : (tensor<bf16>) -> tensor<1x1xbf16> loc(#loc)
        %44 = "ttir.broadcast"(%43) <{broadcast_dimensions = array<i64: 1, 128>}> : (tensor<1x1xbf16>) -> tensor<1x128xbf16> loc(#loc)
        %45 = "ttir.broadcast"(%41) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x1x1x1xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc)
        %46 = "ttir.reshape"(%24) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16>) -> tensor<1x1x1x1xbf16> loc(#loc)
        %47 = "ttir.broadcast"(%46) <{broadcast_dimensions = array<i64: 1, 12, 1, 128>}> : (tensor<1x1x1x1xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc)
        %48 = "ttir.reshape"(%21) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<f32>) -> tensor<1x1x1xf32> loc(#loc)
        %49 = "ttir.broadcast"(%48) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc)
        %50 = "ttir.reshape"(%0) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1xi64>) -> tensor<1x1x1xi64> loc(#loc20)
        %51 = "ttir.reshape"(%50) <{shape = [1 : i32]}> : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc21)
        %52 = "ttir.lt"(%51, %19) : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi1> loc(#loc22)
        %53 = "ttir.add"(%51, %20) : (tensor<1xi64>, tensor<1xi64>) -> tensor<1xi64> loc(#loc23)
        %54 = "ttir.where"(%52, %53, %51) : (tensor<1xi1>, tensor<1xi64>, tensor<1xi64>) -> tensor<1xi64> loc(#loc24)
        %55 = "ttir.reshape"(%5) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc25)
        %56 = "ttir.reshape"(%4) <{shape = [1 : i32, 128256 : i32, 3072 : i32]}> : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc26)
        %57 = "ttir.reshape"(%56) <{shape = [128256 : i32, 3072 : i32]}> : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc27)
        %58 = "ttir.reshape"(%3) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xi64>) -> tensor<1x1x1xi64> loc(#loc28)
        %59 = "ttir.reshape"(%58) <{shape = [1 : i32]}> : (tensor<1x1x1xi64>) -> tensor<1xi64> loc(#loc29)
        %60 = "ttir.typecast"(%59) <{conservative_folding = false}> : (tensor<1xi64>) -> tensor<1xui32> loc(#loc30)
        %61 = "ttir.gather"(%57, %60) <{collapsed_slice_dims = array<i64: 0>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 1>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 3072>, start_index_map = array<i64: 0>, start_indices_batching_dims = array<i64>}> : (tensor<128256x3072xbf16>, tensor<1xui32>) -> tensor<1x3072xbf16> loc(#loc31)
        %62 = "ttir.reshape"(%61) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc32)
        %63 = "ttir.typecast"(%62) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc33)
        %64 = "ttir.pow"(%63, %49) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc34)
        %65 = "ttir.sum"(%64) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>) -> tensor<1x1xf32> loc(#loc35)
        %66 = "ttir.multiply"(%65, %22) : (tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32> loc(#loc36)
        %67 = "ttir.reshape"(%66) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc37)
        %68 = "ttir.add"(%67, %23) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc38)
        %69 = "ttir.rsqrt"(%68) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc39)
        %70 = "ttir.reshape"(%69) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc40)
        %71 = "ttir.reshape"(%70) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc41)
        %72 = "ttir.broadcast"(%71) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc41)
        %73 = "ttir.multiply"(%63, %72) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc42)
        %74 = "ttir.typecast"(%73) <{conservative_folding = false}> : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc43)
        %75 = "ttir.multiply"(%55, %74) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc44)
        %76 = "ttir.reshape"(%75) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc45)
        %77 = "ttir.reshape"(%2) <{shape = [1 : i32, 512 : i32, 3072 : i32]}> : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc46)
        %78 = "ttir.reshape"(%77) <{shape = [512 : i32, 3072 : i32]}> : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc47)
        %79 = "ttir.permute"(%78) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16> loc(#loc48)
        %80 = "ttir.dot_general"(%76, %79) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16> loc(#loc49)
        %81 = "ttir.reshape"(%80) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc50)
        %82 = "ttir.reshape"(%1) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xf32>) -> tensor<1x1x64xf32> loc(#loc51)
        %83 = "ttir.reshape"(%82) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32> loc(#loc52)
        %84 = "ttir.typecast"(%50) <{conservative_folding = false}> : (tensor<1x1x1xi64>) -> tensor<1x1x1xf32> loc(#loc53)
        %85 = "ttir.dot_general"(%83, %84) <{batch_dims_lhs = array<i64: 0>, batch_dims_rhs = array<i64: 0>, contract_dims_lhs = array<i64: 2>, contract_dims_rhs = array<i64: 1>}> : (tensor<1x64x1xf32>, tensor<1x1x1xf32>) -> tensor<1x64x1xf32> loc(#loc54)
        %86 = "ttir.reshape"(%85) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<1x64x1xf32>) -> tensor<1x1x64xf32> loc(#loc55)
        %87 = "ttir.concat"(%86, %86) <{dim = 2 : si32}> : (tensor<1x1x64xf32>, tensor<1x1x64xf32>) -> tensor<1x1x128xf32> loc(#loc56)
        %88 = "ttir.cos"(%87) : (tensor<1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc57)
        %89 = "ttir.typecast"(%88) <{conservative_folding = false}> : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc58)
        %90 = "ttir.reshape"(%89) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc59)
        %91 = "ttir.broadcast"(%90) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x1x128xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc59)
        %92 = "ttir.multiply"(%81, %91) : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc60)
        %93 = "ttir.slice_static"(%81) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16> loc(#loc61)
        %94 = "ttir.neg"(%93) : (tensor<1x4x1x64xbf16>) -> tensor<1x4x1x64xbf16> loc(#loc62)
        %95 = "ttir.slice_static"(%81) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16>) -> tensor<1x4x1x64xbf16> loc(#loc63)
        %96 = "ttir.concat"(%94, %95) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16>, tensor<1x4x1x64xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc64)
        %97 = "ttir.sin"(%87) : (tensor<1x1x128xf32>) -> tensor<1x1x128xf32> loc(#loc65)
        %98 = "ttir.typecast"(%97) <{conservative_folding = false}> : (tensor<1x1x128xf32>) -> tensor<1x1x128xbf16> loc(#loc66)
        %99 = "ttir.reshape"(%98) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc67)
        %100 = "ttir.broadcast"(%99) <{broadcast_dimensions = array<i64: 1, 4, 1, 1>}> : (tensor<1x1x1x128xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc67)
        %101 = "ttir.multiply"(%96, %100) : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc68)
        %102 = "ttir.add"(%92, %101) : (tensor<1x4x1x128xbf16>, tensor<1x4x1x128xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc69)
        %103 = "ttir.update_cache"(%6, %102, %0) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128xbf16>, tensor<1xi64>) -> tensor<1x4x128x128xbf16> loc(#loc70)
        %104 = "ttir.reshape"(%7) <{shape = [1 : i32, 512 : i32, 3072 : i32]}> : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16> loc(#loc71)
        %105 = "ttir.reshape"(%104) <{shape = [512 : i32, 3072 : i32]}> : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16> loc(#loc72)
        %106 = "ttir.permute"(%105) <{permutation = array<i64: 1, 0>}> : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16> loc(#loc73)
        %107 = "ttir.dot_general"(%76, %106) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x512xbf16>) -> tensor<1x512xbf16> loc(#loc74)
        %108 = "ttir.reshape"(%107) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16>) -> tensor<1x4x1x128xbf16> loc(#loc75)
        %109 = "ttir.update_cache"(%8, %108, %0) <{batch_offset = 0 : i32}> : (tensor<1x4x128x128xbf16>, tensor<1x4x1x128xbf16>, tensor<1xi64>) -> tensor<1x4x128x128xbf16> loc(#loc76)
        %110 = "ttir.reshape"(%18) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc77)
        %111 = "ttir.reshape"(%15) <{shape = [1 : i32, 1536 : i32, 3072 : i32]}> : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16> loc(#loc78)
        %112 = "ttir.reshape"(%111) <{shape = [1536 : i32, 3072 : i32]}> : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16> loc(#loc79)
        %113 = "ttir.permute"(%112) <{permutation = array<i64: 1, 0>}> : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16> loc(#loc80)
        %114 = "ttir.dot_general"(%76, %113) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<1x1536xbf16> loc(#loc81)
        %115 = "ttir.reshape"(%114) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc82)
        %116 = "ttir.broadcast"(%90) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc83)
        %117 = "ttir.multiply"(%115, %116) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc84)
        %118 = "ttir.slice_static"(%115) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16> loc(#loc85)
        %119 = "ttir.neg"(%118) : (tensor<1x12x1x64xbf16>) -> tensor<1x12x1x64xbf16> loc(#loc86)
        %120 = "ttir.slice_static"(%115) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x64xbf16> loc(#loc87)
        %121 = "ttir.concat"(%119, %120) <{dim = 3 : si32}> : (tensor<1x12x1x64xbf16>, tensor<1x12x1x64xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc88)
        %122 = "ttir.broadcast"(%99) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc89)
        %123 = "ttir.multiply"(%121, %122) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc90)
        %124 = "ttir.add"(%117, %123) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc91)
        %125 = "ttir.reshape"(%103) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>) -> tensor<1x4x1x128x128xbf16> loc(#loc92)
        %126 = "ttir.broadcast"(%125) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>) -> tensor<1x4x3x128x128xbf16> loc(#loc92)
        %127 = "ttir.reshape"(%126) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16> loc(#loc93)
        %128 = "ttir.permute"(%127) <{permutation = array<i64: 0, 1, 3, 2>}> : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16> loc(#loc94)
        %129 = "ttir.dot_general"(%124, %128) <{batch_dims_lhs = array<i64: 0, 1>, batch_dims_rhs = array<i64: 0, 1>, contract_dims_lhs = array<i64: 3>, contract_dims_rhs = array<i64: 2>}> : (tensor<1x12x1x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc95)
        %130 = "ttir.multiply"(%129, %47) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc96)
        %131 = "ttir.reshape"(%14) <{shape = [1 : i32]}> : (tensor<i1>) -> tensor<1xi1> loc(#loc97)
        %132 = "ttir.broadcast"(%131) <{broadcast_dimensions = array<i64: 128>}> : (tensor<1xi1>) -> tensor<128xi1> loc(#loc97)
        %133 = "ttir.logical_and"(%132, %25) : (tensor<128xi1>, tensor<128xi1>) -> tensor<128xi1> loc(#loc98)
        %134 = "ttir.reshape"(%133) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xi1>) -> tensor<1x1x1x128xi1> loc(#loc99)
        %135 = "ttir.reshape"(%51) <{shape = [1 : i32, 1 : i32]}> : (tensor<1xi64>) -> tensor<1x1xi64> loc(#loc100)
        %136 = "ttir.broadcast"(%135) <{broadcast_dimensions = array<i64: 1, 128>}> : (tensor<1x1xi64>) -> tensor<1x128xi64> loc(#loc100)
        %137 = "ttir.gt"(%31, %136) : (tensor<1x128xi64>, tensor<1x128xi64>) -> tensor<1x128xi1> loc(#loc101)
        %138 = "ttir.typecast"(%137) <{conservative_folding = false}> : (tensor<1x128xi1>) -> tensor<1x128xbf16> loc(#loc102)
        %139 = "ttir.multiply"(%138, %44) : (tensor<1x128xbf16>, tensor<1x128xbf16>) -> tensor<1x128xbf16> loc(#loc103)
        %140 = "ttir.reshape"(%139) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc104)
        %141 = "ttir.slice_static"(%140) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 1 : i32, 1 : i32, 32 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1x1x128xbf16>) -> tensor<1x1x1x32xbf16> loc(#loc105)
        %142 = "ttir.reshape"(%13) <{shape = [1 : i32, 1 : i32, 32 : i32]}> : (tensor<1x32xi64>) -> tensor<1x1x32xi64> loc(#loc106)
        %143 = "ttir.reshape"(%142) <{shape = [1 : i32, 1 : i32, 1 : i32, 32 : i32]}> : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64> loc(#loc107)
        %144 = "ttir.typecast"(%143) <{conservative_folding = false}> : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16> loc(#loc108)
        %145 = "ttir.add"(%141, %144) : (tensor<1x1x1x32xbf16>, tensor<1x1x1x32xbf16>) -> tensor<1x1x1x32xbf16> loc(#loc109)
        %146 = "ttir.eq"(%145, %42) : (tensor<1x1x1x32xbf16>, tensor<1x1x1x32xbf16>) -> tensor<1x1x1x32xi1> loc(#loc110)
        %147 = "ttir.where"(%146, %40, %141) : (tensor<1x1x1x32xi1>, tensor<1x1x1x32xbf16>, tensor<1x1x1x32xbf16>) -> tensor<1x1x1x32xbf16> loc(#loc111)
        %148 = "ttir.floor"(%29) : (tensor<128xf32>) -> tensor<128xf32> loc(#loc112)
        %149 = "ttir.typecast"(%148) <{conservative_folding = false}> : (tensor<128xf32>) -> tensor<128xi64> loc(#loc113)
        %150 = "ttir.clamp_tensor"(%149, %38, %36) : (tensor<128xi64>, tensor<128xi64>, tensor<128xi64>) -> tensor<128xi64> loc(#loc114)
        %151 = "ttir.lt"(%150, %38) : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1> loc(#loc115)
        %152 = "ttir.add"(%150, %34) : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi64> loc(#loc116)
        %153 = "ttir.where"(%151, %152, %150) : (tensor<128xi1>, tensor<128xi64>, tensor<128xi64>) -> tensor<128xi64> loc(#loc117)
        %154 = "ttir.reshape"(%153) <{shape = [128 : i32, 1 : i32]}> : (tensor<128xi64>) -> tensor<128x1xi64> loc(#loc118)
        %155 = "ttir.gather"(%147, %154) <{collapsed_slice_dims = array<i64: 3>, index_vector_dim = 1 : si64, indices_are_sorted = false, offset_dims = array<i64: 0, 1, 2>, operand_batching_dims = array<i64>, slice_sizes = array<i64: 1, 1, 1, 1>, start_index_map = array<i64: 3>, start_indices_batching_dims = array<i64>}> : (tensor<1x1x1x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x1x128xbf16> loc(#loc119)
        %156 = "ttir.where"(%134, %155, %45) : (tensor<1x1x1x128xi1>, tensor<1x1x1x128xbf16>, tensor<1x1x1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc197)
        %157 = "ttir.where"(%134, %156, %140) : (tensor<1x1x1x128xi1>, tensor<1x1x1x128xbf16>, tensor<1x1x1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc122)
        %158 = "ttir.reshape"(%157) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x1x128xbf16>) -> tensor<1x1x128xbf16> loc(#loc123)
        %159 = "ttir.reshape"(%158) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<1x1x1x128xbf16> loc(#loc124)
        %160 = "ttir.broadcast"(%159) <{broadcast_dimensions = array<i64: 1, 12, 1, 1>}> : (tensor<1x1x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc124)
        %161 = "ttir.add"(%130, %160) : (tensor<1x12x1x128xbf16>, tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc125)
        %162 = "ttir.typecast"(%161) <{conservative_folding = false}> : (tensor<1x12x1x128xbf16>) -> tensor<1x12x1x128xf32> loc(#loc126)
        %163 = "ttir.max"(%162) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1xf32> loc(#loc127)
        %164 = "ttir.reshape"(%163) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>) -> tensor<1x12x1x1xf32> loc(#loc128)
        %165 = "ttir.broadcast"(%164) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>) -> tensor<1x12x1x128xf32> loc(#loc128)
        %166 = "ttir.subtract"(%162, %165) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32> loc(#loc129)
        %167 = "ttir.exp"(%166) : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32> loc(#loc130)
        %168 = "ttir.sum"(%167) <{dim_arg = [3 : i32], keep_dim = false}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1xf32> loc(#loc131)
        %169 = "ttir.reshape"(%168) <{shape = [1 : i32, 12 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1xf32>) -> tensor<1x12x1x1xf32> loc(#loc132)
        %170 = "ttir.broadcast"(%169) <{broadcast_dimensions = array<i64: 1, 1, 1, 128>}> : (tensor<1x12x1x1xf32>) -> tensor<1x12x1x128xf32> loc(#loc132)
        %171 = "ttir.div"(%167, %170) : (tensor<1x12x1x128xf32>, tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xf32> loc(#loc133)
        %172 = "ttir.typecast"(%171) <{conservative_folding = false}> : (tensor<1x12x1x128xf32>) -> tensor<1x12x1x128xbf16> loc(#loc134)
        %173 = "ttir.reshape"(%109) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16>) -> tensor<1x4x1x128x128xbf16> loc(#loc135)
        %174 = "ttir.broadcast"(%173) <{broadcast_dimensions = array<i64: 1, 1, 3, 1, 1>}> : (tensor<1x4x1x128x128xbf16>) -> tensor<1x4x3x128x128xbf16> loc(#loc135)
        %175 = "ttir.reshape"(%174) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16> loc(#loc136)
        %176 = "ttir.dot_general"(%172, %175) <{batch_dims_lhs = array<i64: 0, 1>, batch_dims_rhs = array<i64: 0, 1>, contract_dims_lhs = array<i64: 3>, contract_dims_rhs = array<i64: 2>}> : (tensor<1x12x1x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x1x128xbf16> loc(#loc137)
        %177 = "ttir.reshape"(%176) <{shape = [1 : i32, 1536 : i32]}> : (tensor<1x12x1x128xbf16>) -> tensor<1x1536xbf16> loc(#loc138)
        %178 = "ttir.reshape"(%12) <{shape = [1 : i32, 3072 : i32, 1536 : i32]}> : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16> loc(#loc139)
        %179 = "ttir.reshape"(%178) <{shape = [3072 : i32, 1536 : i32]}> : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16> loc(#loc140)
        %180 = "ttir.permute"(%179) <{permutation = array<i64: 1, 0>}> : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16> loc(#loc141)
        %181 = "ttir.dot_general"(%177, %180) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc142)
        %182 = "ttir.all_reduce"(%181) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc142)
        %183 = "ttir.reshape"(%182) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc143)
        %184 = "ttir.add"(%62, %183) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc144)
        %185 = "ttir.reshape"(%16) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc145)
        %186 = "ttir.typecast"(%184) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc146)
        %187 = "ttir.pow"(%186, %49) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc147)
        %188 = "ttir.sum"(%187) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>) -> tensor<1x1xf32> loc(#loc148)
        %189 = "ttir.multiply"(%188, %22) : (tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32> loc(#loc149)
        %190 = "ttir.reshape"(%189) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc150)
        %191 = "ttir.add"(%190, %23) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc151)
        %192 = "ttir.rsqrt"(%191) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc152)
        %193 = "ttir.reshape"(%192) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc153)
        %194 = "ttir.reshape"(%193) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc154)
        %195 = "ttir.broadcast"(%194) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc154)
        %196 = "ttir.multiply"(%186, %195) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc155)
        %197 = "ttir.typecast"(%196) <{conservative_folding = false}> : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc156)
        %198 = "ttir.multiply"(%185, %197) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc157)
        %199 = "ttir.reshape"(%198) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc158)
        %200 = "ttir.reshape"(%17) <{shape = [1 : i32, 4096 : i32, 3072 : i32]}> : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc159)
        %201 = "ttir.reshape"(%200) <{shape = [4096 : i32, 3072 : i32]}> : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc160)
        %202 = "ttir.permute"(%201) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16> loc(#loc161)
        %203 = "ttir.dot_general"(%199, %202) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16> loc(#loc162)
        %204 = "ttir.reshape"(%203) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc163)
        %205 = "ttir.sigmoid"(%204) : (tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc164)
        %206 = "ttir.multiply"(%204, %205) : (tensor<1x1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc165)
        %207 = "ttir.reshape"(%11) <{shape = [1 : i32, 4096 : i32, 3072 : i32]}> : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16> loc(#loc166)
        %208 = "ttir.reshape"(%207) <{shape = [4096 : i32, 3072 : i32]}> : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16> loc(#loc167)
        %209 = "ttir.permute"(%208) <{permutation = array<i64: 1, 0>}> : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16> loc(#loc168)
        %210 = "ttir.dot_general"(%199, %209) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<1x4096xbf16> loc(#loc169)
        %211 = "ttir.reshape"(%210) <{shape = [1 : i32, 1 : i32, 4096 : i32]}> : (tensor<1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc170)
        %212 = "ttir.multiply"(%206, %211) : (tensor<1x1x4096xbf16>, tensor<1x1x4096xbf16>) -> tensor<1x1x4096xbf16> loc(#loc171)
        %213 = "ttir.reshape"(%212) <{shape = [1 : i32, 4096 : i32]}> : (tensor<1x1x4096xbf16>) -> tensor<1x4096xbf16> loc(#loc172)
        %214 = "ttir.reshape"(%10) <{shape = [1 : i32, 3072 : i32, 4096 : i32]}> : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16> loc(#loc173)
        %215 = "ttir.reshape"(%214) <{shape = [3072 : i32, 4096 : i32]}> : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16> loc(#loc174)
        %216 = "ttir.permute"(%215) <{permutation = array<i64: 1, 0>}> : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16> loc(#loc175)
        %217 = "ttir.dot_general"(%213, %216) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc176)
        %218 = "ttir.all_reduce"(%217) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>}> : (tensor<1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc176)
        %219 = "ttir.reshape"(%218) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc177)
        %220 = "ttir.add"(%184, %219) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc178)
        %221 = "ttir.typecast"(%220) <{conservative_folding = false}> : (tensor<1x1x3072xbf16>) -> tensor<1x1x3072xf32> loc(#loc179)
        %222 = "ttir.pow"(%221, %49) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc180)
        %223 = "ttir.sum"(%222) <{dim_arg = [2 : i32], keep_dim = false}> : (tensor<1x1x3072xf32>) -> tensor<1x1xf32> loc(#loc181)
        %224 = "ttir.multiply"(%223, %22) : (tensor<1x1xf32>, tensor<1x1xf32>) -> tensor<1x1xf32> loc(#loc182)
        %225 = "ttir.reshape"(%224) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc183)
        %226 = "ttir.add"(%225, %23) : (tensor<1x1x1xf32>, tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc184)
        %227 = "ttir.rsqrt"(%226) : (tensor<1x1x1xf32>) -> tensor<1x1x1xf32> loc(#loc185)
        %228 = "ttir.reshape"(%227) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32>) -> tensor<1x1xf32> loc(#loc186)
        %229 = "ttir.reshape"(%228) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1xf32>) -> tensor<1x1x1xf32> loc(#loc187)
        %230 = "ttir.broadcast"(%229) <{broadcast_dimensions = array<i64: 1, 1, 3072>}> : (tensor<1x1x1xf32>) -> tensor<1x1x3072xf32> loc(#loc187)
        %231 = "ttir.multiply"(%221, %230) : (tensor<1x1x3072xf32>, tensor<1x1x3072xf32>) -> tensor<1x1x3072xf32> loc(#loc188)
        %232 = "ttir.typecast"(%231) <{conservative_folding = false}> : (tensor<1x1x3072xf32>) -> tensor<1x1x3072xbf16> loc(#loc189)
        %233 = "ttir.multiply"(%110, %232) : (tensor<1x1x3072xbf16>, tensor<1x1x3072xbf16>) -> tensor<1x1x3072xbf16> loc(#loc190)
        %234 = "ttir.reshape"(%233) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xbf16>) -> tensor<1x3072xbf16> loc(#loc191)
        %235 = "ttir.reshape"(%9) <{shape = [1 : i32, 128256 : i32, 3072 : i32]}> : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16> loc(#loc192)
        %236 = "ttir.reshape"(%235) <{shape = [128256 : i32, 3072 : i32]}> : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16> loc(#loc193)
        %237 = "ttir.permute"(%236) <{permutation = array<i64: 1, 0>}> : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16> loc(#loc194)
        %238 = "ttir.dot_general"(%234, %237) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<1x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<1x128256xbf16> loc(#loc195)
        %239 = "ttir.reshape"(%238) <{shape = [1 : i32, 1 : i32, 128256 : i32]}> : (tensor<1x128256xbf16>) -> tensor<1x1x128256xbf16> loc(#loc196)
        %240 = "ttir.mesh_shard"(%103) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc)
        %241 = "ttir.mesh_shard"(%109) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16> loc(#loc)
        %242 = "ttir.mesh_shard"(%238) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x128256xbf16>) -> tensor<1x128256xbf16> loc(#loc)
        %243 = "ttir.mesh_shard"(%239) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<replicate>}> : (tensor<1x1x128256xbf16>) -> tensor<1x1x128256xbf16> loc(#loc)
        return %240, %241, %242, %243 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<1x128256xbf16>, tensor<1x1x128256xbf16> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc20 = loc("reshape.4")
#loc21 = loc("reshape.6")
#loc22 = loc("compare.115")
#loc23 = loc("add.112")
#loc24 = loc("select.116")
#loc25 = loc("reshape.80")
#loc26 = loc("reshape.44")
#loc27 = loc("reshape.46")
#loc28 = loc("reshape.39")
#loc29 = loc("reshape.42")
#loc30 = loc("convert.47")
#loc31 = loc("gather.48")
#loc32 = loc("reshape.49")
#loc33 = loc("convert.50")
#loc34 = loc("power.52")
#loc35 = loc("reduce.59")
#loc36 = loc("multiply.68")
#loc37 = loc("reshape.69")
#loc38 = loc("add.73")
#loc39 = loc("rsqrt.74")
#loc40 = loc("reshape.75")
#loc41 = loc("broadcast.76")
#loc42 = loc("multiply.77")
#loc43 = loc("convert.78")
#loc44 = loc("multiply.84")
#loc45 = loc("reshape.85")
#loc46 = loc("reshape.31")
#loc47 = loc("reshape.33")
#loc48 = loc("transpose.34")
#loc49 = loc("dot.86")
#loc50 = loc("transpose.89")
#loc51 = loc("reshape.14")
#loc52 = loc("reshape.19")
#loc53 = loc("convert.11")
#loc54 = loc("dot.22")
#loc55 = loc("transpose.23")
#loc56 = loc("concatenate.24")
#loc57 = loc("cosine.98")
#loc58 = loc("convert.101")
#loc59 = loc("broadcast.104")
#loc60 = loc("multiply.105")
#loc61 = loc("slice.91")
#loc62 = loc("negate.92")
#loc63 = loc("slice.90")
#loc64 = loc("concatenate.93")
#loc65 = loc("sine.25")
#loc66 = loc("convert.28")
#loc67 = loc("broadcast.95")
#loc68 = loc("multiply.96")
#loc69 = loc("add.108")
#loc70 = loc("scatter.125")
#loc71 = loc("reshape.128")
#loc72 = loc("reshape.130")
#loc73 = loc("transpose.131")
#loc74 = loc("dot.133")
#loc75 = loc("transpose.136")
#loc76 = loc("scatter.153")
#loc77 = loc("reshape.467")
#loc78 = loc("reshape.322")
#loc79 = loc("reshape.324")
#loc80 = loc("transpose.325")
#loc81 = loc("dot.327")
#loc82 = loc("transpose.330")
#loc83 = loc("broadcast.339")
#loc84 = loc("multiply.340")
#loc85 = loc("slice.332")
#loc86 = loc("negate.333")
#loc87 = loc("slice.331")
#loc88 = loc("concatenate.334")
#loc89 = loc("broadcast.336")
#loc90 = loc("multiply.337")
#loc91 = loc("add.343")
#loc92 = loc("broadcast.317")
#loc93 = loc("reshape.318")
#loc94 = loc("transpose.319")
#loc95 = loc("dot.344")
#loc96 = loc("multiply.347")
#loc97 = loc("broadcast.294")
#loc98 = loc("and.297")
#loc99 = loc("reshape.298")
#loc100 = loc("broadcast.197")
#loc101 = loc("compare.198")
#loc102 = loc("convert.199")
#loc103 = loc("multiply.205")
#loc104 = loc("reshape.207")
#loc105 = loc("slice.268")
#loc106 = loc("reshape.258")
#loc107 = loc("reshape.263")
#loc108 = loc("convert.269")
#loc109 = loc("add.272")
#loc110 = loc("compare.275")
#loc111 = loc("select.277")
#loc112 = loc("floor.227")
#loc113 = loc("convert.228")
#loc114 = loc("clamp.231")
#loc115 = loc("compare.240")
#loc116 = loc("add.237")
#loc117 = loc("select.241")
#loc118 = loc("reshape.242")
#loc119 = loc("gather.279")
#loc120 = loc("select.301")
#loc121 = loc("not.299")
#loc122 = loc("select.302")
#loc123 = loc("reshape.350")
#loc124 = loc("broadcast.351")
#loc125 = loc("add.352")
#loc126 = loc("convert.353")
#loc127 = loc("reduce.359")
#loc128 = loc("broadcast.360")
#loc129 = loc("subtract.361")
#loc130 = loc("exponential.362")
#loc131 = loc("reduce.368")
#loc132 = loc("broadcast.369")
#loc133 = loc("divide.370")
#loc134 = loc("convert.371")
#loc135 = loc("broadcast.190")
#loc136 = loc("reshape.191")
#loc137 = loc("dot.372")
#loc138 = loc("reshape.376")
#loc139 = loc("reshape.179")
#loc140 = loc("reshape.181")
#loc141 = loc("transpose.182")
#loc142 = loc("dot.377")
#loc143 = loc("reshape.378")
#loc144 = loc("add.381")
#loc145 = loc("reshape.412")
#loc146 = loc("convert.382")
#loc147 = loc("power.384")
#loc148 = loc("reduce.391")
#loc149 = loc("multiply.400")
#loc150 = loc("reshape.401")
#loc151 = loc("add.405")
#loc152 = loc("rsqrt.406")
#loc153 = loc("reshape.407")
#loc154 = loc("broadcast.408")
#loc155 = loc("multiply.409")
#loc156 = loc("convert.410")
#loc157 = loc("multiply.416")
#loc158 = loc("reshape.425")
#loc159 = loc("reshape.421")
#loc160 = loc("reshape.423")
#loc161 = loc("transpose.424")
#loc162 = loc("dot.426")
#loc163 = loc("reshape.427")
#loc164 = loc("logistic.428")
#loc165 = loc("multiply.429")
#loc166 = loc("reshape.170")
#loc167 = loc("reshape.172")
#loc168 = loc("transpose.173")
#loc169 = loc("dot.418")
#loc170 = loc("reshape.419")
#loc171 = loc("multiply.430")
#loc172 = loc("reshape.431")
#loc173 = loc("reshape.165")
#loc174 = loc("reshape.167")
#loc175 = loc("transpose.168")
#loc176 = loc("dot.432")
#loc177 = loc("reshape.433")
#loc178 = loc("add.436")
#loc179 = loc("convert.437")
#loc180 = loc("power.439")
#loc181 = loc("reduce.446")
#loc182 = loc("multiply.455")
#loc183 = loc("reshape.456")
#loc184 = loc("add.460")
#loc185 = loc("rsqrt.461")
#loc186 = loc("reshape.462")
#loc187 = loc("broadcast.463")
#loc188 = loc("multiply.464")
#loc189 = loc("convert.465")
#loc190 = loc("multiply.471")
#loc191 = loc("reshape.475")
#loc192 = loc("reshape.156")
#loc193 = loc("reshape.158")
#loc194 = loc("transpose.159")
#loc195 = loc("dot.476")
#loc196 = loc("reshape.477")
#loc197 = loc(fused[#loc120, #loc121])
------------------ END OF MLIR MODULE ------------------
2026-01-02 18:37:47.080 (  18.138s) [        CBC3A000]      module_builder.cc:785   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2026-01-02 18:37:47.080 (  18.138s) [        CBC3A000]      module_builder.cc:799   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2026-01-02 18:37:47.080 (  18.138s) [        CBC3A000]      module_builder.cc:809   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
2026-01-02 18:37:47.290 (  18.349s) [        CBC3A000]      module_builder.cc:1025     1| MLIR Module ttnn:
#dram = #ttnn.buffer_type<dram>
#l1 = #ttnn.buffer_type<l1>
#loc = loc(unknown)
#loc19 = loc("p0.3")
#loc20 = loc("p1.13")
#loc21 = loc("p2.30")
#loc22 = loc("p3.38")
#loc23 = loc("p4.43")
#loc24 = loc("p5.79")
#loc25 = loc("p6.119")
#loc26 = loc("p7.127")
#loc27 = loc("p8.147")
#loc28 = loc("p9.155")
#loc29 = loc("p10.164")
#loc30 = loc("p11.169")
#loc31 = loc("p12.178")
#loc32 = loc("p13.257")
#loc33 = loc("p14.290")
#loc34 = loc("p15.321")
#loc35 = loc("p16.411")
#loc36 = loc("p17.420")
#loc37 = loc("p18.466")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073168640, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073177216, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3072xbf16, #system_memory>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x3072xbf16, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128256x3072xbf16, #system_memory>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128256x3072xbf16, #dram>, <interleaved>>
#ttnn_layout9 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout10 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout11 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout12 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout13 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x64xf32, #system_memory>>
#ttnn_layout14 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 64 + d1, d2), <1x1>, memref<2x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout15 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x64xf32, #dram>, <interleaved>>
#ttnn_layout16 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout17 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x1xui32, #dram>, <interleaved>>
#ttnn_layout18 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout19 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout20 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout21 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x4x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout22 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout23 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4x1x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout24 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1xsi32, #dram>, <interleaved>>
#ttnn_layout25 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout26 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1xsi32, #dram>, <interleaved>>
#ttnn_layout27 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<32x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout28 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<4008x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout29 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x256x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout30 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<256x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout31 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout32 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x32xsi32, #dram>, <interleaved>>
#ttnn_layout33 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1xbf16, #dram>, <interleaved>>
#ttnn_layout34 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1024 + d1 * 128 + d2, d3), <1x1>, memref<1024x128xbf16, #system_memory>>
#ttnn_layout35 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128256xbf16, #system_memory>>
#ttnn_layout36 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x128256xbf16, #system_memory>>
#ttnn_layout37 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<128x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout38 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x48x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout39 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<16x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout40 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<48x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout41 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<96x128x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout42 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout43 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout44 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, u32>, #dram>, <interleaved>>
#ttnn_layout45 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1xui32, #dram>, <interleaved>>
#ttnn_layout46 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout47 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout48 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout49 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x96x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout50 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x16x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout51 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout52 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout53 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x2x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout54 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout55 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 128 + d1 * 32 + d2, d3), <1x1>, memref<4x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout56 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1, (d0, d1) -> (0, d0 floordiv 8, d0 mod 8)>, memref<1x4x!ttcore.tile<32x32, bf16>, #l1>, <height_sharded>>
#ttnn_layout57 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout58 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout59 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x2x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout60 = #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 512 + d1 * 128 + d2 * 128 + d3, d4), <1x1>, memref<16x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout61 = #ttnn.ttnn_layout<(d0, d1, d2, d3, d4) -> (d0 * 1536 + d1 * 384 + d2 * 128 + d3, d4), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout62 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 1536 + d1 * 128 + d2, d3), <1x1>, memref<48x4x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout63 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout64 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout65 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<32x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout66 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<32x1xbf16, #dram>, <interleaved>>
#ttnn_layout67 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<128x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout68 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<128x1x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout69 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 384 + d1 * 32 + d2, d3), <1x1>, memref<12x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout70 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x96x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout71 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 32 + d1 * 32 + d2, d3), <1x1>, memref<1x48x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout72 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout73 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout74 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 * 32 + d1, d2), <1x1>, memref<1x4008x!ttcore.tile<32x32, bf16>, #dram>, <interleaved>>
#ttnn_layout75 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #dram>, <interleaved>>
#ttnn_layout76 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 128 + d2, d3), <1x1>, memref<512x128xbf16, #system_memory>>
#ttnn_layout77 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x128256xbf16, #dram>, <interleaved>>
#ttnn_layout78 = #ttnn.ttnn_layout<(d0, d1, d2) -> (d0 + d1, d2), <1x1>, memref<1x128256xbf16, #dram>, <interleaved>>
module @SyncTensorsGraph.479 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.479 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]> loc(#loc)
      func.func private @main_const_eval_0() -> tensor<1x1x1x128xbf16, #ttnn_layout> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<"0x803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F803F000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"> : tensor<128xbf16>}> : (!ttnn.device) -> tensor<128xbf16, #ttnn_layout1> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16, #ttnn_layout1>) -> tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc128)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<128xbf16, #ttnn_layout1>) -> () loc(#loc128)
        return %2 : tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_1() -> tensor<1x1x1xf32, #ttnn_layout2> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, fill_value = 9.99999974E-6 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<1x1x1>}> : (!ttnn.device) -> tensor<1x1x1xf32, #ttnn_layout2> loc(#loc)
        return %1 : tensor<1x1x1xf32, #ttnn_layout2> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_2(%arg0: tensor<3072xbf16, #ttnn_layout3> loc(unknown)) -> tensor<1x3072xbf16, #ttnn_layout4> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<3072xbf16, #ttnn_layout3>, !ttnn.device) -> tensor<3072xbf16, #ttnn_layout5> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<3072xbf16, #ttnn_layout5>) -> tensor<3072xbf16, #ttnn_layout6> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072xbf16, #ttnn_layout5>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn_layout6>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc129)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<3072xbf16, #ttnn_layout6>) -> () loc(#loc129)
        return %3 : tensor<1x3072xbf16, #ttnn_layout4> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_3(%arg0: tensor<3072xbf16, #ttnn_layout3> loc(unknown)) -> tensor<1x3072xbf16, #ttnn_layout4> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<3072xbf16, #ttnn_layout3>, !ttnn.device) -> tensor<3072xbf16, #ttnn_layout5> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<3072xbf16, #ttnn_layout5>) -> tensor<3072xbf16, #ttnn_layout6> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072xbf16, #ttnn_layout5>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn_layout6>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc130)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<3072xbf16, #ttnn_layout6>) -> () loc(#loc130)
        return %3 : tensor<1x3072xbf16, #ttnn_layout4> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_4(%arg0: tensor<128256x3072xbf16, #ttnn_layout7> loc(unknown)) -> tensor<128256x3072xbf16, #ttnn_layout8> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc131)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<128256x3072xbf16, #ttnn_layout7>, !ttnn.device) -> tensor<128256x3072xbf16, #ttnn_layout8> loc(#loc131)
        return %1 : tensor<128256x3072xbf16, #ttnn_layout8> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_5() -> (tensor<1x1x1x1xbf16, #ttnn_layout9>, tensor<1x1x1x32xbf16, #ttnn_layout9>) attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = -3.38953139E+38 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout10> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout10>) -> tensor<1x1x1x1xbf16, #ttnn_layout9> loc(#loc)
        %3 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout10>) -> tensor<1x1x1x1xbf16, #ttnn_layout9> loc(#loc132)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<bf16, #ttnn_layout10>) -> () loc(#loc132)
        %4 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<1x1x1x32>}> : (tensor<1x1x1x1xbf16, #ttnn_layout9>) -> tensor<1x1x1x32xbf16, #ttnn_layout9> loc(#loc6)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout9>) -> () loc(#loc6)
        return %3, %4 : tensor<1x1x1x1xbf16, #ttnn_layout9>, tensor<1x1x1x32xbf16, #ttnn_layout9> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_6() -> tensor<1x1x1x1xbf16, #ttnn_layout9> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.0883789062 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout10> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout10>) -> tensor<1x1x1x1xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<bf16, #ttnn_layout10>) -> () loc(#loc)
        return %2 : tensor<1x1x1x1xbf16, #ttnn_layout9> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_7() -> tensor<1x1x1x128xsi32, #ttnn_layout11> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<"0x000000000100000002000000030000000400000005000000060000000700000008000000090000000A0000000B0000000C0000000D0000000E0000000F000000100000001100000012000000130000001400000015000000160000001700000018000000190000001A0000001B0000001C0000001D0000001E0000001F000000200000002100000022000000230000002400000025000000260000002700000028000000290000002A0000002B0000002C0000002D0000002E0000002F000000300000003100000032000000330000003400000035000000360000003700000038000000390000003A0000003B0000003C0000003D0000003E0000003F000000400000004100000042000000430000004400000045000000460000004700000048000000490000004A0000004B0000004C0000004D0000004E0000004F000000500000005100000052000000530000005400000055000000560000005700000058000000590000005A0000005B0000005C0000005D0000005E0000005F000000600000006100000062000000630000006400000065000000660000006700000068000000690000006A0000006B0000006C0000006D0000006E0000006F000000700000007100000072000000730000007400000075000000760000007700000078000000790000007A0000007B0000007C0000007D0000007E0000007F000000"> : tensor<1x128xsi32>}> : (!ttnn.device) -> tensor<1x128xsi32, #ttnn_layout12> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 128 : i32]}> : (tensor<1x128xsi32, #ttnn_layout12>) -> tensor<1x1x1x128xsi32, #ttnn_layout11> loc(#loc158)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x128xsi32, #ttnn_layout12>) -> () loc(#loc158)
        return %2 : tensor<1x1x1x128xsi32, #ttnn_layout11> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_8() -> (tensor<1x1x1x1xbf16, #ttnn_layout9>, tensor<1x1x1x128xbf16, #ttnn_layout>) attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<bf16>, fill_value = 0.000000e+00 : f32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<bf16, #ttnn_layout10> loc(#loc)
        %2 = "ttnn.reshape"(%1) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout10>) -> tensor<1x1x1x1xbf16, #ttnn_layout9> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<bf16, #ttnn_layout10>) -> () loc(#loc)
        %3 = "ttnn.repeat"(%2) <{repeat_dims = #ttnn.shape<1x1x1x128>}> : (tensor<1x1x1x1xbf16, #ttnn_layout9>) -> tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc134)
        return %2, %3 : tensor<1x1x1x1xbf16, #ttnn_layout9>, tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_9(%arg0: tensor<64xf32, #ttnn_layout13> loc(unknown)) -> tensor<1x64x1xf32, #ttnn_layout14> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<64xf32, #ttnn_layout13>, !ttnn.device) -> tensor<64xf32, #ttnn_layout15> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<64xf32, #ttnn_layout15>) -> tensor<64xf32, #ttnn_layout16> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<64xf32, #ttnn_layout15>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 64 : i32, 1 : i32]}> : (tensor<64xf32, #ttnn_layout16>) -> tensor<1x64x1xf32, #ttnn_layout14> loc(#loc9)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<64xf32, #ttnn_layout16>) -> () loc(#loc9)
        return %3 : tensor<1x64x1xf32, #ttnn_layout14> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_10() -> tensor<128x1xui32, #ttnn_layout17> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.constant"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, value = dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>}> : (!ttnn.device) -> tensor<128xf32, #ttnn_layout18> loc(#loc)
        %2 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = 32 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn_layout19> loc(#loc)
        %3 = "ttnn.full"(%0) <{dtype = #ttcore.supportedDataTypes<si32>, fill_value = 0 : i32, layout = #ttnn.layout<tile>, shape = #ttnn.shape<>}> : (!ttnn.device) -> tensor<si32, #ttnn_layout19> loc(#loc)
        %4 = "ttnn.reshape"(%2) <{shape = [1 : i32]}> : (tensor<si32, #ttnn_layout19>) -> tensor<1xsi32, #ttnn_layout20> loc(#loc)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<si32, #ttnn_layout19>) -> () loc(#loc)
        %5 = "ttnn.reshape"(%3) <{shape = [1 : i32]}> : (tensor<si32, #ttnn_layout19>) -> tensor<1xsi32, #ttnn_layout20> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<si32, #ttnn_layout19>) -> () loc(#loc)
        %6 = "ttnn.floor"(%1) : (tensor<128xf32, #ttnn_layout18>) -> tensor<128xf32, #ttnn_layout18> loc(#loc10)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<128xf32, #ttnn_layout18>) -> () loc(#loc10)
        %7 = "ttnn.typecast"(%6) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<128xf32, #ttnn_layout18>) -> tensor<128xsi32, #ttnn_layout21> loc(#loc11)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<128xf32, #ttnn_layout18>) -> () loc(#loc11)
        %8 = "ttnn.clamp_scalar"(%7) <{max = 3.100000e+01 : f32, min = 0.000000e+00 : f32}> : (tensor<128xsi32, #ttnn_layout21>) -> tensor<128xsi32, #ttnn_layout21> loc(#loc12)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<128xsi32, #ttnn_layout21>) -> () loc(#loc12)
        %9 = "ttnn.lt"(%8, %5) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<128xsi32, #ttnn_layout21>, tensor<1xsi32, #ttnn_layout20>) -> tensor<128xbf16, #ttnn_layout1> loc(#loc13)
        "ttnn.deallocate"(%5) <{force = false}> : (tensor<1xsi32, #ttnn_layout20>) -> () loc(#loc13)
        %10 = "ttnn.add"(%8, %4) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<128xsi32, #ttnn_layout21>, tensor<1xsi32, #ttnn_layout20>) -> tensor<128xsi32, #ttnn_layout21> loc(#loc14)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1xsi32, #ttnn_layout20>) -> () loc(#loc14)
        %11 = "ttnn.typecast"(%9) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<128xbf16, #ttnn_layout1>) -> tensor<128xf32, #ttnn_layout18> loc(#loc135)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<128xbf16, #ttnn_layout1>) -> () loc(#loc135)
        %12 = "ttnn.typecast"(%10) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<128xsi32, #ttnn_layout21>) -> tensor<128xf32, #ttnn_layout18> loc(#loc135)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<128xsi32, #ttnn_layout21>) -> () loc(#loc135)
        %13 = "ttnn.typecast"(%8) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<128xsi32, #ttnn_layout21>) -> tensor<128xf32, #ttnn_layout18> loc(#loc135)
        "ttnn.deallocate"(%8) <{force = false}> : (tensor<128xsi32, #ttnn_layout21>) -> () loc(#loc135)
        %14 = "ttnn.where"(%11, %12, %13) : (tensor<128xf32, #ttnn_layout18>, tensor<128xf32, #ttnn_layout18>, tensor<128xf32, #ttnn_layout18>) -> tensor<128xf32, #ttnn_layout18> loc(#loc15)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<128xf32, #ttnn_layout18>) -> () loc(#loc15)
        "ttnn.deallocate"(%12) <{force = false}> : (tensor<128xf32, #ttnn_layout18>) -> () loc(#loc15)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<128xf32, #ttnn_layout18>) -> () loc(#loc15)
        %15 = "ttnn.typecast"(%14) <{dtype = #ttcore.supportedDataTypes<si32>}> : (tensor<128xf32, #ttnn_layout18>) -> tensor<128xsi32, #ttnn_layout21> loc(#loc135)
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<128xf32, #ttnn_layout18>) -> () loc(#loc135)
        %16 = "ttnn.reshape"(%15) <{shape = [128 : i32, 1 : i32]}> : (tensor<128xsi32, #ttnn_layout21>) -> tensor<128x1xsi32, #ttnn_layout22> loc(#loc16)
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<128xsi32, #ttnn_layout21>) -> () loc(#loc16)
        %17 = "ttnn.typecast"(%16) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<128x1xsi32, #ttnn_layout22>) -> tensor<128x1xui32, #ttnn_layout23> loc(#loc136)
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<128x1xsi32, #ttnn_layout22>) -> () loc(#loc136)
        %18 = "ttnn.to_layout"(%17) <{layout = #ttnn.layout<row_major>}> : (tensor<128x1xui32, #ttnn_layout23>) -> tensor<128x1xui32, #ttnn_layout17> loc(#loc136)
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<128x1xui32, #ttnn_layout23>) -> () loc(#loc136)
        return %18 : tensor<128x1xui32, #ttnn_layout17> loc(#loc)
      } loc(#loc)
      func.func private @main_const_eval_11(%arg0: tensor<3072xbf16, #ttnn_layout3> loc(unknown)) -> tensor<1x3072xbf16, #ttnn_layout4> attributes {const_eval} {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %1 = "ttnn.to_device"(%arg0, %0) <{memory_config = #ttnn.memory_config<#dram, <interleaved>>}> : (tensor<3072xbf16, #ttnn_layout3>, !ttnn.device) -> tensor<3072xbf16, #ttnn_layout5> loc(#loc)
        %2 = "ttnn.to_layout"(%1) <{layout = #ttnn.layout<tile>}> : (tensor<3072xbf16, #ttnn_layout5>) -> tensor<3072xbf16, #ttnn_layout6> loc(#loc)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<3072xbf16, #ttnn_layout5>) -> () loc(#loc)
        %3 = "ttnn.reshape"(%2) <{shape = [1 : i32, 3072 : i32]}> : (tensor<3072xbf16, #ttnn_layout6>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc137)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<3072xbf16, #ttnn_layout6>) -> () loc(#loc137)
        return %3 : tensor<1x3072xbf16, #ttnn_layout4> loc(#loc)
      } loc(#loc)
      func.func @main(%arg0: tensor<1xsi32, #ttnn_layout24> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p0.3"), %arg1: tensor<64xf32, #ttnn_layout13> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_rotary_emb_inv_freq"} loc("p1.13"), %arg2: tensor<1024x3072xbf16, #ttnn_layout25> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_k_proj_weight"} loc("p2.30"), %arg3: tensor<1x1xsi32, #ttnn_layout26> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p3.38"), %arg4: tensor<128256x3072xbf16, #ttnn_layout7> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_embed_tokens_weight"} loc("p4.43"), %arg5: tensor<3072xbf16, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___input_layernorm_weight"} loc("p5.79"), %arg6: tensor<1x8x128x128xbf16, #ttnn_layout27> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_2"} loc("p6.119"), %arg7: tensor<1024x3072xbf16, #ttnn_layout25> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_v_proj_weight"} loc("p7.127"), %arg8: tensor<1x8x128x128xbf16, #ttnn_layout27> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_4"} loc("p8.147"), %arg9: tensor<128256x3072xbf16, #ttnn_layout28> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___lm_head_weight"} loc("p9.155"), %arg10: tensor<3072x8192xbf16, #ttnn_layout29> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_down_proj_weight"} loc("p10.164"), %arg11: tensor<8192x3072xbf16, #ttnn_layout30> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_up_proj_weight"} loc("p11.169"), %arg12: tensor<3072x3072xbf16, #ttnn_layout31> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_o_proj_weight"} loc("p12.178"), %arg13: tensor<1x32xsi32, #ttnn_layout32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_3"} loc("p13.257"), %arg14: tensor<bf16, #ttnn_layout33> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>} loc("p14.290"), %arg15: tensor<3072x3072xbf16, #ttnn_layout31> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___self_attn_q_proj_weight"} loc("p15.321"), %arg16: tensor<3072xbf16, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___post_attention_layernorm_weight"} loc("p16.411"), %arg17: tensor<8192x3072xbf16, #ttnn_layout30> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_layers__modules__0___mlp_gate_proj_weight"} loc("p17.420"), %arg18: tensor<3072xbf16, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___model_norm_weight"} loc("p18.466")) -> (tensor<1x8x128x128xbf16, #ttnn_layout34> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x8x128x128xbf16, #ttnn_layout34> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x128256xbf16, #ttnn_layout35> {ttcore.shard_status = #ttcore.shard_status<unsharded>}, tensor<1x1x128256xbf16, #ttnn_layout36> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttcore.load_cached(@main_const_eval_0, []) : () -> tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc)
        %1 = ttcore.load_cached(@main_const_eval_1, []) : () -> tensor<1x1x1xf32, #ttnn_layout2> loc(#loc)
        %2 = ttcore.load_cached(@main_const_eval_2, [%arg5]) : (tensor<3072xbf16, #ttnn_layout3>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%arg5) <{force = false}> : (tensor<3072xbf16, #ttnn_layout3>) -> () loc(#loc)
        %3 = ttcore.load_cached(@main_const_eval_3, [%arg18]) : (tensor<3072xbf16, #ttnn_layout3>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%arg18) <{force = false}> : (tensor<3072xbf16, #ttnn_layout3>) -> () loc(#loc)
        %4 = ttcore.load_cached(@main_const_eval_4, [%arg4]) : (tensor<128256x3072xbf16, #ttnn_layout7>) -> tensor<128256x3072xbf16, #ttnn_layout8> loc(#loc)
        "ttnn.deallocate"(%arg4) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout7>) -> () loc(#loc)
        %5:2 = ttcore.load_cached(@main_const_eval_5, []) : () -> (tensor<1x1x1x1xbf16, #ttnn_layout9>, tensor<1x1x1x32xbf16, #ttnn_layout9>) loc(#loc)
        %6 = ttcore.load_cached(@main_const_eval_6, []) : () -> tensor<1x1x1x1xbf16, #ttnn_layout9> loc(#loc)
        %7 = ttcore.load_cached(@main_const_eval_7, []) : () -> tensor<1x1x1x128xsi32, #ttnn_layout11> loc(#loc)
        %8:2 = ttcore.load_cached(@main_const_eval_8, []) : () -> (tensor<1x1x1x1xbf16, #ttnn_layout9>, tensor<1x1x1x128xbf16, #ttnn_layout>) loc(#loc)
        %9 = ttcore.load_cached(@main_const_eval_9, [%arg1]) : (tensor<64xf32, #ttnn_layout13>) -> tensor<1x64x1xf32, #ttnn_layout14> loc(#loc)
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<64xf32, #ttnn_layout13>) -> () loc(#loc)
        %10 = ttcore.load_cached(@main_const_eval_10, []) : () -> tensor<128x1xui32, #ttnn_layout17> loc(#loc)
        %11 = ttcore.load_cached(@main_const_eval_11, [%arg16]) : (tensor<3072xbf16, #ttnn_layout3>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%arg16) <{force = false}> : (tensor<3072xbf16, #ttnn_layout3>) -> () loc(#loc)
        %12 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        %13 = "ttnn.mesh_shard"(%arg11, %12) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn_layout30>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn_layout37> loc(#loc)
        "ttnn.deallocate"(%arg11) <{force = false}> : (tensor<8192x3072xbf16, #ttnn_layout30>) -> () loc(#loc)
        %14 = "ttnn.mesh_shard"(%arg12, %12) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn_layout31>, !ttnn.device) -> tensor<3072x1536xbf16, #ttnn_layout38> loc(#loc)
        "ttnn.deallocate"(%arg12) <{force = false}> : (tensor<3072x3072xbf16, #ttnn_layout31>) -> () loc(#loc)
        %15 = "ttnn.mesh_shard"(%arg2, %12) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn_layout25>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn_layout39> loc(#loc)
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<1024x3072xbf16, #ttnn_layout25>) -> () loc(#loc)
        %16 = "ttnn.mesh_shard"(%arg7, %12) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1024x3072xbf16, #ttnn_layout25>, !ttnn.device) -> tensor<512x3072xbf16, #ttnn_layout39> loc(#loc)
        "ttnn.deallocate"(%arg7) <{force = false}> : (tensor<1024x3072xbf16, #ttnn_layout25>) -> () loc(#loc)
        %17 = "ttnn.mesh_shard"(%arg15, %12) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x3072xbf16, #ttnn_layout31>, !ttnn.device) -> tensor<1536x3072xbf16, #ttnn_layout40> loc(#loc)
        "ttnn.deallocate"(%arg15) <{force = false}> : (tensor<3072x3072xbf16, #ttnn_layout31>) -> () loc(#loc)
        %18 = "ttnn.mesh_shard"(%arg17, %12) <{shard_dims = array<i64: -1, 0>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 2, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<8192x3072xbf16, #ttnn_layout30>, !ttnn.device) -> tensor<4096x3072xbf16, #ttnn_layout37> loc(#loc)
        "ttnn.deallocate"(%arg17) <{force = false}> : (tensor<8192x3072xbf16, #ttnn_layout30>) -> () loc(#loc)
        %19 = "ttnn.mesh_shard"(%arg10, %12) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2>, shard_type = #ttcore.shard_type<identity>}> : (tensor<3072x8192xbf16, #ttnn_layout29>, !ttnn.device) -> tensor<3072x4096xbf16, #ttnn_layout41> loc(#loc)
        "ttnn.deallocate"(%arg10) <{force = false}> : (tensor<3072x8192xbf16, #ttnn_layout29>) -> () loc(#loc)
        %20 = "ttnn.mesh_shard"(%arg6, %12) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn_layout27>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn_layout42> loc(#loc)
        "ttnn.deallocate"(%arg6) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn_layout27>) -> () loc(#loc)
        %21 = "ttnn.mesh_shard"(%arg8, %12) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x128x128xbf16, #ttnn_layout27>, !ttnn.device) -> tensor<1x4x128x128xbf16, #ttnn_layout42> loc(#loc)
        "ttnn.deallocate"(%arg8) <{force = false}> : (tensor<1x8x128x128xbf16, #ttnn_layout27>) -> () loc(#loc)
        %22 = "ttnn.to_layout"(%arg3) <{layout = #ttnn.layout<tile>}> : (tensor<1x1xsi32, #ttnn_layout26>) -> tensor<1x1xsi32, #ttnn_layout43> loc(#loc38)
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<1x1xsi32, #ttnn_layout26>) -> () loc(#loc38)
        %23 = "ttnn.typecast"(%22) <{dtype = #ttcore.supportedDataTypes<u32>}> : (tensor<1x1xsi32, #ttnn_layout43>) -> tensor<1x1xui32, #ttnn_layout44> loc(#loc39)
        "ttnn.deallocate"(%22) <{force = false}> : (tensor<1x1xsi32, #ttnn_layout43>) -> () loc(#loc39)
        %24 = "ttnn.to_layout"(%23) <{layout = #ttnn.layout<row_major>}> : (tensor<1x1xui32, #ttnn_layout44>) -> tensor<1x1xui32, #ttnn_layout45> loc(#loc131)
        "ttnn.deallocate"(%23) <{force = false}> : (tensor<1x1xui32, #ttnn_layout44>) -> () loc(#loc131)
        %25 = "ttnn.embedding"(%24, %4) : (tensor<1x1xui32, #ttnn_layout45>, tensor<128256x3072xbf16, #ttnn_layout8>) -> tensor<1x1x3072xbf16, #ttnn_layout46> loc(#loc4)
        "ttnn.deallocate"(%24) <{force = false}> : (tensor<1x1xui32, #ttnn_layout45>) -> () loc(#loc4)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout8>) -> () loc(#loc4)
        %26 = "ttnn.typecast"(%25) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x3072xbf16, #ttnn_layout46>) -> tensor<1x1x3072xf32, #ttnn_layout47> loc(#loc40)
        %27 = "ttnn.pow_scalar"(%26) <{rhs = 2.000000e+00 : f32}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> tensor<1x1x3072xf32, #ttnn_layout47> loc(#loc41)
        %28 = "ttnn.mean"(%27) <{dim_arg = [2 : i32], keep_dim = true}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> tensor<1x1x1xf32, #ttnn_layout2> loc(#loc138)
        "ttnn.deallocate"(%27) <{force = false}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> () loc(#loc138)
        %29 = "ttnn.add"(%28, %1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1xf32, #ttnn_layout2>, tensor<1x1x1xf32, #ttnn_layout2>) -> tensor<1x1x1xf32, #ttnn_layout2> loc(#loc43)
        "ttnn.deallocate"(%28) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> () loc(#loc43)
        %30 = "ttnn.rsqrt"(%29) : (tensor<1x1x1xf32, #ttnn_layout2>) -> tensor<1x1x1xf32, #ttnn_layout2> loc(#loc44)
        "ttnn.deallocate"(%29) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> () loc(#loc44)
        %31 = "ttnn.reshape"(%30) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> tensor<1x1xf32, #ttnn_layout48> loc(#loc44)
        "ttnn.deallocate"(%30) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> () loc(#loc44)
        %32 = "ttnn.reshape"(%26) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> tensor<1x3072xf32, #ttnn_layout49> loc(#loc171)
        "ttnn.deallocate"(%26) <{force = false}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> () loc(#loc171)
        %33 = "ttnn.multiply"(%32, %31) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn_layout49>, tensor<1x1xf32, #ttnn_layout48>) -> tensor<1x3072xf32, #ttnn_layout49> loc(#loc45)
        "ttnn.deallocate"(%32) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout49>) -> () loc(#loc45)
        "ttnn.deallocate"(%31) <{force = false}> : (tensor<1x1xf32, #ttnn_layout48>) -> () loc(#loc45)
        %34 = "ttnn.typecast"(%33) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn_layout49>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc46)
        "ttnn.deallocate"(%33) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout49>) -> () loc(#loc46)
        %35 = "ttnn.multiply"(%2, %34) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn_layout4>, tensor<1x3072xbf16, #ttnn_layout4>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc47)
        "ttnn.deallocate"(%34) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout4>) -> () loc(#loc47)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout4>) -> () loc(#loc47)
        %36 = "ttnn.matmul"(%35, %15) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn_layout4>, tensor<512x3072xbf16, #ttnn_layout39>) -> tensor<1x512xbf16, #ttnn_layout50> loc(#loc48)
        "ttnn.deallocate"(%15) <{force = false}> : (tensor<512x3072xbf16, #ttnn_layout39>) -> () loc(#loc48)
        %37 = "ttnn.reshape"(%36) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn_layout50>) -> tensor<1x4x1x128xbf16, #ttnn_layout51> loc(#loc49)
        "ttnn.deallocate"(%36) <{force = false}> : (tensor<1x512xbf16, #ttnn_layout50>) -> () loc(#loc49)
        %38 = "ttnn.to_layout"(%arg0) <{layout = #ttnn.layout<tile>}> : (tensor<1xsi32, #ttnn_layout24>) -> tensor<1xsi32, #ttnn_layout20> loc(#loc50)
        %39 = "ttnn.typecast"(%38) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1xsi32, #ttnn_layout20>) -> tensor<1xf32, #ttnn_layout52> loc(#loc51)
        "ttnn.deallocate"(%38) <{force = false}> : (tensor<1xsi32, #ttnn_layout20>) -> () loc(#loc51)
        %40 = "ttnn.reshape"(%39) <{shape = [1 : i32, 1 : i32, 1 : i32]}> : (tensor<1xf32, #ttnn_layout52>) -> tensor<1x1x1xf32, #ttnn_layout2> loc(#loc51)
        "ttnn.deallocate"(%39) <{force = false}> : (tensor<1xf32, #ttnn_layout52>) -> () loc(#loc51)
        %41 = "ttnn.matmul"(%9, %40) <{transpose_a = false, transpose_b = false}> : (tensor<1x64x1xf32, #ttnn_layout14>, tensor<1x1x1xf32, #ttnn_layout2>) -> tensor<1x64x1xf32, #ttnn_layout14> loc(#loc52)
        "ttnn.deallocate"(%40) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> () loc(#loc52)
        "ttnn.deallocate"(%9) <{force = false}> : (tensor<1x64x1xf32, #ttnn_layout14>) -> () loc(#loc52)
        %42 = "ttnn.reshape"(%41) <{shape = [1 : i32, 1 : i32, 1 : i32, 64 : i32]}> : (tensor<1x64x1xf32, #ttnn_layout14>) -> tensor<1x1x1x64xf32, #ttnn_layout53> loc(#loc53)
        %43 = "ttnn.reshape"(%41) <{shape = [1 : i32, 1 : i32, 1 : i32, 64 : i32]}> : (tensor<1x64x1xf32, #ttnn_layout14>) -> tensor<1x1x1x64xf32, #ttnn_layout53> loc(#loc53)
        "ttnn.deallocate"(%41) <{force = false}> : (tensor<1x64x1xf32, #ttnn_layout14>) -> () loc(#loc53)
        %44 = "ttnn.concat"(%42, %43) <{dim = 3 : si32}> : (tensor<1x1x1x64xf32, #ttnn_layout53>, tensor<1x1x1x64xf32, #ttnn_layout53>) -> tensor<1x1x1x128xf32, #ttnn_layout54> loc(#loc53)
        "ttnn.deallocate"(%43) <{force = false}> : (tensor<1x1x1x64xf32, #ttnn_layout53>) -> () loc(#loc53)
        "ttnn.deallocate"(%42) <{force = false}> : (tensor<1x1x1x64xf32, #ttnn_layout53>) -> () loc(#loc53)
        %45 = "ttnn.cos"(%44) : (tensor<1x1x1x128xf32, #ttnn_layout54>) -> tensor<1x1x1x128xf32, #ttnn_layout54> loc(#loc54)
        %46 = "ttnn.typecast"(%45) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x128xf32, #ttnn_layout54>) -> tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc55)
        "ttnn.deallocate"(%45) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn_layout54>) -> () loc(#loc55)
        %47 = "ttnn.permute"(%46) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc160)
        %48 = "ttnn.permute"(%37) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x4x1x128xbf16, #ttnn_layout51>) -> tensor<1x1x4x128xbf16, #ttnn_layout> loc(#loc161)
        %49 = "ttnn.multiply"(%48, %47) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x4x128xbf16, #ttnn_layout>, tensor<1x1x1x128xbf16, #ttnn_layout>) -> tensor<1x1x4x128xbf16, #ttnn_layout> loc(#loc57)
        "ttnn.deallocate"(%48) <{force = false}> : (tensor<1x1x4x128xbf16, #ttnn_layout>) -> () loc(#loc57)
        "ttnn.deallocate"(%47) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> () loc(#loc57)
        %50 = "ttnn.slice_static"(%37) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn_layout51>) -> tensor<1x4x1x64xbf16, #ttnn_layout55> loc(#loc58)
        %51 = "ttnn.neg"(%50) : (tensor<1x4x1x64xbf16, #ttnn_layout55>) -> tensor<1x4x1x64xbf16, #ttnn_layout55> loc(#loc59)
        "ttnn.deallocate"(%50) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn_layout55>) -> () loc(#loc59)
        %52 = "ttnn.slice_static"(%37) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 4 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x4x1x128xbf16, #ttnn_layout51>) -> tensor<1x4x1x64xbf16, #ttnn_layout55> loc(#loc60)
        "ttnn.deallocate"(%37) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn_layout51>) -> () loc(#loc60)
        %53 = "ttnn.concat"(%51, %52) <{dim = 3 : si32}> : (tensor<1x4x1x64xbf16, #ttnn_layout55>, tensor<1x4x1x64xbf16, #ttnn_layout55>) -> tensor<1x4x1x128xbf16, #ttnn_layout51> loc(#loc61)
        "ttnn.deallocate"(%52) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn_layout55>) -> () loc(#loc61)
        "ttnn.deallocate"(%51) <{force = false}> : (tensor<1x4x1x64xbf16, #ttnn_layout55>) -> () loc(#loc61)
        %54 = "ttnn.permute"(%53) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x4x1x128xbf16, #ttnn_layout51>) -> tensor<1x1x4x128xbf16, #ttnn_layout> loc(#loc61)
        "ttnn.deallocate"(%53) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn_layout51>) -> () loc(#loc61)
        %55 = "ttnn.sin"(%44) : (tensor<1x1x1x128xf32, #ttnn_layout54>) -> tensor<1x1x1x128xf32, #ttnn_layout54> loc(#loc62)
        "ttnn.deallocate"(%44) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn_layout54>) -> () loc(#loc62)
        %56 = "ttnn.typecast"(%55) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x128xf32, #ttnn_layout54>) -> tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc63)
        "ttnn.deallocate"(%55) <{force = false}> : (tensor<1x1x1x128xf32, #ttnn_layout54>) -> () loc(#loc63)
        %57 = "ttnn.permute"(%56) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc162)
        %58 = "ttnn.multiply"(%54, %57) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x4x128xbf16, #ttnn_layout>, tensor<1x1x1x128xbf16, #ttnn_layout>) -> tensor<1x1x4x128xbf16, #ttnn_layout> loc(#loc64)
        "ttnn.deallocate"(%57) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> () loc(#loc64)
        "ttnn.deallocate"(%54) <{force = false}> : (tensor<1x1x4x128xbf16, #ttnn_layout>) -> () loc(#loc64)
        %59 = "ttnn.add"(%49, %58) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x4x128xbf16, #ttnn_layout>, tensor<1x1x4x128xbf16, #ttnn_layout>) -> tensor<1x1x4x128xbf16, #ttnn_layout> loc(#loc65)
        "ttnn.deallocate"(%58) <{force = false}> : (tensor<1x1x4x128xbf16, #ttnn_layout>) -> () loc(#loc65)
        "ttnn.deallocate"(%49) <{force = false}> : (tensor<1x1x4x128xbf16, #ttnn_layout>) -> () loc(#loc65)
        %60 = "ttnn.to_layout"(%arg0) <{layout = #ttnn.layout<tile>}> : (tensor<1xsi32, #ttnn_layout24>) -> tensor<1xsi32, #ttnn_layout20> loc(#loc66)
        %61 = "ttnn.repeat"(%60) <{repeat_dims = #ttnn.shape<1>}> : (tensor<1xsi32, #ttnn_layout20>) -> tensor<1xsi32, #ttnn_layout20> loc(#loc56)
        "ttnn.deallocate"(%60) <{force = false}> : (tensor<1xsi32, #ttnn_layout20>) -> () loc(#loc56)
        %62 = "ttnn.to_memory_config"(%59) <{memory_config = #ttnn.memory_config<#l1, <height_sharded>, #ttnn.shard_spec<<[#ttnn.core_range<(0,0), (0,0)>]>, <32x128>, <row_major>>>}> : (tensor<1x1x4x128xbf16, #ttnn_layout>) -> tensor<1x1x4x128xbf16, #ttnn_layout56> loc(#loc56)
        "ttnn.deallocate"(%59) <{force = false}> : (tensor<1x1x4x128xbf16, #ttnn_layout>) -> () loc(#loc56)
        %63 = "ttnn.to_layout"(%61) <{layout = #ttnn.layout<row_major>}> : (tensor<1xsi32, #ttnn_layout20>) -> tensor<1xsi32, #ttnn_layout24> loc(#loc142)
        "ttnn.deallocate"(%61) <{force = false}> : (tensor<1xsi32, #ttnn_layout20>) -> () loc(#loc142)
        "ttnn.paged_update_cache"(%20, %62, %63) <{share_cache = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout42>, tensor<1x1x4x128xbf16, #ttnn_layout56>, tensor<1xsi32, #ttnn_layout24>) -> () loc(#loc56)
        "ttnn.deallocate"(%63) <{force = false}> : (tensor<1xsi32, #ttnn_layout24>) -> () loc(#loc56)
        "ttnn.deallocate"(%62) <{force = false}> : (tensor<1x1x4x128xbf16, #ttnn_layout56>) -> () loc(#loc56)
        %64 = "ttnn.matmul"(%35, %16) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn_layout4>, tensor<512x3072xbf16, #ttnn_layout39>) -> tensor<1x512xbf16, #ttnn_layout50> loc(#loc67)
        "ttnn.deallocate"(%16) <{force = false}> : (tensor<512x3072xbf16, #ttnn_layout39>) -> () loc(#loc67)
        %65 = "ttnn.reshape"(%64) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32]}> : (tensor<1x512xbf16, #ttnn_layout50>) -> tensor<1x4x1x128xbf16, #ttnn_layout51> loc(#loc68)
        "ttnn.deallocate"(%64) <{force = false}> : (tensor<1x512xbf16, #ttnn_layout50>) -> () loc(#loc68)
        %66 = "ttnn.permute"(%65) <{permutation = array<i64: 0, 2, 1, 3>}> : (tensor<1x4x1x128xbf16, #ttnn_layout51>) -> tensor<1x1x4x128xbf16, #ttnn_layout> loc(#loc69)
        "ttnn.deallocate"(%65) <{force = false}> : (tensor<1x4x1x128xbf16, #ttnn_layout51>) -> () loc(#loc69)
        %67 = "ttnn.to_layout"(%arg0) <{layout = #ttnn.layout<tile>}> : (tensor<1xsi32, #ttnn_layout24>) -> tensor<1xsi32, #ttnn_layout20> loc(#loc70)
        %68 = "ttnn.repeat"(%67) <{repeat_dims = #ttnn.shape<1>}> : (tensor<1xsi32, #ttnn_layout20>) -> tensor<1xsi32, #ttnn_layout20> loc(#loc69)
        "ttnn.deallocate"(%67) <{force = false}> : (tensor<1xsi32, #ttnn_layout20>) -> () loc(#loc69)
        %69 = "ttnn.to_memory_config"(%66) <{memory_config = #ttnn.memory_config<#l1, <height_sharded>, #ttnn.shard_spec<<[#ttnn.core_range<(0,0), (0,0)>]>, <32x128>, <row_major>>>}> : (tensor<1x1x4x128xbf16, #ttnn_layout>) -> tensor<1x1x4x128xbf16, #ttnn_layout56> loc(#loc69)
        "ttnn.deallocate"(%66) <{force = false}> : (tensor<1x1x4x128xbf16, #ttnn_layout>) -> () loc(#loc69)
        %70 = "ttnn.to_layout"(%68) <{layout = #ttnn.layout<row_major>}> : (tensor<1xsi32, #ttnn_layout20>) -> tensor<1xsi32, #ttnn_layout24> loc(#loc143)
        "ttnn.deallocate"(%68) <{force = false}> : (tensor<1xsi32, #ttnn_layout20>) -> () loc(#loc143)
        "ttnn.paged_update_cache"(%21, %69, %70) <{share_cache = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout42>, tensor<1x1x4x128xbf16, #ttnn_layout56>, tensor<1xsi32, #ttnn_layout24>) -> () loc(#loc69)
        "ttnn.deallocate"(%70) <{force = false}> : (tensor<1xsi32, #ttnn_layout24>) -> () loc(#loc69)
        "ttnn.deallocate"(%69) <{force = false}> : (tensor<1x1x4x128xbf16, #ttnn_layout56>) -> () loc(#loc69)
        %71 = "ttnn.matmul"(%35, %17) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn_layout4>, tensor<1536x3072xbf16, #ttnn_layout40>) -> tensor<1x1536xbf16, #ttnn_layout57> loc(#loc71)
        "ttnn.deallocate"(%35) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout4>) -> () loc(#loc71)
        "ttnn.deallocate"(%17) <{force = false}> : (tensor<1536x3072xbf16, #ttnn_layout40>) -> () loc(#loc71)
        %72 = "ttnn.reshape"(%71) <{shape = [1 : i32, 12 : i32, 1 : i32, 128 : i32]}> : (tensor<1x1536xbf16, #ttnn_layout57>) -> tensor<1x12x1x128xbf16, #ttnn_layout58> loc(#loc72)
        "ttnn.deallocate"(%71) <{force = false}> : (tensor<1x1536xbf16, #ttnn_layout57>) -> () loc(#loc72)
        %73 = "ttnn.multiply"(%72, %46) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>, tensor<1x1x1x128xbf16, #ttnn_layout>) -> tensor<1x12x1x128xbf16, #ttnn_layout58> loc(#loc73)
        "ttnn.deallocate"(%46) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> () loc(#loc73)
        %74 = "ttnn.slice_static"(%72) <{begins = [0 : i32, 0 : i32, 0 : i32, 64 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 128 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> tensor<1x12x1x64xbf16, #ttnn_layout59> loc(#loc74)
        %75 = "ttnn.neg"(%74) : (tensor<1x12x1x64xbf16, #ttnn_layout59>) -> tensor<1x12x1x64xbf16, #ttnn_layout59> loc(#loc75)
        "ttnn.deallocate"(%74) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn_layout59>) -> () loc(#loc75)
        %76 = "ttnn.slice_static"(%72) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 12 : i32, 1 : i32, 64 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> tensor<1x12x1x64xbf16, #ttnn_layout59> loc(#loc76)
        "ttnn.deallocate"(%72) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> () loc(#loc76)
        %77 = "ttnn.concat"(%75, %76) <{dim = 3 : si32}> : (tensor<1x12x1x64xbf16, #ttnn_layout59>, tensor<1x12x1x64xbf16, #ttnn_layout59>) -> tensor<1x12x1x128xbf16, #ttnn_layout58> loc(#loc77)
        "ttnn.deallocate"(%76) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn_layout59>) -> () loc(#loc77)
        "ttnn.deallocate"(%75) <{force = false}> : (tensor<1x12x1x64xbf16, #ttnn_layout59>) -> () loc(#loc77)
        %78 = "ttnn.multiply"(%77, %56) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>, tensor<1x1x1x128xbf16, #ttnn_layout>) -> tensor<1x12x1x128xbf16, #ttnn_layout58> loc(#loc78)
        "ttnn.deallocate"(%77) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> () loc(#loc78)
        "ttnn.deallocate"(%56) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> () loc(#loc78)
        %79 = "ttnn.add"(%73, %78) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>, tensor<1x12x1x128xbf16, #ttnn_layout58>) -> tensor<1x12x1x128xbf16, #ttnn_layout58> loc(#loc79)
        "ttnn.deallocate"(%78) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> () loc(#loc79)
        "ttnn.deallocate"(%73) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> () loc(#loc79)
        %80 = "ttnn.reshape"(%20) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn_layout42>) -> tensor<1x4x1x128x128xbf16, #ttnn_layout60> loc(#loc80)
        %81 = "ttnn.repeat"(%80) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn_layout60>) -> tensor<1x4x3x128x128xbf16, #ttnn_layout61> loc(#loc80)
        "ttnn.deallocate"(%80) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn_layout60>) -> () loc(#loc80)
        %82 = "ttnn.reshape"(%81) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn_layout61>) -> tensor<1x12x128x128xbf16, #ttnn_layout62> loc(#loc81)
        "ttnn.deallocate"(%81) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn_layout61>) -> () loc(#loc81)
        %83 = "ttnn.matmul"(%79, %82) <{transpose_a = false, transpose_b = true}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>, tensor<1x12x128x128xbf16, #ttnn_layout62>) -> tensor<1x12x1x128xbf16, #ttnn_layout58> loc(#loc82)
        "ttnn.deallocate"(%82) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn_layout62>) -> () loc(#loc82)
        "ttnn.deallocate"(%79) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> () loc(#loc82)
        %84 = "ttnn.multiply"(%83, %6) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>, tensor<1x1x1x1xbf16, #ttnn_layout9>) -> tensor<1x12x1x128xbf16, #ttnn_layout58> loc(#loc83)
        "ttnn.deallocate"(%83) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> () loc(#loc83)
        "ttnn.deallocate"(%6) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout9>) -> () loc(#loc83)
        %85 = "ttnn.to_layout"(%arg14) <{layout = #ttnn.layout<tile>}> : (tensor<bf16, #ttnn_layout33>) -> tensor<bf16, #ttnn_layout10> loc(#loc144)
        "ttnn.deallocate"(%arg14) <{force = false}> : (tensor<bf16, #ttnn_layout33>) -> () loc(#loc144)
        %86 = "ttnn.reshape"(%85) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<bf16, #ttnn_layout10>) -> tensor<1x1x1x1xbf16, #ttnn_layout9> loc(#loc145)
        "ttnn.deallocate"(%85) <{force = false}> : (tensor<bf16, #ttnn_layout10>) -> () loc(#loc145)
        %87 = "ttnn.logical_and"(%86, %0) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x1xbf16, #ttnn_layout9>, tensor<1x1x1x128xbf16, #ttnn_layout>) -> tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc84)
        "ttnn.deallocate"(%86) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout9>) -> () loc(#loc84)
        "ttnn.deallocate"(%0) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> () loc(#loc84)
        %88 = "ttnn.to_layout"(%arg0) <{layout = #ttnn.layout<tile>}> : (tensor<1xsi32, #ttnn_layout24>) -> tensor<1xsi32, #ttnn_layout20> loc(#loc163)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<1xsi32, #ttnn_layout24>) -> () loc(#loc163)
        %89 = "ttnn.reshape"(%88) <{shape = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1xsi32, #ttnn_layout20>) -> tensor<1x1x1x1xsi32, #ttnn_layout63> loc(#loc164)
        "ttnn.deallocate"(%88) <{force = false}> : (tensor<1xsi32, #ttnn_layout20>) -> () loc(#loc164)
        %90 = "ttnn.gt"(%7, %89) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x128xsi32, #ttnn_layout11>, tensor<1x1x1x1xsi32, #ttnn_layout63>) -> tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc85)
        "ttnn.deallocate"(%89) <{force = false}> : (tensor<1x1x1x1xsi32, #ttnn_layout63>) -> () loc(#loc85)
        "ttnn.deallocate"(%7) <{force = false}> : (tensor<1x1x1x128xsi32, #ttnn_layout11>) -> () loc(#loc85)
        %91 = "ttnn.multiply"(%90, %5#0) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x128xbf16, #ttnn_layout>, tensor<1x1x1x1xbf16, #ttnn_layout9>) -> tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc86)
        "ttnn.deallocate"(%90) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> () loc(#loc86)
        "ttnn.deallocate"(%5#0) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout9>) -> () loc(#loc86)
        %92 = "ttnn.slice_static"(%91) <{begins = [0 : i32, 0 : i32, 0 : i32, 0 : i32], ends = [1 : i32, 1 : i32, 1 : i32, 32 : i32], step = [1 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> tensor<1x1x1x32xbf16, #ttnn_layout9> loc(#loc87)
        %93 = "ttnn.to_layout"(%arg13) <{layout = #ttnn.layout<tile>}> : (tensor<1x32xsi32, #ttnn_layout32>) -> tensor<1x32xsi32, #ttnn_layout43> loc(#loc88)
        "ttnn.deallocate"(%arg13) <{force = false}> : (tensor<1x32xsi32, #ttnn_layout32>) -> () loc(#loc88)
        %94 = "ttnn.typecast"(%93) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x32xsi32, #ttnn_layout43>) -> tensor<1x32xbf16, #ttnn_layout64> loc(#loc89)
        "ttnn.deallocate"(%93) <{force = false}> : (tensor<1x32xsi32, #ttnn_layout43>) -> () loc(#loc89)
        %95 = "ttnn.reshape"(%94) <{shape = [1 : i32, 1 : i32, 1 : i32, 32 : i32]}> : (tensor<1x32xbf16, #ttnn_layout64>) -> tensor<1x1x1x32xbf16, #ttnn_layout9> loc(#loc89)
        "ttnn.deallocate"(%94) <{force = false}> : (tensor<1x32xbf16, #ttnn_layout64>) -> () loc(#loc89)
        %96 = "ttnn.add"(%92, %95) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x32xbf16, #ttnn_layout9>, tensor<1x1x1x32xbf16, #ttnn_layout9>) -> tensor<1x1x1x32xbf16, #ttnn_layout9> loc(#loc90)
        "ttnn.deallocate"(%95) <{force = false}> : (tensor<1x1x1x32xbf16, #ttnn_layout9>) -> () loc(#loc90)
        %97 = "ttnn.eq"(%96, %8#0) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x1x32xbf16, #ttnn_layout9>, tensor<1x1x1x1xbf16, #ttnn_layout9>) -> tensor<1x1x1x32xbf16, #ttnn_layout9> loc(#loc91)
        "ttnn.deallocate"(%96) <{force = false}> : (tensor<1x1x1x32xbf16, #ttnn_layout9>) -> () loc(#loc91)
        "ttnn.deallocate"(%8#0) <{force = false}> : (tensor<1x1x1x1xbf16, #ttnn_layout9>) -> () loc(#loc91)
        %98 = "ttnn.where"(%97, %5#1, %92) : (tensor<1x1x1x32xbf16, #ttnn_layout9>, tensor<1x1x1x32xbf16, #ttnn_layout9>, tensor<1x1x1x32xbf16, #ttnn_layout9>) -> tensor<1x1x1x32xbf16, #ttnn_layout9> loc(#loc6)
        "ttnn.deallocate"(%97) <{force = false}> : (tensor<1x1x1x32xbf16, #ttnn_layout9>) -> () loc(#loc6)
        "ttnn.deallocate"(%92) <{force = false}> : (tensor<1x1x1x32xbf16, #ttnn_layout9>) -> () loc(#loc6)
        "ttnn.deallocate"(%5#1) <{force = false}> : (tensor<1x1x1x32xbf16, #ttnn_layout9>) -> () loc(#loc6)
        %99 = "ttnn.permute"(%98) <{permutation = array<i64: 3, 0, 1, 2>}> : (tensor<1x1x1x32xbf16, #ttnn_layout9>) -> tensor<32x1x1x1xbf16, #ttnn_layout65> loc(#loc146)
        "ttnn.deallocate"(%98) <{force = false}> : (tensor<1x1x1x32xbf16, #ttnn_layout9>) -> () loc(#loc146)
        %100 = "ttnn.reshape"(%99) <{shape = [32 : i32, 1 : i32]}> : (tensor<32x1x1x1xbf16, #ttnn_layout65>) -> tensor<32x1xbf16, #ttnn_layout64> loc(#loc147)
        "ttnn.deallocate"(%99) <{force = false}> : (tensor<32x1x1x1xbf16, #ttnn_layout65>) -> () loc(#loc147)
        %101 = "ttnn.to_layout"(%100) <{layout = #ttnn.layout<row_major>}> : (tensor<32x1xbf16, #ttnn_layout64>) -> tensor<32x1xbf16, #ttnn_layout66> loc(#loc136)
        "ttnn.deallocate"(%100) <{force = false}> : (tensor<32x1xbf16, #ttnn_layout64>) -> () loc(#loc136)
        %102 = "ttnn.embedding"(%10, %101) : (tensor<128x1xui32, #ttnn_layout17>, tensor<32x1xbf16, #ttnn_layout66>) -> tensor<128x1x1xbf16, #ttnn_layout67> loc(#loc17)
        "ttnn.deallocate"(%101) <{force = false}> : (tensor<32x1xbf16, #ttnn_layout66>) -> () loc(#loc17)
        "ttnn.deallocate"(%10) <{force = false}> : (tensor<128x1xui32, #ttnn_layout17>) -> () loc(#loc17)
        %103 = "ttnn.reshape"(%102) <{shape = [128 : i32, 1 : i32, 1 : i32, 1 : i32]}> : (tensor<128x1x1xbf16, #ttnn_layout67>) -> tensor<128x1x1x1xbf16, #ttnn_layout68> loc(#loc148)
        "ttnn.deallocate"(%102) <{force = false}> : (tensor<128x1x1xbf16, #ttnn_layout67>) -> () loc(#loc148)
        %104 = "ttnn.permute"(%103) <{permutation = array<i64: 1, 2, 3, 0>}> : (tensor<128x1x1x1xbf16, #ttnn_layout68>) -> tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc149)
        "ttnn.deallocate"(%103) <{force = false}> : (tensor<128x1x1x1xbf16, #ttnn_layout68>) -> () loc(#loc149)
        %105 = "ttnn.where"(%87, %104, %8#1) : (tensor<1x1x1x128xbf16, #ttnn_layout>, tensor<1x1x1x128xbf16, #ttnn_layout>, tensor<1x1x1x128xbf16, #ttnn_layout>) -> tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc134)
        "ttnn.deallocate"(%104) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> () loc(#loc134)
        "ttnn.deallocate"(%8#1) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> () loc(#loc134)
        %106 = "ttnn.where"(%87, %105, %91) : (tensor<1x1x1x128xbf16, #ttnn_layout>, tensor<1x1x1x128xbf16, #ttnn_layout>, tensor<1x1x1x128xbf16, #ttnn_layout>) -> tensor<1x1x1x128xbf16, #ttnn_layout> loc(#loc92)
        "ttnn.deallocate"(%105) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> () loc(#loc92)
        "ttnn.deallocate"(%91) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> () loc(#loc92)
        "ttnn.deallocate"(%87) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> () loc(#loc92)
        %107 = "ttnn.add"(%84, %106) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>, tensor<1x1x1x128xbf16, #ttnn_layout>) -> tensor<1x12x1x128xbf16, #ttnn_layout58> loc(#loc93)
        "ttnn.deallocate"(%106) <{force = false}> : (tensor<1x1x1x128xbf16, #ttnn_layout>) -> () loc(#loc93)
        "ttnn.deallocate"(%84) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> () loc(#loc93)
        %108 = "ttnn.typecast"(%107) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> tensor<1x12x1x128xf32, #ttnn_layout69> loc(#loc94)
        "ttnn.deallocate"(%107) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> () loc(#loc94)
        %109 = "ttnn.softmax"(%108) <{dimension = 3 : si32, numericStable = true}> : (tensor<1x12x1x128xf32, #ttnn_layout69>) -> tensor<1x12x1x128xf32, #ttnn_layout69> loc(#loc95)
        "ttnn.deallocate"(%108) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn_layout69>) -> () loc(#loc95)
        %110 = "ttnn.typecast"(%109) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x12x1x128xf32, #ttnn_layout69>) -> tensor<1x12x1x128xbf16, #ttnn_layout58> loc(#loc96)
        "ttnn.deallocate"(%109) <{force = false}> : (tensor<1x12x1x128xf32, #ttnn_layout69>) -> () loc(#loc96)
        %111 = "ttnn.reshape"(%21) <{shape = [1 : i32, 4 : i32, 1 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x128x128xbf16, #ttnn_layout42>) -> tensor<1x4x1x128x128xbf16, #ttnn_layout60> loc(#loc97)
        %112 = "ttnn.repeat"(%111) <{repeat_dims = #ttnn.shape<1x1x3x1x1>}> : (tensor<1x4x1x128x128xbf16, #ttnn_layout60>) -> tensor<1x4x3x128x128xbf16, #ttnn_layout61> loc(#loc97)
        "ttnn.deallocate"(%111) <{force = false}> : (tensor<1x4x1x128x128xbf16, #ttnn_layout60>) -> () loc(#loc97)
        %113 = "ttnn.reshape"(%112) <{shape = [1 : i32, 12 : i32, 128 : i32, 128 : i32]}> : (tensor<1x4x3x128x128xbf16, #ttnn_layout61>) -> tensor<1x12x128x128xbf16, #ttnn_layout62> loc(#loc98)
        "ttnn.deallocate"(%112) <{force = false}> : (tensor<1x4x3x128x128xbf16, #ttnn_layout61>) -> () loc(#loc98)
        %114 = "ttnn.matmul"(%110, %113) <{transpose_a = false, transpose_b = false}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>, tensor<1x12x128x128xbf16, #ttnn_layout62>) -> tensor<1x12x1x128xbf16, #ttnn_layout58> loc(#loc99)
        "ttnn.deallocate"(%113) <{force = false}> : (tensor<1x12x128x128xbf16, #ttnn_layout62>) -> () loc(#loc99)
        "ttnn.deallocate"(%110) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> () loc(#loc99)
        %115 = "ttnn.reshape"(%114) <{shape = [1 : i32, 1536 : i32]}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> tensor<1x1536xbf16, #ttnn_layout57> loc(#loc100)
        "ttnn.deallocate"(%114) <{force = false}> : (tensor<1x12x1x128xbf16, #ttnn_layout58>) -> () loc(#loc100)
        %116 = "ttnn.matmul"(%115, %14) <{transpose_a = false, transpose_b = true}> : (tensor<1x1536xbf16, #ttnn_layout57>, tensor<3072x1536xbf16, #ttnn_layout38>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc101)
        "ttnn.deallocate"(%115) <{force = false}> : (tensor<1x1536xbf16, #ttnn_layout57>) -> () loc(#loc101)
        "ttnn.deallocate"(%14) <{force = false}> : (tensor<3072x1536xbf16, #ttnn_layout38>) -> () loc(#loc101)
        %117 = "ttnn.reshape"(%116) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn_layout4>) -> tensor<1x1x1x3072xbf16, #ttnn_layout70> loc(#loc165)
        "ttnn.deallocate"(%116) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout4>) -> () loc(#loc165)
        %118 = "ttnn.reduce_scatter"(%117) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn_layout70>) -> tensor<1x1x1x1536xbf16, #ttnn_layout71> loc(#loc166)
        "ttnn.deallocate"(%117) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn_layout70>) -> () loc(#loc166)
        %119 = "ttnn.all_gather"(%118) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn_layout71>) -> tensor<1x1x1x3072xbf16, #ttnn_layout70> loc(#loc151)
        "ttnn.deallocate"(%118) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn_layout71>) -> () loc(#loc151)
        %120 = "ttnn.reshape"(%119) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn_layout70>) -> tensor<1x1x3072xbf16, #ttnn_layout46> loc(#loc102)
        "ttnn.deallocate"(%119) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn_layout70>) -> () loc(#loc102)
        %121 = "ttnn.add"(%25, %120) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x3072xbf16, #ttnn_layout46>, tensor<1x1x3072xbf16, #ttnn_layout46>) -> tensor<1x1x3072xbf16, #ttnn_layout46> loc(#loc103)
        "ttnn.deallocate"(%120) <{force = false}> : (tensor<1x1x3072xbf16, #ttnn_layout46>) -> () loc(#loc103)
        "ttnn.deallocate"(%25) <{force = false}> : (tensor<1x1x3072xbf16, #ttnn_layout46>) -> () loc(#loc103)
        %122 = "ttnn.typecast"(%121) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x3072xbf16, #ttnn_layout46>) -> tensor<1x1x3072xf32, #ttnn_layout47> loc(#loc104)
        %123 = "ttnn.pow_scalar"(%122) <{rhs = 2.000000e+00 : f32}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> tensor<1x1x3072xf32, #ttnn_layout47> loc(#loc105)
        %124 = "ttnn.mean"(%123) <{dim_arg = [2 : i32], keep_dim = true}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> tensor<1x1x1xf32, #ttnn_layout2> loc(#loc152)
        "ttnn.deallocate"(%123) <{force = false}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> () loc(#loc152)
        %125 = "ttnn.add"(%124, %1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1xf32, #ttnn_layout2>, tensor<1x1x1xf32, #ttnn_layout2>) -> tensor<1x1x1xf32, #ttnn_layout2> loc(#loc107)
        "ttnn.deallocate"(%124) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> () loc(#loc107)
        %126 = "ttnn.rsqrt"(%125) : (tensor<1x1x1xf32, #ttnn_layout2>) -> tensor<1x1x1xf32, #ttnn_layout2> loc(#loc108)
        "ttnn.deallocate"(%125) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> () loc(#loc108)
        %127 = "ttnn.reshape"(%126) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> tensor<1x1xf32, #ttnn_layout48> loc(#loc108)
        "ttnn.deallocate"(%126) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> () loc(#loc108)
        %128 = "ttnn.reshape"(%122) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> tensor<1x3072xf32, #ttnn_layout49> loc(#loc172)
        "ttnn.deallocate"(%122) <{force = false}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> () loc(#loc172)
        %129 = "ttnn.multiply"(%128, %127) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn_layout49>, tensor<1x1xf32, #ttnn_layout48>) -> tensor<1x3072xf32, #ttnn_layout49> loc(#loc109)
        "ttnn.deallocate"(%128) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout49>) -> () loc(#loc109)
        "ttnn.deallocate"(%127) <{force = false}> : (tensor<1x1xf32, #ttnn_layout48>) -> () loc(#loc109)
        %130 = "ttnn.typecast"(%129) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn_layout49>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc110)
        "ttnn.deallocate"(%129) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout49>) -> () loc(#loc110)
        %131 = "ttnn.multiply"(%11, %130) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn_layout4>, tensor<1x3072xbf16, #ttnn_layout4>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc111)
        "ttnn.deallocate"(%130) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout4>) -> () loc(#loc111)
        "ttnn.deallocate"(%11) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout4>) -> () loc(#loc111)
        %132 = "ttnn.matmul"(%131, %18) <{activation = "silu", transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn_layout4>, tensor<4096x3072xbf16, #ttnn_layout37>) -> tensor<1x4096xbf16, #ttnn_layout72> loc(#loc112)
        "ttnn.deallocate"(%18) <{force = false}> : (tensor<4096x3072xbf16, #ttnn_layout37>) -> () loc(#loc112)
        %133 = "ttnn.matmul"(%131, %13) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn_layout4>, tensor<4096x3072xbf16, #ttnn_layout37>) -> tensor<1x4096xbf16, #ttnn_layout72> loc(#loc113)
        "ttnn.deallocate"(%131) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout4>) -> () loc(#loc113)
        "ttnn.deallocate"(%13) <{force = false}> : (tensor<4096x3072xbf16, #ttnn_layout37>) -> () loc(#loc113)
        %134 = "ttnn.multiply"(%132, %133) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x4096xbf16, #ttnn_layout72>, tensor<1x4096xbf16, #ttnn_layout72>) -> tensor<1x4096xbf16, #ttnn_layout72> loc(#loc114)
        "ttnn.deallocate"(%133) <{force = false}> : (tensor<1x4096xbf16, #ttnn_layout72>) -> () loc(#loc114)
        "ttnn.deallocate"(%132) <{force = false}> : (tensor<1x4096xbf16, #ttnn_layout72>) -> () loc(#loc114)
        %135 = "ttnn.matmul"(%134, %19) <{transpose_a = false, transpose_b = true}> : (tensor<1x4096xbf16, #ttnn_layout72>, tensor<3072x4096xbf16, #ttnn_layout41>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc115)
        "ttnn.deallocate"(%134) <{force = false}> : (tensor<1x4096xbf16, #ttnn_layout72>) -> () loc(#loc115)
        "ttnn.deallocate"(%19) <{force = false}> : (tensor<3072x4096xbf16, #ttnn_layout41>) -> () loc(#loc115)
        %136 = "ttnn.reshape"(%135) <{shape = [1 : i32, 1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x3072xbf16, #ttnn_layout4>) -> tensor<1x1x1x3072xbf16, #ttnn_layout70> loc(#loc168)
        "ttnn.deallocate"(%135) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout4>) -> () loc(#loc168)
        %137 = "ttnn.reduce_scatter"(%136) <{cluster_axis = 1 : ui32, reduce_type = #ttcore.reduce_type<sum>, scatter_dim = 3 : si32}> : (tensor<1x1x1x3072xbf16, #ttnn_layout70>) -> tensor<1x1x1x1536xbf16, #ttnn_layout71> loc(#loc169)
        "ttnn.deallocate"(%136) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn_layout70>) -> () loc(#loc169)
        %138 = "ttnn.all_gather"(%137) <{all_gather_dim = 3 : si32, cluster_axis = 1 : ui32}> : (tensor<1x1x1x1536xbf16, #ttnn_layout71>) -> tensor<1x1x1x3072xbf16, #ttnn_layout70> loc(#loc155)
        "ttnn.deallocate"(%137) <{force = false}> : (tensor<1x1x1x1536xbf16, #ttnn_layout71>) -> () loc(#loc155)
        %139 = "ttnn.reshape"(%138) <{shape = [1 : i32, 1 : i32, 3072 : i32]}> : (tensor<1x1x1x3072xbf16, #ttnn_layout70>) -> tensor<1x1x3072xbf16, #ttnn_layout46> loc(#loc116)
        "ttnn.deallocate"(%138) <{force = false}> : (tensor<1x1x1x3072xbf16, #ttnn_layout70>) -> () loc(#loc116)
        %140 = "ttnn.add"(%121, %139) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x1x3072xbf16, #ttnn_layout46>, tensor<1x1x3072xbf16, #ttnn_layout46>) -> tensor<1x1x3072xbf16, #ttnn_layout46> loc(#loc117)
        "ttnn.deallocate"(%139) <{force = false}> : (tensor<1x1x3072xbf16, #ttnn_layout46>) -> () loc(#loc117)
        "ttnn.deallocate"(%121) <{force = false}> : (tensor<1x1x3072xbf16, #ttnn_layout46>) -> () loc(#loc117)
        %141 = "ttnn.typecast"(%140) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x3072xbf16, #ttnn_layout46>) -> tensor<1x1x3072xf32, #ttnn_layout47> loc(#loc118)
        "ttnn.deallocate"(%140) <{force = false}> : (tensor<1x1x3072xbf16, #ttnn_layout46>) -> () loc(#loc118)
        %142 = "ttnn.pow_scalar"(%141) <{rhs = 2.000000e+00 : f32}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> tensor<1x1x3072xf32, #ttnn_layout47> loc(#loc119)
        %143 = "ttnn.mean"(%142) <{dim_arg = [2 : i32], keep_dim = true}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> tensor<1x1x1xf32, #ttnn_layout2> loc(#loc156)
        "ttnn.deallocate"(%142) <{force = false}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> () loc(#loc156)
        %144 = "ttnn.add"(%143, %1) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x1x1xf32, #ttnn_layout2>, tensor<1x1x1xf32, #ttnn_layout2>) -> tensor<1x1x1xf32, #ttnn_layout2> loc(#loc121)
        "ttnn.deallocate"(%143) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> () loc(#loc121)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> () loc(#loc121)
        %145 = "ttnn.rsqrt"(%144) : (tensor<1x1x1xf32, #ttnn_layout2>) -> tensor<1x1x1xf32, #ttnn_layout2> loc(#loc122)
        "ttnn.deallocate"(%144) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> () loc(#loc122)
        %146 = "ttnn.reshape"(%145) <{shape = [1 : i32, 1 : i32]}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> tensor<1x1xf32, #ttnn_layout48> loc(#loc122)
        "ttnn.deallocate"(%145) <{force = false}> : (tensor<1x1x1xf32, #ttnn_layout2>) -> () loc(#loc122)
        %147 = "ttnn.reshape"(%141) <{shape = [1 : i32, 3072 : i32]}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> tensor<1x3072xf32, #ttnn_layout49> loc(#loc173)
        "ttnn.deallocate"(%141) <{force = false}> : (tensor<1x1x3072xf32, #ttnn_layout47>) -> () loc(#loc173)
        %148 = "ttnn.multiply"(%147, %146) <{dtype = #ttcore.supportedDataTypes<f32>}> : (tensor<1x3072xf32, #ttnn_layout49>, tensor<1x1xf32, #ttnn_layout48>) -> tensor<1x3072xf32, #ttnn_layout49> loc(#loc123)
        "ttnn.deallocate"(%147) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout49>) -> () loc(#loc123)
        "ttnn.deallocate"(%146) <{force = false}> : (tensor<1x1xf32, #ttnn_layout48>) -> () loc(#loc123)
        %149 = "ttnn.typecast"(%148) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xf32, #ttnn_layout49>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc124)
        "ttnn.deallocate"(%148) <{force = false}> : (tensor<1x3072xf32, #ttnn_layout49>) -> () loc(#loc124)
        %150 = "ttnn.multiply"(%3, %149) <{dtype = #ttcore.supportedDataTypes<bf16>}> : (tensor<1x3072xbf16, #ttnn_layout4>, tensor<1x3072xbf16, #ttnn_layout4>) -> tensor<1x3072xbf16, #ttnn_layout4> loc(#loc125)
        "ttnn.deallocate"(%149) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout4>) -> () loc(#loc125)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout4>) -> () loc(#loc125)
        %151 = "ttnn.matmul"(%150, %arg9) <{transpose_a = false, transpose_b = true}> : (tensor<1x3072xbf16, #ttnn_layout4>, tensor<128256x3072xbf16, #ttnn_layout28>) -> tensor<1x128256xbf16, #ttnn_layout73> loc(#loc126)
        "ttnn.deallocate"(%150) <{force = false}> : (tensor<1x3072xbf16, #ttnn_layout4>) -> () loc(#loc126)
        "ttnn.deallocate"(%arg9) <{force = false}> : (tensor<128256x3072xbf16, #ttnn_layout28>) -> () loc(#loc126)
        %152 = "ttnn.reshape"(%151) <{shape = [1 : i32, 1 : i32, 128256 : i32]}> : (tensor<1x128256xbf16, #ttnn_layout73>) -> tensor<1x1x128256xbf16, #ttnn_layout74> loc(#loc127)
        %153 = "ttnn.to_layout"(%20) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn_layout42>) -> tensor<1x4x128x128xbf16, #ttnn_layout75> loc(#loc)
        "ttnn.deallocate"(%20) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout42>) -> () loc(#loc)
        %154 = "ttnn.from_device"(%153) : (tensor<1x4x128x128xbf16, #ttnn_layout75>) -> tensor<1x4x128x128xbf16, #ttnn_layout76> loc(#loc)
        "ttnn.deallocate"(%153) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout75>) -> () loc(#loc)
        %155 = "ttnn.aggregate_tensor"(%154, %12) <{composer_config = #ttnn.mesh_composer_config<dims = [3 : i32, 1 : i32], mesh_shape_override = [1 : ui32, 2 : ui32]>}> : (tensor<1x4x128x128xbf16, #ttnn_layout76>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn_layout34> loc(#loc)
        "ttnn.deallocate"(%154) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout76>) -> () loc(#loc)
        %156 = "ttnn.to_layout"(%21) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x128x128xbf16, #ttnn_layout42>) -> tensor<1x4x128x128xbf16, #ttnn_layout75> loc(#loc)
        "ttnn.deallocate"(%21) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout42>) -> () loc(#loc)
        %157 = "ttnn.from_device"(%156) : (tensor<1x4x128x128xbf16, #ttnn_layout75>) -> tensor<1x4x128x128xbf16, #ttnn_layout76> loc(#loc)
        "ttnn.deallocate"(%156) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout75>) -> () loc(#loc)
        %158 = "ttnn.aggregate_tensor"(%157, %12) <{composer_config = #ttnn.mesh_composer_config<dims = [3 : i32, 1 : i32], mesh_shape_override = [1 : ui32, 2 : ui32]>}> : (tensor<1x4x128x128xbf16, #ttnn_layout76>, !ttnn.device) -> tensor<1x8x128x128xbf16, #ttnn_layout34> loc(#loc)
        "ttnn.deallocate"(%157) <{force = false}> : (tensor<1x4x128x128xbf16, #ttnn_layout76>) -> () loc(#loc)
        %159 = "ttnn.to_layout"(%151) <{layout = #ttnn.layout<row_major>}> : (tensor<1x128256xbf16, #ttnn_layout73>) -> tensor<1x128256xbf16, #ttnn_layout77> loc(#loc)
        "ttnn.deallocate"(%151) <{force = false}> : (tensor<1x128256xbf16, #ttnn_layout73>) -> () loc(#loc)
        %160 = "ttnn.from_device"(%159) : (tensor<1x128256xbf16, #ttnn_layout77>) -> tensor<1x128256xbf16, #ttnn_layout35> loc(#loc)
        "ttnn.deallocate"(%159) <{force = false}> : (tensor<1x128256xbf16, #ttnn_layout77>) -> () loc(#loc)
        %161 = "ttnn.aggregate_tensor"(%160, %12) <{composer_config = #ttnn.mesh_composer_config<dims = [0 : i32], mesh_shape_override = [1 : ui32]>}> : (tensor<1x128256xbf16, #ttnn_layout35>, !ttnn.device) -> tensor<1x128256xbf16, #ttnn_layout35> loc(#loc)
        "ttnn.deallocate"(%160) <{force = false}> : (tensor<1x128256xbf16, #ttnn_layout35>) -> () loc(#loc)
        %162 = "ttnn.to_layout"(%152) <{layout = #ttnn.layout<row_major>}> : (tensor<1x1x128256xbf16, #ttnn_layout74>) -> tensor<1x1x128256xbf16, #ttnn_layout78> loc(#loc)
        "ttnn.deallocate"(%152) <{force = false}> : (tensor<1x1x128256xbf16, #ttnn_layout74>) -> () loc(#loc)
        %163 = "ttnn.from_device"(%162) : (tensor<1x1x128256xbf16, #ttnn_layout78>) -> tensor<1x1x128256xbf16, #ttnn_layout36> loc(#loc)
        "ttnn.deallocate"(%162) <{force = false}> : (tensor<1x1x128256xbf16, #ttnn_layout78>) -> () loc(#loc)
        %164 = "ttnn.aggregate_tensor"(%163, %12) <{composer_config = #ttnn.mesh_composer_config<dims = [0 : i32], mesh_shape_override = [1 : ui32]>}> : (tensor<1x1x128256xbf16, #ttnn_layout36>, !ttnn.device) -> tensor<1x1x128256xbf16, #ttnn_layout36> loc(#loc)
        "ttnn.deallocate"(%163) <{force = false}> : (tensor<1x1x128256xbf16, #ttnn_layout36>) -> () loc(#loc)
        return %155, %158, %161, %164 : tensor<1x8x128x128xbf16, #ttnn_layout34>, tensor<1x8x128x128xbf16, #ttnn_layout34>, tensor<1x128256xbf16, #ttnn_layout35>, tensor<1x1x128256xbf16, #ttnn_layout36> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("reshape.298")
#loc2 = loc("reshape.85")
#loc3 = loc("reshape.475")
#loc4 = loc("gather.48")
#loc5 = loc("reshape.207")
#loc6 = loc("select.277")
#loc7 = loc("select.301")
#loc8 = loc("not.299")
#loc9 = loc("reshape.19")
#loc10 = loc("floor.227")
#loc11 = loc("convert.228")
#loc12 = loc("clamp.231")
#loc13 = loc("compare.240")
#loc14 = loc("add.237")
#loc15 = loc("select.241")
#loc16 = loc("reshape.242")
#loc17 = loc("gather.279")
#loc18 = loc("reshape.425")
#loc38 = loc("convert.47_in_0_layout")
#loc39 = loc("convert.47")
#loc40 = loc("convert.50")
#loc41 = loc("power.52")
#loc42 = loc("reduce.59")
#loc43 = loc("add.73")
#loc44 = loc("rsqrt.74")
#loc45 = loc("multiply.77")
#loc46 = loc("convert.78")
#loc47 = loc("multiply.84")
#loc48 = loc("dot.86")
#loc49 = loc("transpose.89")
#loc50 = loc("convert.11_in_0_layout")
#loc51 = loc("convert.11")
#loc52 = loc("dot.22")
#loc53 = loc("concatenate.24")
#loc54 = loc("cosine.98")
#loc55 = loc("convert.101")
#loc56 = loc("scatter.125")
#loc57 = loc("multiply.105")
#loc58 = loc("slice.91")
#loc59 = loc("negate.92")
#loc60 = loc("slice.90")
#loc61 = loc("concatenate.93")
#loc62 = loc("sine.25")
#loc63 = loc("convert.28")
#loc64 = loc("multiply.96")
#loc65 = loc("add.108")
#loc66 = loc("scatter.125_in_0_layout")
#loc67 = loc("dot.133")
#loc68 = loc("transpose.136")
#loc69 = loc("scatter.153")
#loc70 = loc("scatter.153_in_0_layout")
#loc71 = loc("dot.327")
#loc72 = loc("transpose.330")
#loc73 = loc("multiply.340")
#loc74 = loc("slice.332")
#loc75 = loc("negate.333")
#loc76 = loc("slice.331")
#loc77 = loc("concatenate.334")
#loc78 = loc("multiply.337")
#loc79 = loc("add.343")
#loc80 = loc("broadcast.317")
#loc81 = loc("reshape.318")
#loc82 = loc("dot.344")
#loc83 = loc("multiply.347")
#loc84 = loc("and.297")
#loc85 = loc("compare.198")
#loc86 = loc("multiply.205")
#loc87 = loc("slice.268")
#loc88 = loc("convert.269_in_0_layout")
#loc89 = loc("convert.269")
#loc90 = loc("add.272")
#loc91 = loc("compare.275")
#loc92 = loc("select.302")
#loc93 = loc("add.352")
#loc94 = loc("convert.353")
#loc95 = loc("divide.370")
#loc96 = loc("convert.371")
#loc97 = loc("broadcast.190")
#loc98 = loc("reshape.191")
#loc99 = loc("dot.372")
#loc100 = loc("reshape.376")
#loc101 = loc("dot.377")
#loc102 = loc("reshape.378")
#loc103 = loc("add.381")
#loc104 = loc("convert.382")
#loc105 = loc("power.384")
#loc106 = loc("reduce.391")
#loc107 = loc("add.405")
#loc108 = loc("rsqrt.406")
#loc109 = loc("multiply.409")
#loc110 = loc("convert.410")
#loc111 = loc("multiply.416")
#loc112 = loc("dot.426")
#loc113 = loc("dot.418")
#loc114 = loc("multiply.430")
#loc115 = loc("dot.432")
#loc116 = loc("reshape.433")
#loc117 = loc("add.436")
#loc118 = loc("convert.437")
#loc119 = loc("power.439")
#loc120 = loc("reduce.446")
#loc121 = loc("add.460")
#loc122 = loc("rsqrt.461")
#loc123 = loc("multiply.464")
#loc124 = loc("convert.465")
#loc125 = loc("multiply.471")
#loc126 = loc("dot.476")
#loc127 = loc("reshape.477")
#loc128 = loc("reshape.298_tm1"(#loc1))
#loc129 = loc("reshape.85_tm0"(#loc2))
#loc130 = loc("reshape.475_tm0"(#loc3))
#loc131 = loc("gather.48_workaround"(#loc4))
#loc132 = loc("reshape.207_tm1"(#loc5))
#loc133 = loc("reshape.207_tm0"(#loc5))
#loc134 = loc(fused[#loc7, #loc8])
#loc135 = loc("select.241_workaround"(#loc15))
#loc136 = loc("gather.279_workaround"(#loc17))
#loc137 = loc("reshape.425_tm0"(#loc18))
#loc138 = loc("reduce.59_mean"(#loc42))
#loc139 = loc("reshape.85_tm1"(#loc2))
#loc140 = loc("scatter.125_tm0"(#loc56))
#loc141 = loc("scatter.125_tm1"(#loc56))
#loc142 = loc("scatter.125_workaround"(#loc56))
#loc143 = loc("scatter.153_workaround"(#loc69))
#loc144 = loc("reshape.298_tm0_in_0_layout"(#loc1))
#loc145 = loc("reshape.298_tm0"(#loc1))
#loc146 = loc("gather.279_permuteInput"(#loc17))
#loc147 = loc("gather.279_reshapeInput"(#loc17))
#loc148 = loc("gather.279_reshapeOutput"(#loc17))
#loc149 = loc("gather.279_permuteOutput"(#loc17))
#loc150 = loc("dot.377_reduceScatter"(#loc101))
#loc151 = loc("dot.377_all_gather_4d"(#loc101))
#loc152 = loc("reduce.391_mean"(#loc106))
#loc153 = loc("reshape.425_tm1"(#loc18))
#loc154 = loc("dot.432_reduceScatter"(#loc115))
#loc155 = loc("dot.432_all_gather_4d"(#loc115))
#loc156 = loc("reduce.446_mean"(#loc120))
#loc157 = loc("reshape.475_tm1"(#loc3))
#loc158 = loc("reshape.207_tm0_tm0"(#loc133))
#loc159 = loc("reshape.85_tm1_tm0"(#loc139))
#loc160 = loc("scatter.125_tm0_tm1"(#loc140))
#loc161 = loc("scatter.125_tm0_tm0"(#loc140))
#loc162 = loc("scatter.125_tm1_tm1"(#loc141))
#loc163 = loc("reshape.207_tm0_tm1_in_0_layout"(#loc133))
#loc164 = loc("reshape.207_tm0_tm1"(#loc133))
#loc165 = loc("dot.377_reduceScatter_reshape_to_4d"(#loc150))
#loc166 = loc("dot.377_reduceScatter_reduce_scatter_4d"(#loc150))
#loc167 = loc("reshape.425_tm1_tm0"(#loc153))
#loc168 = loc("dot.432_reduceScatter_reshape_to_4d"(#loc154))
#loc169 = loc("dot.432_reduceScatter_reduce_scatter_4d"(#loc154))
#loc170 = loc("reshape.475_tm1_tm0"(#loc157))
#loc171 = loc("reshape.85_tm1_tm0_tm0"(#loc159))
#loc172 = loc("reshape.425_tm1_tm0_tm0"(#loc167))
#loc173 = loc("reshape.475_tm1_tm0_tm0"(#loc170))
------------------ END OF MLIR MODULE ------------------
2026-01-02 18:37:47.377 (  18.435s) [        CBC3A000]loaded_executable_insta:290      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2026-01-02 18:37:47.377 (  18.435s) [        CBC3A000]loaded_executable_insta:309      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2026-01-02 18:37:47.378 (  18.436s) [        CBC3A000]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2026-01-02 18:37:47.378 (  18.436s) [        CBC3A000]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-01-02 18:37:47.378 (  18.436s) [        CBC3A000]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-01-02 18:37:47.378 (  18.436s) [        CBC3A000]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-01-02 18:37:47.378 (  18.436s) [        CBC3A000] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-02 18:37:47.378 (  18.436s) [        CBC3A000] executable_instance.cc:179      1| Literal MLIR code (size=40801):

module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, mhlo.spmd_output_sharding="{{devices=[1,2,1,1]<=[2]},{devices=[1,2,1,1]<=[2]},{replicated},{replicated}}"
} {
  func.func @main(%arg0: tensor<32xi64>, %arg1: tensor<64xf32>, %arg2: tensor<1024x3072xbf16>, %arg3: tensor<1x32xi64>, %arg4: tensor<128256x3072xbf16>, %arg5: tensor<3072xbf16>, %arg6: tensor<1x8x128x128xbf16>, %arg7: tensor<1024x3072xbf16>, %arg8: tensor<1x8x128x128xbf16>, %arg9: tensor<128256x3072xbf16>, %arg10: tensor<3072x8192xbf16>, %arg11: tensor<8192x3072xbf16>, %arg12: tensor<3072x3072xbf16>, %arg13: tensor<1x32xi64>, %arg14: tensor<i1>, %arg15: tensor<3072x3072xbf16>, %arg16: tensor<3072xbf16>, %arg17: tensor<8192x3072xbf16>, %arg18: tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>) {
    %0 = mhlo.copy %arg0 {mhlo.sharding = "{replicated}"} : tensor<32xi64>
    %1 = stablehlo.custom_call @SPMDFullToShardShape(%0) {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xi64>
    %2 = mhlo.copy %arg1 {mhlo.sharding = "{replicated}"} : tensor<64xf32>
    %3 = stablehlo.custom_call @SPMDFullToShardShape(%2) {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<64xf32>
    %4 = mhlo.copy %arg2 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %5 = stablehlo.custom_call @SPMDFullToShardShape(%4) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %6 = mhlo.copy %arg3 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %7 = stablehlo.custom_call @SPMDFullToShardShape(%6) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %8 = mhlo.copy %arg4 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %9 = stablehlo.custom_call @SPMDFullToShardShape(%8) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %10 = mhlo.copy %arg5 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %11 = stablehlo.custom_call @SPMDFullToShardShape(%10) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %12 = mhlo.copy %arg6 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %13 = stablehlo.custom_call @SPMDFullToShardShape(%12) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %14 = mhlo.copy %arg7 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %15 = stablehlo.custom_call @SPMDFullToShardShape(%14) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %16 = mhlo.copy %arg8 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %17 = stablehlo.custom_call @SPMDFullToShardShape(%16) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %18 = mhlo.copy %arg9 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %19 = stablehlo.custom_call @SPMDFullToShardShape(%18) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %20 = mhlo.copy %arg10 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x8192xbf16>
    %21 = stablehlo.custom_call @SPMDFullToShardShape(%20) {mhlo.sharding = "{manual}"} : (tensor<3072x8192xbf16>) -> tensor<3072x4096xbf16>
    %22 = mhlo.copy %arg11 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %23 = stablehlo.custom_call @SPMDFullToShardShape(%22) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %24 = mhlo.copy %arg12 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x3072xbf16>
    %25 = stablehlo.custom_call @SPMDFullToShardShape(%24) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<3072x1536xbf16>
    %26 = mhlo.copy %arg13 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %27 = stablehlo.custom_call @SPMDFullToShardShape(%26) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %28 = mhlo.copy %arg14 {mhlo.sharding = "{replicated}"} : tensor<i1>
    %29 = stablehlo.custom_call @SPMDFullToShardShape(%28) {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<i1>
    %30 = mhlo.copy %arg15 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<3072x3072xbf16>
    %31 = stablehlo.custom_call @SPMDFullToShardShape(%30) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<1536x3072xbf16>
    %32 = mhlo.copy %arg16 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %33 = stablehlo.custom_call @SPMDFullToShardShape(%32) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %34 = mhlo.copy %arg17 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %35 = stablehlo.custom_call @SPMDFullToShardShape(%34) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %36 = mhlo.copy %arg18 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %37 = stablehlo.custom_call @SPMDFullToShardShape(%36) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %cst = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"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tensor<128xi64>
    %c_0 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xi64>
    %cst_1 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0xFF800000> : tensor<f32>
    %c_2 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<128> : tensor<i64>
    %cst_3 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<2.000000e+00> : tensor<f32>
    %cst_4 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<3.25520843E-4> : tensor<f32>
    %cst_5 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<9.99999974E-6> : tensor<f32>
    %cst_6 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<8.837890e-02> : tensor<bf16>
    %c_7 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1>
    %c_8 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<1> : tensor<i64>
    %cst_9 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<bf16>
    %cst_10 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<-3.389530e+38> : tensor<bf16>
    %c_11 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0> : tensor<i64>
    %cst_12 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>
    %c_13 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<31> : tensor<i64>
    %c_14 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<32> : tensor<i64>
    %38 = stablehlo.broadcast_in_dim %c_14, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %39 = stablehlo.broadcast_in_dim %c_13, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %40 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %41 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %42 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %43 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %44 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %45 = stablehlo.broadcast_in_dim %c_8, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32x128xi64>
    %46 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x128xbf16>
    %47 = stablehlo.broadcast_in_dim %cst_6, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x12x32x128xbf16>
    %48 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %49 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %50 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %51 = stablehlo.broadcast_in_dim %c_2, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %52 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %53 = stablehlo.reshape %1 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<1x1x32xi64>
    %54 = stablehlo.reshape %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %55 = stablehlo.compare  LT, %54, %52 {mhlo.sharding = "{manual}"} : (tensor<32xi64>, tensor<32xi64>) -> tensor<32xi1>
    %56 = stablehlo.add %54, %51 {mhlo.sharding = "{manual}"} : tensor<32xi64>
    %57 = stablehlo.select %55, %56, %54 {mhlo.sharding = "{manual}"} : tensor<32xi1>, tensor<32xi64>
    %58 = stablehlo.reshape %57 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x1xi64>
    %59 = stablehlo.reshape %11 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %60 = stablehlo.reshape %59 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %62 = stablehlo.reshape %9 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %63 = stablehlo.reshape %62 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %64 = stablehlo.reshape %7 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %65 = stablehlo.reshape %64 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %66 = stablehlo.convert %65 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xui32>
    %67 = "stablehlo.gather"(%63, %66) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>, tensor<32xui32>) -> tensor<32x3072xbf16>
    %68 = stablehlo.reshape %67 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %69 = stablehlo.convert %68 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %70 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %71 = stablehlo.power %69, %70 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %72 = stablehlo.reduce(%71 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %73 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %74 = stablehlo.multiply %72, %73 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %75 = stablehlo.reshape %74 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %76 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %77 = stablehlo.add %75, %76 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %78 = stablehlo.rsqrt %77 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %79 = stablehlo.reshape %78 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %80 = stablehlo.broadcast_in_dim %79, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %81 = stablehlo.multiply %69, %80 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %82 = stablehlo.convert %81 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %83 = stablehlo.multiply %61, %82 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %84 = stablehlo.reshape %83 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %85 = stablehlo.reshape %5 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %86 = stablehlo.reshape %85 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %87 = stablehlo.transpose %86, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %88 = stablehlo.dot_general %84, %87, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %89 = stablehlo.reshape %88 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %90 = stablehlo.transpose %89, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %91 = stablehlo.reshape %3 {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %92 = stablehlo.reshape %91 {mhlo.sharding = "{manual}"} : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %93 = stablehlo.convert %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x32xf32>
    %94 = stablehlo.dot_general %92, %93, batching_dims = [0] x [0], contracting_dims = [2] x [1] {mhlo.sharding = "{manual}"} : (tensor<1x64x1xf32>, tensor<1x1x32xf32>) -> tensor<1x64x32xf32>
    %95 = stablehlo.transpose %94, dims = [0, 2, 1] {mhlo.sharding = "{manual}", result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,32,64]{1,2,0}"} : (tensor<1x64x32xf32>) -> tensor<1x32x64xf32>
    %96 = stablehlo.concatenate %95, %95, dim = 2 {mhlo.sharding = "{manual}"} : (tensor<1x32x64xf32>, tensor<1x32x64xf32>) -> tensor<1x32x128xf32>
    %97 = stablehlo.cosine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %98 = stablehlo.convert %97 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %100 = stablehlo.multiply %90, %99 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %101 = stablehlo.slice %90 [0:1, 0:4, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %102 = stablehlo.negate %101 {mhlo.sharding = "{manual}"} : tensor<1x4x32x64xbf16>
    %103 = stablehlo.slice %90 [0:1, 0:4, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %104 = stablehlo.concatenate %102, %103, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x4x32x64xbf16>, tensor<1x4x32x64xbf16>) -> tensor<1x4x32x128xbf16>
    %105 = stablehlo.sine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %106 = stablehlo.convert %105 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %107 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %108 = stablehlo.multiply %104, %107 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %109 = stablehlo.add %100, %108 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %110 = "stablehlo.scatter"(%13, %58, %109) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %111 = stablehlo.reshape %15 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %112 = stablehlo.reshape %111 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %113 = stablehlo.transpose %112, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %114 = stablehlo.dot_general %84, %113, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %115 = stablehlo.reshape %114 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %116 = stablehlo.transpose %115, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %117 = "stablehlo.scatter"(%17, %58, %116) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %118 = stablehlo.reshape %37 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %119 = stablehlo.reshape %118 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %120 = stablehlo.broadcast_in_dim %119, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %121 = stablehlo.reshape %31 {mhlo.sharding = "{manual}"} : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16>
    %122 = stablehlo.reshape %121 {mhlo.sharding = "{manual}"} : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %123 = stablehlo.transpose %122, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
    %124 = stablehlo.dot_general %84, %123, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<32x1536xbf16>
    %125 = stablehlo.reshape %124 {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>) -> tensor<1x32x12x128xbf16>
    %126 = stablehlo.transpose %125, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,32,128]{3,1,2,0}"} : (tensor<1x32x12x128xbf16>) -> tensor<1x12x32x128xbf16>
    %127 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %128 = stablehlo.multiply %126, %127 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %129 = stablehlo.slice %126 [0:1, 0:12, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %130 = stablehlo.negate %129 {mhlo.sharding = "{manual}"} : tensor<1x12x32x64xbf16>
    %131 = stablehlo.slice %126 [0:1, 0:12, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %132 = stablehlo.concatenate %130, %131, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x64xbf16>, tensor<1x12x32x64xbf16>) -> tensor<1x12x32x128xbf16>
    %133 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %134 = stablehlo.multiply %132, %133 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %135 = stablehlo.add %128, %134 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %136 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %137 = stablehlo.reshape %136 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %138 = stablehlo.transpose %137, dims = [0, 1, 3, 2] {mhlo.sharding = "{manual}", result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %139 = stablehlo.dot_general %135, %138, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %140 = stablehlo.multiply %139, %47 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %141 = stablehlo.broadcast_in_dim %29, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<128xi1>
    %142 = stablehlo.and %141, %c_7 {mhlo.sharding = "{manual}"} : tensor<128xi1>
    %143 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x1x128xi1>
    %144 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x128xi1>
    %145 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %146 = stablehlo.not %143 {mhlo.sharding = "{manual}"} : tensor<1x1x1x128xi1>
    %147 = stablehlo.reshape %146 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x128xi1>) -> tensor<1x1x128xi1>
    %148 = stablehlo.broadcast_in_dim %147, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %149 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %150 = stablehlo.broadcast_in_dim %c_0, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %151 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %152 = stablehlo.subtract %151, %150 {mhlo.sharding = "{manual}"} : tensor<32x128xi64>
    %153 = stablehlo.compare  GE, %152, %45 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %154 = stablehlo.select %153, %44, %43 {mhlo.sharding = "{manual}"} : tensor<32x128xi1>, tensor<32x128xbf16>
    %155 = stablehlo.broadcast_in_dim %54, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %156 = stablehlo.compare  GT, %149, %155 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %157 = stablehlo.convert %156 {mhlo.sharding = "{manual}"} : (tensor<32x128xi1>) -> tensor<32x128xbf16>
    %158 = stablehlo.multiply %154, %157 {mhlo.sharding = "{manual}"} : tensor<32x128xbf16>
    %159 = stablehlo.reshape %158 {mhlo.sharding = "{manual}"} : (tensor<32x128xbf16>) -> tensor<1x1x32x128xbf16>
    %160 = stablehlo.slice %159 [0:1, 0:1, 0:32, 0:32] {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x1x32x32xbf16>
    %161 = stablehlo.reshape %27 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %162 = stablehlo.reshape %161 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64>
    %163 = stablehlo.convert %162 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16>
    %164 = stablehlo.reshape %163 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32xbf16>
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x32xbf16>) -> tensor<1x1x32x32xbf16>
    %166 = stablehlo.add %160, %165 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xbf16>
    %167 = stablehlo.compare  EQ, %166, %42 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xi1>
    %168 = stablehlo.select %167, %41, %160 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xi1>, tensor<1x1x32x32xbf16>
    %169 = stablehlo.floor %cst_12 {mhlo.sharding = "{manual}"} : tensor<128xf32>
    %170 = stablehlo.convert %169 {mhlo.sharding = "{manual}"} : (tensor<128xf32>) -> tensor<128xi64>
    %171 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %172 = stablehlo.clamp %171, %170, %39 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %173 = stablehlo.compare  LT, %172, %40 {mhlo.sharding = "{manual}"} : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1>
    %174 = stablehlo.add %172, %38 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %175 = stablehlo.select %173, %174, %172 {mhlo.sharding = "{manual}"} : tensor<128xi1>, tensor<128xi64>
    %176 = stablehlo.reshape %175 {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<128x1xi64>
    %177 = "stablehlo.gather"(%168, %176) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 32, 1>}> {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x32x128xbf16>
    %178 = stablehlo.select %148, %46, %177 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %179 = stablehlo.select %145, %178, %159 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %180 = stablehlo.reshape %179 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x32x128xbf16>
    %181 = stablehlo.broadcast_in_dim %180, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %182 = stablehlo.add %140, %181 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %183 = stablehlo.convert %182 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xf32>
    %184 = stablehlo.reduce(%183 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %185 = stablehlo.broadcast_in_dim %184, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %186 = stablehlo.subtract %183, %185 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %187 = stablehlo.exponential %186 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %188 = stablehlo.reduce(%187 init: %cst) applies stablehlo.add across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %189 = stablehlo.broadcast_in_dim %188, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %190 = stablehlo.divide %187, %189 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %191 = stablehlo.convert %190 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>) -> tensor<1x12x32x128xbf16>
    %192 = stablehlo.broadcast_in_dim %117, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %193 = stablehlo.reshape %192 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %194 = stablehlo.dot_general %191, %193, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %195 = stablehlo.transpose %194, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,32,24,128]{3,1,2,0}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x32x12x128xbf16>
    %196 = stablehlo.reshape %195 {mhlo.sharding = "{manual}"} : (tensor<1x32x12x128xbf16>) -> tensor<32x1536xbf16>
    %197 = stablehlo.reshape %25 {mhlo.sharding = "{manual}"} : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16>
    %198 = stablehlo.reshape %197 {mhlo.sharding = "{manual}"} : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %199 = stablehlo.transpose %198, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
    %200 = stablehlo.dot_general %196, %199, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<32x3072xbf16>
    %201 = "stablehlo.all_reduce"(%200) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %202 = stablehlo.reshape %201 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %203 = stablehlo.add %68, %202 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %204 = stablehlo.reshape %33 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %205 = stablehlo.reshape %204 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %206 = stablehlo.broadcast_in_dim %205, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %207 = stablehlo.convert %203 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %208 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %209 = stablehlo.power %207, %208 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %210 = stablehlo.reduce(%209 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %211 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %212 = stablehlo.multiply %210, %211 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %213 = stablehlo.reshape %212 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %214 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %215 = stablehlo.add %213, %214 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %216 = stablehlo.rsqrt %215 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %217 = stablehlo.reshape %216 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %218 = stablehlo.broadcast_in_dim %217, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %219 = stablehlo.multiply %207, %218 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %220 = stablehlo.convert %219 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %221 = stablehlo.multiply %206, %220 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %222 = stablehlo.reshape %221 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %223 = stablehlo.reshape %35 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %224 = stablehlo.reshape %223 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %225 = stablehlo.transpose %224, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %226 = stablehlo.dot_general %222, %225, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %227 = stablehlo.reshape %226 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %228 = stablehlo.logistic %227 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %229 = stablehlo.multiply %227, %228 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %230 = stablehlo.reshape %23 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %231 = stablehlo.reshape %230 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %232 = stablehlo.transpose %231, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %233 = stablehlo.dot_general %222, %232, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %234 = stablehlo.reshape %233 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %235 = stablehlo.multiply %229, %234 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %236 = stablehlo.reshape %235 {mhlo.sharding = "{manual}"} : (tensor<1x32x4096xbf16>) -> tensor<32x4096xbf16>
    %237 = stablehlo.reshape %21 {mhlo.sharding = "{manual}"} : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16>
    %238 = stablehlo.reshape %237 {mhlo.sharding = "{manual}"} : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %239 = stablehlo.transpose %238, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
    %240 = stablehlo.dot_general %236, %239, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<32x3072xbf16>
    %241 = "stablehlo.all_reduce"(%240) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %242 = stablehlo.reshape %241 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %243 = stablehlo.add %203, %242 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %244 = stablehlo.convert %243 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %245 = stablehlo.power %244, %50 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %246 = stablehlo.reduce(%245 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %247 = stablehlo.multiply %246, %49 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %248 = stablehlo.reshape %247 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %249 = stablehlo.add %248, %48 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %250 = stablehlo.rsqrt %249 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %251 = stablehlo.reshape %250 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %252 = stablehlo.broadcast_in_dim %251, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %253 = stablehlo.multiply %244, %252 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %254 = stablehlo.convert %253 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %255 = stablehlo.multiply %120, %254 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %256 = stablehlo.reshape %255 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %257 = stablehlo.reshape %19 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %258 = stablehlo.reshape %257 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %259 = stablehlo.transpose %258, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %260 = stablehlo.dot_general %256, %259, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<32x128256xbf16>
    %261 = stablehlo.reshape %260 {mhlo.sharding = "{manual}"} : (tensor<32x128256xbf16>) -> tensor<1x32x128256xbf16>
    %262 = mhlo.copy %110 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %263 = stablehlo.custom_call @SPMDShardToFullShape(%262) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %264 = mhlo.copy %117 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %265 = stablehlo.custom_call @SPMDShardToFullShape(%264) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %266 = mhlo.copy %260 {mhlo.sharding = "{manual}"} : tensor<32x128256xbf16>
    %267 = stablehlo.custom_call @SPMDShardToFullShape(%266) {mhlo.sharding = "{replicated}"} : (tensor<32x128256xbf16>) -> tensor<32x128256xbf16>
    %268 = mhlo.copy %261 {mhlo.sharding = "{manual}"} : tensor<1x32x128256xbf16>
    %269 = stablehlo.custom_call @SPMDShardToFullShape(%268) {mhlo.sharding = "{replicated}"} : (tensor<1x32x128256xbf16>) -> tensor<1x32x128256xbf16>
    return %263, %265, %267, %269 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>
  }
}


2026-01-02 18:37:47.378 (  18.436s) [        CBC3A000] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-02 18:37:47.378 (  18.436s) [        CBC3A000] executable_instance.cc:179      1| Literal MLIR code (size=40801):

module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, mhlo.spmd_output_sharding="{{devices=[1,2,1,1]<=[2]},{devices=[1,2,1,1]<=[2]},{replicated},{replicated}}"
} {
  func.func @main(%arg0: tensor<32xi64>, %arg1: tensor<64xf32>, %arg2: tensor<1024x3072xbf16>, %arg3: tensor<1x32xi64>, %arg4: tensor<128256x3072xbf16>, %arg5: tensor<3072xbf16>, %arg6: tensor<1x8x128x128xbf16>, %arg7: tensor<1024x3072xbf16>, %arg8: tensor<1x8x128x128xbf16>, %arg9: tensor<128256x3072xbf16>, %arg10: tensor<3072x8192xbf16>, %arg11: tensor<8192x3072xbf16>, %arg12: tensor<3072x3072xbf16>, %arg13: tensor<1x32xi64>, %arg14: tensor<i1>, %arg15: tensor<3072x3072xbf16>, %arg16: tensor<3072xbf16>, %arg17: tensor<8192x3072xbf16>, %arg18: tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>) {
    %0 = mhlo.copy %arg0 {mhlo.sharding = "{replicated}"} : tensor<32xi64>
    %1 = stablehlo.custom_call @SPMDFullToShardShape(%0) {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xi64>
    %2 = mhlo.copy %arg1 {mhlo.sharding = "{replicated}"} : tensor<64xf32>
    %3 = stablehlo.custom_call @SPMDFullToShardShape(%2) {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<64xf32>
    %4 = mhlo.copy %arg2 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %5 = stablehlo.custom_call @SPMDFullToShardShape(%4) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %6 = mhlo.copy %arg3 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %7 = stablehlo.custom_call @SPMDFullToShardShape(%6) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %8 = mhlo.copy %arg4 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %9 = stablehlo.custom_call @SPMDFullToShardShape(%8) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %10 = mhlo.copy %arg5 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %11 = stablehlo.custom_call @SPMDFullToShardShape(%10) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %12 = mhlo.copy %arg6 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %13 = stablehlo.custom_call @SPMDFullToShardShape(%12) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %14 = mhlo.copy %arg7 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %15 = stablehlo.custom_call @SPMDFullToShardShape(%14) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %16 = mhlo.copy %arg8 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %17 = stablehlo.custom_call @SPMDFullToShardShape(%16) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %18 = mhlo.copy %arg9 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %19 = stablehlo.custom_call @SPMDFullToShardShape(%18) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %20 = mhlo.copy %arg10 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x8192xbf16>
    %21 = stablehlo.custom_call @SPMDFullToShardShape(%20) {mhlo.sharding = "{manual}"} : (tensor<3072x8192xbf16>) -> tensor<3072x4096xbf16>
    %22 = mhlo.copy %arg11 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %23 = stablehlo.custom_call @SPMDFullToShardShape(%22) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %24 = mhlo.copy %arg12 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x3072xbf16>
    %25 = stablehlo.custom_call @SPMDFullToShardShape(%24) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<3072x1536xbf16>
    %26 = mhlo.copy %arg13 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %27 = stablehlo.custom_call @SPMDFullToShardShape(%26) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %28 = mhlo.copy %arg14 {mhlo.sharding = "{replicated}"} : tensor<i1>
    %29 = stablehlo.custom_call @SPMDFullToShardShape(%28) {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<i1>
    %30 = mhlo.copy %arg15 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<3072x3072xbf16>
    %31 = stablehlo.custom_call @SPMDFullToShardShape(%30) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<1536x3072xbf16>
    %32 = mhlo.copy %arg16 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %33 = stablehlo.custom_call @SPMDFullToShardShape(%32) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %34 = mhlo.copy %arg17 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %35 = stablehlo.custom_call @SPMDFullToShardShape(%34) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %36 = mhlo.copy %arg18 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %37 = stablehlo.custom_call @SPMDFullToShardShape(%36) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %cst = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"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tensor<128xi64>
    %c_0 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xi64>
    %cst_1 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0xFF800000> : tensor<f32>
    %c_2 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<128> : tensor<i64>
    %cst_3 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<2.000000e+00> : tensor<f32>
    %cst_4 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<3.25520843E-4> : tensor<f32>
    %cst_5 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<9.99999974E-6> : tensor<f32>
    %cst_6 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<8.837890e-02> : tensor<bf16>
    %c_7 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1>
    %c_8 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<1> : tensor<i64>
    %cst_9 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<bf16>
    %cst_10 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<-3.389530e+38> : tensor<bf16>
    %c_11 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0> : tensor<i64>
    %cst_12 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>
    %c_13 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<31> : tensor<i64>
    %c_14 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<32> : tensor<i64>
    %38 = stablehlo.broadcast_in_dim %c_14, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %39 = stablehlo.broadcast_in_dim %c_13, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %40 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %41 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %42 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %43 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %44 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %45 = stablehlo.broadcast_in_dim %c_8, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32x128xi64>
    %46 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x128xbf16>
    %47 = stablehlo.broadcast_in_dim %cst_6, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x12x32x128xbf16>
    %48 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %49 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %50 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %51 = stablehlo.broadcast_in_dim %c_2, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %52 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %53 = stablehlo.reshape %1 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<1x1x32xi64>
    %54 = stablehlo.reshape %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %55 = stablehlo.compare  LT, %54, %52 {mhlo.sharding = "{manual}"} : (tensor<32xi64>, tensor<32xi64>) -> tensor<32xi1>
    %56 = stablehlo.add %54, %51 {mhlo.sharding = "{manual}"} : tensor<32xi64>
    %57 = stablehlo.select %55, %56, %54 {mhlo.sharding = "{manual}"} : tensor<32xi1>, tensor<32xi64>
    %58 = stablehlo.reshape %57 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x1xi64>
    %59 = stablehlo.reshape %11 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %60 = stablehlo.reshape %59 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %62 = stablehlo.reshape %9 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %63 = stablehlo.reshape %62 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %64 = stablehlo.reshape %7 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %65 = stablehlo.reshape %64 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %66 = stablehlo.convert %65 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xui32>
    %67 = "stablehlo.gather"(%63, %66) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>, tensor<32xui32>) -> tensor<32x3072xbf16>
    %68 = stablehlo.reshape %67 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %69 = stablehlo.convert %68 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %70 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %71 = stablehlo.power %69, %70 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %72 = stablehlo.reduce(%71 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %73 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %74 = stablehlo.multiply %72, %73 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %75 = stablehlo.reshape %74 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %76 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %77 = stablehlo.add %75, %76 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %78 = stablehlo.rsqrt %77 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %79 = stablehlo.reshape %78 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %80 = stablehlo.broadcast_in_dim %79, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %81 = stablehlo.multiply %69, %80 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %82 = stablehlo.convert %81 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %83 = stablehlo.multiply %61, %82 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %84 = stablehlo.reshape %83 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %85 = stablehlo.reshape %5 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %86 = stablehlo.reshape %85 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %87 = stablehlo.transpose %86, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %88 = stablehlo.dot_general %84, %87, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %89 = stablehlo.reshape %88 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %90 = stablehlo.transpose %89, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %91 = stablehlo.reshape %3 {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %92 = stablehlo.reshape %91 {mhlo.sharding = "{manual}"} : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %93 = stablehlo.convert %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x32xf32>
    %94 = stablehlo.dot_general %92, %93, batching_dims = [0] x [0], contracting_dims = [2] x [1] {mhlo.sharding = "{manual}"} : (tensor<1x64x1xf32>, tensor<1x1x32xf32>) -> tensor<1x64x32xf32>
    %95 = stablehlo.transpose %94, dims = [0, 2, 1] {mhlo.sharding = "{manual}", result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,32,64]{1,2,0}"} : (tensor<1x64x32xf32>) -> tensor<1x32x64xf32>
    %96 = stablehlo.concatenate %95, %95, dim = 2 {mhlo.sharding = "{manual}"} : (tensor<1x32x64xf32>, tensor<1x32x64xf32>) -> tensor<1x32x128xf32>
    %97 = stablehlo.cosine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %98 = stablehlo.convert %97 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %100 = stablehlo.multiply %90, %99 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %101 = stablehlo.slice %90 [0:1, 0:4, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %102 = stablehlo.negate %101 {mhlo.sharding = "{manual}"} : tensor<1x4x32x64xbf16>
    %103 = stablehlo.slice %90 [0:1, 0:4, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %104 = stablehlo.concatenate %102, %103, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x4x32x64xbf16>, tensor<1x4x32x64xbf16>) -> tensor<1x4x32x128xbf16>
    %105 = stablehlo.sine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %106 = stablehlo.convert %105 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %107 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %108 = stablehlo.multiply %104, %107 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %109 = stablehlo.add %100, %108 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %110 = "stablehlo.scatter"(%13, %58, %109) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %111 = stablehlo.reshape %15 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %112 = stablehlo.reshape %111 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %113 = stablehlo.transpose %112, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %114 = stablehlo.dot_general %84, %113, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %115 = stablehlo.reshape %114 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %116 = stablehlo.transpose %115, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %117 = "stablehlo.scatter"(%17, %58, %116) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %118 = stablehlo.reshape %37 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %119 = stablehlo.reshape %118 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %120 = stablehlo.broadcast_in_dim %119, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %121 = stablehlo.reshape %31 {mhlo.sharding = "{manual}"} : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16>
    %122 = stablehlo.reshape %121 {mhlo.sharding = "{manual}"} : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %123 = stablehlo.transpose %122, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
    %124 = stablehlo.dot_general %84, %123, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<32x1536xbf16>
    %125 = stablehlo.reshape %124 {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>) -> tensor<1x32x12x128xbf16>
    %126 = stablehlo.transpose %125, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,32,128]{3,1,2,0}"} : (tensor<1x32x12x128xbf16>) -> tensor<1x12x32x128xbf16>
    %127 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %128 = stablehlo.multiply %126, %127 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %129 = stablehlo.slice %126 [0:1, 0:12, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %130 = stablehlo.negate %129 {mhlo.sharding = "{manual}"} : tensor<1x12x32x64xbf16>
    %131 = stablehlo.slice %126 [0:1, 0:12, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %132 = stablehlo.concatenate %130, %131, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x64xbf16>, tensor<1x12x32x64xbf16>) -> tensor<1x12x32x128xbf16>
    %133 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %134 = stablehlo.multiply %132, %133 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %135 = stablehlo.add %128, %134 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %136 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %137 = stablehlo.reshape %136 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %138 = stablehlo.transpose %137, dims = [0, 1, 3, 2] {mhlo.sharding = "{manual}", result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %139 = stablehlo.dot_general %135, %138, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %140 = stablehlo.multiply %139, %47 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %141 = stablehlo.broadcast_in_dim %29, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<128xi1>
    %142 = stablehlo.and %141, %c_7 {mhlo.sharding = "{manual}"} : tensor<128xi1>
    %143 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x1x128xi1>
    %144 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x128xi1>
    %145 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %146 = stablehlo.not %143 {mhlo.sharding = "{manual}"} : tensor<1x1x1x128xi1>
    %147 = stablehlo.reshape %146 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x128xi1>) -> tensor<1x1x128xi1>
    %148 = stablehlo.broadcast_in_dim %147, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %149 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %150 = stablehlo.broadcast_in_dim %c_0, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %151 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %152 = stablehlo.subtract %151, %150 {mhlo.sharding = "{manual}"} : tensor<32x128xi64>
    %153 = stablehlo.compare  GE, %152, %45 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %154 = stablehlo.select %153, %44, %43 {mhlo.sharding = "{manual}"} : tensor<32x128xi1>, tensor<32x128xbf16>
    %155 = stablehlo.broadcast_in_dim %54, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %156 = stablehlo.compare  GT, %149, %155 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %157 = stablehlo.convert %156 {mhlo.sharding = "{manual}"} : (tensor<32x128xi1>) -> tensor<32x128xbf16>
    %158 = stablehlo.multiply %154, %157 {mhlo.sharding = "{manual}"} : tensor<32x128xbf16>
    %159 = stablehlo.reshape %158 {mhlo.sharding = "{manual}"} : (tensor<32x128xbf16>) -> tensor<1x1x32x128xbf16>
    %160 = stablehlo.slice %159 [0:1, 0:1, 0:32, 0:32] {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x1x32x32xbf16>
    %161 = stablehlo.reshape %27 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %162 = stablehlo.reshape %161 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64>
    %163 = stablehlo.convert %162 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16>
    %164 = stablehlo.reshape %163 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32xbf16>
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x32xbf16>) -> tensor<1x1x32x32xbf16>
    %166 = stablehlo.add %160, %165 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xbf16>
    %167 = stablehlo.compare  EQ, %166, %42 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xi1>
    %168 = stablehlo.select %167, %41, %160 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xi1>, tensor<1x1x32x32xbf16>
    %169 = stablehlo.floor %cst_12 {mhlo.sharding = "{manual}"} : tensor<128xf32>
    %170 = stablehlo.convert %169 {mhlo.sharding = "{manual}"} : (tensor<128xf32>) -> tensor<128xi64>
    %171 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %172 = stablehlo.clamp %171, %170, %39 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %173 = stablehlo.compare  LT, %172, %40 {mhlo.sharding = "{manual}"} : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1>
    %174 = stablehlo.add %172, %38 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %175 = stablehlo.select %173, %174, %172 {mhlo.sharding = "{manual}"} : tensor<128xi1>, tensor<128xi64>
    %176 = stablehlo.reshape %175 {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<128x1xi64>
    %177 = "stablehlo.gather"(%168, %176) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 32, 1>}> {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x32x128xbf16>
    %178 = stablehlo.select %148, %46, %177 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %179 = stablehlo.select %145, %178, %159 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %180 = stablehlo.reshape %179 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x32x128xbf16>
    %181 = stablehlo.broadcast_in_dim %180, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %182 = stablehlo.add %140, %181 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %183 = stablehlo.convert %182 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xf32>
    %184 = stablehlo.reduce(%183 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %185 = stablehlo.broadcast_in_dim %184, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %186 = stablehlo.subtract %183, %185 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %187 = stablehlo.exponential %186 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %188 = stablehlo.reduce(%187 init: %cst) applies stablehlo.add across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %189 = stablehlo.broadcast_in_dim %188, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %190 = stablehlo.divide %187, %189 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %191 = stablehlo.convert %190 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>) -> tensor<1x12x32x128xbf16>
    %192 = stablehlo.broadcast_in_dim %117, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %193 = stablehlo.reshape %192 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %194 = stablehlo.dot_general %191, %193, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %195 = stablehlo.transpose %194, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,32,24,128]{3,1,2,0}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x32x12x128xbf16>
    %196 = stablehlo.reshape %195 {mhlo.sharding = "{manual}"} : (tensor<1x32x12x128xbf16>) -> tensor<32x1536xbf16>
    %197 = stablehlo.reshape %25 {mhlo.sharding = "{manual}"} : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16>
    %198 = stablehlo.reshape %197 {mhlo.sharding = "{manual}"} : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %199 = stablehlo.transpose %198, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
    %200 = stablehlo.dot_general %196, %199, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<32x3072xbf16>
    %201 = "stablehlo.all_reduce"(%200) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %202 = stablehlo.reshape %201 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %203 = stablehlo.add %68, %202 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %204 = stablehlo.reshape %33 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %205 = stablehlo.reshape %204 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %206 = stablehlo.broadcast_in_dim %205, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %207 = stablehlo.convert %203 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %208 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %209 = stablehlo.power %207, %208 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %210 = stablehlo.reduce(%209 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %211 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %212 = stablehlo.multiply %210, %211 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %213 = stablehlo.reshape %212 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %214 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %215 = stablehlo.add %213, %214 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %216 = stablehlo.rsqrt %215 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %217 = stablehlo.reshape %216 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %218 = stablehlo.broadcast_in_dim %217, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %219 = stablehlo.multiply %207, %218 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %220 = stablehlo.convert %219 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %221 = stablehlo.multiply %206, %220 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %222 = stablehlo.reshape %221 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %223 = stablehlo.reshape %35 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %224 = stablehlo.reshape %223 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %225 = stablehlo.transpose %224, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %226 = stablehlo.dot_general %222, %225, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %227 = stablehlo.reshape %226 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %228 = stablehlo.logistic %227 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %229 = stablehlo.multiply %227, %228 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %230 = stablehlo.reshape %23 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %231 = stablehlo.reshape %230 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %232 = stablehlo.transpose %231, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %233 = stablehlo.dot_general %222, %232, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %234 = stablehlo.reshape %233 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %235 = stablehlo.multiply %229, %234 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %236 = stablehlo.reshape %235 {mhlo.sharding = "{manual}"} : (tensor<1x32x4096xbf16>) -> tensor<32x4096xbf16>
    %237 = stablehlo.reshape %21 {mhlo.sharding = "{manual}"} : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16>
    %238 = stablehlo.reshape %237 {mhlo.sharding = "{manual}"} : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %239 = stablehlo.transpose %238, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
    %240 = stablehlo.dot_general %236, %239, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<32x3072xbf16>
    %241 = "stablehlo.all_reduce"(%240) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %242 = stablehlo.reshape %241 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %243 = stablehlo.add %203, %242 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %244 = stablehlo.convert %243 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %245 = stablehlo.power %244, %50 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %246 = stablehlo.reduce(%245 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %247 = stablehlo.multiply %246, %49 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %248 = stablehlo.reshape %247 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %249 = stablehlo.add %248, %48 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %250 = stablehlo.rsqrt %249 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %251 = stablehlo.reshape %250 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %252 = stablehlo.broadcast_in_dim %251, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %253 = stablehlo.multiply %244, %252 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %254 = stablehlo.convert %253 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %255 = stablehlo.multiply %120, %254 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %256 = stablehlo.reshape %255 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %257 = stablehlo.reshape %19 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %258 = stablehlo.reshape %257 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %259 = stablehlo.transpose %258, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %260 = stablehlo.dot_general %256, %259, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<32x128256xbf16>
    %261 = stablehlo.reshape %260 {mhlo.sharding = "{manual}"} : (tensor<32x128256xbf16>) -> tensor<1x32x128256xbf16>
    %262 = mhlo.copy %110 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %263 = stablehlo.custom_call @SPMDShardToFullShape(%262) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %264 = mhlo.copy %117 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %265 = stablehlo.custom_call @SPMDShardToFullShape(%264) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %266 = mhlo.copy %260 {mhlo.sharding = "{manual}"} : tensor<32x128256xbf16>
    %267 = stablehlo.custom_call @SPMDShardToFullShape(%266) {mhlo.sharding = "{replicated}"} : (tensor<32x128256xbf16>) -> tensor<32x128256xbf16>
    %268 = mhlo.copy %261 {mhlo.sharding = "{manual}"} : tensor<1x32x128256xbf16>
    %269 = stablehlo.custom_call @SPMDShardToFullShape(%268) {mhlo.sharding = "{replicated}"} : (tensor<1x32x128256xbf16>) -> tensor<1x32x128256xbf16>
    return %263, %265, %267, %269 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>
  }
}


2026-01-02 18:37:47.395 (  18.454s) [        CBC3A000] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-02 18:37:47.395 (  18.454s) [        CBC3A000] executable_instance.cc:179      1| Literal MLIR code (size=40801):

module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, mhlo.spmd_output_sharding="{{devices=[1,2,1,1]<=[2]},{devices=[1,2,1,1]<=[2]},{replicated},{replicated}}"
} {
  func.func @main(%arg0: tensor<32xi64>, %arg1: tensor<64xf32>, %arg2: tensor<1024x3072xbf16>, %arg3: tensor<1x32xi64>, %arg4: tensor<128256x3072xbf16>, %arg5: tensor<3072xbf16>, %arg6: tensor<1x8x128x128xbf16>, %arg7: tensor<1024x3072xbf16>, %arg8: tensor<1x8x128x128xbf16>, %arg9: tensor<128256x3072xbf16>, %arg10: tensor<3072x8192xbf16>, %arg11: tensor<8192x3072xbf16>, %arg12: tensor<3072x3072xbf16>, %arg13: tensor<1x32xi64>, %arg14: tensor<i1>, %arg15: tensor<3072x3072xbf16>, %arg16: tensor<3072xbf16>, %arg17: tensor<8192x3072xbf16>, %arg18: tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>) {
    %0 = mhlo.copy %arg0 {mhlo.sharding = "{replicated}"} : tensor<32xi64>
    %1 = stablehlo.custom_call @SPMDFullToShardShape(%0) {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xi64>
    %2 = mhlo.copy %arg1 {mhlo.sharding = "{replicated}"} : tensor<64xf32>
    %3 = stablehlo.custom_call @SPMDFullToShardShape(%2) {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<64xf32>
    %4 = mhlo.copy %arg2 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %5 = stablehlo.custom_call @SPMDFullToShardShape(%4) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %6 = mhlo.copy %arg3 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %7 = stablehlo.custom_call @SPMDFullToShardShape(%6) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %8 = mhlo.copy %arg4 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %9 = stablehlo.custom_call @SPMDFullToShardShape(%8) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %10 = mhlo.copy %arg5 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %11 = stablehlo.custom_call @SPMDFullToShardShape(%10) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %12 = mhlo.copy %arg6 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %13 = stablehlo.custom_call @SPMDFullToShardShape(%12) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %14 = mhlo.copy %arg7 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %15 = stablehlo.custom_call @SPMDFullToShardShape(%14) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %16 = mhlo.copy %arg8 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %17 = stablehlo.custom_call @SPMDFullToShardShape(%16) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %18 = mhlo.copy %arg9 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %19 = stablehlo.custom_call @SPMDFullToShardShape(%18) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %20 = mhlo.copy %arg10 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x8192xbf16>
    %21 = stablehlo.custom_call @SPMDFullToShardShape(%20) {mhlo.sharding = "{manual}"} : (tensor<3072x8192xbf16>) -> tensor<3072x4096xbf16>
    %22 = mhlo.copy %arg11 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %23 = stablehlo.custom_call @SPMDFullToShardShape(%22) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %24 = mhlo.copy %arg12 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x3072xbf16>
    %25 = stablehlo.custom_call @SPMDFullToShardShape(%24) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<3072x1536xbf16>
    %26 = mhlo.copy %arg13 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %27 = stablehlo.custom_call @SPMDFullToShardShape(%26) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %28 = mhlo.copy %arg14 {mhlo.sharding = "{replicated}"} : tensor<i1>
    %29 = stablehlo.custom_call @SPMDFullToShardShape(%28) {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<i1>
    %30 = mhlo.copy %arg15 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<3072x3072xbf16>
    %31 = stablehlo.custom_call @SPMDFullToShardShape(%30) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<1536x3072xbf16>
    %32 = mhlo.copy %arg16 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %33 = stablehlo.custom_call @SPMDFullToShardShape(%32) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %34 = mhlo.copy %arg17 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %35 = stablehlo.custom_call @SPMDFullToShardShape(%34) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %36 = mhlo.copy %arg18 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %37 = stablehlo.custom_call @SPMDFullToShardShape(%36) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %cst = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"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tensor<128xi64>
    %c_0 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xi64>
    %cst_1 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0xFF800000> : tensor<f32>
    %c_2 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<128> : tensor<i64>
    %cst_3 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<2.000000e+00> : tensor<f32>
    %cst_4 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<3.25520843E-4> : tensor<f32>
    %cst_5 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<9.99999974E-6> : tensor<f32>
    %cst_6 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<8.837890e-02> : tensor<bf16>
    %c_7 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1>
    %c_8 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<1> : tensor<i64>
    %cst_9 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<bf16>
    %cst_10 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<-3.389530e+38> : tensor<bf16>
    %c_11 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0> : tensor<i64>
    %cst_12 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>
    %c_13 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<31> : tensor<i64>
    %c_14 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<32> : tensor<i64>
    %38 = stablehlo.broadcast_in_dim %c_14, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %39 = stablehlo.broadcast_in_dim %c_13, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %40 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %41 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %42 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %43 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %44 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %45 = stablehlo.broadcast_in_dim %c_8, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32x128xi64>
    %46 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x128xbf16>
    %47 = stablehlo.broadcast_in_dim %cst_6, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x12x32x128xbf16>
    %48 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %49 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %50 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %51 = stablehlo.broadcast_in_dim %c_2, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %52 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %53 = stablehlo.reshape %1 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<1x1x32xi64>
    %54 = stablehlo.reshape %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %55 = stablehlo.compare  LT, %54, %52 {mhlo.sharding = "{manual}"} : (tensor<32xi64>, tensor<32xi64>) -> tensor<32xi1>
    %56 = stablehlo.add %54, %51 {mhlo.sharding = "{manual}"} : tensor<32xi64>
    %57 = stablehlo.select %55, %56, %54 {mhlo.sharding = "{manual}"} : tensor<32xi1>, tensor<32xi64>
    %58 = stablehlo.reshape %57 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x1xi64>
    %59 = stablehlo.reshape %11 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %60 = stablehlo.reshape %59 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %62 = stablehlo.reshape %9 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %63 = stablehlo.reshape %62 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %64 = stablehlo.reshape %7 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %65 = stablehlo.reshape %64 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %66 = stablehlo.convert %65 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xui32>
    %67 = "stablehlo.gather"(%63, %66) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>, tensor<32xui32>) -> tensor<32x3072xbf16>
    %68 = stablehlo.reshape %67 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %69 = stablehlo.convert %68 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %70 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %71 = stablehlo.power %69, %70 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %72 = stablehlo.reduce(%71 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %73 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %74 = stablehlo.multiply %72, %73 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %75 = stablehlo.reshape %74 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %76 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %77 = stablehlo.add %75, %76 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %78 = stablehlo.rsqrt %77 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %79 = stablehlo.reshape %78 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %80 = stablehlo.broadcast_in_dim %79, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %81 = stablehlo.multiply %69, %80 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %82 = stablehlo.convert %81 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %83 = stablehlo.multiply %61, %82 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %84 = stablehlo.reshape %83 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %85 = stablehlo.reshape %5 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %86 = stablehlo.reshape %85 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %87 = stablehlo.transpose %86, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %88 = stablehlo.dot_general %84, %87, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %89 = stablehlo.reshape %88 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %90 = stablehlo.transpose %89, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %91 = stablehlo.reshape %3 {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %92 = stablehlo.reshape %91 {mhlo.sharding = "{manual}"} : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %93 = stablehlo.convert %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x32xf32>
    %94 = stablehlo.dot_general %92, %93, batching_dims = [0] x [0], contracting_dims = [2] x [1] {mhlo.sharding = "{manual}"} : (tensor<1x64x1xf32>, tensor<1x1x32xf32>) -> tensor<1x64x32xf32>
    %95 = stablehlo.transpose %94, dims = [0, 2, 1] {mhlo.sharding = "{manual}", result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,32,64]{1,2,0}"} : (tensor<1x64x32xf32>) -> tensor<1x32x64xf32>
    %96 = stablehlo.concatenate %95, %95, dim = 2 {mhlo.sharding = "{manual}"} : (tensor<1x32x64xf32>, tensor<1x32x64xf32>) -> tensor<1x32x128xf32>
    %97 = stablehlo.cosine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %98 = stablehlo.convert %97 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %100 = stablehlo.multiply %90, %99 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %101 = stablehlo.slice %90 [0:1, 0:4, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %102 = stablehlo.negate %101 {mhlo.sharding = "{manual}"} : tensor<1x4x32x64xbf16>
    %103 = stablehlo.slice %90 [0:1, 0:4, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %104 = stablehlo.concatenate %102, %103, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x4x32x64xbf16>, tensor<1x4x32x64xbf16>) -> tensor<1x4x32x128xbf16>
    %105 = stablehlo.sine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %106 = stablehlo.convert %105 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %107 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %108 = stablehlo.multiply %104, %107 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %109 = stablehlo.add %100, %108 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %110 = "stablehlo.scatter"(%13, %58, %109) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %111 = stablehlo.reshape %15 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %112 = stablehlo.reshape %111 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %113 = stablehlo.transpose %112, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %114 = stablehlo.dot_general %84, %113, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %115 = stablehlo.reshape %114 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %116 = stablehlo.transpose %115, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %117 = "stablehlo.scatter"(%17, %58, %116) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %118 = stablehlo.reshape %37 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %119 = stablehlo.reshape %118 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %120 = stablehlo.broadcast_in_dim %119, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %121 = stablehlo.reshape %31 {mhlo.sharding = "{manual}"} : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16>
    %122 = stablehlo.reshape %121 {mhlo.sharding = "{manual}"} : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %123 = stablehlo.transpose %122, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
    %124 = stablehlo.dot_general %84, %123, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<32x1536xbf16>
    %125 = stablehlo.reshape %124 {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>) -> tensor<1x32x12x128xbf16>
    %126 = stablehlo.transpose %125, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,32,128]{3,1,2,0}"} : (tensor<1x32x12x128xbf16>) -> tensor<1x12x32x128xbf16>
    %127 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %128 = stablehlo.multiply %126, %127 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %129 = stablehlo.slice %126 [0:1, 0:12, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %130 = stablehlo.negate %129 {mhlo.sharding = "{manual}"} : tensor<1x12x32x64xbf16>
    %131 = stablehlo.slice %126 [0:1, 0:12, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %132 = stablehlo.concatenate %130, %131, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x64xbf16>, tensor<1x12x32x64xbf16>) -> tensor<1x12x32x128xbf16>
    %133 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %134 = stablehlo.multiply %132, %133 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %135 = stablehlo.add %128, %134 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %136 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %137 = stablehlo.reshape %136 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %138 = stablehlo.transpose %137, dims = [0, 1, 3, 2] {mhlo.sharding = "{manual}", result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %139 = stablehlo.dot_general %135, %138, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %140 = stablehlo.multiply %139, %47 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %141 = stablehlo.broadcast_in_dim %29, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<128xi1>
    %142 = stablehlo.and %141, %c_7 {mhlo.sharding = "{manual}"} : tensor<128xi1>
    %143 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x1x128xi1>
    %144 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x128xi1>
    %145 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %146 = stablehlo.not %143 {mhlo.sharding = "{manual}"} : tensor<1x1x1x128xi1>
    %147 = stablehlo.reshape %146 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x128xi1>) -> tensor<1x1x128xi1>
    %148 = stablehlo.broadcast_in_dim %147, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %149 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %150 = stablehlo.broadcast_in_dim %c_0, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %151 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %152 = stablehlo.subtract %151, %150 {mhlo.sharding = "{manual}"} : tensor<32x128xi64>
    %153 = stablehlo.compare  GE, %152, %45 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %154 = stablehlo.select %153, %44, %43 {mhlo.sharding = "{manual}"} : tensor<32x128xi1>, tensor<32x128xbf16>
    %155 = stablehlo.broadcast_in_dim %54, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %156 = stablehlo.compare  GT, %149, %155 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %157 = stablehlo.convert %156 {mhlo.sharding = "{manual}"} : (tensor<32x128xi1>) -> tensor<32x128xbf16>
    %158 = stablehlo.multiply %154, %157 {mhlo.sharding = "{manual}"} : tensor<32x128xbf16>
    %159 = stablehlo.reshape %158 {mhlo.sharding = "{manual}"} : (tensor<32x128xbf16>) -> tensor<1x1x32x128xbf16>
    %160 = stablehlo.slice %159 [0:1, 0:1, 0:32, 0:32] {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x1x32x32xbf16>
    %161 = stablehlo.reshape %27 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %162 = stablehlo.reshape %161 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64>
    %163 = stablehlo.convert %162 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16>
    %164 = stablehlo.reshape %163 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32xbf16>
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x32xbf16>) -> tensor<1x1x32x32xbf16>
    %166 = stablehlo.add %160, %165 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xbf16>
    %167 = stablehlo.compare  EQ, %166, %42 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xi1>
    %168 = stablehlo.select %167, %41, %160 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xi1>, tensor<1x1x32x32xbf16>
    %169 = stablehlo.floor %cst_12 {mhlo.sharding = "{manual}"} : tensor<128xf32>
    %170 = stablehlo.convert %169 {mhlo.sharding = "{manual}"} : (tensor<128xf32>) -> tensor<128xi64>
    %171 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %172 = stablehlo.clamp %171, %170, %39 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %173 = stablehlo.compare  LT, %172, %40 {mhlo.sharding = "{manual}"} : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1>
    %174 = stablehlo.add %172, %38 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %175 = stablehlo.select %173, %174, %172 {mhlo.sharding = "{manual}"} : tensor<128xi1>, tensor<128xi64>
    %176 = stablehlo.reshape %175 {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<128x1xi64>
    %177 = "stablehlo.gather"(%168, %176) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 32, 1>}> {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x32x128xbf16>
    %178 = stablehlo.select %148, %46, %177 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %179 = stablehlo.select %145, %178, %159 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %180 = stablehlo.reshape %179 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x32x128xbf16>
    %181 = stablehlo.broadcast_in_dim %180, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %182 = stablehlo.add %140, %181 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %183 = stablehlo.convert %182 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xf32>
    %184 = stablehlo.reduce(%183 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %185 = stablehlo.broadcast_in_dim %184, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %186 = stablehlo.subtract %183, %185 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %187 = stablehlo.exponential %186 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %188 = stablehlo.reduce(%187 init: %cst) applies stablehlo.add across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %189 = stablehlo.broadcast_in_dim %188, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %190 = stablehlo.divide %187, %189 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %191 = stablehlo.convert %190 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>) -> tensor<1x12x32x128xbf16>
    %192 = stablehlo.broadcast_in_dim %117, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %193 = stablehlo.reshape %192 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %194 = stablehlo.dot_general %191, %193, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %195 = stablehlo.transpose %194, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,32,24,128]{3,1,2,0}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x32x12x128xbf16>
    %196 = stablehlo.reshape %195 {mhlo.sharding = "{manual}"} : (tensor<1x32x12x128xbf16>) -> tensor<32x1536xbf16>
    %197 = stablehlo.reshape %25 {mhlo.sharding = "{manual}"} : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16>
    %198 = stablehlo.reshape %197 {mhlo.sharding = "{manual}"} : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %199 = stablehlo.transpose %198, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
    %200 = stablehlo.dot_general %196, %199, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<32x3072xbf16>
    %201 = "stablehlo.all_reduce"(%200) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %202 = stablehlo.reshape %201 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %203 = stablehlo.add %68, %202 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %204 = stablehlo.reshape %33 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %205 = stablehlo.reshape %204 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %206 = stablehlo.broadcast_in_dim %205, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %207 = stablehlo.convert %203 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %208 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %209 = stablehlo.power %207, %208 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %210 = stablehlo.reduce(%209 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %211 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %212 = stablehlo.multiply %210, %211 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %213 = stablehlo.reshape %212 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %214 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %215 = stablehlo.add %213, %214 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %216 = stablehlo.rsqrt %215 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %217 = stablehlo.reshape %216 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %218 = stablehlo.broadcast_in_dim %217, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %219 = stablehlo.multiply %207, %218 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %220 = stablehlo.convert %219 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %221 = stablehlo.multiply %206, %220 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %222 = stablehlo.reshape %221 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %223 = stablehlo.reshape %35 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %224 = stablehlo.reshape %223 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %225 = stablehlo.transpose %224, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %226 = stablehlo.dot_general %222, %225, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %227 = stablehlo.reshape %226 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %228 = stablehlo.logistic %227 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %229 = stablehlo.multiply %227, %228 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %230 = stablehlo.reshape %23 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %231 = stablehlo.reshape %230 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %232 = stablehlo.transpose %231, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %233 = stablehlo.dot_general %222, %232, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %234 = stablehlo.reshape %233 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %235 = stablehlo.multiply %229, %234 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %236 = stablehlo.reshape %235 {mhlo.sharding = "{manual}"} : (tensor<1x32x4096xbf16>) -> tensor<32x4096xbf16>
    %237 = stablehlo.reshape %21 {mhlo.sharding = "{manual}"} : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16>
    %238 = stablehlo.reshape %237 {mhlo.sharding = "{manual}"} : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %239 = stablehlo.transpose %238, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
    %240 = stablehlo.dot_general %236, %239, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<32x3072xbf16>
    %241 = "stablehlo.all_reduce"(%240) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %242 = stablehlo.reshape %241 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %243 = stablehlo.add %203, %242 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %244 = stablehlo.convert %243 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %245 = stablehlo.power %244, %50 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %246 = stablehlo.reduce(%245 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %247 = stablehlo.multiply %246, %49 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %248 = stablehlo.reshape %247 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %249 = stablehlo.add %248, %48 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %250 = stablehlo.rsqrt %249 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %251 = stablehlo.reshape %250 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %252 = stablehlo.broadcast_in_dim %251, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %253 = stablehlo.multiply %244, %252 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %254 = stablehlo.convert %253 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %255 = stablehlo.multiply %120, %254 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %256 = stablehlo.reshape %255 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %257 = stablehlo.reshape %19 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %258 = stablehlo.reshape %257 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %259 = stablehlo.transpose %258, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %260 = stablehlo.dot_general %256, %259, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<32x128256xbf16>
    %261 = stablehlo.reshape %260 {mhlo.sharding = "{manual}"} : (tensor<32x128256xbf16>) -> tensor<1x32x128256xbf16>
    %262 = mhlo.copy %110 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %263 = stablehlo.custom_call @SPMDShardToFullShape(%262) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %264 = mhlo.copy %117 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %265 = stablehlo.custom_call @SPMDShardToFullShape(%264) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %266 = mhlo.copy %260 {mhlo.sharding = "{manual}"} : tensor<32x128256xbf16>
    %267 = stablehlo.custom_call @SPMDShardToFullShape(%266) {mhlo.sharding = "{replicated}"} : (tensor<32x128256xbf16>) -> tensor<32x128256xbf16>
    %268 = mhlo.copy %261 {mhlo.sharding = "{manual}"} : tensor<1x32x128256xbf16>
    %269 = stablehlo.custom_call @SPMDShardToFullShape(%268) {mhlo.sharding = "{replicated}"} : (tensor<1x32x128256xbf16>) -> tensor<1x32x128256xbf16>
    return %263, %265, %267, %269 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>
  }
}


2026-01-02 18:37:47.396 (  18.454s) [        CBC3A000] executable_instance.cc:110      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2026-01-02 18:37:47.396 (  18.454s) [        CBC3A000] executable_instance.cc:179      1| Literal MLIR code (size=40801):

module @SyncTensorsGraph.516 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, mhlo.spmd_output_sharding="{{devices=[1,2,1,1]<=[2]},{devices=[1,2,1,1]<=[2]},{replicated},{replicated}}"
} {
  func.func @main(%arg0: tensor<32xi64>, %arg1: tensor<64xf32>, %arg2: tensor<1024x3072xbf16>, %arg3: tensor<1x32xi64>, %arg4: tensor<128256x3072xbf16>, %arg5: tensor<3072xbf16>, %arg6: tensor<1x8x128x128xbf16>, %arg7: tensor<1024x3072xbf16>, %arg8: tensor<1x8x128x128xbf16>, %arg9: tensor<128256x3072xbf16>, %arg10: tensor<3072x8192xbf16>, %arg11: tensor<8192x3072xbf16>, %arg12: tensor<3072x3072xbf16>, %arg13: tensor<1x32xi64>, %arg14: tensor<i1>, %arg15: tensor<3072x3072xbf16>, %arg16: tensor<3072xbf16>, %arg17: tensor<8192x3072xbf16>, %arg18: tensor<3072xbf16>) -> (tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>) {
    %0 = mhlo.copy %arg0 {mhlo.sharding = "{replicated}"} : tensor<32xi64>
    %1 = stablehlo.custom_call @SPMDFullToShardShape(%0) {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xi64>
    %2 = mhlo.copy %arg1 {mhlo.sharding = "{replicated}"} : tensor<64xf32>
    %3 = stablehlo.custom_call @SPMDFullToShardShape(%2) {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<64xf32>
    %4 = mhlo.copy %arg2 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %5 = stablehlo.custom_call @SPMDFullToShardShape(%4) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %6 = mhlo.copy %arg3 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %7 = stablehlo.custom_call @SPMDFullToShardShape(%6) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %8 = mhlo.copy %arg4 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %9 = stablehlo.custom_call @SPMDFullToShardShape(%8) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %10 = mhlo.copy %arg5 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %11 = stablehlo.custom_call @SPMDFullToShardShape(%10) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %12 = mhlo.copy %arg6 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %13 = stablehlo.custom_call @SPMDFullToShardShape(%12) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %14 = mhlo.copy %arg7 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<1024x3072xbf16>
    %15 = stablehlo.custom_call @SPMDFullToShardShape(%14) {mhlo.sharding = "{manual}"} : (tensor<1024x3072xbf16>) -> tensor<512x3072xbf16>
    %16 = mhlo.copy %arg8 {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : tensor<1x8x128x128xbf16>
    %17 = stablehlo.custom_call @SPMDFullToShardShape(%16) {mhlo.sharding = "{manual}"} : (tensor<1x8x128x128xbf16>) -> tensor<1x4x128x128xbf16>
    %18 = mhlo.copy %arg9 {mhlo.sharding = "{replicated}"} : tensor<128256x3072xbf16>
    %19 = stablehlo.custom_call @SPMDFullToShardShape(%18) {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %20 = mhlo.copy %arg10 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x8192xbf16>
    %21 = stablehlo.custom_call @SPMDFullToShardShape(%20) {mhlo.sharding = "{manual}"} : (tensor<3072x8192xbf16>) -> tensor<3072x4096xbf16>
    %22 = mhlo.copy %arg11 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %23 = stablehlo.custom_call @SPMDFullToShardShape(%22) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %24 = mhlo.copy %arg12 {mhlo.sharding = "{devices=[1,2]<=[2]}"} : tensor<3072x3072xbf16>
    %25 = stablehlo.custom_call @SPMDFullToShardShape(%24) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<3072x1536xbf16>
    %26 = mhlo.copy %arg13 {mhlo.sharding = "{replicated}"} : tensor<1x32xi64>
    %27 = stablehlo.custom_call @SPMDFullToShardShape(%26) {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x32xi64>
    %28 = mhlo.copy %arg14 {mhlo.sharding = "{replicated}"} : tensor<i1>
    %29 = stablehlo.custom_call @SPMDFullToShardShape(%28) {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<i1>
    %30 = mhlo.copy %arg15 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<3072x3072xbf16>
    %31 = stablehlo.custom_call @SPMDFullToShardShape(%30) {mhlo.sharding = "{manual}"} : (tensor<3072x3072xbf16>) -> tensor<1536x3072xbf16>
    %32 = mhlo.copy %arg16 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %33 = stablehlo.custom_call @SPMDFullToShardShape(%32) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %34 = mhlo.copy %arg17 {mhlo.sharding = "{devices=[2,1]<=[2]}"} : tensor<8192x3072xbf16>
    %35 = stablehlo.custom_call @SPMDFullToShardShape(%34) {mhlo.sharding = "{manual}"} : (tensor<8192x3072xbf16>) -> tensor<4096x3072xbf16>
    %36 = mhlo.copy %arg18 {mhlo.sharding = "{replicated}"} : tensor<3072xbf16>
    %37 = stablehlo.custom_call @SPMDFullToShardShape(%36) {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<3072xbf16>
    %cst = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<f32>
    %c = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"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tensor<128xi64>
    %c_0 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]> : tensor<32xi64>
    %cst_1 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0xFF800000> : tensor<f32>
    %c_2 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<128> : tensor<i64>
    %cst_3 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<2.000000e+00> : tensor<f32>
    %cst_4 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<3.25520843E-4> : tensor<f32>
    %cst_5 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<9.99999974E-6> : tensor<f32>
    %cst_6 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<8.837890e-02> : tensor<bf16>
    %c_7 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0xFFFFFFFF000000000000000000000000"> : tensor<128xi1>
    %c_8 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<1> : tensor<i64>
    %cst_9 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0.000000e+00> : tensor<bf16>
    %cst_10 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<-3.389530e+38> : tensor<bf16>
    %c_11 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<0> : tensor<i64>
    %cst_12 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<"0x000000000000803F0000004000004040000080400000A0400000C0400000E0400000004100001041000020410000304100004041000050410000604100007041000080410000884100009041000098410000A0410000A8410000B0410000B8410000C0410000C8410000D0410000D8410000E0410000E8410000F0410000F84100000042000004420000084200000C4200001042000014420000184200001C4200002042000024420000284200002C4200003042000034420000384200003C4200004042000044420000484200004C4200005042000054420000584200005C4200006042000064420000684200006C4200007042000074420000784200007C42000080420000824200008442000086420000884200008A4200008C4200008E42000090420000924200009442000096420000984200009A4200009C4200009E420000A0420000A2420000A4420000A6420000A8420000AA420000AC420000AE420000B0420000B2420000B4420000B6420000B8420000BA420000BC420000BE420000C0420000C2420000C4420000C6420000C8420000CA420000CC420000CE420000D0420000D2420000D4420000D6420000D8420000DA420000DC420000DE420000E0420000E2420000E4420000E6420000E8420000EA420000EC420000EE420000F0420000F2420000F4420000F6420000F8420000FA420000FC420000FE42"> : tensor<128xf32>
    %c_13 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<31> : tensor<i64>
    %c_14 = stablehlo.constant {mhlo.sharding = "{manual}"} dense<32> : tensor<i64>
    %38 = stablehlo.broadcast_in_dim %c_14, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %39 = stablehlo.broadcast_in_dim %c_13, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %40 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %41 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %42 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x32xbf16>
    %43 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %44 = stablehlo.broadcast_in_dim %cst_10, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<32x128xbf16>
    %45 = stablehlo.broadcast_in_dim %c_8, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32x128xi64>
    %46 = stablehlo.broadcast_in_dim %cst_9, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x1x32x128xbf16>
    %47 = stablehlo.broadcast_in_dim %cst_6, dims = [] {mhlo.sharding = "{manual}"} : (tensor<bf16>) -> tensor<1x12x32x128xbf16>
    %48 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %49 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %50 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %51 = stablehlo.broadcast_in_dim %c_2, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %52 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<32xi64>
    %53 = stablehlo.reshape %1 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<1x1x32xi64>
    %54 = stablehlo.reshape %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %55 = stablehlo.compare  LT, %54, %52 {mhlo.sharding = "{manual}"} : (tensor<32xi64>, tensor<32xi64>) -> tensor<32xi1>
    %56 = stablehlo.add %54, %51 {mhlo.sharding = "{manual}"} : tensor<32xi64>
    %57 = stablehlo.select %55, %56, %54 {mhlo.sharding = "{manual}"} : tensor<32xi1>, tensor<32xi64>
    %58 = stablehlo.reshape %57 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x1xi64>
    %59 = stablehlo.reshape %11 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %60 = stablehlo.reshape %59 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %61 = stablehlo.broadcast_in_dim %60, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %62 = stablehlo.reshape %9 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %63 = stablehlo.reshape %62 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %64 = stablehlo.reshape %7 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %65 = stablehlo.reshape %64 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<32xi64>
    %66 = stablehlo.convert %65 {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32xui32>
    %67 = "stablehlo.gather"(%63, %66) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, slice_sizes = array<i64: 1, 3072>}> {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>, tensor<32xui32>) -> tensor<32x3072xbf16>
    %68 = stablehlo.reshape %67 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %69 = stablehlo.convert %68 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %70 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %71 = stablehlo.power %69, %70 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %72 = stablehlo.reduce(%71 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %73 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %74 = stablehlo.multiply %72, %73 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %75 = stablehlo.reshape %74 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %76 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %77 = stablehlo.add %75, %76 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %78 = stablehlo.rsqrt %77 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %79 = stablehlo.reshape %78 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %80 = stablehlo.broadcast_in_dim %79, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %81 = stablehlo.multiply %69, %80 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %82 = stablehlo.convert %81 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %83 = stablehlo.multiply %61, %82 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %84 = stablehlo.reshape %83 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %85 = stablehlo.reshape %5 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %86 = stablehlo.reshape %85 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %87 = stablehlo.transpose %86, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %88 = stablehlo.dot_general %84, %87, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %89 = stablehlo.reshape %88 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %90 = stablehlo.transpose %89, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %91 = stablehlo.reshape %3 {mhlo.sharding = "{manual}"} : (tensor<64xf32>) -> tensor<1x1x64xf32>
    %92 = stablehlo.reshape %91 {mhlo.sharding = "{manual}"} : (tensor<1x1x64xf32>) -> tensor<1x64x1xf32>
    %93 = stablehlo.convert %53 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x32xf32>
    %94 = stablehlo.dot_general %92, %93, batching_dims = [0] x [0], contracting_dims = [2] x [1] {mhlo.sharding = "{manual}"} : (tensor<1x64x1xf32>, tensor<1x1x32xf32>) -> tensor<1x64x32xf32>
    %95 = stablehlo.transpose %94, dims = [0, 2, 1] {mhlo.sharding = "{manual}", result_layout = dense<[1, 2, 0]> : tensor<3xindex>, xla_shape = "f32[1,32,64]{1,2,0}"} : (tensor<1x64x32xf32>) -> tensor<1x32x64xf32>
    %96 = stablehlo.concatenate %95, %95, dim = 2 {mhlo.sharding = "{manual}"} : (tensor<1x32x64xf32>, tensor<1x32x64xf32>) -> tensor<1x32x128xf32>
    %97 = stablehlo.cosine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %98 = stablehlo.convert %97 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %99 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %100 = stablehlo.multiply %90, %99 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %101 = stablehlo.slice %90 [0:1, 0:4, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %102 = stablehlo.negate %101 {mhlo.sharding = "{manual}"} : tensor<1x4x32x64xbf16>
    %103 = stablehlo.slice %90 [0:1, 0:4, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x4x32x128xbf16>) -> tensor<1x4x32x64xbf16>
    %104 = stablehlo.concatenate %102, %103, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x4x32x64xbf16>, tensor<1x4x32x64xbf16>) -> tensor<1x4x32x128xbf16>
    %105 = stablehlo.sine %96 {mhlo.sharding = "{manual}"} : tensor<1x32x128xf32>
    %106 = stablehlo.convert %105 {mhlo.sharding = "{manual}"} : (tensor<1x32x128xf32>) -> tensor<1x32x128xbf16>
    %107 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x4x32x128xbf16>
    %108 = stablehlo.multiply %104, %107 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %109 = stablehlo.add %100, %108 {mhlo.sharding = "{manual}"} : tensor<1x4x32x128xbf16>
    %110 = "stablehlo.scatter"(%13, %58, %109) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %111 = stablehlo.reshape %15 {mhlo.sharding = "{manual}"} : (tensor<512x3072xbf16>) -> tensor<1x512x3072xbf16>
    %112 = stablehlo.reshape %111 {mhlo.sharding = "{manual}"} : (tensor<1x512x3072xbf16>) -> tensor<512x3072xbf16>
    %113 = stablehlo.transpose %112, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,1024]{0,1}"} : (tensor<512x3072xbf16>) -> tensor<3072x512xbf16>
    %114 = stablehlo.dot_general %84, %113, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x512xbf16>) -> tensor<32x512xbf16>
    %115 = stablehlo.reshape %114 {mhlo.sharding = "{manual}"} : (tensor<32x512xbf16>) -> tensor<1x32x4x128xbf16>
    %116 = stablehlo.transpose %115, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,8,32,128]{3,1,2,0}"} : (tensor<1x32x4x128xbf16>) -> tensor<1x4x32x128xbf16>
    %117 = "stablehlo.scatter"(%17, %58, %116) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      stablehlo.return %arg20 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>, tensor<32x1xi64>, tensor<1x4x32x128xbf16>) -> tensor<1x4x128x128xbf16>
    %118 = stablehlo.reshape %37 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %119 = stablehlo.reshape %118 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %120 = stablehlo.broadcast_in_dim %119, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %121 = stablehlo.reshape %31 {mhlo.sharding = "{manual}"} : (tensor<1536x3072xbf16>) -> tensor<1x1536x3072xbf16>
    %122 = stablehlo.reshape %121 {mhlo.sharding = "{manual}"} : (tensor<1x1536x3072xbf16>) -> tensor<1536x3072xbf16>
    %123 = stablehlo.transpose %122, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<1536x3072xbf16>) -> tensor<3072x1536xbf16>
    %124 = stablehlo.dot_general %84, %123, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x1536xbf16>) -> tensor<32x1536xbf16>
    %125 = stablehlo.reshape %124 {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>) -> tensor<1x32x12x128xbf16>
    %126 = stablehlo.transpose %125, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,32,128]{3,1,2,0}"} : (tensor<1x32x12x128xbf16>) -> tensor<1x12x32x128xbf16>
    %127 = stablehlo.broadcast_in_dim %98, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %128 = stablehlo.multiply %126, %127 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %129 = stablehlo.slice %126 [0:1, 0:12, 0:32, 64:128] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %130 = stablehlo.negate %129 {mhlo.sharding = "{manual}"} : tensor<1x12x32x64xbf16>
    %131 = stablehlo.slice %126 [0:1, 0:12, 0:32, 0:64] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x64xbf16>
    %132 = stablehlo.concatenate %130, %131, dim = 3 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x64xbf16>, tensor<1x12x32x64xbf16>) -> tensor<1x12x32x128xbf16>
    %133 = stablehlo.broadcast_in_dim %106, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %134 = stablehlo.multiply %132, %133 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %135 = stablehlo.add %128, %134 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %136 = stablehlo.broadcast_in_dim %110, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %137 = stablehlo.reshape %136 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %138 = stablehlo.transpose %137, dims = [0, 1, 3, 2] {mhlo.sharding = "{manual}", result_layout = dense<[2, 3, 1, 0]> : tensor<4xindex>, xla_shape = "bf16[1,24,128,128]{2,3,1,0}"} : (tensor<1x12x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %139 = stablehlo.dot_general %135, %138, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %140 = stablehlo.multiply %139, %47 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %141 = stablehlo.broadcast_in_dim %29, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i1>) -> tensor<128xi1>
    %142 = stablehlo.and %141, %c_7 {mhlo.sharding = "{manual}"} : tensor<128xi1>
    %143 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x1x128xi1>
    %144 = stablehlo.reshape %142 {mhlo.sharding = "{manual}"} : (tensor<128xi1>) -> tensor<1x1x128xi1>
    %145 = stablehlo.broadcast_in_dim %144, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %146 = stablehlo.not %143 {mhlo.sharding = "{manual}"} : tensor<1x1x1x128xi1>
    %147 = stablehlo.reshape %146 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x128xi1>) -> tensor<1x1x128xi1>
    %148 = stablehlo.broadcast_in_dim %147, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x128xi1>) -> tensor<1x1x32x128xi1>
    %149 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %150 = stablehlo.broadcast_in_dim %c_0, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %151 = stablehlo.broadcast_in_dim %c, dims = [1] {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<32x128xi64>
    %152 = stablehlo.subtract %151, %150 {mhlo.sharding = "{manual}"} : tensor<32x128xi64>
    %153 = stablehlo.compare  GE, %152, %45 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %154 = stablehlo.select %153, %44, %43 {mhlo.sharding = "{manual}"} : tensor<32x128xi1>, tensor<32x128xbf16>
    %155 = stablehlo.broadcast_in_dim %54, dims = [0] {mhlo.sharding = "{manual}"} : (tensor<32xi64>) -> tensor<32x128xi64>
    %156 = stablehlo.compare  GT, %149, %155 {mhlo.sharding = "{manual}"} : (tensor<32x128xi64>, tensor<32x128xi64>) -> tensor<32x128xi1>
    %157 = stablehlo.convert %156 {mhlo.sharding = "{manual}"} : (tensor<32x128xi1>) -> tensor<32x128xbf16>
    %158 = stablehlo.multiply %154, %157 {mhlo.sharding = "{manual}"} : tensor<32x128xbf16>
    %159 = stablehlo.reshape %158 {mhlo.sharding = "{manual}"} : (tensor<32x128xbf16>) -> tensor<1x1x32x128xbf16>
    %160 = stablehlo.slice %159 [0:1, 0:1, 0:32, 0:32] {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x1x32x32xbf16>
    %161 = stablehlo.reshape %27 {mhlo.sharding = "{manual}"} : (tensor<1x32xi64>) -> tensor<1x1x32xi64>
    %162 = stablehlo.reshape %161 {mhlo.sharding = "{manual}"} : (tensor<1x1x32xi64>) -> tensor<1x1x1x32xi64>
    %163 = stablehlo.convert %162 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xi64>) -> tensor<1x1x1x32xbf16>
    %164 = stablehlo.reshape %163 {mhlo.sharding = "{manual}"} : (tensor<1x1x1x32xbf16>) -> tensor<1x1x32xbf16>
    %165 = stablehlo.broadcast_in_dim %164, dims = [0, 1, 3] {mhlo.sharding = "{manual}"} : (tensor<1x1x32xbf16>) -> tensor<1x1x32x32xbf16>
    %166 = stablehlo.add %160, %165 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xbf16>
    %167 = stablehlo.compare  EQ, %166, %42 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<1x1x32x32xbf16>) -> tensor<1x1x32x32xi1>
    %168 = stablehlo.select %167, %41, %160 {mhlo.sharding = "{manual}"} : tensor<1x1x32x32xi1>, tensor<1x1x32x32xbf16>
    %169 = stablehlo.floor %cst_12 {mhlo.sharding = "{manual}"} : tensor<128xf32>
    %170 = stablehlo.convert %169 {mhlo.sharding = "{manual}"} : (tensor<128xf32>) -> tensor<128xi64>
    %171 = stablehlo.broadcast_in_dim %c_11, dims = [] {mhlo.sharding = "{manual}"} : (tensor<i64>) -> tensor<128xi64>
    %172 = stablehlo.clamp %171, %170, %39 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %173 = stablehlo.compare  LT, %172, %40 {mhlo.sharding = "{manual}"} : (tensor<128xi64>, tensor<128xi64>) -> tensor<128xi1>
    %174 = stablehlo.add %172, %38 {mhlo.sharding = "{manual}"} : tensor<128xi64>
    %175 = stablehlo.select %173, %174, %172 {mhlo.sharding = "{manual}"} : tensor<128xi1>, tensor<128xi64>
    %176 = stablehlo.reshape %175 {mhlo.sharding = "{manual}"} : (tensor<128xi64>) -> tensor<128x1xi64>
    %177 = "stablehlo.gather"(%168, %176) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2], collapsed_slice_dims = [3], start_index_map = [3], index_vector_dim = 1>, slice_sizes = array<i64: 1, 1, 32, 1>}> {mhlo.sharding = "{manual}"} : (tensor<1x1x32x32xbf16>, tensor<128x1xi64>) -> tensor<1x1x32x128xbf16>
    %178 = stablehlo.select %148, %46, %177 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %179 = stablehlo.select %145, %178, %159 {mhlo.sharding = "{manual}"} : tensor<1x1x32x128xi1>, tensor<1x1x32x128xbf16>
    %180 = stablehlo.reshape %179 {mhlo.sharding = "{manual}"} : (tensor<1x1x32x128xbf16>) -> tensor<1x32x128xbf16>
    %181 = stablehlo.broadcast_in_dim %180, dims = [0, 2, 3] {mhlo.sharding = "{manual}"} : (tensor<1x32x128xbf16>) -> tensor<1x12x32x128xbf16>
    %182 = stablehlo.add %140, %181 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xbf16>
    %183 = stablehlo.convert %182 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x12x32x128xf32>
    %184 = stablehlo.reduce(%183 init: %cst_1) applies stablehlo.maximum across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %185 = stablehlo.broadcast_in_dim %184, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %186 = stablehlo.subtract %183, %185 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %187 = stablehlo.exponential %186 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %188 = stablehlo.reduce(%187 init: %cst) applies stablehlo.add across dimensions = [3] {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>, tensor<f32>) -> tensor<1x12x32xf32>
    %189 = stablehlo.broadcast_in_dim %188, dims = [0, 1, 2] {mhlo.sharding = "{manual}"} : (tensor<1x12x32xf32>) -> tensor<1x12x32x128xf32>
    %190 = stablehlo.divide %187, %189 {mhlo.sharding = "{manual}"} : tensor<1x12x32x128xf32>
    %191 = stablehlo.convert %190 {mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xf32>) -> tensor<1x12x32x128xbf16>
    %192 = stablehlo.broadcast_in_dim %117, dims = [0, 1, 3, 4] {mhlo.sharding = "{manual}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x4x3x128x128xbf16>
    %193 = stablehlo.reshape %192 {mhlo.sharding = "{manual}"} : (tensor<1x4x3x128x128xbf16>) -> tensor<1x12x128x128xbf16>
    %194 = stablehlo.dot_general %191, %193, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2] {mhlo.frontend_attributes = {grad_x = "false", grad_y = "false"}, mhlo.sharding = "{manual}"} : (tensor<1x12x32x128xbf16>, tensor<1x12x128x128xbf16>) -> tensor<1x12x32x128xbf16>
    %195 = stablehlo.transpose %194, dims = [0, 2, 1, 3] {mhlo.sharding = "{manual}", result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "bf16[1,32,24,128]{3,1,2,0}"} : (tensor<1x12x32x128xbf16>) -> tensor<1x32x12x128xbf16>
    %196 = stablehlo.reshape %195 {mhlo.sharding = "{manual}"} : (tensor<1x32x12x128xbf16>) -> tensor<32x1536xbf16>
    %197 = stablehlo.reshape %25 {mhlo.sharding = "{manual}"} : (tensor<3072x1536xbf16>) -> tensor<1x3072x1536xbf16>
    %198 = stablehlo.reshape %197 {mhlo.sharding = "{manual}"} : (tensor<1x3072x1536xbf16>) -> tensor<3072x1536xbf16>
    %199 = stablehlo.transpose %198, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,3072]{0,1}"} : (tensor<3072x1536xbf16>) -> tensor<1536x3072xbf16>
    %200 = stablehlo.dot_general %196, %199, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x1536xbf16>, tensor<1536x3072xbf16>) -> tensor<32x3072xbf16>
    %201 = "stablehlo.all_reduce"(%200) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %202 = stablehlo.reshape %201 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %203 = stablehlo.add %68, %202 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %204 = stablehlo.reshape %33 {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x1x3072xbf16>
    %205 = stablehlo.reshape %204 {mhlo.sharding = "{manual}"} : (tensor<1x1x3072xbf16>) -> tensor<3072xbf16>
    %206 = stablehlo.broadcast_in_dim %205, dims = [2] {mhlo.sharding = "{manual}"} : (tensor<3072xbf16>) -> tensor<1x32x3072xbf16>
    %207 = stablehlo.convert %203 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %208 = stablehlo.broadcast_in_dim %cst_3, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x3072xf32>
    %209 = stablehlo.power %207, %208 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %210 = stablehlo.reduce(%209 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %211 = stablehlo.broadcast_in_dim %cst_4, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32xf32>
    %212 = stablehlo.multiply %210, %211 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %213 = stablehlo.reshape %212 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %214 = stablehlo.broadcast_in_dim %cst_5, dims = [] {mhlo.sharding = "{manual}"} : (tensor<f32>) -> tensor<1x32x1xf32>
    %215 = stablehlo.add %213, %214 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %216 = stablehlo.rsqrt %215 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %217 = stablehlo.reshape %216 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %218 = stablehlo.broadcast_in_dim %217, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %219 = stablehlo.multiply %207, %218 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %220 = stablehlo.convert %219 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %221 = stablehlo.multiply %206, %220 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %222 = stablehlo.reshape %221 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %223 = stablehlo.reshape %35 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %224 = stablehlo.reshape %223 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %225 = stablehlo.transpose %224, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %226 = stablehlo.dot_general %222, %225, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %227 = stablehlo.reshape %226 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %228 = stablehlo.logistic %227 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %229 = stablehlo.multiply %227, %228 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %230 = stablehlo.reshape %23 {mhlo.sharding = "{manual}"} : (tensor<4096x3072xbf16>) -> tensor<1x4096x3072xbf16>
    %231 = stablehlo.reshape %230 {mhlo.sharding = "{manual}"} : (tensor<1x4096x3072xbf16>) -> tensor<4096x3072xbf16>
    %232 = stablehlo.transpose %231, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,8192]{0,1}"} : (tensor<4096x3072xbf16>) -> tensor<3072x4096xbf16>
    %233 = stablehlo.dot_general %222, %232, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x4096xbf16>) -> tensor<32x4096xbf16>
    %234 = stablehlo.reshape %233 {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>) -> tensor<1x32x4096xbf16>
    %235 = stablehlo.multiply %229, %234 {mhlo.sharding = "{manual}"} : tensor<1x32x4096xbf16>
    %236 = stablehlo.reshape %235 {mhlo.sharding = "{manual}"} : (tensor<1x32x4096xbf16>) -> tensor<32x4096xbf16>
    %237 = stablehlo.reshape %21 {mhlo.sharding = "{manual}"} : (tensor<3072x4096xbf16>) -> tensor<1x3072x4096xbf16>
    %238 = stablehlo.reshape %237 {mhlo.sharding = "{manual}"} : (tensor<1x3072x4096xbf16>) -> tensor<3072x4096xbf16>
    %239 = stablehlo.transpose %238, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[8192,3072]{0,1}"} : (tensor<3072x4096xbf16>) -> tensor<4096x3072xbf16>
    %240 = stablehlo.dot_general %236, %239, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x4096xbf16>, tensor<4096x3072xbf16>) -> tensor<32x3072xbf16>
    %241 = "stablehlo.all_reduce"(%240) <{channel_handle = #stablehlo.channel_handle<handle = 1, type = 1>, replica_groups = dense<[[0, 1]]> : tensor<1x2xi64>}> ({
    ^bb0(%arg19: tensor<bf16>, %arg20: tensor<bf16>):
      %270 = stablehlo.add %arg19, %arg20 {mhlo.sharding = "{manual}"} : tensor<bf16>
      stablehlo.return %270 : tensor<bf16>
    }) {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<32x3072xbf16>
    %242 = stablehlo.reshape %241 {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>) -> tensor<1x32x3072xbf16>
    %243 = stablehlo.add %203, %242 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %244 = stablehlo.convert %243 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<1x32x3072xf32>
    %245 = stablehlo.power %244, %50 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %246 = stablehlo.reduce(%245 init: %cst) applies stablehlo.add across dimensions = [2] {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>, tensor<f32>) -> tensor<1x32xf32>
    %247 = stablehlo.multiply %246, %49 {mhlo.sharding = "{manual}"} : tensor<1x32xf32>
    %248 = stablehlo.reshape %247 {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x1xf32>
    %249 = stablehlo.add %248, %48 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %250 = stablehlo.rsqrt %249 {mhlo.sharding = "{manual}"} : tensor<1x32x1xf32>
    %251 = stablehlo.reshape %250 {mhlo.sharding = "{manual}"} : (tensor<1x32x1xf32>) -> tensor<1x32xf32>
    %252 = stablehlo.broadcast_in_dim %251, dims = [0, 1] {mhlo.sharding = "{manual}"} : (tensor<1x32xf32>) -> tensor<1x32x3072xf32>
    %253 = stablehlo.multiply %244, %252 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xf32>
    %254 = stablehlo.convert %253 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xf32>) -> tensor<1x32x3072xbf16>
    %255 = stablehlo.multiply %120, %254 {mhlo.sharding = "{manual}"} : tensor<1x32x3072xbf16>
    %256 = stablehlo.reshape %255 {mhlo.sharding = "{manual}"} : (tensor<1x32x3072xbf16>) -> tensor<32x3072xbf16>
    %257 = stablehlo.reshape %19 {mhlo.sharding = "{manual}"} : (tensor<128256x3072xbf16>) -> tensor<1x128256x3072xbf16>
    %258 = stablehlo.reshape %257 {mhlo.sharding = "{manual}"} : (tensor<1x128256x3072xbf16>) -> tensor<128256x3072xbf16>
    %259 = stablehlo.transpose %258, dims = [1, 0] {mhlo.sharding = "{manual}", result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "bf16[3072,128256]{0,1}"} : (tensor<128256x3072xbf16>) -> tensor<3072x128256xbf16>
    %260 = stablehlo.dot_general %256, %259, contracting_dims = [1] x [0] {mhlo.sharding = "{manual}"} : (tensor<32x3072xbf16>, tensor<3072x128256xbf16>) -> tensor<32x128256xbf16>
    %261 = stablehlo.reshape %260 {mhlo.sharding = "{manual}"} : (tensor<32x128256xbf16>) -> tensor<1x32x128256xbf16>
    %262 = mhlo.copy %110 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %263 = stablehlo.custom_call @SPMDShardToFullShape(%262) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %264 = mhlo.copy %117 {mhlo.sharding = "{manual}"} : tensor<1x4x128x128xbf16>
    %265 = stablehlo.custom_call @SPMDShardToFullShape(%264) {mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x4x128x128xbf16>) -> tensor<1x8x128x128xbf16>
    %266 = mhlo.copy %260 {mhlo.sharding = "{manual}"} : tensor<32x128256xbf16>
    %267 = stablehlo.custom_call @SPMDShardToFullShape(%266) {mhlo.sharding = "{replicated}"} : (tensor<32x128256xbf16>) -> tensor<32x128256xbf16>
    %268 = mhlo.copy %261 {mhlo.sharding = "{manual}"} : tensor<1x32x128256xbf16>
    %269 = stablehlo.custom_call @SPMDShardToFullShape(%268) {mhlo.sharding = "{replicated}"} : (tensor<1x32x128256xbf16>) -> tensor<1x32x128256xbf16>
    return %263, %265, %267, %269 : tensor<1x8x128x128xbf16>, tensor<1x8x128x128xbf16>, tensor<32x128256xbf16>, tensor<1x32x128256xbf16>
  }
}


2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.469s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     buffer_instance.cc:690      1| BufferInstance::PJRT_Buffer_Device
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640] executable_instance.cc:202      1| ExecutableInstance::PJRT_Executable_NumOutputs
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]loaded_executable_insta:345      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]flatbuffer_loaded_execu:260      1| FlatbufferLoadedExecutableInstance::Execute
2026-01-02 18:37:47.411 (  18.470s) [        3AFFD640]     client_instance.cc:424      1| ClientInstance::getOrCreateMeshDevice - reusing already opened mesh device [1, 2]
2026-01-02 18:37:47.411 (  18.470s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:47.411 (  18.470s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:47.411 (  18.470s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:47.411 (  18.470s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:47.413 (  18.471s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 1 with shape [64]
2026-01-02 18:37:47.413 (  18.471s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 2 with shape [512, 3072]
2026-01-02 18:37:47.413 (  18.472s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 4 with shape [128256, 3072]
2026-01-02 18:37:47.413 (  18.472s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 5 with shape [3072]
2026-01-02 18:37:47.413 (  18.472s) [        3AFFD640]flatbuffer_loaded_execu:108      1| Re-laying out already prepared input tensor for argument index 6 with shape [1, 8, 128, 128].
2026-01-02 18:37:47.418 (  18.476s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 7 with shape [512, 3072]
2026-01-02 18:37:47.418 (  18.477s) [        3AFFD640]flatbuffer_loaded_execu:108      1| Re-laying out already prepared input tensor for argument index 8 with shape [1, 8, 128, 128].
2026-01-02 18:37:47.419 (  18.477s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 9 with shape [128256, 3072]
2026-01-02 18:37:47.419 (  18.477s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 10 with shape [3072, 4096]
2026-01-02 18:37:47.419 (  18.477s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 11 with shape [4096, 3072]
2026-01-02 18:37:47.419 (  18.477s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 12 with shape [3072, 1536]
2026-01-02 18:37:47.419 (  18.477s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 13 with shape [1, 32]
2026-01-02 18:37:47.419 (  18.477s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 14 with shape []
2026-01-02 18:37:47.419 (  18.477s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 15 with shape [1536, 3072]
2026-01-02 18:37:47.419 (  18.477s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 16 with shape [3072]
2026-01-02 18:37:47.419 (  18.477s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 17 with shape [4096, 3072]
2026-01-02 18:37:47.419 (  18.477s) [        3AFFD640]flatbuffer_loaded_execu:92       1| Reusing already prepared input tensor for argument index 18 with shape [3072]
2026-01-02 18:37:48.383 | critical |          Always | TT_FATAL: Invalid arguments to reshape (assert.hpp:103)
2026-01-02 18:37:48.419 (  19.477s) [        3AFFD640]                utils.h:62     ERR| Exception:
{TT_FATAL @ /localdev/jameszianxu/tt-xla/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal/ttnn/core/tensor/tensor_utils.cpp:54: new_volume == old_volume
info:
Invalid arguments to reshape
backtrace:
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/libTTMLIRCompiler.so(+0x10975d07) [0x7fee807ccd07]
 --- tt::tt_metal::infer_dims_for_reshape(tt::tt_metal::Tensor const&, std::span<int const, 18446744073709551615ul>)
 --- ttnn::operations::data_movement::ReshapeViewOperation::invoke(tt::tt_metal::Tensor const&, std::span<int const, 18446744073709551615ul>, std::optional<tt::tt_metal::MemoryConfig> const&, std::optional<std::variant<unsigned int, float> > const&, ttnn::TileReshapeMapMode, std::optional<tt::tt_metal::CoreRangeSet> const&)
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/libTTMLIRRuntime.so(+0x51fd40) [0x7ff02c685d40]
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/libTTMLIRRuntime.so(+0x51fab8) [0x7ff02c685ab8]
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/libTTMLIRRuntime.so(+0x51f791) [0x7ff02c685791]
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/libTTMLIRRuntime.so(+0x51f5b8) [0x7ff02c6855b8]
 --- tt::runtime::ttnn::operations::data_movement::run(tt::target::ttnn::ReshapeOp const*, tt::runtime::ttnn::ProgramContext&)
 --- tt::runtime::ttnn::ProgramExecutor::runOperation(tt::target::ttnn::Operation const*)
 --- tt::runtime::ttnn::ProgramExecutor::execute()
 --- tt::runtime::ttnn::submit(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&)
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/libTTMLIRRuntime.so(+0x3416ac) [0x7ff02c4a76ac]
 --- /localdev/jameszianxu/tt-xla/third_party/tt-mlir/install/lib/libTTMLIRRuntime.so(+0x33bbd4) [0x7ff02c4a1bd4]
 --- tt::runtime::submit(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&)
 --- std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > std::__invoke_impl<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&>(std::__invoke_other, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&)
 --- std::__invoke_result<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&>::type std::__invoke<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&>(std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&)
 --- std::invoke_result<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&>::type std::invoke<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&>(std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&)
 --- std::optional<std::conditional<std::is_same_v<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >, void>, std::monostate, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > >::type> tt::pjrt::utils::invoke_noexcept<std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > >(std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> > (&)(tt::runtime::Device, tt::runtime::Binary, unsigned int, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&), tt::runtime::Device&, tt::runtime::Binary const&, unsigned int&, std::vector<tt::runtime::Tensor, std::allocator<tt::runtime::Tensor> >&)
 --- tt::pjrt::FlatbufferLoadedExecutableInstance::execute(PJRT_LoadedExecutable_Execute_Args*)
 --- tt::pjrt::internal::onLoadedExecutableExecute(PJRT_LoadedExecutable_Execute_Args*)
 --- xla::PjRtCApiLoadedExecutable::Execute(absl::lts_20230802::Span<std::vector<xla::PjRtBuffer*, std::allocator<xla::PjRtBuffer*> > const>, xla::ExecuteOptions const&, std::optional<std::vector<xla::PjRtFuture<void>, std::allocator<xla::PjRtFuture<void> > > >&)
 --- torch_xla::runtime::PjRtComputationClient::ExecuteReplicated(torch_xla::runtime::ComputationClient::Computation const&, absl::lts_20230802::Span<std::shared_ptr<torch_xla::runtime::ComputationClient::Data> const>, absl::lts_20230802::Span<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, torch_xla::runtime::ComputationClient::ExecuteReplicatedOptions const&)
 --- /usr/local/lib/python3.11/dist-packages/_XLAC.cpython-311-x86_64-linux-gnu.so(+0x6ddf582) [0x7ff102921582]
 --- torch::lazy::MultiWait::Complete(std::function<void ()> const&)
 --- Eigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)
 --- void absl::lts_20230802::internal_any_invocable::RemoteInvoker<false, void, tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}&>(absl::lts_20230802::internal_any_invocable::TypeErasedState*)
 --- /usr/local/lib/python3.11/dist-packages/_XLAC.cpython-311-x86_64-linux-gnu.so(+0x11678942) [0x7ff10d1ba942]
 --- /lib/x86_64-linux-gnu/libc.so.6(+0x94ac3) [0x7ff1cbccfac3]
 --- /lib/x86_64-linux-gnu/libc.so.6(+0x1268c0) [0x7ff1cbd618c0]
}

2026-01-02 18:37:48.429 (  19.488s) [        3AFFD640]     client_instance.cc:507      1| Closing parent mesh.
2026-01-02 18:37:48.529 (  19.587s) [        3AFFD640]      error_instance.cc:52       1| ErrorInstance::PJRT_Error_Message
2026-01-02 18:37:48.529 (  19.587s) [        3AFFD640]      error_instance.cc:61       1| ErrorInstance::PJRT_Error_GetCode
2026-01-02 18:37:48.529 (  19.587s) [        3AFFD640]      error_instance.cc:46       1| ErrorInstance::PJRT_Error_Destroy
2026-01-02 18:37:48.529 (  19.588s) [        3AFFD640]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.529 (  19.588s) [        3AFFD640]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.529 (  19.588s) [        3AFFD640]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.529 (  19.588s) [        3AFFD640]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
Traceback (most recent call last):
  File "/localdev/jameszianxu/tt-xla/examples/pytorch/llama.py", line 432, in <module>
    llama(interactive=args.interactive)
  File "/localdev/jameszianxu/tt-xla/examples/pytorch/llama.py", line 114, in llama
    run_generate(
  File "/localdev/jameszianxu/tt-xla/examples/pytorch/llama.py", line 352, in run_generate
    output_logits: torch.Tensor = output.logits.to("cpu")
                                  ^^^^^^^^^^^^^^^^^^^^^^^
  File "/localdev/jameszianxu/tt-xla/python_package/tt_torch/torch_overrides.py", line 22, in __torch_function__
    return func(*args, **(kwargs or {}))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Bad StatusOr access: INTERNAL: Error code: 13
2026-01-02 18:37:48.783 (  19.841s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.783 (  19.842s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.783 (  19.842s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.783 (  19.842s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.783 (  19.842s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.783 (  19.842s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.783 (  19.842s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.835 (  19.894s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.885 (  19.944s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.885 (  19.944s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.886 (  19.944s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.886 (  19.944s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.886 (  19.945s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.886 (  19.945s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.886 (  19.945s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.887 (  19.945s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.887 (  19.945s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.887 (  19.946s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.887 (  19.946s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.887 (  19.946s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.887 (  19.946s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.887 (  19.946s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.888 (  19.946s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.888 (  19.946s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.888 (  19.947s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.888 (  19.947s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.888 (  19.947s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.889 (  19.947s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.889 (  19.947s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.889 (  19.947s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.889 (  19.948s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.889 (  19.948s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.889 (  19.948s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.889 (  19.948s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.889 (  19.948s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.890 (  19.948s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.890 (  19.948s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.890 (  19.948s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.890 (  19.949s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.890 (  19.949s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.890 (  19.949s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.890 (  19.949s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.890 (  19.949s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.891 (  19.949s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.891 (  19.949s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.891 (  19.949s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.891 (  19.950s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.891 (  19.950s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.891 (  19.950s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.891 (  19.950s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.891 (  19.950s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.892 (  19.950s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.892 (  19.950s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.892 (  19.950s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.892 (  19.950s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.892 (  19.951s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.892 (  19.951s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.892 (  19.951s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.892 (  19.951s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.892 (  19.951s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.893 (  19.951s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.893 (  19.951s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.893 (  19.951s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.893 (  19.952s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.893 (  19.952s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.893 (  19.952s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.893 (  19.952s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.893 (  19.952s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.894 (  19.952s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.894 (  19.952s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.894 (  19.952s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.894 (  19.953s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.894 (  19.953s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.894 (  19.953s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.894 (  19.953s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.894 (  19.953s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.895 (  19.953s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.895 (  19.953s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.895 (  19.953s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.895 (  19.953s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.895 (  19.954s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.895 (  19.954s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.895 (  19.954s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.895 (  19.954s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.895 (  19.954s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.896 (  19.954s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.896 (  19.954s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.896 (  19.954s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.896 (  19.955s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.896 (  19.955s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.896 (  19.955s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.896 (  19.955s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.896 (  19.955s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.897 (  19.955s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.897 (  19.955s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.897 (  19.955s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.897 (  19.956s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.897 (  19.956s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.897 (  19.956s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.897 (  19.956s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.897 (  19.956s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.897 (  19.956s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.898 (  19.956s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.898 (  19.956s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.898 (  19.956s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.898 (  19.957s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.898 (  19.957s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.898 (  19.957s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.898 (  19.957s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.898 (  19.957s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.898 (  19.957s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.899 (  19.957s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.899 (  19.957s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.899 (  19.957s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.899 (  19.958s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.899 (  19.958s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.899 (  19.958s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.899 (  19.958s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.899 (  19.958s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.899 (  19.958s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.900 (  19.958s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.900 (  19.958s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.900 (  19.959s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.900 (  19.959s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.900 (  19.959s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.900 (  19.959s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.900 (  19.959s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.900 (  19.959s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.901 (  19.959s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.901 (  19.959s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.901 (  19.959s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.901 (  19.960s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.901 (  19.960s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.901 (  19.960s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.901 (  19.960s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.901 (  19.960s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.902 (  19.960s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.902 (  19.960s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.902 (  19.960s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.902 (  19.961s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.902 (  19.961s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.902 (  19.961s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.902 (  19.961s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.902 (  19.961s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.903 (  19.961s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.903 (  19.961s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.903 (  19.961s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.903 (  19.961s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.903 (  19.962s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.903 (  19.962s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.903 (  19.962s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.903 (  19.962s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.903 (  19.962s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.904 (  19.962s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.904 (  19.962s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.904 (  19.962s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.904 (  19.962s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.904 (  19.963s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.904 (  19.963s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.904 (  19.963s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.904 (  19.963s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.904 (  19.963s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.905 (  19.963s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.905 (  19.963s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.905 (  19.963s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.905 (  19.963s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.905 (  19.963s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.905 (  19.964s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.905 (  19.964s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.905 (  19.964s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.905 (  19.964s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.905 (  19.964s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.906 (  19.964s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.906 (  19.964s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.906 (  19.964s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.906 (  19.965s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.906 (  19.965s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.906 (  19.965s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.906 (  19.965s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.906 (  19.965s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.907 (  19.965s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.907 (  19.965s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.907 (  19.965s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.907 (  19.966s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.907 (  19.966s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.907 (  19.966s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.907 (  19.966s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.907 (  19.966s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.908 (  19.966s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.908 (  19.966s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.908 (  19.967s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.908 (  19.967s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.908 (  19.967s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.908 (  19.967s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.908 (  19.967s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.909 (  19.967s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.909 (  19.967s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.909 (  19.967s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.909 (  19.967s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.909 (  19.968s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.909 (  19.968s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.909 (  19.968s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.909 (  19.968s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.909 (  19.968s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.910 (  19.968s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.910 (  19.968s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.910 (  19.968s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.910 (  19.968s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.910 (  19.969s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.910 (  19.969s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.910 (  19.969s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.910 (  19.969s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.911 (  19.969s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.911 (  19.969s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.911 (  19.969s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.911 (  19.969s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.911 (  19.970s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.911 (  19.970s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.911 (  19.970s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.911 (  19.970s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.911 (  19.970s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.911 (  19.970s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.912 (  19.970s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.912 (  19.970s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.912 (  19.970s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.912 (  19.970s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.912 (  19.971s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.912 (  19.971s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.912 (  19.971s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.912 (  19.971s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.912 (  19.971s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.913 (  19.971s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.913 (  19.971s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.913 (  19.971s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.913 (  19.971s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.913 (  19.972s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.913 (  19.972s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.913 (  19.972s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.913 (  19.972s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.913 (  19.972s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.914 (  19.972s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.914 (  19.972s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.914 (  19.972s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.914 (  19.972s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.914 (  19.973s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.914 (  19.973s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.914 (  19.973s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.914 (  19.973s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.914 (  19.973s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.914 (  19.973s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.915 (  19.973s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.915 (  19.973s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.915 (  19.973s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.915 (  19.974s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.915 (  19.974s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.915 (  19.974s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.915 (  19.974s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.915 (  19.974s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.916 (  19.974s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.916 (  19.974s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.916 (  19.974s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.916 (  19.974s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.916 (  19.975s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.916 (  19.975s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.916 (  19.975s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.916 (  19.975s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.916 (  19.975s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.916 (  19.975s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.917 (  19.975s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.917 (  19.975s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.917 (  19.976s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.917 (  19.976s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.917 (  19.976s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.917 (  19.976s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.917 (  19.976s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.917 (  19.976s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.918 (  19.976s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.918 (  19.976s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.918 (  19.976s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.918 (  19.976s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.918 (  19.977s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.918 (  19.977s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.918 (  19.977s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.918 (  19.977s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.918 (  19.977s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.919 (  19.977s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.919 (  19.977s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.919 (  19.977s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.919 (  19.978s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.919 (  19.978s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.919 (  19.978s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.919 (  19.978s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.919 (  19.978s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.919 (  19.978s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.919 (  19.978s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.920 (  19.978s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.920 (  19.978s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.920 (  19.978s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.920 (  19.978s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.920 (  19.979s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.920 (  19.979s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.920 (  19.979s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.920 (  19.979s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.920 (  19.979s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.921 (  19.979s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.921 (  19.979s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.921 (  19.979s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.921 (  19.979s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.921 (  19.980s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.921 (  19.980s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.921 (  19.980s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.921 (  19.980s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.921 (  19.980s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.921 (  19.980s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.922 (  19.980s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.922 (  19.980s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.922 (  19.980s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.922 (  19.981s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.922 (  19.981s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.922 (  19.981s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.922 (  19.981s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.922 (  19.981s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.922 (  19.981s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.923 (  19.981s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.923 (  19.981s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.923 (  19.981s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.923 (  19.982s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.923 (  19.982s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.923 (  19.982s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.923 (  19.982s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.923 (  19.982s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.923 (  19.982s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.924 (  19.982s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.924 (  19.982s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.924 (  19.982s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.924 (  19.983s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.924 (  19.983s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.924 (  19.983s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.924 (  19.983s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.924 (  19.983s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.925 (  19.983s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.925 (  19.983s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.925 (  19.983s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.925 (  19.983s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.925 (  19.984s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.925 (  19.984s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.925 (  19.984s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.925 (  19.984s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.925 (  19.984s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.926 (  19.984s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.926 (  19.984s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.926 (  19.984s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.926 (  19.984s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.926 (  19.985s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.926 (  19.985s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.926 (  19.985s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.926 (  19.985s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.926 (  19.985s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.927 (  19.985s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.927 (  19.985s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.927 (  19.985s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.927 (  19.985s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.927 (  19.986s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.927 (  19.986s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.927 (  19.986s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.927 (  19.986s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.927 (  19.986s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.927 (  19.986s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.928 (  19.986s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.928 (  19.986s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.928 (  19.986s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.928 (  19.987s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.928 (  19.987s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.928 (  19.987s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.928 (  19.987s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.928 (  19.987s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.929 (  19.987s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.929 (  19.987s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.929 (  19.987s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.929 (  19.987s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.929 (  19.988s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.929 (  19.988s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.929 (  19.988s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.929 (  19.988s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.929 (  19.988s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.929 (  19.988s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.930 (  19.988s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.930 (  19.988s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.930 (  19.988s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.930 (  19.989s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.930 (  19.989s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.930 (  19.989s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.930 (  19.989s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.930 (  19.989s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.930 (  19.989s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.931 (  19.989s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.931 (  19.989s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.931 (  19.989s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.931 (  19.989s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.931 (  19.990s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.931 (  19.990s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.931 (  19.990s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.931 (  19.990s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.931 (  19.990s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.931 (  19.990s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.932 (  19.990s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.932 (  19.990s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.932 (  19.990s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.932 (  19.990s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.932 (  19.991s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.932 (  19.991s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.932 (  19.991s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.932 (  19.991s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.932 (  19.991s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.932 (  19.991s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.933 (  19.991s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.933 (  19.991s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.933 (  19.991s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.933 (  19.992s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.933 (  19.992s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.933 (  19.992s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.933 (  19.992s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.933 (  19.992s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.933 (  19.992s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.934 (  19.992s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.934 (  19.992s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.934 (  19.992s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.934 (  19.993s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.934 (  19.993s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.934 (  19.993s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.934 (  19.993s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.934 (  19.993s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.934 (  19.993s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.935 (  19.993s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.935 (  19.993s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.935 (  19.993s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.935 (  19.994s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.935 (  19.994s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.935 (  19.994s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.935 (  19.994s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.935 (  19.994s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.935 (  19.994s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.935 (  19.994s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.936 (  19.994s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.936 (  19.994s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.936 (  19.994s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.936 (  19.994s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.936 (  19.995s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.936 (  19.995s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.936 (  19.995s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.936 (  19.995s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.936 (  19.995s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.937 (  19.995s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.937 (  19.995s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.937 (  19.995s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.937 (  19.995s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.937 (  19.996s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.937 (  19.996s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.937 (  19.996s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.937 (  19.996s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.937 (  19.996s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.937 (  19.996s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.938 (  19.996s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.938 (  19.996s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.938 (  19.996s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.938 (  19.996s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.938 (  19.997s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.938 (  19.997s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.938 (  19.997s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.938 (  19.997s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.938 (  19.997s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.938 (  19.997s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.939 (  19.997s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.939 (  19.997s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.939 (  19.997s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.939 (  19.997s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.939 (  19.998s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.939 (  19.998s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.939 (  19.998s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.939 (  19.998s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.939 (  19.998s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.939 (  19.998s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.940 (  19.998s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.940 (  19.998s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.940 (  19.998s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.940 (  19.998s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.940 (  19.999s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.940 (  19.999s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.940 (  19.999s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.940 (  19.999s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.940 (  19.999s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.941 (  19.999s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.941 (  19.999s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.941 (  19.999s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.941 (  19.999s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.941 (  20.000s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.941 (  20.000s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.941 (  20.000s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.941 (  20.000s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.941 (  20.000s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.942 (  20.000s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.942 (  20.000s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.942 (  20.000s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.942 (  20.000s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.942 (  20.001s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.942 (  20.001s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.942 (  20.001s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.942 (  20.001s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.946 (  20.005s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.946 (  20.005s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.946 (  20.005s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.946 (  20.005s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.947 (  20.005s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.947 (  20.005s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.947 (  20.005s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.947 (  20.005s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:48.947 (  20.006s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:49.013 (  20.071s) [        CBC3A000]     buffer_instance.cc:537      1| BufferInstance::PJRT_Buffer_Destroy
2026-01-02 18:37:49.809 (  20.867s) [        CBC3A000]     client_instance.cc:192      1| ClientInstance::~ClientInstance
