WARNING:root:Defaulting to PJRT_DEVICE=CPU
2025-09-25 17:43:16.180 (   0.000s) [        FA002000]      dylib_platform.cc:47       1| DylibPlatform::SubclassInitialize
2025-09-25 17:43:16.182 (   0.002s) [        FA002000]     client_instance.cc:42       1| ClientInstance::ClientInstance
2025-09-25 17:43:16.182 (   0.002s) [        FA002000]              client.cc:18       1| TTClientInstance::TTClientInstance
2025-09-25 17:43:16.182 (   0.002s) [        FA002000]     client_instance.cc:67       1| ClientInstance::Initialize
2025-09-25 17:44:01.429 (  45.249s) [        FA002000]              stubs.inc:106   WARN| STUB: PJRT_Client_TopologyDescription
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]      error_instance.cc:49       1| ErrorInstance::PJRT_Error_Message
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]      error_instance.cc:58       1| ErrorInstance::PJRT_Error_GetCode
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]      error_instance.cc:43       1| ErrorInstance::PJRT_Error_Destroy
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]     client_instance.cc:423      1| ClientInstance::PJRT_Client_PlatformVersion
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]     client_instance.cc:403      1| ClientInstance::PJRT_Client_PlatformName
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]     client_instance.cc:435      1| ClientInstance::PJRT_Client_Devices
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]     device_instance.cc:44       1| DeviceInstance::PJRT_Device_GetDescription
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:63       1| DeviceDescription::PJRT_DeviceDescription_Attributes
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]     client_instance.cc:448      1| ClientInstance::PJRT_Client_AddressableDevices
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]     client_instance.cc:498      1| ClientInstance::PJRT_Client_AddressableMemories
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]     device_instance.cc:71       1| DeviceInstance::PJRT_Device_AddressableMemories
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]     memory_instance.cc:124      1| MemoryInstance::PJRT_Memory_AddressableByDevices
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]        api_bindings.cc:76       1| PJRT_Plugin_Attributes
2025-09-25 17:44:01.430342: W torch_xla/csrc/runtime/profiler.cpp:88] Profiler API not found for PJRT plugin
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:99       1| DeviceDescription::PJRT_DeviceDescription_ToString
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.430 (  45.249s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
/localdev/jameszianxu/tt-xla/examples/pytorch/scatter_cache.py:68: DeprecationWarning: Use torch_xla.device instead
  device = xm.xla_device()
2025-09-25 17:44:01.665 (  45.485s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.665 (  45.485s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.666 (  45.485s) [        FA002000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-25 17:44:01.666 (  45.485s) [        FA002000]     client_instance.cc:549      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-25 17:44:01.666 (  45.485s) [        FA002000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-25 17:44:01.667 (  45.486s) [        FA002000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x23c87b30 copyFromHost BORROWED shape=[1,4,64,128] - NEW tensor.data=0x7fff7dea60d0 tensor.handle=0x7fff7dea6120
2025-09-25 17:44:01.667 (  45.486s) [        FA002000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-25 17:44:01.667 (  45.486s) [        FA002000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-25 17:44:01.667 (  45.486s) [        FA002000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-25 17:44:01.667 (  45.486s) [        FA002000]     client_instance.cc:549      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-25 17:44:01.667 (  45.486s) [        FA002000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-25 17:44:01.667 (  45.486s) [        FA002000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x23b822c0 copyFromHost BORROWED shape=[1,4,64,128] - NEW tensor.data=0x7fff7dea60d0 tensor.handle=0x7fff7dea6120
2025-09-25 17:44:01.667 (  45.486s) [        FA002000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-25 17:44:01.667 (  45.486s) [        FA002000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-25 17:44:01.667 (  45.487s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.667 (  45.487s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.667 (  45.487s) [        FA002000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-25 17:44:01.667 (  45.487s) [        FA002000]     client_instance.cc:549      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-25 17:44:01.667 (  45.487s) [        FA002000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-25 17:44:01.667 (  45.487s) [        FA002000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x23af4740 copyFromHost OWNED shape=[64] - NEW tensor.data=0x7fff7dea60d0 tensor.handle=0x7fff7dea6120
2025-09-25 17:44:01.667 (  45.487s) [        FA002000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-25 17:44:01.667 (  45.487s) [        FA002000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-25 17:44:01.667 (  45.487s) [        FA002000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-25 17:44:01.667 (  45.487s) [        FA002000]     client_instance.cc:549      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-25 17:44:01.667 (  45.487s) [        FA002000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-25 17:44:01.668 (  45.487s) [        FA002000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x23a81530 copyFromHost OWNED shape=[64] - NEW tensor.data=0x7fff7dea60d0 tensor.handle=0x7fff7dea6120
2025-09-25 17:44:01.668 (  45.487s) [        FA002000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-25 17:44:01.668 (  45.487s) [        FA002000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-25 17:44:01.668 (  45.487s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.668 (  45.487s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:01.669 (  45.489s) [        FA002000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-25 17:44:01.669 (  45.489s) [        FA002000]     client_instance.cc:549      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-25 17:44:01.669 (  45.489s) [        FA002000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-25 17:44:01.669 (  45.489s) [        FA002000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x23a1e880 copyFromHost BORROWED shape=[1,4,1024,128] - NEW tensor.data=0x7fff7dea60d0 tensor.handle=0x7fff7dea6120
2025-09-25 17:44:01.669 (  45.489s) [        FA002000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-25 17:44:01.670 (  45.489s) [        FA002000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-25 17:44:01.670 (  45.489s) [        FA002000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-25 17:44:01.670 (  45.489s) [        FA002000]     client_instance.cc:549      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-25 17:44:01.670 (  45.489s) [        FA002000]     memory_instance.cc:57       1| MemoryInstance::getDevice
2025-09-25 17:44:01.670 (  45.489s) [        FA002000]     buffer_instance.cc:225   INFO| BUFFER_TRACE: BufferInstance=0x23a205b0 copyFromHost BORROWED shape=[1,4,1024,128] - NEW tensor.data=0x7fff7dea60d0 tensor.handle=0x7fff7dea6120
2025-09-25 17:44:01.670 (  45.489s) [        FA002000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-25 17:44:01.670 (  45.489s) [        FA002000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-25 17:44:02.129 (  45.949s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:02.129 (  45.949s) [        FA002000]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:02.129 (  45.949s) [        FA002000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-25 17:44:02.129 (  45.949s) [        FA002000]     client_instance.cc:549      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-25 17:44:02.129 (  45.949s) [        FA002000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-25 17:44:02.130 (  45.949s) [        FA002000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x23283e10 copyFromHost OWNED shape=[] - NEW tensor.data=0x7fff7dea2ec0 tensor.handle=0x7fff7dea2f10
2025-09-25 17:44:02.130 (  45.949s) [        FA002000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-25 17:44:02.130 (  45.949s) [        FA002000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-25 17:44:02.130 (  45.949s) [        FA002000]     device_instance.cc:82       1| DeviceInstance::PJRT_Device_DefaultMemory
2025-09-25 17:44:02.130 (  45.949s) [        FA002000]     client_instance.cc:549      1| ClientInstance::PJRT_Client_BufferFromHostBuffer
2025-09-25 17:44:02.130 (  45.949s) [        FA002000]     memory_instance.cc:57       1| MemoryInstance::getDevice
[32m                 Always[0m | [1m[38;5;208m WARNING[0m | User provided a tensor of data type: Int64 which is not supported by runtime/ttnn. Casting to: Int32, this may impact throughput and the integrity of the data.
2025-09-25 17:44:02.130 (  45.949s) [        FA002000]     buffer_instance.cc:205   INFO| BUFFER_TRACE: BufferInstance=0x2329a2d0 copyFromHost OWNED shape=[] - NEW tensor.data=0x7fff7dea2ec0 tensor.handle=0x7fff7dea2f10
2025-09-25 17:44:02.130 (  45.949s) [        FA002000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-25 17:44:02.130 (  45.949s) [        FA002000]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.131 (  45.950s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.140 (  45.959s) [        FA002000]     client_instance.cc:511      1| ClientInstance::PJRT_Client_Compile
2025-09-25 17:44:02.140 (  45.960s) [        FA002000]      module_builder.cc:99       1| ModuleBuilder::buildModule
2025-09-25 17:44:02.142 (  45.961s) [        FA002000]      module_builder.cc:161      1| VHLO Module:
#loc1 = loc("p0.1")
#loc2 = loc("p1.3")
#loc3 = loc("p2.7")
#loc4 = loc("p3.19")
#loc15 = loc("scatter.25")
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1x8x64x128x!vhlo.f32_v1> loc("p0.1"), %arg1: !vhlo.tensor_v1<64x!vhlo.i64_v1> loc("p1.3"), %arg2: !vhlo.tensor_v1<!vhlo.i64_v1> loc("p2.7"), %arg3: !vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1> loc("p3.19")) -> (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1> loc(#loc)
    %1 = "vhlo.broadcast_in_dim_v1"(%0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1> loc(#loc)
    %2 = "vhlo.custom_call_v1"(%arg3) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1> loc(#loc5)
    %3 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.i64_v1> loc(#loc6)
    %4 = "vhlo.custom_call_v1"(%3) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.i64_v1> loc(#loc7)
    %5 = "vhlo.reshape_v1"(%4) : (!vhlo.tensor_v1<1x1x64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1> loc(#loc8)
    %6 = "vhlo.compare_v1"(%5, %1) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<64x!vhlo.i64_v1>, !vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.bool_v1> loc(#loc9)
    %7 = "vhlo.broadcast_in_dim_v1"(%arg2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1> loc(#loc10)
    %8 = "vhlo.add_v1"(%5, %7) : (!vhlo.tensor_v1<64x!vhlo.i64_v1>, !vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1> loc(#loc11)
    %9 = "vhlo.select_v1"(%6, %8, %5) : (!vhlo.tensor_v1<64x!vhlo.bool_v1>, !vhlo.tensor_v1<64x!vhlo.i64_v1>, !vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1> loc(#loc12)
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x1x!vhlo.i64_v1> loc(#loc13)
    %11 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___key_states">}>} : (!vhlo.tensor_v1<1x8x64x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x64x128x!vhlo.f32_v1> loc(#loc14)
    %12 = "vhlo.scatter_v2"(%2, %10, %11) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg4: !vhlo.tensor_v1<!vhlo.f32_v1> loc("scatter.25"), %arg5: !vhlo.tensor_v1<!vhlo.f32_v1> loc("scatter.25")):
      "vhlo.return_v1"(%arg5) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> () loc(#loc)
    }) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>, !vhlo.tensor_v1<64x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x64x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1> loc(#loc15)
    %13 = "vhlo.custom_call_v1"(%12) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1> loc(#loc16)
    "vhlo.return_v1"(%13) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) -> () loc(#loc)
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">} loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc5 = loc("custom-call.20")
#loc6 = loc("reshape.4")
#loc7 = loc("custom-call.5")
#loc8 = loc("reshape.6")
#loc9 = loc("compare.15")
#loc10 = loc("broadcast.11")
#loc11 = loc("add.12")
#loc12 = loc("select.16")
#loc13 = loc("reshape.17")
#loc14 = loc("custom-call.2")
#loc16 = loc("custom-call.27")
// -----// IR Dump Before VhloToVersionPass (vhlo-to-version) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1x8x64x128x!vhlo.f32_v1>, %arg1: !vhlo.tensor_v1<64x!vhlo.i64_v1>, %arg2: !vhlo.tensor_v1<!vhlo.i64_v1>, %arg3: !vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) -> (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1>
    %1 = "vhlo.broadcast_in_dim_v1"(%0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1>
    %2 = "vhlo.custom_call_v1"(%arg3) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>
    %3 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.i64_v1>
    %4 = "vhlo.custom_call_v1"(%3) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.i64_v1>
    %5 = "vhlo.reshape_v1"(%4) : (!vhlo.tensor_v1<1x1x64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1>
    %6 = "vhlo.compare_v1"(%5, %1) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<64x!vhlo.i64_v1>, !vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.bool_v1>
    %7 = "vhlo.broadcast_in_dim_v1"(%arg2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1>
    %8 = "vhlo.add_v1"(%5, %7) : (!vhlo.tensor_v1<64x!vhlo.i64_v1>, !vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1>
    %9 = "vhlo.select_v1"(%6, %8, %5) : (!vhlo.tensor_v1<64x!vhlo.bool_v1>, !vhlo.tensor_v1<64x!vhlo.i64_v1>, !vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1>
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x1x!vhlo.i64_v1>
    %11 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___key_states">}>} : (!vhlo.tensor_v1<1x8x64x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x64x128x!vhlo.f32_v1>
    %12 = "vhlo.scatter_v2"(%2, %10, %11) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg4: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg5: !vhlo.tensor_v1<!vhlo.f32_v1>):
      "vhlo.return_v1"(%arg5) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>, !vhlo.tensor_v1<64x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x64x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>
    %13 = "vhlo.custom_call_v1"(%12) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>
    "vhlo.return_v1"(%13) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump Before VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<1x8x64x128x!vhlo.f32_v1>, %arg1: !vhlo.tensor_v1<64x!vhlo.i64_v1>, %arg2: !vhlo.tensor_v1<!vhlo.i64_v1>, %arg3: !vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) -> (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) {
    %0 = "vhlo.constant_v1"() <{value = #vhlo.tensor_v1<dense<0> : tensor<i64>>}> : () -> !vhlo.tensor_v1<!vhlo.i64_v1>
    %1 = "vhlo.broadcast_in_dim_v1"(%0) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1>
    %2 = "vhlo.custom_call_v1"(%arg3) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_0">}>} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>
    %3 = "vhlo.reshape_v1"(%arg1) : (!vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.i64_v1>
    %4 = "vhlo.custom_call_v1"(%3) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"args_1">}>} : (!vhlo.tensor_v1<1x1x64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<1x1x64x!vhlo.i64_v1>
    %5 = "vhlo.reshape_v1"(%4) : (!vhlo.tensor_v1<1x1x64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1>
    %6 = "vhlo.compare_v1"(%5, %1) <{compare_type = #vhlo<comparison_type_v1 NOTYPE>, comparison_direction = #vhlo<comparison_direction_v1 LT>}> : (!vhlo.tensor_v1<64x!vhlo.i64_v1>, !vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.bool_v1>
    %7 = "vhlo.broadcast_in_dim_v1"(%arg2) <{broadcast_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>}> : (!vhlo.tensor_v1<!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1>
    %8 = "vhlo.add_v1"(%5, %7) : (!vhlo.tensor_v1<64x!vhlo.i64_v1>, !vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1>
    %9 = "vhlo.select_v1"(%6, %8, %5) : (!vhlo.tensor_v1<64x!vhlo.bool_v1>, !vhlo.tensor_v1<64x!vhlo.i64_v1>, !vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x!vhlo.i64_v1>
    %10 = "vhlo.reshape_v1"(%9) : (!vhlo.tensor_v1<64x!vhlo.i64_v1>) -> !vhlo.tensor_v1<64x1x!vhlo.i64_v1>
    %11 = "vhlo.custom_call_v1"(%arg0) <{api_version = #vhlo<api_version_v1 API_VERSION_UNSPECIFIED>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"tt.mark_argument">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"ttcore.argument_type"> = #vhlo.string_v1<"input">, #vhlo.string_v1<"ttir.name"> = #vhlo.string_v1<"l__self___key_states">}>} : (!vhlo.tensor_v1<1x8x64x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x64x128x!vhlo.f32_v1>
    %12 = "vhlo.scatter_v2"(%2, %10, %11) <{index_vector_dim = #vhlo.integer_v1<1 : i64>, indices_are_sorted = #vhlo.bool_v1<false>, input_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, inserted_window_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_dims_to_operand_dims = #vhlo.tensor_v1<dense<2> : tensor<1xi64>>, scatter_indices_batching_dims = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, unique_indices = #vhlo.bool_v1<false>, update_window_dims = #vhlo.tensor_v1<dense<[0, 1, 3]> : tensor<3xi64>>}> ({
    ^bb0(%arg4: !vhlo.tensor_v1<!vhlo.f32_v1>, %arg5: !vhlo.tensor_v1<!vhlo.f32_v1>):
      "vhlo.return_v1"(%arg5) : (!vhlo.tensor_v1<!vhlo.f32_v1>) -> ()
    }) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>, !vhlo.tensor_v1<64x1x!vhlo.i64_v1>, !vhlo.tensor_v1<1x8x64x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>
    %13 = "vhlo.custom_call_v1"(%12) <{api_version = #vhlo<api_version_v1 API_VERSION_ORIGINAL>, backend_config = #vhlo.string_v1<"">, call_target_name = #vhlo.string_v1<"Sharding">, called_computations = #vhlo.array_v1<[]>, has_side_effect = #vhlo.bool_v1<false>, operand_layouts = #vhlo.array_v1<[]>, output_operand_aliases = #vhlo.array_v1<[]>, result_layouts = #vhlo.array_v1<[]>}> {mhlo.frontend_attributes = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>">}>, mhlo.sharding = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">} : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>
    "vhlo.return_v1"(%13) : (!vhlo.tensor_v1<1x8x1024x128x!vhlo.f32_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, []>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2,1,1]<=[2]}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump After VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"}, %arg1: tensor<64xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"}, %arg2: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"}, %arg3: tensor<1x8x1024x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"}) -> tensor<1x8x1024x128xf32> {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.custom_call @tt.mark_argument(%arg3) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    %2 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %3 = stablehlo.custom_call @tt.mark_argument(%2) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<1x1x64xi64>) -> tensor<1x1x64xi64>
    %4 = stablehlo.reshape %3 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %5 = stablehlo.compare  LT, %4, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %6 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %7 = stablehlo.add %4, %6 : tensor<64xi64>
    %8 = stablehlo.select %5, %7, %4 : tensor<64xi1>, tensor<64xi64>
    %9 = stablehlo.reshape %8 : (tensor<64xi64>) -> tensor<64x1xi64>
    %10 = stablehlo.custom_call @tt.mark_argument(%arg0) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "l__self___key_states"}} : (tensor<1x8x64x128xf32>) -> tensor<1x8x64x128xf32>
    %11 = "stablehlo.scatter"(%1, %9, %10) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %12 = stablehlo.custom_call @Sharding(%11) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %12 : tensor<1x8x1024x128xf32>
  }
}


2025-09-25 17:44:02.149 (  45.969s) [        FA002000]      module_builder.cc:181      1| SHLO Module:
#loc1 = loc("p0.1")
#loc2 = loc("p1.3")
#loc3 = loc("p2.7")
#loc4 = loc("p3.19")
#loc15 = loc("scatter.25")
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} loc("p0.1"), %arg1: tensor<64xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}"} loc("p1.3"), %arg2: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}"} loc("p2.7"), %arg3: tensor<1x8x1024x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} loc("p3.19")) -> tensor<1x8x1024x128xf32> {
    %c = stablehlo.constant dense<0> : tensor<i64> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64> loc(#loc)
    %1 = stablehlo.custom_call @tt.mark_argument(%arg3) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_0"}} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32> loc(#loc5)
    %2 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64> loc(#loc6)
    %3 = stablehlo.custom_call @tt.mark_argument(%2) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "args_1"}} : (tensor<1x1x64xi64>) -> tensor<1x1x64xi64> loc(#loc7)
    %4 = stablehlo.reshape %3 : (tensor<1x1x64xi64>) -> tensor<64xi64> loc(#loc8)
    %5 = stablehlo.compare  LT, %4, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1> loc(#loc9)
    %6 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64> loc(#loc10)
    %7 = stablehlo.add %4, %6 : tensor<64xi64> loc(#loc11)
    %8 = stablehlo.select %5, %7, %4 : tensor<64xi1>, tensor<64xi64> loc(#loc12)
    %9 = stablehlo.reshape %8 : (tensor<64xi64>) -> tensor<64x1xi64> loc(#loc13)
    %10 = stablehlo.custom_call @tt.mark_argument(%arg0) {api_version = 0 : i32, mhlo.frontend_attributes = {ttcore.argument_type = "input", ttir.name = "l__self___key_states"}} : (tensor<1x8x64x128xf32>) -> tensor<1x8x64x128xf32> loc(#loc14)
    %11 = "stablehlo.scatter"(%1, %9, %10) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32> loc("scatter.25"), %arg5: tensor<f32> loc("scatter.25")):
      stablehlo.return %arg5 : tensor<f32> loc(#loc)
    }) : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32> loc(#loc15)
    %12 = stablehlo.custom_call @Sharding(%11) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32> loc(#loc16)
    return %12 : tensor<1x8x1024x128xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc5 = loc("custom-call.20")
#loc6 = loc("reshape.4")
#loc7 = loc("custom-call.5")
#loc8 = loc("reshape.6")
#loc9 = loc("compare.15")
#loc10 = loc("broadcast.11")
#loc11 = loc("add.12")
#loc12 = loc("select.16")
#loc13 = loc("reshape.17")
#loc14 = loc("custom-call.2")
#loc16 = loc("custom-call.27")
2025-09-25 17:44:02.151 (  45.971s) [        FA002000]      module_builder.cc:190      1| SHLO Module after frontend StableHLO pipeline:
#loc1 = loc("p0.1")
#loc2 = loc("p1.3")
#loc3 = loc("p2.7")
#loc4 = loc("p3.19")
#loc12 = loc("scatter.25")
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "l__self___key_states"} loc("p0.1"), %arg1: tensor<64xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"} loc("p1.3"), %arg2: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_0"} loc("p2.7"), %arg3: tensor<1x8x1024x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"} loc("p3.19")) -> tensor<1x8x1024x128xf32> {
    %c = stablehlo.constant dense<0> : tensor<i64> loc(#loc)
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64> loc(#loc)
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64> loc(#loc5)
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64> loc(#loc6)
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1> loc(#loc7)
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64> loc(#loc8)
    %5 = stablehlo.add %2, %4 : tensor<64xi64> loc(#loc9)
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64> loc(#loc10)
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64> loc(#loc11)
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32> loc("scatter.25"), %arg5: tensor<f32> loc("scatter.25")):
      stablehlo.return %arg5 : tensor<f32> loc(#loc)
    }) : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32> loc(#loc12)
    %9 = stablehlo.custom_call @Sharding(%8) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32> loc(#loc13)
    return %9 : tensor<1x8x1024x128xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc5 = loc("reshape.4")
#loc6 = loc("reshape.6")
#loc7 = loc("compare.15")
#loc8 = loc("broadcast.11")
#loc9 = loc("add.12")
#loc10 = loc("select.16")
#loc11 = loc("reshape.17")
#loc13 = loc("custom-call.27")
// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg2: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}) -> tensor<1x8x1024x128xf32> {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = stablehlo.custom_call @Sharding(%8) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %9 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg2: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}) -> tensor<1x8x1024x128xf32> {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = stablehlo.custom_call @Sharding(%8) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %9 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg2: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}) -> tensor<1x8x1024x128xf32> {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = stablehlo.custom_call @Sharding(%8) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %9 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_1"}, %arg2: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttir.name = "args_0"}) -> tensor<1x8x1024x128xf32> {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = stablehlo.custom_call @Sharding(%8) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %9 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump After ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = stablehlo.custom_call @Sharding(%8) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %9 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}]>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, []>"}, mhlo.sharding = "{replicated}", ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}, {}, {}]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}", ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = stablehlo.custom_call @Sharding(%8) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %9 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump After ConvertXlaSdyToSdyPass (convert-xla-sdy-to-sdy) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = stablehlo.custom_call @Sharding(%8) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    %10 = sdy.sharding_constraint %8 <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]> : tensor<1x8x1024x128xf32>
    return %10 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before AnalyzeMeshPass (analyze-mesh) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = stablehlo.custom_call @Sharding(%8) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    %10 = sdy.sharding_constraint %8 <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]> : tensor<1x8x1024x128xf32>
    return %10 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before ApplyShardingConstraintsPass (sdy-apply-sharding-constraints) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = stablehlo.custom_call @Sharding(%8) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    %10 = sdy.sharding_constraint %8 <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]> : tensor<1x8x1024x128xf32>
    return %10 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = stablehlo.custom_call @Sharding(%8) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{}, {\22_axis_0\22}, {}, {}]>]>"}, mhlo.sharding = "{devices=[1,2,1,1]<=[2]}"} : (tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    %10 = sdy.sharding_constraint %8 <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]> : tensor<1x8x1024x128xf32>
    return %10 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump After AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = sdy.sharding_constraint %8 <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]> : tensor<1x8x1024x128xf32>
    return %9 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before ShardingConstraintToReshardPass (sdy-sharding-constraint-to-reshard) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = sdy.sharding_constraint %8 <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]> : tensor<1x8x1024x128xf32>
    return %9 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump After ShardingConstraintToReshardPass (sdy-sharding-constraint-to-reshard) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = sdy.reshard %8 <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]> : tensor<1x8x1024x128xf32>
    return %9 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before InsertExplicitReshardsPass (sdy-insert-explicit-reshards) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = sdy.reshard %8 <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]> : tensor<1x8x1024x128xf32>
    return %9 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %c = stablehlo.constant dense<0> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %1 = stablehlo.reshape %arg1 : (tensor<64xi64>) -> tensor<1x1x64xi64>
    %2 = stablehlo.reshape %1 : (tensor<1x1x64xi64>) -> tensor<64xi64>
    %3 = stablehlo.compare  LT, %2, %0 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
    %4 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<i64>) -> tensor<64xi64>
    %5 = stablehlo.add %2, %4 : tensor<64xi64>
    %6 = stablehlo.select %3, %5, %2 : tensor<64xi1>, tensor<64xi64>
    %7 = stablehlo.reshape %6 : (tensor<64xi64>) -> tensor<64x1xi64>
    %8 = "stablehlo.scatter"(%arg3, %7, %arg0) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
    ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
      stablehlo.return %arg5 : tensor<f32>
    }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
    %9 = sdy.reshard %8 <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]> : tensor<1x8x1024x128xf32>
    return %9 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump After WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{?}]>, <@mesh, []>, <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>] out_shardings=[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>] manual_axes={} (%arg4: tensor<1x8x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x8x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
      %10 = sdy.reshard %9 <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]> : tensor<1x8x1024x128xf32>
      sdy.return %10 : tensor<1x8x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{?}]>, <@mesh, []>, <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>] out_shardings=[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>] manual_axes={} (%arg4: tensor<1x8x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x8x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
      %10 = sdy.reshard %9 <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]> : tensor<1x8x1024x128xf32>
      sdy.return %10 : tensor<1x8x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump After ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{?}]>, <@mesh, []>, <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>] out_shardings=[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>] manual_axes={} (%arg4: tensor<1x8x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x8x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
      sdy.return %9 : tensor<1x8x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before UpdateGlobalToLocalShapesPass (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {sdy.sharding = #sdy.sharding<@mesh, [{?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {sdy.sharding = #sdy.sharding<@mesh, []>, ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{?}]>, <@mesh, []>, <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>] out_shardings=[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>] manual_axes={} (%arg4: tensor<1x8x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x8x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>]>} : (tensor<1x8x1024x128xf32>, tensor<64x1xi64>, tensor<1x8x64x128xf32>) -> tensor<1x8x1024x128xf32>
      sdy.return %9 : tensor<1x8x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


ScatterOp debug info:
  UpdateWindowDims: 0, 1, 3
  InsertedWindowDims: 2
  ScatterDimsToOperandDims: 2
  Input sharding dims: inputDimShardings #1

inputDimShardings #2
"_axis_0",
inputDimShardings #3

inputDimShardings #4

Scatter axis is 2
Scatter axis 2 is orthogonal to sharding axes - safe cache update!
// -----// IR Dump After UpdateGlobalToLocalShapesPass (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{?}]>, <@mesh, []>, <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>] out_shardings=[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg4: tensor<1x4x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x4x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
      sdy.return %9 : tensor<1x4x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before CloseShardingsPass (sdy-close-shardings) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>, <@mesh, [{?}]>, <@mesh, []>, <@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>] out_shardings=[<@mesh, [{?}, {"_axis_0", ?}, {?}, {?}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg4: tensor<1x4x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x4x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
      sdy.return %9 : tensor<1x4x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump After CloseShardingsPass (sdy-close-shardings) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg4: tensor<1x4x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x4x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
      sdy.return %9 : tensor<1x4x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg4: tensor<1x4x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x4x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
      sdy.return %9 : tensor<1x4x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


2025-09-25 17:44:02.169 (  45.989s) [        FA002000]      module_builder.cc:473      1| SHLO Module after compiler StableHLO pipeline:
#loc1 = loc("p0.1")
#loc2 = loc("p1.3")
#loc3 = loc("p2.7")
#loc4 = loc("p3.19")
#loc12 = loc("scatter.25")
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]> loc(#loc)
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"} loc("p0.1"), %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p1.3"), %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"} loc("p2.7"), %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p3.19")) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg4: tensor<1x4x64x128xf32> loc("p0.1"), %arg5: tensor<64xi64> loc("p1.3"), %arg6: tensor<i64> loc("p2.7"), %arg7: tensor<1x4x1024x128xf32> loc("p3.19")) {
      %c = stablehlo.constant dense<0> : tensor<i64> loc(#loc)
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64> loc(#loc)
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64> loc(#loc5)
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64> loc(#loc6)
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1> loc(#loc7)
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64> loc(#loc8)
      %6 = stablehlo.add %3, %5 : tensor<64xi64> loc(#loc9)
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64> loc(#loc10)
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64> loc(#loc11)
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32> loc("scatter.25"), %arg9: tensor<f32> loc("scatter.25")):
        stablehlo.return %arg9 : tensor<f32> loc(#loc)
      }) : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32> loc(#loc12)
      sdy.return %9 : tensor<1x4x1024x128xf32> loc(#loc)
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32> loc(#loc)
    return %0 : tensor<1x8x1024x128xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc5 = loc("reshape.4")
#loc6 = loc("reshape.6")
#loc7 = loc("compare.15")
#loc8 = loc("broadcast.11")
#loc9 = loc("add.12")
#loc10 = loc("select.16")
#loc11 = loc("reshape.17")
// -----// IR Dump Before ConvertArithToStableHLO (convert-arith-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg4: tensor<1x4x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x4x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
      sdy.return %9 : tensor<1x4x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before LegalizeStableHLOCompositeToTTIR (legalize-stablehlo-composite-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg4: tensor<1x4x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x4x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
      sdy.return %9 : tensor<1x4x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before StablehloLegalizeCompositeToCallPass (stablehlo-legalize-composite-to-call) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg4: tensor<1x4x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x4x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
      sdy.return %9 : tensor<1x4x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg4: tensor<1x4x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x4x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
      sdy.return %9 : tensor<1x4x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg4: tensor<1x4x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x4x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
      sdy.return %9 : tensor<1x4x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before ConvertStableHLOToTTIR (convert-stablehlo-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["_axis_0_updated"=1, "_axis_0"=2]>
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = sdy.manual_computation(%arg0, %arg1, %arg2, %arg3) in_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>, <@mesh, [{}]>, <@mesh, []>, <@mesh, [{}, {"_axis_0"}, {}, {}]>] out_shardings=[<@mesh, [{}, {"_axis_0"}, {}, {}]>] manual_axes={"_axis_0_updated", "_axis_0"} (%arg4: tensor<1x4x64x128xf32>, %arg5: tensor<64xi64>, %arg6: tensor<i64>, %arg7: tensor<1x4x1024x128xf32>) {
      %c = stablehlo.constant dense<0> : tensor<i64>
      %1 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %2 = stablehlo.reshape %arg5 : (tensor<64xi64>) -> tensor<1x1x64xi64>
      %3 = stablehlo.reshape %2 : (tensor<1x1x64xi64>) -> tensor<64xi64>
      %4 = stablehlo.compare  LT, %3, %1 : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi1>
      %5 = stablehlo.broadcast_in_dim %arg6, dims = [] : (tensor<i64>) -> tensor<64xi64>
      %6 = stablehlo.add %3, %5 : tensor<64xi64>
      %7 = stablehlo.select %4, %6, %3 : tensor<64xi1>, tensor<64xi64>
      %8 = stablehlo.reshape %7 : (tensor<64xi64>) -> tensor<64x1xi64>
      %9 = "stablehlo.scatter"(%arg7, %8, %arg4) <{scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 3], inserted_window_dims = [2], scatter_dims_to_operand_dims = [2], index_vector_dim = 1>}> ({
      ^bb0(%arg8: tensor<f32>, %arg9: tensor<f32>):
        stablehlo.return %arg9 : tensor<f32>
      }) : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
      sdy.return %9 : tensor<1x4x1024x128xf32>
    } : (tensor<1x8x64x128xf32>, tensor<64xi64>, tensor<i64>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %0 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump After ConvertStableHLOToTTIR (convert-stablehlo-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = ttir.empty() : tensor<1x4x64x128xf32>
    %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
    %2 = ttir.empty() : tensor<64xi64>
    %3 = "ttir.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %4 = ttir.empty() : tensor<i64>
    %5 = "ttir.mesh_shard"(%arg2, %4) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<i64>, tensor<i64>) -> tensor<i64>
    %6 = ttir.empty() : tensor<1x4x1024x128xf32>
    %7 = "ttir.mesh_shard"(%arg3, %6) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
    %8 = "ttir.constant"() <{value = dense<0> : tensor<i64>}> : () -> tensor<i64>
    %9 = ttir.empty() : tensor<1xi64>
    %10 = "ttir.reshape"(%8, %9) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64>
    %11 = ttir.empty() : tensor<64xi64>
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xi64>, tensor<64xi64>) -> tensor<64xi64>
    %13 = ttir.empty() : tensor<1x1x64xi64>
    %14 = "ttir.reshape"(%3, %13) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xi64>, tensor<1x1x64xi64>) -> tensor<1x1x64xi64>
    %15 = ttir.empty() : tensor<64xi64>
    %16 = "ttir.reshape"(%14, %15) <{shape = [64 : i32]}> : (tensor<1x1x64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %17 = ttir.empty() : tensor<64xi1>
    %18 = "ttir.lt"(%16, %12, %17) : (tensor<64xi64>, tensor<64xi64>, tensor<64xi1>) -> tensor<64xi1>
    %19 = ttir.empty() : tensor<1xi64>
    %20 = "ttir.reshape"(%5, %19) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64>
    %21 = ttir.empty() : tensor<64xi64>
    %22 = "ttir.broadcast"(%20, %21) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xi64>, tensor<64xi64>) -> tensor<64xi64>
    %23 = ttir.empty() : tensor<64xi64>
    %24 = "ttir.add"(%16, %22, %23) : (tensor<64xi64>, tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %25 = ttir.empty() : tensor<64xi64>
    %26 = "ttir.where"(%18, %24, %16, %25) : (tensor<64xi1>, tensor<64xi64>, tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %27 = ttir.empty() : tensor<64x1xi64>
    %28 = "ttir.reshape"(%26, %27) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xi64>, tensor<64x1xi64>) -> tensor<64x1xi64>
    %29 = ttir.empty() : tensor<1x4x1024x128xf32>
    %30 = "ttir.scatter"(%7, %28, %1, %29) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
    %31 = ttir.empty() : tensor<1x8x1024x128xf32>
    %32 = "ttir.mesh_shard"(%30, %31) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %32 : tensor<1x8x1024x128xf32>
  }
}


2025-09-25 17:44:02.176 (  45.995s) [        FA002000]      module_builder.cc:499      1| TTIR Module:
#loc1 = loc("p0.1")
#loc2 = loc("p1.3")
#loc3 = loc("p2.7")
#loc4 = loc("p3.19")
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"} loc("p0.1"), %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p1.3"), %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"} loc("p2.7"), %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p3.19")) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = ttir.empty() : tensor<1x4x64x128xf32> loc(#loc)
    %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32> loc(#loc)
    %2 = ttir.empty() : tensor<64xi64> loc(#loc)
    %3 = "ttir.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64> loc(#loc)
    %4 = ttir.empty() : tensor<i64> loc(#loc)
    %5 = "ttir.mesh_shard"(%arg2, %4) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<i64>, tensor<i64>) -> tensor<i64> loc(#loc)
    %6 = ttir.empty() : tensor<1x4x1024x128xf32> loc(#loc)
    %7 = "ttir.mesh_shard"(%arg3, %6) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32> loc(#loc)
    %8 = "ttir.constant"() <{value = dense<0> : tensor<i64>}> : () -> tensor<i64> loc(#loc)
    %9 = ttir.empty() : tensor<1xi64> loc(#loc)
    %10 = "ttir.reshape"(%8, %9) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64> loc(#loc)
    %11 = ttir.empty() : tensor<64xi64> loc(#loc)
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xi64>, tensor<64xi64>) -> tensor<64xi64> loc(#loc)
    %13 = ttir.empty() : tensor<1x1x64xi64> loc(#loc5)
    %14 = "ttir.reshape"(%3, %13) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xi64>, tensor<1x1x64xi64>) -> tensor<1x1x64xi64> loc(#loc5)
    %15 = ttir.empty() : tensor<64xi64> loc(#loc6)
    %16 = "ttir.reshape"(%14, %15) <{shape = [64 : i32]}> : (tensor<1x1x64xi64>, tensor<64xi64>) -> tensor<64xi64> loc(#loc6)
    %17 = ttir.empty() : tensor<64xi1> loc(#loc7)
    %18 = "ttir.lt"(%16, %12, %17) : (tensor<64xi64>, tensor<64xi64>, tensor<64xi1>) -> tensor<64xi1> loc(#loc7)
    %19 = ttir.empty() : tensor<1xi64> loc(#loc8)
    %20 = "ttir.reshape"(%5, %19) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64> loc(#loc8)
    %21 = ttir.empty() : tensor<64xi64> loc(#loc8)
    %22 = "ttir.broadcast"(%20, %21) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xi64>, tensor<64xi64>) -> tensor<64xi64> loc(#loc8)
    %23 = ttir.empty() : tensor<64xi64> loc(#loc9)
    %24 = "ttir.add"(%16, %22, %23) : (tensor<64xi64>, tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64> loc(#loc9)
    %25 = ttir.empty() : tensor<64xi64> loc(#loc10)
    %26 = "ttir.where"(%18, %24, %16, %25) : (tensor<64xi1>, tensor<64xi64>, tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64> loc(#loc10)
    %27 = ttir.empty() : tensor<64x1xi64> loc(#loc11)
    %28 = "ttir.reshape"(%26, %27) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xi64>, tensor<64x1xi64>) -> tensor<64x1xi64> loc(#loc11)
    %29 = ttir.empty() : tensor<1x4x1024x128xf32> loc(#loc12)
    %30 = "ttir.scatter"(%7, %28, %1, %29) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32> loc(#loc12)
    %31 = ttir.empty() : tensor<1x8x1024x128xf32> loc(#loc)
    %32 = "ttir.mesh_shard"(%30, %31) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32> loc(#loc)
    return %32 : tensor<1x8x1024x128xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc5 = loc("reshape.4")
#loc6 = loc("reshape.6")
#loc7 = loc("compare.15")
#loc8 = loc("broadcast.11")
#loc9 = loc("add.12")
#loc10 = loc("select.16")
#loc11 = loc("reshape.17")
#loc12 = loc("scatter.25")
2025-09-25 17:44:02.177 (  45.997s) [        FA002000]      module_builder.cc:550   WARN| `mhlo.num_partitions` attribute not found, assuming default number of partitions: 1
2025-09-25 17:44:02.177 (  45.997s) [        FA002000]      module_builder.cc:564   WARN| `mhlo.num_replicas` attribute not found, assuming default number of replicas: 1
2025-09-25 17:44:02.177 (  45.997s) [        FA002000]      module_builder.cc:574   WARN| Num replicas and num partitions are not set, inferring the number of devices from mesh shape
// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = ttir.empty() : tensor<1x4x64x128xf32>
    %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
    %2 = ttir.empty() : tensor<64xi64>
    %3 = "ttir.mesh_shard"(%arg1, %2) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %4 = ttir.empty() : tensor<i64>
    %5 = "ttir.mesh_shard"(%arg2, %4) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<i64>, tensor<i64>) -> tensor<i64>
    %6 = ttir.empty() : tensor<1x4x1024x128xf32>
    %7 = "ttir.mesh_shard"(%arg3, %6) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
    %8 = "ttir.constant"() <{value = dense<0> : tensor<i64>}> : () -> tensor<i64>
    %9 = ttir.empty() : tensor<1xi64>
    %10 = "ttir.reshape"(%8, %9) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64>
    %11 = ttir.empty() : tensor<64xi64>
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xi64>, tensor<64xi64>) -> tensor<64xi64>
    %13 = ttir.empty() : tensor<1x1x64xi64>
    %14 = "ttir.reshape"(%3, %13) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xi64>, tensor<1x1x64xi64>) -> tensor<1x1x64xi64>
    %15 = ttir.empty() : tensor<64xi64>
    %16 = "ttir.reshape"(%14, %15) <{shape = [64 : i32]}> : (tensor<1x1x64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %17 = ttir.empty() : tensor<64xi1>
    %18 = "ttir.lt"(%16, %12, %17) : (tensor<64xi64>, tensor<64xi64>, tensor<64xi1>) -> tensor<64xi1>
    %19 = ttir.empty() : tensor<1xi64>
    %20 = "ttir.reshape"(%5, %19) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64>
    %21 = ttir.empty() : tensor<64xi64>
    %22 = "ttir.broadcast"(%20, %21) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xi64>, tensor<64xi64>) -> tensor<64xi64>
    %23 = ttir.empty() : tensor<64xi64>
    %24 = "ttir.add"(%16, %22, %23) : (tensor<64xi64>, tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %25 = ttir.empty() : tensor<64xi64>
    %26 = "ttir.where"(%18, %24, %16, %25) : (tensor<64xi1>, tensor<64xi64>, tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %27 = ttir.empty() : tensor<64x1xi64>
    %28 = "ttir.reshape"(%26, %27) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xi64>, tensor<64x1xi64>) -> tensor<64x1xi64>
    %29 = ttir.empty() : tensor<1x4x1024x128xf32>
    %30 = "ttir.scatter"(%7, %28, %1, %29) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
    %31 = ttir.empty() : tensor<1x8x1024x128xf32>
    %32 = "ttir.mesh_shard"(%30, %31) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %32 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.full"() <{fill_value = 0 : i32, shape = array<i32>}> : () -> tensor<i64>
    %1 = ttir.empty() : tensor<1x4x64x128xf32>
    %2 = "ttir.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
    %3 = ttir.empty() : tensor<64xi64>
    %4 = "ttir.mesh_shard"(%arg1, %3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %5 = ttir.empty() : tensor<i64>
    %6 = "ttir.mesh_shard"(%arg2, %5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<i64>, tensor<i64>) -> tensor<i64>
    %7 = ttir.empty() : tensor<1x4x1024x128xf32>
    %8 = "ttir.mesh_shard"(%arg3, %7) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
    %9 = ttir.empty() : tensor<1xi64>
    %10 = "ttir.reshape"(%0, %9) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64>
    %11 = ttir.empty() : tensor<64xi64>
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xi64>, tensor<64xi64>) -> tensor<64xi64>
    %13 = ttir.empty() : tensor<64xi1>
    %14 = "ttir.lt"(%4, %12, %13) : (tensor<64xi64>, tensor<64xi64>, tensor<64xi1>) -> tensor<64xi1>
    %15 = ttir.empty() : tensor<1xi64>
    %16 = "ttir.reshape"(%6, %15) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64>
    %17 = ttir.empty() : tensor<64xi64>
    %18 = "ttir.broadcast"(%16, %17) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xi64>, tensor<64xi64>) -> tensor<64xi64>
    %19 = ttir.empty() : tensor<64xi64>
    %20 = "ttir.add"(%4, %18, %19) : (tensor<64xi64>, tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %21 = ttir.empty() : tensor<64xi64>
    %22 = "ttir.where"(%14, %20, %4, %21) : (tensor<64xi1>, tensor<64xi64>, tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %23 = ttir.empty() : tensor<64x1xi64>
    %24 = "ttir.reshape"(%22, %23) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xi64>, tensor<64x1xi64>) -> tensor<64x1xi64>
    %25 = ttir.empty() : tensor<1x4x1024x128xf32>
    %26 = "ttir.scatter"(%8, %24, %2, %25) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
    %27 = ttir.empty() : tensor<1x8x1024x128xf32>
    %28 = "ttir.mesh_shard"(%26, %27) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %28 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before ElementTypeNormalization (ttir-element-type-normalization) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xi64> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<i64> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.full"() <{fill_value = 0 : i32, shape = array<i32>}> : () -> tensor<i64>
    %1 = ttir.empty() : tensor<1x4x64x128xf32>
    %2 = "ttir.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
    %3 = ttir.empty() : tensor<64xi64>
    %4 = "ttir.mesh_shard"(%arg1, %3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %5 = ttir.empty() : tensor<i64>
    %6 = "ttir.mesh_shard"(%arg2, %5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<i64>, tensor<i64>) -> tensor<i64>
    %7 = ttir.empty() : tensor<1x4x1024x128xf32>
    %8 = "ttir.mesh_shard"(%arg3, %7) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
    %9 = ttir.empty() : tensor<1xi64>
    %10 = "ttir.reshape"(%0, %9) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64>
    %11 = ttir.empty() : tensor<64xi64>
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xi64>, tensor<64xi64>) -> tensor<64xi64>
    %13 = ttir.empty() : tensor<64xi1>
    %14 = "ttir.lt"(%4, %12, %13) : (tensor<64xi64>, tensor<64xi64>, tensor<64xi1>) -> tensor<64xi1>
    %15 = ttir.empty() : tensor<1xi64>
    %16 = "ttir.reshape"(%6, %15) <{shape = [1 : i32]}> : (tensor<i64>, tensor<1xi64>) -> tensor<1xi64>
    %17 = ttir.empty() : tensor<64xi64>
    %18 = "ttir.broadcast"(%16, %17) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xi64>, tensor<64xi64>) -> tensor<64xi64>
    %19 = ttir.empty() : tensor<64xi64>
    %20 = "ttir.add"(%4, %18, %19) : (tensor<64xi64>, tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %21 = ttir.empty() : tensor<64xi64>
    %22 = "ttir.where"(%14, %20, %4, %21) : (tensor<64xi1>, tensor<64xi64>, tensor<64xi64>, tensor<64xi64>) -> tensor<64xi64>
    %23 = ttir.empty() : tensor<64x1xi64>
    %24 = "ttir.reshape"(%22, %23) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xi64>, tensor<64x1xi64>) -> tensor<64x1xi64>
    %25 = ttir.empty() : tensor<1x4x1024x128xf32>
    %26 = "ttir.scatter"(%8, %24, %2, %25) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xi64>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
    %27 = ttir.empty() : tensor<1x8x1024x128xf32>
    %28 = "ttir.mesh_shard"(%26, %27) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %28 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump After ElementTypeNormalization (ttir-element-type-normalization) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.full"() <{fill_value = 0 : i32, shape = array<i32>}> : () -> tensor<si32>
    %1 = ttir.empty() : tensor<1x4x64x128xf32>
    %2 = "ttir.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
    %3 = ttir.empty() : tensor<64xsi32>
    %4 = "ttir.mesh_shard"(%arg1, %3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
    %5 = ttir.empty() : tensor<si32>
    %6 = "ttir.mesh_shard"(%arg2, %5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<si32>, tensor<si32>) -> tensor<si32>
    %7 = ttir.empty() : tensor<1x4x1024x128xf32>
    %8 = "ttir.mesh_shard"(%arg3, %7) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
    %9 = ttir.empty() : tensor<1xsi32>
    %10 = "ttir.reshape"(%0, %9) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
    %11 = ttir.empty() : tensor<64xsi32>
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
    %13 = ttir.empty() : tensor<64xbf16>
    %14 = "ttir.lt"(%4, %12, %13) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xbf16>) -> tensor<64xbf16>
    %15 = ttir.empty() : tensor<1xsi32>
    %16 = "ttir.reshape"(%6, %15) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
    %17 = ttir.empty() : tensor<64xsi32>
    %18 = "ttir.broadcast"(%16, %17) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
    %19 = ttir.empty() : tensor<64xsi32>
    %20 = "ttir.add"(%4, %18, %19) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
    %21 = ttir.empty() : tensor<64xsi32>
    %22 = "ttir.where"(%14, %20, %4, %21) : (tensor<64xbf16>, tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
    %23 = ttir.empty() : tensor<64x1xsi32>
    %24 = "ttir.reshape"(%22, %23) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xsi32>, tensor<64x1xsi32>) -> tensor<64x1xsi32>
    %25 = ttir.empty() : tensor<1x4x1024x128xf32>
    %26 = "ttir.scatter"(%8, %24, %2, %25) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xsi32>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
    %27 = ttir.empty() : tensor<1x8x1024x128xf32>
    %28 = "ttir.mesh_shard"(%26, %27) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %28 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump Before TTCoreWrapDeviceModulePass (ttcore-wrap-device-module) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.full"() <{fill_value = 0 : i32, shape = array<i32>}> : () -> tensor<si32>
    %1 = ttir.empty() : tensor<1x4x64x128xf32>
    %2 = "ttir.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
    %3 = ttir.empty() : tensor<64xsi32>
    %4 = "ttir.mesh_shard"(%arg1, %3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
    %5 = ttir.empty() : tensor<si32>
    %6 = "ttir.mesh_shard"(%arg2, %5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<si32>, tensor<si32>) -> tensor<si32>
    %7 = ttir.empty() : tensor<1x4x1024x128xf32>
    %8 = "ttir.mesh_shard"(%arg3, %7) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
    %9 = ttir.empty() : tensor<1xsi32>
    %10 = "ttir.reshape"(%0, %9) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
    %11 = ttir.empty() : tensor<64xsi32>
    %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
    %13 = ttir.empty() : tensor<64xbf16>
    %14 = "ttir.lt"(%4, %12, %13) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xbf16>) -> tensor<64xbf16>
    %15 = ttir.empty() : tensor<1xsi32>
    %16 = "ttir.reshape"(%6, %15) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
    %17 = ttir.empty() : tensor<64xsi32>
    %18 = "ttir.broadcast"(%16, %17) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
    %19 = ttir.empty() : tensor<64xsi32>
    %20 = "ttir.add"(%4, %18, %19) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
    %21 = ttir.empty() : tensor<64xsi32>
    %22 = "ttir.where"(%14, %20, %4, %21) : (tensor<64xbf16>, tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
    %23 = ttir.empty() : tensor<64x1xsi32>
    %24 = "ttir.reshape"(%22, %23) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xsi32>, tensor<64x1xsi32>) -> tensor<64x1xsi32>
    %25 = ttir.empty() : tensor<1x4x1024x128xf32>
    %26 = "ttir.scatter"(%8, %24, %2, %25) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xsi32>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
    %27 = ttir.empty() : tensor<1x8x1024x128xf32>
    %28 = "ttir.mesh_shard"(%26, %27) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
    return %28 : tensor<1x8x1024x128xf32>
  }
}


// -----// IR Dump After TTCoreWrapDeviceModulePass (ttcore-wrap-device-module) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = 0 : i32, shape = array<i32>}> : () -> tensor<si32>
        %1 = ttir.empty() : tensor<1x4x64x128xf32>
        %2 = "ttir.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %3 = ttir.empty() : tensor<64xsi32>
        %4 = "ttir.mesh_shard"(%arg1, %3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %5 = ttir.empty() : tensor<si32>
        %6 = "ttir.mesh_shard"(%arg2, %5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<si32>, tensor<si32>) -> tensor<si32>
        %7 = ttir.empty() : tensor<1x4x1024x128xf32>
        %8 = "ttir.mesh_shard"(%arg3, %7) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %9 = ttir.empty() : tensor<1xsi32>
        %10 = "ttir.reshape"(%0, %9) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %11 = ttir.empty() : tensor<64xsi32>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %13 = ttir.empty() : tensor<64xbf16>
        %14 = "ttir.lt"(%4, %12, %13) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xbf16>) -> tensor<64xbf16>
        %15 = ttir.empty() : tensor<1xsi32>
        %16 = "ttir.reshape"(%6, %15) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %17 = ttir.empty() : tensor<64xsi32>
        %18 = "ttir.broadcast"(%16, %17) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %19 = ttir.empty() : tensor<64xsi32>
        %20 = "ttir.add"(%4, %18, %19) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %21 = ttir.empty() : tensor<64xsi32>
        %22 = "ttir.where"(%14, %20, %4, %21) : (tensor<64xbf16>, tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %23 = ttir.empty() : tensor<64x1xsi32>
        %24 = "ttir.reshape"(%22, %23) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xsi32>, tensor<64x1xsi32>) -> tensor<64x1xsi32>
        %25 = ttir.empty() : tensor<1x4x1024x128xf32>
        %26 = "ttir.scatter"(%8, %24, %2, %25) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xsi32>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %27 = ttir.empty() : tensor<1x8x1024x128xf32>
        %28 = "ttir.mesh_shard"(%26, %27) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %28 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRHoistTransform (ttir-cpu-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = 0 : i32, shape = array<i32>}> : () -> tensor<si32>
        %1 = ttir.empty() : tensor<1x4x64x128xf32>
        %2 = "ttir.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %3 = ttir.empty() : tensor<64xsi32>
        %4 = "ttir.mesh_shard"(%arg1, %3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %5 = ttir.empty() : tensor<si32>
        %6 = "ttir.mesh_shard"(%arg2, %5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<si32>, tensor<si32>) -> tensor<si32>
        %7 = ttir.empty() : tensor<1x4x1024x128xf32>
        %8 = "ttir.mesh_shard"(%arg3, %7) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %9 = ttir.empty() : tensor<1xsi32>
        %10 = "ttir.reshape"(%0, %9) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %11 = ttir.empty() : tensor<64xsi32>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %13 = ttir.empty() : tensor<64xbf16>
        %14 = "ttir.lt"(%4, %12, %13) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xbf16>) -> tensor<64xbf16>
        %15 = ttir.empty() : tensor<1xsi32>
        %16 = "ttir.reshape"(%6, %15) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %17 = ttir.empty() : tensor<64xsi32>
        %18 = "ttir.broadcast"(%16, %17) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %19 = ttir.empty() : tensor<64xsi32>
        %20 = "ttir.add"(%4, %18, %19) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %21 = ttir.empty() : tensor<64xsi32>
        %22 = "ttir.where"(%14, %20, %4, %21) : (tensor<64xbf16>, tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %23 = ttir.empty() : tensor<64x1xsi32>
        %24 = "ttir.reshape"(%22, %23) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xsi32>, tensor<64x1xsi32>) -> tensor<64x1xsi32>
        %25 = ttir.empty() : tensor<1x4x1024x128xf32>
        %26 = "ttir.scatter"(%8, %24, %2, %25) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xsi32>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %27 = ttir.empty() : tensor<1x8x1024x128xf32>
        %28 = "ttir.mesh_shard"(%26, %27) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %28 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTCoreRegisterDevicePass (ttcore-register-device) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = 0 : i32, shape = array<i32>}> : () -> tensor<si32>
        %1 = ttir.empty() : tensor<1x4x64x128xf32>
        %2 = "ttir.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %3 = ttir.empty() : tensor<64xsi32>
        %4 = "ttir.mesh_shard"(%arg1, %3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %5 = ttir.empty() : tensor<si32>
        %6 = "ttir.mesh_shard"(%arg2, %5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<si32>, tensor<si32>) -> tensor<si32>
        %7 = ttir.empty() : tensor<1x4x1024x128xf32>
        %8 = "ttir.mesh_shard"(%arg3, %7) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %9 = ttir.empty() : tensor<1xsi32>
        %10 = "ttir.reshape"(%0, %9) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %11 = ttir.empty() : tensor<64xsi32>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %13 = ttir.empty() : tensor<64xbf16>
        %14 = "ttir.lt"(%4, %12, %13) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xbf16>) -> tensor<64xbf16>
        %15 = ttir.empty() : tensor<1xsi32>
        %16 = "ttir.reshape"(%6, %15) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %17 = ttir.empty() : tensor<64xsi32>
        %18 = "ttir.broadcast"(%16, %17) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %19 = ttir.empty() : tensor<64xsi32>
        %20 = "ttir.add"(%4, %18, %19) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %21 = ttir.empty() : tensor<64xsi32>
        %22 = "ttir.where"(%14, %20, %4, %21) : (tensor<64xbf16>, tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %23 = ttir.empty() : tensor<64x1xsi32>
        %24 = "ttir.reshape"(%22, %23) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xsi32>, tensor<64x1xsi32>) -> tensor<64x1xsi32>
        %25 = ttir.empty() : tensor<1x4x1024x128xf32>
        %26 = "ttir.scatter"(%8, %24, %2, %25) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xsi32>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %27 = ttir.empty() : tensor<1x8x1024x128xf32>
        %28 = "ttir.mesh_shard"(%26, %27) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %28 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump After TTCoreRegisterDevicePass (ttcore-register-device) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = 0 : i32, shape = array<i32>}> : () -> tensor<si32>
        %1 = ttir.empty() : tensor<1x4x64x128xf32>
        %2 = "ttir.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %3 = ttir.empty() : tensor<64xsi32>
        %4 = "ttir.mesh_shard"(%arg1, %3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %5 = ttir.empty() : tensor<si32>
        %6 = "ttir.mesh_shard"(%arg2, %5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<si32>, tensor<si32>) -> tensor<si32>
        %7 = ttir.empty() : tensor<1x4x1024x128xf32>
        %8 = "ttir.mesh_shard"(%arg3, %7) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %9 = ttir.empty() : tensor<1xsi32>
        %10 = "ttir.reshape"(%0, %9) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %11 = ttir.empty() : tensor<64xsi32>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %13 = ttir.empty() : tensor<64xbf16>
        %14 = "ttir.lt"(%4, %12, %13) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xbf16>) -> tensor<64xbf16>
        %15 = ttir.empty() : tensor<1xsi32>
        %16 = "ttir.reshape"(%6, %15) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %17 = ttir.empty() : tensor<64xsi32>
        %18 = "ttir.broadcast"(%16, %17) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %19 = ttir.empty() : tensor<64xsi32>
        %20 = "ttir.add"(%4, %18, %19) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %21 = ttir.empty() : tensor<64xsi32>
        %22 = "ttir.where"(%14, %20, %4, %21) : (tensor<64xbf16>, tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %23 = ttir.empty() : tensor<64x1xsi32>
        %24 = "ttir.reshape"(%22, %23) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xsi32>, tensor<64x1xsi32>) -> tensor<64x1xsi32>
        %25 = ttir.empty() : tensor<1x4x1024x128xf32>
        %26 = "ttir.scatter"(%8, %24, %2, %25) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xsi32>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %27 = ttir.empty() : tensor<1x8x1024x128xf32>
        %28 = "ttir.mesh_shard"(%26, %27) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %28 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = 0 : i32, shape = array<i32>}> : () -> tensor<si32>
        %1 = ttir.empty() : tensor<1x4x64x128xf32>
        %2 = "ttir.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %3 = ttir.empty() : tensor<64xsi32>
        %4 = "ttir.mesh_shard"(%arg1, %3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %5 = ttir.empty() : tensor<si32>
        %6 = "ttir.mesh_shard"(%arg2, %5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<si32>, tensor<si32>) -> tensor<si32>
        %7 = ttir.empty() : tensor<1x4x1024x128xf32>
        %8 = "ttir.mesh_shard"(%arg3, %7) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %9 = ttir.empty() : tensor<1xsi32>
        %10 = "ttir.reshape"(%0, %9) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %11 = ttir.empty() : tensor<64xsi32>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %13 = ttir.empty() : tensor<64xbf16>
        %14 = "ttir.lt"(%4, %12, %13) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xbf16>) -> tensor<64xbf16>
        %15 = ttir.empty() : tensor<1xsi32>
        %16 = "ttir.reshape"(%6, %15) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %17 = ttir.empty() : tensor<64xsi32>
        %18 = "ttir.broadcast"(%16, %17) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %19 = ttir.empty() : tensor<64xsi32>
        %20 = "ttir.add"(%4, %18, %19) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %21 = ttir.empty() : tensor<64xsi32>
        %22 = "ttir.where"(%14, %20, %4, %21) : (tensor<64xbf16>, tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %23 = ttir.empty() : tensor<64x1xsi32>
        %24 = "ttir.reshape"(%22, %23) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xsi32>, tensor<64x1xsi32>) -> tensor<64x1xsi32>
        %25 = ttir.empty() : tensor<1x4x1024x128xf32>
        %26 = "ttir.scatter"(%8, %24, %2, %25) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xsi32>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %27 = ttir.empty() : tensor<1x8x1024x128xf32>
        %28 = "ttir.mesh_shard"(%26, %27) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %28 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = 0 : i32, shape = array<i32>}> : () -> tensor<si32>
        %1 = ttir.empty() : tensor<1x4x64x128xf32>
        %2 = "ttir.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %3 = ttir.empty() : tensor<64xsi32>
        %4 = "ttir.mesh_shard"(%arg1, %3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %5 = ttir.empty() : tensor<si32>
        %6 = "ttir.mesh_shard"(%arg2, %5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<si32>, tensor<si32>) -> tensor<si32>
        %7 = ttir.empty() : tensor<1x4x1024x128xf32>
        %8 = "ttir.mesh_shard"(%arg3, %7) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %9 = ttir.empty() : tensor<1xsi32>
        %10 = "ttir.reshape"(%0, %9) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %11 = ttir.empty() : tensor<64xsi32>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %13 = ttir.empty() : tensor<64xbf16>
        %14 = "ttir.lt"(%4, %12, %13) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xbf16>) -> tensor<64xbf16>
        %15 = ttir.empty() : tensor<1xsi32>
        %16 = "ttir.reshape"(%6, %15) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %17 = ttir.empty() : tensor<64xsi32>
        %18 = "ttir.broadcast"(%16, %17) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %19 = ttir.empty() : tensor<64xsi32>
        %20 = "ttir.add"(%4, %18, %19) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %21 = ttir.empty() : tensor<64xsi32>
        %22 = "ttir.where"(%14, %20, %4, %21) : (tensor<64xbf16>, tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %23 = ttir.empty() : tensor<64x1xsi32>
        %24 = "ttir.reshape"(%22, %23) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xsi32>, tensor<64x1xsi32>) -> tensor<64x1xsi32>
        %25 = ttir.empty() : tensor<1x4x1024x128xf32>
        %26 = "ttir.scatter"(%8, %24, %2, %25) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xsi32>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %27 = ttir.empty() : tensor<1x8x1024x128xf32>
        %28 = "ttir.mesh_shard"(%26, %27) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %28 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.full"() <{fill_value = 0 : i32, shape = array<i32>}> : () -> tensor<si32>
        %1 = ttir.empty() : tensor<1x4x64x128xf32>
        %2 = "ttir.mesh_shard"(%arg0, %1) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %3 = ttir.empty() : tensor<64xsi32>
        %4 = "ttir.mesh_shard"(%arg1, %3) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %5 = ttir.empty() : tensor<si32>
        %6 = "ttir.mesh_shard"(%arg2, %5) <{shard_dims = array<i64: -1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<si32>, tensor<si32>) -> tensor<si32>
        %7 = ttir.empty() : tensor<1x4x1024x128xf32>
        %8 = "ttir.mesh_shard"(%arg3, %7) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %9 = ttir.empty() : tensor<1xsi32>
        %10 = "ttir.reshape"(%0, %9) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %11 = ttir.empty() : tensor<64xsi32>
        %12 = "ttir.broadcast"(%10, %11) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %13 = ttir.empty() : tensor<64xbf16>
        %14 = "ttir.lt"(%4, %12, %13) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xbf16>) -> tensor<64xbf16>
        %15 = ttir.empty() : tensor<1xsi32>
        %16 = "ttir.reshape"(%6, %15) <{shape = [1 : i32]}> : (tensor<si32>, tensor<1xsi32>) -> tensor<1xsi32>
        %17 = ttir.empty() : tensor<64xsi32>
        %18 = "ttir.broadcast"(%16, %17) <{broadcast_dimensions = array<i64: 64>}> : (tensor<1xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %19 = ttir.empty() : tensor<64xsi32>
        %20 = "ttir.add"(%4, %18, %19) : (tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %21 = ttir.empty() : tensor<64xsi32>
        %22 = "ttir.where"(%14, %20, %4, %21) : (tensor<64xbf16>, tensor<64xsi32>, tensor<64xsi32>, tensor<64xsi32>) -> tensor<64xsi32>
        %23 = ttir.empty() : tensor<64x1xsi32>
        %24 = "ttir.reshape"(%22, %23) <{shape = [64 : i32, 1 : i32]}> : (tensor<64xsi32>, tensor<64x1xsi32>) -> tensor<64x1xsi32>
        %25 = ttir.empty() : tensor<1x4x1024x128xf32>
        %26 = "ttir.scatter"(%8, %24, %2, %25) <{index_vector_dim = 1 : i32, indices_are_sorted = false, input_batching_dims = array<i32>, inserted_window_dims = array<i32: 2>, scatter_dims_to_operand_dims = array<i32: 2>, scatter_indices_batching_dims = array<i32>, unique_indices = false, update_window_dims = array<i32: 0, 1, 3>}> : (tensor<1x4x1024x128xf32>, tensor<64x1xsi32>, tensor<1x4x64x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %27 = ttir.empty() : tensor<1x8x1024x128xf32>
        %28 = "ttir.mesh_shard"(%26, %27) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %28 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump After TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRQuantDequantConversion (ttir-quant-dequant-conversion) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRToTTIRDecomposition (ttir-to-ttir-decomposition) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRFlattenSlidingWindow (ttir-flatten-sliding-window) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRExplicateTMs (ttir-explicate-tms) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIREraseInverseOps (ttir-erase-inverse-ops) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRImplicitBroadcastFold (ttir-implicit-broadcast-fold) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRQuantDataTypeConversionPass (ttir-quant-data-type-conversion) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTNNLayout (ttnn-layout) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x64x128xf32>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32>, tensor<1x4x1024x128xf32>) -> tensor<1x4x1024x128xf32>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32>, tensor<1x4x64x128xf32>) -> tensor<1x4x1024x128xf32>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32>
        %6 = "ttir.mesh_shard"(%4, %5) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32>, tensor<1x8x1024x128xf32>) -> tensor<1x8x1024x128xf32>
        return %6 : tensor<1x8x1024x128xf32>
      }
    }
  }
}


// -----// IR Dump After TTNNLayout (ttnn-layout) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32, #ttnn_layout5>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32, #ttnn_layout6>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32, #ttnn_layout3>
        %6 = ttir.empty() : tensor<1x4x1024x128xf32, #ttnn_layout7>
        %7 = ttir.to_layout %4, %6 : tensor<1x4x1024x128xf32, #ttnn_layout6> into tensor<1x4x1024x128xf32, #ttnn_layout7> -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %8 = ttir.empty() : tensor<1x8x1024x128xf32, #ttnn_layout4>
        %9 = ttir.to_layout %5, %8 : tensor<1x8x1024x128xf32, #ttnn_layout3> into tensor<1x8x1024x128xf32, #ttnn_layout4> -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        %10 = "ttir.mesh_shard"(%7, %9) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>, tensor<1x8x1024x128xf32, #ttnn_layout4>) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        return %10 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before ConvertTTIRToTTNN (convert-ttir-to-ttnn) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<1x4x64x128xf32, #ttnn_layout5>
        %1 = "ttir.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %2 = ttir.empty() : tensor<1x4x1024x128xf32, #ttnn_layout6>
        %3 = "ttir.mesh_shard"(%arg3, %2) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        %4 = "ttir.fill_cache"(%3, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        %5 = ttir.empty() : tensor<1x8x1024x128xf32, #ttnn_layout3>
        %6 = ttir.empty() : tensor<1x4x1024x128xf32, #ttnn_layout7>
        %7 = ttir.to_layout %4, %6 : tensor<1x4x1024x128xf32, #ttnn_layout6> into tensor<1x4x1024x128xf32, #ttnn_layout7> -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %8 = ttir.empty() : tensor<1x8x1024x128xf32, #ttnn_layout4>
        %9 = ttir.to_layout %5, %8 : tensor<1x8x1024x128xf32, #ttnn_layout3> into tensor<1x8x1024x128xf32, #ttnn_layout4> -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        %10 = "ttir.mesh_shard"(%7, %9) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>, tensor<1x8x1024x128xf32, #ttnn_layout4>) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        return %10 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump After ConvertTTIRToTTNN (convert-ttir-to-ttnn) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x4x64x128>}> : (!ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %2 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, !ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %3 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x4x1024x128>}> : (!ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        %4 = "ttnn.mesh_shard"(%arg3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, !ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        "ttnn.fill_cache"(%4, %2) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> ()
        %5 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x8x1024x128>}> : (!ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout3>
        %6 = "ttnn.zeros"() <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, shape = #ttnn.shape<1x4x1024x128>}> : () -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %7 = "ttnn.to_layout"(%4) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %8 = "ttnn.zeros"() <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, shape = #ttnn.shape<1x8x1024x128>}> : () -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        %9 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        %10 = "ttnn.mesh_shard"(%7, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>, !ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        return %10 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before TTNNFusing (ttnn-fusing) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x4x64x128>}> : (!ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %2 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, !ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %3 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x4x1024x128>}> : (!ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        %4 = "ttnn.mesh_shard"(%arg3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, !ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        "ttnn.fill_cache"(%4, %2) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> ()
        %5 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<1x8x1024x128>}> : (!ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout3>
        %6 = "ttnn.zeros"() <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, shape = #ttnn.shape<1x4x1024x128>}> : () -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %7 = "ttnn.to_layout"(%4) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %8 = "ttnn.zeros"() <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, shape = #ttnn.shape<1x8x1024x128>}> : () -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        %9 = "ttnn.to_layout"(%5) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        %10 = "ttnn.mesh_shard"(%7, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>, !ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        return %10 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump After TTNNFusing (ttnn-fusing) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, !ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %2 = "ttnn.mesh_shard"(%arg3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, !ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        "ttnn.fill_cache"(%2, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> ()
        %3 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %4 = "ttnn.mesh_shard"(%3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>, !ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        return %4 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before TTNNWorkarounds (ttnn-workaround) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, !ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %2 = "ttnn.mesh_shard"(%arg3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, !ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        "ttnn.fill_cache"(%2, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> ()
        %3 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %4 = "ttnn.mesh_shard"(%3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>, !ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        return %4 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, !ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %2 = "ttnn.mesh_shard"(%arg3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, !ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        "ttnn.fill_cache"(%2, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> ()
        %3 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %4 = "ttnn.mesh_shard"(%3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>, !ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        return %4 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, !ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %2 = "ttnn.mesh_shard"(%arg3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, !ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        "ttnn.fill_cache"(%2, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> ()
        %3 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %4 = "ttnn.mesh_shard"(%3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>, !ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        return %4 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, !ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %2 = "ttnn.mesh_shard"(%arg3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, !ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        "ttnn.fill_cache"(%2, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> ()
        %3 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %4 = "ttnn.mesh_shard"(%3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>, !ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        return %4 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before TTNNDecomposeLayouts (ttnn-decompose-layouts) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, !ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %2 = "ttnn.mesh_shard"(%arg3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, !ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        "ttnn.fill_cache"(%2, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> ()
        %3 = "ttnn.to_layout"(%2) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<row_major>, memory_config = #ttnn.memory_config<#system_memory>}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %4 = "ttnn.mesh_shard"(%3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>, !ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        return %4 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump After TTNNDecomposeLayouts (ttnn-decompose-layouts) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #system_memory>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, !ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %2 = "ttnn.mesh_shard"(%arg3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, !ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        "ttnn.fill_cache"(%2, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> ()
        %3 = "ttnn.from_device"(%2) : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>) -> tensor<1x4x1024x128xf32, #ttnn_layout8>
        %5 = "ttnn.mesh_shard"(%4, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout8>, !ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        return %5 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before TTCoreOptimizationBarrierFold (ttcore-optimization-barrier-fold) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #system_memory>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, !ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %2 = "ttnn.mesh_shard"(%arg3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, !ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        "ttnn.fill_cache"(%2, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> ()
        %3 = "ttnn.from_device"(%2) : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>) -> tensor<1x4x1024x128xf32, #ttnn_layout8>
        %5 = "ttnn.mesh_shard"(%4, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout8>, !ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        return %5 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump Before TTNNDeallocate (ttnn-deallocate) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #system_memory>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, !ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        %2 = "ttnn.mesh_shard"(%arg3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, !ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        "ttnn.fill_cache"(%2, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> ()
        %3 = "ttnn.from_device"(%2) : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>) -> tensor<1x4x1024x128xf32, #ttnn_layout8>
        %5 = "ttnn.mesh_shard"(%4, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout8>, !ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        return %5 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


// -----// IR Dump After TTNNDeallocate (ttnn-deallocate) ('builtin.module' operation: @SyncTensorsGraph.29) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #system_memory>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"}, %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"}, %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"}, %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"}) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<si32, #ttnn_layout2>) -> ()
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<64xsi32, #ttnn_layout1>) -> ()
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, !ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5>
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<1x8x64x128xf32, #ttnn_layout>) -> ()
        %2 = "ttnn.mesh_shard"(%arg3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, !ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6>
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>) -> ()
        "ttnn.fill_cache"(%2, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> ()
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x4x64x128xf32, #ttnn_layout5>) -> ()
        %3 = "ttnn.from_device"(%2) : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout7>
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> ()
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>) -> tensor<1x4x1024x128xf32, #ttnn_layout8>
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>) -> ()
        %5 = "ttnn.mesh_shard"(%4, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout8>, !ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout4>
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1x4x1024x128xf32, #ttnn_layout8>) -> ()
        return %5 : tensor<1x8x1024x128xf32, #ttnn_layout4>
      }
    }
  }
}


2025-09-25 17:44:02.231 (  46.051s) [        FA002000]      module_builder.cc:621      1| TTNN Module:
#dram = #ttnn.buffer_type<dram>
#loc1 = loc("p0.1")
#loc2 = loc("p1.3")
#loc3 = loc("p2.7")
#loc4 = loc("p3.19")
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073184544, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99808, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073192864, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#system_memory = #ttnn.buffer_type<system_memory>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 512 + d1 * 64 + d2, d3), <1x1>, memref<16x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0) -> (0, d0), <1x1>, memref<1x2x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout2 = #ttnn.ttnn_layout<() -> (0, 0), <1x1>, memref<1x1x!ttcore.tile<32x32, si32>, #dram>, <interleaved>>
#ttnn_layout3 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<256x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout4 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 8192 + d1 * 1024 + d2, d3), <1x1>, memref<8192x128xf32, #system_memory>>
#ttnn_layout5 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 256 + d1 * 64 + d2, d3), <1x1>, memref<8x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout6 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout7 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<128x4x!ttcore.tile<32x32, f32>, #system_memory>>
#ttnn_layout8 = #ttnn.ttnn_layout<(d0, d1, d2, d3) -> (d0 * 4096 + d1 * 1024 + d2, d3), <1x1>, memref<4096x128xf32, #system_memory>>
module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.29 attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]> loc(#loc)
      func.func @main(%arg0: tensor<1x8x64x128xf32, #ttnn_layout> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "l__self___key_states"} loc("p0.1"), %arg1: tensor<64xsi32, #ttnn_layout1> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_1"} loc("p1.3"), %arg2: tensor<si32, #ttnn_layout2> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "auto_annotated_const_0"} loc("p2.7"), %arg3: tensor<1x8x1024x128xf32, #ttnn_layout3> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<presharded>, ttir.name = "args_0"} loc("p3.19")) -> (tensor<1x8x1024x128xf32, #ttnn_layout4> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device loc(#loc)
        "ttnn.deallocate"(%arg2) <{force = false}> : (tensor<si32, #ttnn_layout2>) -> () loc(#loc)
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<64xsi32, #ttnn_layout1>) -> () loc(#loc)
        %1 = "ttnn.mesh_shard"(%arg0, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x64x128xf32, #ttnn_layout>, !ttnn.device) -> tensor<1x4x64x128xf32, #ttnn_layout5> loc(#loc)
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<1x8x64x128xf32, #ttnn_layout>) -> () loc(#loc)
        %2 = "ttnn.mesh_shard"(%arg3, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<full_to_shard>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<identity>}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>, !ttnn.device) -> tensor<1x4x1024x128xf32, #ttnn_layout6> loc(#loc)
        "ttnn.deallocate"(%arg3) <{force = false}> : (tensor<1x8x1024x128xf32, #ttnn_layout3>) -> () loc(#loc)
        "ttnn.fill_cache"(%2, %1) <{batch_offset = 0 : i32}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>, tensor<1x4x64x128xf32, #ttnn_layout5>) -> () loc(#loc5)
        "ttnn.deallocate"(%1) <{force = false}> : (tensor<1x4x64x128xf32, #ttnn_layout5>) -> () loc(#loc5)
        %3 = "ttnn.from_device"(%2) : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> tensor<1x4x1024x128xf32, #ttnn_layout7> loc(#loc)
        "ttnn.deallocate"(%2) <{force = false}> : (tensor<1x4x1024x128xf32, #ttnn_layout6>) -> () loc(#loc)
        %4 = "ttnn.to_layout"(%3) <{layout = #ttnn.layout<row_major>}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>) -> tensor<1x4x1024x128xf32, #ttnn_layout8> loc(#loc)
        "ttnn.deallocate"(%3) <{force = false}> : (tensor<1x4x1024x128xf32, #ttnn_layout7>) -> () loc(#loc)
        %5 = "ttnn.mesh_shard"(%4, %0) <{shard_dims = array<i64: -1, 1>, shard_direction = #ttcore.shard_direction<shard_to_full>, shard_shape = array<i64: 1, 2, 1, 1>, shard_type = #ttcore.shard_type<devices>}> : (tensor<1x4x1024x128xf32, #ttnn_layout8>, !ttnn.device) -> tensor<1x8x1024x128xf32, #ttnn_layout4> loc(#loc)
        "ttnn.deallocate"(%4) <{force = false}> : (tensor<1x4x1024x128xf32, #ttnn_layout8>) -> () loc(#loc)
        return %5 : tensor<1x8x1024x128xf32, #ttnn_layout4> loc(#loc)
      } loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc5 = loc("scatter.25")
2025-09-25 17:44:02.234 (  46.054s) [        FA002000]loaded_executable_insta:426      1| LoadedExecutableInstance::PJRT_LoadedExecutable_GetExecutable
2025-09-25 17:44:02.234 (  46.054s) [        FA002000]loaded_executable_insta:445      1| LoadedExecutableInstance::PJRT_LoadedExecutable_AddressableDevices
2025-09-25 17:44:02.235 (  46.054s) [        FA002000]              stubs.inc:70    WARN| STUB: PJRT_Executable_GetCompiledMemoryStats
2025-09-25 17:44:02.235 (  46.054s) [        FA002000]      error_instance.cc:49       1| ErrorInstance::PJRT_Error_Message
2025-09-25 17:44:02.235 (  46.054s) [        FA002000]      error_instance.cc:58       1| ErrorInstance::PJRT_Error_GetCode
2025-09-25 17:44:02.235 (  46.054s) [        FA002000]      error_instance.cc:43       1| ErrorInstance::PJRT_Error_Destroy
2025-09-25 17:44:02.235 (  46.054s) [        FA002000] executable_instance.cc:107      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-25 17:44:02.235 (  46.054s) [        FA002000] executable_instance.cc:107      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-25 17:44:02.240 (  46.059s) [        FA002000] executable_instance.cc:107      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-25 17:44:02.240 (  46.059s) [        FA002000] executable_instance.cc:107      1| ExecutableInstance::PJRT_Executable_OptimizedProgram
2025-09-25 17:44:02.250 (  46.070s) [        A9FFB640]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:02.250 (  46.070s) [        A9FFB640]  device_description.cc:44       1| DeviceDescription::PJRT_DeviceDescription_Id
2025-09-25 17:44:02.250 (  46.070s) [        A9FFB640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-25 17:44:02.250 (  46.070s) [        A9FFB640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-25 17:44:02.250 (  46.070s) [        A9FFB640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-25 17:44:02.250 (  46.070s) [        A9FFB640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-25 17:44:02.250 (  46.070s) [        A9FFB640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-25 17:44:02.250 (  46.070s) [        A9FFB640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-25 17:44:02.250 (  46.070s) [        A9FFB640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]     buffer_instance.cc:553      1| BufferInstance::PJRT_Buffer_Device
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]     device_instance.cc:53       1| DeviceInstance::PJRT_Device_IsAddressable
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640] executable_instance.cc:139      1| ExecutableInstance::PJRT_Executable_NumOutputs
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]loaded_executable_insta:482      1| LoadedExecutableInstance::PJRT_LoadedExecutable_Execute
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]loaded_executable_insta:88       1| LoadedExecutableInstance::Execute
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]     client_instance.cc:360      1| ClientInstance::getOrCreateMeshDevice - reusing already opened mesh device [1, 2]
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]loaded_executable_insta:229   INFO| EXEC_TRACE: Input arg_index=0 device_index=0 BufferInstance=0x23c87b30 shape=[1,4,64,128] m_runtime_tensor.data=0x7f39a9ff9d50 tensor.handle=0x7f39a9ff9da0
2025-09-25 17:44:02.251 (  46.070s) [        A9FFB640]loaded_executable_insta:229   INFO| EXEC_TRACE: Input arg_index=0 device_index=1 BufferInstance=0x23b822c0 shape=[1,4,64,128] m_runtime_tensor.data=0x7f39a9ff9d50 tensor.handle=0x7f39a9ff9da0
2025-09-25 17:44:02.252 (  46.072s) [        A9FFB640]loaded_executable_insta:229   INFO| EXEC_TRACE: Input arg_index=1 device_index=0 BufferInstance=0x23af4740 shape=[64] m_runtime_tensor.data=0x7f39a9ff9d50 tensor.handle=0x7f39a9ff9da0
2025-09-25 17:44:02.252 (  46.072s) [        A9FFB640]loaded_executable_insta:229   INFO| EXEC_TRACE: Input arg_index=1 device_index=1 BufferInstance=0x23a81530 shape=[64] m_runtime_tensor.data=0x7f39a9ff9d50 tensor.handle=0x7f39a9ff9da0
2025-09-25 17:44:02.253 (  46.072s) [        A9FFB640]loaded_executable_insta:229   INFO| EXEC_TRACE: Input arg_index=2 device_index=0 BufferInstance=0x23283e10 shape=[] m_runtime_tensor.data=0x7f39a9ff9d50 tensor.handle=0x7f39a9ff9da0
2025-09-25 17:44:02.253 (  46.072s) [        A9FFB640]loaded_executable_insta:229   INFO| EXEC_TRACE: Input arg_index=2 device_index=1 BufferInstance=0x2329a2d0 shape=[] m_runtime_tensor.data=0x7f39a9ff9d50 tensor.handle=0x7f39a9ff9da0
2025-09-25 17:44:02.253 (  46.072s) [        A9FFB640]loaded_executable_insta:229   INFO| EXEC_TRACE: Input arg_index=3 device_index=0 BufferInstance=0x23a1e880 shape=[1,4,1024,128] m_runtime_tensor.data=0x7f39a9ff9d50 tensor.handle=0x7f39a9ff9da0
2025-09-25 17:44:02.253 (  46.072s) [        A9FFB640]loaded_executable_insta:229   INFO| EXEC_TRACE: Input arg_index=3 device_index=1 BufferInstance=0x23a205b0 shape=[1,4,1024,128] m_runtime_tensor.data=0x7f39a9ff9d50 tensor.handle=0x7f39a9ff9da0
2025-09-25 17:44:02.874 (  46.694s) [        A9FFB640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f379c01fa00 constructor with tensor.data=0x7f39a9ff9ba0 tensor.handle=0x7f39a9ff9bb0
2025-09-25 17:44:02.874 (  46.694s) [        A9FFB640]loaded_executable_insta:375   INFO| EXEC_TRACE: Output device_index=0 output_index=0 NEW BufferInstance=0x7f379c01fa00 m_runtime_tensor.data=0x7f39a9ff9da0 tensor.handle=0x7f39a9ff9db0
2025-09-25 17:44:02.874 (  46.694s) [        A9FFB640]     buffer_instance.cc:84    INFO| BUFFER_TRACE: Output BufferInstance=0x7f379c01f7b0 constructor with tensor.data=0x7f39a9ff9ba0 tensor.handle=0x7f39a9ff9bb0
2025-09-25 17:44:02.874 (  46.694s) [        A9FFB640]loaded_executable_insta:375   INFO| EXEC_TRACE: Output device_index=1 output_index=0 NEW BufferInstance=0x7f379c01f7b0 m_runtime_tensor.data=0x7f39a9ff9da0 tensor.handle=0x7f39a9ff9db0
2025-09-25 17:44:02.874 (  46.694s) [        A9FFB640]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-25 17:44:02.875 (  46.694s) [        A9FFB640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-25 17:44:02.875 (  46.694s) [        A9FFB640]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-25 17:44:02.875 (  46.694s) [        A9FFB640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-25 17:44:02.875 (  46.694s) [        A9FFB640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-25 17:44:02.875 (  46.694s) [        A9FFB640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-25 17:44:02.875 (  46.694s) [        A9FFB640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-25 17:44:02.875 (  46.694s) [        A9FFB640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-25 17:44:02.875 (  46.694s) [        A9FFB640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-25 17:44:02.875 (  46.694s) [        A9FFB640]     buffer_instance.cc:458      1| BufferInstance::PJRT_Buffer_DynamicDimensionIndices
2025-09-25 17:44:02.875 (  46.694s) [        A9FFB640]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-25 17:44:02.875 (  46.694s) [        A9FFB640]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-25 17:44:02.875 (  46.694s) [        A9FFB640]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-25 17:44:02.875 (  46.694s) [        A9FFB640]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-25 17:44:02.875 (  46.695s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.875 (  46.695s) [        FA002000]     buffer_instance.cc:501      1| BufferInstance::PJRT_Buffer_IsDeleted
2025-09-25 17:44:02.875 (  46.695s) [        FA002000]     buffer_instance.cc:446      1| BufferInstance::PJRT_Buffer_UnpaddedDimensions
2025-09-25 17:44:02.875 (  46.695s) [        FA002000]     buffer_instance.cc:427      1| BufferInstance::PJRT_Buffer_ElementType
2025-09-25 17:44:02.875 (  46.695s) [        FA002000]     buffer_instance.cc:435      1| BufferInstance::PJRT_Buffer_Dimensions
2025-09-25 17:44:02.875 (  46.695s) [        FA002000]     buffer_instance.cc:468      1| BufferInstance::PJRT_Buffer_ToHostBuffer
2025-09-25 17:44:02.875 (  46.695s) [        FA002000]      event_instance.cc:222      1| EventInstance::PJRT_Event_OnReady
2025-09-25 17:44:02.877 (  46.696s) [        327FC640]      event_instance.cc:171      1| EventInstance::PJRT_Event_Destroy
2025-09-25 17:44:02.882 (  46.702s) [        FA002000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-25 17:44:02.882 (  46.702s) [        FA002000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-25 17:44:02.882 (  46.702s) [        FA002000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-25 17:44:02.882 (  46.702s) [        FA002000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
Using TT-Metal from the source tree: /localdev/jameszianxu/tt-xla/third_party/tt-mlir/src/tt-mlir/third_party/tt-metal/src/tt-metal
WARNING: TT plugin is setting XLA_STABLEHLO_COMPILE to 1. This is required for TT PJRT plugin to work correctly.
Setting up XLA environment...
XLA environment configured.
Created device mesh: (1, 2) with 2 devices
[james] override use torch.export.export
program.graph_signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_key_states'), target='L__self___key_states', persistent=True), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='args_0'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='args_1'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_INPUT_MUTATION: 6>, arg=TensorArgument(name='index_put'), target='args_0'), OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='index_put'), target=None)])
tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          [1., 1., 1.,  ..., 1., 1., 1.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
2025-09-25 17:44:03.124 (  46.944s) [        FA002000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
2025-09-25 17:44:03.125 (  46.944s) [        FA002000]     buffer_instance.cc:419      1| BufferInstance::PJRT_Buffer_Destroy
