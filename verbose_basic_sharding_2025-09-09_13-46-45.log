WARNING:root:Defaulting to PJRT_DEVICE=CPU
============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.2, pluggy-1.6.0 -- /localdev/jameszianxu/daily/tt-torch/env/venv/bin/python3.11
cachedir: .pytest_cache
rootdir: /localdev/jameszianxu/daily/tt-torch
configfile: pytest.ini
plugins: cov-6.2.1, forked-1.6.0, xdist-3.8.0, split-0.10.0
collecting ... collected 1 item

tests/torch/test_basic_sharding.py::test_linear_param_sharded 2025-09-09 13:44:33.101415: W torch_xla/csrc/runtime/profiler.cpp:88] Profiler API not found for PJRT plugin
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<32x128x!vhlo.f32_v1>, %arg1: !vhlo.tensor_v1<32x32x!vhlo.f32_v1>) -> (!vhlo.tensor_v1<32x128x!vhlo.f32_v1>) {
    %0 = "vhlo.dot_general_v2"(%arg1, %arg0) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<32x32x!vhlo.f32_v1>, !vhlo.tensor_v1<32x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.f32_v1>
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<32x128x!vhlo.f32_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}
// -----// IR Dump Before VhloToVersionPass (vhlo-to-version) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<32x128x!vhlo.f32_v1>, %arg1: !vhlo.tensor_v1<32x32x!vhlo.f32_v1>) -> (!vhlo.tensor_v1<32x128x!vhlo.f32_v1>) {
    %0 = "vhlo.dot_general_v2"(%arg1, %arg0) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<32x32x!vhlo.f32_v1>, !vhlo.tensor_v1<32x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.f32_v1>
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<32x128x!vhlo.f32_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump Before VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  vhlo.func_v1 @main(%arg0: !vhlo.tensor_v1<32x128x!vhlo.f32_v1>, %arg1: !vhlo.tensor_v1<32x32x!vhlo.f32_v1>) -> (!vhlo.tensor_v1<32x128x!vhlo.f32_v1>) {
    %0 = "vhlo.dot_general_v2"(%arg1, %arg0) <{accumulation_type = #vhlo.type_v1<!vhlo.none_v1>, allow_imprecise_accumulation = #vhlo.type_v1<!vhlo.none_v1>, lhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, lhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, lhs_contracting_dimensions = #vhlo.tensor_v1<dense<1> : tensor<1xi64>>, lhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>, num_primitive_operations = #vhlo.type_v1<!vhlo.none_v1>, precision_config = #vhlo.array_v1<[#vhlo<precision_v1 DEFAULT>, #vhlo<precision_v1 DEFAULT>]>, rhs_batching_dimensions = #vhlo.tensor_v1<dense<> : tensor<0xi64>>, rhs_component_count = #vhlo.type_v1<!vhlo.none_v1>, rhs_contracting_dimensions = #vhlo.tensor_v1<dense<0> : tensor<1xi64>>, rhs_precision_type = #vhlo.type_v1<!vhlo.none_v1>}> : (!vhlo.tensor_v1<32x32x!vhlo.f32_v1>, !vhlo.tensor_v1<32x128x!vhlo.f32_v1>) -> !vhlo.tensor_v1<32x128x!vhlo.f32_v1>
    "vhlo.return_v1"(%0) : (!vhlo.tensor_v1<32x128x!vhlo.f32_v1>) -> ()
  } {arg_attrs = #vhlo.array_v1<[#vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{devices=[1,2]<=[2]}">}>, #vhlo.dict_v1<{#vhlo.string_v1<"mhlo.frontend_attributes"> = #vhlo.dict_v1<{#vhlo.string_v1<"xla.sdy.sharding"> = #vhlo.string_v1<"#sdy.sharding<@mesh, [{}, {}]>">}>, #vhlo.string_v1<"mhlo.sharding"> = #vhlo.string_v1<"{replicated}">}>]>, res_attrs = #vhlo.array_v1<[]>, sym_visibility = #vhlo.string_v1<"">}
}


// -----// IR Dump After VhloLegalizeToStablehloPass (vhlo-legalize-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}) -> tensor<32x128xf32> {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}) -> tensor<32x128xf32> {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}) -> tensor<32x128xf32> {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}
// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}) -> tensor<32x128xf32> {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}) -> tensor<32x128xf32> {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}) -> tensor<32x128xf32> {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}"}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}"}) -> tensor<32x128xf32> {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump After ApplyArgumentShardStatusPass (apply-argument-shard-status) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before AnalyzeMeshPass (analyze-mesh) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump After AnalyzeMeshPass (analyze-mesh) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before ApplyShardingConstraintsPass (sdy-apply-sharding-constraints) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before AggressivePropagationPass (sdy-aggressive-propagate) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before ShardingConstraintToReshardPass (sdy-sharding-constraint-to-reshard) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before InsertExplicitReshardsPass (sdy-insert-explicit-reshards) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before WrapUnderManualComputationPass (wrap-under-manual-computation) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before ReshardToCollectivesPass (sdy-reshard-to-collectives) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before UpdateGlobalToLocalShapesPass (update-global-to-local-shapes) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before CloseShardingsPass (sdy-close-shardings) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}
// -----// IR Dump Before ConvertArithToStableHLO (convert-arith-to-stablehlo) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before LegalizeStableHLOCompositeToTTIR (legalize-stablehlo-composite-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before StablehloLegalizeCompositeToCallPass (stablehlo-legalize-composite-to-call) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before ConvertStableHLOToTTIR (convert-stablehlo-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  sdy.mesh @mesh = <["x"=1, "y"=2]>
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = stablehlo.dot_general %arg1, %arg0, contracting_dims = [1] x [0] : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump After ConvertStableHLOToTTIR (convert-stablehlo-to-ttir) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}
// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before ElementTypeNormalization (ttir-element-type-normalization) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump Before TTCoreWrapDeviceModulePass (ttcore-wrap-device-module) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
    return %0 : tensor<32x128xf32>
  }
}


// -----// IR Dump After TTCoreWrapDeviceModulePass (ttcore-wrap-device-module) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %0 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRHoistTransform (ttir-cpu-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %0 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTCoreRegisterDevicePass (ttcore-register-device) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %0 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump After TTCoreRegisterDevicePass (ttcore-register-device) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %0 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTPopulateArgumentTypes (tt-populate-argument-types) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %0 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %0 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %0 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRQuantDequantConversion (ttir-quant-dequant-conversion) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %0 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRToTTIRDecomposition (ttir-to-ttir-decomposition) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttir.dot_general"(%arg1, %arg0) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<32x32xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %0 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump After TTIRToTTIRDecomposition (ttir-to-ttir-decomposition) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x32xf32>
        %1 = "ttir.permute"(%arg1, %0) <{permutation = array<i64: 0, 1>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
        %2 = ttir.empty() : tensor<32x128xf32>
        %3 = "ttir.permute"(%arg0, %2) <{permutation = array<i64: 0, 1>}> : (tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        %4 = ttir.empty() : tensor<32x32xf32>
        %5 = "ttir.reshape"(%1, %4) <{shape = [32 : i32, 32 : i32]}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
        %6 = ttir.empty() : tensor<32x128xf32>
        %7 = "ttir.reshape"(%3, %6) <{shape = [32 : i32, 128 : i32]}> : (tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        %8 = ttir.empty() : tensor<32x128xf32>
        %9 = "ttir.matmul"(%5, %7, %8) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32>, tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        %10 = ttir.empty() : tensor<32x128xf32>
        %11 = "ttir.reshape"(%9, %10) <{shape = [32 : i32, 128 : i32]}> : (tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %11 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x32xf32>
        %1 = "ttir.permute"(%arg1, %0) <{permutation = array<i64: 0, 1>}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
        %2 = ttir.empty() : tensor<32x128xf32>
        %3 = "ttir.permute"(%arg0, %2) <{permutation = array<i64: 0, 1>}> : (tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        %4 = ttir.empty() : tensor<32x32xf32>
        %5 = "ttir.reshape"(%1, %4) <{shape = [32 : i32, 32 : i32]}> : (tensor<32x32xf32>, tensor<32x32xf32>) -> tensor<32x32xf32>
        %6 = ttir.empty() : tensor<32x128xf32>
        %7 = "ttir.reshape"(%3, %6) <{shape = [32 : i32, 128 : i32]}> : (tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        %8 = ttir.empty() : tensor<32x128xf32>
        %9 = "ttir.matmul"(%5, %7, %8) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32>, tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        %10 = ttir.empty() : tensor<32x128xf32>
        %11 = "ttir.reshape"(%9, %10) <{shape = [32 : i32, 128 : i32]}> : (tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %11 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump After TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x128xf32>
        %1 = "ttir.matmul"(%arg1, %arg0, %0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32>, tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %1 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x128xf32>
        %1 = "ttir.matmul"(%arg1, %arg0, %0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32>, tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %1 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before Inliner (inline) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x128xf32>
        %1 = "ttir.matmul"(%arg1, %arg0, %0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32>, tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %1 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('func.func' operation: @main) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x128xf32>
        %1 = "ttir.matmul"(%arg1, %arg0, %0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32>, tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %1 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRFlattenSlidingWindow (ttir-flatten-sliding-window) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x128xf32>
        %1 = "ttir.matmul"(%arg1, %arg0, %0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32>, tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %1 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRExplicateTMs (ttir-explicate-tms) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x128xf32>
        %1 = "ttir.matmul"(%arg1, %arg0, %0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32>, tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %1 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIREraseInverseOps (ttir-erase-inverse-ops) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x128xf32>
        %1 = "ttir.matmul"(%arg1, %arg0, %0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32>, tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %1 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRFusing (ttir-fusing) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x128xf32>
        %1 = "ttir.matmul"(%arg1, %arg0, %0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32>, tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %1 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRImplicitBroadcastFold (ttir-implicit-broadcast-fold) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x128xf32>
        %1 = "ttir.matmul"(%arg1, %arg0, %0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32>, tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %1 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTIRQuantDataTypeConversionPass (ttir-quant-data-type-conversion) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x128xf32>
        %1 = "ttir.matmul"(%arg1, %arg0, %0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32>, tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %1 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump Before TTNNLayout (ttnn-layout) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x128xf32>
        %1 = "ttir.matmul"(%arg1, %arg0, %0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32>, tensor<32x128xf32>, tensor<32x128xf32>) -> tensor<32x128xf32>
        return %1 : tensor<32x128xf32>
      }
    }
  }
}


// -----// IR Dump After TTNNLayout (ttnn-layout) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32, #ttnn_layout> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32, #ttnn_layout1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x128xf32, #ttnn_layout>
        %1 = "ttir.matmul"(%arg1, %arg0, %0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32, #ttnn_layout1>, tensor<32x128xf32, #ttnn_layout>, tensor<32x128xf32, #ttnn_layout>) -> tensor<32x128xf32, #ttnn_layout>
        return %1 : tensor<32x128xf32, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump Before ConvertTTIRToTTNN (convert-ttir-to-ttnn) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32, #ttnn_layout> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32, #ttnn_layout1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = ttir.empty() : tensor<32x128xf32, #ttnn_layout>
        %1 = "ttir.matmul"(%arg1, %arg0, %0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32, #ttnn_layout1>, tensor<32x128xf32, #ttnn_layout>, tensor<32x128xf32, #ttnn_layout>) -> tensor<32x128xf32, #ttnn_layout>
        return %1 : tensor<32x128xf32, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump After ConvertTTIRToTTNN (convert-ttir-to-ttnn) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32, #ttnn_layout> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32, #ttnn_layout1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<32x128>}> : (!ttnn.device) -> tensor<32x128xf32, #ttnn_layout>
        %2 = "ttnn.matmul"(%arg1, %arg0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32, #ttnn_layout1>, tensor<32x128xf32, #ttnn_layout>) -> tensor<32x128xf32, #ttnn_layout>
        return %2 : tensor<32x128xf32, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump Before TTNNFusing (ttnn-fusing) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32, #ttnn_layout> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32, #ttnn_layout1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.get_device"() <{mesh_offset = #ttnn<mesh_offset 0x0>, mesh_shape = #ttnn<mesh_shape 1x2>}> : () -> !ttnn.device
        %1 = "ttnn.empty"(%0) <{dtype = #ttcore.supportedDataTypes<f32>, layout = #ttnn.layout<tile>, memory_config = #ttnn.memory_config<#dram, <interleaved>>, shape = #ttnn.shape<32x128>}> : (!ttnn.device) -> tensor<32x128xf32, #ttnn_layout>
        %2 = "ttnn.matmul"(%arg1, %arg0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32, #ttnn_layout1>, tensor<32x128xf32, #ttnn_layout>) -> tensor<32x128xf32, #ttnn_layout>
        return %2 : tensor<32x128xf32, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump After TTNNFusing (ttnn-fusing) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32, #ttnn_layout> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32, #ttnn_layout1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.matmul"(%arg1, %arg0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32, #ttnn_layout1>, tensor<32x128xf32, #ttnn_layout>) -> tensor<32x128xf32, #ttnn_layout>
        return %0 : tensor<32x128xf32, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump Before TTNNWorkarounds (ttnn-workaround) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32, #ttnn_layout> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32, #ttnn_layout1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.matmul"(%arg1, %arg0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32, #ttnn_layout1>, tensor<32x128xf32, #ttnn_layout>) -> tensor<32x128xf32, #ttnn_layout>
        return %0 : tensor<32x128xf32, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32, #ttnn_layout> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32, #ttnn_layout1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.matmul"(%arg1, %arg0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32, #ttnn_layout1>, tensor<32x128xf32, #ttnn_layout>) -> tensor<32x128xf32, #ttnn_layout>
        return %0 : tensor<32x128xf32, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump Before ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32, #ttnn_layout> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32, #ttnn_layout1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.matmul"(%arg1, %arg0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32, #ttnn_layout1>, tensor<32x128xf32, #ttnn_layout>) -> tensor<32x128xf32, #ttnn_layout>
        return %0 : tensor<32x128xf32, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump Before ConstEvalHoistTransform (const-eval-hoist-transform) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32, #ttnn_layout> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32, #ttnn_layout1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.matmul"(%arg1, %arg0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32, #ttnn_layout1>, tensor<32x128xf32, #ttnn_layout>) -> tensor<32x128xf32, #ttnn_layout>
        return %0 : tensor<32x128xf32, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump Before TTNNDecomposeLayouts (ttnn-decompose-layouts) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32, #ttnn_layout> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32, #ttnn_layout1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.matmul"(%arg1, %arg0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32, #ttnn_layout1>, tensor<32x128xf32, #ttnn_layout>) -> tensor<32x128xf32, #ttnn_layout>
        return %0 : tensor<32x128xf32, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump Before TTNNDeallocate (ttnn-deallocate) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32, #ttnn_layout> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32, #ttnn_layout1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.matmul"(%arg1, %arg0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32, #ttnn_layout1>, tensor<32x128xf32, #ttnn_layout>) -> tensor<32x128xf32, #ttnn_layout>
        return %0 : tensor<32x128xf32, #ttnn_layout>
      }
    }
  }
}


// -----// IR Dump After TTNNDeallocate (ttnn-deallocate) ('builtin.module' operation: @SyncTensorsGraph.5) //----- //
#dram = #ttnn.buffer_type<dram>
#system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>
#ttnn_layout = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
#ttnn_layout1 = #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #dram>, <interleaved>>
module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #system_desc} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32, #ttnn_layout> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32, #ttnn_layout1> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32, #ttnn_layout> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.matmul"(%arg1, %arg0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32, #ttnn_layout1>, tensor<32x128xf32, #ttnn_layout>) -> tensor<32x128xf32, #ttnn_layout>
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<32x32xf32, #ttnn_layout1>) -> ()
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<32x128xf32, #ttnn_layout>) -> ()
        return %0 : tensor<32x128xf32, #ttnn_layout>
      }
    }
  }
}


module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>} {
  ttcore.device_module {
    builtin.module @SyncTensorsGraph.5 attributes {mhlo.cross_program_prefetches = [], mhlo.frontend_attributes = {xla.sdy.meshes = "{mesh = #sdy.mesh<[\22_axis_0\22=2]>}"}, mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false, ttcore.meshes = #ttcore.meshes<[<"mesh" = 1x2>]>, ttcore.system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073185088, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}, {arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 99712, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 32, dram_unreserved_end = 1073193408, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_register_size_tiles = 8, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0, 1], [1 : i32, 0 : i32], [ 0x0x0x0]>} {
      ttcore.device @default_device = <workerGrid = #ttcore.grid<8x16, (d0, d1) -> (d1 floordiv 8, d0, d1 mod 2)>, l1Map = (d0, d1, d2)[s0] -> (d1 floordiv 8, d0, d1 mod 2, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = 1x2, chipIds = [0, 1]>
      func.func @main(%arg0: tensor<32x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {\22_axis_0\22}]>"}, mhlo.sharding = "{devices=[1,2]<=[2]}", ttcore.shard_status = #ttcore.shard_status<presharded>}, %arg1: tensor<32x32xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{}, {}]>"}, mhlo.sharding = "{replicated}", ttcore.shard_status = #ttcore.shard_status<presharded>}) -> (tensor<32x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
        %0 = "ttnn.matmul"(%arg1, %arg0) <{transpose_a = false, transpose_b = false}> : (tensor<32x32xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>, tensor<32x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> tensor<32x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
        "ttnn.deallocate"(%arg1) <{force = false}> : (tensor<32x32xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x1x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        "ttnn.deallocate"(%arg0) <{force = false}> : (tensor<32x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>) -> ()
        return %0 : tensor<32x128xf32, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <1x1>, memref<1x4x!ttcore.tile<32x32, f32>, #ttnn.buffer_type<dram>>, <interleaved>>>
      }
    }
  }
}
XLA environment configured.
Created device mesh: (1, 2) with 2 devices
Note: Using experimental XLA backend.
Absolute differences between golden and ret matrices:
tensor([[6.7344e-04, 6.8831e-04, 8.9866e-04, 1.7992e-03, 3.2526e-04, 1.9764e-03,
         2.0672e-03, 5.8615e-04, 2.5064e-04, 4.1631e-04, 5.8055e-05, 2.5672e-03,
         1.3256e-03, 1.3645e-03, 1.5812e-03, 8.0097e-04, 2.5157e-03, 1.1659e-03,
         1.6655e-03, 2.7049e-04, 3.3424e-03, 6.4451e-04, 2.5077e-03, 5.9164e-04,
         2.3103e-03, 5.2691e-05, 2.2149e-04, 2.7757e-03, 2.8476e-03, 4.5022e-04,
         5.5057e-04, 4.1902e-04, 1.2281e-03, 2.7004e-03, 4.1068e-03, 1.7124e-03,
         2.1076e-04, 1.6506e-03, 1.8378e-03, 9.9611e-04, 3.4949e-03, 1.4746e-03,
         2.9740e-03, 5.7304e-04, 3.9191e-03, 1.2226e-03, 9.1791e-05, 6.3354e-04,
         2.3726e-03, 1.8137e-03, 1.2100e-04, 1.4384e-03, 2.8688e-03, 5.3382e-04,
         1.5996e-03, 3.6716e-04, 5.7101e-04, 5.4274e-03, 2.4590e-03, 1.1032e-03,
         1.6104e-03, 2.1133e-04, 2.0788e-03, 1.3517e-03, 4.0983e+00, 2.9560e+00,
         6.7981e-01, 3.0999e+00, 1.6603e+00, 1.2503e+00, 1.1011e+00, 1.6088e+00,
         2.7604e-01, 9.9214e-01, 6.0779e-01, 1.4684e+00, 2.7860e+00, 6.3807e+00,
         8.6063e-01, 2.6700e+00, 2.9226e+00, 6.9896e-01, 4.3766e+00, 3.7947e+00,
         2.0657e+00, 1.9427e+00, 4.2060e+00, 9.9530e-01, 4.7511e+00, 3.4294e+00,
         2.2411e-01, 2.4315e+00, 2.3541e-01, 2.7219e-01, 1.8959e+00, 4.0913e+00,
         2.4667e+00, 3.7861e+00, 1.3415e+00, 1.3872e+00, 8.5013e-01, 4.0934e-01,
         2.4865e+00, 7.7378e-01, 1.0728e+00, 4.4572e-02, 1.8004e+00, 1.7793e+00,
         2.3885e+00, 1.9619e+00, 8.5002e-02, 4.1932e-01, 7.2442e-01, 1.5490e+00,
         2.5431e+00, 1.9258e+00, 1.0303e+00, 2.2569e+00, 1.4038e+00, 1.0686e+00,
         5.3156e+00, 2.6180e+00, 1.9535e+00, 1.7415e+00, 2.1343e+00, 5.6776e-01,
         1.1279e+00, 2.6039e+00],
        [1.8071e-01, 1.3411e+00, 3.8912e+00, 5.8541e-01, 1.5943e+00, 3.7739e+00,
         5.1208e+00, 4.1029e-01, 1.0857e+00, 3.0920e-01, 4.8009e+00, 3.6469e-02,
         1.0933e+00, 3.0658e-01, 1.0528e+00, 1.6617e+00, 2.0780e+00, 6.9377e-01,
         4.0375e+00, 1.6605e+00, 2.2998e+00, 1.8500e+00, 4.0503e-01, 1.6018e+00,
         1.4809e+00, 3.4342e+00, 7.9044e-01, 9.7803e-01, 2.0688e+00, 2.1073e+00,
         3.4988e+00, 7.9796e-01, 2.9888e+00, 3.7183e+00, 2.0869e+00, 1.4404e+00,
         4.6127e+00, 1.4401e+00, 2.0396e+00, 1.4025e+00, 1.2600e+00, 2.0535e+00,
         1.4835e+00, 1.9522e-02, 1.9958e+00, 3.4779e+00, 1.5702e+00, 6.5858e-02,
         1.2238e+00, 1.2907e+00, 1.7638e+00, 4.5779e-01, 2.8803e+00, 1.7243e+00,
         3.1905e-01, 9.9795e-01, 2.7189e+00, 3.6124e+00, 1.7504e+00, 7.2131e-01,
         3.8950e+00, 6.5556e-01, 8.7395e-01, 5.9795e-01, 5.5084e-01, 1.4150e+00,
         4.1521e+00, 2.5329e+00, 2.3697e+00, 9.7126e-01, 1.4453e+00, 5.0796e+00,
         1.6905e+00, 2.5715e+00, 1.1149e+00, 3.2953e+00, 9.2542e-01, 8.7389e-01,
         1.2395e+00, 2.3005e+00, 3.5734e+00, 1.5811e+00, 1.6399e+00, 1.7388e+00,
         1.2207e+00, 6.4870e-01, 3.1040e+00, 5.8392e-01, 2.0816e+00, 2.1981e-01,
         4.2603e+00, 6.4762e-01, 7.3858e-01, 4.3802e+00, 1.9548e+00, 8.0801e-01,
         1.3356e+00, 2.6648e+00, 4.0674e+00, 3.4961e+00, 2.1607e+00, 3.9908e+00,
         2.6981e+00, 1.6215e+00, 1.3228e+00, 8.4982e-01, 2.0423e+00, 2.4711e+00,
         1.3019e+00, 5.4571e-01, 1.1951e+00, 2.5050e+00, 3.7266e+00, 1.0921e+00,
         2.2231e+00, 3.1237e+00, 2.1410e+00, 2.7156e+00, 2.7306e+00, 3.8994e-02,
         3.6659e+00, 7.6693e-02, 5.6672e-01, 1.3277e+00, 9.6275e-01, 4.5342e-01,
         1.3473e-01, 9.7378e-01],
        [1.0051e+00, 1.6663e+00, 1.1710e+00, 1.2779e+00, 1.0849e+00, 7.0019e-03,
         1.7447e+00, 2.3703e-01, 3.4523e-01, 1.2971e+00, 4.4506e+00, 1.2611e+00,
         2.1158e+00, 4.1102e+00, 8.6730e-01, 9.8848e-01, 2.1097e+00, 1.5696e+00,
         3.2448e+00, 5.1711e-01, 1.0027e-02, 1.1423e+00, 2.1859e+00, 1.3145e+00,
         3.6450e+00, 1.3385e+00, 7.0071e-01, 9.3934e-01, 1.5344e+00, 2.1754e+00,
         1.7106e+00, 4.5929e-01, 1.2784e+00, 7.0699e-01, 2.6779e-02, 3.1386e+00,
         1.6846e+00, 2.3918e+00, 3.1185e+00, 5.5570e-02, 3.5159e-01, 2.6716e-01,
         4.0727e+00, 5.5247e-01, 6.2288e-01, 7.3981e-01, 1.0552e+00, 3.4725e+00,
         2.1795e+00, 3.7385e+00, 8.8283e-01, 1.4713e+00, 4.7619e+00, 9.6131e-02,
         1.3199e+00, 5.3363e-01, 2.8384e+00, 2.7289e+00, 7.2320e-01, 9.1136e-04,
         2.7530e+00, 2.5862e+00, 3.9367e+00, 3.0887e-01, 2.1569e-01, 3.5424e+00,
         1.9235e+00, 1.4940e-01, 4.9914e-01, 3.5076e+00, 2.6784e+00, 1.3112e+00,
         2.9397e+00, 6.9036e-01, 6.2291e+00, 6.9169e-02, 1.5952e+00, 8.6290e-01,
         1.5199e-01, 2.3225e+00, 4.0467e+00, 1.0313e+00, 5.5307e-01, 4.6934e-01,
         1.1900e-01, 1.1086e+00, 1.6755e+00, 4.5072e+00, 6.5369e-01, 5.6486e+00,
         4.2876e+00, 2.6509e+00, 1.1485e+00, 9.6809e-01, 2.3986e+00, 2.0765e+00,
         8.5521e-02, 4.8904e-01, 2.2939e+00, 1.5610e-01, 8.0450e-01, 2.0654e+00,
         7.6020e-02, 1.1715e+00, 2.8542e+00, 2.8184e-01, 6.9295e-01, 1.2187e-01,
         1.0146e+00, 1.7460e+00, 1.5292e+00, 3.2547e-01, 1.0163e+00, 1.4930e+00,
         2.3535e+00, 7.2097e-01, 1.7995e+00, 2.6696e+00, 2.0131e+00, 1.1119e+00,
         2.5843e-01, 2.1720e+00, 4.4190e+00, 1.2704e-01, 3.5602e+00, 2.1949e+00,
         6.1998e-01, 2.3573e+00],
        [1.6414e+00, 1.0451e-01, 5.3033e-01, 4.2508e+00, 4.3693e+00, 8.6802e-01,
         1.0620e+00, 1.9110e+00, 2.3705e+00, 4.4288e+00, 2.3916e-01, 3.0829e-01,
         9.9493e-01, 4.6043e-01, 1.3705e+00, 1.4778e+00, 2.2103e+00, 4.8942e-01,
         7.3794e-01, 1.0313e+00, 1.6290e+00, 4.1910e-01, 3.1844e+00, 6.6581e-01,
         1.8435e+00, 1.6311e+00, 4.4268e+00, 3.7222e-01, 1.6954e-01, 1.3984e+00,
         1.1251e+00, 3.4326e-01, 3.1237e+00, 2.6082e+00, 3.6751e-01, 9.1991e-01,
         1.3186e+00, 4.0296e+00, 4.0415e-01, 1.2179e+00, 5.8526e+00, 9.4233e-02,
         2.5096e+00, 3.2506e+00, 1.7422e-01, 9.8615e-01, 2.9506e+00, 6.2911e-01,
         1.9380e+00, 4.6951e-01, 1.9264e+00, 2.7036e+00, 7.9061e-01, 1.0925e+00,
         4.7057e+00, 5.9685e-01, 1.9257e+00, 1.7008e-01, 1.2323e+00, 3.5696e+00,
         2.4599e+00, 3.8365e+00, 1.5936e+00, 4.2655e-01, 9.6512e-01, 2.1389e+00,
         1.1141e+00, 2.5272e-01, 3.8800e+00, 8.1093e-01, 1.5516e+00, 1.4857e+00,
         1.2323e+00, 2.2271e+00, 3.4371e+00, 1.5859e+00, 1.2331e+00, 1.4329e+00,
         3.5010e+00, 1.1564e+00, 2.4460e-01, 3.5480e+00, 1.7848e+00, 1.0933e+00,
         1.2054e+00, 2.6019e-01, 5.9399e-01, 3.6308e+00, 5.9136e-01, 8.5498e-03,
         1.0237e+00, 1.8022e+00, 2.0950e+00, 2.3643e+00, 3.4384e+00, 4.1766e-01,
         2.4314e+00, 3.3995e+00, 1.2800e+00, 1.5116e+00, 1.1655e-01, 1.5594e+00,
         3.3939e+00, 2.1757e+00, 1.2382e+00, 1.0010e+00, 3.1203e+00, 9.5272e-01,
         4.4374e+00, 2.0266e+00, 2.9542e+00, 1.9643e+00, 4.6747e-01, 4.3767e+00,
         2.9728e+00, 8.7370e-01, 4.6429e-01, 1.7125e+00, 5.2660e-01, 3.5222e-01,
         3.6637e+00, 1.9293e+00, 4.1747e+00, 2.0698e+00, 5.5254e-01, 2.3820e+00,
         1.5462e+00, 2.8437e+00],
        [4.2074e-01, 2.6500e+00, 7.1428e-01, 1.1144e+00, 4.5930e-01, 2.1040e+00,
         1.0816e-01, 9.7045e-01, 3.9548e-01, 1.9877e+00, 1.2955e+00, 1.9766e+00,
         4.5230e+00, 5.9466e+00, 1.7617e+00, 8.9108e-01, 2.0452e+00, 4.1673e-01,
         7.6478e-01, 1.0868e+00, 1.3303e+00, 1.6444e+00, 7.7827e-01, 2.9246e+00,
         2.1058e+00, 2.6222e+00, 2.1515e+00, 7.7709e-01, 3.5565e+00, 1.0138e+00,
         1.4723e+00, 1.2969e+00, 2.1638e+00, 3.7191e+00, 1.9622e+00, 2.9787e+00,
         4.0238e+00, 3.6528e+00, 2.1684e+00, 2.6213e+00, 4.9375e-01, 1.6635e+00,
         2.4058e+00, 1.1398e+00, 4.4027e+00, 7.2277e-01, 1.1994e-03, 4.0140e+00,
         3.9038e-01, 5.8223e-01, 6.8035e-01, 1.2449e+00, 4.9782e+00, 2.2856e+00,
         6.3884e-01, 5.5318e-02, 3.3533e+00, 1.0028e+00, 2.2041e+00, 2.4413e+00,
         5.0585e+00, 1.3937e+00, 3.0578e+00, 6.8315e-01, 5.3279e+00, 1.7486e+00,
         6.5813e+00, 3.6650e-01, 5.6124e+00, 2.3805e+00, 1.3880e+00, 3.0635e+00,
         1.4249e+00, 1.4562e+00, 2.2305e+00, 1.7010e+00, 3.0140e-01, 6.6704e-01,
         5.0495e+00, 1.2763e-01, 8.3014e-02, 2.1128e+00, 2.7066e+00, 7.0180e-02,
         3.1540e+00, 2.6112e-01, 2.5514e+00, 2.1447e+00, 1.8595e+00, 2.2499e+00,
         6.0385e+00, 4.9214e-01, 2.8032e+00, 1.4016e+00, 3.6997e+00, 1.7217e+00,
         4.1615e-01, 6.9263e-01, 8.0142e-02, 2.7169e+00, 1.3286e+00, 5.0783e+00,
         2.9770e+00, 1.8499e+00, 2.2787e+00, 3.8510e+00, 1.0454e+00, 7.0184e-01,
         1.5138e+00, 1.7662e+00, 1.2667e+00, 1.0164e-02, 3.3363e+00, 2.9250e+00,
         3.6267e+00, 1.6391e+00, 3.5581e+00, 1.5156e+00, 1.7143e+00, 8.6538e-01,
         1.8395e+00, 6.9338e-01, 1.8055e+00, 9.9247e-01, 2.1209e+00, 7.1406e-01,
         3.4983e+00, 8.1647e-01],
        [1.9767e+00, 1.0950e-01, 9.8341e-01, 1.9600e+00, 3.0152e-01, 1.1904e+00,
         1.5195e+00, 2.2710e+00, 4.9987e+00, 3.5549e+00, 6.2616e+00, 2.1168e-01,
         2.0980e-02, 1.6547e+00, 1.1546e+00, 4.8869e+00, 2.5975e+00, 3.8999e+00,
         2.0928e+00, 2.6708e+00, 3.2159e-01, 4.6461e-01, 3.1732e+00, 4.1591e+00,
         3.4988e+00, 6.7802e+00, 2.3331e+00, 8.7572e-01, 2.3092e+00, 2.1662e+00,
         6.8371e-01, 3.3665e-01, 1.0456e+00, 6.0920e-01, 3.0850e+00, 3.3077e+00,
         2.2196e+00, 2.3786e-01, 4.8636e-01, 5.0481e-01, 5.8924e+00, 1.0590e+00,
         1.8485e-01, 1.0099e+00, 1.3022e+00, 5.4809e-01, 2.3914e+00, 1.7062e+00,
         1.3232e-01, 8.0105e-01, 6.3255e-01, 1.3836e+00, 8.1893e-01, 1.6788e+00,
         1.8848e+00, 2.3552e+00, 2.6326e+00, 1.5582e+00, 2.3348e+00, 1.0860e+00,
         2.4243e-01, 1.6783e+00, 2.5694e-01, 1.0454e+00, 1.3001e+00, 2.3584e+00,
         2.7023e+00, 1.8821e+00, 7.3545e-01, 2.0356e+00, 2.2575e+00, 2.4671e+00,
         1.5991e+00, 2.8897e+00, 8.6406e-02, 1.3796e+00, 1.6538e+00, 1.7950e+00,
         1.1618e+00, 8.2462e-01, 1.9361e+00, 1.2719e+00, 2.6526e+00, 1.2692e+00,
         4.3712e-01, 4.0887e+00, 3.2493e+00, 2.0156e+00, 2.6421e-01, 4.5613e+00,
         5.2273e+00, 2.3524e+00, 2.1702e+00, 2.1868e+00, 1.5236e-01, 3.1504e-01,
         1.9206e+00, 6.3463e+00, 1.0376e+00, 4.4584e+00, 1.4504e+00, 8.4258e-01,
         3.2360e+00, 2.5865e+00, 1.2568e+00, 1.5859e+00, 1.8060e+00, 5.5264e-03,
         2.8682e+00, 7.6670e-01, 6.2029e-01, 7.4761e-01, 2.9299e+00, 1.8643e+00,
         2.3979e+00, 1.4286e+00, 2.6040e+00, 1.1519e+00, 2.6561e-01, 4.3902e+00,
         1.2167e+00, 3.6643e-01, 7.4218e-01, 9.4312e-01, 2.4657e+00, 1.8831e+00,
         2.4727e+00, 1.4954e+00],
        [3.2098e+00, 7.6556e-01, 4.0363e+00, 3.5688e+00, 3.9014e-01, 2.6840e+00,
         2.0090e+00, 8.2751e-01, 1.1603e+00, 4.0362e+00, 4.2387e+00, 1.7285e+00,
         8.7192e-01, 7.6355e-01, 1.7575e+00, 1.9280e-01, 1.4416e+00, 2.3167e+00,
         4.0620e-01, 7.3325e-01, 4.1393e+00, 9.8854e-01, 2.7769e+00, 1.1252e+00,
         1.3604e+00, 5.6867e+00, 4.0719e-01, 3.1154e+00, 6.8232e-01, 2.7427e+00,
         2.1916e+00, 2.4586e+00, 2.1904e+00, 6.6933e-01, 2.3350e+00, 7.2020e-01,
         1.6973e-01, 7.1315e-01, 8.5140e-01, 2.9457e+00, 5.3422e+00, 9.0220e-01,
         1.9372e+00, 1.2096e+00, 2.3542e+00, 4.9434e-01, 2.1102e+00, 3.1059e-01,
         3.4320e+00, 3.7306e+00, 5.6120e-01, 1.8387e+00, 4.1358e-01, 1.4201e+00,
         2.3123e-01, 2.8154e+00, 4.0830e-01, 2.6578e+00, 2.1281e+00, 2.4082e+00,
         2.7839e-01, 2.7163e+00, 2.2275e+00, 1.3113e-01, 1.7956e+00, 1.2508e+00,
         2.5933e+00, 1.7598e-01, 7.6004e-01, 1.3532e+00, 1.3343e+00, 2.0673e+00,
         7.6536e-01, 3.4500e+00, 1.4324e+00, 1.1027e+00, 2.1721e+00, 3.6294e+00,
         5.2729e-01, 3.1424e-01, 1.1834e+00, 3.5448e-01, 9.2295e-01, 2.5166e+00,
         1.5012e+00, 2.7008e-01, 2.6304e+00, 9.2453e-01, 4.2012e+00, 2.6912e+00,
         3.9985e+00, 3.8504e-01, 2.1928e+00, 9.1439e-01, 3.6813e+00, 1.7594e+00,
         9.9365e-02, 2.7188e+00, 5.8995e-01, 1.5270e+00, 1.5598e+00, 1.1733e-01,
         9.3845e-01, 2.5154e-02, 2.5875e+00, 2.0286e-01, 2.3350e+00, 1.2335e+00,
         1.3483e+00, 2.1804e+00, 1.8083e+00, 5.2012e-01, 1.1801e+00, 3.0762e+00,
         3.9214e+00, 1.8399e-01, 2.7171e+00, 1.0597e+00, 3.2873e+00, 8.4558e-01,
         4.7585e+00, 1.6307e+00, 2.6675e+00, 3.3414e+00, 4.3368e+00, 1.9707e+00,
         6.5740e-01, 2.5824e+00],
        [5.1207e-01, 1.2614e+00, 5.3927e-02, 9.9786e-01, 2.0751e+00, 1.1982e+00,
         1.2851e+00, 5.0233e-02, 6.4376e-01, 2.5751e+00, 1.3419e+00, 7.1655e-02,
         7.8470e-01, 1.5282e+00, 3.1814e+00, 2.8157e+00, 2.0044e+00, 7.0833e-01,
         9.3060e-01, 9.6302e-01, 2.0267e+00, 1.2745e+00, 1.1551e+00, 1.6993e+00,
         2.1735e+00, 1.6581e+00, 3.0501e+00, 1.6072e-01, 1.6833e+00, 1.0926e+00,
         8.3687e-01, 1.1435e+00, 2.5389e-01, 1.5308e-01, 1.3212e+00, 2.8814e+00,
         2.8641e+00, 1.4824e+00, 6.7414e-01, 2.7019e+00, 2.3828e-01, 2.4897e+00,
         7.7987e-01, 1.2009e+00, 3.7373e+00, 5.8974e-01, 7.7495e-01, 1.9988e+00,
         7.0143e-03, 1.6189e+00, 2.3281e+00, 3.2526e-01, 8.7853e-01, 1.4014e+00,
         3.7180e-01, 4.4559e-01, 3.1104e+00, 4.0331e-01, 2.4107e+00, 1.0733e+00,
         1.4418e+00, 2.1899e+00, 9.4386e-01, 7.6888e-01, 3.4986e+00, 4.0423e+00,
         1.7153e+00, 1.6387e+00, 2.6071e+00, 2.6917e+00, 2.0179e+00, 8.3964e-01,
         2.3777e-01, 6.6247e-01, 1.8679e-01, 2.3915e+00, 2.0846e+00, 1.3835e+00,
         6.6605e+00, 4.2699e+00, 4.5089e-01, 4.9728e+00, 1.4950e+00, 3.5713e+00,
         4.3064e+00, 8.6042e-01, 9.8899e-01, 1.0394e+00, 2.0797e+00, 2.2361e-01,
         2.4163e+00, 4.0036e+00, 3.3084e-01, 3.0655e+00, 9.8179e-01, 2.1455e+00,
         9.0705e-01, 3.1986e+00, 2.0432e+00, 5.2836e-01, 7.6091e-01, 4.4915e+00,
         2.5655e+00, 5.5759e-01, 1.0002e+00, 4.2740e-01, 1.3941e-01, 6.0670e-01,
         3.5243e-01, 1.7099e+00, 3.8268e-01, 1.3569e+00, 3.9709e+00, 1.2237e+00,
         3.2557e+00, 1.8766e+00, 1.5328e+00, 9.9934e-02, 2.1502e+00, 8.3573e-01,
         1.5366e+00, 1.5726e+00, 1.6012e+00, 2.4008e+00, 2.2847e+00, 4.0584e+00,
         4.8775e-01, 3.2161e+00],
        [3.1429e-01, 5.5611e-03, 2.4225e+00, 3.0688e+00, 3.6505e+00, 8.7956e-01,
         1.3824e+00, 2.0605e+00, 1.2791e+00, 1.4252e-01, 8.0123e-01, 2.3006e+00,
         4.9790e-01, 5.2942e+00, 1.7213e+00, 6.0108e-01, 2.0400e+00, 2.5299e+00,
         2.1230e+00, 1.7066e-01, 3.3320e+00, 1.6731e+00, 2.5395e+00, 2.8485e+00,
         1.6891e-01, 2.4908e+00, 2.7567e+00, 1.0307e+00, 4.6842e+00, 6.2014e+00,
         2.6482e+00, 1.8418e+00, 1.8953e+00, 2.8719e+00, 1.4071e+00, 3.5969e+00,
         2.1922e+00, 8.9017e-01, 1.8611e+00, 2.1812e+00, 7.7990e-01, 2.2079e+00,
         2.8543e-01, 4.2540e-01, 2.9567e+00, 3.0263e+00, 8.8292e-01, 3.2185e+00,
         2.4462e+00, 7.4468e-02, 1.5134e-01, 5.4762e-01, 1.6942e+00, 2.3201e+00,
         3.4030e+00, 1.0333e+00, 1.7873e+00, 6.8918e-01, 6.6492e+00, 4.2910e+00,
         3.5763e+00, 3.0157e+00, 3.1079e-01, 3.7482e-01, 2.9084e+00, 1.5170e+00,
         2.5342e-01, 9.1548e-01, 1.9213e+00, 2.4682e-01, 1.0948e-01, 4.0462e+00,
         6.8061e-01, 9.4186e-01, 1.5807e+00, 3.9898e+00, 5.0520e+00, 1.8458e+00,
         5.7121e-01, 3.6426e+00, 9.5157e-01, 4.3696e+00, 4.9018e+00, 9.5064e-01,
         2.9132e+00, 9.5740e-01, 1.4686e+00, 8.3106e-01, 3.1181e-01, 5.7486e+00,
         3.4976e+00, 2.5606e+00, 2.6796e+00, 1.6258e+00, 7.1997e-01, 4.5059e-01,
         2.1631e+00, 2.9989e+00, 1.1914e+00, 2.6472e+00, 4.2413e-02, 2.6808e-01,
         2.6731e+00, 2.6597e-01, 4.9736e-02, 1.3421e+00, 2.3308e-01, 5.2844e-01,
         7.7854e-02, 6.2292e-01, 2.0572e+00, 9.1842e-02, 3.1296e+00, 2.6026e+00,
         2.2882e+00, 5.7142e-01, 7.6123e-02, 5.3340e+00, 1.9707e+00, 2.0567e+00,
         2.5333e+00, 6.2342e-01, 5.8572e-01, 3.6477e+00, 3.0404e+00, 3.3331e+00,
         4.4266e+00, 2.6034e+00],
        [2.2454e+00, 2.9053e+00, 7.3426e-01, 1.8180e+00, 2.4266e+00, 1.0559e+00,
         4.1735e+00, 2.8437e+00, 1.9449e+00, 5.7122e-01, 2.2565e+00, 1.7372e-01,
         4.1340e-01, 1.8289e+00, 1.3744e+00, 1.2237e+00, 1.4287e+00, 3.2963e+00,
         2.1357e+00, 3.7648e+00, 4.0932e-02, 1.5820e+00, 1.3602e+00, 1.6158e+00,
         1.7714e+00, 1.8816e+00, 9.1283e-01, 3.4274e-01, 4.6477e+00, 3.1148e+00,
         2.1463e+00, 1.6439e+00, 2.0141e+00, 1.1707e+00, 4.7123e-01, 2.8861e+00,
         3.0394e+00, 1.2529e+00, 1.0493e+00, 1.8053e+00, 4.9317e-01, 5.1043e+00,
         1.3670e+00, 2.5803e+00, 3.0161e+00, 1.8058e+00, 6.4327e-01, 4.2461e-03,
         3.7407e+00, 1.1824e+00, 9.3740e-01, 1.6483e-01, 1.0785e+00, 3.3331e-01,
         1.6240e+00, 6.8736e-01, 9.3822e-01, 1.5429e+00, 1.0607e+00, 1.1311e+00,
         1.7012e+00, 6.0900e-01, 2.7755e+00, 1.1250e-01, 1.7915e-01, 3.3107e+00,
         9.1688e-01, 4.7619e+00, 8.6908e-01, 8.7103e-01, 6.4619e+00, 1.3359e+00,
         2.7654e-01, 7.7456e-01, 3.7410e+00, 1.3510e+00, 8.8622e-01, 6.5278e+00,
         2.1573e+00, 1.0022e+00, 1.3957e+00, 5.0288e+00, 7.7587e-01, 3.9797e+00,
         2.6691e+00, 3.1186e+00, 2.3322e+00, 1.5553e+00, 2.3140e-01, 8.3985e-01,
         9.0318e-01, 9.3187e-01, 7.3241e-01, 3.3290e+00, 1.8031e+00, 2.4087e+00,
         1.5523e+00, 1.5577e+00, 1.6853e+00, 7.2611e-01, 2.8156e+00, 1.1456e-02,
         2.6910e+00, 1.1844e+00, 1.1202e+00, 8.8842e-01, 2.7232e+00, 3.6844e+00,
         3.0392e+00, 2.3723e+00, 5.9542e+00, 1.5624e+00, 1.2485e-01, 1.9798e+00,
         1.9566e+00, 2.7048e+00, 6.9605e-01, 1.2277e+00, 1.9121e+00, 3.9651e+00,
         4.9382e+00, 4.6465e+00, 4.8301e+00, 5.1957e-01, 3.1684e+00, 1.5942e+00,
         4.5305e-01, 1.4368e+00],
        [2.5498e+00, 8.9818e-01, 1.0450e+00, 1.8892e-01, 1.5592e+00, 1.3634e+00,
         2.7524e+00, 1.8993e+00, 1.2140e+00, 2.6024e+00, 1.1474e+00, 9.0497e-01,
         1.2415e+00, 1.9944e+00, 6.2729e+00, 3.7287e+00, 5.2566e-01, 4.6263e+00,
         9.8708e-01, 1.1061e+00, 1.2095e+00, 1.8825e+00, 3.1433e-01, 1.2286e+00,
         3.0358e+00, 3.1692e+00, 2.4691e+00, 5.7104e+00, 1.1250e+00, 1.3567e+00,
         2.3529e+00, 8.2593e-02, 6.8729e-01, 9.3838e-01, 2.8338e+00, 8.6485e-01,
         2.1385e+00, 4.6441e-01, 4.2840e-01, 3.9108e-01, 4.2203e+00, 8.1856e-01,
         2.8258e+00, 1.0639e+00, 5.3299e-02, 8.8765e-01, 3.6781e+00, 8.8010e-01,
         1.0857e+00, 1.7037e+00, 3.6266e-01, 1.5164e-01, 3.3204e+00, 4.8524e-01,
         1.9156e-02, 3.5298e+00, 3.4095e+00, 3.4779e+00, 2.4605e+00, 1.7659e-01,
         2.3561e+00, 6.1592e-01, 1.5180e+00, 3.0094e+00, 1.8547e+00, 1.0075e+00,
         3.6007e+00, 2.3694e+00, 1.6809e+00, 1.8587e+00, 3.9991e-01, 9.3407e-01,
         2.8972e-01, 9.9420e-01, 1.8368e+00, 6.5885e-01, 6.9903e-01, 5.4309e+00,
         1.8684e+00, 1.5704e+00, 5.7129e-01, 1.8576e-01, 1.2684e+00, 1.0910e+00,
         7.4084e-01, 8.0871e-01, 2.5355e-01, 7.7973e-01, 6.1422e+00, 2.3723e-01,
         2.5397e+00, 1.6414e+00, 9.8436e-01, 7.0190e-01, 9.6835e-01, 1.7863e+00,
         1.5547e+00, 1.0735e+00, 1.0441e+00, 1.3200e+00, 4.3532e+00, 8.8934e-01,
         8.7606e-02, 1.3494e+00, 2.4347e+00, 1.1480e-01, 1.4086e+00, 5.6290e-01,
         4.3558e-01, 3.7825e-01, 2.3455e+00, 2.0011e+00, 1.5280e+00, 6.0865e-01,
         2.0691e+00, 2.1920e+00, 1.3070e+00, 1.1601e+00, 2.5795e+00, 2.1876e+00,
         9.6731e-01, 2.9383e-01, 1.0456e+00, 3.0644e+00, 2.7424e+00, 1.0614e+00,
         3.8173e-01, 5.0048e+00],
        [3.5534e+00, 2.4267e-01, 3.7585e-01, 1.6509e+00, 1.8616e+00, 2.3893e+00,
         1.0122e+00, 4.0311e-01, 1.2148e+00, 3.1866e+00, 1.0413e+00, 1.7450e+00,
         1.9661e+00, 4.2275e+00, 2.3237e+00, 6.3597e-01, 4.2176e-01, 1.0831e+00,
         2.0415e+00, 2.8097e+00, 1.3213e+00, 1.1912e+00, 4.8547e-01, 1.0335e+00,
         3.7209e-02, 9.2657e-01, 3.4058e+00, 3.6226e-01, 1.2127e+00, 1.1631e-01,
         1.0228e+00, 1.4781e-02, 1.7249e-01, 4.1675e+00, 1.1635e+00, 7.4386e-01,
         5.0122e-01, 4.0225e+00, 2.9263e+00, 2.5380e+00, 1.4364e+00, 1.2445e+00,
         7.7961e-03, 3.5225e+00, 6.5239e-01, 1.9752e+00, 1.4691e+00, 1.0449e+00,
         4.3379e-01, 2.0965e-01, 1.6936e+00, 1.6654e+00, 1.9059e+00, 1.4189e+00,
         1.2221e+00, 1.0816e+00, 1.8523e+00, 3.7674e-01, 4.5544e-01, 4.4976e+00,
         1.9049e-01, 3.2882e+00, 5.3463e-01, 5.6563e-01, 2.1587e+00, 4.2222e-01,
         2.4032e+00, 1.1283e+00, 2.0085e+00, 1.3413e-01, 3.9276e+00, 6.0845e-02,
         1.8955e+00, 2.5550e+00, 1.1971e+00, 1.0951e+00, 1.7187e+00, 5.5928e-01,
         1.6297e+00, 2.0877e+00, 1.5724e+00, 1.8018e+00, 3.5262e+00, 7.0304e-01,
         4.9477e-02, 3.7376e+00, 1.1638e+00, 4.7681e-01, 2.6210e+00, 4.4589e-01,
         1.7689e-01, 1.3936e+00, 4.8520e-02, 1.0115e+00, 2.7164e+00, 1.2865e+00,
         2.8116e+00, 2.9815e-01, 4.2045e+00, 1.2339e+00, 1.3052e+00, 2.6807e+00,
         1.3849e+00, 2.7371e-01, 1.3697e+00, 4.1391e+00, 4.1735e+00, 1.3197e+00,
         2.4207e+00, 2.5966e+00, 1.2438e+00, 4.2399e+00, 1.0170e+00, 7.7400e-01,
         3.1168e+00, 1.5534e+00, 3.1651e+00, 4.0166e-02, 2.0752e+00, 1.1372e+00,
         4.3140e+00, 2.2175e+00, 1.7224e+00, 3.6880e-02, 5.5101e+00, 4.5957e+00,
         8.6834e-01, 4.1887e+00],
        [3.0065e+00, 1.7169e+00, 6.3069e+00, 3.0980e+00, 1.2758e+00, 1.9761e+00,
         1.7326e+00, 2.4474e+00, 1.1663e+00, 3.8433e+00, 2.3764e+00, 4.2733e+00,
         1.5641e-01, 2.4962e+00, 5.2561e+00, 3.8833e+00, 1.6531e+00, 3.7234e+00,
         3.7626e-01, 1.7056e+00, 5.8311e-01, 3.3778e+00, 7.8936e-01, 3.1309e-02,
         3.0490e+00, 2.6214e+00, 5.0759e+00, 2.1413e+00, 5.9366e-01, 3.4792e+00,
         3.8257e+00, 5.2686e+00, 5.4163e-01, 3.3524e-01, 1.0197e+00, 2.1779e+00,
         2.4284e+00, 1.7546e+00, 2.1037e+00, 2.7792e+00, 2.4452e+00, 9.5678e-01,
         1.1272e+00, 4.2399e+00, 2.0756e+00, 1.2721e-01, 1.9396e+00, 1.5962e+00,
         5.7425e-01, 7.5819e+00, 2.0977e+00, 1.2067e+00, 2.8871e+00, 2.1810e+00,
         2.4189e+00, 4.4979e+00, 1.6882e+00, 3.9736e+00, 1.2522e+00, 6.2315e-01,
         1.4538e+00, 3.7794e+00, 5.5464e-01, 1.4770e+00, 2.2482e+00, 1.0541e+00,
         4.3640e+00, 2.0699e+00, 2.0187e+00, 1.4791e+00, 1.2181e+00, 2.1286e+00,
         8.3967e-01, 4.4932e+00, 1.3755e+00, 2.9248e+00, 9.6508e-01, 1.6281e+00,
         1.7252e+00, 4.8322e-01, 7.8582e-01, 3.0954e-01, 8.4894e-01, 9.2594e-01,
         8.9391e-01, 3.0297e-01, 4.4747e-01, 3.5800e+00, 4.8188e-01, 6.7331e+00,
         1.8620e+00, 1.1305e+00, 7.7406e-02, 7.1524e-01, 5.1031e+00, 2.4712e+00,
         1.5652e+00, 6.1776e-01, 4.0022e+00, 2.8476e+00, 1.9420e+00, 6.4863e-01,
         1.3249e+00, 5.4212e-01, 6.3543e-01, 1.8214e+00, 1.1681e+00, 3.1205e+00,
         2.0640e+00, 1.3075e+00, 3.9763e+00, 2.0135e+00, 5.3666e-01, 3.4735e+00,
         5.3432e-01, 3.5101e+00, 2.3874e+00, 1.6087e-02, 2.0919e+00, 1.4628e+00,
         3.9844e+00, 5.8125e-01, 1.7406e+00, 1.3354e+00, 4.9843e+00, 4.3771e+00,
         3.0435e+00, 3.7341e-03],
        [3.6551e+00, 6.0656e-01, 1.9538e-01, 5.7543e-01, 5.2254e-01, 8.5263e-01,
         7.5222e-01, 6.5601e+00, 1.1328e+00, 4.8391e+00, 9.8349e-01, 1.5015e+00,
         3.3852e+00, 3.8921e+00, 1.7685e-01, 1.5924e+00, 1.1884e+00, 1.1124e+00,
         2.5230e+00, 1.5548e+00, 7.4106e-01, 4.6592e-01, 3.6679e+00, 2.7780e+00,
         1.7453e+00, 5.1649e-01, 7.9188e+00, 6.2206e-01, 3.2997e-01, 1.6654e+00,
         3.6467e+00, 1.4628e+00, 1.0855e+00, 4.9099e+00, 1.7231e+00, 4.1535e-02,
         2.7741e+00, 3.3618e+00, 2.6974e-01, 1.5657e+00, 2.2304e+00, 8.0390e-01,
         2.2132e+00, 4.7298e-01, 4.5379e-01, 2.3706e+00, 1.4332e+00, 1.2340e+00,
         1.2279e+00, 1.7443e+00, 1.3583e+00, 1.8968e+00, 3.4511e+00, 8.2952e-02,
         2.6799e+00, 6.1068e-02, 2.0817e+00, 2.4080e+00, 1.8000e-01, 4.3035e+00,
         1.4674e+00, 1.0243e+00, 1.3873e+00, 3.0160e+00, 6.9204e+00, 1.1383e+00,
         2.7146e+00, 1.2149e+00, 3.7287e-02, 1.0363e+00, 4.0392e-02, 2.9746e+00,
         1.4650e+00, 1.4524e+00, 2.7886e+00, 3.6294e+00, 2.0293e+00, 6.9684e+00,
         2.9881e+00, 1.7644e+00, 5.7104e-02, 6.1080e+00, 1.0484e+00, 4.7502e+00,
         1.3844e+00, 2.0538e+00, 1.7453e+00, 1.2675e+00, 1.3323e+00, 6.7544e-01,
         3.1918e+00, 4.3935e-01, 7.2752e-01, 6.5537e-01, 1.8340e+00, 4.0845e+00,
         5.0081e-01, 4.6040e+00, 8.3558e-01, 1.1817e+00, 3.5969e-03, 1.9042e+00,
         3.0111e-01, 2.2159e-01, 4.3896e+00, 2.4189e+00, 1.0200e+00, 9.2753e-01,
         1.0191e+00, 7.8711e-01, 1.8551e-03, 3.6736e+00, 2.9063e+00, 4.9460e+00,
         1.1371e+00, 1.2006e+00, 2.4541e+00, 6.1732e-01, 7.0538e-01, 8.1877e-01,
         2.2399e+00, 1.7197e+00, 1.8322e-01, 5.2074e-01, 1.3644e+00, 4.8857e-01,
         5.0671e-02, 1.2938e+00],
        [3.6293e-01, 4.3399e-01, 3.4004e+00, 2.6710e+00, 3.8134e+00, 8.4406e-01,
         1.1998e+00, 1.4540e-01, 4.9145e-01, 2.2154e+00, 1.6159e+00, 1.1365e+00,
         5.6998e-01, 8.3562e-01, 5.2574e+00, 1.1449e+00, 8.7780e-01, 4.4980e-01,
         2.8699e+00, 1.6946e+00, 2.2774e+00, 4.6889e-01, 1.8006e+00, 1.5451e-01,
         3.3845e+00, 2.2607e-01, 1.4542e+00, 3.4029e-01, 1.3500e+00, 1.9806e+00,
         1.7216e+00, 2.0763e+00, 2.1196e+00, 5.8403e-01, 5.6846e-01, 3.6934e+00,
         1.4303e+00, 1.1735e+00, 2.6272e+00, 2.2671e-01, 1.6456e+00, 3.2566e+00,
         1.1452e+00, 2.2457e+00, 2.2353e+00, 3.3365e-01, 8.4557e-01, 3.2319e-01,
         1.5200e+00, 2.2693e+00, 1.2001e+00, 5.7006e-01, 7.3902e-01, 3.2243e-01,
         1.5892e+00, 2.2357e+00, 1.4699e+00, 3.0547e-01, 8.0088e-01, 1.4244e+00,
         1.2104e+00, 2.8675e+00, 2.7039e+00, 2.3260e+00, 1.0451e-01, 3.6336e-01,
         1.5796e+00, 2.2820e+00, 2.8581e+00, 1.9099e+00, 1.3663e+00, 3.8528e+00,
         3.9787e-01, 5.5083e-01, 4.5299e+00, 2.9846e+00, 6.8243e-01, 2.3683e+00,
         9.9038e-01, 3.0186e-01, 2.1418e+00, 3.4237e+00, 1.5771e+00, 2.1005e+00,
         1.8931e+00, 2.3491e+00, 1.5346e+00, 9.4923e-01, 1.2360e-01, 2.9379e+00,
         1.7141e+00, 3.5784e+00, 1.0707e-01, 2.1963e-01, 1.7643e+00, 4.1032e+00,
         1.3451e+00, 2.5173e+00, 3.4885e-01, 2.3584e+00, 4.4282e-01, 3.8485e+00,
         5.2439e-02, 2.3780e+00, 2.0992e+00, 9.9272e-01, 5.7912e-01, 1.6942e+00,
         1.4112e+00, 4.3662e+00, 2.2887e+00, 2.8565e+00, 1.3113e+00, 2.2252e+00,
         1.7208e+00, 2.8222e+00, 5.0318e+00, 5.3538e+00, 2.1718e+00, 5.3338e-01,
         2.9052e+00, 1.2722e+00, 7.6719e-01, 3.4857e+00, 2.2166e+00, 2.8927e+00,
         1.0149e+00, 3.2027e-01],
        [2.5098e+00, 2.5379e+00, 3.6029e+00, 1.7455e+00, 9.6323e-01, 1.9792e+00,
         1.6189e+00, 1.8617e+00, 1.9217e+00, 2.4436e+00, 9.2713e-01, 3.6756e+00,
         2.8330e-01, 9.8242e-01, 3.4325e+00, 1.4582e+00, 1.5983e+00, 4.6914e+00,
         4.8460e-02, 2.0390e+00, 3.8273e+00, 2.1429e+00, 2.4582e+00, 3.8968e+00,
         7.4163e-01, 1.2644e+00, 3.7809e+00, 4.6744e+00, 2.4721e+00, 1.5166e-01,
         3.3570e+00, 3.4728e+00, 1.1803e+00, 3.1555e+00, 8.4571e-01, 2.2033e+00,
         2.5395e+00, 2.4684e+00, 1.3805e+00, 6.3147e-02, 2.0716e+00, 3.2190e+00,
         9.2690e-01, 4.8077e-01, 3.2549e+00, 4.3075e-01, 3.5990e+00, 5.9228e-01,
         2.2907e+00, 5.8875e-01, 4.8703e+00, 1.4990e-01, 5.6547e-01, 2.9207e-01,
         2.5518e-01, 1.9329e+00, 4.5232e-01, 2.1511e+00, 1.2613e-01, 1.7303e+00,
         2.3292e+00, 4.5927e+00, 8.6123e-01, 4.9319e-01, 1.5260e+00, 2.7798e-01,
         8.0160e-01, 1.2017e+00, 4.6596e+00, 8.3856e-01, 3.5347e-01, 1.9158e+00,
         7.8278e-01, 2.2799e+00, 3.5091e+00, 2.2403e+00, 3.9050e-02, 4.0302e+00,
         1.0291e+00, 2.5656e+00, 1.2107e-01, 2.0424e-01, 8.4976e-01, 1.9294e+00,
         1.6939e+00, 2.5269e+00, 1.4882e+00, 2.7367e+00, 6.6394e+00, 5.1960e+00,
         2.0363e-01, 2.9132e+00, 1.9407e+00, 2.7179e+00, 1.0227e+00, 1.1215e+00,
         7.2006e-01, 2.7257e+00, 8.6004e-01, 3.5101e+00, 5.2081e+00, 8.8362e-01,
         1.9880e+00, 4.7114e+00, 4.1607e+00, 1.5455e-01, 1.3230e+00, 4.5028e-01,
         7.0782e-01, 2.1508e+00, 2.3145e+00, 1.2344e+00, 6.9052e-02, 1.2837e-01,
         3.6925e-01, 2.6095e+00, 1.7823e+00, 3.0948e+00, 4.8939e-01, 2.8065e-01,
         4.7341e-01, 3.8855e+00, 2.4218e-01, 5.7267e-01, 1.8275e+00, 1.4129e+00,
         1.0564e-01, 3.8410e+00],
        [1.1768e+00, 9.5683e-01, 4.8711e-02, 2.9822e+00, 1.4277e+00, 5.6385e-01,
         4.2859e-01, 9.4518e-01, 9.3593e-01, 8.1010e-01, 7.5153e-01, 1.4097e+00,
         2.4789e+00, 1.6484e+00, 1.0968e+00, 2.6179e-01, 2.5154e+00, 1.7295e+00,
         2.2944e+00, 1.2507e+00, 1.6713e+00, 2.4482e+00, 4.7567e-01, 1.3898e-01,
         2.1603e-01, 1.9774e-02, 2.0979e+00, 2.2975e-01, 7.7322e-01, 2.9229e+00,
         8.7453e-01, 4.7469e-01, 7.6570e-01, 9.0921e-02, 5.5970e-02, 2.4227e+00,
         1.5279e-01, 2.3841e+00, 3.6274e+00, 1.3232e-02, 3.8968e-01, 6.8852e-01,
         1.0035e+00, 2.3427e-01, 1.4792e+00, 1.0533e+00, 2.1300e+00, 2.0540e+00,
         2.3039e+00, 4.7021e-01, 6.5905e-01, 8.2765e-01, 2.0585e+00, 1.0885e+00,
         1.6016e+00, 1.2332e+00,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan, 2.2109e+00, 6.9339e-01,
         8.0027e-01, 3.2198e+00, 6.9801e-01, 1.5181e+00, 1.4353e+00, 5.9828e-01,
                nan,        nan,        nan,        nan, 1.4422e+00, 1.7326e-01,
         6.7953e-01, 8.2204e-01, 2.1626e-01, 7.9148e-01, 1.0956e-01, 9.9877e-01,
                nan,        nan, 9.7260e-01, 1.2079e+00, 7.0925e-01, 1.8236e+00,
         4.5693e-01, 1.1739e+00,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan],
        [       nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
         3.5872e-01, 4.7452e-01, 1.2244e+00, 9.7075e-01,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan],
        [9.3238e-01, 1.3091e+00, 6.8595e-01, 1.2866e-02, 2.7214e-01, 1.2400e+00,
         1.5005e+00, 3.5443e-01, 1.0630e+00, 4.5090e-01, 6.9906e-01, 6.0725e-02,
         5.5734e-01, 1.8241e+00, 2.2079e+00, 1.8852e+00, 1.8090e-01, 9.2063e-01,
         1.1596e+00, 2.3533e+00, 6.5143e-01, 4.3484e-01, 9.2684e-01, 1.1345e+00,
         2.3167e+00, 1.1409e+00, 1.8353e+00, 6.5164e-01, 9.4404e-01, 2.7933e+00,
         1.2419e+00, 6.8034e-01, 1.6179e+00, 8.3639e-01, 4.2629e-01, 8.6889e-01,
         2.4083e+00, 4.2067e-01, 7.5068e-01, 4.1924e-01, 1.9157e-01, 1.1042e+00,
         8.0505e-01, 8.2215e-01, 3.4485e+00, 7.9774e-01, 2.0162e-01, 6.5605e-01,
         2.1130e+00, 7.2650e-01, 9.2711e-01, 2.1720e+00, 1.2755e+00, 1.0939e+00,
         1.3573e+00, 4.5911e-01, 2.8829e-01, 2.4900e+00, 2.3349e+00, 9.3428e-01,
         5.4079e-01, 1.0553e+00, 6.6108e-01, 4.5551e-02, 7.0089e-01, 2.9686e+00,
         5.8511e-01, 2.2837e+00, 4.0368e-01, 2.5456e+00, 4.0335e-01, 2.4694e-01,
         1.1471e+00, 1.1804e+00, 1.1098e-01, 1.0315e+00, 8.6244e-01, 5.0026e+00,
         4.4186e-01, 2.3685e+00, 1.5258e+00, 2.8170e+00, 2.5288e-01, 1.0797e+00,
         1.6803e-01, 1.2595e+00, 1.3819e+00, 5.7400e-01, 1.2028e-01, 2.8812e-01,
         1.2326e+00, 1.9051e+00, 2.1879e+00, 3.3561e-01, 3.5627e-01, 6.1690e-01,
         6.7560e-02, 7.1431e+00, 2.2783e-01, 2.0076e+00, 1.2407e+00, 4.9220e-01,
         5.1557e-01, 1.9340e-01, 1.3235e+00, 5.4291e-01, 2.3288e-02, 1.0955e+00,
         1.6003e+00, 1.9051e+00, 1.5853e+00, 1.3382e+00, 2.7891e-01, 2.5371e+00,
         2.1771e+00, 1.2535e+00, 1.7893e+00, 2.5597e+00, 5.0325e-01, 7.4000e-01,
         6.0709e-01, 2.1962e+00, 1.1632e+00, 2.1233e+00, 1.5277e+00, 3.3324e-01,
         9.2168e-01, 8.2296e-01],
        [5.8108e-01, 9.5842e-01, 1.5866e+00, 1.8087e+00, 1.7769e+00, 7.6499e-01,
         3.6334e+00, 4.8851e-01, 1.0877e-01, 2.3846e-01, 2.7896e+00, 1.0055e+00,
         3.1878e+00, 3.9719e-01, 2.6672e+00, 4.5893e-01, 1.3947e+00, 3.8651e+00,
         7.6272e-01, 2.2164e+00, 1.9880e-02, 4.3912e+00, 3.6719e-01, 7.3805e-01,
         1.2123e+00, 2.1273e+00, 1.0412e+00, 2.1149e+00, 5.2610e-01, 1.4982e+00,
         2.6301e+00, 1.1814e+00, 3.3472e-01, 1.7020e+00, 2.0481e-01, 2.1118e-01,
         7.5365e-01, 7.3513e-01, 1.4575e+00, 1.8223e+00, 1.9065e+00, 5.9890e-01,
         1.8374e+00, 3.2156e+00, 4.3688e-01, 4.1903e+00, 1.4769e+00, 1.2137e+00,
         4.1893e-01, 1.6214e+00, 1.5961e+00, 7.0864e-01, 2.6211e+00, 1.6707e+00,
         5.7187e-01, 1.1404e+00, 3.2702e+00, 2.0061e+00, 1.6650e+00, 6.1186e-01,
         3.6937e+00, 1.9963e+00, 6.4440e-01, 2.6374e-02, 1.4779e+00, 1.2743e+00,
         1.0096e+00, 1.0910e+00, 6.1539e-01, 6.9198e-01, 1.4039e+00, 1.5678e+00,
         1.3688e+00, 1.3776e+00, 2.2453e+00, 1.6374e+00, 6.0708e-01, 2.4199e+00,
         2.3910e-01, 1.7660e+00, 3.4882e+00, 4.8812e-01, 1.9635e+00, 1.6450e-01,
         6.8502e-01, 4.3502e-02, 3.7749e-01, 7.6906e-01, 6.7683e-02, 7.5843e-01,
         9.8599e-02, 7.9534e-01, 1.0738e+00, 4.2902e-01, 1.0311e+00, 5.4248e-01,
         1.1637e+00, 1.0764e+00, 2.1979e+00, 7.3589e-01, 7.4595e-02, 2.6058e-01,
         4.4358e+00, 1.4313e-01, 1.2885e+00, 9.0676e-03, 1.6832e-01, 3.1399e+00,
         2.8048e+00, 1.0787e+00, 2.7416e+00, 3.1740e-01, 1.9452e+00, 4.9702e-01,
         1.0006e+00, 8.9645e-03, 1.2949e+00, 1.2209e+00, 1.5113e+00, 7.0166e-01,
         9.2694e-01, 1.7063e+00, 2.1022e+00, 1.5310e+00, 1.1409e+00, 9.4067e-01,
         1.4336e+00, 1.4373e+00],
        [4.6433e-01, 1.2480e-01, 6.8316e-02, 7.9347e-01, 1.3110e+00, 3.1705e-01,
         1.8433e+00, 2.0567e+00, 1.2015e+00, 6.0374e-01, 4.8383e-01, 1.9918e-02,
         1.3343e+00, 1.5035e-01, 3.7131e+00, 2.1676e+00, 8.1342e-01, 1.4590e+00,
         6.1374e-01, 1.7598e-01, 7.6697e-01, 4.6983e-01, 3.0507e+00, 4.5146e-01,
         4.7570e-01, 6.3940e-01, 1.0248e+00, 3.4280e+00, 1.8212e+00, 2.0342e+00,
         1.4378e+00, 8.0738e-01, 2.2544e-01, 1.3223e+00, 2.0715e+00, 1.2925e+00,
         1.9768e+00, 1.9799e+00, 1.2764e+00, 1.1893e-01, 1.8063e+00, 9.9341e-01,
         2.8336e+00, 1.6515e+00, 4.3149e-01, 1.3268e+00, 1.8230e+00, 1.4176e+00,
         2.3002e-01, 1.7639e+00, 2.3071e-02, 4.4433e-01, 3.2377e+00, 1.6876e+00,
         6.2418e-01, 1.6130e+00, 1.5235e+00, 4.2510e+00, 2.9897e+00, 2.5664e+00,
         3.8936e+00, 6.8794e-01, 1.3416e+00, 2.2833e+00, 1.5794e+00, 1.2198e+00,
         9.1732e-01, 1.5757e+00, 2.0011e+00, 5.5807e-01, 5.8095e-01, 8.5186e-01,
         1.1461e-01, 1.9658e+00, 2.9764e-01, 9.2317e-01, 1.4338e+00, 2.5816e-01,
         1.5788e+00, 4.0292e+00, 1.3728e-01, 6.9028e-01, 9.7213e-01, 8.4827e-01,
         1.9071e+00, 8.6488e-01, 1.6664e+00, 1.6234e+00, 1.7936e+00, 4.7555e+00,
         1.4110e+00, 7.5846e-02, 6.4877e-01, 2.0074e+00, 1.6231e+00, 2.3581e+00,
         2.0129e+00, 1.6610e+00, 7.0910e-02, 6.9002e-01, 2.2309e+00, 2.2638e+00,
         3.3097e-01, 1.1350e+00, 5.9823e-01, 1.9521e-03, 4.7233e-01, 2.7608e-01,
         5.6163e-01, 1.7075e+00, 4.2573e-02, 6.9236e-01, 1.0238e+00, 3.4634e-01,
         6.1742e-01, 2.9769e-01, 9.2717e-01, 4.3246e-01, 1.5714e+00, 3.4157e-01,
         8.8883e-01, 2.1655e+00, 9.7093e-01, 4.6074e-01, 6.2196e-01, 2.2397e+00,
         1.3142e+00, 1.6000e+00],
        [3.3729e-01, 1.9984e-01, 9.5503e-01, 9.8133e-01, 5.5160e-01, 1.6112e+00,
         4.1486e-01, 1.5227e+00, 1.5634e-01, 2.4690e-01, 8.9646e-01, 3.5558e-01,
         3.7179e-01, 2.1479e+00, 1.2446e-01, 1.4384e+00, 6.5917e-01, 6.7022e-01,
         3.0471e-02, 5.8855e-01, 1.5035e-01, 2.5745e-01, 1.4066e+00, 5.9431e-01,
         3.9644e+00, 1.1565e+00, 2.8084e-01, 1.4205e+00, 1.5328e+00, 1.9899e+00,
         1.7476e+00, 5.2021e-01, 2.5797e-01, 8.4505e-01, 9.2871e-01, 4.1657e-01,
         4.5117e-01, 9.5734e-01, 2.0041e+00, 1.0289e+00, 5.0095e-02, 4.2903e-01,
         1.1630e+00, 1.3341e-01, 1.7376e+00, 8.1582e-01, 2.2739e-01, 5.6321e-01,
         1.8223e+00, 7.4631e-01, 1.0909e+00, 3.1683e-01, 1.8129e+00, 1.8932e+00,
         1.7827e+00, 1.2453e+00, 1.0824e+00, 8.4666e-01, 8.5053e-01, 1.0146e+00,
         1.0914e+00, 9.4376e-01, 9.4773e-01, 1.3599e+00, 8.7811e-01, 2.2441e+00,
         4.6630e+00, 3.2494e-01, 2.9744e-01, 1.5322e-01, 1.2268e+00, 1.6590e+00,
         1.0223e+00, 1.5111e+00, 1.9542e+00, 1.5858e+00, 9.1915e-01, 2.5460e+00,
         7.6871e-02, 3.0900e-01, 1.0503e+00, 2.0244e+00, 7.0254e-02, 2.1650e+00,
         1.7780e-01, 2.6358e-01, 2.2268e+00, 2.1228e-02, 1.7837e-01, 1.0104e+00,
         4.1185e-01, 9.8298e-01, 7.1087e-01, 3.2140e+00, 3.8477e-01, 2.1269e+00,
         2.0913e+00, 2.8781e+00, 3.7072e-01, 2.3519e-01, 2.5579e+00, 4.9978e-01,
         4.4457e-03, 3.7210e-03, 9.2836e-02, 5.1187e-02, 7.0507e-01, 6.2559e-01,
         1.7247e+00, 2.5215e-02, 1.3550e+00, 4.7892e-01, 7.0387e-02, 2.6274e-01,
         9.1961e-01, 1.0039e+00, 6.3452e-01, 3.7979e-01, 2.1919e+00, 9.3590e-01,
         3.7676e-01, 2.5781e-01, 3.1701e-01, 1.1486e+00, 1.4704e-01, 9.5875e-01,
         1.1828e+00, 7.5140e-01],
        [2.1423e+00, 1.2836e-01, 1.4457e+00, 6.4596e-01, 8.3022e-01, 3.0667e+00,
         2.0525e-01, 2.0747e+00, 6.2158e-01, 1.4635e+00, 1.7496e-01, 1.1145e+00,
         1.3981e-01, 2.7829e+00, 2.7787e+00, 1.5496e+00, 6.3355e-01, 1.4679e+00,
         2.9300e-01, 3.7348e+00, 1.6910e-01, 1.5375e+00, 2.0156e+00, 3.1963e-01,
         3.4180e-01, 1.2818e+00, 2.4793e+00, 6.0144e-01, 1.9567e+00, 3.1056e-01,
         1.1063e+00, 1.7870e+00, 9.7094e-01, 2.7369e-01, 8.6576e-01, 2.1899e+00,
         3.6404e-01, 2.4314e+00, 5.1021e-01, 1.8638e-01, 1.4596e-01, 5.5754e-01,
         8.7030e-01, 2.8949e+00, 7.0905e-01, 1.3363e+00, 1.3042e+00, 1.9224e+00,
         1.5149e+00, 1.3280e+00, 3.0071e-01, 8.0820e-01, 1.0899e+00, 1.2070e+00,
         1.9628e-01, 2.6197e+00, 1.0906e+00, 1.3209e+00, 1.4969e+00, 4.2425e+00,
         1.3887e+00, 1.9164e+00, 6.9938e-01, 2.7939e-01, 2.8116e+00, 1.4277e+00,
         9.1536e-01, 4.6119e-01, 2.8415e+00, 2.0367e+00, 1.4490e+00, 4.2156e-01,
         9.2853e-01, 8.5608e-01, 1.2023e+00, 1.1709e+00, 1.6596e+00, 1.9700e+00,
         2.6661e-01, 8.5045e-01, 2.2334e+00, 2.4731e+00, 8.7389e-01, 9.4196e-01,
         2.0179e+00, 3.4348e-01, 2.9594e-01, 4.6226e-01, 1.0397e+00, 9.9118e-01,
         2.0426e+00, 2.7943e+00, 1.6920e+00, 4.4849e-01, 3.2795e-01, 3.6149e-01,
         1.3505e+00, 6.0725e-01, 2.3796e+00, 1.2338e-01, 2.2673e-02, 5.3047e-01,
         1.2463e+00, 8.5624e-01, 9.0618e-03, 5.6764e-01, 1.3850e+00, 2.3089e+00,
         4.5727e+00, 1.4038e-01, 1.7134e-01, 6.8161e-01, 6.0652e-02, 4.8055e-01,
         1.1527e+00, 9.3641e-01, 1.2708e+00, 1.3570e+00, 1.9547e+00, 3.8944e-01,
         1.2832e+00, 5.2332e-01, 1.2871e+00, 1.3659e+00, 1.2898e+00, 6.7376e-01,
         2.2297e+00, 5.1164e-01],
        [1.2299e+00, 8.2541e-02, 1.6990e+00, 1.4284e+00, 8.2702e-02, 1.3263e+00,
         3.4749e+00, 2.8278e-02, 2.0574e+00, 5.2905e-01, 1.1855e+00, 2.0969e-01,
         1.5359e-01, 3.0237e-01, 1.1448e+00, 1.0387e+00, 1.5408e+00, 1.0903e+00,
         3.5572e+00, 2.1137e+00, 9.2887e-02, 7.6594e-01, 2.0715e+00, 2.7854e-01,
         7.4972e-01, 6.1737e-01, 1.3057e+00, 4.1789e-01, 1.0401e+00, 4.5060e-02,
         2.5143e+00, 8.3797e-02, 2.1972e+00, 3.8843e-01, 2.7897e+00, 2.6274e+00,
         3.4738e-01, 1.7242e+00, 1.9245e+00, 1.5646e+00, 8.1292e-01, 2.2917e+00,
         3.2147e+00, 1.2298e-01, 1.4699e+00, 2.3166e+00, 2.8139e-01, 2.8435e+00,
         2.4312e+00, 5.6108e-01, 1.9856e-01, 3.8704e-01, 1.7938e+00, 1.1595e+00,
         3.7662e-01, 1.0784e+00, 4.0162e+00, 9.9936e-01, 7.8011e-01, 1.0722e+00,
         3.6880e+00, 1.4918e+00, 1.5941e+00, 3.9595e-01, 2.4199e+00, 2.1066e+00,
         1.8379e+00, 1.9318e+00, 2.7573e+00, 7.3497e-01, 5.3341e-01, 2.2331e+00,
                nan,        nan,        nan,        nan, 5.5537e-01, 1.3825e-01,
         4.7130e-01, 2.5257e+00, 4.1790e+00, 1.4122e-01, 1.2277e+00, 5.5369e-01,
         2.6498e+00, 1.4049e+00, 3.5504e+00, 1.9279e+00, 3.1270e-01, 1.6994e+00,
         1.2014e+00, 2.6607e+00, 3.1793e+00, 1.5821e+00, 1.2088e-01, 2.5550e+00,
         7.3676e-01, 9.1191e-01, 3.6645e+00, 1.1645e+00, 1.5467e-01, 2.0752e-01,
         4.0975e-01, 2.5545e+00, 4.7844e+00, 1.0872e+00, 1.6466e+00, 2.2857e-01,
         2.9583e-01, 4.2261e-01, 8.4826e-01, 2.1072e+00, 1.8939e+00, 7.2914e-01,
         8.1023e-01, 1.5871e+00, 1.1142e+00, 4.6992e+00, 1.5435e+00, 2.2038e+00,
         1.0245e+00, 5.3419e-01, 6.6536e-02, 3.3857e+00,        nan,        nan,
                nan,        nan],
        [2.2522e+00, 1.7839e+00, 3.2912e+00, 2.2120e+00,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan, 1.6007e+00, 2.1170e+00, 1.5507e-01, 1.4201e+00,
         1.2514e-01, 1.2202e+00, 4.8534e+00, 1.5224e-01, 6.4334e-01, 2.5028e+00,
         1.7829e+00, 2.9212e+00, 2.6528e-01, 1.3687e+00, 1.7556e+00, 1.8803e+00,
         4.1358e+00, 4.3077e-01, 1.1348e+00, 5.9068e-01,        nan,        nan,
         4.2183e-01, 2.7207e+00,        nan,        nan,        nan,        nan,
         3.0456e-02, 3.7407e+00, 7.2262e-01, 1.2377e-01, 1.6940e+00, 1.1876e+00,
         3.6018e+00, 1.6884e+00, 1.0163e+00, 1.6539e+00, 4.1474e-01, 1.0341e+00,
         1.8632e-02, 2.5905e+00, 1.8413e+00, 1.7114e+00,        nan,        nan,
                nan,        nan, 1.0658e+00, 5.2023e+00, 2.2488e+00, 3.4709e-01,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan, 2.1791e+00, 8.9066e-01, 2.9001e-01, 1.7716e+00,
         1.1702e+00, 2.7772e+00, 8.9321e-01, 1.3491e+00, 3.1355e+00, 9.7759e-02,
         1.6239e+00, 1.8431e+00, 2.3202e+00, 2.7279e-01, 9.8166e-01, 4.6356e-01,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan],
        [       nan,        nan,        nan,        nan,        nan,        nan,
         1.4514e+00, 1.2221e+00,        nan,        nan,        nan,        nan,
         9.6639e-01, 4.1529e-02, 2.0771e+00, 2.0918e-01,        nan,        nan,
                nan,        nan,        nan,        nan,        nan,        nan,
                nan,        nan, 2.2558e+00, 6.7808e-01,        nan,        nan,
         2.6999e+00, 1.3895e+00,        nan,        nan, 2.9978e+00, 3.8688e+00,
                nan,        nan, 7.8458e-01, 2.3071e+00,        nan,        nan,
         1.1511e-02, 1.8055e+00,        nan,        nan, 2.7080e+00, 1.2270e+00,
                nan,        nan, 3.7647e-02, 5.1410e-01,        nan,        nan,
         6.3326e-01, 1.3797e+00,        nan,        nan, 2.6656e-01, 1.2515e+00,
                nan,        nan, 3.4022e-01, 5.4263e-01,        nan,        nan,
         2.5652e-01, 8.4193e-02,        nan,        nan, 1.8612e+00, 2.6796e+00,
                nan,        nan, 3.4350e+00, 1.3509e+00,        nan,        nan,
         9.5325e-01, 8.3184e-02,        nan,        nan, 1.7877e+00, 3.4375e+00,
                nan,        nan, 2.7824e+00, 9.1453e-01,        nan,        nan,
         2.3456e-01, 3.3233e+00,        nan,        nan, 6.5623e-01, 4.9640e+00,
                nan,        nan, 1.1829e+00, 2.2605e-01,        nan,        nan,
         4.9390e-01, 1.3452e+00,        nan,        nan, 3.8999e-01, 5.0646e-02,
                nan,        nan, 5.3725e-01, 7.2688e-01,        nan,        nan,
         3.5576e-01, 2.9182e+00,        nan,        nan, 2.7665e-01, 8.7519e-01,
                nan,        nan, 7.3165e+28, 7.0371e+28,        nan,        nan,
         2.1033e+00, 8.8233e-01],
        [       nan,        nan, 1.9538e+00, 1.3277e+00,        nan,        nan,
         5.9153e-01, 3.5416e+00,        nan,        nan, 1.0178e+00, 2.6908e+00,
                nan,        nan, 6.5046e-01, 1.3241e-01,        nan,        nan,
         1.9936e+00, 7.0810e-01,        nan,        nan, 7.3165e+28, 1.7856e+31,
                nan,        nan, 1.8754e+28, 1.3528e+00,        nan,        nan,
         1.0857e+00, 2.0325e+00,        nan,        nan, 9.0632e-01, 1.0348e+00,
                nan,        nan, 7.3165e+28, 1.8389e+25,        nan,        nan,
         1.1461e+00, 1.5768e+00,        nan,        nan, 1.5853e-01, 3.0731e-01,
                nan,        nan, 2.5316e-01, 1.9094e+00,        nan,        nan,
         1.3648e+00, 5.2802e-01,        nan,        nan, 1.2342e+00, 2.9844e+00,
                nan,        nan, 8.4164e-01, 1.9646e+00,        nan,        nan,
         7.3165e+28, 2.8175e+20,        nan,        nan, 1.5514e+00, 2.4776e+00,
                nan,        nan, 1.8050e-01, 1.3320e+00,        nan,        nan,
         6.9001e-01, 7.5343e-01,        nan,        nan, 8.1720e-01, 3.2619e+00,
                nan,        nan, 3.2793e-01, 1.2255e+00,        nan,        nan,
         1.3265e+00, 7.3740e-01,        nan,        nan, 7.3165e+28, 1.8174e+31,
                nan,        nan, 2.0715e+00, 1.6697e+00,        nan,        nan,
         1.5815e+00, 2.0086e+00,        nan,        nan, 5.1096e-01, 5.5478e-01,
                nan,        nan, 2.6217e+20, 2.5763e+20,        nan,        nan,
         8.7789e-01, 1.7826e+00,        nan,        nan, 2.2369e+00, 1.1946e-01,
                nan,        nan, 6.8285e-01, 9.4380e-01,        nan,        nan,
         2.6217e+20, 2.5763e+20],
        [       nan,        nan, 2.9101e+00, 1.1117e+00,        nan,        nan,
         1.6076e-01, 5.9835e-01,        nan,        nan, 2.7252e+00, 2.3683e+00,
                nan,        nan, 2.6217e+20, 2.5763e+20,        nan,        nan,
         9.6639e-02, 3.4798e+00,        nan,        nan, 2.4398e-01, 1.7278e+00,
                nan,        nan, 2.3808e+00, 3.2655e+00,        nan,        nan,
         2.6217e+20, 4.1220e+21,        nan,        nan, 6.2989e-01, 1.0711e+00,
                nan,        nan, 8.2536e-01, 1.6205e+00,        nan,        nan,
         5.9085e-01, 1.4178e+00,        nan,        nan, 2.6217e+20, 4.1220e+21,
                nan,        nan, 1.4744e+00, 5.9652e-01,        nan,        nan,
         1.0162e+00, 2.6878e+00,        nan,        nan, 4.4710e-01, 7.6375e-01,
                nan,        nan, 2.6217e+20, 1.6488e+22,        nan,        nan,
         3.4180e+00, 1.1556e+00,        nan,        nan, 2.0718e-02, 1.6881e+00,
                nan,        nan, 3.4909e-01, 1.3170e-01,        nan,        nan,
         2.6217e+20, 4.3222e+27,        nan,        nan, 1.4544e+00, 1.1678e+00,
                nan,        nan, 4.8592e-01, 3.7146e+00,        nan,        nan,
         1.9550e+00, 2.7727e+00,        nan,        nan, 2.6217e+20, 4.3222e+27,
                nan,        nan, 1.3572e+00, 8.3427e-01,        nan,        nan,
         1.2032e+00, 2.1827e+00,        nan,        nan, 9.4071e-01, 4.6467e-01,
                nan,        nan, 2.6217e+20, 4.3222e+27,        nan,        nan,
         1.4321e+00, 2.6515e+00,        nan,        nan, 5.3547e-01, 1.4065e-01,
                nan,        nan, 1.2795e+00, 1.1457e+00,        nan,        nan,
         2.6217e+20, 1.7289e+28],
        [       nan,        nan, 2.8927e+00, 2.9411e+00,        nan,        nan,
         8.4442e-01, 7.8115e-01,        nan,        nan, 3.6870e-01, 2.5759e-01,
                nan,        nan, 7.3165e+28, 7.5014e+28,        nan,        nan,
         1.8795e+24, 2.3605e+00,        nan,        nan, 1.6838e+00, 1.0703e+00,
                nan,        nan, 2.8036e+00, 6.8646e-02,        nan,        nan,
         7.3165e+28, 7.5014e+28,        nan,        nan, 1.1779e+24, 2.7373e+20,
                nan,        nan, 7.1714e-01, 1.3072e+00,        nan,        nan,
         4.8507e-01, 1.9151e+00,        nan,        nan, 1.1044e+00, 1.7278e+00,
                nan,        nan, 2.6217e+20, 2.7662e+29,        nan,        nan,
         2.1663e+00, 1.7979e+00,        nan,        nan, 1.4781e+00, 8.2666e-01,
                nan,        nan, 2.3107e+00, 1.1790e+00,        nan,        nan,
         2.6217e+20, 4.4260e+30,        nan,        nan, 1.3382e+00, 1.6652e-01,
                nan,        nan, 7.6496e-01, 5.5004e-01,        nan,        nan,
         8.6769e-02, 1.6074e+00,        nan,        nan, 7.3165e+28, 7.5014e+28,
                nan,        nan, 4.2321e+21, 2.5251e+00,        nan,        nan,
         2.8747e+00, 2.0096e+00,        nan,        nan, 3.2883e-01, 3.9914e-01,
                nan,        nan, 7.3165e+28, 7.5014e+28,        nan,        nan,
         7.3020e+31, 2.7086e+23,        nan,        nan, 1.6224e+00, 9.3623e-01,
                nan,        nan, 2.0393e-01, 2.5048e-01,        nan,        nan,
         6.2621e-01, 1.4487e+00,        nan,        nan, 2.6217e+20, 1.7704e+31,
                nan,        nan, 2.5763e+20, 4.6168e+24,        nan,        nan,
         9.0221e-01, 2.0545e+00],
        [       nan,        nan, 2.4071e+00, 1.1589e+00,        nan,        nan,
         1.1093e+00, 4.2005e+00,        nan,        nan, 2.6217e+20, 1.7704e+31,
                nan,        nan, 1.0806e+27, 4.3055e+21,        nan,        nan,
         2.1496e+00, 1.4325e+00,        nan,        nan, 7.1491e-01, 2.1378e+00,
                nan,        nan, 8.1491e-01, 7.3856e-01,        nan,        nan,
         2.6217e+20, 1.7704e+31,        nan,        nan, 1.5760e-01, 3.4796e+00,
                nan,        nan, 1.9867e+00, 1.5298e+00,        nan,        nan,
         1.0169e+00, 1.1895e+00,        nan,        nan, 2.6217e+20, 1.8129e+34,
                nan,        nan, 2.0373e+00, 3.0427e+00,        nan,        nan,
         1.4589e+00, 8.2899e-01,        nan,        nan, 6.0159e-01, 2.4294e+00,
                nan,        nan, 2.6217e+20, 2.9006e+35,        nan,        nan,
         1.6852e+00, 1.2269e+00,        nan,        nan, 1.8509e-01, 6.3055e-01,
                nan,        nan, 8.7726e-01, 2.0620e+00,        nan,        nan,
         1.0363e+00, 4.8751e-01,        nan,        nan, 1.6177e+00, 7.3547e-02,
                nan,        nan, 1.3779e+00, 8.0052e-01,        nan,        nan,
         7.3165e+28, 1.8522e+28,        nan,        nan, 7.9379e-01, 3.8678e+00,
                nan,        nan, 3.6015e+00, 6.8802e-01,        nan,        nan,
         1.8744e+00, 5.7674e-01,        nan,        nan, 7.3165e+28, 1.8522e+28,
                nan,        nan, 4.7976e+00, 3.5636e-01,        nan,        nan,
         5.2892e-01, 8.9144e-01,        nan,        nan, 1.9299e+00, 1.6312e-01,
                nan,        nan, 2.5277e+00, 9.4288e-01,        nan,        nan,
         2.4856e+00, 2.6850e-01],
        [       nan,        nan, 1.2822e+00, 1.9907e+00,        nan,        nan,
         7.3165e+28, 1.1022e+24,        nan,        nan, 2.1068e-01, 1.6942e+00,
                nan,        nan, 4.4111e-01, 2.1767e+00,        nan,        nan,
         2.0883e-01, 3.3116e-01,        nan,        nan, 1.2089e+33, 3.3351e+00,
                nan,        nan, 5.5238e+00, 1.9917e+00,        nan,        nan,
         3.3337e+00, 1.6055e+00,        nan,        nan, 7.3165e+28, 2.8617e+23,
                nan,        nan, 1.7915e-01, 1.0737e+00,        nan,        nan,
         7.1575e-01, 5.8811e-01,        nan,        nan, 2.7409e+00, 9.9030e-02,
         2.5432e+00, 6.6696e-01, 1.3974e+00, 1.4068e+00, 2.4557e-01, 8.6836e-01,
         1.2818e+00, 1.0918e+00, 2.6688e+00, 1.1009e+00, 2.1673e+00, 1.7978e+00,
                nan,        nan, 7.3165e+28, 1.7540e+19,        nan,        nan,
         2.2735e+00, 8.3470e-01,        nan,        nan, 1.7893e+00, 2.0355e+00,
                nan,        nan, 1.2644e+00, 1.0310e+00,        nan,        nan,
         1.6674e+19, 3.8834e+00,        nan,        nan, 1.3345e-01, 1.1829e+00,
                nan,        nan, 2.1499e-01, 1.6090e+00,        nan,        nan,
         7.3165e+28, 1.7540e+19,        nan,        nan, 1.2689e-01, 1.1335e+00,
                nan,        nan, 1.8797e+00, 1.8313e+00,        nan,        nan,
         6.2667e-01, 1.8095e-01,        nan,        nan, 1.0147e+00, 1.3343e+00,
                nan,        nan, 1.3557e+00, 1.7582e-01,        nan,        nan,
         1.3632e+00, 3.3794e-01,        nan,        nan, 7.3165e+28, 1.8614e+34,
                nan,        nan, 1.7753e+00, 4.1107e+00,        nan,        nan,
         2.0915e+00, 1.3931e+00],
        [       nan,        nan, 1.5260e-01, 8.2036e-01,        nan,        nan,
         4.3600e+27, 3.3365e-01,        nan,        nan, 2.1073e+00, 2.9455e-01,
                nan,        nan, 2.1410e-01, 7.6142e-01, 1.6319e+00, 1.9609e+00,
         3.5735e-01, 1.4459e-01, 5.7859e-01, 7.3659e-01, 1.9740e-01, 1.2873e+00,
         1.1633e+00, 1.7070e+00, 2.7167e+00, 2.0824e+00, 2.7972e+00, 7.3496e-01,
         6.7686e-01, 9.6955e-01, 9.3467e-01, 1.2026e+00, 1.8200e-01, 1.1751e+00,
         2.2127e+00, 3.5339e-01, 3.2457e+00, 4.8037e-01, 1.6458e+00, 3.8453e-01,
         6.5244e-01, 1.1975e+00, 4.9162e-01, 9.4735e-01, 1.6799e+00, 1.1612e+00,
         1.0238e+00, 2.7203e-01, 3.8135e-01, 3.8827e-01, 1.4374e-01, 2.2235e-01,
         5.1027e-01, 5.2767e-03, 7.4974e-01, 1.2004e+00, 1.4395e+00, 6.5872e-01,
         8.3972e-01, 4.2283e-01, 2.7344e-01, 5.4804e-01, 1.2942e+00, 3.2162e+00,
         1.6027e+00, 3.7643e-01, 9.8502e-01, 1.3693e-01, 1.2179e+00, 1.4960e+00,
         4.7017e-01, 6.7681e-01, 1.7519e+00, 7.7016e-01, 1.7506e+00, 5.3829e-01,
         4.0043e-01, 5.2626e-01, 1.3093e+00, 1.5610e+00, 8.5123e-01, 1.0494e+00,
         1.0199e+00, 9.0016e-01, 1.1458e+00, 1.2593e+00, 1.1048e+00, 3.2003e+00,
         4.1845e-01, 4.9583e-01, 1.8120e-01, 1.7116e+00, 1.9925e-01, 4.8517e-01,
         1.5218e+00, 1.3332e-01, 6.0636e-01, 8.5001e-01, 7.1873e-01, 2.3917e-01,
         1.1994e+00, 1.0156e+00, 1.0838e-01, 2.5464e-01, 1.4986e-01, 2.8883e-01,
         1.3462e+00, 1.6223e+00, 6.1610e-01, 5.4627e-01, 2.1282e+00, 7.4102e-01,
         1.5712e-01, 3.1977e-02, 2.1705e+00, 8.0171e-01, 3.1025e-01, 3.9058e-02,
         1.6093e+00, 2.4248e+00, 1.0462e+00, 1.2253e+00, 1.3576e+00, 1.2445e+00,
         2.4135e+00, 5.3112e-01]], grad_fn=<AbsBackward0>)
FAILED

=================================== FAILURES ===================================
__________________________ test_linear_param_sharded ___________________________

    @pytest.mark.usefixtures("use_xla_spmd_environment")
    def test_linear_param_sharded():
        class Basic(nn.Module):
            def __init__(self):
                super().__init__()
                self.sharded_weight = nn.Parameter(torch.randn(32, 128))
    
            def forward(self, x):
                return x @ self.sharded_weight
    
        cc = CompilerConfig()
        cc.xla_mesh = create_device_mesh()
    
        test_class = Basic()
        weight_shard_spec = (None, "model")
        sharding_utils.mark_sharding(test_class.sharded_weight, weight_shard_spec)
    
        # Check that sharding annotation worked
        assert sharding_utils.get_sharding(test_class.sharded_weight) == weight_shard_spec
    
        weak_ref = weakref.ref(test_class.sharded_weight)
    
        # Check that the PCC between the ondevice sharded matmul and CPU unsharded matmul is the same
>       verify_module(test_class, input_shapes=[(32, 32)], compiler_config=cc)

tests/torch/test_basic_sharding.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tt_torch/tools/utils.py:981: in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
tt_torch/tools/verify.py:346: in verify_module
    _verify_torch_module(
tt_torch/tools/verify.py:252: in _verify_torch_module
    verify_against_golden(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

golden_tensors = (tensor([[-4.4558e-01, -1.3957e+00,  6.0367e-01, -1.8950e+00,  7.1571e-01,
          1.0825e+00,  6.3741e-01, -1.8950e...e+00,  1.0462e+00,  1.2253e+00, -1.3576e+00,
         -1.2445e+00, -2.4135e+00,  5.3112e-01]], grad_fn=<MmBackward0>),)
calculated_tensors = (tensor([[-4.4490e-01, -1.3950e+00,  6.0277e-01, -1.8932e+00,  7.1603e-01,
          1.0805e+00,  6.3535e-01, -1.8944e...,  2.8042e-08,  0.0000e+00,  8.3097e-36,
          4.5764e-41,  2.8305e-08,  0.0000e+00]], grad_fn=<ToCopyBackward0>),)
assert_pcc = True, assert_atol = True, required_pcc = 0.99, required_atol = 0.01
relative_atol = None, disable_print = False

    def verify_against_golden(
        golden_tensors,
        calculated_tensors,
        assert_pcc,
        assert_atol,
        required_pcc=0.99,
        required_atol=None,
        relative_atol=None,
        disable_print=False,
    ):
        assert (required_atol is not None) != (
            relative_atol is not None
        ), "Exactly one of atol or relative_atol should be provided."
        assert isinstance(
            golden_tensors, tuple
        ), f"Expecting the golden tensors to be a tuple of tensors after _extract_outputs. Got type: {type(golden_tensors)}"
        assert isinstance(
            calculated_tensors, tuple
        ), f"Expecting the calculated tensors to be a tuple of tensors after _extract_outputs. Got type: {type(calculated_tensors)}"
        assert len(golden_tensors) == len(
            calculated_tensors
        ), f"Expecting the number of golden tensors (ct: {len(golden_tensors)}) and calculated tensors (ct: {len(calculated_tensors)}) to be the same."
    
        pccs, pcc_passeds = [], []
        atols, atol_thresholds, atols_passeds = [], [], []
    
        # Distinct value to put in the `pccs` list so we can append the correct log
        SKIPPED_PCC_CALCULATION_FOR_SINGLE_VALUE = None
        SKIPPED_NON_TENSOR_ITEM = None
    
        for i, (golden, calculated) in enumerate(zip(golden_tensors, calculated_tensors)):
            if not isinstance(golden, torch.Tensor) or not isinstance(
                calculated, torch.Tensor
            ):
                # For non-tensor items, check exact equality
                if golden == calculated:
                    pccs.append(SKIPPED_NON_TENSOR_ITEM)
                    pcc_passeds.append(True)
                    atols.append(SKIPPED_NON_TENSOR_ITEM)
                    atol_thresholds.append(0)
                    atols_passeds.append(True)
                else:
                    # Items don't match
                    pccs.append(SKIPPED_NON_TENSOR_ITEM)
                    pcc_passeds.append(False)
                    atols.append(SKIPPED_NON_TENSOR_ITEM)
                    atol_thresholds.append(0)
                    atols_passeds.append(False)
                continue
            assert (
                golden.shape == calculated.shape
            ), f"Shape mismatch on output {i}: {golden.shape} vs {calculated.shape}"
            assert isinstance(golden, torch.Tensor) and isinstance(
                calculated, torch.Tensor
            ), f"Expecting both golden and calculated tensors to be of type torch.Tensor for output {i}, but got golden: {type(golden)} and calculated: {type(calculated)}"
    
            if golden.flatten().size() == (1,):
                pcc_ = SKIPPED_PCC_CALCULATION_FOR_SINGLE_VALUE
                pcc_passeds.append(True)
            else:
                pcc_ = calculate_pcc(golden, calculated)
                pcc_passeds.append(pcc_ >= required_pcc)
            pccs.append(pcc_)
    
            if relative_atol is not None:
                max_value = (torch.max(torch.abs(golden[~torch.isnan(golden)]))).item()
                required_atol = max_value * relative_atol
    
            atol_thresholds.append(required_atol)
            atol_ = calculate_atol(golden, calculated)
            atols.append(atol_)
            atols_passeds.append(atol_ <= required_atol)
    
        check_mark = "\U00002705"
        red_x = "\U0000274C"
        warning = "\U0000274E"
    
        pcc_warning = f"{warning} (assert_pcc == False)"
        atol_warning = f"{warning} (assert_atol == False)"
    
        passed_pcc = True
        passed_atol = True
        err_msg = ""
        msg = ""
    
        # Iterate over all tensors and their results and build a message for printing.
        for i, ((pcc_passed, pcc_), (atol_passed, atol_), atol_threshold) in enumerate(
            zip(zip(pcc_passeds, pccs), zip(atols_passeds, atols), atol_thresholds)
        ):
            msg = msg + f"Results for output {i}:\n"
            if pcc_passed:
                if (
                    pcc_ != SKIPPED_PCC_CALCULATION_FOR_SINGLE_VALUE
                    or pcc_ != SKIPPED_NON_TENSOR_ITEM
                ):
                    msg = msg + f"  PCC: {pcc_:0,.4f}, threshold: {required_pcc} "
                    msg = msg + f"{check_mark}\n"
            else:
                msg = msg + f"  PCC: {pcc_:0,.4f}, threshold: {required_pcc} "
                msg = msg + f"{red_x if assert_pcc else pcc_warning}\n"
                err_msg = (
                    err_msg
                    + f"PCC of output {i}: {pcc_:0,.4f}, threshold: {required_pcc} {red_x if assert_pcc else pcc_warning}\n"
                )
                passed_pcc = False
    
            if atol_passed:
                if atol_ != SKIPPED_NON_TENSOR_ITEM:
                    msg = (
                        msg
                        + f"  ATOL: {atol_:0,.4f}, threshold: {atol_threshold}{f' (calculated using relative_atol: {relative_atol})' if relative_atol is not None else ''} "
                    )
                    msg = msg + f"{check_mark}\n"
                msg = msg + f"{check_mark}\n"
            else:
                if atol_ != SKIPPED_NON_TENSOR_ITEM:
                    msg = (
                        msg
                        + f"  ATOL: {atol_:0,.4f}, threshold: {atol_threshold}{f' (calculated using relative_atol: {relative_atol})' if relative_atol is not None else ''} "
                    )
                msg = msg + f"{red_x if assert_atol else atol_warning}\n"
                err_msg = (
                    err_msg
                    + f"ATOL of output {i}: {atol_:0,.4f}, threshold: {atol_threshold}{f' (calculated using relative_atol: {relative_atol})' if relative_atol is not None else ''} {red_x if assert_atol else atol_warning}\n"
                )
                passed_atol = False
    
        # Now that all tensors are checked, print the final message
        if assert_pcc and assert_atol:
            if not passed_pcc or not passed_atol:
>               assert False, err_msg
                       ^^^^^
E               AssertionError: PCC of output 0: 0.0051, threshold: 0.99 ❌
E               ATOL of output 0: nan, threshold: 0.01 ❌

tt_torch/tools/verify.py:189: AssertionError
=============================== warnings summary ===============================
tests/torch/test_basic_sharding.py::test_linear_param_sharded
  /localdev/jameszianxu/daily/tt-torch/tt_torch/dynamo/experimental/xla_backend.py:739: DeprecationWarning: Use torch_xla.sync instead
    xm.mark_step()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/torch/test_basic_sharding.py::test_linear_param_sharded - AssertionError: PCC of output 0: 0.0051, threshold: 0.99 ❌
ATOL of output 0: nan, threshold: 0.01 ❌
========================= 1 failed, 1 warning in 8.51s =========================
